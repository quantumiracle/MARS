pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526/pettingzoo_pong_v2_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526/pettingzoo_pong_v2_nfsp.
Episode: 1/10000 (0.0100%),                 avg. length: 1349.0,                last time consumption/overall running time: 9.0235s / 9.0235 s
env0_first_0:                 episode reward: 2.0000,                 loss: nan
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 9.0000,                 loss: nan
env1_second_0:                 episode reward: -9.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1174.25,                last time consumption/overall running time: 572.5947s / 581.6182 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0034
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0033
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1183.05,                last time consumption/overall running time: 860.3504s / 1441.9686 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0032
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0034
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1280.5,                last time consumption/overall running time: 949.2227s / 2391.1914 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0091
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0079
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1887.95,                last time consumption/overall running time: 1415.5822s / 3806.7736 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0208
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0122
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 3013.8,                last time consumption/overall running time: 2272.4475s / 6079.2211 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0116
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0069
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 2986.8,                last time consumption/overall running time: 2254.3837s / 8333.6048 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0052
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0044
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 2827.55,                last time consumption/overall running time: 2133.9031s / 10467.5079 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0051
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0043
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 3260.6,                last time consumption/overall running time: 2459.5309s / 12927.0388 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 9.0000,                 loss: 0.0042
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 2989.75,                last time consumption/overall running time: 2255.6555s / 15182.6943 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0045
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0035
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 3086.8,                last time consumption/overall running time: 2328.8146s / 17511.5089 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0048
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0039
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 3011.55,                last time consumption/overall running time: 2270.3858s / 19781.8947 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.0042
env0_second_0:                 episode reward: 8.7500,                 loss: 0.0036
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 2985.55,                last time consumption/overall running time: 2252.2846s / 22034.1793 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0033
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 2922.8,                last time consumption/overall running time: 2203.4777s / 24237.6570 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0044
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0038
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 3106.1,                last time consumption/overall running time: 2345.6519s / 26583.3089 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0034
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 3224.65,                last time consumption/overall running time: 2430.8971s / 29014.2060 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0042
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0033
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 2981.85,                last time consumption/overall running time: 2248.2705s / 31262.4765 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0033
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 3298.95,                last time consumption/overall running time: 2486.0875s / 33748.5640 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0046
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0035
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 3276.2,                last time consumption/overall running time: 2469.9439s / 36218.5079 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0047
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0028
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 3374.9,                last time consumption/overall running time: 2816.9134s / 39035.4213 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0031
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 3413.85,                last time consumption/overall running time: 3039.2567s / 42074.6780 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0030
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 3211.15,                last time consumption/overall running time: 2862.7907s / 44937.4687 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0043
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 3160.0,                last time consumption/overall running time: 2827.2186s / 47764.6872 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0041
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 3267.9,                last time consumption/overall running time: 2923.4437s / 50688.1309 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0037
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 3153.05,                last time consumption/overall running time: 2813.8849s / 53502.0159 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0028
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 3078.3,                last time consumption/overall running time: 2747.1115s / 56249.1273 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0041
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0028
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 3013.6,                last time consumption/overall running time: 2688.2423s / 58937.3696 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0030
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 3085.55,                last time consumption/overall running time: 2753.5129s / 61690.8826 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0029
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 2809.4,                last time consumption/overall running time: 2507.0967s / 64197.9793 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0037
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0029
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 3011.1,                last time consumption/overall running time: 2686.6023s / 66884.5816 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0029
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 3267.3,                last time consumption/overall running time: 2915.9392s / 69800.5209 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0027
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 3209.4,                last time consumption/overall running time: 2862.9579s / 72663.4788 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0036
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 3373.15,                last time consumption/overall running time: 3012.7911s / 75676.2699 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0036
env0_second_0:                 episode reward: 11.1500,                 loss: 0.0023
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 3330.75,                last time consumption/overall running time: 2976.6262s / 78652.8961 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0037
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0025
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 3353.1,                last time consumption/overall running time: 2994.3893s / 81647.2854 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0037
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0028
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 2914.65,                last time consumption/overall running time: 2603.2817s / 84250.5671 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0039
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0027
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 3169.9,                last time consumption/overall running time: 2829.4503s / 87080.0174 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 3056.35,                last time consumption/overall running time: 2728.7694s / 89808.7869 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.4500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 3100.2,                last time consumption/overall running time: 2769.7049s / 92578.4918 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 3266.55,                last time consumption/overall running time: 2922.7354s / 95501.2271 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0027
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 3249.65,                last time consumption/overall running time: 2900.4629s / 98401.6901 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0035
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0024
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 3367.35,                last time consumption/overall running time: 3002.5760s / 101404.2661 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0035
env0_second_0:                 episode reward: 11.0000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 3078.2,                last time consumption/overall running time: 2746.3178s / 104150.5839 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.0039
env0_second_0:                 episode reward: 12.5000,                 loss: 0.0025
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 3110.3,                last time consumption/overall running time: 2774.9400s / 106925.5239 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0024
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 3325.7,                last time consumption/overall running time: 2963.0939s / 109888.6178 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0037
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 3072.5,                last time consumption/overall running time: 2738.5397s / 112627.1575 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.0037
env0_second_0:                 episode reward: 9.8000,                 loss: 0.0028
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 3071.35,                last time consumption/overall running time: 2739.0238s / 115366.1812 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 3092.35,                last time consumption/overall running time: 2757.8101s / 118123.9914 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0029
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 2964.9,                last time consumption/overall running time: 2643.4370s / 120767.4283 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0037
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0027
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 2862.9,                last time consumption/overall running time: 2553.5679s / 123320.9962 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0027
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 3052.4,                last time consumption/overall running time: 2720.8151s / 126041.8113 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0037
env0_second_0:                 episode reward: 13.2500,                 loss: 0.0024
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 2987.6,                last time consumption/overall running time: 2666.0477s / 128707.8589 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0038
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 3257.05,                last time consumption/overall running time: 2906.2335s / 131614.0924 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0029
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 3438.9,                last time consumption/overall running time: 3067.0759s / 134681.1683 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0035
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0025
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 3253.25,                last time consumption/overall running time: 2899.6877s / 137580.8560 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0036
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0023
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 3374.0,                last time consumption/overall running time: 3008.0938s / 140588.9499 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0035
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 3422.85,                last time consumption/overall running time: 3050.5415s / 143639.4914 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0036
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 3287.05,                last time consumption/overall running time: 2733.4944s / 146372.9857 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0035
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 3287.0,                last time consumption/overall running time: 2541.2030s / 148914.1888 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0035
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0025
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 2966.9,                last time consumption/overall running time: 2265.8777s / 151180.0664 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0035
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0025
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 3084.15,                last time consumption/overall running time: 2352.5312s / 153532.5977 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0037
env0_second_0:                 episode reward: 11.4500,                 loss: 0.0026
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 3122.95,                last time consumption/overall running time: 2383.8415s / 155916.4392 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0040
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 3060.35,                last time consumption/overall running time: 2333.1018s / 158249.5410 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0038
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0024
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 2966.1,                last time consumption/overall running time: 2266.8777s / 160516.4187 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0036
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0024
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 3060.35,                last time consumption/overall running time: 2333.7150s / 162850.1337 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0039
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 3364.5,                last time consumption/overall running time: 2563.8583s / 165413.9920 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0044
env0_second_0:                 episode reward: 9.2500,                 loss: 0.0027
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 3147.15,                last time consumption/overall running time: 2396.8065s / 167810.7985 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 3039.2,                last time consumption/overall running time: 2317.9397s / 170128.7382 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0034
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0022
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 3122.5,                last time consumption/overall running time: 2379.2094s / 172507.9476 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0036
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0029
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 3297.35,                last time consumption/overall running time: 2514.2955s / 175022.2431 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0036
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0028
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 3138.3,                last time consumption/overall running time: 2390.4258s / 177412.6689 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0036
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0026
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 2975.1,                last time consumption/overall running time: 2264.3079s / 179676.9769 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 12.8500,                 loss: 0.0026
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 3016.4,                last time consumption/overall running time: 2295.1185s / 181972.0953 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0024
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 3282.85,                last time consumption/overall running time: 2501.5843s / 184473.6796 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 3230.1,                last time consumption/overall running time: 2456.8856s / 186930.5652 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0037
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0024
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 3307.7,                last time consumption/overall running time: 2517.8783s / 189448.4434 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0036
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0023
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 3359.55,                last time consumption/overall running time: 2551.1352s / 191999.5787 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0036
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 3240.85,                last time consumption/overall running time: 2456.9404s / 194456.5191 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0037
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 3356.55,                last time consumption/overall running time: 2544.4583s / 197000.9774 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.9500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 3080.45,                last time consumption/overall running time: 2335.0017s / 199335.9791 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0027
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 3182.6,                last time consumption/overall running time: 2405.0683s / 201741.0474 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0030
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 3316.35,                last time consumption/overall running time: 2505.0846s / 204246.1320 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0037
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0026
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 3104.85,                last time consumption/overall running time: 2343.7146s / 206589.8466 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.0037
env0_second_0:                 episode reward: 13.9500,                 loss: 0.0024
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 3203.45,                last time consumption/overall running time: 2419.6780s / 209009.5246 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 3317.1,                last time consumption/overall running time: 2506.2901s / 211515.8147 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0029
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 3303.95,                last time consumption/overall running time: 2496.0895s / 214011.9041 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 3256.35,                last time consumption/overall running time: 2458.5197s / 216470.4239 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0025
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 3272.1,                last time consumption/overall running time: 2467.6616s / 218938.0854 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0024
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 3111.05,                last time consumption/overall running time: 2347.4233s / 221285.5088 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.0039
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0023
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 3436.8,                last time consumption/overall running time: 2591.2254s / 223876.7342 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0035
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0024
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 3361.9,                last time consumption/overall running time: 2530.3504s / 226407.0846 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0036
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0023
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 3151.65,                last time consumption/overall running time: 2372.0489s / 228779.1335 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0026
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 3357.4,                last time consumption/overall running time: 2525.6849s / 231304.8184 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0037
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0024
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 3324.7,                last time consumption/overall running time: 2507.4677s / 233812.2861 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0037
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0025
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 2980.6,                last time consumption/overall running time: 2245.9643s / 236058.2504 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 12.4500,                 loss: 0.0024
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 3185.85,                last time consumption/overall running time: 2401.6573s / 238459.9077 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0043
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0027
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 3084.3,                last time consumption/overall running time: 2324.3469s / 240784.2546 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0025
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 2969.0,                last time consumption/overall running time: 2236.2143s / 243020.4689 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0025
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 3125.1,                last time consumption/overall running time: 2355.0367s / 245375.5056 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0023
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2963.55,                last time consumption/overall running time: 2231.8026s / 247607.3082 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0028
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 2808.5,                last time consumption/overall running time: 2117.2477s / 249724.5559 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.0041
env0_second_0:                 episode reward: 12.0000,                 loss: 0.0024
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 3072.6,                last time consumption/overall running time: 2315.5108s / 252040.0667 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0024
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 2849.95,                last time consumption/overall running time: 2144.7676s / 254184.8343 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0021
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 3111.75,                last time consumption/overall running time: 2342.6434s / 256527.4776 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.4000,                 loss: 0.0025
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 3048.45,                last time consumption/overall running time: 2291.4102s / 258818.8878 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0036
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0021
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 3084.55,                last time consumption/overall running time: 2317.9690s / 261136.8568 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.0039
env0_second_0:                 episode reward: 13.4000,                 loss: 0.0024
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 3030.45,                last time consumption/overall running time: 2276.9328s / 263413.7896 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.8500,                 loss: 0.0024
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 3178.55,                last time consumption/overall running time: 2388.0011s / 265801.7907 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0024
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2978.65,                last time consumption/overall running time: 2236.9746s / 268038.7653 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0024
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 3120.45,                last time consumption/overall running time: 2344.8745s / 270383.6398 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0044
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0027
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 3115.3,                last time consumption/overall running time: 2342.2601s / 272725.8999 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 3014.3,                last time consumption/overall running time: 2264.1159s / 274990.0158 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 12.8500,                 loss: 0.0026
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 3046.85,                last time consumption/overall running time: 2288.2060s / 277278.2218 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0035
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0023
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 3598.7,                last time consumption/overall running time: 2702.1867s / 279980.4085 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0036
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0025
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 3278.35,                last time consumption/overall running time: 2461.5222s / 282441.9307 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0037
env0_second_0:                 episode reward: 11.1500,                 loss: 0.0023
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 3391.75,                last time consumption/overall running time: 2544.9876s / 284986.9183 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.0034
env0_second_0:                 episode reward: 11.8500,                 loss: 0.0022
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 3436.5,                last time consumption/overall running time: 2578.4115s / 287565.3298 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0034
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0021
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 3392.45,                last time consumption/overall running time: 2546.5838s / 290111.9136 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0035
env0_second_0:                 episode reward: 11.4500,                 loss: 0.0023
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 3115.65,                last time consumption/overall running time: 2334.1030s / 292446.0167 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.0039
env0_second_0:                 episode reward: 12.1000,                 loss: 0.0024
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 3219.0,                last time consumption/overall running time: 2408.2164s / 294854.2331 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0037
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0023
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 3143.05,                last time consumption/overall running time: 2354.1818s / 297208.4149 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.0035
env0_second_0:                 episode reward: 11.8500,                 loss: 0.0026
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 3488.6,                last time consumption/overall running time: 2609.8137s / 299818.2286 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0025
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 3089.95,                last time consumption/overall running time: 2309.6166s / 302127.8452 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0038
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0025
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 3226.4,                last time consumption/overall running time: 2411.7863s / 304539.6315 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0025
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 3015.0,                last time consumption/overall running time: 2253.9139s / 306793.5454 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0025
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 3052.8,                last time consumption/overall running time: 2277.3969s / 309070.9423 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0040
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0027
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 3084.75,                last time consumption/overall running time: 2299.0509s / 311369.9932 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.0500,                 loss: 0.0022
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 3138.95,                last time consumption/overall running time: 2339.3777s / 313709.3708 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0041
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0025
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 3226.55,                last time consumption/overall running time: 2406.7887s / 316116.1595 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 3222.75,                last time consumption/overall running time: 2398.7625s / 318514.9220 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 3101.85,                last time consumption/overall running time: 2305.8208s / 320820.7428 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.0039
env0_second_0:                 episode reward: 13.4500,                 loss: 0.0023
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 3196.15,                last time consumption/overall running time: 2375.8879s / 323196.6307 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.0034
env0_second_0:                 episode reward: 11.8500,                 loss: 0.0023
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 3197.4,                last time consumption/overall running time: 2375.4728s / 325572.1035 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0040
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0027
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 2850.3,                last time consumption/overall running time: 2122.8216s / 327694.9251 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0042
env0_second_0:                 episode reward: 9.0000,                 loss: 0.0028
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 2845.8,                last time consumption/overall running time: 2127.3324s / 329822.2575 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0044
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0030
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 3030.25,                last time consumption/overall running time: 2264.2826s / 332086.5401 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0044
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0027
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 3341.1,                last time consumption/overall running time: 2493.7528s / 334580.2929 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0046
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0026
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 3312.9,                last time consumption/overall running time: 2470.7898s / 337051.0827 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.0037
env0_second_0:                 episode reward: 8.9500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 3349.7,                last time consumption/overall running time: 2497.7156s / 339548.7983 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0025
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 3332.2,                last time consumption/overall running time: 2483.4810s / 342032.2793 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.0036
env0_second_0:                 episode reward: 9.5000,                 loss: 0.0024
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 2981.65,                last time consumption/overall running time: 2221.2153s / 344253.4946 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 3256.15,                last time consumption/overall running time: 2425.2026s / 346678.6971 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0043
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0035
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 3342.35,                last time consumption/overall running time: 2484.8491s / 349163.5462 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0044
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0028
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 3077.35,                last time consumption/overall running time: 2293.6257s / 351457.1719 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 3155.0,                last time consumption/overall running time: 2349.2024s / 353806.3743 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 3323.15,                last time consumption/overall running time: 2476.0587s / 356282.4330 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0041
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 3387.2,                last time consumption/overall running time: 2521.1309s / 358803.5638 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0037
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0024
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 3314.55,                last time consumption/overall running time: 2467.2567s / 361270.8205 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.0500,                 loss: 0.0026
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 3486.6,                last time consumption/overall running time: 2595.8224s / 363866.6430 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0025
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 3175.4,                last time consumption/overall running time: 2361.1186s / 366227.7615 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0024
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 3406.5,                last time consumption/overall running time: 2529.9937s / 368757.7553 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0038
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 3723.75,                last time consumption/overall running time: 2767.2485s / 371525.0037 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0037
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0025
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 3531.5,                last time consumption/overall running time: 2625.6731s / 374150.6768 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.8500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 3289.85,                last time consumption/overall running time: 2443.6686s / 376594.3454 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0036
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0024
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 3323.15,                last time consumption/overall running time: 2467.2720s / 379061.6174 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0036
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 3076.7,                last time consumption/overall running time: 2281.7834s / 381343.4008 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0037
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 3363.3,                last time consumption/overall running time: 2496.9310s / 383840.3318 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.0044
env0_second_0:                 episode reward: 13.2000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 3348.65,                last time consumption/overall running time: 2744.7369s / 386585.0687 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0042
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 3156.15,                last time consumption/overall running time: 2859.0181s / 389444.0869 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0040
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0026
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 3449.3,                last time consumption/overall running time: 3124.5870s / 392568.6738 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0039
env0_second_0:                 episode reward: 11.0000,                 loss: 0.0026
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 3703.6,                last time consumption/overall running time: 3352.4062s / 395921.0800 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0027
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 3862.6,                last time consumption/overall running time: 3494.3200s / 399415.4000 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0036
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 4113.8,                last time consumption/overall running time: 3721.6546s / 403137.0546 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.0034
env0_second_0:                 episode reward: 5.9000,                 loss: 0.0028
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 3455.35,                last time consumption/overall running time: 3120.8894s / 406257.9441 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0029
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 3545.5,                last time consumption/overall running time: 3203.1385s / 409461.0825 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0040
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0030
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 3559.3,                last time consumption/overall running time: 3211.2303s / 412672.3128 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.2500,                 loss: 0.0030
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 3614.25,                last time consumption/overall running time: 3256.1025s / 415928.4154 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0029
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 3577.4,                last time consumption/overall running time: 3225.8584s / 419154.2738 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 3391.8,                last time consumption/overall running time: 3055.3754s / 422209.6492 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.5000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 3456.5,                last time consumption/overall running time: 3108.3215s / 425317.9707 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0032
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 3912.4,                last time consumption/overall running time: 3517.4785s / 428835.4492 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.0037
env0_second_0:                 episode reward: 8.8500,                 loss: 0.0028
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 3704.15,                last time consumption/overall running time: 3331.3780s / 432166.8271 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0028
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 4007.4,                last time consumption/overall running time: 3604.2402s / 435771.0674 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0037
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0029
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 3686.75,                last time consumption/overall running time: 3312.3531s / 439083.4205 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0039
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 3851.25,                last time consumption/overall running time: 3455.1261s / 442538.5466 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 3543.7,                last time consumption/overall running time: 3176.1670s / 445714.7136 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 9.6000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 3541.35,                last time consumption/overall running time: 3168.4119s / 448883.1255 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0037
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0029
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 3830.25,                last time consumption/overall running time: 3417.5400s / 452300.6655 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0031
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 3473.65,                last time consumption/overall running time: 3097.4713s / 455398.1368 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0033
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 3710.05,                last time consumption/overall running time: 3307.5192s / 458705.6560 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0037
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0034
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 3864.85,                last time consumption/overall running time: 3452.6885s / 462158.3445 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0037
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0031
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 3695.55,                last time consumption/overall running time: 3301.5935s / 465459.9380 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0040
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0031
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 3253.55,                last time consumption/overall running time: 3199.7630s / 468659.7011 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0032
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 3715.8,                last time consumption/overall running time: 3797.8932s / 472457.5942 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0041
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0034
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 3464.55,                last time consumption/overall running time: 3540.7407s / 475998.3350 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0029
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 3728.9,                last time consumption/overall running time: 3812.5117s / 479810.8467 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0041
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0034
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 3845.25,                last time consumption/overall running time: 3932.0028s / 483742.8495 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0042
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0033
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 3805.25,                last time consumption/overall running time: 3890.3562s / 487633.2057 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0039
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0031
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 3600.55,                last time consumption/overall running time: 3689.2935s / 491322.4992 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0036
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 3368.8,                last time consumption/overall running time: 3451.7914s / 494774.2906 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 6.1000,                 loss: 0.0032
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 3004.6,                last time consumption/overall running time: 3077.3418s / 497851.6325 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0043
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0038
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 3662.65,                last time consumption/overall running time: 3756.2179s / 501607.8504 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0032
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 3708.2,                last time consumption/overall running time: 3796.7795s / 505404.6299 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 3827.2,                last time consumption/overall running time: 3938.4483s / 509343.0782 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0031
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 3804.2,                last time consumption/overall running time: 4018.9305s / 513362.0087 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.0037
env0_second_0:                 episode reward: 9.5000,                 loss: 0.0027
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 3401.55,                last time consumption/overall running time: 3584.2661s / 516946.2748 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0037
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 3551.15,                last time consumption/overall running time: 3736.2420s / 520682.5169 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 3449.3,                last time consumption/overall running time: 3627.1622s / 524309.6791 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0041
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0031
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 3724.95,                last time consumption/overall running time: 3737.9447s / 528047.6238 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0044
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0037
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 4116.15,                last time consumption/overall running time: 4095.9161s / 532143.5399 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0037
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0030
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 3585.75,                last time consumption/overall running time: 3575.3285s / 535718.8684 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.0038
env0_second_0:                 episode reward: 5.9000,                 loss: 0.0031
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 3616.25,                last time consumption/overall running time: 3603.7821s / 539322.6504 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0034
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 3822.0,                last time consumption/overall running time: 3807.8114s / 543130.4619 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0038
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0028
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 4086.15,                last time consumption/overall running time: 4076.5026s / 547206.9645 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0036
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0029
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 3729.1,                last time consumption/overall running time: 3727.0273s / 550933.9918 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0038
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0030
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 3644.65,                last time consumption/overall running time: 3635.2256s / 554569.2174 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0044
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0029
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 3473.4,                last time consumption/overall running time: 3464.1515s / 558033.3689 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0027
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 3487.45,                last time consumption/overall running time: 3475.2283s / 561508.5972 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0041
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0031
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 3692.6,                last time consumption/overall running time: 3676.1176s / 565184.7148 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0046
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0033
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 3297.6,                last time consumption/overall running time: 3292.1150s / 568476.8297 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0032
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 3383.9,                last time consumption/overall running time: 3375.3198s / 571852.1495 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0033
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 3413.65,                last time consumption/overall running time: 3405.8093s / 575257.9588 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 3070.1,                last time consumption/overall running time: 3060.8026s / 578318.7614 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0031
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 3020.3,                last time consumption/overall running time: 2976.3516s / 581295.1130 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0043
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0032
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 3394.15,                last time consumption/overall running time: 3143.9813s / 584439.0943 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 3522.4,                last time consumption/overall running time: 3106.8997s / 587545.9940 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 12.1000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 3742.9,                last time consumption/overall running time: 3292.2771s / 590838.2711 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0037
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0030
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 3403.5,                last time consumption/overall running time: 2993.3836s / 593831.6548 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0033
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 3175.05,                last time consumption/overall running time: 2791.3252s / 596622.9799 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0042
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0036
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 3150.05,                last time consumption/overall running time: 2767.2530s / 599390.2329 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0042
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0038
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 3535.7,                last time consumption/overall running time: 3105.7321s / 602495.9650 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0037
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 3356.1,                last time consumption/overall running time: 2943.5823s / 605439.5473 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0032
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 3419.25,                last time consumption/overall running time: 2916.0680s / 608355.6153 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0041
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0031
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 3271.6,                last time consumption/overall running time: 2702.2248s / 611057.8401 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0033
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 3300.2,                last time consumption/overall running time: 2728.5922s / 613786.4323 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0031
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 3297.55,                last time consumption/overall running time: 2719.9216s / 616506.3539 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0026
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 3396.55,                last time consumption/overall running time: 2800.7521s / 619307.1060 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0029
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 3675.2,                last time consumption/overall running time: 3018.6632s / 622325.7692 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0031
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 3355.3,                last time consumption/overall running time: 2761.8679s / 625087.6371 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0042
env0_second_0:                 episode reward: 11.0000,                 loss: 0.0031
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 3346.5,                last time consumption/overall running time: 2751.3928s / 627839.0299 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0032
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 3876.0,                last time consumption/overall running time: 3174.7380s / 631013.7679 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0039
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0029
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 3457.0,                last time consumption/overall running time: 2700.8585s / 633714.6264 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0030
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 3392.05,                last time consumption/overall running time: 2475.7687s / 636190.3951 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0031
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 3134.2,                last time consumption/overall running time: 2290.7962s / 638481.1913 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.0041
env0_second_0:                 episode reward: 12.0500,                 loss: 0.0032
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 3251.1,                last time consumption/overall running time: 2374.7962s / 640855.9875 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0031
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 3454.6,                last time consumption/overall running time: 2516.6438s / 643372.6313 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0041
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0031
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 3355.75,                last time consumption/overall running time: 2341.4231s / 645714.0544 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.0045
env0_second_0:                 episode reward: 8.9500,                 loss: 0.0032
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 3458.4,                last time consumption/overall running time: 2178.0640s / 647892.1183 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0031
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 3346.05,                last time consumption/overall running time: 2108.8386s / 650000.9569 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0032
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 3359.05,                last time consumption/overall running time: 2117.4262s / 652118.3831 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.0044
env0_second_0:                 episode reward: 9.6000,                 loss: 0.0032
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 3175.4,                last time consumption/overall running time: 1995.8872s / 654114.2703 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0034
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 3155.95,                last time consumption/overall running time: 1986.2542s / 656100.5245 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0033
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 3003.35,                last time consumption/overall running time: 1845.6023s / 657946.1268 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.8000,                 loss: 0.0031
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 3365.9,                last time consumption/overall running time: 1984.1595s / 659930.2863 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0030
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 3231.1,                last time consumption/overall running time: 1903.0144s / 661833.3006 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0035
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0028
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 3301.05,                last time consumption/overall running time: 1945.3852s / 663778.6859 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0032
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 3687.0,                last time consumption/overall running time: 2163.4002s / 665942.0861 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0030
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 3683.6,                last time consumption/overall running time: 2170.2656s / 668112.3517 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0035
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0031
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 3456.45,                last time consumption/overall running time: 1971.5390s / 670083.8907 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0036
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0027
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 3434.3,                last time consumption/overall running time: 1883.8126s / 671967.7032 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0032
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 3455.5,                last time consumption/overall running time: 1895.9275s / 673863.6308 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0039
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0033
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 3583.55,                last time consumption/overall running time: 1882.4651s / 675746.0959 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.6000,                 loss: 0.0032
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 3550.1,                last time consumption/overall running time: 1802.7904s / 677548.8863 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0036
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0029
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 3538.8,                last time consumption/overall running time: 1787.6743s / 679336.5606 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0036
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0029
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 3487.0,                last time consumption/overall running time: 1766.3159s / 681102.8765 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0039
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0029
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 3436.6,                last time consumption/overall running time: 1742.4427s / 682845.3193 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0031
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 3868.65,                last time consumption/overall running time: 1961.2303s / 684806.5496 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0033
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 3552.3,                last time consumption/overall running time: 1802.2048s / 686608.7544 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0035
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0027
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 3455.1,                last time consumption/overall running time: 1745.8755s / 688354.6299 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0037
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0030
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 3555.95,                last time consumption/overall running time: 1795.8045s / 690150.4344 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.2500,                 loss: 0.0030
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 3665.15,                last time consumption/overall running time: 1849.6250s / 692000.0594 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0035
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 3422.8,                last time consumption/overall running time: 1729.7537s / 693729.8131 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 3493.55,                last time consumption/overall running time: 1766.5157s / 695496.3288 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0036
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0027
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 3592.05,                last time consumption/overall running time: 1815.5011s / 697311.8299 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.5000,                 loss: 0.0027
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 3442.6,                last time consumption/overall running time: 1741.7574s / 699053.5873 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0035
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0028
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 3561.3,                last time consumption/overall running time: 1796.0473s / 700849.6346 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0036
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 3611.75,                last time consumption/overall running time: 1823.4036s / 702673.0383 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.8000,                 loss: 0.0028
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 3695.7,                last time consumption/overall running time: 1868.8278s / 704541.8660 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0027
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 3471.2,                last time consumption/overall running time: 1745.1483s / 706287.0143 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0039
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0030
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 3322.3,                last time consumption/overall running time: 1666.7177s / 707953.7320 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0032
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 3204.15,                last time consumption/overall running time: 1608.9274s / 709562.6594 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 3485.25,                last time consumption/overall running time: 1757.5719s / 711320.2313 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0039
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 3157.05,                last time consumption/overall running time: 1586.2538s / 712906.4851 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0031
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 3181.95,                last time consumption/overall running time: 1591.2722s / 714497.7573 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.0037
env0_second_0:                 episode reward: 11.4000,                 loss: 0.0027
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 3183.85,                last time consumption/overall running time: 1588.6601s / 716086.4174 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0027
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 2998.95,                last time consumption/overall running time: 1493.2327s / 717579.6501 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0036
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 3107.75,                last time consumption/overall running time: 1549.8642s / 719129.5143 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0038
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0029
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 3173.65,                last time consumption/overall running time: 1584.3828s / 720713.8971 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0035
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 3287.35,                last time consumption/overall running time: 1639.0597s / 722352.9569 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0036
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 3129.9,                last time consumption/overall running time: 1559.2898s / 723912.2467 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0035
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 3170.6,                last time consumption/overall running time: 1581.5844s / 725493.8310 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0038
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0027
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 3130.45,                last time consumption/overall running time: 1559.4277s / 727053.2588 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0035
env0_second_0:                 episode reward: 11.0000,                 loss: 0.0029
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 2971.65,                last time consumption/overall running time: 1481.3756s / 728534.6343 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.0037
env0_second_0:                 episode reward: 12.5500,                 loss: 0.0026
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 2990.2,                last time consumption/overall running time: 1487.5635s / 730022.1979 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0029
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 3340.35,                last time consumption/overall running time: 1660.1668s / 731682.3647 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0029
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 3220.6,                last time consumption/overall running time: 1600.5538s / 733282.9185 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 3122.0,                last time consumption/overall running time: 1552.1841s / 734835.1025 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0039
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0027
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 2718.8,                last time consumption/overall running time: 1351.0607s / 736186.1632 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0037
env0_second_0:                 episode reward: 13.3000,                 loss: 0.0031
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 3311.8,                last time consumption/overall running time: 1646.9460s / 737833.1092 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0037
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0036
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 3276.1,                last time consumption/overall running time: 1628.8785s / 739461.9878 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0037
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 3295.95,                last time consumption/overall running time: 1638.6365s / 741100.6242 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0031
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 2936.5,                last time consumption/overall running time: 1457.4583s / 742558.0825 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0030
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 3045.8,                last time consumption/overall running time: 1510.9622s / 744069.0447 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0032
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 3397.5,                last time consumption/overall running time: 1683.8135s / 745752.8582 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0036
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0034
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 3249.8,                last time consumption/overall running time: 1610.8839s / 747363.7421 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0034
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 3246.35,                last time consumption/overall running time: 1609.6658s / 748973.4079 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0032
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 3537.6,                last time consumption/overall running time: 1589.9619s / 750563.3698 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0032
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 3408.25,                last time consumption/overall running time: 1502.7316s / 752066.1015 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0035
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0030
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 3101.8,                last time consumption/overall running time: 1366.2046s / 753432.3061 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0035
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 3421.4,                last time consumption/overall running time: 1506.8846s / 754939.1907 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0027
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 3642.5,                last time consumption/overall running time: 1609.7379s / 756548.9286 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0037
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 3431.4,                last time consumption/overall running time: 1519.2209s / 758068.1494 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0036
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0028
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 3320.4,                last time consumption/overall running time: 1471.1051s / 759539.2545 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0029
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 3177.05,                last time consumption/overall running time: 1404.6167s / 760943.8712 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0036
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 3262.65,                last time consumption/overall running time: 1444.3969s / 762388.2682 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0029
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 3371.65,                last time consumption/overall running time: 1495.5142s / 763883.7823 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0030
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 3325.4,                last time consumption/overall running time: 1468.9021s / 765352.6844 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0039
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0034
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 3292.15,                last time consumption/overall running time: 1459.1276s / 766811.8120 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0032
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 3111.75,                last time consumption/overall running time: 1378.8595s / 768190.6714 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0034
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 3375.75,                last time consumption/overall running time: 1494.1483s / 769684.8198 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0038
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 3020.4,                last time consumption/overall running time: 1373.5178s / 771058.3375 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0051
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0032
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 3445.75,                last time consumption/overall running time: 1671.3454s / 772729.6829 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0039
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0032
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 2947.95,                last time consumption/overall running time: 1427.6012s / 774157.2841 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0031
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 3359.4,                last time consumption/overall running time: 1628.6182s / 775785.9023 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0037
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0033
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 3540.75,                last time consumption/overall running time: 1715.3839s / 777501.2862 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0032
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 3563.6,                last time consumption/overall running time: 1728.1775s / 779229.4638 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0037
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0031
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 3338.05,                last time consumption/overall running time: 1615.1140s / 780844.5777 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0033
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 3563.15,                last time consumption/overall running time: 1641.3961s / 782485.9738 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0041
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0034
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 3696.5,                last time consumption/overall running time: 1631.7481s / 784117.7220 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0037
env0_second_0:                 episode reward: 5.8000,                 loss: 0.0030
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 3485.1,                last time consumption/overall running time: 1542.0104s / 785659.7324 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 2980.25,                last time consumption/overall running time: 1317.9153s / 786977.6477 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.0037
env0_second_0:                 episode reward: 10.9500,                 loss: 0.0032
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 3063.6,                last time consumption/overall running time: 1357.1170s / 788334.7647 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0034
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 3413.9,                last time consumption/overall running time: 1418.5913s / 789753.3559 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0036
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 3585.65,                last time consumption/overall running time: 1442.6608s / 791196.0168 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0034
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 2958.5,                last time consumption/overall running time: 1187.8028s / 792383.8196 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0037
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0030
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 3381.2,                last time consumption/overall running time: 1356.3980s / 793740.2176 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0033
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 3138.95,                last time consumption/overall running time: 1261.0022s / 795001.2198 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0042
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0037
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 3404.35,                last time consumption/overall running time: 1364.6798s / 796365.8996 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.0040
env0_second_0:                 episode reward: 9.8000,                 loss: 0.0030
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 3520.15,                last time consumption/overall running time: 1422.4132s / 797788.3128 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0028
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 3166.05,                last time consumption/overall running time: 1275.8737s / 799064.1864 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0037
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0028
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 3153.45,                last time consumption/overall running time: 1272.3710s / 800336.5575 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0029
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 3131.05,                last time consumption/overall running time: 1262.5731s / 801599.1305 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.0042
env0_second_0:                 episode reward: 11.8500,                 loss: 0.0030
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 3075.15,                last time consumption/overall running time: 1174.2889s / 802773.4194 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0043
env0_second_0:                 episode reward: 4.7500,                 loss: 0.0031
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 3300.2,                last time consumption/overall running time: 1203.9099s / 803977.3294 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0044
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0032
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 3269.65,                last time consumption/overall running time: 1195.5646s / 805172.8940 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0033
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 2798.95,                last time consumption/overall running time: 1023.6753s / 806196.5693 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.5000,                 loss: 0.0034
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 3546.2,                last time consumption/overall running time: 1289.3787s / 807485.9480 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0035
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 3225.55,                last time consumption/overall running time: 1175.6496s / 808661.5976 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.0037
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0029
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 2564.45,                last time consumption/overall running time: 934.3147s / 809595.9123 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.0129
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0033
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 1652.2,                last time consumption/overall running time: 598.1277s / 810194.0401 s
env0_first_0:                 episode reward: -16.6000,                 loss: 0.0089
env0_second_0:                 episode reward: 16.6000,                 loss: 0.0035
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 2268.65,                last time consumption/overall running time: 817.4930s / 811011.5331 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.0031
env0_second_0:                 episode reward: 13.5000,                 loss: 0.0049
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 3106.55,                last time consumption/overall running time: 1126.3180s / 812137.8511 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0038
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 2679.35,                last time consumption/overall running time: 973.1504s / 813111.0014 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0035
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0030
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 2875.85,                last time consumption/overall running time: 1040.5647s / 814151.5662 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0041
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 2982.95,                last time consumption/overall running time: 1082.5189s / 815234.0851 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0038
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 3205.9,                last time consumption/overall running time: 1155.2064s / 816389.2915 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.6500,                 loss: 0.0035
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 3162.2,                last time consumption/overall running time: 1147.3301s / 817536.6216 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0033
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 3123.65,                last time consumption/overall running time: 1128.3117s / 818664.9332 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0036
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0032
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 3201.65,                last time consumption/overall running time: 1160.4651s / 819825.3983 s
env0_first_0:                 episode reward: -9.2000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.2000,                 loss: 0.0035
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 3631.3,                last time consumption/overall running time: 1315.9171s / 821141.3154 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0036
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0032
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 3402.35,                last time consumption/overall running time: 1232.1377s / 822373.4531 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.0036
env0_second_0:                 episode reward: 8.9500,                 loss: 0.0027
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 3284.65,                last time consumption/overall running time: 1193.9044s / 823567.3575 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0032
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 3568.15,                last time consumption/overall running time: 1290.1788s / 824857.5362 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0036
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0030
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 3301.2,                last time consumption/overall running time: 1197.7968s / 826055.3330 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0038
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 3250.6,                last time consumption/overall running time: 1175.9570s / 827231.2900 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0037
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0032
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 3208.2,                last time consumption/overall running time: 1157.8589s / 828389.1489 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.0035
env0_second_0:                 episode reward: 10.3000,                 loss: 0.0032
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 3128.05,                last time consumption/overall running time: 1128.3217s / 829517.4706 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0032
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 3564.55,                last time consumption/overall running time: 1284.0138s / 830801.4843 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0036
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0031
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 3558.4,                last time consumption/overall running time: 1280.7243s / 832082.2086 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0035
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0029
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 3052.35,                last time consumption/overall running time: 1101.1937s / 833183.4024 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0029
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 3381.75,                last time consumption/overall running time: 1218.7104s / 834402.1128 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0034
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 3305.0,                last time consumption/overall running time: 1188.1308s / 835590.2436 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0037
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 3266.1,                last time consumption/overall running time: 1168.6114s / 836758.8550 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0038
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0033
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 3416.75,                last time consumption/overall running time: 1230.8480s / 837989.7030 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0031
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 3383.55,                last time consumption/overall running time: 1220.7690s / 839210.4720 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0037
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 3819.7,                last time consumption/overall running time: 1375.8248s / 840586.2968 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0036
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0032
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 3603.5,                last time consumption/overall running time: 1300.5795s / 841886.8762 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0037
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0030
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 3529.5,                last time consumption/overall running time: 1267.4684s / 843154.3446 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0033
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 3417.15,                last time consumption/overall running time: 1220.6415s / 844374.9861 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 8.9500,                 loss: 0.0037
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 3504.2,                last time consumption/overall running time: 1253.1311s / 845628.1173 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0034
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 3667.35,                last time consumption/overall running time: 1317.2960s / 846945.4133 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0040
env0_second_0:                 episode reward: 5.7000,                 loss: 0.0035
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 2937.65,                last time consumption/overall running time: 1051.6220s / 847997.0353 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0032
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 3326.95,                last time consumption/overall running time: 1193.9186s / 849190.9539 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0037
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0031
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 3431.65,                last time consumption/overall running time: 1224.2060s / 850415.1599 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0036
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0034
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 3552.6,                last time consumption/overall running time: 1289.9189s / 851705.0788 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0037
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0030
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 3314.5,                last time consumption/overall running time: 1197.0821s / 852902.1609 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0031
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 3560.5,                last time consumption/overall running time: 1277.5889s / 854179.7498 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0039
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0032
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 3289.85,                last time consumption/overall running time: 1185.3950s / 855365.1448 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0034
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 3644.85,                last time consumption/overall running time: 1311.2698s / 856676.4146 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0038
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0029
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 3565.15,                last time consumption/overall running time: 1276.9819s / 857953.3965 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0039
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0029
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 3284.25,                last time consumption/overall running time: 1176.0415s / 859129.4380 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0036
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0031
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 3379.1,                last time consumption/overall running time: 1215.0078s / 860344.4458 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.4500,                 loss: 0.0030
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 3488.15,                last time consumption/overall running time: 1255.1913s / 861599.6371 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0037
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 3098.8,                last time consumption/overall running time: 1118.7954s / 862718.4325 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0044
env0_second_0:                 episode reward: 10.9000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 3127.75,                last time consumption/overall running time: 1123.5704s / 863842.0029 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0035
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 3384.05,                last time consumption/overall running time: 1216.5773s / 865058.5802 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0034
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 3293.1,                last time consumption/overall running time: 1181.1792s / 866239.7594 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0033
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 3436.6,                last time consumption/overall running time: 1235.7625s / 867475.5219 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0035
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 3326.75,                last time consumption/overall running time: 1184.0932s / 868659.6152 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0031
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 3624.75,                last time consumption/overall running time: 1302.1564s / 869961.7715 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0030
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 3421.85,                last time consumption/overall running time: 1229.5500s / 871191.3215 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0037
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 3223.5,                last time consumption/overall running time: 1162.4279s / 872353.7495 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0032
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 3537.4,                last time consumption/overall running time: 1276.7843s / 873630.5337 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0036
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0033
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 3305.35,                last time consumption/overall running time: 1188.2456s / 874818.7794 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0034
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 3057.1,                last time consumption/overall running time: 1101.4688s / 875920.2482 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0033
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 3094.65,                last time consumption/overall running time: 1111.4127s / 877031.6609 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0040
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0038
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 3413.9,                last time consumption/overall running time: 1219.1395s / 878250.8004 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0039
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0031
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 3303.0,                last time consumption/overall running time: 1179.0619s / 879429.8623 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0042
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 3467.4,                last time consumption/overall running time: 1241.8247s / 880671.6870 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.0036
env0_second_0:                 episode reward: 9.5000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 3513.1,                last time consumption/overall running time: 1258.3072s / 881929.9942 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 3638.05,                last time consumption/overall running time: 1306.4129s / 883236.4071 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0038
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0029
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 3860.55,                last time consumption/overall running time: 1387.7513s / 884624.1584 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.0037
env0_second_0:                 episode reward: 5.8500,                 loss: 0.0029
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 3955.6,                last time consumption/overall running time: 1416.7032s / 886040.8616 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0035
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 3881.3,                last time consumption/overall running time: 1397.0191s / 887437.8808 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0037
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0029
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 3128.15,                last time consumption/overall running time: 1129.7089s / 888567.5897 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0037
env0_second_0:                 episode reward: 11.1500,                 loss: 0.0034
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 3403.25,                last time consumption/overall running time: 1221.4388s / 889789.0284 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0041
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0042
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 3288.6,                last time consumption/overall running time: 1180.5044s / 890969.5328 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0042
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0037
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 3455.95,                last time consumption/overall running time: 1239.1614s / 892208.6942 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0041
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0032
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 3213.0,                last time consumption/overall running time: 1158.9673s / 893367.6616 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0043
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0034
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 3096.4,                last time consumption/overall running time: 1110.8085s / 894478.4701 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0042
env0_second_0:                 episode reward: 11.1500,                 loss: 0.0032
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 3607.9,                last time consumption/overall running time: 1302.3644s / 895780.8345 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0030
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 3296.45,                last time consumption/overall running time: 1189.4339s / 896970.2683 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0030
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 3319.95,                last time consumption/overall running time: 1189.3270s / 898159.5953 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0044
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 3259.9,                last time consumption/overall running time: 1175.6295s / 899335.2248 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 3367.15,                last time consumption/overall running time: 1220.7284s / 900555.9533 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0040
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0033
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 3688.9,                last time consumption/overall running time: 1338.8439s / 901894.7972 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0033
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 3047.05,                last time consumption/overall running time: 1108.7271s / 903003.5243 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0036
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 2826.75,                last time consumption/overall running time: 1030.0641s / 904033.5884 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.0051
env0_second_0:                 episode reward: 14.1500,                 loss: 0.0042
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 3309.45,                last time consumption/overall running time: 1195.7986s / 905229.3870 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0038
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 3457.05,                last time consumption/overall running time: 1239.7835s / 906469.1705 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0036
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0033
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 3450.8,                last time consumption/overall running time: 1234.1918s / 907703.3624 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0031
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 3119.9,                last time consumption/overall running time: 1116.2335s / 908819.5958 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0037
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0030
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 3039.8,                last time consumption/overall running time: 1097.4945s / 909917.0903 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0031
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 3125.55,                last time consumption/overall running time: 1124.9241s / 911042.0144 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.6000,                 loss: 0.0032
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 3183.45,                last time consumption/overall running time: 1144.5804s / 912186.5948 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.6000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 3170.7,                last time consumption/overall running time: 1140.6853s / 913327.2801 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.0000,                 loss: 0.0035
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 3274.6,                last time consumption/overall running time: 1184.0494s / 914511.3295 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0044
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0036
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 3379.35,                last time consumption/overall running time: 1207.1894s / 915718.5189 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0034
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 3116.1,                last time consumption/overall running time: 1113.7207s / 916832.2396 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.9500,                 loss: 0.0035
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 3268.1,                last time consumption/overall running time: 1155.7245s / 917987.9641 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0042
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0035
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 3696.5,                last time consumption/overall running time: 1307.1515s / 919295.1156 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0036
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 3168.2,                last time consumption/overall running time: 1118.5234s / 920413.6390 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.0042
env0_second_0:                 episode reward: 9.9000,                 loss: 0.0036
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 3319.65,                last time consumption/overall running time: 1172.4607s / 921586.0997 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0032
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 3282.55,                last time consumption/overall running time: 1155.3042s / 922741.4039 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0038
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0032
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 3291.45,                last time consumption/overall running time: 1158.9580s / 923900.3619 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.6000,                 loss: 0.0031
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 3208.8,                last time consumption/overall running time: 1134.1470s / 925034.5089 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0042
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0036
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 3030.4,                last time consumption/overall running time: 1063.4904s / 926097.9993 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0038
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 3076.55,                last time consumption/overall running time: 1084.8947s / 927182.8939 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0043
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0038
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 3606.6,                last time consumption/overall running time: 1269.1252s / 928452.0191 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0044
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0032
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 3259.55,                last time consumption/overall running time: 1149.0316s / 929601.0507 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0032
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 3284.75,                last time consumption/overall running time: 1157.6504s / 930758.7011 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0042
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0033
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 3677.75,                last time consumption/overall running time: 1299.8452s / 932058.5463 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 3505.0,                last time consumption/overall running time: 1236.7667s / 933295.3130 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0040
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0029
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 3553.05,                last time consumption/overall running time: 1254.9473s / 934550.2603 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 3558.25,                last time consumption/overall running time: 1257.5185s / 935807.7789 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0038
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 3195.15,                last time consumption/overall running time: 1128.6988s / 936936.4777 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0030
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 3549.25,                last time consumption/overall running time: 1250.4037s / 938186.8813 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0028
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 3487.7,                last time consumption/overall running time: 1227.0261s / 939413.9075 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0036
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0027
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 3545.85,                last time consumption/overall running time: 1250.5315s / 940664.4390 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0038
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0032
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 3470.65,                last time consumption/overall running time: 1228.2549s / 941892.6939 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0037
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 3621.6,                last time consumption/overall running time: 1275.8435s / 943168.5373 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0041
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0030
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 3506.1,                last time consumption/overall running time: 1239.9079s / 944408.4452 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.8000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 3851.45,                last time consumption/overall running time: 1359.8827s / 945768.3280 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0036
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0027
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 4034.3,                last time consumption/overall running time: 1421.8429s / 947190.1708 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0034
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0028
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 3546.1,                last time consumption/overall running time: 1251.6389s / 948441.8097 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0034
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 3735.75,                last time consumption/overall running time: 1315.6654s / 949757.4750 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0030
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 3572.15,                last time consumption/overall running time: 1260.0061s / 951017.4811 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0039
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0031
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 3242.3,                last time consumption/overall running time: 1121.6928s / 952139.1739 s
env0_first_0:                 episode reward: -9.2000,                 loss: 0.0036
env0_second_0:                 episode reward: 9.2000,                 loss: 0.0025
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 3062.65,                last time consumption/overall running time: 969.4313s / 953108.6052 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.0042
env0_second_0:                 episode reward: 13.2000,                 loss: 0.0030
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 3312.0,                last time consumption/overall running time: 1045.6723s / 954154.2775 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0040
env0_second_0:                 episode reward: 12.8000,                 loss: 0.0030
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 3359.1,                last time consumption/overall running time: 1057.4238s / 955211.7013 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.0039
env0_second_0:                 episode reward: 13.0000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 3279.5,                last time consumption/overall running time: 1035.6119s / 956247.3132 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0039
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0025
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 3563.7,                last time consumption/overall running time: 1127.1524s / 957374.4656 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0037
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0028
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 3373.5,                last time consumption/overall running time: 1065.4042s / 958439.8698 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0045
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0029
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 3427.4,                last time consumption/overall running time: 1081.1675s / 959521.0373 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0042
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 3430.0,                last time consumption/overall running time: 1084.1685s / 960605.2059 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0039
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0028
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 3340.25,                last time consumption/overall running time: 1052.5621s / 961657.7680 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0039
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0028
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 2916.65,                last time consumption/overall running time: 915.3109s / 962573.0789 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.0043
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0031
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 3255.35,                last time consumption/overall running time: 1019.9869s / 963593.0658 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.0041
env0_second_0:                 episode reward: 10.3500,                 loss: 0.0031
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 3082.8,                last time consumption/overall running time: 969.3289s / 964562.3947 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0039
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0029
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 3067.55,                last time consumption/overall running time: 970.9051s / 965533.2998 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0043
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 3062.25,                last time consumption/overall running time: 965.1814s / 966498.4812 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0031
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 3225.1,                last time consumption/overall running time: 1013.8884s / 967512.3696 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0041
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0030
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 3287.25,                last time consumption/overall running time: 1032.7019s / 968545.0715 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0039
env0_second_0:                 episode reward: 10.1500,                 loss: 0.0028
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 3244.9,                last time consumption/overall running time: 1030.2534s / 969575.3249 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0048
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0030
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 3140.2,                last time consumption/overall running time: 990.8126s / 970566.1374 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0044
env0_second_0:                 episode reward: 11.2000,                 loss: 0.0032
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 3469.65,                last time consumption/overall running time: 1092.6284s / 971658.7658 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0043
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0037
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 3229.35,                last time consumption/overall running time: 1015.1800s / 972673.9458 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0040
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0031
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 3102.85,                last time consumption/overall running time: 973.1481s / 973647.0939 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0046
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0031
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 3117.1,                last time consumption/overall running time: 985.5254s / 974632.6193 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0046
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0032
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 3624.65,                last time consumption/overall running time: 1143.3547s / 975775.9740 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0044
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0032
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 3385.2,                last time consumption/overall running time: 1065.2484s / 976841.2224 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0039
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0029
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 3409.85,                last time consumption/overall running time: 1076.8163s / 977918.0387 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0042
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0029
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 3557.7,                last time consumption/overall running time: 1119.3409s / 979037.3796 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0044
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0033
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 3094.6,                last time consumption/overall running time: 968.5478s / 980005.9274 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0040
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0028
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 3475.95,                last time consumption/overall running time: 1094.2945s / 981100.2218 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0041
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0029
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 3340.3,                last time consumption/overall running time: 1056.3772s / 982156.5990 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.0037
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0028
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 3370.4,                last time consumption/overall running time: 1058.8877s / 983215.4866 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.0037
env0_second_0:                 episode reward: 11.4000,                 loss: 0.0028
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 3020.15,                last time consumption/overall running time: 954.5921s / 984170.0787 sLoad pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rollout.py:21: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rollout_normal(env, model, save_id, args)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arrays = [asanyarray(arr) for arr in arrays]
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -11.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 11.3000,                 loss: 0.0033
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 3047.65,                last time consumption/overall running time: 952.9490s / 985123.0278 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0043
env0_second_0:                 episode reward: 12.3000,                 loss: 0.0031
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 3394.75,                last time consumption/overall running time: 1060.4017s / 986183.4294 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0037
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0029
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 2888.05,                last time consumption/overall running time: 908.6968s / 987092.1263 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0043
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0030
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 3206.9,                last time consumption/overall running time: 1007.9698s / 988100.0961 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0043
env0_second_0:                 episode reward: 12.7000,                 loss: 0.0032
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 3298.2,                last time consumption/overall running time: 1037.6953s / 989137.7914 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0040
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0031
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 3197.0,                last time consumption/overall running time: 1001.7429s / 990139.5342 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0033
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 3182.85,                last time consumption/overall running time: 999.3410s / 991138.8752 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0044
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0032
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 3252.2,                last time consumption/overall running time: 1020.2161s / 992159.0913 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0041
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0026
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 3331.3,                last time consumption/overall running time: 1049.1493s / 993208.2406 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0042
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0032
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 2985.0,                last time consumption/overall running time: 936.1406s / 994144.3812 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0040
env0_second_0:                 episode reward: 11.5500,                 loss: 0.0027
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 3008.55,                last time consumption/overall running time: 944.8062s / 995089.1873 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.0042
env0_second_0:                 episode reward: 12.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
