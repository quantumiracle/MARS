pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
random seed: 91
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fa367a58550>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.048 0.733 0.    0.    0.219 0.   ]
 [0.179 0.    0.    0.687 0.    0.133]]
Load checkpoints (policy family):  [['83' '5753' '6419' '9691' '12712' '16446']
 ['121' '6342' '6627' '9768' '12785' '16467']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220116204408/epi_20000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220116204408_exploit_20000/mdp_arbitrary_mdp_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116204408_exploit_20000/mdp_arbitrary_mdp_nxdo2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.2844s / 1.2844 s
agent0:                 episode reward: 1.2564,                 loss: nan
agent1:                 episode reward: -1.2564,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 1.4839 s
agent0:                 episode reward: 0.5473,                 loss: nan
agent1:                 episode reward: -0.5473,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1595s / 1.6434 s
agent0:                 episode reward: -0.2140,                 loss: nan
agent1:                 episode reward: 0.2140,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3573s / 2.0007 s
agent0:                 episode reward: 0.2408,                 loss: nan
agent1:                 episode reward: -0.2408,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3627s / 2.3634 s
agent0:                 episode reward: -0.2240,                 loss: nan
agent1:                 episode reward: 0.2240,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4069s / 2.7703 s
agent0:                 episode reward: 0.1530,                 loss: nan
agent1:                 episode reward: -0.1530,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3960s / 3.1663 s
agent0:                 episode reward: 0.3199,                 loss: nan
agent1:                 episode reward: -0.3199,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4177s / 3.5841 s
agent0:                 episode reward: 0.0559,                 loss: nan
agent1:                 episode reward: -0.0559,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4208s / 4.0049 s
agent0:                 episode reward: 0.5743,                 loss: nan
agent1:                 episode reward: -0.5743,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3420s / 4.3469 s
agent0:                 episode reward: 0.0286,                 loss: nan
agent1:                 episode reward: -0.0286,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5658s / 4.9127 s
agent0:                 episode reward: -0.1794,                 loss: nan
agent1:                 episode reward: 0.1794,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 38.6921s / 43.6048 s
agent0:                 episode reward: 0.5047,                 loss: nan
agent1:                 episode reward: -0.5047,                 loss: 0.1814
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 102.5629s / 146.1678 s
agent0:                 episode reward: 0.3272,                 loss: nan
agent1:                 episode reward: -0.3272,                 loss: 0.1694
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.7547s / 245.9225 s
agent0:                 episode reward: 0.1490,                 loss: nan
agent1:                 episode reward: -0.1490,                 loss: 0.1615
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 101.0168s / 346.9393 s
agent0:                 episode reward: 0.2807,                 loss: nan
agent1:                 episode reward: -0.2807,                 loss: 0.1537
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 100.4120s / 447.3513 s
agent0:                 episode reward: -0.4284,                 loss: nan
agent1:                 episode reward: 0.4284,                 loss: 0.1507
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 97.2180s / 544.5693 s
agent0:                 episode reward: 0.0005,                 loss: nan
agent1:                 episode reward: -0.0005,                 loss: 0.1472
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 100.4401s / 645.0094 s
agent0:                 episode reward: -0.1891,                 loss: nan
agent1:                 episode reward: 0.1891,                 loss: 0.1441
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.3600s / 743.3694 s
agent0:                 episode reward: 0.0823,                 loss: nan
agent1:                 episode reward: -0.0823,                 loss: 0.1443
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 94.9492s / 838.3185 s
agent0:                 episode reward: -0.0703,                 loss: nan
agent1:                 episode reward: 0.0703,                 loss: 0.1443
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.5814s / 935.8999 s
agent0:                 episode reward: 0.0710,                 loss: nan
agent1:                 episode reward: -0.0710,                 loss: 0.1412
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 100.5324s / 1036.4323 s
agent0:                 episode reward: -0.1867,                 loss: nan
agent1:                 episode reward: 0.1867,                 loss: 0.1421
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 104.1415s / 1140.5738 s
agent0:                 episode reward: 0.5205,                 loss: nan
agent1:                 episode reward: -0.5205,                 loss: 0.1396
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 106.7833s / 1247.3570 s
agent0:                 episode reward: 0.0260,                 loss: nan
agent1:                 episode reward: -0.0260,                 loss: 0.1403
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 111.4667s / 1358.8237 s
agent0:                 episode reward: 0.0968,                 loss: nan
agent1:                 episode reward: -0.0968,                 loss: 0.1393
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 109.3317s / 1468.1554 s
agent0:                 episode reward: 0.3578,                 loss: nan
agent1:                 episode reward: -0.3578,                 loss: 0.1387
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 106.4559s / 1574.6114 s
agent0:                 episode reward: 0.2196,                 loss: nan
agent1:                 episode reward: -0.2196,                 loss: 0.1374
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 106.0004s / 1680.6117 s
agent0:                 episode reward: 0.4737,                 loss: nan
agent1:                 episode reward: -0.4737,                 loss: 0.1350
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 107.0155s / 1787.6272 s
agent0:                 episode reward: 0.7448,                 loss: nan
agent1:                 episode reward: -0.7448,                 loss: 0.1410
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 108.9555s / 1896.5827 s
agent0:                 episode reward: 0.3864,                 loss: nan
agent1:                 episode reward: -0.3864,                 loss: 0.1413
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 106.5813s / 2003.1640 s
agent0:                 episode reward: 0.2169,                 loss: nan
agent1:                 episode reward: -0.2169,                 loss: 0.1409
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 109.8144s / 2112.9785 s
agent0:                 episode reward: -0.1721,                 loss: nan
agent1:                 episode reward: 0.1721,                 loss: 0.1386
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 110.1358s / 2223.1143 s
agent0:                 episode reward: 0.0146,                 loss: nan
agent1:                 episode reward: -0.0146,                 loss: 0.1383
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 108.1625s / 2331.2768 s
agent0:                 episode reward: -0.0176,                 loss: nan
agent1:                 episode reward: 0.0176,                 loss: 0.1368
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 108.0395s / 2439.3163 s
agent0:                 episode reward: 0.1908,                 loss: nan
agent1:                 episode reward: -0.1908,                 loss: 0.1360
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 108.0515s / 2547.3677 s
agent0:                 episode reward: 0.3719,                 loss: nan
agent1:                 episode reward: -0.3719,                 loss: 0.1357
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 109.0526s / 2656.4203 s
agent0:                 episode reward: 0.1578,                 loss: nan
agent1:                 episode reward: -0.1578,                 loss: 0.1338
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 146.9581s / 2803.3785 s
agent0:                 episode reward: 0.1725,                 loss: nan
agent1:                 episode reward: -0.1725,                 loss: 0.1357
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9980s / 3045.3765 s
agent0:                 episode reward: -0.4192,                 loss: nan
agent1:                 episode reward: 0.4192,                 loss: 0.1336
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2856s / 3288.6621 s
agent0:                 episode reward: 0.1460,                 loss: nan
agent1:                 episode reward: -0.1460,                 loss: 0.1327
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.6525s / 3527.3145 s
agent0:                 episode reward: 0.4593,                 loss: nan
agent1:                 episode reward: -0.4593,                 loss: 0.1308
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 228.6829s / 3755.9974 s
agent0:                 episode reward: 0.0600,                 loss: nan
agent1:                 episode reward: -0.0600,                 loss: 0.1320
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2873s / 4002.2847 s
agent0:                 episode reward: 0.0404,                 loss: nan
agent1:                 episode reward: -0.0404,                 loss: 0.1318
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.4143s / 4238.6990 s
agent0:                 episode reward: 0.2938,                 loss: nan
agent1:                 episode reward: -0.2938,                 loss: 0.1297
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6152s / 4479.3142 s
agent0:                 episode reward: 0.2405,                 loss: nan
agent1:                 episode reward: -0.2405,                 loss: 0.1297
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 233.4805s / 4712.7947 s
agent0:                 episode reward: 0.1508,                 loss: nan
agent1:                 episode reward: -0.1508,                 loss: 0.1278
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3726s / 4956.1673 s
agent0:                 episode reward: 0.5130,                 loss: nan
agent1:                 episode reward: -0.5130,                 loss: 0.1252
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3035s / 5199.4707 s
agent0:                 episode reward: 0.3092,                 loss: nan
agent1:                 episode reward: -0.3092,                 loss: 0.1264
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1992s / 5441.6699 s
agent0:                 episode reward: -0.2961,                 loss: nan
agent1:                 episode reward: 0.2961,                 loss: 0.1264
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6862s / 5683.3561 s
agent0:                 episode reward: 0.1228,                 loss: nan
agent1:                 episode reward: -0.1228,                 loss: 0.1254
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.6353s / 5920.9914 s
agent0:                 episode reward: 0.0044,                 loss: nan
agent1:                 episode reward: -0.0044,                 loss: 0.1249
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5540s / 6157.5455 s
agent0:                 episode reward: -0.0374,                 loss: nan
agent1:                 episode reward: 0.0374,                 loss: 0.1250
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6460s / 6404.1915 s
agent0:                 episode reward: 0.0150,                 loss: nan
agent1:                 episode reward: -0.0150,                 loss: 0.1254
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7815s / 6650.9730 s
agent0:                 episode reward: 0.1955,                 loss: nan
agent1:                 episode reward: -0.1955,                 loss: 0.1247
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9348s / 6904.9078 s
agent0:                 episode reward: 0.1104,                 loss: nan
agent1:                 episode reward: -0.1104,                 loss: 0.1257
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 229.8490s / 7134.7568 s
agent0:                 episode reward: -0.0291,                 loss: nan
agent1:                 episode reward: 0.0291,                 loss: 0.1255
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.4891s / 7372.2458 s
agent0:                 episode reward: 0.3935,                 loss: nan
agent1:                 episode reward: -0.3935,                 loss: 0.1251
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2060s / 7612.4519 s
agent0:                 episode reward: 0.4549,                 loss: nan
agent1:                 episode reward: -0.4549,                 loss: 0.1235
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6397s / 7855.0916 s
agent0:                 episode reward: 0.0740,                 loss: nan
agent1:                 episode reward: -0.0740,                 loss: 0.1239
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6206s / 8094.7121 s
agent0:                 episode reward: -0.0461,                 loss: nan
agent1:                 episode reward: 0.0461,                 loss: 0.1222
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2404s / 8339.9525 s
agent0:                 episode reward: -0.0481,                 loss: nan
agent1:                 episode reward: 0.0481,                 loss: 0.1237
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.1341s / 8578.0866 s
agent0:                 episode reward: -0.1465,                 loss: nan
agent1:                 episode reward: 0.1465,                 loss: 0.1240
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0593s / 8821.1459 s
agent0:                 episode reward: 0.1606,                 loss: nan
agent1:                 episode reward: -0.1606,                 loss: 0.1258
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1930s / 9061.3389 s
agent0:                 episode reward: 0.0001,                 loss: nan
agent1:                 episode reward: -0.0001,                 loss: 0.1259
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7222s / 9304.0611 s
agent0:                 episode reward: 0.6683,                 loss: nan
agent1:                 episode reward: -0.6683,                 loss: 0.1256
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0168s / 9548.0779 s
agent0:                 episode reward: 0.4949,                 loss: nan
agent1:                 episode reward: -0.4949,                 loss: 0.1243
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8048s / 9790.8828 s
agent0:                 episode reward: 0.0050,                 loss: nan
agent1:                 episode reward: -0.0050,                 loss: 0.1257
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.6365s / 10029.5192 s
agent0:                 episode reward: -0.1813,                 loss: nan
agent1:                 episode reward: 0.1813,                 loss: 0.1246
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.0161s / 10265.5354 s
agent0:                 episode reward: 0.1711,                 loss: nan
agent1:                 episode reward: -0.1711,                 loss: 0.1250
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 234.1626s / 10499.6979 s
agent0:                 episode reward: 0.3281,                 loss: nan
agent1:                 episode reward: -0.3281,                 loss: 0.1244
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1849s / 10743.8828 s
agent0:                 episode reward: 0.3630,                 loss: nan
agent1:                 episode reward: -0.3630,                 loss: 0.1245
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9497s / 10988.8325 s
agent0:                 episode reward: 0.0984,                 loss: nan
agent1:                 episode reward: -0.0984,                 loss: 0.1252
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5783s / 11230.4108 s
agent0:                 episode reward: 0.4013,                 loss: nan
agent1:                 episode reward: -0.4013,                 loss: 0.1252
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3095s / 11478.7203 s
agent0:                 episode reward: -0.0656,                 loss: nan
agent1:                 episode reward: 0.0656,                 loss: 0.1241
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5322s / 11715.2525 s
agent0:                 episode reward: 0.2501,                 loss: nan
agent1:                 episode reward: -0.2501,                 loss: 0.1264
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6357s / 11958.8882 s
agent0:                 episode reward: 0.2516,                 loss: nan
agent1:                 episode reward: -0.2516,                 loss: 0.1252
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8942s / 12202.7824 s
agent0:                 episode reward: -0.2305,                 loss: nan
agent1:                 episode reward: 0.2305,                 loss: 0.1265
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7801s / 12449.5625 s
agent0:                 episode reward: -0.1381,                 loss: nan
agent1:                 episode reward: 0.1381,                 loss: 0.1255
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1805s / 12697.7430 s
agent0:                 episode reward: 0.1615,                 loss: nan
agent1:                 episode reward: -0.1615,                 loss: 0.1258
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7333s / 12947.4763 s
agent0:                 episode reward: -0.2072,                 loss: nan
agent1:                 episode reward: 0.2072,                 loss: 0.1237
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0706s / 13188.5469 s
agent0:                 episode reward: 0.3343,                 loss: nan
agent1:                 episode reward: -0.3343,                 loss: 0.1245
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7493s / 13436.2962 s
agent0:                 episode reward: -0.3295,                 loss: nan
agent1:                 episode reward: 0.3295,                 loss: 0.1236
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9192s / 13681.2154 s
agent0:                 episode reward: -0.1938,                 loss: nan
agent1:                 episode reward: 0.1938,                 loss: 0.1234
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6978s / 13924.9132 s
agent0:                 episode reward: 0.1126,                 loss: nan
agent1:                 episode reward: -0.1126,                 loss: 0.1238
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4910s / 14171.4042 s
agent0:                 episode reward: -0.1636,                 loss: nan
agent1:                 episode reward: 0.1636,                 loss: 0.1236
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1731s / 14417.5773 s
agent0:                 episode reward: -0.0483,                 loss: nan
agent1:                 episode reward: 0.0483,                 loss: 0.1245
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1498s / 14663.7271 s
agent0:                 episode reward: -0.3472,                 loss: nan
agent1:                 episode reward: 0.3472,                 loss: 0.1229
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2586s / 14903.9857 s
agent0:                 episode reward: -0.0424,                 loss: nan
agent1:                 episode reward: 0.0424,                 loss: 0.1236
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8611s / 15150.8468 s
agent0:                 episode reward: -0.3895,                 loss: nan
agent1:                 episode reward: 0.3895,                 loss: 0.1246
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4593s / 15397.3060 s
agent0:                 episode reward: -0.0027,                 loss: nan
agent1:                 episode reward: 0.0027,                 loss: 0.1238
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6644s / 15636.9704 s
agent0:                 episode reward: 0.4410,                 loss: nan
agent1:                 episode reward: -0.4410,                 loss: 0.1236
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0348s / 15888.0053 s
agent0:                 episode reward: 0.3375,                 loss: nan
agent1:                 episode reward: -0.3375,                 loss: 0.1229
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0802s / 16134.0854 s
agent0:                 episode reward: 0.3652,                 loss: nan
agent1:                 episode reward: -0.3652,                 loss: 0.1236
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0528s / 16382.1382 s
agent0:                 episode reward: 0.0718,                 loss: nan
agent1:                 episode reward: -0.0718,                 loss: 0.1218
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4367s / 16628.5749 s
agent0:                 episode reward: -0.7560,                 loss: nan
agent1:                 episode reward: 0.7560,                 loss: 0.1226
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5605s / 16882.1354 s
agent0:                 episode reward: -0.0513,                 loss: nan
agent1:                 episode reward: 0.0513,                 loss: 0.1244
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4573s / 17129.5926 s
agent0:                 episode reward: -0.0409,                 loss: nan
agent1:                 episode reward: 0.0409,                 loss: 0.1212
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5666s / 17376.1593 s
agent0:                 episode reward: -0.1164,                 loss: nan
agent1:                 episode reward: 0.1164,                 loss: 0.1225
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3229s / 17622.4822 s
agent0:                 episode reward: 0.0872,                 loss: nan
agent1:                 episode reward: -0.0872,                 loss: 0.1232
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8084s / 17862.2905 s
agent0:                 episode reward: 0.2029,                 loss: nan
agent1:                 episode reward: -0.2029,                 loss: 0.1223
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6886s / 18108.9791 s
agent0:                 episode reward: -0.4153,                 loss: nan
agent1:                 episode reward: 0.4153,                 loss: 0.1235
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.7757s / 18347.7548 s
agent0:                 episode reward: -0.0288,                 loss: nan
agent1:                 episode reward: 0.0288,                 loss: 0.1226
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 258.2088s / 18605.9636 s
agent0:                 episode reward: 0.1750,                 loss: nan
agent1:                 episode reward: -0.1750,                 loss: 0.1231
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2126s / 18848.1762 s
agent0:                 episode reward: -0.0305,                 loss: nan
agent1:                 episode reward: 0.0305,                 loss: 0.1210
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2929s / 19093.4690 s
agent0:                 episode reward: 0.1432,                 loss: nan
agent1:                 episode reward: -0.1432,                 loss: 0.1232
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7555s / 19335.2245 s
agent0:                 episode reward: 0.1453,                 loss: nan
agent1:                 episode reward: -0.1453,                 loss: 0.1226
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 236.5902s / 19571.8148 s
agent0:                 episode reward: 0.1931,                 loss: nan
agent1:                 episode reward: -0.1931,                 loss: 0.1218
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5492s / 19817.3639 s
agent0:                 episode reward: -0.2773,                 loss: nan
agent1:                 episode reward: 0.2773,                 loss: 0.1217
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7042s / 20064.0682 s
agent0:                 episode reward: 0.3188,                 loss: nan
agent1:                 episode reward: -0.3188,                 loss: 0.1228
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0125s / 20316.0806 s
agent0:                 episode reward: -0.2422,                 loss: nan
agent1:                 episode reward: 0.2422,                 loss: 0.1224
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9568s / 20561.0374 s
agent0:                 episode reward: 0.2463,                 loss: nan
agent1:                 episode reward: -0.2463,                 loss: 0.1227
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6344s / 20811.6719 s
agent0:                 episode reward: -0.0926,                 loss: nan
agent1:                 episode reward: 0.0926,                 loss: 0.1216
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2439s / 21061.9157 s
agent0:                 episode reward: -0.1270,                 loss: nan
agent1:                 episode reward: 0.1270,                 loss: 0.1214
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3489s / 21310.2646 s
agent0:                 episode reward: 0.0819,                 loss: nan
agent1:                 episode reward: -0.0819,                 loss: 0.1203
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3050s / 21553.5695 s
agent0:                 episode reward: 0.0593,                 loss: nan
agent1:                 episode reward: -0.0593,                 loss: 0.1205
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2868s / 21799.8564 s
agent0:                 episode reward: -0.1775,                 loss: nan
agent1:                 episode reward: 0.1775,                 loss: 0.1213
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6958s / 22048.5522 s
agent0:                 episode reward: 0.4548,                 loss: nan
agent1:                 episode reward: -0.4548,                 loss: 0.1207
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3271s / 22290.8793 s
agent0:                 episode reward: 0.1602,                 loss: nan
agent1:                 episode reward: -0.1602,                 loss: 0.1229
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1015s / 22531.9808 s
agent0:                 episode reward: -0.2578,                 loss: nan
agent1:                 episode reward: 0.2578,                 loss: 0.1209
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0087s / 22775.9895 s
agent0:                 episode reward: 0.1807,                 loss: nan
agent1:                 episode reward: -0.1807,                 loss: 0.1211
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3548s / 23017.3443 s
agent0:                 episode reward: 0.0434,                 loss: nan
agent1:                 episode reward: -0.0434,                 loss: 0.1205
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7483s / 23260.0925 s
agent0:                 episode reward: 0.1381,                 loss: nan
agent1:                 episode reward: -0.1381,                 loss: 0.1226
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6788s / 23508.7713 s
agent0:                 episode reward: -0.4366,                 loss: nan
agent1:                 episode reward: 0.4366,                 loss: 0.1218
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6520s / 23755.4234 s
agent0:                 episode reward: 0.0586,                 loss: nan
agent1:                 episode reward: -0.0586,                 loss: 0.1218
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5201s / 24005.9434 s
agent0:                 episode reward: 0.0619,                 loss: nan
agent1:                 episode reward: -0.0619,                 loss: 0.1204
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3289s / 24257.2723 s
agent0:                 episode reward: -0.0479,                 loss: nan
agent1:                 episode reward: 0.0479,                 loss: 0.1203
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0844s / 24501.3568 s
agent0:                 episode reward: 0.0543,                 loss: nan
agent1:                 episode reward: -0.0543,                 loss: 0.1220
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1229s / 24753.4797 s
agent0:                 episode reward: 0.0573,                 loss: nan
agent1:                 episode reward: -0.0573,                 loss: 0.1213
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.7614s / 24991.2411 s
agent0:                 episode reward: -0.2637,                 loss: nan
agent1:                 episode reward: 0.2637,                 loss: 0.1193
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9368s / 25243.1779 s
agent0:                 episode reward: 0.2312,                 loss: nan
agent1:                 episode reward: -0.2312,                 loss: 0.1193
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8811s / 25486.0590 s
agent0:                 episode reward: 0.2642,                 loss: nan
agent1:                 episode reward: -0.2642,                 loss: 0.1212
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.7612s / 25723.8202 s
agent0:                 episode reward: 0.3894,                 loss: nan
agent1:                 episode reward: -0.3894,                 loss: 0.1199
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8029s / 25966.6231 s
agent0:                 episode reward: -0.4636,                 loss: nan
agent1:                 episode reward: 0.4636,                 loss: 0.1203
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4504s / 26211.0735 s
agent0:                 episode reward: -0.2010,                 loss: nan
agent1:                 episode reward: 0.2010,                 loss: 0.1213
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8510s / 26454.9245 s
agent0:                 episode reward: 0.0581,                 loss: nan
agent1:                 episode reward: -0.0581,                 loss: 0.1212
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9622s / 26706.8866 s
agent0:                 episode reward: 0.2312,                 loss: nan
agent1:                 episode reward: -0.2312,                 loss: 0.1200
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4395s / 26947.3262 s
agent0:                 episode reward: -0.0433,                 loss: nan
agent1:                 episode reward: 0.0433,                 loss: 0.1202
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7539s / 27196.0801 s
agent0:                 episode reward: 0.1132,                 loss: nan
agent1:                 episode reward: -0.1132,                 loss: 0.1202
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8454s / 27437.9255 s
agent0:                 episode reward: 0.1634,                 loss: nan
agent1:                 episode reward: -0.1634,                 loss: 0.1208
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0243s / 27680.9498 s
agent0:                 episode reward: -0.1769,                 loss: nan
agent1:                 episode reward: 0.1769,                 loss: 0.1196
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4824s / 27922.4322 s
agent0:                 episode reward: 0.0010,                 loss: nan
agent1:                 episode reward: -0.0010,                 loss: 0.1198
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6317s / 28170.0639 s
agent0:                 episode reward: -0.2690,                 loss: nan
agent1:                 episode reward: 0.2690,                 loss: 0.1201
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7592s / 28416.8231 s
agent0:                 episode reward: 0.0818,                 loss: nan
agent1:                 episode reward: -0.0818,                 loss: 0.1190
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6009s / 28658.4239 s
agent0:                 episode reward: 0.4487,                 loss: nan
agent1:                 episode reward: -0.4487,                 loss: 0.1189
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 233.5948s / 28892.0188 s
agent0:                 episode reward: -0.3182,                 loss: nan
agent1:                 episode reward: 0.3182,                 loss: 0.1191
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9864s / 29136.0052 s
agent0:                 episode reward: 0.1880,                 loss: nan
agent1:                 episode reward: -0.1880,                 loss: 0.1185
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2601s / 29382.2653 s
agent0:                 episode reward: 0.2490,                 loss: nan
agent1:                 episode reward: -0.2490,                 loss: 0.1198
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5354s / 29628.8007 s
agent0:                 episode reward: -0.2700,                 loss: nan
agent1:                 episode reward: 0.2700,                 loss: 0.1216
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9641s / 29869.7649 s
agent0:                 episode reward: 0.1487,                 loss: nan
agent1:                 episode reward: -0.1487,                 loss: 0.1190
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4604s / 30118.2252 s
agent0:                 episode reward: -0.2217,                 loss: nan
agent1:                 episode reward: 0.2217,                 loss: 0.1184
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5238s / 30361.7490 s
agent0:                 episode reward: -0.3952,                 loss: nan
agent1:                 episode reward: 0.3952,                 loss: 0.1202
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3997s / 30612.1487 s
agent0:                 episode reward: -0.3628,                 loss: nan
agent1:                 episode reward: 0.3628,                 loss: 0.1179
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0058s / 30854.1546 s
agent0:                 episode reward: -0.2238,                 loss: nan
agent1:                 episode reward: 0.2238,                 loss: 0.1187
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3688s / 31094.5234 s
agent0:                 episode reward: -0.1046,                 loss: nan
agent1:                 episode reward: 0.1046,                 loss: 0.1195
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.7433s / 31332.2667 s
agent0:                 episode reward: -0.5898,                 loss: nan
agent1:                 episode reward: 0.5898,                 loss: 0.1217
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7644s / 31583.0310 s
agent0:                 episode reward: 0.1023,                 loss: nan
agent1:                 episode reward: -0.1023,                 loss: 0.1198
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.2592s / 31821.2902 s
agent0:                 episode reward: -0.2194,                 loss: nan
agent1:                 episode reward: 0.2194,                 loss: 0.1207
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.4973s / 32078.7876 s
agent0:                 episode reward: 0.3814,                 loss: nan
agent1:                 episode reward: -0.3814,                 loss: 0.1205
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6548s / 32323.4424 s
agent0:                 episode reward: -0.0755,                 loss: nan
agent1:                 episode reward: 0.0755,                 loss: 0.1190
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8197s / 32568.2621 s
agent0:                 episode reward: 0.0351,                 loss: nan
agent1:                 episode reward: -0.0351,                 loss: 0.1185
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2269s / 32809.4890 s
agent0:                 episode reward: -0.2150,                 loss: nan
agent1:                 episode reward: 0.2150,                 loss: 0.1191
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6148s / 33052.1038 s
agent0:                 episode reward: 0.1981,                 loss: nan
agent1:                 episode reward: -0.1981,                 loss: 0.1189
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1651s / 33306.2689 s
agent0:                 episode reward: -0.0606,                 loss: nan
agent1:                 episode reward: 0.0606,                 loss: 0.1168
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5316s / 33548.8005 s
agent0:                 episode reward: -0.4344,                 loss: nan
agent1:                 episode reward: 0.4344,                 loss: 0.1166
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1485s / 33793.9490 s
agent0:                 episode reward: -0.1762,                 loss: nan
agent1:                 episode reward: 0.1762,                 loss: 0.1158
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1867s / 34036.1357 s
agent0:                 episode reward: 0.2249,                 loss: nan
agent1:                 episode reward: -0.2249,                 loss: 0.1167
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7058s / 34278.8415 s
agent0:                 episode reward: -0.2515,                 loss: nan
agent1:                 episode reward: 0.2515,                 loss: 0.1168
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.9960s / 34532.8375 s
agent0:                 episode reward: 0.1413,                 loss: nan
agent1:                 episode reward: -0.1413,                 loss: 0.1177
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4656s / 34784.3031 s
agent0:                 episode reward: -0.1875,                 loss: nan
agent1:                 episode reward: 0.1875,                 loss: 0.1163
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4168s / 35025.7199 s
agent0:                 episode reward: -0.2517,                 loss: nan
agent1:                 episode reward: 0.2517,                 loss: 0.1156
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9974s / 35274.7173 s
agent0:                 episode reward: 0.0367,                 loss: nan
agent1:                 episode reward: -0.0367,                 loss: 0.1166
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5032s / 35525.2205 s
agent0:                 episode reward: -0.0565,                 loss: nan
agent1:                 episode reward: 0.0565,                 loss: 0.1165
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1701s / 35772.3906 s
agent0:                 episode reward: -0.3416,                 loss: nan
agent1:                 episode reward: 0.3416,                 loss: 0.1158
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6450s / 36014.0356 s
agent0:                 episode reward: -0.2922,                 loss: nan
agent1:                 episode reward: 0.2922,                 loss: 0.1161
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4365s / 36258.4721 s
agent0:                 episode reward: -0.3241,                 loss: nan
agent1:                 episode reward: 0.3241,                 loss: 0.1150
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1378s / 36507.6099 s
agent0:                 episode reward: -0.1067,                 loss: nan
agent1:                 episode reward: 0.1067,                 loss: 0.1148
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0181s / 36757.6280 s
agent0:                 episode reward: 0.0439,                 loss: nan
agent1:                 episode reward: -0.0439,                 loss: 0.1165
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9238s / 37000.5518 s
agent0:                 episode reward: 0.0768,                 loss: nan
agent1:                 episode reward: -0.0768,                 loss: 0.1155
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0040s / 37248.5558 s
agent0:                 episode reward: 0.0825,                 loss: nan
agent1:                 episode reward: -0.0825,                 loss: 0.1167
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7128s / 37489.2687 s
agent0:                 episode reward: 0.2236,                 loss: nan
agent1:                 episode reward: -0.2236,                 loss: 0.1155
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0321s / 37739.3008 s
agent0:                 episode reward: -0.3613,                 loss: nan
agent1:                 episode reward: 0.3613,                 loss: 0.1164
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9400s / 37983.2408 s
agent0:                 episode reward: 0.0423,                 loss: nan
agent1:                 episode reward: -0.0423,                 loss: 0.1156
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7597s / 38235.0005 s
agent0:                 episode reward: 0.0238,                 loss: nan
agent1:                 episode reward: -0.0238,                 loss: 0.1150
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2355s / 38480.2361 s
agent0:                 episode reward: 0.0917,                 loss: nan
agent1:                 episode reward: -0.0917,                 loss: 0.1155
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5401s / 38718.7762 s
agent0:                 episode reward: 0.0551,                 loss: nan
agent1:                 episode reward: -0.0551,                 loss: 0.1154
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2452s / 38973.0214 s
agent0:                 episode reward: 0.0544,                 loss: nan
agent1:                 episode reward: -0.0544,                 loss: 0.1147
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4396s / 39215.4610 s
agent0:                 episode reward: 0.1175,                 loss: nan
agent1:                 episode reward: -0.1175,                 loss: 0.1154
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.8748s / 39473.3358 s
agent0:                 episode reward: 0.0438,                 loss: nan
agent1:                 episode reward: -0.0438,                 loss: 0.1153
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6378s / 39719.9736 s
agent0:                 episode reward: -0.0081,                 loss: nan
agent1:                 episode reward: 0.0081,                 loss: 0.1144
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.4542s / 39956.4278 s
agent0:                 episode reward: -0.0105,                 loss: nan
agent1:                 episode reward: 0.0105,                 loss: 0.1157
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9174s / 40206.3452 s
agent0:                 episode reward: 0.4225,                 loss: nan
agent1:                 episode reward: -0.4225,                 loss: 0.1145
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5441s / 40453.8893 s
agent0:                 episode reward: 0.0624,                 loss: nan
agent1:                 episode reward: -0.0624,                 loss: 0.1152
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6963s / 40703.5856 s
agent0:                 episode reward: -0.3537,                 loss: nan
agent1:                 episode reward: 0.3537,                 loss: 0.1138
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8862s / 40955.4719 s
agent0:                 episode reward: -0.3570,                 loss: nan
agent1:                 episode reward: 0.3570,                 loss: 0.1149
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6896s / 41202.1615 s
agent0:                 episode reward: -0.2414,                 loss: nan
agent1:                 episode reward: 0.2414,                 loss: 0.1147
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.2314s / 41440.3929 s
agent0:                 episode reward: -0.3138,                 loss: nan
agent1:                 episode reward: 0.3138,                 loss: 0.1158
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8735s / 41683.2664 s
agent0:                 episode reward: -0.3508,                 loss: nan
agent1:                 episode reward: 0.3508,                 loss: 0.1170
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8172s / 41925.0835 s
agent0:                 episode reward: -0.6700,                 loss: nan
agent1:                 episode reward: 0.6700,                 loss: 0.1161
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8147s / 42169.8983 s
agent0:                 episode reward: 0.2403,                 loss: nan
agent1:                 episode reward: -0.2403,                 loss: 0.1163
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5550s / 42411.4532 s
agent0:                 episode reward: -0.1850,                 loss: nan
agent1:                 episode reward: 0.1850,                 loss: 0.1154
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8922s / 42656.3454 s
agent0:                 episode reward: -0.1577,                 loss: nan
agent1:                 episode reward: 0.1577,                 loss: 0.1169
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4562s / 42902.8016 s
agent0:                 episode reward: -0.2015,                 loss: nan
agent1:                 episode reward: 0.2015,                 loss: 0.1163
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5033s / 43151.3049 s
agent0:                 episode reward: 0.0849,                 loss: nan
agent1:                 episode reward: -0.0849,                 loss: 0.1141
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0599s / 43403.3648 s
agent0:                 episode reward: -0.2037,                 loss: nan
agent1:                 episode reward: 0.2037,                 loss: 0.1168
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8320s / 43644.1968 s
agent0:                 episode reward: -0.2002,                 loss: nan
agent1:                 episode reward: 0.2002,                 loss: 0.1153
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.4514s / 43898.6482 s
agent0:                 episode reward: 0.0931,                 loss: nan
agent1:                 episode reward: -0.0931,                 loss: 0.1170
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4122s / 44138.0604 s
agent0:                 episode reward: -0.2355,                 loss: nan
agent1:                 episode reward: 0.2355,                 loss: 0.1162
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5693s / 44384.6297 s
agent0:                 episode reward: -0.4369,                 loss: nan
agent1:                 episode reward: 0.4369,                 loss: 0.1169
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4014s / 44632.0311 s
agent0:                 episode reward: 0.4194,                 loss: nan
agent1:                 episode reward: -0.4194,                 loss: 0.1149
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 259.7129s / 44891.7440 s
agent0:                 episode reward: -0.0270,                 loss: nan
agent1:                 episode reward: 0.0270,                 loss: 0.1151
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9295s / 45129.6735 s
agent0:                 episode reward: -0.2666,                 loss: nan
agent1:                 episode reward: 0.2666,                 loss: 0.1160
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0956s / 45372.7690 s
agent0:                 episode reward: -0.1756,                 loss: nan
agent1:                 episode reward: 0.1756,                 loss: 0.1138
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6958s / 45616.4648 s
agent0:                 episode reward: -0.1903,                 loss: nan
agent1:                 episode reward: 0.1903,                 loss: 0.1111
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4325s / 45861.8973 s
agent0:                 episode reward: 0.1395,                 loss: nan
agent1:                 episode reward: -0.1395,                 loss: 0.1126
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5194s / 46107.4167 s
agent0:                 episode reward: 0.0990,                 loss: nan
agent1:                 episode reward: -0.0990,                 loss: 0.1102
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2346s / 46353.6513 s
agent0:                 episode reward: -0.5806,                 loss: nan
agent1:                 episode reward: 0.5806,                 loss: 0.1101
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5788s / 46599.2301 s
agent0:                 episode reward: 0.0269,                 loss: nan
agent1:                 episode reward: -0.0269,                 loss: 0.1108
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1940s / 46839.4241 s
agent0:                 episode reward: -0.1280,                 loss: nan
agent1:                 episode reward: 0.1280,                 loss: 0.1095
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2581s / 47083.6822 s
agent0:                 episode reward: -0.1711,                 loss: nan
agent1:                 episode reward: 0.1711,                 loss: 0.1090
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1675s / 47325.8497 s
agent0:                 episode reward: -0.1562,                 loss: nan
agent1:                 episode reward: 0.1562,                 loss: 0.1111
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8328s / 47573.6825 s
agent0:                 episode reward: -0.0241,                 loss: nan
agent1:                 episode reward: 0.0241,                 loss: 0.1098
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4816s / 47818.1641 s
agent0:                 episode reward: -0.3700,                 loss: nan
agent1:                 episode reward: 0.3700,                 loss: 0.1102
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7805s / 48067.9445 s
agent0:                 episode reward: -0.0322,                 loss: nan
agent1:                 episode reward: 0.0322,                 loss: 0.1098
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8704s / 48308.8149 s
agent0:                 episode reward: -0.1179,                 loss: nan
agent1:                 episode reward: 0.1179,                 loss: 0.1112
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4694s / 48560.2844 s
agent0:                 episode reward: -0.1794,                 loss: nan
agent1:                 episode reward: 0.1794,                 loss: 0.1111
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6887s / 48806.9731 s
agent0:                 episode reward: -0.2174,                 loss: nan
agent1:                 episode reward: 0.2174,                 loss: 0.1101
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8634s / 49054.8365 s
agent0:                 episode reward: -0.0900,                 loss: nan
agent1:                 episode reward: 0.0900,                 loss: 0.1120
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8400s / 49297.6765 s
agent0:                 episode reward: 0.0996,                 loss: nan
agent1:                 episode reward: -0.0996,                 loss: 0.1095
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0399s / 49545.7164 s
agent0:                 episode reward: -0.5163,                 loss: nan
agent1:                 episode reward: 0.5163,                 loss: 0.1151
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7391s / 49797.4555 s
agent0:                 episode reward: -0.3997,                 loss: nan
agent1:                 episode reward: 0.3997,                 loss: 0.1152
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0324s / 50045.4879 s
agent0:                 episode reward: -0.1793,                 loss: nan
agent1:                 episode reward: 0.1793,                 loss: 0.1154
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4760s / 50290.9640 s
agent0:                 episode reward: -0.2637,                 loss: nan
agent1:                 episode reward: 0.2637,                 loss: 0.1152
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 258.1354s / 50549.0993 s
agent0:                 episode reward: 0.0515,                 loss: nan
agent1:                 episode reward: -0.0515,                 loss: 0.1170
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2087s / 50792.3080 s
agent0:                 episode reward: -0.2992,                 loss: nan
agent1:                 episode reward: 0.2992,                 loss: 0.1162
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2882s / 51033.5962 s
agent0:                 episode reward: -0.1307,                 loss: nan
agent1:                 episode reward: 0.1307,                 loss: 0.1151
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2968s / 51285.8929 s
agent0:                 episode reward: -0.1542,                 loss: nan
agent1:                 episode reward: 0.1542,                 loss: 0.1137
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4893s / 51535.3822 s
agent0:                 episode reward: -0.1924,                 loss: nan
agent1:                 episode reward: 0.1924,                 loss: 0.1142
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8204s / 51782.2026 s
agent0:                 episode reward: -0.3425,                 loss: nan
agent1:                 episode reward: 0.3425,                 loss: 0.1157
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3945s / 52028.5971 s
agent0:                 episode reward: 0.0635,                 loss: nan
agent1:                 episode reward: -0.0635,                 loss: 0.1155
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3362s / 52279.9333 s
agent0:                 episode reward: -0.1246,                 loss: nan
agent1:                 episode reward: 0.1246,                 loss: 0.1146
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6583s / 52532.5916 s
agent0:                 episode reward: -0.0047,                 loss: nan
agent1:                 episode reward: 0.0047,                 loss: 0.1136
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0254s / 52775.6170 s
agent0:                 episode reward: -0.1269,                 loss: nan
agent1:                 episode reward: 0.1269,                 loss: 0.1158
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8717s / 53024.4887 s
agent0:                 episode reward: 0.0787,                 loss: nan
agent1:                 episode reward: -0.0787,                 loss: 0.1162
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2632s / 53277.7519 s
agent0:                 episode reward: -0.1531,                 loss: nan
agent1:                 episode reward: 0.1531,                 loss: 0.1156
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9965s / 53528.7484 s
agent0:                 episode reward: -0.2710,                 loss: nan
agent1:                 episode reward: 0.2710,                 loss: 0.1166
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5949s / 53770.3433 s
agent0:                 episode reward: -0.2780,                 loss: nan
agent1:                 episode reward: 0.2780,                 loss: 0.1117
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.3120s / 54008.6553 s
agent0:                 episode reward: -0.3033,                 loss: nan
agent1:                 episode reward: 0.3033,                 loss: 0.1120
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0753s / 54255.7306 s
agent0:                 episode reward: -0.4028,                 loss: nan
agent1:                 episode reward: 0.4028,                 loss: 0.1121
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2221s / 54499.9527 s
agent0:                 episode reward: -0.1892,                 loss: nan
agent1:                 episode reward: 0.1892,                 loss: 0.1125
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8606s / 54748.8133 s
agent0:                 episode reward: 0.1532,                 loss: nan
agent1:                 episode reward: -0.1532,                 loss: 0.1121
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3614s / 54991.1747 s
agent0:                 episode reward: -0.3280,                 loss: nan
agent1:                 episode reward: 0.3280,                 loss: 0.1125
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5021s / 55245.6768 s
agent0:                 episode reward: -0.4103,                 loss: nan
agent1:                 episode reward: 0.4103,                 loss: 0.1116
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.4461s / 55501.1229 s
agent0:                 episode reward: 0.0457,                 loss: nan
agent1:                 episode reward: -0.0457,                 loss: 0.1125
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5757s / 55745.6986 s
agent0:                 episode reward: -0.4272,                 loss: nan
agent1:                 episode reward: 0.4272,                 loss: 0.1123
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 259.1699s / 56004.8685 s
agent0:                 episode reward: -0.3611,                 loss: nan
agent1:                 episode reward: 0.3611,                 loss: 0.1140
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9404s / 56248.8089 s
agent0:                 episode reward: -0.0413,                 loss: nan
agent1:                 episode reward: 0.0413,                 loss: 0.1119
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.0302s / 56486.8391 s
agent0:                 episode reward: -0.0212,                 loss: nan
agent1:                 episode reward: 0.0212,                 loss: 0.1104
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7354s / 56737.5746 s
agent0:                 episode reward: -0.3157,                 loss: nan
agent1:                 episode reward: 0.3157,                 loss: 0.1112
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8481s / 56983.4226 s
agent0:                 episode reward: -0.2657,                 loss: nan
agent1:                 episode reward: 0.2657,                 loss: 0.1120
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1433s / 57231.5659 s
agent0:                 episode reward: 0.3379,                 loss: nan
agent1:                 episode reward: -0.3379,                 loss: 0.1105
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2457s / 57478.8116 s
agent0:                 episode reward: -0.0527,                 loss: nan
agent1:                 episode reward: 0.0527,                 loss: 0.1104
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9907s / 57725.8024 s
agent0:                 episode reward: 0.0341,                 loss: nan
agent1:                 episode reward: -0.0341,                 loss: 0.1115
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5098s / 57974.3122 s
agent0:                 episode reward: 0.2291,                 loss: nan
agent1:                 episode reward: -0.2291,                 loss: 0.1136
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6332s / 58217.9454 s
agent0:                 episode reward: -0.2441,                 loss: nan
agent1:                 episode reward: 0.2441,                 loss: 0.1126
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0486s / 58462.9939 s
agent0:                 episode reward: 0.1516,                 loss: nan
agent1:                 episode reward: -0.1516,                 loss: 0.1117
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5348s / 58703.5288 s
agent0:                 episode reward: -0.0525,                 loss: nan
agent1:                 episode reward: 0.0525,                 loss: 0.1118
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0251s / 58953.5539 s
agent0:                 episode reward: -0.5416,                 loss: nan
agent1:                 episode reward: 0.5416,                 loss: 0.1133
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6829s / 59197.2368 s
agent0:                 episode reward: -0.3216,                 loss: nan
agent1:                 episode reward: 0.3216,                 loss: 0.1133
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1123s / 59441.3491 s
agent0:                 episode reward: -0.1761,                 loss: nan
agent1:                 episode reward: 0.1761,                 loss: 0.1129
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6350s / 59691.9841 s
agent0:                 episode reward: 0.2148,                 loss: nan
agent1:                 episode reward: -0.2148,                 loss: 0.1118
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6927s / 59939.6768 s
agent0:                 episode reward: -0.4041,                 loss: nan
agent1:                 episode reward: 0.4041,                 loss: 0.1135
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3901s / 60189.0669 s
agent0:                 episode reward: 0.0977,                 loss: nan
agent1:                 episode reward: -0.0977,                 loss: 0.1115
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7863s / 60439.8532 s
agent0:                 episode reward: -0.0548,                 loss: nan
agent1:                 episode reward: 0.0548,                 loss: 0.1110
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1055s / 60690.9587 s
agent0:                 episode reward: 0.3156,                 loss: nan
agent1:                 episode reward: -0.3156,                 loss: 0.1142
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1854s / 60943.1441 s
agent0:                 episode reward: -0.5993,                 loss: nan
agent1:                 episode reward: 0.5993,                 loss: 0.1121
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1940s / 61187.3381 s
agent0:                 episode reward: -0.4756,                 loss: nan
agent1:                 episode reward: 0.4756,                 loss: 0.1130
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7439s / 61437.0820 s
agent0:                 episode reward: -0.2734,                 loss: nan
agent1:                 episode reward: 0.2734,                 loss: 0.1129
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 230.2539s / 61667.3359 s
agent0:                 episode reward: -0.1609,                 loss: nan
agent1:                 episode reward: 0.1609,                 loss: 0.1119
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3187s / 61916.6546 s
agent0:                 episode reward: -0.1022,                 loss: nan
agent1:                 episode reward: 0.1022,                 loss: 0.1111
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.2674s / 62155.9220 s
agent0:                 episode reward: -0.2232,                 loss: nan
agent1:                 episode reward: 0.2232,                 loss: 0.1110
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1331s / 62398.0551 s
agent0:                 episode reward: 0.0045,                 loss: nan
agent1:                 episode reward: -0.0045,                 loss: 0.1112
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7368s / 62648.7919 s
agent0:                 episode reward: -0.1683,                 loss: nan
agent1:                 episode reward: 0.1683,                 loss: 0.1111
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6703s / 62898.4622 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.1105
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9797s / 63139.4419 s
agent0:                 episode reward: -0.3045,                 loss: nan
agent1:                 episode reward: 0.3045,                 loss: 0.1118
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3883s / 63390.8302 s
agent0:                 episode reward: -0.0866,                 loss: nan
agent1:                 episode reward: 0.0866,                 loss: 0.1123
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7153s / 63638.5455 s
agent0:                 episode reward: -0.0842,                 loss: nan
agent1:                 episode reward: 0.0842,                 loss: 0.1102
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0585s / 63886.6040 s
agent0:                 episode reward: 0.0170,                 loss: nan
agent1:                 episode reward: -0.0170,                 loss: 0.1127
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6865s / 64136.2905 s
agent0:                 episode reward: 0.0180,                 loss: nan
agent1:                 episode reward: -0.0180,                 loss: 0.1125
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9449s / 64377.2355 s
agent0:                 episode reward: 0.0550,                 loss: nan
agent1:                 episode reward: -0.0550,                 loss: 0.1112
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6747s / 64625.9102 s
agent0:                 episode reward: -0.2044,                 loss: nan
agent1:                 episode reward: 0.2044,                 loss: 0.1122
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.0385s / 64879.9487 s
agent0:                 episode reward: -0.5066,                 loss: nan
agent1:                 episode reward: 0.5066,                 loss: 0.1112
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2543s / 65131.2030 s
agent0:                 episode reward: -0.3227,                 loss: nan
agent1:                 episode reward: 0.3227,                 loss: 0.1106
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4119s / 65375.6149 s
agent0:                 episode reward: -0.3358,                 loss: nan
agent1:                 episode reward: 0.3358,                 loss: 0.1110
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3947s / 65617.0096 s
agent0:                 episode reward: -0.4209,                 loss: nan
agent1:                 episode reward: 0.4209,                 loss: 0.1103
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6447s / 65858.6543 s
agent0:                 episode reward: -0.3186,                 loss: nan
agent1:                 episode reward: 0.3186,                 loss: 0.1110
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 232.0428s / 66090.6971 s
agent0:                 episode reward: -0.0324,                 loss: nan
agent1:                 episode reward: 0.0324,                 loss: 0.1102
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1881s / 66336.8852 s
agent0:                 episode reward: -0.1732,                 loss: nan
agent1:                 episode reward: 0.1732,                 loss: 0.1112
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6269s / 66582.5122 s
agent0:                 episode reward: -0.0650,                 loss: nan
agent1:                 episode reward: 0.0650,                 loss: 0.1121
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0928s / 66824.6050 s
agent0:                 episode reward: -0.0246,                 loss: nan
agent1:                 episode reward: 0.0246,                 loss: 0.1101
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 236.6723s / 67061.2772 s
agent0:                 episode reward: -0.3149,                 loss: nan
agent1:                 episode reward: 0.3149,                 loss: 0.1104
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.1850s / 67317.4622 s
agent0:                 episode reward: -0.0792,                 loss: nan
agent1:                 episode reward: 0.0792,                 loss: 0.1108
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5373s / 67567.9996 s
agent0:                 episode reward: -0.3244,                 loss: nan
agent1:                 episode reward: 0.3244,                 loss: 0.1099
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9005s / 67817.9001 s
agent0:                 episode reward: -0.5746,                 loss: nan
agent1:                 episode reward: 0.5746,                 loss: 0.1104
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5153s / 68068.4154 s
agent0:                 episode reward: -0.2422,                 loss: nan
agent1:                 episode reward: 0.2422,                 loss: 0.1102
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9567s / 68321.3721 s
agent0:                 episode reward: 0.0096,                 loss: nan
agent1:                 episode reward: -0.0096,                 loss: 0.1100
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2918s / 68565.6639 s
agent0:                 episode reward: -0.3880,                 loss: nan
agent1:                 episode reward: 0.3880,                 loss: 0.1108
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4581s / 68816.1220 s
agent0:                 episode reward: -0.6878,                 loss: nan
agent1:                 episode reward: 0.6878,                 loss: 0.1105
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3010s / 69058.4230 s
agent0:                 episode reward: -0.1193,                 loss: nan
agent1:                 episode reward: 0.1193,                 loss: 0.1102
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 261.4562s / 69319.8792 s
agent0:                 episode reward: -0.1018,                 loss: nan
agent1:                 episode reward: 0.1018,                 loss: 0.1103
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9521s / 69565.8313 s
agent0:                 episode reward: 0.1189,                 loss: nan
agent1:                 episode reward: -0.1189,                 loss: 0.1092
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.9014s / 69807.7327 s
agent0:                 episode reward: -0.4934,                 loss: nan
agent1:                 episode reward: 0.4934,                 loss: 0.1102
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1128s / 70056.8455 s
agent0:                 episode reward: -0.2331,                 loss: nan
agent1:                 episode reward: 0.2331,                 loss: 0.1094
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6662s / 70302.5117 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.1095
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5892s / 70551.1009 s
agent0:                 episode reward: -0.0195,                 loss: nan
agent1:                 episode reward: 0.0195,                 loss: 0.1090
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7990s / 70792.9000 s
agent0:                 episode reward: -0.4335,                 loss: nan
agent1:                 episode reward: 0.4335,                 loss: 0.1084
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8200s / 71041.7199 s
agent0:                 episode reward: -0.0457,                 loss: nan
agent1:                 episode reward: 0.0457,                 loss: 0.1091
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9339s / 71296.6538 s
agent0:                 episode reward: -0.6634,                 loss: nan
agent1:                 episode reward: 0.6634,                 loss: 0.1100
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6215s / 71551.2753 s
agent0:                 episode reward: -0.0841,                 loss: nan
agent1:                 episode reward: 0.0841,                 loss: 0.1091
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9016s / 71802.1769 s
agent0:                 episode reward: 0.1197,                 loss: nan
agent1:                 episode reward: -0.1197,                 loss: 0.1086
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.1158s / 72057.2928 s
agent0:                 episode reward: -0.0632,                 loss: nan
agent1:                 episode reward: 0.0632,                 loss: 0.1095
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7940s / 72304.0868 s
agent0:                 episode reward: -0.3489,                 loss: nan
agent1:                 episode reward: 0.3489,                 loss: 0.1086
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5890s / 72550.6758 s
agent0:                 episode reward: -0.2019,                 loss: nan
agent1:                 episode reward: 0.2019,                 loss: 0.1075
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2398s / 72797.9156 s
agent0:                 episode reward: -0.4597,                 loss: nan
agent1:                 episode reward: 0.4597,                 loss: 0.1069
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.5647s / 73036.4803 s
agent0:                 episode reward: 0.1769,                 loss: nan
agent1:                 episode reward: -0.1769,                 loss: 0.1079
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9857s / 73287.4659 s
agent0:                 episode reward: -0.1138,                 loss: nan
agent1:                 episode reward: 0.1138,                 loss: 0.1080
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6823s / 73535.1482 s
agent0:                 episode reward: -0.3765,                 loss: nan
agent1:                 episode reward: 0.3765,                 loss: 0.1076
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5601s / 73780.7083 s
agent0:                 episode reward: -0.3574,                 loss: nan
agent1:                 episode reward: 0.3574,                 loss: 0.1061
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5223s / 74028.2306 s
agent0:                 episode reward: -0.2387,                 loss: nan
agent1:                 episode reward: 0.2387,                 loss: 0.1090
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9532s / 74268.1838 s
agent0:                 episode reward: -0.4968,                 loss: nan
agent1:                 episode reward: 0.4968,                 loss: 0.1095
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.5432s / 74523.7270 s
agent0:                 episode reward: 0.0787,                 loss: nan
agent1:                 episode reward: -0.0787,                 loss: 0.1102
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7268s / 74771.4539 s
agent0:                 episode reward: -0.2301,                 loss: nan
agent1:                 episode reward: 0.2301,                 loss: 0.1114
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0062s / 75021.4601 s
agent0:                 episode reward: -0.7424,                 loss: nan
agent1:                 episode reward: 0.7424,                 loss: 0.1109
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2744s / 75274.7345 s
agent0:                 episode reward: -0.1298,                 loss: nan
agent1:                 episode reward: 0.1298,                 loss: 0.1119
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2013s / 75527.9358 s
agent0:                 episode reward: -0.5097,                 loss: nan
agent1:                 episode reward: 0.5097,                 loss: 0.1104
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6836s / 75775.6194 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.1112
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0130s / 76024.6324 s
agent0:                 episode reward: -0.4657,                 loss: nan
agent1:                 episode reward: 0.4657,                 loss: 0.1105
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8413s / 76274.4737 s
agent0:                 episode reward: -0.1043,                 loss: nan
agent1:                 episode reward: 0.1043,                 loss: 0.1102
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4586s / 76519.9323 s
agent0:                 episode reward: -0.6971,                 loss: nan
agent1:                 episode reward: 0.6971,                 loss: 0.1090
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3008s / 76764.2332 s
agent0:                 episode reward: 0.2734,                 loss: nan
agent1:                 episode reward: -0.2734,                 loss: 0.1094
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2717s / 77005.5048 s
agent0:                 episode reward: -0.2663,                 loss: nan
agent1:                 episode reward: 0.2663,                 loss: 0.1102
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4281s / 77253.9329 s
agent0:                 episode reward: -0.2841,                 loss: nan
agent1:                 episode reward: 0.2841,                 loss: 0.1101
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7062s / 77498.6391 s
agent0:                 episode reward: -0.1685,                 loss: nan
agent1:                 episode reward: 0.1685,                 loss: 0.1085
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1997s / 77748.8388 s
agent0:                 episode reward: -0.1176,                 loss: nan
agent1:                 episode reward: 0.1176,                 loss: 0.1104
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8409s / 77990.6797 s
agent0:                 episode reward: -0.5951,                 loss: nan
agent1:                 episode reward: 0.5951,                 loss: 0.1099
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4850s / 78241.1647 s
agent0:                 episode reward: -0.0414,                 loss: nan
agent1:                 episode reward: 0.0414,                 loss: 0.1100
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.1602s / 78478.3250 s
agent0:                 episode reward: -0.4521,                 loss: nan
agent1:                 episode reward: 0.4521,                 loss: 0.1103
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1920s / 78725.5170 s
agent0:                 episode reward: -0.2858,                 loss: nan
agent1:                 episode reward: 0.2858,                 loss: 0.1079
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1253s / 78971.6423 s
agent0:                 episode reward: -0.1319,                 loss: nan
agent1:                 episode reward: 0.1319,                 loss: 0.1108
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2549s / 79217.8972 s
agent0:                 episode reward: -0.0551,                 loss: nan
agent1:                 episode reward: 0.0551,                 loss: 0.1089
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3062s / 79464.2034 s
agent0:                 episode reward: -0.1100,                 loss: nan
agent1:                 episode reward: 0.1100,                 loss: 0.1082
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.0034s / 79704.2068 s
agent0:                 episode reward: -0.2850,                 loss: nan
agent1:                 episode reward: 0.2850,                 loss: 0.1087
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.2907s / 79959.4975 s
agent0:                 episode reward: -0.5237,                 loss: nan
agent1:                 episode reward: 0.5237,                 loss: 0.1095
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5777s / 80202.0752 s
agent0:                 episode reward: -0.3934,                 loss: nan
agent1:                 episode reward: 0.3934,                 loss: 0.1106
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2241s / 80444.2993 s
agent0:                 episode reward: -0.2243,                 loss: nan
agent1:                 episode reward: 0.2243,                 loss: 0.1099
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2506s / 80695.5500 s
agent0:                 episode reward: -0.6424,                 loss: nan
agent1:                 episode reward: 0.6424,                 loss: 0.1081
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.4654s / 80952.0153 s
agent0:                 episode reward: -0.5347,                 loss: nan
agent1:                 episode reward: 0.5347,                 loss: 0.1087
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8655s / 81197.8808 s
agent0:                 episode reward: -0.4996,                 loss: nan
agent1:                 episode reward: 0.4996,                 loss: 0.1079
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.9459s / 81437.8268 s
agent0:                 episode reward: -0.3083,                 loss: nan
agent1:                 episode reward: 0.3083,                 loss: 0.1086
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8627s / 81683.6895 s
agent0:                 episode reward: -0.3262,                 loss: nan
agent1:                 episode reward: 0.3262,                 loss: 0.1087
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.1899s / 81940.8794 s
agent0:                 episode reward: -0.4239,                 loss: nan
agent1:                 episode reward: 0.4239,                 loss: 0.1096
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3086s / 82191.1880 s
agent0:                 episode reward: 0.0262,                 loss: nan
agent1:                 episode reward: -0.0262,                 loss: 0.1092
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0682s / 82444.2562 s
agent0:                 episode reward: -0.1999,                 loss: nan
agent1:                 episode reward: 0.1999,                 loss: 0.1092
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1682s / 82692.4245 s
agent0:                 episode reward: -0.0824,                 loss: nan
agent1:                 episode reward: 0.0824,                 loss: 0.1095
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9319s / 82944.3564 s
agent0:                 episode reward: -0.2006,                 loss: nan
agent1:                 episode reward: 0.2006,                 loss: 0.1100
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5418s / 83188.8981 s
agent0:                 episode reward: -0.3962,                 loss: nan
agent1:                 episode reward: 0.3962,                 loss: 0.1091
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4931s / 83433.3913 s
agent0:                 episode reward: -0.5198,                 loss: nan
agent1:                 episode reward: 0.5198,                 loss: 0.1091
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 261.3441s / 83694.7353 s
agent0:                 episode reward: -0.4360,                 loss: nan
agent1:                 episode reward: 0.4360,                 loss: 0.1095
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7466s / 83946.4819 s
agent0:                 episode reward: -0.1244,                 loss: nan
agent1:                 episode reward: 0.1244,                 loss: 0.1103
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0602s / 84193.5421 s
agent0:                 episode reward: -0.5620,                 loss: nan
agent1:                 episode reward: 0.5620,                 loss: 0.1087
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5685s / 84442.1106 s
agent0:                 episode reward: -0.1028,                 loss: nan
agent1:                 episode reward: 0.1028,                 loss: 0.1096
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2585s / 84692.3691 s
agent0:                 episode reward: -0.0247,                 loss: nan
agent1:                 episode reward: 0.0247,                 loss: 0.1096
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8163s / 84946.1854 s
agent0:                 episode reward: -0.6506,                 loss: nan
agent1:                 episode reward: 0.6506,                 loss: 0.1100
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0673s / 85195.2527 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.1085
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7733s / 85446.0260 s
agent0:                 episode reward: -0.3323,                 loss: nan
agent1:                 episode reward: 0.3323,                 loss: 0.1095
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1709s / 85695.1969 s
agent0:                 episode reward: -0.0535,                 loss: nan
agent1:                 episode reward: 0.0535,                 loss: 0.1087
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 233.2245s / 85928.4214 s
agent0:                 episode reward: -0.2586,                 loss: nan
agent1:                 episode reward: 0.2586,                 loss: 0.1097
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2382s / 86174.6596 s
agent0:                 episode reward: 0.0833,                 loss: nan
agent1:                 episode reward: -0.0833,                 loss: 0.1094
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5024s / 86424.1620 s
agent0:                 episode reward: -0.4636,                 loss: nan
agent1:                 episode reward: 0.4636,                 loss: 0.1080
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 258.5142s / 86682.6762 s
agent0:                 episode reward: -0.5952,                 loss: nan
agent1:                 episode reward: 0.5952,                 loss: 0.1086
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4791s / 86936.1553 s
agent0:                 episode reward: -0.3003,                 loss: nan
agent1:                 episode reward: 0.3003,                 loss: 0.1083
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.7693s / 87178.9246 s
agent0:                 episode reward: -0.5637,                 loss: nan
agent1:                 episode reward: 0.5637,                 loss: 0.1072
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4890s / 87431.4136 s
agent0:                 episode reward: -0.5909,                 loss: nan
agent1:                 episode reward: 0.5909,                 loss: 0.1079
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8866s / 87685.3002 s
agent0:                 episode reward: -0.2967,                 loss: nan
agent1:                 episode reward: 0.2967,                 loss: 0.1078
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0565s / 87936.3567 s
agent0:                 episode reward: -0.2437,                 loss: nan
agent1:                 episode reward: 0.2437,                 loss: 0.1092
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3389s / 88182.6956 s
agent0:                 episode reward: -0.0626,                 loss: nan
agent1:                 episode reward: 0.0626,                 loss: 0.1088
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.4419s / 88438.1375 s
agent0:                 episode reward: -0.4369,                 loss: nan
agent1:                 episode reward: 0.4369,                 loss: 0.1079
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6931s / 88685.8306 s
agent0:                 episode reward: 0.1094,                 loss: nan
agent1:                 episode reward: -0.1094,                 loss: 0.1089
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0856s / 88933.9162 s
agent0:                 episode reward: 0.1682,                 loss: nan
agent1:                 episode reward: -0.1682,                 loss: 0.1083
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9740s / 89186.8903 s
agent0:                 episode reward: -0.2013,                 loss: nan
agent1:                 episode reward: 0.2013,                 loss: 0.1095
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.5990s / 89436.4893 s
agent0:                 episode reward: -0.1254,                 loss: nan
agent1:                 episode reward: 0.1254,                 loss: 0.1091
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9056s / 89686.3948 s
agent0:                 episode reward: -0.1847,                 loss: nan
agent1:                 episode reward: 0.1847,                 loss: 0.1088
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1629s / 89927.5577 s
agent0:                 episode reward: -0.3447,                 loss: nan
agent1:                 episode reward: 0.3447,                 loss: 0.1084
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2669s / 90179.8245 s
agent0:                 episode reward: -0.4254,                 loss: nan
agent1:                 episode reward: 0.4254,                 loss: 0.1089
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0807s / 90434.9052 s
agent0:                 episode reward: -0.5402,                 loss: nan
agent1:                 episode reward: 0.5402,                 loss: 0.1085
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7228s / 90685.6280 s
agent0:                 episode reward: -0.5846,                 loss: nan
agent1:                 episode reward: 0.5846,                 loss: 0.1077
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3913s / 90934.0194 s
agent0:                 episode reward: -0.2793,                 loss: nan
agent1:                 episode reward: 0.2793,                 loss: 0.1096
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.8327s / 91188.8521 s
agent0:                 episode reward: -0.3210,                 loss: nan
agent1:                 episode reward: 0.3210,                 loss: 0.1053
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4890s / 91439.3411 s
agent0:                 episode reward: -0.2926,                 loss: nan
agent1:                 episode reward: 0.2926,                 loss: 0.1070
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.3402s / 91696.6813 s
agent0:                 episode reward: -0.3840,                 loss: nan
agent1:                 episode reward: 0.3840,                 loss: 0.1070
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3472s / 91947.0285 s
agent0:                 episode reward: -0.2838,                 loss: nan
agent1:                 episode reward: 0.2838,                 loss: 0.1088
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6869s / 92192.7154 s
agent0:                 episode reward: 0.1485,                 loss: nan
agent1:                 episode reward: -0.1485,                 loss: 0.1085
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2700s / 92437.9854 s
agent0:                 episode reward: -0.4045,                 loss: nan
agent1:                 episode reward: 0.4045,                 loss: 0.1080