2022-05-10 18:41:44.210098: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 18:41:44.210197: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 18:41:44.210204: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f7779c73128>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-3', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510161908_exploit_10000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510161908_exploit_10000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8201s / 0.8201 s
agent0:                 episode reward: 1.5174,                 loss: nan
agent1:                 episode reward: -1.5174,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0640s / 0.8840 s
agent0:                 episode reward: 1.5454,                 loss: nan
agent1:                 episode reward: -1.5454,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0703s / 0.9544 s
agent0:                 episode reward: 0.6552,                 loss: nan
agent1:                 episode reward: -0.6552,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0633s / 1.0177 s
agent0:                 episode reward: 0.6751,                 loss: nan
agent1:                 episode reward: -0.6751,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5967s / 1.6144 s
agent0:                 episode reward: 0.6425,                 loss: nan
agent1:                 episode reward: -0.6425,                 loss: 0.3785
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6960s / 2.3104 s
agent0:                 episode reward: 0.3711,                 loss: nan
agent1:                 episode reward: -0.3711,                 loss: 0.3545
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6846s / 2.9950 s
agent0:                 episode reward: 0.4339,                 loss: nan
agent1:                 episode reward: -0.4339,                 loss: 0.3404
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6889s / 3.6839 s
agent0:                 episode reward: 0.7340,                 loss: nan
agent1:                 episode reward: -0.7340,                 loss: 0.2712
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6946s / 4.3785 s
agent0:                 episode reward: 0.7451,                 loss: nan
agent1:                 episode reward: -0.7451,                 loss: 0.2426
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7010s / 5.0796 s
agent0:                 episode reward: 0.7114,                 loss: nan
agent1:                 episode reward: -0.7114,                 loss: 0.3254
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7065s / 5.7861 s
agent0:                 episode reward: 0.0990,                 loss: nan
agent1:                 episode reward: -0.0990,                 loss: 0.3274
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6999s / 6.4859 s
agent0:                 episode reward: 0.8830,                 loss: nan
agent1:                 episode reward: -0.8830,                 loss: 0.3267
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7284s / 7.2143 s
agent0:                 episode reward: 0.7484,                 loss: nan
agent1:                 episode reward: -0.7484,                 loss: 0.3240
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7163s / 7.9306 s
agent0:                 episode reward: 0.6334,                 loss: nan
agent1:                 episode reward: -0.6334,                 loss: 0.3205
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7011s / 8.6317 s
agent0:                 episode reward: 0.4650,                 loss: nan
agent1:                 episode reward: -0.4650,                 loss: 0.3320
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7074s / 9.3391 s
agent0:                 episode reward: -0.1549,                 loss: nan
agent1:                 episode reward: 0.1549,                 loss: 0.3145
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7530s / 10.0920 s
agent0:                 episode reward: 0.9344,                 loss: nan
agent1:                 episode reward: -0.9344,                 loss: 0.3083
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7350s / 10.8271 s
agent0:                 episode reward: 0.7949,                 loss: nan
agent1:                 episode reward: -0.7949,                 loss: 0.3046
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7130s / 11.5401 s
agent0:                 episode reward: 0.0270,                 loss: nan
agent1:                 episode reward: -0.0270,                 loss: 0.3010
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7084s / 12.2485 s
agent0:                 episode reward: 0.6632,                 loss: nan
agent1:                 episode reward: -0.6632,                 loss: 0.2545
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7219s / 12.9705 s
agent0:                 episode reward: 0.3517,                 loss: nan
agent1:                 episode reward: -0.3517,                 loss: 0.2315
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7184s / 13.6888 s
agent0:                 episode reward: 1.3496,                 loss: nan
agent1:                 episode reward: -1.3496,                 loss: 0.2262
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7406s / 14.4294 s
agent0:                 episode reward: 0.3555,                 loss: nan
agent1:                 episode reward: -0.3555,                 loss: 0.2242
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7375s / 15.1669 s
agent0:                 episode reward: 0.4515,                 loss: nan
agent1:                 episode reward: -0.4515,                 loss: 0.2211
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7351s / 15.9020 s
agent0:                 episode reward: 0.6901,                 loss: nan
agent1:                 episode reward: -0.6901,                 loss: 0.1830
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7301s / 16.6321 s
agent0:                 episode reward: 0.4783,                 loss: nan
agent1:                 episode reward: -0.4783,                 loss: 0.1683
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7349s / 17.3670 s
agent0:                 episode reward: 0.8841,                 loss: nan
agent1:                 episode reward: -0.8841,                 loss: 0.1667
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7772s / 18.1442 s
agent0:                 episode reward: 1.2101,                 loss: nan
agent1:                 episode reward: -1.2101,                 loss: 0.1648
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7589s / 18.9031 s
agent0:                 episode reward: 0.2854,                 loss: nan
agent1:                 episode reward: -0.2854,                 loss: 0.1625
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7394s / 19.6425 s
agent0:                 episode reward: 0.5422,                 loss: nan
agent1:                 episode reward: -0.5422,                 loss: 0.1453
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8255s / 20.4680 s
agent0:                 episode reward: 0.1214,                 loss: nan
agent1:                 episode reward: -0.1214,                 loss: 0.1349
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7376s / 21.2056 s
agent0:                 episode reward: 1.1381,                 loss: nan
agent1:                 episode reward: -1.1381,                 loss: 0.1345
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7476s / 21.9533 s
agent0:                 episode reward: 0.5753,                 loss: nan
agent1:                 episode reward: -0.5753,                 loss: 0.1340
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7891s / 22.7424 s
agent0:                 episode reward: 0.8194,                 loss: nan
agent1:                 episode reward: -0.8194,                 loss: 0.1340
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7486s / 23.4910 s
agent0:                 episode reward: 0.6193,                 loss: nan
agent1:                 episode reward: -0.6193,                 loss: 0.1528
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7503s / 24.2413 s
agent0:                 episode reward: 1.0379,                 loss: nan
agent1:                 episode reward: -1.0379,                 loss: 0.1516
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7504s / 24.9917 s
agent0:                 episode reward: 1.0702,                 loss: nan
agent1:                 episode reward: -1.0702,                 loss: 0.1488
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7944s / 25.7862 s
agent0:                 episode reward: 0.3382,                 loss: nan
agent1:                 episode reward: -0.3382,                 loss: 0.1470
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7618s / 26.5479 s
agent0:                 episode reward: -0.1304,                 loss: nan
agent1:                 episode reward: 0.1304,                 loss: 0.1471
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7573s / 27.3052 s
agent0:                 episode reward: -0.2806,                 loss: nan
agent1:                 episode reward: 0.2806,                 loss: 0.1858
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7624s / 28.0677 s
agent0:                 episode reward: 0.4846,                 loss: nan
agent1:                 episode reward: -0.4846,                 loss: 0.1865
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7783s / 28.8460 s
agent0:                 episode reward: 0.5730,                 loss: nan
agent1:                 episode reward: -0.5730,                 loss: 0.1840
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7694s / 29.6153 s
agent0:                 episode reward: 0.8288,                 loss: nan
agent1:                 episode reward: -0.8288,                 loss: 0.1827
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8114s / 30.4268 s
agent0:                 episode reward: 1.1199,                 loss: nan
agent1:                 episode reward: -1.1199,                 loss: 0.1811
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8536s / 31.2804 s
agent0:                 episode reward: 0.5147,                 loss: nan
agent1:                 episode reward: -0.5147,                 loss: 0.2260
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7825s / 32.0629 s
agent0:                 episode reward: 0.1826,                 loss: nan
agent1:                 episode reward: -0.1826,                 loss: 0.2276
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7795s / 32.8425 s
agent0:                 episode reward: 0.8552,                 loss: nan
agent1:                 episode reward: -0.8552,                 loss: 0.2271
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7791s / 33.6216 s
agent0:                 episode reward: 0.1953,                 loss: nan
agent1:                 episode reward: -0.1953,                 loss: 0.2245
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7783s / 34.3998 s
agent0:                 episode reward: -0.1436,                 loss: nan
agent1:                 episode reward: 0.1436,                 loss: 0.2231
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7947s / 35.1945 s
agent0:                 episode reward: 0.3261,                 loss: nan
agent1:                 episode reward: -0.3261,                 loss: 0.2759
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8090s / 36.0036 s
agent0:                 episode reward: 0.6124,                 loss: nan
agent1:                 episode reward: -0.6124,                 loss: 0.2783
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7822s / 36.7857 s
agent0:                 episode reward: 0.7960,                 loss: nan
agent1:                 episode reward: -0.7960,                 loss: 0.2771
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7918s / 37.5775 s
agent0:                 episode reward: -0.3705,                 loss: nan
agent1:                 episode reward: 0.3705,                 loss: 0.2736
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7954s / 38.3729 s
agent0:                 episode reward: 0.5307,                 loss: nan
agent1:                 episode reward: -0.5307,                 loss: 0.2698
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8225s / 39.1955 s
agent0:                 episode reward: 0.8839,                 loss: nan
agent1:                 episode reward: -0.8839,                 loss: 0.2869
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8070s / 40.0024 s
agent0:                 episode reward: 0.4715,                 loss: nan
agent1:                 episode reward: -0.4715,                 loss: 0.2816
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8772s / 40.8796 s
agent0:                 episode reward: 0.7170,                 loss: nan
agent1:                 episode reward: -0.7170,                 loss: 0.2784
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8301s / 41.7097 s
agent0:                 episode reward: -0.2077,                 loss: nan
agent1:                 episode reward: 0.2077,                 loss: 0.2765
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8132s / 42.5229 s
agent0:                 episode reward: -0.2303,                 loss: nan
agent1:                 episode reward: 0.2303,                 loss: 0.2729
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8072s / 43.3301 s
agent0:                 episode reward: 0.5494,                 loss: nan
agent1:                 episode reward: -0.5494,                 loss: 0.2632
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8238s / 44.1539 s
agent0:                 episode reward: 0.3795,                 loss: nan
agent1:                 episode reward: -0.3795,                 loss: 0.2543
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8168s / 44.9707 s
agent0:                 episode reward: 0.7315,                 loss: nan
agent1:                 episode reward: -0.7315,                 loss: 0.2523
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8233s / 45.7941 s
agent0:                 episode reward: 0.3359,                 loss: nan
agent1:                 episode reward: -0.3359,                 loss: 0.2522
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8183s / 46.6123 s
agent0:                 episode reward: 0.5924,                 loss: nan
agent1:                 episode reward: -0.5924,                 loss: 0.2513
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8459s / 47.4583 s
agent0:                 episode reward: 0.1679,                 loss: nan
agent1:                 episode reward: -0.1679,                 loss: 0.1994
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8118s / 48.2701 s
agent0:                 episode reward: -0.0875,                 loss: nan
agent1:                 episode reward: 0.0875,                 loss: 0.1827
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8615s / 49.1316 s
agent0:                 episode reward: 0.6570,                 loss: nan
agent1:                 episode reward: -0.6570,                 loss: 0.1838
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8316s / 49.9632 s
agent0:                 episode reward: 0.2528,                 loss: nan
agent1:                 episode reward: -0.2528,                 loss: 0.1839
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8358s / 50.7989 s
agent0:                 episode reward: 0.0563,                 loss: nan
agent1:                 episode reward: -0.0563,                 loss: 0.1840
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9034s / 51.7023 s
agent0:                 episode reward: 0.2501,                 loss: nan
agent1:                 episode reward: -0.2501,                 loss: 0.1347
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8872s / 52.5895 s
agent0:                 episode reward: 0.3363,                 loss: nan
agent1:                 episode reward: -0.3363,                 loss: 0.1211
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8972s / 53.4867 s
agent0:                 episode reward: 0.7762,                 loss: nan
agent1:                 episode reward: -0.7762,                 loss: 0.1202
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8233s / 54.3100 s
agent0:                 episode reward: 0.6059,                 loss: nan
agent1:                 episode reward: -0.6059,                 loss: 0.1196
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8306s / 55.1406 s
agent0:                 episode reward: 0.6823,                 loss: nan
agent1:                 episode reward: -0.6823,                 loss: 0.1179
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9306s / 56.0712 s
agent0:                 episode reward: 1.1817,                 loss: nan
agent1:                 episode reward: -1.1817,                 loss: 0.1211
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8637s / 56.9349 s
agent0:                 episode reward: -0.0601,                 loss: nan
agent1:                 episode reward: 0.0601,                 loss: 0.1181
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8457s / 57.7806 s
agent0:                 episode reward: -0.2468,                 loss: nan
agent1:                 episode reward: 0.2468,                 loss: 0.1194
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8719s / 58.6525 s
agent0:                 episode reward: 0.1233,                 loss: nan
agent1:                 episode reward: -0.1233,                 loss: 0.1184
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8521s / 59.5046 s
agent0:                 episode reward: 0.4457,                 loss: nan
agent1:                 episode reward: -0.4457,                 loss: 0.1185
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8524s / 60.3569 s
agent0:                 episode reward: 0.4906,                 loss: nan
agent1:                 episode reward: -0.4906,                 loss: 0.1464
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8432s / 61.2001 s
agent0:                 episode reward: -0.0321,                 loss: nan
agent1:                 episode reward: 0.0321,                 loss: 0.1478
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9379s / 62.1380 s
agent0:                 episode reward: 0.3860,                 loss: nan
agent1:                 episode reward: -0.3860,                 loss: 0.1482
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8462s / 62.9841 s
agent0:                 episode reward: 1.1145,                 loss: nan
agent1:                 episode reward: -1.1145,                 loss: 0.1469
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8758s / 63.8600 s
agent0:                 episode reward: 0.7556,                 loss: nan
agent1:                 episode reward: -0.7556,                 loss: 0.1453
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8904s / 64.7504 s
agent0:                 episode reward: -0.5946,                 loss: nan
agent1:                 episode reward: 0.5946,                 loss: 0.1655
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8773s / 65.6277 s
agent0:                 episode reward: 0.1796,                 loss: nan
agent1:                 episode reward: -0.1796,                 loss: 0.1673
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8784s / 66.5061 s
agent0:                 episode reward: 0.4224,                 loss: nan
agent1:                 episode reward: -0.4224,                 loss: 0.1656
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8699s / 67.3760 s
agent0:                 episode reward: 0.3294,                 loss: nan
agent1:                 episode reward: -0.3294,                 loss: 0.1665
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8724s / 68.2484 s
agent0:                 episode reward: 0.5619,                 loss: nan
agent1:                 episode reward: -0.5619,                 loss: 0.1672
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8798s / 69.1282 s
agent0:                 episode reward: 0.5165,                 loss: nan
agent1:                 episode reward: -0.5165,                 loss: 0.1827
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8875s / 70.0157 s
agent0:                 episode reward: 0.3861,                 loss: nan
agent1:                 episode reward: -0.3861,                 loss: 0.1839
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8951s / 70.9108 s
agent0:                 episode reward: 0.4624,                 loss: nan
agent1:                 episode reward: -0.4624,                 loss: 0.1834
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9367s / 71.8475 s
agent0:                 episode reward: 0.7341,                 loss: nan
agent1:                 episode reward: -0.7341,                 loss: 0.1826
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8763s / 72.7238 s
agent0:                 episode reward: 1.2372,                 loss: nan
agent1:                 episode reward: -1.2372,                 loss: 0.1833
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9163s / 73.6401 s
agent0:                 episode reward: -0.1005,                 loss: nan
agent1:                 episode reward: 0.1005,                 loss: 0.2137
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9649s / 74.6050 s
agent0:                 episode reward: 0.5594,                 loss: nan
agent1:                 episode reward: -0.5594,                 loss: 0.2176
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9115s / 75.5166 s
agent0:                 episode reward: 0.4906,                 loss: nan
agent1:                 episode reward: -0.4906,                 loss: 0.2160
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9200s / 76.4366 s
agent0:                 episode reward: 0.5000,                 loss: nan
agent1:                 episode reward: -0.5000,                 loss: 0.2158
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8962s / 77.3328 s
agent0:                 episode reward: 0.6696,                 loss: nan
agent1:                 episode reward: -0.6696,                 loss: 0.2124
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8810s / 78.2137 s
agent0:                 episode reward: 0.0806,                 loss: nan
agent1:                 episode reward: -0.0806,                 loss: 0.2674
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8964s / 79.1101 s
agent0:                 episode reward: 0.4840,                 loss: nan
agent1:                 episode reward: -0.4840,                 loss: 0.2726
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9221s / 80.0322 s
agent0:                 episode reward: 0.8863,                 loss: nan
agent1:                 episode reward: -0.8863,                 loss: 0.2717
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9062s / 80.9385 s
agent0:                 episode reward: 0.3515,                 loss: nan
agent1:                 episode reward: -0.3515,                 loss: 0.2715
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9496s / 81.8881 s
agent0:                 episode reward: 0.6727,                 loss: nan
agent1:                 episode reward: -0.6727,                 loss: 0.2682
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9188s / 82.8069 s
agent0:                 episode reward: 0.4722,                 loss: nan
agent1:                 episode reward: -0.4722,                 loss: 0.2977
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9102s / 83.7171 s
agent0:                 episode reward: 1.3699,                 loss: nan
agent1:                 episode reward: -1.3699,                 loss: 0.2942
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9041s / 84.6213 s
agent0:                 episode reward: 0.0762,                 loss: nan
agent1:                 episode reward: -0.0762,                 loss: 0.2949
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9246s / 85.5459 s
agent0:                 episode reward: -0.0811,                 loss: nan
agent1:                 episode reward: 0.0811,                 loss: 0.2910
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9334s / 86.4793 s
agent0:                 episode reward: -0.7617,                 loss: nan
agent1:                 episode reward: 0.7617,                 loss: 0.2930
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9271s / 87.4065 s
agent0:                 episode reward: 0.0327,                 loss: nan
agent1:                 episode reward: -0.0327,                 loss: 0.2311
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9466s / 88.3531 s
agent0:                 episode reward: 0.3523,                 loss: nan
agent1:                 episode reward: -0.3523,                 loss: 0.2167
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9947s / 89.3477 s
agent0:                 episode reward: 0.1958,                 loss: nan
agent1:                 episode reward: -0.1958,                 loss: 0.2170
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9340s / 90.2817 s
agent0:                 episode reward: 0.3060,                 loss: nan
agent1:                 episode reward: -0.3060,                 loss: 0.2164
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9344s / 91.2161 s
agent0:                 episode reward: 0.2255,                 loss: nan
agent1:                 episode reward: -0.2255,                 loss: 0.2162
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9936s / 92.2097 s
agent0:                 episode reward: 0.6930,                 loss: nan
agent1:                 episode reward: -0.6930,                 loss: 0.1542
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9396s / 93.1494 s
agent0:                 episode reward: 0.0855,                 loss: nan
agent1:                 episode reward: -0.0855,                 loss: 0.1354
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9347s / 94.0841 s
agent0:                 episode reward: 0.5088,                 loss: nan
agent1:                 episode reward: -0.5088,                 loss: 0.1368
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9351s / 95.0192 s
agent0:                 episode reward: -0.4974,                 loss: nan
agent1:                 episode reward: 0.4974,                 loss: 0.1335
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9490s / 95.9682 s
agent0:                 episode reward: -0.3861,                 loss: nan
agent1:                 episode reward: 0.3861,                 loss: 0.1362
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9700s / 96.9383 s
agent0:                 episode reward: 0.3366,                 loss: nan
agent1:                 episode reward: -0.3366,                 loss: 0.1232
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9425s / 97.8808 s
agent0:                 episode reward: 0.6328,                 loss: nan
agent1:                 episode reward: -0.6328,                 loss: 0.1210
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9728s / 98.8536 s
agent0:                 episode reward: -0.0996,                 loss: nan
agent1:                 episode reward: 0.0996,                 loss: 0.1197
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9500s / 99.8036 s
agent0:                 episode reward: 0.4230,                 loss: nan
agent1:                 episode reward: -0.4230,                 loss: 0.1197
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9512s / 100.7547 s
agent0:                 episode reward: 0.0625,                 loss: nan
agent1:                 episode reward: -0.0625,                 loss: 0.1203
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9853s / 101.7400 s
agent0:                 episode reward: -0.1764,                 loss: nan
agent1:                 episode reward: 0.1764,                 loss: 0.1295
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0134s / 102.7533 s
agent0:                 episode reward: 0.0423,                 loss: nan
agent1:                 episode reward: -0.0423,                 loss: 0.1288
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9502s / 103.7036 s
agent0:                 episode reward: 0.4486,                 loss: nan
agent1:                 episode reward: -0.4486,                 loss: 0.1284
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9611s / 104.6647 s
agent0:                 episode reward: -0.2769,                 loss: nan
agent1:                 episode reward: 0.2769,                 loss: 0.1298
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9783s / 105.6430 s
agent0:                 episode reward: 0.6168,                 loss: nan
agent1:                 episode reward: -0.6168,                 loss: 0.1292
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9658s / 106.6088 s
agent0:                 episode reward: -0.3081,                 loss: nan
agent1:                 episode reward: 0.3081,                 loss: 0.1355
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9728s / 107.5816 s
agent0:                 episode reward: 0.4170,                 loss: nan
agent1:                 episode reward: -0.4170,                 loss: 0.1347
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9642s / 108.5457 s
agent0:                 episode reward: 0.0524,                 loss: nan
agent1:                 episode reward: -0.0524,                 loss: 0.1345
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9548s / 109.5006 s
agent0:                 episode reward: 1.0017,                 loss: nan
agent1:                 episode reward: -1.0017,                 loss: 0.1363
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9895s / 110.4900 s
agent0:                 episode reward: -0.1503,                 loss: nan
agent1:                 episode reward: 0.1503,                 loss: 0.1346
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9747s / 111.4647 s
agent0:                 episode reward: 0.4719,                 loss: nan
agent1:                 episode reward: -0.4719,                 loss: 0.1658
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9863s / 112.4510 s
agent0:                 episode reward: 0.4628,                 loss: nan
agent1:                 episode reward: -0.4628,                 loss: 0.1669
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0346s / 113.4857 s
agent0:                 episode reward: 0.2951,                 loss: nan
agent1:                 episode reward: -0.2951,                 loss: 0.1705
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9792s / 114.4648 s
agent0:                 episode reward: 0.0570,                 loss: nan
agent1:                 episode reward: -0.0570,                 loss: 0.1699
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9834s / 115.4482 s
agent0:                 episode reward: -0.5693,                 loss: nan
agent1:                 episode reward: 0.5693,                 loss: 0.1703
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0246s / 116.4728 s
agent0:                 episode reward: 0.3797,                 loss: nan
agent1:                 episode reward: -0.3797,                 loss: 0.2152
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9631s / 117.4360 s
agent0:                 episode reward: 0.5345,                 loss: nan
agent1:                 episode reward: -0.5345,                 loss: 0.2211
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9702s / 118.4062 s
agent0:                 episode reward: 0.8421,                 loss: nan
agent1:                 episode reward: -0.8421,                 loss: 0.2196
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9967s / 119.4028 s
agent0:                 episode reward: 0.7921,                 loss: nan
agent1:                 episode reward: -0.7921,                 loss: 0.2190
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9746s / 120.3774 s
agent0:                 episode reward: -0.7589,                 loss: nan
agent1:                 episode reward: 0.7589,                 loss: 0.2206
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9797s / 121.3571 s
agent0:                 episode reward: 0.5852,                 loss: nan
agent1:                 episode reward: -0.5852,                 loss: 0.2621
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0329s / 122.3900 s
agent0:                 episode reward: 0.1674,                 loss: nan
agent1:                 episode reward: -0.1674,                 loss: 0.2669
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0448s / 123.4348 s
agent0:                 episode reward: 0.0220,                 loss: nan
agent1:                 episode reward: -0.0220,                 loss: 0.2664
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0024s / 124.4372 s
agent0:                 episode reward: 0.2869,                 loss: nan
agent1:                 episode reward: -0.2869,                 loss: 0.2643
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0102s / 125.4474 s
agent0:                 episode reward: -0.1267,                 loss: nan
agent1:                 episode reward: 0.1267,                 loss: 0.2663
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9936s / 126.4410 s
agent0:                 episode reward: 0.6287,                 loss: nan
agent1:                 episode reward: -0.6287,                 loss: 0.2671
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9954s / 127.4363 s
agent0:                 episode reward: -0.0270,                 loss: nan
agent1:                 episode reward: 0.0270,                 loss: 0.2661
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0036s / 128.4400 s
agent0:                 episode reward: 0.2143,                 loss: nan
agent1:                 episode reward: -0.2143,                 loss: 0.2643
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9901s / 129.4301 s
agent0:                 episode reward: 0.6838,                 loss: nan
agent1:                 episode reward: -0.6838,                 loss: 0.2658
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0187s / 130.4488 s
agent0:                 episode reward: -0.1126,                 loss: nan
agent1:                 episode reward: 0.1126,                 loss: 0.2621
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0160s / 131.4648 s
agent0:                 episode reward: 1.2109,                 loss: nan
agent1:                 episode reward: -1.2109,                 loss: 0.2559
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0050s / 132.4698 s
agent0:                 episode reward: 0.0796,                 loss: nan
agent1:                 episode reward: -0.0796,                 loss: 0.2515
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0630s / 133.5328 s
agent0:                 episode reward: -0.7323,                 loss: nan
agent1:                 episode reward: 0.7323,                 loss: 0.2496
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0148s / 134.5476 s
agent0:                 episode reward: 0.7517,                 loss: nan
agent1:                 episode reward: -0.7517,                 loss: 0.2476
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0142s / 135.5618 s
agent0:                 episode reward: 0.0331,                 loss: nan
agent1:                 episode reward: -0.0331,                 loss: 0.2485
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0308s / 136.5927 s
agent0:                 episode reward: 0.2270,                 loss: nan
agent1:                 episode reward: -0.2270,                 loss: 0.1699
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0390s / 137.6316 s
agent0:                 episode reward: 0.2712,                 loss: nan
agent1:                 episode reward: -0.2712,                 loss: 0.1482
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0442s / 138.6758 s
agent0:                 episode reward: -0.0987,                 loss: nan
agent1:                 episode reward: 0.0987,                 loss: 0.1468
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0193s / 139.6952 s
agent0:                 episode reward: 0.2852,                 loss: nan
agent1:                 episode reward: -0.2852,                 loss: 0.1457
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0268s / 140.7220 s
agent0:                 episode reward: -0.0936,                 loss: nan
agent1:                 episode reward: 0.0936,                 loss: 0.1469
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0389s / 141.7609 s
agent0:                 episode reward: 0.2518,                 loss: nan
agent1:                 episode reward: -0.2518,                 loss: 0.1367
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0413s / 142.8021 s
agent0:                 episode reward: -0.0511,                 loss: nan
agent1:                 episode reward: 0.0511,                 loss: 0.1317
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0948s / 143.8969 s
agent0:                 episode reward: -0.4943,                 loss: nan
agent1:                 episode reward: 0.4943,                 loss: 0.1312
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0400s / 144.9369 s
agent0:                 episode reward: 0.0716,                 loss: nan
agent1:                 episode reward: -0.0716,                 loss: 0.1297
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0449s / 145.9818 s
agent0:                 episode reward: -0.1367,                 loss: nan
agent1:                 episode reward: 0.1367,                 loss: 0.1291
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1069s / 147.0887 s
agent0:                 episode reward: -0.3302,                 loss: nan
agent1:                 episode reward: 0.3302,                 loss: 0.1382
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0616s / 148.1503 s
agent0:                 episode reward: 0.4607,                 loss: nan
agent1:                 episode reward: -0.4607,                 loss: 0.1395
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0467s / 149.1970 s
agent0:                 episode reward: 0.5731,                 loss: nan
agent1:                 episode reward: -0.5731,                 loss: 0.1377
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0472s / 150.2442 s
agent0:                 episode reward: -0.8175,                 loss: nan
agent1:                 episode reward: 0.8175,                 loss: 0.1370
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0545s / 151.2987 s
agent0:                 episode reward: -0.2306,                 loss: nan
agent1:                 episode reward: 0.2306,                 loss: 0.1383
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0681s / 152.3668 s
agent0:                 episode reward: 0.3507,                 loss: nan
agent1:                 episode reward: -0.3507,                 loss: 0.1652
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1094s / 153.4762 s
agent0:                 episode reward: -0.3865,                 loss: nan
agent1:                 episode reward: 0.3865,                 loss: 0.1671
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0639s / 154.5400 s
agent0:                 episode reward: -0.9487,                 loss: nan
agent1:                 episode reward: 0.9487,                 loss: 0.1673
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0732s / 155.6132 s
agent0:                 episode reward: -0.6579,                 loss: nan
agent1:                 episode reward: 0.6579,                 loss: 0.1672
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0449s / 156.6581 s
agent0:                 episode reward: -0.0750,                 loss: nan
agent1:                 episode reward: 0.0750,                 loss: 0.1661
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0713s / 157.7293 s
agent0:                 episode reward: -0.0325,                 loss: nan
agent1:                 episode reward: 0.0325,                 loss: 0.1903
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0818s / 158.8111 s
agent0:                 episode reward: 0.0822,                 loss: nan
agent1:                 episode reward: -0.0822,                 loss: 0.1956
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0767s / 159.8879 s
agent0:                 episode reward: 0.3445,                 loss: nan
agent1:                 episode reward: -0.3445,                 loss: 0.1955
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0688s / 160.9566 s
agent0:                 episode reward: 0.2480,                 loss: nan
agent1:                 episode reward: -0.2480,                 loss: 0.1951
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0883s / 162.0450 s
agent0:                 episode reward: -0.0279,                 loss: nan
agent1:                 episode reward: 0.0279,                 loss: 0.1944
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0967s / 163.1416 s
agent0:                 episode reward: -0.4532,                 loss: nan
agent1:                 episode reward: 0.4532,                 loss: 0.2307
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1306s / 164.2722 s
agent0:                 episode reward: 0.3977,                 loss: nan
agent1:                 episode reward: -0.3977,                 loss: 0.2352
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0856s / 165.3578 s
agent0:                 episode reward: -0.1866,                 loss: nan
agent1:                 episode reward: 0.1866,                 loss: 0.2359
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0855s / 166.4433 s
agent0:                 episode reward: -0.5630,                 loss: nan
agent1:                 episode reward: 0.5630,                 loss: 0.2376
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1154s / 167.5587 s
agent0:                 episode reward: -0.6069,                 loss: nan
agent1:                 episode reward: 0.6069,                 loss: 0.2358
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0946s / 168.6533 s
agent0:                 episode reward: -0.1568,                 loss: nan
agent1:                 episode reward: 0.1568,                 loss: 0.2596
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0878s / 169.7412 s
agent0:                 episode reward: 0.2027,                 loss: nan
agent1:                 episode reward: -0.2027,                 loss: 0.2588
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1004s / 170.8416 s
agent0:                 episode reward: 0.0565,                 loss: nan
agent1:                 episode reward: -0.0565,                 loss: 0.2563
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1118s / 171.9534 s
agent0:                 episode reward: -0.2654,                 loss: nan
agent1:                 episode reward: 0.2654,                 loss: 0.2559
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0967s / 173.0501 s
agent0:                 episode reward: 0.0590,                 loss: nan
agent1:                 episode reward: -0.0590,                 loss: 0.2560
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1666s / 174.2167 s
agent0:                 episode reward: 0.2730,                 loss: nan
agent1:                 episode reward: -0.2730,                 loss: 0.2658
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0973s / 175.3140 s
agent0:                 episode reward: 0.2049,                 loss: nan
agent1:                 episode reward: -0.2049,                 loss: 0.2600
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1207s / 176.4348 s
agent0:                 episode reward: -0.0289,                 loss: nan
agent1:                 episode reward: 0.0289,                 loss: 0.2608
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1154s / 177.5501 s
agent0:                 episode reward: -0.2125,                 loss: nan
agent1:                 episode reward: 0.2125,                 loss: 0.2583
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0930s / 178.6431 s
agent0:                 episode reward: -0.0092,                 loss: nan
agent1:                 episode reward: 0.0092,                 loss: 0.2565
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1229s / 179.7660 s
agent0:                 episode reward: -0.3904,                 loss: nan
agent1:                 episode reward: 0.3904,                 loss: 0.2093
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0889s / 180.8550 s
agent0:                 episode reward: 0.0332,                 loss: nan
agent1:                 episode reward: -0.0332,                 loss: 0.1971
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0902s / 181.9451 s
agent0:                 episode reward: 0.0161,                 loss: nan
agent1:                 episode reward: -0.0161,                 loss: 0.1970
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1249s / 183.0700 s
agent0:                 episode reward: -0.5761,                 loss: nan
agent1:                 episode reward: 0.5761,                 loss: 0.1972
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1191s / 184.1891 s
agent0:                 episode reward: -0.4130,                 loss: nan
agent1:                 episode reward: 0.4130,                 loss: 0.1960
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1665s / 185.3556 s
agent0:                 episode reward: -0.0794,                 loss: nan
agent1:                 episode reward: 0.0794,                 loss: 0.1604
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1500s / 186.5055 s
agent0:                 episode reward: -0.4156,                 loss: nan
agent1:                 episode reward: 0.4156,                 loss: 0.1501
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1373s / 187.6428 s
agent0:                 episode reward: 0.1876,                 loss: nan
agent1:                 episode reward: -0.1876,                 loss: 0.1488
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1402s / 188.7830 s
agent0:                 episode reward: 0.2089,                 loss: nan
agent1:                 episode reward: -0.2089,                 loss: 0.1477
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1258s / 189.9088 s
agent0:                 episode reward: -0.9255,                 loss: nan
agent1:                 episode reward: 0.9255,                 loss: 0.1469
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1314s / 191.0402 s
agent0:                 episode reward: 0.3722,                 loss: nan
agent1:                 episode reward: -0.3722,                 loss: 0.1458
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1244s / 192.1646 s
agent0:                 episode reward: -0.2230,                 loss: nan
agent1:                 episode reward: 0.2230,                 loss: 0.1401
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1399s / 193.3045 s
agent0:                 episode reward: 0.3495,                 loss: nan
agent1:                 episode reward: -0.3495,                 loss: 0.1391
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1473s / 194.4518 s
agent0:                 episode reward: 0.6783,                 loss: nan
agent1:                 episode reward: -0.6783,                 loss: 0.1366
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1915s / 195.6434 s
agent0:                 episode reward: -0.0088,                 loss: nan
agent1:                 episode reward: 0.0088,                 loss: 0.1364
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1673s / 196.8107 s
agent0:                 episode reward: 0.1365,                 loss: nan
agent1:                 episode reward: -0.1365,                 loss: 0.1278
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1839s / 197.9946 s
agent0:                 episode reward: -0.2276,                 loss: nan
agent1:                 episode reward: 0.2276,                 loss: 0.1207
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1311s / 199.1257 s
agent0:                 episode reward: -0.3736,                 loss: nan
agent1:                 episode reward: 0.3736,                 loss: 0.1227
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1382s / 200.2639 s
agent0:                 episode reward: -0.3147,                 loss: nan
agent1:                 episode reward: 0.3147,                 loss: 0.1217
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1568s / 201.4207 s
agent0:                 episode reward: -0.7060,                 loss: nan
agent1:                 episode reward: 0.7060,                 loss: 0.1220
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1493s / 202.5700 s
agent0:                 episode reward: 0.2521,                 loss: nan
agent1:                 episode reward: -0.2521,                 loss: 0.1507
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1556s / 203.7256 s
agent0:                 episode reward: -0.2687,                 loss: nan
agent1:                 episode reward: 0.2687,                 loss: 0.1540
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2265s / 204.9522 s
agent0:                 episode reward: -0.5609,                 loss: nan
agent1:                 episode reward: 0.5609,                 loss: 0.1535
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1514s / 206.1035 s
agent0:                 episode reward: -0.1826,                 loss: nan
agent1:                 episode reward: 0.1826,                 loss: 0.1516
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1528s / 207.2563 s
agent0:                 episode reward: -0.2174,                 loss: nan
agent1:                 episode reward: 0.2174,                 loss: 0.1535
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1689s / 208.4252 s
agent0:                 episode reward: -0.7227,                 loss: nan
agent1:                 episode reward: 0.7227,                 loss: 0.1874
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1735s / 209.5987 s
agent0:                 episode reward: -0.4402,                 loss: nan
agent1:                 episode reward: 0.4402,                 loss: 0.1950
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1722s / 210.7709 s
agent0:                 episode reward: 0.6417,                 loss: nan
agent1:                 episode reward: -0.6417,                 loss: 0.1973
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1526s / 211.9235 s
agent0:                 episode reward: 0.0130,                 loss: nan
agent1:                 episode reward: -0.0130,                 loss: 0.1945
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1872s / 213.1107 s
agent0:                 episode reward: -0.1394,                 loss: nan
agent1:                 episode reward: 0.1394,                 loss: 0.1937
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1719s / 214.2825 s
agent0:                 episode reward: -0.2437,                 loss: nan
agent1:                 episode reward: 0.2437,                 loss: 0.2521
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2243s / 215.5068 s
agent0:                 episode reward: -0.1718,                 loss: nan
agent1:                 episode reward: 0.1718,                 loss: 0.2580
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1731s / 216.6799 s
agent0:                 episode reward: 0.2993,                 loss: nan
agent1:                 episode reward: -0.2993,                 loss: 0.2556
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1754s / 217.8552 s
agent0:                 episode reward: -0.2602,                 loss: nan
agent1:                 episode reward: 0.2602,                 loss: 0.2562
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1777s / 219.0330 s
agent0:                 episode reward: 0.0137,                 loss: nan
agent1:                 episode reward: -0.0137,                 loss: 0.2561
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1769s / 220.2099 s
agent0:                 episode reward: -0.0820,                 loss: nan
agent1:                 episode reward: 0.0820,                 loss: 0.2628
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2043s / 221.4142 s
agent0:                 episode reward: -0.2362,                 loss: nan
agent1:                 episode reward: 0.2362,                 loss: 0.2615
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2263s / 222.6405 s
agent0:                 episode reward: -0.8264,                 loss: nan
agent1:                 episode reward: 0.8264,                 loss: 0.2616
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1887s / 223.8292 s
agent0:                 episode reward: -0.0904,                 loss: nan
agent1:                 episode reward: 0.0904,                 loss: 0.2624
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2034s / 225.0326 s
agent0:                 episode reward: -0.0397,                 loss: nan
agent1:                 episode reward: 0.0397,                 loss: 0.2620
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2647s / 226.2973 s
agent0:                 episode reward: -0.4191,                 loss: nan
agent1:                 episode reward: 0.4191,                 loss: 0.2402
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1991s / 227.4963 s
agent0:                 episode reward: -1.1229,                 loss: nan
agent1:                 episode reward: 1.1229,                 loss: 0.2343
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2451s / 228.7415 s
agent0:                 episode reward: 0.1531,                 loss: nan
agent1:                 episode reward: -0.1531,                 loss: 0.2348
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2258s / 229.9672 s
agent0:                 episode reward: -0.2172,                 loss: nan
agent1:                 episode reward: 0.2172,                 loss: 0.2349
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2232s / 231.1904 s
agent0:                 episode reward: -0.7760,                 loss: nan
agent1:                 episode reward: 0.7760,                 loss: 0.2355
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2124s / 232.4029 s
agent0:                 episode reward: -0.1099,                 loss: nan
agent1:                 episode reward: 0.1099,                 loss: 0.1858
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2245s / 233.6274 s
agent0:                 episode reward: -0.1728,                 loss: nan
agent1:                 episode reward: 0.1728,                 loss: 0.1747
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2247s / 234.8521 s
agent0:                 episode reward: -0.3734,                 loss: nan
agent1:                 episode reward: 0.3734,                 loss: 0.1741
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2914s / 236.1436 s
agent0:                 episode reward: -1.1936,                 loss: nan
agent1:                 episode reward: 1.1936,                 loss: 0.1751
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2204s / 237.3640 s
agent0:                 episode reward: -0.5074,                 loss: nan
agent1:                 episode reward: 0.5074,                 loss: 0.1732
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2527s / 238.6168 s
agent0:                 episode reward: 0.3472,                 loss: nan
agent1:                 episode reward: -0.3472,                 loss: 0.1480
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2705s / 239.8872 s
agent0:                 episode reward: -1.0040,                 loss: nan
agent1:                 episode reward: 1.0040,                 loss: 0.1359
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2167s / 241.1039 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.1366
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2575s / 242.3614 s
agent0:                 episode reward: -0.1183,                 loss: nan
agent1:                 episode reward: 0.1183,                 loss: 0.1357
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2283s / 243.5897 s
agent0:                 episode reward: -0.9748,                 loss: nan
agent1:                 episode reward: 0.9748,                 loss: 0.1354
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2179s / 244.8077 s
agent0:                 episode reward: 0.1403,                 loss: nan
agent1:                 episode reward: -0.1403,                 loss: 0.1593
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2909s / 246.0986 s
agent0:                 episode reward: 0.1716,                 loss: nan
agent1:                 episode reward: -0.1716,                 loss: 0.1615
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2458s / 247.3443 s
agent0:                 episode reward: -0.2990,                 loss: nan
agent1:                 episode reward: 0.2990,                 loss: 0.1616
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2545s / 248.5989 s
agent0:                 episode reward: -0.8416,                 loss: nan
agent1:                 episode reward: 0.8416,                 loss: 0.1616
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2259s / 249.8248 s
agent0:                 episode reward: -1.1573,                 loss: nan
agent1:                 episode reward: 1.1573,                 loss: 0.1628
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2229s / 251.0477 s
agent0:                 episode reward: -0.9447,                 loss: nan
agent1:                 episode reward: 0.9447,                 loss: 0.1632
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2340s / 252.2817 s
agent0:                 episode reward: 0.2511,                 loss: nan
agent1:                 episode reward: -0.2511,                 loss: 0.1609
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2312s / 253.5129 s
agent0:                 episode reward: -0.3335,                 loss: nan
agent1:                 episode reward: 0.3335,                 loss: 0.1620
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2808s / 254.7937 s
agent0:                 episode reward: -0.3706,                 loss: nan
agent1:                 episode reward: 0.3706,                 loss: 0.1609
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2557s / 256.0495 s
agent0:                 episode reward: 0.0344,                 loss: nan
agent1:                 episode reward: -0.0344,                 loss: 0.1612
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3260s / 257.3754 s
agent0:                 episode reward: -0.5693,                 loss: nan
agent1:                 episode reward: 0.5693,                 loss: 0.2178
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2675s / 258.6429 s
agent0:                 episode reward: -0.4930,                 loss: nan
agent1:                 episode reward: 0.4930,                 loss: 0.2236
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2451s / 259.8880 s
agent0:                 episode reward: -0.5479,                 loss: nan
agent1:                 episode reward: 0.5479,                 loss: 0.2237
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2642s / 261.1523 s
agent0:                 episode reward: 0.2911,                 loss: nan
agent1:                 episode reward: -0.2911,                 loss: 0.2227
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2884s / 262.4407 s
agent0:                 episode reward: -1.2102,                 loss: nan
agent1:                 episode reward: 1.2102,                 loss: 0.2219
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2612s / 263.7019 s
agent0:                 episode reward: -0.2231,                 loss: nan
agent1:                 episode reward: 0.2231,                 loss: 0.2364
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2692s / 264.9711 s
agent0:                 episode reward: -0.9917,                 loss: nan
agent1:                 episode reward: 0.9917,                 loss: 0.2417
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3438s / 266.3149 s
agent0:                 episode reward: -1.1459,                 loss: nan
agent1:                 episode reward: 1.1459,                 loss: 0.2376
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2988s / 267.6136 s
agent0:                 episode reward: -0.5356,                 loss: nan
agent1:                 episode reward: 0.5356,                 loss: 0.2369
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2781s / 268.8917 s
agent0:                 episode reward: -0.2714,                 loss: nan
agent1:                 episode reward: 0.2714,                 loss: 0.2371
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2721s / 270.1639 s
agent0:                 episode reward: 0.1069,                 loss: nan
agent1:                 episode reward: -0.1069,                 loss: 0.2312
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2776s / 271.4414 s
agent0:                 episode reward: -0.7216,                 loss: nan
agent1:                 episode reward: 0.7216,                 loss: 0.2259
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2890s / 272.7304 s
agent0:                 episode reward: -1.0822,                 loss: nan
agent1:                 episode reward: 1.0822,                 loss: 0.2273
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2717s / 274.0021 s
agent0:                 episode reward: -0.5609,                 loss: nan
agent1:                 episode reward: 0.5609,                 loss: 0.2278
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2891s / 275.2912 s
agent0:                 episode reward: -0.1791,                 loss: nan
agent1:                 episode reward: 0.1791,                 loss: 0.2277
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3409s / 276.6321 s
agent0:                 episode reward: -0.6002,                 loss: nan
agent1:                 episode reward: 0.6002,                 loss: 0.2227
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2796s / 277.9117 s
agent0:                 episode reward: -1.2904,                 loss: nan
agent1:                 episode reward: 1.2904,                 loss: 0.2193
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3194s / 279.2311 s
agent0:                 episode reward: -0.7953,                 loss: nan
agent1:                 episode reward: 0.7953,                 loss: 0.2200
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2827s / 280.5138 s
agent0:                 episode reward: -0.0737,                 loss: nan
agent1:                 episode reward: 0.0737,                 loss: 0.2183
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2914s / 281.8052 s
agent0:                 episode reward: -0.3622,                 loss: nan
agent1:                 episode reward: 0.3622,                 loss: 0.2185
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3116s / 283.1168 s
agent0:                 episode reward: 0.2403,                 loss: nan
agent1:                 episode reward: -0.2403,                 loss: 0.1974
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3064s / 284.4232 s
agent0:                 episode reward: 0.0730,                 loss: nan
agent1:                 episode reward: -0.0730,                 loss: 0.1864
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3245s / 285.7477 s
agent0:                 episode reward: 0.2399,                 loss: nan
agent1:                 episode reward: -0.2399,                 loss: 0.1860
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3515s / 287.0992 s
agent0:                 episode reward: -0.7400,                 loss: nan
agent1:                 episode reward: 0.7400,                 loss: 0.1872
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3217s / 288.4210 s
agent0:                 episode reward: -0.9221,                 loss: nan
agent1:                 episode reward: 0.9221,                 loss: 0.1854
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3143s / 289.7353 s
agent0:                 episode reward: -0.4389,                 loss: nan
agent1:                 episode reward: 0.4389,                 loss: 0.1562
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3228s / 291.0581 s
agent0:                 episode reward: 0.2616,                 loss: nan
agent1:                 episode reward: -0.2616,                 loss: 0.1468
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3005s / 292.3586 s
agent0:                 episode reward: -0.3933,                 loss: nan
agent1:                 episode reward: 0.3933,                 loss: 0.1490
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2951s / 293.6537 s
agent0:                 episode reward: -0.1860,                 loss: nan
agent1:                 episode reward: 0.1860,                 loss: 0.1457
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3137s / 294.9674 s
agent0:                 episode reward: 0.0813,                 loss: nan
agent1:                 episode reward: -0.0813,                 loss: 0.1452
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3449s / 296.3123 s
agent0:                 episode reward: -0.6925,                 loss: nan
agent1:                 episode reward: 0.6925,                 loss: 0.1375
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3835s / 297.6958 s
agent0:                 episode reward: -0.1839,                 loss: nan
agent1:                 episode reward: 0.1839,                 loss: 0.1334
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3352s / 299.0310 s
agent0:                 episode reward: 0.4006,                 loss: nan
agent1:                 episode reward: -0.4006,                 loss: 0.1321
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3836s / 300.4146 s
agent0:                 episode reward: -1.0832,                 loss: nan
agent1:                 episode reward: 1.0832,                 loss: 0.1336
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3249s / 301.7395 s
agent0:                 episode reward: -0.2594,                 loss: nan
agent1:                 episode reward: 0.2594,                 loss: 0.1324
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3406s / 303.0801 s
agent0:                 episode reward: 0.1012,                 loss: nan
agent1:                 episode reward: -0.1012,                 loss: 0.1650
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3666s / 304.4467 s
agent0:                 episode reward: -0.3729,                 loss: nan
agent1:                 episode reward: 0.3729,                 loss: 0.1675
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3369s / 305.7836 s
agent0:                 episode reward: -0.2847,                 loss: nan
agent1:                 episode reward: 0.2847,                 loss: 0.1682
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3424s / 307.1260 s
agent0:                 episode reward: -0.3427,                 loss: nan
agent1:                 episode reward: 0.3427,                 loss: 0.1695
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3826s / 308.5086 s
agent0:                 episode reward: -0.4836,                 loss: nan
agent1:                 episode reward: 0.4836,                 loss: 0.1679
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3430s / 309.8516 s
agent0:                 episode reward: -0.4981,                 loss: nan
agent1:                 episode reward: 0.4981,                 loss: 0.2221
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3460s / 311.1976 s
agent0:                 episode reward: -0.0646,                 loss: nan
agent1:                 episode reward: 0.0646,                 loss: 0.2269
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3578s / 312.5554 s
agent0:                 episode reward: -0.4785,                 loss: nan
agent1:                 episode reward: 0.4785,                 loss: 0.2267
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3285s / 313.8839 s
agent0:                 episode reward: -1.0803,                 loss: nan
agent1:                 episode reward: 1.0803,                 loss: 0.2269
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3935s / 315.2774 s
agent0:                 episode reward: -1.0793,                 loss: nan
agent1:                 episode reward: 1.0793,                 loss: 0.2259
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3367s / 316.6141 s
agent0:                 episode reward: -1.2409,                 loss: nan
agent1:                 episode reward: 1.2409,                 loss: 0.2753
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4134s / 318.0275 s
agent0:                 episode reward: -0.5469,                 loss: nan
agent1:                 episode reward: 0.5469,                 loss: 0.2761
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3648s / 319.3923 s
agent0:                 episode reward: -0.4964,                 loss: nan
agent1:                 episode reward: 0.4964,                 loss: 0.2773
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3688s / 320.7611 s
agent0:                 episode reward: -0.5640,                 loss: nan
agent1:                 episode reward: 0.5640,                 loss: 0.2738
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3667s / 322.1278 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: 0.2742
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3625s / 323.4903 s
agent0:                 episode reward: -0.4117,                 loss: nan
agent1:                 episode reward: 0.4117,                 loss: 0.2650
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4633s / 324.9536 s
agent0:                 episode reward: -0.5187,                 loss: nan
agent1:                 episode reward: 0.5187,                 loss: 0.2582
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3590s / 326.3126 s
agent0:                 episode reward: 0.3025,                 loss: nan
agent1:                 episode reward: -0.3025,                 loss: 0.2585
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3974s / 327.7100 s
agent0:                 episode reward: -0.7512,                 loss: nan
agent1:                 episode reward: 0.7512,                 loss: 0.2601
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4139s / 329.1239 s
agent0:                 episode reward: -0.1934,                 loss: nan
agent1:                 episode reward: 0.1934,                 loss: 0.2573
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4226s / 330.5465 s
agent0:                 episode reward: -0.6091,                 loss: nan
agent1:                 episode reward: 0.6091,                 loss: 0.2216
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3721s / 331.9187 s
agent0:                 episode reward: -0.5413,                 loss: nan
agent1:                 episode reward: 0.5413,                 loss: 0.2109
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3904s / 333.3090 s
agent0:                 episode reward: -0.5348,                 loss: nan
agent1:                 episode reward: 0.5348,                 loss: 0.2137
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3789s / 334.6879 s
agent0:                 episode reward: -0.3228,                 loss: nan
agent1:                 episode reward: 0.3228,                 loss: 0.2109
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3991s / 336.0870 s
agent0:                 episode reward: -0.9402,                 loss: nan
agent1:                 episode reward: 0.9402,                 loss: 0.2113
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4022s / 337.4892 s
agent0:                 episode reward: -0.0580,                 loss: nan
agent1:                 episode reward: 0.0580,                 loss: 0.1824
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4865s / 338.9757 s
agent0:                 episode reward: -0.6600,                 loss: nan
agent1:                 episode reward: 0.6600,                 loss: 0.1721
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4436s / 340.4193 s
agent0:                 episode reward: -0.6740,                 loss: nan
agent1:                 episode reward: 0.6740,                 loss: 0.1739
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4086s / 341.8279 s
agent0:                 episode reward: -0.5387,                 loss: nan
agent1:                 episode reward: 0.5387,                 loss: 0.1727
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4097s / 343.2375 s
agent0:                 episode reward: -0.2013,                 loss: nan
agent1:                 episode reward: 0.2013,                 loss: 0.1740
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3989s / 344.6364 s
agent0:                 episode reward: -1.0951,                 loss: nan
agent1:                 episode reward: 1.0951,                 loss: 0.1854
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4283s / 346.0648 s
agent0:                 episode reward: -0.7647,                 loss: nan
agent1:                 episode reward: 0.7647,                 loss: 0.1860
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4319s / 347.4966 s
agent0:                 episode reward: -0.6991,                 loss: nan
agent1:                 episode reward: 0.6991,                 loss: 0.1842
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4703s / 348.9669 s
agent0:                 episode reward: -0.8674,                 loss: nan
agent1:                 episode reward: 0.8674,                 loss: 0.1865
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4499s / 350.4168 s
agent0:                 episode reward: -0.8442,                 loss: nan
agent1:                 episode reward: 0.8442,                 loss: 0.1856
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4182s / 351.8350 s
agent0:                 episode reward: -0.6538,                 loss: nan
agent1:                 episode reward: 0.6538,                 loss: 0.1589
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4039s / 353.2390 s
agent0:                 episode reward: -1.1089,                 loss: nan
agent1:                 episode reward: 1.1089,                 loss: 0.1534
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4233s / 354.6622 s
agent0:                 episode reward: -0.3898,                 loss: nan
agent1:                 episode reward: 0.3898,                 loss: 0.1527
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4350s / 356.0972 s
agent0:                 episode reward: 0.0451,                 loss: nan
agent1:                 episode reward: -0.0451,                 loss: 0.1547
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4444s / 357.5417 s
agent0:                 episode reward: -1.3649,                 loss: nan
agent1:                 episode reward: 1.3649,                 loss: 0.1519
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4663s / 359.0079 s
agent0:                 episode reward: -0.8096,                 loss: nan
agent1:                 episode reward: 0.8096,                 loss: 0.1409
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4544s / 360.4623 s
agent0:                 episode reward: -0.8326,                 loss: nan
agent1:                 episode reward: 0.8326,                 loss: 0.1377
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4367s / 361.8990 s
agent0:                 episode reward: -0.2442,                 loss: nan
agent1:                 episode reward: 0.2442,                 loss: 0.1384
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4519s / 363.3509 s
agent0:                 episode reward: -0.7801,                 loss: nan
agent1:                 episode reward: 0.7801,                 loss: 0.1381
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4781s / 364.8290 s
agent0:                 episode reward: -0.8505,                 loss: nan
agent1:                 episode reward: 0.8505,                 loss: 0.1377
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4432s / 366.2722 s
agent0:                 episode reward: -0.5694,                 loss: nan
agent1:                 episode reward: 0.5694,                 loss: 0.1495
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4568s / 367.7290 s
agent0:                 episode reward: -0.4560,                 loss: nan
agent1:                 episode reward: 0.4560,                 loss: 0.1528
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5411s / 369.2702 s
agent0:                 episode reward: -1.0467,                 loss: nan
agent1:                 episode reward: 1.0467,                 loss: 0.1529
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5185s / 370.7887 s
agent0:                 episode reward: -1.1248,                 loss: nan
agent1:                 episode reward: 1.1248,                 loss: 0.1503
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4770s / 372.2657 s
agent0:                 episode reward: -0.6130,                 loss: nan
agent1:                 episode reward: 0.6130,                 loss: 0.1507
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4528s / 373.7185 s
agent0:                 episode reward: -0.4775,                 loss: nan
agent1:                 episode reward: 0.4775,                 loss: 0.1809
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4661s / 375.1847 s
agent0:                 episode reward: -0.2743,                 loss: nan
agent1:                 episode reward: 0.2743,                 loss: 0.1862
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4612s / 376.6458 s
agent0:                 episode reward: -0.8629,                 loss: nan
agent1:                 episode reward: 0.8629,                 loss: 0.1835
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4764s / 378.1222 s
agent0:                 episode reward: -0.6000,                 loss: nan
agent1:                 episode reward: 0.6000,                 loss: 0.1846
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5370s / 379.6592 s
agent0:                 episode reward: -0.8910,                 loss: nan
agent1:                 episode reward: 0.8910,                 loss: 0.1840
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5198s / 381.1790 s
agent0:                 episode reward: -0.4062,                 loss: nan
agent1:                 episode reward: 0.4062,                 loss: 0.2452
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4905s / 382.6695 s
agent0:                 episode reward: -0.3739,                 loss: nan
agent1:                 episode reward: 0.3739,                 loss: 0.2506
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4888s / 384.1583 s
agent0:                 episode reward: -0.5970,                 loss: nan
agent1:                 episode reward: 0.5970,                 loss: 0.2506
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4762s / 385.6345 s
agent0:                 episode reward: -0.8182,                 loss: nan
agent1:                 episode reward: 0.8182,                 loss: 0.2489
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5250s / 387.1595 s
agent0:                 episode reward: -0.3508,                 loss: nan
agent1:                 episode reward: 0.3508,                 loss: 0.2500
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5314s / 388.6909 s
agent0:                 episode reward: -0.9200,                 loss: nan
agent1:                 episode reward: 0.9200,                 loss: 0.2758
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6025s / 390.2934 s
agent0:                 episode reward: -0.8438,                 loss: nan
agent1:                 episode reward: 0.8438,                 loss: 0.2756
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5131s / 391.8065 s
agent0:                 episode reward: -0.2541,                 loss: nan
agent1:                 episode reward: 0.2541,                 loss: 0.2763
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5123s / 393.3188 s
agent0:                 episode reward: -0.5561,                 loss: nan
agent1:                 episode reward: 0.5561,                 loss: 0.2741
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5145s / 394.8333 s
agent0:                 episode reward: -0.3234,                 loss: nan
agent1:                 episode reward: 0.3234,                 loss: 0.2728
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5310s / 396.3643 s
agent0:                 episode reward: -0.8824,                 loss: nan
agent1:                 episode reward: 0.8824,                 loss: 0.2644
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5264s / 397.8907 s
agent0:                 episode reward: -0.4942,                 loss: nan
agent1:                 episode reward: 0.4942,                 loss: 0.2590
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5367s / 399.4274 s
agent0:                 episode reward: -0.5357,                 loss: nan
agent1:                 episode reward: 0.5357,                 loss: 0.2560
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5955s / 401.0229 s
agent0:                 episode reward: -0.3443,                 loss: nan
agent1:                 episode reward: 0.3443,                 loss: 0.2560
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5541s / 402.5770 s
agent0:                 episode reward: -0.2815,                 loss: nan
agent1:                 episode reward: 0.2815,                 loss: 0.2554
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5290s / 404.1060 s
agent0:                 episode reward: -0.3317,                 loss: nan
agent1:                 episode reward: 0.3317,                 loss: 0.2069
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5255s / 405.6315 s
agent0:                 episode reward: -0.3603,                 loss: nan
agent1:                 episode reward: 0.3603,                 loss: 0.1924
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5218s / 407.1533 s
agent0:                 episode reward: -1.0161,                 loss: nan
agent1:                 episode reward: 1.0161,                 loss: 0.1908
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5272s / 408.6805 s
agent0:                 episode reward: -0.7844,                 loss: nan
agent1:                 episode reward: 0.7844,                 loss: 0.1897
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5724s / 410.2529 s
agent0:                 episode reward: -0.2933,                 loss: nan
agent1:                 episode reward: 0.2933,                 loss: 0.1874
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5344s / 411.7872 s
agent0:                 episode reward: 0.3044,                 loss: nan
agent1:                 episode reward: -0.3044,                 loss: 0.1544
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5673s / 413.3546 s
agent0:                 episode reward: -0.9310,                 loss: nan
agent1:                 episode reward: 0.9310,                 loss: 0.1472
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5328s / 414.8874 s
agent0:                 episode reward: -0.2819,                 loss: nan
agent1:                 episode reward: 0.2819,                 loss: 0.1459
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5239s / 416.4112 s
agent0:                 episode reward: -0.6745,                 loss: nan
agent1:                 episode reward: 0.6745,                 loss: 0.1444
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5543s / 417.9656 s
agent0:                 episode reward: -0.9537,                 loss: nan
agent1:                 episode reward: 0.9537,                 loss: 0.1465
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5638s / 419.5293 s
agent0:                 episode reward: -1.0857,                 loss: nan
agent1:                 episode reward: 1.0857,                 loss: 0.1352
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6238s / 421.1531 s
agent0:                 episode reward: -0.9608,                 loss: nan
agent1:                 episode reward: 0.9608,                 loss: 0.1309
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5669s / 422.7200 s
agent0:                 episode reward: -0.8099,                 loss: nan
agent1:                 episode reward: 0.8099,                 loss: 0.1290
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5920s / 424.3120 s
agent0:                 episode reward: -1.2017,                 loss: nan
agent1:                 episode reward: 1.2017,                 loss: 0.1297
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5695s / 425.8814 s
agent0:                 episode reward: -1.2498,                 loss: nan
agent1:                 episode reward: 1.2498,                 loss: 0.1275
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5790s / 427.4604 s
agent0:                 episode reward: -1.0103,                 loss: nan
agent1:                 episode reward: 1.0103,                 loss: 0.1390
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5637s / 429.0241 s
agent0:                 episode reward: -0.7670,                 loss: nan
agent1:                 episode reward: 0.7670,                 loss: 0.1391
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6445s / 430.6686 s
agent0:                 episode reward: -0.1730,                 loss: nan
agent1:                 episode reward: 0.1730,                 loss: 0.1402
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5656s / 432.2342 s
agent0:                 episode reward: -0.7387,                 loss: nan
agent1:                 episode reward: 0.7387,                 loss: 0.1394
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5759s / 433.8101 s
agent0:                 episode reward: -0.4624,                 loss: nan
agent1:                 episode reward: 0.4624,                 loss: 0.1397
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5687s / 435.3788 s
agent0:                 episode reward: -0.3988,                 loss: nan
agent1:                 episode reward: 0.3988,                 loss: 0.1518
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5798s / 436.9586 s
agent0:                 episode reward: -0.7062,                 loss: nan
agent1:                 episode reward: 0.7062,                 loss: 0.1500
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6225s / 438.5811 s
agent0:                 episode reward: -0.6655,                 loss: nan
agent1:                 episode reward: 0.6655,                 loss: 0.1516
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5779s / 440.1590 s
agent0:                 episode reward: -1.0389,                 loss: nan
agent1:                 episode reward: 1.0389,                 loss: 0.1509
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6824s / 441.8413 s
agent0:                 episode reward: -0.5120,                 loss: nan
agent1:                 episode reward: 0.5120,                 loss: 0.1495
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6156s / 443.4569 s
agent0:                 episode reward: -1.2057,                 loss: nan
agent1:                 episode reward: 1.2057,                 loss: 0.1860
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6074s / 445.0644 s
agent0:                 episode reward: -0.8804,                 loss: nan
agent1:                 episode reward: 0.8804,                 loss: 0.1882
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6355s / 446.6999 s
agent0:                 episode reward: -0.8068,                 loss: nan
agent1:                 episode reward: 0.8068,                 loss: 0.1871
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6227s / 448.3226 s
agent0:                 episode reward: -0.7067,                 loss: nan
agent1:                 episode reward: 0.7067,                 loss: 0.1864
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6181s / 449.9408 s
agent0:                 episode reward: -1.0748,                 loss: nan
agent1:                 episode reward: 1.0748,                 loss: 0.1868
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6737s / 451.6144 s
agent0:                 episode reward: -0.4660,                 loss: nan
agent1:                 episode reward: 0.4660,                 loss: 0.2362
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6378s / 453.2522 s
agent0:                 episode reward: -1.1031,                 loss: nan
agent1:                 episode reward: 1.1031,                 loss: 0.2399
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6441s / 454.8963 s
agent0:                 episode reward: -0.8733,                 loss: nan
agent1:                 episode reward: 0.8733,                 loss: 0.2392
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6588s / 456.5552 s
agent0:                 episode reward: -0.4433,                 loss: nan
agent1:                 episode reward: 0.4433,                 loss: 0.2404
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6129s / 458.1681 s
agent0:                 episode reward: -0.6408,                 loss: nan
agent1:                 episode reward: 0.6408,                 loss: 0.2376
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6340s / 459.8021 s
agent0:                 episode reward: -0.5160,                 loss: nan
agent1:                 episode reward: 0.5160,                 loss: 0.2563
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6640s / 461.4660 s
agent0:                 episode reward: -0.4921,                 loss: nan
agent1:                 episode reward: 0.4921,                 loss: 0.2530
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6598s / 463.1258 s
agent0:                 episode reward: -1.1834,                 loss: nan
agent1:                 episode reward: 1.1834,                 loss: 0.2498
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6522s / 464.7780 s
agent0:                 episode reward: -1.1578,                 loss: nan
agent1:                 episode reward: 1.1578,                 loss: 0.2540
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6447s / 466.4227 s
agent0:                 episode reward: -0.2925,                 loss: nan
agent1:                 episode reward: 0.2925,                 loss: 0.2492
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6219s / 468.0446 s
agent0:                 episode reward: -0.9193,                 loss: nan
agent1:                 episode reward: 0.9193,                 loss: 0.1911
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6270s / 469.6716 s
agent0:                 episode reward: -0.5877,                 loss: nan
agent1:                 episode reward: 0.5877,                 loss: 0.1766
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7161s / 471.3877 s
agent0:                 episode reward: -0.7147,                 loss: nan
agent1:                 episode reward: 0.7147,                 loss: 0.1760
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6413s / 473.0290 s
agent0:                 episode reward: -0.7319,                 loss: nan
agent1:                 episode reward: 0.7319,                 loss: 0.1751
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6884s / 474.7174 s
agent0:                 episode reward: -0.2150,                 loss: nan
agent1:                 episode reward: 0.2150,                 loss: 0.1749
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6746s / 476.3920 s
agent0:                 episode reward: -1.1197,                 loss: nan
agent1:                 episode reward: 1.1197,                 loss: 0.1400
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6688s / 478.0608 s
agent0:                 episode reward: -0.5571,                 loss: nan
agent1:                 episode reward: 0.5571,                 loss: 0.1278
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6854s / 479.7462 s
agent0:                 episode reward: -0.9245,                 loss: nan
agent1:                 episode reward: 0.9245,                 loss: 0.1287
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6979s / 481.4440 s
agent0:                 episode reward: -0.7124,                 loss: nan
agent1:                 episode reward: 0.7124,                 loss: 0.1288
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7070s / 483.1510 s
agent0:                 episode reward: -0.8820,                 loss: nan
agent1:                 episode reward: 0.8820,                 loss: 0.1280
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6656s / 484.8166 s
agent0:                 episode reward: -0.3830,                 loss: nan
agent1:                 episode reward: 0.3830,                 loss: 0.1153
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6768s / 486.4934 s
agent0:                 episode reward: -0.8629,                 loss: nan
agent1:                 episode reward: 0.8629,                 loss: 0.1085
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7054s / 488.1988 s
agent0:                 episode reward: -0.4435,                 loss: nan
agent1:                 episode reward: 0.4435,                 loss: 0.1092
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7139s / 489.9127 s
agent0:                 episode reward: -0.9935,                 loss: nan
agent1:                 episode reward: 0.9935,                 loss: 0.1097
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6943s / 491.6070 s
agent0:                 episode reward: -0.6799,                 loss: nan
agent1:                 episode reward: 0.6799,                 loss: 0.1077
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7538s / 493.3609 s
agent0:                 episode reward: -0.4360,                 loss: nan
agent1:                 episode reward: 0.4360,                 loss: 0.1312
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6678s / 495.0287 s
agent0:                 episode reward: -1.2570,                 loss: nan
agent1:                 episode reward: 1.2570,                 loss: 0.1318
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7312s / 496.7599 s
agent0:                 episode reward: -0.5668,                 loss: nan
agent1:                 episode reward: 0.5668,                 loss: 0.1321
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6961s / 498.4560 s
agent0:                 episode reward: -1.0033,                 loss: nan
agent1:                 episode reward: 1.0033,                 loss: 0.1319
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7128s / 500.1688 s
agent0:                 episode reward: -1.0422,                 loss: nan
agent1:                 episode reward: 1.0422,                 loss: 0.1323
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7176s / 501.8864 s
agent0:                 episode reward: -1.0482,                 loss: nan
agent1:                 episode reward: 1.0482,                 loss: 0.1929
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7472s / 503.6335 s
agent0:                 episode reward: -0.7792,                 loss: nan
agent1:                 episode reward: 0.7792,                 loss: 0.1991
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7493s / 505.3828 s
agent0:                 episode reward: -0.7461,                 loss: nan
agent1:                 episode reward: 0.7461,                 loss: 0.1976
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7396s / 507.1225 s
agent0:                 episode reward: -0.8676,                 loss: nan
agent1:                 episode reward: 0.8676,                 loss: 0.1980
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6971s / 508.8195 s
agent0:                 episode reward: -0.5856,                 loss: nan
agent1:                 episode reward: 0.5856,                 loss: 0.1977
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7470s / 510.5665 s
agent0:                 episode reward: -1.1347,                 loss: nan
agent1:                 episode reward: 1.1347,                 loss: 0.2226
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7664s / 512.3329 s
agent0:                 episode reward: -0.6474,                 loss: nan
agent1:                 episode reward: 0.6474,                 loss: 0.2241
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7707s / 514.1036 s
agent0:                 episode reward: -1.4599,                 loss: nan
agent1:                 episode reward: 1.4599,                 loss: 0.2210
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7022s / 515.8059 s
agent0:                 episode reward: -1.0119,                 loss: nan
agent1:                 episode reward: 1.0119,                 loss: 0.2224
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7457s / 517.5515 s
agent0:                 episode reward: -0.6324,                 loss: nan
agent1:                 episode reward: 0.6324,                 loss: 0.2215
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7599s / 519.3114 s
agent0:                 episode reward: -1.2726,                 loss: nan
agent1:                 episode reward: 1.2726,                 loss: 0.2419
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7204s / 521.0318 s
agent0:                 episode reward: -1.0152,                 loss: nan
agent1:                 episode reward: 1.0152,                 loss: 0.2399
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8156s / 522.8474 s
agent0:                 episode reward: -0.7439,                 loss: nan
agent1:                 episode reward: 0.7439,                 loss: 0.2388
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7320s / 524.5794 s
agent0:                 episode reward: -0.8140,                 loss: nan
agent1:                 episode reward: 0.8140,                 loss: 0.2388
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7258s / 526.3053 s
agent0:                 episode reward: -1.1516,                 loss: nan
agent1:                 episode reward: 1.1516,                 loss: 0.2379
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7227s / 528.0280 s
agent0:                 episode reward: -0.5064,                 loss: nan
agent1:                 episode reward: 0.5064,                 loss: 0.2348
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7526s / 529.7806 s
agent0:                 episode reward: -1.1647,                 loss: nan
agent1:                 episode reward: 1.1647,                 loss: 0.2264
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7595s / 531.5401 s
agent0:                 episode reward: -1.1125,                 loss: nan
agent1:                 episode reward: 1.1125,                 loss: 0.2275
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8269s / 533.3670 s
agent0:                 episode reward: -0.5057,                 loss: nan
agent1:                 episode reward: 0.5057,                 loss: 0.2284
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7759s / 535.1429 s
agent0:                 episode reward: -0.9285,                 loss: nan
agent1:                 episode reward: 0.9285,                 loss: 0.2274
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7448s / 536.8877 s
agent0:                 episode reward: 0.2807,                 loss: nan
agent1:                 episode reward: -0.2807,                 loss: 0.2035
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7759s / 538.6636 s
agent0:                 episode reward: -0.1744,                 loss: nan
agent1:                 episode reward: 0.1744,                 loss: 0.1932
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7528s / 540.4164 s
agent0:                 episode reward: -0.8208,                 loss: nan
agent1:                 episode reward: 0.8208,                 loss: 0.1894
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7620s / 542.1784 s
agent0:                 episode reward: -1.1349,                 loss: nan
agent1:                 episode reward: 1.1349,                 loss: 0.1905
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8459s / 544.0243 s
agent0:                 episode reward: -0.9145,                 loss: nan
agent1:                 episode reward: 0.9145,                 loss: 0.1900
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7579s / 545.7822 s
agent0:                 episode reward: -0.2981,                 loss: nan
agent1:                 episode reward: 0.2981,                 loss: 0.1422
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7935s / 547.5757 s
agent0:                 episode reward: -0.2086,                 loss: nan
agent1:                 episode reward: 0.2086,                 loss: 0.1274
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7752s / 549.3509 s
agent0:                 episode reward: -0.1157,                 loss: nan
agent1:                 episode reward: 0.1157,                 loss: 0.1259
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7737s / 551.1246 s
agent0:                 episode reward: -1.0406,                 loss: nan
agent1:                 episode reward: 1.0406,                 loss: 0.1257
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7887s / 552.9133 s
agent0:                 episode reward: -1.0868,                 loss: nan
agent1:                 episode reward: 1.0868,                 loss: 0.1259
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8699s / 554.7832 s
agent0:                 episode reward: -1.3632,                 loss: nan
agent1:                 episode reward: 1.3632,                 loss: 0.1006
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8009s / 556.5841 s
agent0:                 episode reward: -2.0658,                 loss: nan
agent1:                 episode reward: 2.0658,                 loss: 0.0918
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8252s / 558.4094 s
agent0:                 episode reward: -1.3916,                 loss: nan
agent1:                 episode reward: 1.3916,                 loss: 0.0918
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8124s / 560.2217 s
agent0:                 episode reward: -0.9603,                 loss: nan
agent1:                 episode reward: 0.9603,                 loss: 0.0918
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8006s / 562.0223 s
agent0:                 episode reward: -1.0339,                 loss: nan
agent1:                 episode reward: 1.0339,                 loss: 0.0905
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8656s / 563.8879 s
agent0:                 episode reward: -1.1596,                 loss: nan
agent1:                 episode reward: 1.1596,                 loss: 0.1100
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8303s / 565.7182 s
agent0:                 episode reward: -1.4863,                 loss: nan
agent1:                 episode reward: 1.4863,                 loss: 0.1093
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7894s / 567.5076 s
agent0:                 episode reward: -1.3064,                 loss: nan
agent1:                 episode reward: 1.3064,                 loss: 0.1083
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8025s / 569.3101 s
agent0:                 episode reward: -1.0411,                 loss: nan
agent1:                 episode reward: 1.0411,                 loss: 0.1084
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8207s / 571.1308 s
agent0:                 episode reward: -0.5383,                 loss: nan
agent1:                 episode reward: 0.5383,                 loss: 0.1095
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8406s / 572.9714 s
agent0:                 episode reward: -1.5661,                 loss: nan
agent1:                 episode reward: 1.5661,                 loss: 0.1333
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8725s / 574.8439 s
agent0:                 episode reward: -0.7613,                 loss: nan
agent1:                 episode reward: 0.7613,                 loss: 0.1360
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8047s / 576.6485 s
agent0:                 episode reward: -0.9795,                 loss: nan
agent1:                 episode reward: 0.9795,                 loss: 0.1372
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8295s / 578.4781 s
agent0:                 episode reward: -1.4432,                 loss: nan
agent1:                 episode reward: 1.4432,                 loss: 0.1353
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8454s / 580.3235 s
agent0:                 episode reward: -1.1302,                 loss: nan
agent1:                 episode reward: 1.1302,                 loss: 0.1344
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8373s / 582.1608 s
agent0:                 episode reward: -0.9665,                 loss: nan
agent1:                 episode reward: 0.9665,                 loss: 0.1786
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9046s / 584.0654 s
agent0:                 episode reward: -1.7651,                 loss: nan
agent1:                 episode reward: 1.7651,                 loss: 0.1851
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8601s / 585.9255 s
agent0:                 episode reward: -1.6611,                 loss: nan
agent1:                 episode reward: 1.6611,                 loss: 0.1828
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8630s / 587.7885 s
agent0:                 episode reward: -0.7943,                 loss: nan
agent1:                 episode reward: 0.7943,                 loss: 0.1830
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8471s / 589.6356 s
agent0:                 episode reward: -1.0744,                 loss: nan
agent1:                 episode reward: 1.0744,                 loss: 0.1831
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8602s / 591.4958 s
agent0:                 episode reward: -0.4724,                 loss: nan
agent1:                 episode reward: 0.4724,                 loss: 0.2337
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8628s / 593.3586 s
agent0:                 episode reward: -0.8434,                 loss: nan
agent1:                 episode reward: 0.8434,                 loss: 0.2371
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9317s / 595.2903 s
agent0:                 episode reward: -1.1709,                 loss: nan
agent1:                 episode reward: 1.1709,                 loss: 0.2379
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8684s / 597.1587 s
agent0:                 episode reward: -1.1822,                 loss: nan
agent1:                 episode reward: 1.1822,                 loss: 0.2381
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8557s / 599.0144 s
agent0:                 episode reward: -0.6395,                 loss: nan
agent1:                 episode reward: 0.6395,                 loss: 0.2367
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8594s / 600.8738 s
agent0:                 episode reward: -1.4473,                 loss: nan
agent1:                 episode reward: 1.4473,                 loss: 0.2512
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8631s / 602.7370 s
agent0:                 episode reward: -1.0842,                 loss: nan
agent1:                 episode reward: 1.0842,                 loss: 0.2499
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9478s / 604.6848 s
agent0:                 episode reward: -0.7549,                 loss: nan
agent1:                 episode reward: 0.7549,                 loss: 0.2516
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9002s / 606.5849 s
agent0:                 episode reward: -1.0507,                 loss: nan
agent1:                 episode reward: 1.0507,                 loss: 0.2509
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8898s / 608.4748 s
agent0:                 episode reward: -1.1675,                 loss: nan
agent1:                 episode reward: 1.1675,                 loss: 0.2496/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8986s / 610.3734 s
agent0:                 episode reward: -0.7186,                 loss: nan
agent1:                 episode reward: 0.7186,                 loss: 0.2648
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8679s / 612.2413 s
agent0:                 episode reward: -1.1711,                 loss: nan
agent1:                 episode reward: 1.1711,                 loss: 0.2646
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9040s / 614.1453 s
agent0:                 episode reward: -0.6865,                 loss: nan
agent1:                 episode reward: 0.6865,                 loss: 0.2640
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9480s / 616.0932 s
agent0:                 episode reward: -1.0571,                 loss: nan
agent1:                 episode reward: 1.0571,                 loss: 0.2618
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9143s / 618.0075 s
agent0:                 episode reward: -0.3057,                 loss: nan
agent1:                 episode reward: 0.3057,                 loss: 0.2633
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8996s / 619.9071 s
agent0:                 episode reward: -0.8891,                 loss: nan
agent1:                 episode reward: 0.8891,                 loss: 0.2278
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9113s / 621.8184 s
agent0:                 episode reward: -1.4920,                 loss: nan
agent1:                 episode reward: 1.4920,                 loss: 0.2132
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9031s / 623.7215 s
agent0:                 episode reward: -0.7574,                 loss: nan
agent1:                 episode reward: 0.7574,                 loss: 0.2140
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9581s / 625.6795 s
agent0:                 episode reward: -0.4082,                 loss: nan
agent1:                 episode reward: 0.4082,                 loss: 0.2160
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9123s / 627.5918 s
agent0:                 episode reward: -0.7427,                 loss: nan
agent1:                 episode reward: 0.7427,                 loss: 0.2147
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9483s / 629.5401 s
agent0:                 episode reward: -1.3802,                 loss: nan
agent1:                 episode reward: 1.3802,                 loss: 0.1567
