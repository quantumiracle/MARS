pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=5, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=5, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 5, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220206_0346/pettingzoo_surround_v1_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220206_0346/pettingzoo_surround_v1_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 1345.0,                last time consumption/overall running time: 9.1696s / 9.1696 s
env0_first_0:                 episode reward: 6.0000,                 loss: 0.0474
env0_second_0:                 episode reward: -6.0000,                 loss: 0.0476
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1404.95,                last time consumption/overall running time: 237.5998s / 246.7694 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0466
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0470
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1297.95,                last time consumption/overall running time: 276.7403s / 523.5097 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0430
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0430
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1175.35,                last time consumption/overall running time: 271.7446s / 795.2543 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0391
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0396
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1160.55,                last time consumption/overall running time: 275.9362s / 1071.1904 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0355
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0342
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1133.45,                last time consumption/overall running time: 285.0830s / 1356.2734 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0311
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0297
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1118.55,                last time consumption/overall running time: 282.6612s / 1638.9346 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0272
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0263
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1110.8,                last time consumption/overall running time: 276.4628s / 1915.3975 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0246
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0260
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1154.15,                last time consumption/overall running time: 287.2909s / 2202.6883 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0242
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0290
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1094.6,                last time consumption/overall running time: 273.6817s / 2476.3700 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0240
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0302
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1098.9,                last time consumption/overall running time: 274.2249s / 2750.5949 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0243
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0276
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1074.9,                last time consumption/overall running time: 269.5699s / 3020.1648 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0239
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0252
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1108.2,                last time consumption/overall running time: 274.2429s / 3294.4077 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0236
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0236
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1176.55,                last time consumption/overall running time: 292.4107s / 3586.8184 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0209
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0209
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1115.7,                last time consumption/overall running time: 282.5821s / 3869.4004 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0213
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0184
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1148.0,                last time consumption/overall running time: 287.1698s / 4156.5702 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0207
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0196
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1104.4,                last time consumption/overall running time: 281.5503s / 4438.1205 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0202
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0214
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1094.95,                last time consumption/overall running time: 273.8817s / 4712.0022 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0210
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0225
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1137.4,                last time consumption/overall running time: 279.1984s / 4991.2006 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0217
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0215
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1223.4,                last time consumption/overall running time: 308.2585s / 5299.4591 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0214
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0224
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1141.0,                last time consumption/overall running time: 285.2870s / 5584.7461 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0218
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0222
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1162.0,                last time consumption/overall running time: 282.0939s / 5866.8400 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0202
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0218
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1126.35,                last time consumption/overall running time: 287.6878s / 6154.5278 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0199
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0207
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1199.5,                last time consumption/overall running time: 298.0641s / 6452.5919 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0200
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0204
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1097.3,                last time consumption/overall running time: 270.4198s / 6723.0118 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0191
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0184
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1139.6,                last time consumption/overall running time: 284.8872s / 7007.8989 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0176
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0160
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1116.55,                last time consumption/overall running time: 280.3054s / 7288.2044 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0170
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0150
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1059.5,                last time consumption/overall running time: 261.4335s / 7549.6379 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0153
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0142
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1134.95,                last time consumption/overall running time: 285.0696s / 7834.7075 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0154
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0153
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1173.75,                last time consumption/overall running time: 291.3082s / 8126.0157 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0173
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0171
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1108.7,                last time consumption/overall running time: 275.5506s / 8401.5663 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0189
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0182
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1144.8,                last time consumption/overall running time: 285.5042s / 8687.0705 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0179
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0207
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1105.05,                last time consumption/overall running time: 272.8371s / 8959.9076 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0174
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0201
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1148.8,                last time consumption/overall running time: 286.5137s / 9246.4213 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0172
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0185
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1163.2,                last time consumption/overall running time: 291.4915s / 9537.9129 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0183
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0184
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1099.8,                last time consumption/overall running time: 274.1634s / 9812.0763 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0188
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0179
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1124.35,                last time consumption/overall running time: 272.5835s / 10084.6598 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0184
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0184
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1096.15,                last time consumption/overall running time: 274.0176s / 10358.6774 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0171
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0171
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1063.35,                last time consumption/overall running time: 266.1961s / 10624.8734 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0143
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0161
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1125.9,                last time consumption/overall running time: 277.7689s / 10902.6424 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0135
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0152
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1116.6,                last time consumption/overall running time: 273.9422s / 11176.5845 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0131
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0135
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1146.15,                last time consumption/overall running time: 283.6363s / 11460.2209 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0140
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0155
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1126.9,                last time consumption/overall running time: 276.6018s / 11736.8226 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0158
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0172
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1152.6,                last time consumption/overall running time: 279.6951s / 12016.5178 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0178
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0190
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1115.85,                last time consumption/overall running time: 274.6807s / 12291.1984 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0192
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0204
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1061.6,                last time consumption/overall running time: 265.0688s / 12556.2672 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0189
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0201
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1082.75,                last time consumption/overall running time: 271.0375s / 12827.3047 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0180
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0176
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1162.0,                last time consumption/overall running time: 291.0704s / 13118.3751 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0163
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0166
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1188.3,                last time consumption/overall running time: 299.0308s / 13417.4059 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0148
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0148
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1167.55,                last time consumption/overall running time: 289.9579s / 13707.3639 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0159
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0157
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1128.5,                last time consumption/overall running time: 278.6318s / 13985.9957 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0165
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0167
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1323.8,                last time consumption/overall running time: 330.4958s / 14316.4914 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0191
env0_second_0:                 episode reward: 4.5500,                 loss: 0.0202
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1249.15,                last time consumption/overall running time: 303.1368s / 14619.6282 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0241
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0251
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1181.8,                last time consumption/overall running time: 286.3549s / 14905.9831 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0237
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0258
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1147.95,                last time consumption/overall running time: 285.7694s / 15191.7525 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0233
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0238
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1130.55,                last time consumption/overall running time: 273.4380s / 15465.1904 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0217
env0_second_0:                 episode reward: 8.7000,                 loss: 0.0210
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1143.7,                last time consumption/overall running time: 275.9573s / 15741.1478 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0193
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0173
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1110.05,                last time consumption/overall running time: 273.7199s / 16014.8676 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0168
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0159
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1115.75,                last time consumption/overall running time: 270.5957s / 16285.4634 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0154
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0161
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1101.15,                last time consumption/overall running time: 275.0883s / 16560.5516 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0156
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0161
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1154.8,                last time consumption/overall running time: 290.2726s / 16850.8242 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0168
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0160
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1098.0,                last time consumption/overall running time: 269.1376s / 17119.9619 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0167
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0151
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1156.85,                last time consumption/overall running time: 286.9618s / 17406.9236 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0176
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0156
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1103.25,                last time consumption/overall running time: 269.7297s / 17676.6533 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0164
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0162
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1189.25,                last time consumption/overall running time: 290.9899s / 17967.6432 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0161
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0157
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1108.0,                last time consumption/overall running time: 268.2821s / 18235.9253 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0163
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0157
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1118.5,                last time consumption/overall running time: 274.1551s / 18510.0804 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0167
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0156
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1142.75,                last time consumption/overall running time: 279.4857s / 18789.5661 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0163
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0166
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1167.8,                last time consumption/overall running time: 288.9508s / 19078.5169 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0167
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0172
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1101.25,                last time consumption/overall running time: 267.8668s / 19346.3837 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0182
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0171
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1140.0,                last time consumption/overall running time: 285.2610s / 19631.6447 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0178
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0179
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1163.55,                last time consumption/overall running time: 290.7005s / 19922.3452 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0171
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0180
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1191.55,                last time consumption/overall running time: 291.7038s / 20214.0489 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0171
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0177
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1148.8,                last time consumption/overall running time: 285.9039s / 20499.9528 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0171
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0176
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1160.25,                last time consumption/overall running time: 284.5684s / 20784.5212 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0173
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0185
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1095.0,                last time consumption/overall running time: 275.9700s / 21060.4912 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0177
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0175
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1087.15,                last time consumption/overall running time: 267.4861s / 21327.9773 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0174
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0169
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1088.6,                last time consumption/overall running time: 272.9699s / 21600.9472 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0158
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1125.95,                last time consumption/overall running time: 282.1805s / 21883.1277 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0139
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0149
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1113.0,                last time consumption/overall running time: 275.3506s / 22158.4784 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0135
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0140
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1175.95,                last time consumption/overall running time: 295.4867s / 22453.9651 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0149
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0147
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1124.8,                last time consumption/overall running time: 276.2172s / 22730.1823 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0153
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0158
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1148.5,                last time consumption/overall running time: 288.3049s / 23018.4872 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0154
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0164
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1104.35,                last time consumption/overall running time: 277.5259s / 23296.0132 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0160
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0156
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1077.15,                last time consumption/overall running time: 263.5832s / 23559.5964 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0155
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0160
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1172.3,                last time consumption/overall running time: 289.6971s / 23849.2935 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0157
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0150
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1182.7,                last time consumption/overall running time: 286.2471s / 24135.5406 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0162
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0168
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1183.5,                last time consumption/overall running time: 289.5089s / 24425.0496 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0153
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0163
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1106.55,                last time consumption/overall running time: 273.0225s / 24698.0720 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0150
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0154
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1141.55,                last time consumption/overall running time: 278.8363s / 24976.9083 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0157
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0152
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1153.05,                last time consumption/overall running time: 287.1301s / 25264.0385 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0161
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0156
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1153.1,                last time consumption/overall running time: 280.1298s / 25544.1683 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0157
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0153
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1078.3,                last time consumption/overall running time: 261.7345s / 25805.9029 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0160
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0147
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1106.3,                last time consumption/overall running time: 270.7231s / 26076.6259 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0167
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0151
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1175.45,                last time consumption/overall running time: 288.4097s / 26365.0356 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0163
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0165
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1135.5,                last time consumption/overall running time: 276.1377s / 26641.1733 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0171
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0169
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1181.75,                last time consumption/overall running time: 286.8351s / 26928.0085 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0174
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0169
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1181.2,                last time consumption/overall running time: 288.3662s / 27216.3746 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0172
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0177
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 1129.25,                last time consumption/overall running time: 275.7097s / 27492.0843 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0172
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0173
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1177.15,                last time consumption/overall running time: 287.4724s / 27779.5568 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0167
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0165
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1135.7,                last time consumption/overall running time: 279.4523s / 28059.0090 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0176
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0166
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1150.7,                last time consumption/overall running time: 282.4766s / 28341.4857 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0180
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0169
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1155.05,                last time consumption/overall running time: 282.8379s / 28624.3236 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0182
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0169
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1170.95,                last time consumption/overall running time: 285.3517s / 28909.6753 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0183
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0171
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1191.15,                last time consumption/overall running time: 291.7763s / 29201.4515 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0177
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0172
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1128.65,                last time consumption/overall running time: 277.8212s / 29479.2727 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0178
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0174
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1138.75,                last time consumption/overall running time: 280.7364s / 29760.0092 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0181
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0187
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 1227.15,                last time consumption/overall running time: 300.6710s / 30060.6802 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0180
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0186
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1145.9,                last time consumption/overall running time: 280.8663s / 30341.5465 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0178
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0192
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1184.0,                last time consumption/overall running time: 287.1531s / 30628.6996 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0180
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0193
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1204.05,                last time consumption/overall running time: 298.5155s / 30927.2151 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0178
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0193
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 1147.1,                last time consumption/overall running time: 288.2881s / 31215.5032 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0176
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0182
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 1158.65,                last time consumption/overall running time: 288.0932s / 31503.5964 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0177
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0176
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 1196.1,                last time consumption/overall running time: 291.1964s / 31794.7928 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0177
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0178
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 1158.75,                last time consumption/overall running time: 284.4578s / 32079.2506 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0181
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0173
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 1174.55,                last time consumption/overall running time: 281.5628s / 32360.8134 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0183
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0157
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1145.65,                last time consumption/overall running time: 278.0517s / 32638.8651 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0187
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0155
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1140.6,                last time consumption/overall running time: 276.7823s / 32915.6474 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0175
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0163
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1140.85,                last time consumption/overall running time: 281.6102s / 33197.2576 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0163
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0161
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1125.15,                last time consumption/overall running time: 278.7860s / 33476.0436 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0163
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0158
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 1183.6,                last time consumption/overall running time: 293.4003s / 33769.4439 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0164
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0167
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1188.05,                last time consumption/overall running time: 296.3426s / 34065.7864 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0163
env0_second_0:                 episode reward: 5.7000,                 loss: 0.0177
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1116.7,                last time consumption/overall running time: 275.2594s / 34341.0458 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0168
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1137.7,                last time consumption/overall running time: 281.5198s / 34622.5656 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0172
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0176
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1173.4,                last time consumption/overall running time: 286.0916s / 34908.6572 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0187
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0186
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1172.2,                last time consumption/overall running time: 288.0831s / 35196.7403 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0183
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0184
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 1130.15,                last time consumption/overall running time: 275.9627s / 35472.7030 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0174
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0179
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1155.35,                last time consumption/overall running time: 284.0034s / 35756.7065 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0162
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0174
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1116.35,                last time consumption/overall running time: 272.0309s / 36028.7374 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0152
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0169
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1177.6,                last time consumption/overall running time: 287.8338s / 36316.5712 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0151
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0166
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1123.25,                last time consumption/overall running time: 278.5286s / 36595.0998 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0154
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0161
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1107.0,                last time consumption/overall running time: 273.0382s / 36868.1380 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0144
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0157
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1148.55,                last time consumption/overall running time: 286.3482s / 37154.4862 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0155
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0160
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 1156.15,                last time consumption/overall running time: 283.7357s / 37438.2219 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0166
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0156
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1153.4,                last time consumption/overall running time: 290.9140s / 37729.1359 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0178
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0161
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 1160.0,                last time consumption/overall running time: 292.5680s / 38021.7039 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0181
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0170
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1205.25,                last time consumption/overall running time: 299.5089s / 38321.2127 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0174
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0174
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1187.15,                last time consumption/overall running time: 295.9863s / 38617.1990 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0180
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0184
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 1180.45,                last time consumption/overall running time: 297.1697s / 38914.3687 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0169
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0179
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1187.6,                last time consumption/overall running time: 302.3970s / 39216.7657 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0181
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0181
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1169.05,                last time consumption/overall running time: 293.7787s / 39510.5444 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0184
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0196
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1219.5,                last time consumption/overall running time: 302.8718s / 39813.4162 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0189
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0195
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1135.8,                last time consumption/overall running time: 282.2508s / 40095.6670 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0190
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0194
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1162.95,                last time consumption/overall running time: 309.4109s / 40405.0779 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0182
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0183
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1136.35,                last time consumption/overall running time: 301.3181s / 40706.3960 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0176
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0181
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1174.35,                last time consumption/overall running time: 306.3161s / 41012.7120 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0180
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0179
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 1131.15,                last time consumption/overall running time: 294.9617s / 41307.6738 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0184
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0182
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1150.7,                last time consumption/overall running time: 304.9384s / 41612.6121 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0169
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0175
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 1138.3,                last time consumption/overall running time: 294.1315s / 41906.7436 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0160
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0153
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1164.45,                last time consumption/overall running time: 306.4329s / 42213.1765 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0157
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0155
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1260.85,                last time consumption/overall running time: 323.6765s / 42536.8530 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.0178
env0_second_0:                 episode reward: 4.8500,                 loss: 0.0165
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1185.05,                last time consumption/overall running time: 307.8837s / 42844.7368 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0187
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0173
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1144.7,                last time consumption/overall running time: 296.0684s / 43140.8052 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0180
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0170
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1170.45,                last time consumption/overall running time: 306.3512s / 43447.1564 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0180
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0162
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1102.4,                last time consumption/overall running time: 290.9744s / 43738.1308 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.0169
env0_second_0:                 episode reward: 8.8500,                 loss: 0.0152
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1138.45,                last time consumption/overall running time: 294.7487s / 44032.8795 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0159
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0151
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1153.45,                last time consumption/overall running time: 300.3805s / 44333.2600 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0165
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0166
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1185.5,                last time consumption/overall running time: 295.1058s / 44628.3658 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0173
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0174
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1151.6,                last time consumption/overall running time: 288.8900s / 44917.2558 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0185
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0172
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1140.5,                last time consumption/overall running time: 281.1490s / 45198.4048 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0181
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0164
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1156.0,                last time consumption/overall running time: 289.6211s / 45488.0260 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0178
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1102.5,                last time consumption/overall running time: 274.5323s / 45762.5583 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0178
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0179
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1152.9,                last time consumption/overall running time: 289.9796s / 46052.5378 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0174
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0168
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1214.7,                last time consumption/overall running time: 304.7102s / 46357.2480 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0168
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0174
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1167.65,                last time consumption/overall running time: 293.1035s / 46650.3515 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0174
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0176
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1138.9,                last time consumption/overall running time: 289.4940s / 46939.8456 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0169
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0172
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1116.75,                last time consumption/overall running time: 276.6164s / 47216.4619 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0172
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0161
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1128.8,                last time consumption/overall running time: 277.9124s / 47494.3743 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0171
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0160
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1189.2,                last time consumption/overall running time: 297.8531s / 47792.2274 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0176
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0152
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1192.35,                last time consumption/overall running time: 295.7143s / 48087.9417 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0185
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0155
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1199.1,                last time consumption/overall running time: 293.1778s / 48381.1195 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0192
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0167
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1157.4,                last time consumption/overall running time: 285.2183s / 48666.3378 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0183
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0171
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1135.3,                last time consumption/overall running time: 285.5282s / 48951.8661 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0181
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0175
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1187.1,                last time consumption/overall running time: 293.9851s / 49245.8512 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0178
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0175
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1210.15,                last time consumption/overall running time: 294.3048s / 49540.1560 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0176
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0174
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1171.65,                last time consumption/overall running time: 291.1679s / 49831.3239 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0179
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0183
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1179.65,                last time consumption/overall running time: 294.9066s / 50126.2305 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0176
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0182
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 1139.0,                last time consumption/overall running time: 287.6217s / 50413.8522 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0178
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0195
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1160.15,                last time consumption/overall running time: 295.7226s / 50709.5748 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0174
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0185
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1128.9,                last time consumption/overall running time: 281.5506s / 50991.1254 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0171
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0175
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1161.65,                last time consumption/overall running time: 294.4787s / 51285.6042 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0176
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0177
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1196.95,                last time consumption/overall running time: 301.0348s / 51586.6390 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0186
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0170
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1192.1,                last time consumption/overall running time: 301.6590s / 51888.2980 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0176
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0168
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1162.0,                last time consumption/overall running time: 291.6779s / 52179.9758 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0173
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1154.85,                last time consumption/overall running time: 284.4554s / 52464.4312 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0174
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0178
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1112.25,                last time consumption/overall running time: 283.1058s / 52747.5370 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0167
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0171
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1155.35,                last time consumption/overall running time: 289.4050s / 53036.9420 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0171
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0164
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1148.55,                last time consumption/overall running time: 281.5149s / 53318.4569 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0179
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0156
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1201.2,                last time consumption/overall running time: 298.5507s / 53617.0076 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.0180
env0_second_0:                 episode reward: 6.4000,                 loss: 0.0164
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 1215.9,                last time consumption/overall running time: 303.2036s / 53920.2112 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0185
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0180
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 1248.9,                last time consumption/overall running time: 315.0428s / 54235.2540 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0191
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0192
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1142.15,                last time consumption/overall running time: 286.5280s / 54521.7820 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0197
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0182
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1191.9,                last time consumption/overall running time: 302.0748s / 54823.8568 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0197
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0175
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 1221.3,                last time consumption/overall running time: 313.4380s / 55137.2949 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0190
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0168
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1155.45,                last time consumption/overall running time: 296.6047s / 55433.8995 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0190
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0171
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1177.65,                last time consumption/overall running time: 302.6810s / 55736.5805 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0185
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0172
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1140.0,                last time consumption/overall running time: 288.0436s / 56024.6241 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0186
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0176
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1166.6,                last time consumption/overall running time: 297.4008s / 56322.0249 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0189
env0_second_0:                 episode reward: 5.8000,                 loss: 0.0180
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1200.2,                last time consumption/overall running time: 298.0052s / 56620.0301 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0188
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0181
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1131.95,                last time consumption/overall running time: 280.1950s / 56900.2251 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0187
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0176
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1207.1,                last time consumption/overall running time: 305.6140s / 57205.8391 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0190
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0179
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1193.6,                last time consumption/overall running time: 300.2816s / 57506.1207 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0201
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0178
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 1169.65,                last time consumption/overall running time: 297.5445s / 57803.6652 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0196
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0176
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1154.9,                last time consumption/overall running time: 290.3864s / 58094.0516 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0205
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0180
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1127.6,                last time consumption/overall running time: 281.5371s / 58375.5886 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0189
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0181
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 1167.65,                last time consumption/overall running time: 296.2324s / 58671.8210 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0171
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 1212.1,                last time consumption/overall running time: 304.5151s / 58976.3361 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0168
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0169
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 1152.35,                last time consumption/overall running time: 295.8301s / 59272.1661 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0160
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0169
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1157.25,                last time consumption/overall running time: 289.2615s / 59561.4277 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0165
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0174
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 1168.95,                last time consumption/overall running time: 298.1900s / 59859.6177 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0174
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0173
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1167.8,                last time consumption/overall running time: 300.3132s / 60159.9308 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0171
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0176
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 1147.7,                last time consumption/overall running time: 291.2427s / 60451.1735 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0171
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0161
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 1152.25,                last time consumption/overall running time: 291.8195s / 60742.9930 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0179
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0157
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 1174.0,                last time consumption/overall running time: 297.2340s / 61040.2270 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0184
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0165
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 1181.3,                last time consumption/overall running time: 300.3617s / 61340.5887 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0183
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0179
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 1171.35,                last time consumption/overall running time: 295.9397s / 61636.5284 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0187
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0202
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 1152.45,                last time consumption/overall running time: 295.8595s / 61932.3879 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0197
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0193
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 1148.9,                last time consumption/overall running time: 291.4545s / 62223.8424 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0191
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0182
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 1176.35,                last time consumption/overall running time: 302.3930s / 62526.2354 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0187
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0177
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 1183.4,                last time consumption/overall running time: 307.3485s / 62833.5839 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0184
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0168
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 1142.05,                last time consumption/overall running time: 293.1257s / 63126.7096 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0175
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0172
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1218.1,                last time consumption/overall running time: 299.9284s / 63426.6380 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0170
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0171
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1144.1,                last time consumption/overall running time: 284.0694s / 63710.7074 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0169
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0176
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1179.0,                last time consumption/overall running time: 291.9435s / 64002.6509 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0176
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0177
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 1159.75,                last time consumption/overall running time: 290.4055s / 64293.0564 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0179
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0174
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1193.9,                last time consumption/overall running time: 295.6910s / 64588.7474 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0184
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0177
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1178.45,                last time consumption/overall running time: 298.9750s / 64887.7224 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0179
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0186
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1157.55,                last time consumption/overall running time: 287.5362s / 65175.2586 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0180
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0185
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1211.75,                last time consumption/overall running time: 300.1976s / 65475.4562 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0180
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0184
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1247.85,                last time consumption/overall running time: 309.9483s / 65785.4045 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0184
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0188
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1199.75,                last time consumption/overall running time: 316.7098s / 66102.1143 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0186
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0192
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1199.85,                last time consumption/overall running time: 298.8217s / 66400.9360 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0185
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0191
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1162.0,                last time consumption/overall running time: 289.2800s / 66690.2160 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0188
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0186
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1179.95,                last time consumption/overall running time: 301.9415s / 66992.1574 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0189
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0178
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1190.6,                last time consumption/overall running time: 310.2414s / 67302.3988 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0194
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0193
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1151.2,                last time consumption/overall running time: 292.9367s / 67595.3355 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0195
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0197
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1193.2,                last time consumption/overall running time: 301.4526s / 67896.7881 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0183
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0194
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1239.5,                last time consumption/overall running time: 308.7059s / 68205.4940 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0189
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0200
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1149.35,                last time consumption/overall running time: 293.2771s / 68498.7711 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0179
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0199
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1130.2,                last time consumption/overall running time: 285.6991s / 68784.4702 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0176
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0182
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1166.7,                last time consumption/overall running time: 299.4803s / 69083.9505 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0174
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0179
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1191.6,                last time consumption/overall running time: 302.5838s / 69386.5344 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0179
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0177
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1135.65,                last time consumption/overall running time: 287.9355s / 69674.4699 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0172
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1198.8,                last time consumption/overall running time: 294.1683s / 69968.6381 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0171
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0175
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1134.25,                last time consumption/overall running time: 286.6134s / 70255.2515 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0183
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0179
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1108.4,                last time consumption/overall running time: 270.2163s / 70525.4678 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0185
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0176
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1281.8,                last time consumption/overall running time: 324.4640s / 70849.9317 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0180
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0182
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 1185.25,                last time consumption/overall running time: 296.1476s / 71146.0793 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0179
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0184
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1221.8,                last time consumption/overall running time: 311.0618s / 71457.1411 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0178
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0181
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1170.2,                last time consumption/overall running time: 296.2623s / 71753.4034 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0180
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0177
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1220.75,                last time consumption/overall running time: 310.4820s / 72063.8854 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.0184
env0_second_0:                 episode reward: 5.7500,                 loss: 0.0176
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 1118.9,                last time consumption/overall running time: 283.3684s / 72347.2538 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0187
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0175
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1165.8,                last time consumption/overall running time: 292.9471s / 72640.2009 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0179
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0168
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1148.3,                last time consumption/overall running time: 286.1138s / 72926.3147 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0177
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0184
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 1230.3,                last time consumption/overall running time: 311.0658s / 73237.3805 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0180
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1176.55,                last time consumption/overall running time: 286.8960s / 73524.2765 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0182
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0165
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1202.8,                last time consumption/overall running time: 301.6008s / 73825.8774 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0177
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0164
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1182.5,                last time consumption/overall running time: 314.1753s / 74140.0527 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0179
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0168
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 1176.35,                last time consumption/overall running time: 296.1108s / 74436.1635 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0168
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0164
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1140.3,                last time consumption/overall running time: 293.7324s / 74729.8960 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0165
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0160
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1159.9,                last time consumption/overall running time: 295.2395s / 75025.1354 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0166
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0165
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1135.2,                last time consumption/overall running time: 288.0039s / 75313.1393 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0163
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0162
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1196.45,                last time consumption/overall running time: 303.5499s / 75616.6892 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0166
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0162
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1158.95,                last time consumption/overall running time: 293.9582s / 75910.6475 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0158
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0174
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1151.85,                last time consumption/overall running time: 291.9250s / 76202.5725 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0167
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0187
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1204.65,                last time consumption/overall running time: 296.0741s / 76498.6466 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.0171
env0_second_0:                 episode reward: 6.5500,                 loss: 0.0186
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1197.35,                last time consumption/overall running time: 298.6648s / 76797.3114 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0173
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0179
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1124.25,                last time consumption/overall running time: 278.6174s / 77075.9288 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0173
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0171
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1185.75,                last time consumption/overall running time: 295.3354s / 77371.2641 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0173
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0161
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1157.8,                last time consumption/overall running time: 292.5971s / 77663.8612 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0168
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0165
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 1135.2,                last time consumption/overall running time: 285.7528s / 77949.6140 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0161
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0168
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 1197.55,                last time consumption/overall running time: 301.7938s / 78251.4078 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0175
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0164
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 1117.6,                last time consumption/overall running time: 279.1083s / 78530.5160 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0185
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0172
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 1156.8,                last time consumption/overall running time: 292.9158s / 78823.4318 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0179
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0171
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 1212.75,                last time consumption/overall running time: 310.9285s / 79134.3603 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0177
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0180
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 1155.2,                last time consumption/overall running time: 286.3523s / 79420.7126 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0187
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0181
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1170.8,                last time consumption/overall running time: 295.1192s / 79715.8319 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0169
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1172.1,                last time consumption/overall running time: 298.7510s / 80014.5829 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0161
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0164
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 1156.4,                last time consumption/overall running time: 295.4003s / 80309.9831 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0164
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0163
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1172.0,                last time consumption/overall running time: 295.2922s / 80605.2753 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0163
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0163
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 1151.0,                last time consumption/overall running time: 295.6054s / 80900.8807 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0167
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0163
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1148.7,                last time consumption/overall running time: 289.2653s / 81190.1461 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0176
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0163
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1168.7,                last time consumption/overall running time: 295.3899s / 81485.5359 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0166
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0168
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 1161.95,                last time consumption/overall running time: 299.0878s / 81784.6238 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0170
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0171
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 1230.1,                last time consumption/overall running time: 313.6868s / 82098.3105 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0175
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0172
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 1190.2,                last time consumption/overall running time: 303.1957s / 82401.5062 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0184
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0179
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 1235.95,                last time consumption/overall running time: 315.8030s / 82717.3092 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0178
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0187
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 1256.7,                last time consumption/overall running time: 308.5980s / 83025.9072 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.0186
env0_second_0:                 episode reward: 6.2000,                 loss: 0.0202
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 1288.0,                last time consumption/overall running time: 326.6982s / 83352.6054 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0209
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0242
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 1188.85,                last time consumption/overall running time: 301.8315s / 83654.4369 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0226
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0236
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 1149.0,                last time consumption/overall running time: 287.6267s / 83942.0635 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0216
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0218
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 1186.3,                last time consumption/overall running time: 299.0863s / 84241.1499 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0211
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0220
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 1103.65,                last time consumption/overall running time: 283.7677s / 84524.9175 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0183
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0198
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 1189.6,                last time consumption/overall running time: 300.1318s / 84825.0493 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0165
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0187
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 1198.35,                last time consumption/overall running time: 296.7513s / 85121.8006 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0166
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0193
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 1114.9,                last time consumption/overall running time: 276.7860s / 85398.5867 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0171
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0183
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 1181.75,                last time consumption/overall running time: 296.6869s / 85695.2736 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0173
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0174
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 1167.25,                last time consumption/overall running time: 292.4582s / 85987.7318 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0171
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0173
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 1168.45,                last time consumption/overall running time: 293.5952s / 86281.3270 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0172
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0168
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 1169.85,                last time consumption/overall running time: 297.4548s / 86578.7818 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0161
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0168
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 1201.6,                last time consumption/overall running time: 312.5581s / 86891.3399 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0160
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0162
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 1236.35,                last time consumption/overall running time: 308.5525s / 87199.8924 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0169
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0166
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 1185.1,                last time consumption/overall running time: 294.9295s / 87494.8219 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0167
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0183
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1178.1,                last time consumption/overall running time: 298.4509s / 87793.2728 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0170
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0193
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 1154.5,                last time consumption/overall running time: 297.8010s / 88091.0738 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0170
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0188
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 1153.45,                last time consumption/overall running time: 288.5042s / 88379.5780 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0173
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0178
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 1152.75,                last time consumption/overall running time: 290.4453s / 88670.0233 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0168
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0174
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 1170.25,                last time consumption/overall running time: 296.9846s / 88967.0079 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0175
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0176
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 1182.25,                last time consumption/overall running time: 293.7524s / 89260.7603 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0171
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0169
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 1142.45,                last time consumption/overall running time: 278.4182s / 89539.1785 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0171
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0172
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 1233.3,                last time consumption/overall running time: 301.6387s / 89840.8173 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0172
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 1172.3,                last time consumption/overall running time: 294.2903s / 90135.1076 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0173
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0167
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 1195.4,                last time consumption/overall running time: 305.3137s / 90440.4213 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0168
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0160
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 1225.85,                last time consumption/overall running time: 313.3030s / 90753.7242 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0171
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0170
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 1173.1,                last time consumption/overall running time: 297.8190s / 91051.5433 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0174
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0172
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 1209.4,                last time consumption/overall running time: 307.5191s / 91359.0624 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0183
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0179
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 1208.6,                last time consumption/overall running time: 310.6998s / 91669.7623 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0182
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0185
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 1198.15,                last time consumption/overall running time: 310.3783s / 91980.1406 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0182
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0180
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 1216.1,                last time consumption/overall running time: 313.8876s / 92294.0282 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0178
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0178
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 1158.8,                last time consumption/overall running time: 296.0791s / 92590.1073 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0173
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0183
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 1178.2,                last time consumption/overall running time: 298.0850s / 92888.1923 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0172
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0181
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 1174.5,                last time consumption/overall running time: 292.9730s / 93181.1653 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0167
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0180
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 1165.7,                last time consumption/overall running time: 292.6840s / 93473.8493 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0176
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0191
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 1218.75,                last time consumption/overall running time: 314.7396s / 93788.5889 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0178
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0189
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 1177.3,                last time consumption/overall running time: 293.6502s / 94082.2391 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0186
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0178
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 1197.0,                last time consumption/overall running time: 301.6265s / 94383.8656 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0173
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0180
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 1187.35,                last time consumption/overall running time: 299.0283s / 94682.8939 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0166
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0179
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 1192.8,                last time consumption/overall running time: 301.4349s / 94984.3288 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0160
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0176
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 1222.4,                last time consumption/overall running time: 310.3912s / 95294.7200 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0166
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0174
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 1133.95,                last time consumption/overall running time: 292.4886s / 95587.2086 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0168
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0174
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 1209.1,                last time consumption/overall running time: 305.8696s / 95893.0782 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0179
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0180
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 1203.55,                last time consumption/overall running time: 298.6844s / 96191.7626 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0185
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0189
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 1187.85,                last time consumption/overall running time: 291.1758s / 96482.9385 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0185
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0192
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 1214.05,                last time consumption/overall running time: 305.2487s / 96788.1872 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0180
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0191
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 1215.45,                last time consumption/overall running time: 318.1055s / 97106.2926 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0187
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0198
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 1213.1,                last time consumption/overall running time: 305.0344s / 97411.3270 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0186
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0202
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 1133.85,                last time consumption/overall running time: 288.0475s / 97699.3745 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0177
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0189
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 1218.25,                last time consumption/overall running time: 307.2866s / 98006.6610 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0182
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0189
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 1191.6,                last time consumption/overall running time: 290.8697s / 98297.5308 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0186
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0193
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 1212.3,                last time consumption/overall running time: 300.1671s / 98597.6979 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0182
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0194
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 1187.0,                last time consumption/overall running time: 311.1986s / 98908.8965 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0194
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0209
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 1173.6,                last time consumption/overall running time: 304.7334s / 99213.6298 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0196
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0201
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 1209.75,                last time consumption/overall running time: 301.3907s / 99515.0205 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0189
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0195
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 1203.35,                last time consumption/overall running time: 307.3065s / 99822.3271 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0192
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0204
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 1136.7,                last time consumption/overall running time: 293.0390s / 100115.3660 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0178
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0190
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1192.7,                last time consumption/overall running time: 297.8139s / 100413.1799 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0166
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0178
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 1147.95,                last time consumption/overall running time: 290.6152s / 100703.7952 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0161
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0171
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 1184.45,                last time consumption/overall running time: 297.1347s / 101000.9299 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0169
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0166
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 1175.95,                last time consumption/overall running time: 298.5735s / 101299.5034 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0177
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0174
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 1159.1,                last time consumption/overall running time: 299.1713s / 101598.6748 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0174
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0181
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 1140.8,                last time consumption/overall running time: 285.3041s / 101883.9789 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0179
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0175
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 1158.3,                last time consumption/overall running time: 292.5146s / 102176.4935 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0162
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0170
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 1139.1,                last time consumption/overall running time: 289.9512s / 102466.4447 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0153
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0166
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 1162.8,                last time consumption/overall running time: 291.3085s / 102757.7531 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0156
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0163
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 1169.4,                last time consumption/overall running time: 299.4641s / 103057.2173 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0169
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0174
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 1169.6,                last time consumption/overall running time: 296.2610s / 103353.4782 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0174
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0180
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 1222.25,                last time consumption/overall running time: 308.4194s / 103661.8976 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0182
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0189
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 1166.6,                last time consumption/overall running time: 290.0215s / 103951.9191 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0187
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0184
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 1205.05,                last time consumption/overall running time: 301.8143s / 104253.7334 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0191
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0175
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 1128.9,                last time consumption/overall running time: 282.2770s / 104536.0104 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0178
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0181
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 1201.8,                last time consumption/overall running time: 300.9891s / 104836.9995 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0181
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0182
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 1179.1,                last time consumption/overall running time: 295.0840s / 105132.0835 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0183
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0186
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 1185.45,                last time consumption/overall running time: 304.3150s / 105436.3985 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0181
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0186
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 1154.15,                last time consumption/overall running time: 289.9256s / 105726.3241 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0172
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0181
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 1219.45,                last time consumption/overall running time: 317.5051s / 106043.8291 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0179
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0172
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 1276.2,                last time consumption/overall running time: 325.1419s / 106368.9711 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0198
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0184
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 1183.95,                last time consumption/overall running time: 304.4851s / 106673.4562 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0188
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0190
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 1158.4,                last time consumption/overall running time: 293.9337s / 106967.3899 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0187
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0178
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 1170.8,                last time consumption/overall running time: 295.1295s / 107262.5194 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0186
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0177
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 1141.15,                last time consumption/overall running time: 283.9566s / 107546.4760 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0174
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0172
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 1105.45,                last time consumption/overall running time: 287.0756s / 107833.5516 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0160
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0165
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 1201.15,                last time consumption/overall running time: 301.4169s / 108134.9686 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0159
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0165
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 1198.45,                last time consumption/overall running time: 303.3654s / 108438.3340 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0162
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0162
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 1187.5,                last time consumption/overall running time: 294.2433s / 108732.5774 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0159
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0164
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 1144.95,                last time consumption/overall running time: 292.1530s / 109024.7303 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0156
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0155
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 1159.45,                last time consumption/overall running time: 288.7937s / 109313.5240 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0160
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0159
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 1120.95,                last time consumption/overall running time: 290.4564s / 109603.9804 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0162
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0161
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 1186.35,                last time consumption/overall running time: 292.5166s / 109896.4970 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0158
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0154
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 1160.75,                last time consumption/overall running time: 288.1047s / 110184.6018 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0155
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0151
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 1249.1,                last time consumption/overall running time: 309.6626s / 110494.2643 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0159
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0156
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 1189.0,                last time consumption/overall running time: 301.8294s / 110796.0937 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0161
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0158
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 1188.1,                last time consumption/overall running time: 296.9854s / 111093.0791 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0167
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0167
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 1174.6,                last time consumption/overall running time: 289.6307s / 111382.7098 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0171
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0164
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 1140.55,                last time consumption/overall running time: 281.7769s / 111664.4866 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0173
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0164
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 1164.25,                last time consumption/overall running time: 284.7671s / 111949.2538 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0171
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0163
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 1145.0,                last time consumption/overall running time: 283.7426s / 112232.9963 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0162
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0157
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 1177.55,                last time consumption/overall running time: 296.6718s / 112529.6681 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0158
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0156
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 1165.25,                last time consumption/overall running time: 288.6728s / 112818.3408 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0154
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0158
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 1115.35,                last time consumption/overall running time: 272.5937s / 113090.9345 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0151
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0150
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 1160.6,                last time consumption/overall running time: 283.5531s / 113374.4877 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0151
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0146
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 1142.85,                last time consumption/overall running time: 281.8081s / 113656.2958 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0156
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0153
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 1141.8,                last time consumption/overall running time: 296.4111s / 113952.7069 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0153
env0_second_0:                 episode reward: 8.6500,                 loss: 0.0155
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 1200.5,                last time consumption/overall running time: 299.7900s / 114252.4969 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0154
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0159
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 1206.2,                last time consumption/overall running time: 308.2097s / 114560.7066 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0167
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0164
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 1147.55,                last time consumption/overall running time: 284.0002s / 114844.7068 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0169
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0168
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 1196.1,                last time consumption/overall running time: 293.2842s / 115137.9910 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0173
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0170
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 1258.45,                last time consumption/overall running time: 309.0025s / 115446.9935 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0176
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0182
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 1144.5,                last time consumption/overall running time: 287.1204s / 115734.1139 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0181
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0176
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 1171.25,                last time consumption/overall running time: 288.2495s / 116022.3634 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0180
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0173
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 1128.85,                last time consumption/overall running time: 277.1813s / 116299.5447 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0170
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0169
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 1169.65,                last time consumption/overall running time: 299.2275s / 116598.7722 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0172
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0165
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 1175.65,                last time consumption/overall running time: 285.8348s / 116884.6070 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0158
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0167
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 1159.0,                last time consumption/overall running time: 285.4377s / 117170.0447 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0157
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0169
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 1156.95,                last time consumption/overall running time: 288.1849s / 117458.2295 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0155
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0177
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 1153.2,                last time consumption/overall running time: 282.6720s / 117740.9015 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0161
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0174
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 1167.2,                last time consumption/overall running time: 288.6837s / 118029.5852 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0160
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0171
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 1214.2,                last time consumption/overall running time: 305.7081s / 118335.2933 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0171
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 1214.45,                last time consumption/overall running time: 300.8104s / 118636.1036 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0175
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0186
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 1187.55,                last time consumption/overall running time: 298.5413s / 118934.6449 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0180
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0182
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 1209.4,                last time consumption/overall running time: 301.2022s / 119235.8472 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0186
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0184
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 1178.2,                last time consumption/overall running time: 296.0815s / 119531.9286 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0181
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0183
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 1144.45,                last time consumption/overall running time: 282.6983s / 119814.6269 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0182
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0180
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 1146.5,                last time consumption/overall running time: 282.9040s / 120097.5310 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0165
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0169
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 1243.1,                last time consumption/overall running time: 309.0157s / 120406.5467 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0170
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0171
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 1157.45,                last time consumption/overall running time: 291.8981s / 120698.4448 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0157
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0175
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 1119.75,                last time consumption/overall running time: 280.1079s / 120978.5527 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0161
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0171
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 1137.35,                last time consumption/overall running time: 280.9732s / 121259.5259 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0169
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0179
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 1218.0,                last time consumption/overall running time: 304.5427s / 121564.0686 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0171
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0175
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 1121.65,                last time consumption/overall running time: 273.8429s / 121837.9115 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0165
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0164
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 1242.45,                last time consumption/overall running time: 305.4355s / 122143.3470 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0178
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0169
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 1237.75,                last time consumption/overall running time: 307.2453s / 122450.5923 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0170
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0171
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 1188.85,                last time consumption/overall running time: 291.1720s / 122741.7643 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0182
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0182
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 1162.7,                last time consumption/overall running time: 293.8267s / 123035.5910 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0180
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0191
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 1206.35,                last time consumption/overall running time: 299.2075s / 123334.7985 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0190
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0190
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 1160.2,                last time consumption/overall running time: 286.5773s / 123621.3758 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0187
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0178
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 1178.85,                last time consumption/overall running time: 291.1873s / 123912.5631 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0181
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0179
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 1183.1,                last time consumption/overall running time: 297.7876s / 124210.3507 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0179
env0_second_0:                 episode reward: 7.5000,                 loss: 0.0178
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 1222.7,                last time consumption/overall running time: 301.6930s / 124512.0437 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0184
env0_second_0:                 episode reward: 6.7500,                 loss: 0.0178
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 1243.0,                last time consumption/overall running time: 308.4756s / 124820.5193 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0182
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0184
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 1187.4,                last time consumption/overall running time: 294.6367s / 125115.1560 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0201
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0199
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 1188.4,                last time consumption/overall running time: 293.8948s / 125409.0508 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0199
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0200
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 1236.85,                last time consumption/overall running time: 305.7208s / 125714.7716 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0198
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0198
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 1176.3,                last time consumption/overall running time: 294.1682s / 126008.9398 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0193
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0197
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 1187.65,                last time consumption/overall running time: 297.4449s / 126306.3847 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0187
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0193
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 1181.85,                last time consumption/overall running time: 293.2872s / 126599.6718 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0181
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0175
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 1165.35,                last time consumption/overall running time: 287.3565s / 126887.0283 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0169
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0169
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 1161.1,                last time consumption/overall running time: 298.8462s / 127185.8745 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0177
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0173
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 1225.3,                last time consumption/overall running time: 306.0982s / 127491.9727 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.0185
env0_second_0:                 episode reward: 5.6500,                 loss: 0.0174
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 1213.55,                last time consumption/overall running time: 299.6081s / 127791.5808 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.0191
env0_second_0:                 episode reward: 6.2000,                 loss: 0.0181
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 1271.45,                last time consumption/overall running time: 320.1110s / 128111.6918 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0194
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0188
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 1219.9,                last time consumption/overall running time: 311.4898s / 128423.1816 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.0196
env0_second_0:                 episode reward: 6.5000,                 loss: 0.0184
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 1167.5,                last time consumption/overall running time: 288.2627s / 128711.4443 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0193
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0182
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 1215.05,                last time consumption/overall running time: 303.1371s / 129014.5814 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0188
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0185
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 1186.15,                last time consumption/overall running time: 291.8740s / 129306.4554 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0178
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0187
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 1225.8,                last time consumption/overall running time: 308.4908s / 129614.9461 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0174
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0181
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 1249.6,                last time consumption/overall running time: 302.7831s / 129917.7292 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0175
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0193
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 1152.4,                last time consumption/overall running time: 282.3586s / 130200.0878 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0174
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0190
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 1215.15,                last time consumption/overall running time: 298.5835s / 130498.6713 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0168
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0180
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 1228.65,                last time consumption/overall running time: 308.7886s / 130807.4599 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0169
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0185
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 1220.6,                last time consumption/overall running time: 307.4857s / 131114.9456 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0168
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0180
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 1190.45,                last time consumption/overall running time: 292.9648s / 131407.9104 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0169
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0172
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 1215.9,                last time consumption/overall running time: 300.5292s / 131708.4395 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0161
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0165
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 1210.8,                last time consumption/overall running time: 294.6950s / 132003.1345 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0158
env0_second_0:                 episode reward: 7.8000,                 loss: 0.0166
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 1251.15,                last time consumption/overall running time: 307.6072s / 132310.7417 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0160
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0177
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 1191.0,                last time consumption/overall running time: 296.5923s / 132607.3341 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0163
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0180
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 1174.0,                last time consumption/overall running time: 289.2483s / 132896.5824 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0155
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0174
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 1164.85,                last time consumption/overall running time: 291.4078s / 133187.9901 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0150
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0171
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 1211.4,                last time consumption/overall running time: 303.6865s / 133491.6766 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0156
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0164
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 1157.85,                last time consumption/overall running time: 296.8097s / 133788.4863 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0146
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0167
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 1162.75,                last time consumption/overall running time: 291.6209s / 134080.1072 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0143
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0159
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 1167.75,                last time consumption/overall running time: 287.2376s / 134367.3448 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0139
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0166
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 1172.85,                last time consumption/overall running time: 288.2083s / 134655.5531 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0149
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0163
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 1193.1,                last time consumption/overall running time: 297.1704s / 134952.7235 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0144
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0159
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 1149.8,                last time consumption/overall running time: 284.6693s / 135237.3929 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0149
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0157
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 1146.0,                last time consumption/overall running time: 286.9179s / 135524.3107 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0149
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0173
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 1168.45,                last time consumption/overall running time: 285.6444s / 135809.9551 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.0150
env0_second_0:                 episode reward: 7.0000,                 loss: 0.0166
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 1206.45,                last time consumption/overall running time: 296.9682s / 136106.9233 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0148
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0166
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 1225.55,                last time consumption/overall running time: 303.1566s / 136410.0800 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0154
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0161
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 1208.3,                last time consumption/overall running time: 299.8958s / 136709.9757 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0151
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0157
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 1126.25,                last time consumption/overall running time: 273.4809s / 136983.4566 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.0143
env0_second_0:                 episode reward: 8.7500,                 loss: 0.0157
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 1189.25,                last time consumption/overall running time: 289.6199s / 137273.0765 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0148
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0162
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 1209.45,                last time consumption/overall running time: 296.3329s / 137569.4094 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0150
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0165
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 1194.25,                last time consumption/overall running time: 297.1360s / 137866.5454 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0155
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0171
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 1118.55,                last time consumption/overall running time: 276.6546s / 138143.2000 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0155
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0172
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 1180.65,                last time consumption/overall running time: 296.7705s / 138439.9705 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0154
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0178
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 1249.9,                last time consumption/overall running time: 305.5396s / 138745.5100 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0154
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 1175.15,                last time consumption/overall running time: 288.9252s / 139034.4352 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.0149
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0167
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 1210.05,                last time consumption/overall running time: 297.3363s / 139331.7715 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0149
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0168
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 1161.6,                last time consumption/overall running time: 287.8124s / 139619.5840 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0150
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0170
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 1199.15,                last time consumption/overall running time: 300.5716s / 139920.1556 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0153
env0_second_0:                 episode reward: 7.9500,                 loss: 0.0169
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 1169.8,                last time consumption/overall running time: 295.4895s / 140215.6451 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0148
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0165
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 1109.2,                last time consumption/overall running time: 279.4766s / 140495.1217 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0141
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0163
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 1246.85,                last time consumption/overall running time: 323.7059s / 140818.8276 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0143
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0165
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 1179.5,                last time consumption/overall running time: 300.8283s / 141119.6559 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0145
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0164
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 1202.85,                last time consumption/overall running time: 300.0244s / 141419.6803 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0149
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0169
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 1181.4,                last time consumption/overall running time: 294.2285s / 141713.9087 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.0158
env0_second_0:                 episode reward: 7.9000,                 loss: 0.0173
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 1133.75,                last time consumption/overall running time: 278.6232s / 141992.5319 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0160
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0176
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 1189.1,                last time consumption/overall running time: 296.9030s / 142289.4349 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0161
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0177
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 1174.3,                last time consumption/overall running time: 294.6698s / 142584.1047 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0162
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0172
env1_first_0:                 episode reward: -7.2000,                 loss: nanLoad surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
Load surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 1245.35,                last time consumption/overall running time: 306.5417s / 142890.6465 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0166
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0171
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 1204.75,                last time consumption/overall running time: 304.9296s / 143195.5760 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0172
env0_second_0:                 episode reward: 7.6000,                 loss: 0.0170
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 1260.9,                last time consumption/overall running time: 308.2389s / 143503.8150 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0172
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0170
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 1216.25,                last time consumption/overall running time: 298.1602s / 143801.9752 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0166
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0176
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 1204.55,                last time consumption/overall running time: 292.7515s / 144094.7267 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0165
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0179
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 1248.95,                last time consumption/overall running time: 309.2889s / 144404.0156 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0168
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0178
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 1211.65,                last time consumption/overall running time: 306.6746s / 144710.6902 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0179
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0171
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 1161.85,                last time consumption/overall running time: 287.8368s / 144998.5270 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0175
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0168
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 1207.1,                last time consumption/overall running time: 295.4912s / 145294.0182 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0169
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0176
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 1217.8,                last time consumption/overall running time: 299.4469s / 145593.4651 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0171
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0181
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 1180.05,                last time consumption/overall running time: 287.8406s / 145881.3057 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0175
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0178
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
