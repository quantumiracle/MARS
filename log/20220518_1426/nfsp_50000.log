pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f19b77b9ba8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/50000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/50000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_50000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_50000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6808s / 0.6808 s
agent0:                 episode reward: 1.3458,                 loss: nan
agent1:                 episode reward: -1.3458,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 0.8797 s
agent0:                 episode reward: 0.2544,                 loss: nan
agent1:                 episode reward: -0.2544,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 1.0772 s
agent0:                 episode reward: 0.6625,                 loss: nan
agent1:                 episode reward: -0.6625,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 1.2714 s
agent0:                 episode reward: 0.4071,                 loss: nan
agent1:                 episode reward: -0.4071,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 1.4691 s
agent0:                 episode reward: 0.0961,                 loss: nan
agent1:                 episode reward: -0.0961,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 1.6697 s
agent0:                 episode reward: 0.3675,                 loss: nan
agent1:                 episode reward: -0.3675,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 1.8683 s
agent0:                 episode reward: -0.1114,                 loss: nan
agent1:                 episode reward: 0.1114,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 2.0706 s
agent0:                 episode reward: 0.0174,                 loss: nan
agent1:                 episode reward: -0.0174,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 2.2670 s
agent0:                 episode reward: 0.1266,                 loss: nan
agent1:                 episode reward: -0.1266,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 2.4664 s
agent0:                 episode reward: 0.3981,                 loss: nan
agent1:                 episode reward: -0.3981,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 2.6644 s
agent0:                 episode reward: 0.2188,                 loss: nan
agent1:                 episode reward: -0.2188,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 2.8652 s
agent0:                 episode reward: 0.5286,                 loss: nan
agent1:                 episode reward: -0.5286,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 3.0636 s
agent0:                 episode reward: 0.3436,                 loss: nan
agent1:                 episode reward: -0.3436,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 3.2632 s
agent0:                 episode reward: 0.0252,                 loss: nan
agent1:                 episode reward: -0.0252,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 3.4629 s
agent0:                 episode reward: 0.1047,                 loss: nan
agent1:                 episode reward: -0.1047,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 3.6621 s
agent0:                 episode reward: -0.2683,                 loss: nan
agent1:                 episode reward: 0.2683,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 3.8549 s
agent0:                 episode reward: 0.0987,                 loss: nan
agent1:                 episode reward: -0.0987,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 4.0553 s
agent0:                 episode reward: 0.0831,                 loss: nan
agent1:                 episode reward: -0.0831,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 4.2541 s
agent0:                 episode reward: 0.1652,                 loss: nan
agent1:                 episode reward: -0.1652,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 4.4482 s
agent0:                 episode reward: 0.3143,                 loss: nan
agent1:                 episode reward: -0.3143,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 4.6477 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 4.8457 s
agent0:                 episode reward: 0.0535,                 loss: nan
agent1:                 episode reward: -0.0535,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 5.0477 s
agent0:                 episode reward: 0.3112,                 loss: nan
agent1:                 episode reward: -0.3112,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 5.2476 s
agent0:                 episode reward: 0.1842,                 loss: nan
agent1:                 episode reward: -0.1842,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 5.4486 s
agent0:                 episode reward: 0.3723,                 loss: nan
agent1:                 episode reward: -0.3723,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 5.6497 s
agent0:                 episode reward: -0.1438,                 loss: nan
agent1:                 episode reward: 0.1438,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 5.8504 s
agent0:                 episode reward: 0.1961,                 loss: nan
agent1:                 episode reward: -0.1961,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 6.0537 s
agent0:                 episode reward: 0.2347,                 loss: nan
agent1:                 episode reward: -0.2347,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 6.2550 s
agent0:                 episode reward: 0.1260,                 loss: nan
agent1:                 episode reward: -0.1260,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 6.4549 s
agent0:                 episode reward: 0.2772,                 loss: nan
agent1:                 episode reward: -0.2772,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 6.6491 s
agent0:                 episode reward: 0.1906,                 loss: nan
agent1:                 episode reward: -0.1906,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 6.8470 s
agent0:                 episode reward: 0.1176,                 loss: nan
agent1:                 episode reward: -0.1176,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 7.0476 s
agent0:                 episode reward: 0.5403,                 loss: nan
agent1:                 episode reward: -0.5403,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 7.2484 s
agent0:                 episode reward: 0.2320,                 loss: nan
agent1:                 episode reward: -0.2320,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 7.4465 s
agent0:                 episode reward: -0.0011,                 loss: nan
agent1:                 episode reward: 0.0011,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 7.6400 s
agent0:                 episode reward: -0.1171,                 loss: nan
agent1:                 episode reward: 0.1171,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 7.8385 s
agent0:                 episode reward: 0.5366,                 loss: nan
agent1:                 episode reward: -0.5366,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 8.0377 s
agent0:                 episode reward: 0.2625,                 loss: nan
agent1:                 episode reward: -0.2625,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 8.2349 s
agent0:                 episode reward: 0.4544,                 loss: nan
agent1:                 episode reward: -0.4544,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 8.4336 s
agent0:                 episode reward: 0.2809,                 loss: nan
agent1:                 episode reward: -0.2809,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 8.6294 s
agent0:                 episode reward: 0.1071,                 loss: nan
agent1:                 episode reward: -0.1071,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 8.8266 s
agent0:                 episode reward: 0.4700,                 loss: nan
agent1:                 episode reward: -0.4700,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 9.0308 s
agent0:                 episode reward: 0.0734,                 loss: nan
agent1:                 episode reward: -0.0734,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 9.2294 s
agent0:                 episode reward: -0.0004,                 loss: nan
agent1:                 episode reward: 0.0004,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 9.4291 s
agent0:                 episode reward: 0.3604,                 loss: nan
agent1:                 episode reward: -0.3604,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 9.6303 s
agent0:                 episode reward: 0.5017,                 loss: nan
agent1:                 episode reward: -0.5017,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 9.8277 s
agent0:                 episode reward: 0.0181,                 loss: nan
agent1:                 episode reward: -0.0181,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 10.0251 s
agent0:                 episode reward: 0.2839,                 loss: nan
agent1:                 episode reward: -0.2839,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 10.2242 s
agent0:                 episode reward: 0.4862,                 loss: nan
agent1:                 episode reward: -0.4862,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 10.4220 s
agent0:                 episode reward: 0.6305,                 loss: nan
agent1:                 episode reward: -0.6305,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 10.6247 s
agent0:                 episode reward: 0.2742,                 loss: nan
agent1:                 episode reward: -0.2742,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 10.8275 s
agent0:                 episode reward: 0.3411,                 loss: nan
agent1:                 episode reward: -0.3411,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 11.0289 s
agent0:                 episode reward: 0.4154,                 loss: nan
agent1:                 episode reward: -0.4154,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 11.2252 s
agent0:                 episode reward: 0.1730,                 loss: nan
agent1:                 episode reward: -0.1730,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2114s / 11.4366 s
agent0:                 episode reward: 0.4762,                 loss: nan
agent1:                 episode reward: -0.4762,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2040s / 11.6407 s
agent0:                 episode reward: 0.4335,                 loss: nan
agent1:                 episode reward: -0.4335,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 11.8397 s
agent0:                 episode reward: 0.0340,                 loss: nan
agent1:                 episode reward: -0.0340,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 12.0403 s
agent0:                 episode reward: 0.2861,                 loss: nan
agent1:                 episode reward: -0.2861,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 12.2405 s
agent0:                 episode reward: 0.6321,                 loss: nan
agent1:                 episode reward: -0.6321,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 12.4412 s
agent0:                 episode reward: 0.1762,                 loss: nan
agent1:                 episode reward: -0.1762,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 12.6374 s
agent0:                 episode reward: -0.0451,                 loss: nan
agent1:                 episode reward: 0.0451,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 12.8347 s
agent0:                 episode reward: 0.3491,                 loss: nan
agent1:                 episode reward: -0.3491,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 13.0340 s
agent0:                 episode reward: 0.3087,                 loss: nan
agent1:                 episode reward: -0.3087,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 13.2319 s
agent0:                 episode reward: 0.0383,                 loss: nan
agent1:                 episode reward: -0.0383,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 13.4270 s
agent0:                 episode reward: 0.0093,                 loss: nan
agent1:                 episode reward: -0.0093,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 13.6267 s
agent0:                 episode reward: 0.4906,                 loss: nan
agent1:                 episode reward: -0.4906,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 13.8255 s
agent0:                 episode reward: -0.2468,                 loss: nan
agent1:                 episode reward: 0.2468,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 14.0253 s
agent0:                 episode reward: 0.2132,                 loss: nan
agent1:                 episode reward: -0.2132,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 14.2290 s
agent0:                 episode reward: 0.3005,                 loss: nan
agent1:                 episode reward: -0.3005,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 14.4296 s
agent0:                 episode reward: 0.5105,                 loss: nan
agent1:                 episode reward: -0.5105,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 14.6315 s
agent0:                 episode reward: 0.2309,                 loss: nan
agent1:                 episode reward: -0.2309,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 14.8312 s
agent0:                 episode reward: 0.3692,                 loss: nan
agent1:                 episode reward: -0.3692,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 15.0355 s
agent0:                 episode reward: 0.5900,                 loss: nan
agent1:                 episode reward: -0.5900,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 15.2319 s
agent0:                 episode reward: -0.0429,                 loss: nan
agent1:                 episode reward: 0.0429,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 15.4303 s
agent0:                 episode reward: 0.5897,                 loss: nan
agent1:                 episode reward: -0.5897,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 15.6322 s
agent0:                 episode reward: 0.3900,                 loss: nan
agent1:                 episode reward: -0.3900,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 15.8306 s
agent0:                 episode reward: 0.2217,                 loss: nan
agent1:                 episode reward: -0.2217,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 16.0266 s
agent0:                 episode reward: 0.2366,                 loss: nan
agent1:                 episode reward: -0.2366,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 16.2287 s
agent0:                 episode reward: 0.3826,                 loss: nan
agent1:                 episode reward: -0.3826,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 16.4268 s
agent0:                 episode reward: 0.2015,                 loss: nan
agent1:                 episode reward: -0.2015,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 16.6278 s
agent0:                 episode reward: 0.1820,                 loss: nan
agent1:                 episode reward: -0.1820,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 16.8289 s
agent0:                 episode reward: 0.5597,                 loss: nan
agent1:                 episode reward: -0.5597,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 17.0283 s
agent0:                 episode reward: 0.4351,                 loss: nan
agent1:                 episode reward: -0.4351,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 17.2283 s
agent0:                 episode reward: 0.2938,                 loss: nan
agent1:                 episode reward: -0.2938,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 17.4319 s
agent0:                 episode reward: 0.4075,                 loss: nan
agent1:                 episode reward: -0.4075,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 17.6305 s
agent0:                 episode reward: 0.1486,                 loss: nan
agent1:                 episode reward: -0.1486,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 17.8299 s
agent0:                 episode reward: 0.0488,                 loss: nan
agent1:                 episode reward: -0.0488,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 18.0298 s
agent0:                 episode reward: 0.3362,                 loss: nan
agent1:                 episode reward: -0.3362,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 18.2327 s
agent0:                 episode reward: 0.4495,                 loss: nan
agent1:                 episode reward: -0.4495,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 18.4321 s
agent0:                 episode reward: 0.5711,                 loss: nan
agent1:                 episode reward: -0.5711,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 18.6325 s
agent0:                 episode reward: 0.2159,                 loss: nan
agent1:                 episode reward: -0.2159,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 18.8346 s
agent0:                 episode reward: 0.1496,                 loss: nan
agent1:                 episode reward: -0.1496,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 19.0313 s
agent0:                 episode reward: -0.0735,                 loss: nan
agent1:                 episode reward: 0.0735,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 19.2309 s
agent0:                 episode reward: 0.5201,                 loss: nan
agent1:                 episode reward: -0.5201,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 19.4295 s
agent0:                 episode reward: -0.2144,                 loss: nan
agent1:                 episode reward: 0.2144,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 19.6287 s
agent0:                 episode reward: 0.1365,                 loss: nan
agent1:                 episode reward: -0.1365,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 19.8243 s
agent0:                 episode reward: 0.5354,                 loss: nan
agent1:                 episode reward: -0.5354,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 20.0190 s
agent0:                 episode reward: 0.3384,                 loss: nan
agent1:                 episode reward: -0.3384,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2035s / 20.2225 s
agent0:                 episode reward: 0.1923,                 loss: nan
agent1:                 episode reward: -0.1923,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 20.4246 s
agent0:                 episode reward: 0.2892,                 loss: nan
agent1:                 episode reward: -0.2892,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 20.6179 s
agent0:                 episode reward: 0.5144,                 loss: nan
agent1:                 episode reward: -0.5144,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2099s / 20.8278 s
agent0:                 episode reward: 0.4372,                 loss: nan
agent1:                 episode reward: -0.4372,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 21.0279 s
agent0:                 episode reward: 0.1855,                 loss: nan
agent1:                 episode reward: -0.1855,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 21.2276 s
agent0:                 episode reward: 0.3923,                 loss: nan
agent1:                 episode reward: -0.3923,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 21.4264 s
agent0:                 episode reward: 0.6026,                 loss: nan
agent1:                 episode reward: -0.6026,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2039s / 21.6304 s
agent0:                 episode reward: 0.1550,                 loss: nan
agent1:                 episode reward: -0.1550,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 21.8305 s
agent0:                 episode reward: 0.0883,                 loss: nan
agent1:                 episode reward: -0.0883,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 22.0290 s
agent0:                 episode reward: -0.1877,                 loss: nan
agent1:                 episode reward: 0.1877,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 22.2309 s
agent0:                 episode reward: 0.3069,                 loss: nan
agent1:                 episode reward: -0.3069,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 22.4307 s
agent0:                 episode reward: 0.0855,                 loss: nan
agent1:                 episode reward: -0.0855,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 22.6315 s
agent0:                 episode reward: 0.1666,                 loss: nan
agent1:                 episode reward: -0.1666,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 22.8330 s
agent0:                 episode reward: 0.0331,                 loss: nan
agent1:                 episode reward: -0.0331,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 23.0349 s
agent0:                 episode reward: 0.3245,                 loss: nan
agent1:                 episode reward: -0.3245,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 23.2337 s
agent0:                 episode reward: 0.2251,                 loss: nan
agent1:                 episode reward: -0.2251,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 23.4348 s
agent0:                 episode reward: 0.5186,                 loss: nan
agent1:                 episode reward: -0.5186,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 23.6328 s
agent0:                 episode reward: 0.1975,                 loss: nan
agent1:                 episode reward: -0.1975,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 23.8341 s
agent0:                 episode reward: 0.4742,                 loss: nan
agent1:                 episode reward: -0.4742,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 24.0352 s
agent0:                 episode reward: 0.4330,                 loss: nan
agent1:                 episode reward: -0.4330,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2040s / 24.2392 s
agent0:                 episode reward: 0.2661,                 loss: nan
agent1:                 episode reward: -0.2661,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 24.4412 s
agent0:                 episode reward: 0.3074,                 loss: nan
agent1:                 episode reward: -0.3074,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 24.6411 s
agent0:                 episode reward: 0.5563,                 loss: nan
agent1:                 episode reward: -0.5563,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 24.8376 s
agent0:                 episode reward: 0.4180,                 loss: nan
agent1:                 episode reward: -0.4180,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 25.0376 s
agent0:                 episode reward: -0.1914,                 loss: nan
agent1:                 episode reward: 0.1914,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 25.2392 s
agent0:                 episode reward: 0.0264,                 loss: nan
agent1:                 episode reward: -0.0264,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 25.4339 s
agent0:                 episode reward: 0.1117,                 loss: nan
agent1:                 episode reward: -0.1117,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 25.6344 s
agent0:                 episode reward: 0.5973,                 loss: nan
agent1:                 episode reward: -0.5973,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 25.8356 s
agent0:                 episode reward: 0.2697,                 loss: nan
agent1:                 episode reward: -0.2697,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 26.0318 s
agent0:                 episode reward: -0.0958,                 loss: nan
agent1:                 episode reward: 0.0958,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 26.2300 s
agent0:                 episode reward: -0.0660,                 loss: nan
agent1:                 episode reward: 0.0660,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 26.4313 s
agent0:                 episode reward: 0.2189,                 loss: nan
agent1:                 episode reward: -0.2189,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 26.6281 s
agent0:                 episode reward: 0.2948,                 loss: nan
agent1:                 episode reward: -0.2948,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 26.8251 s
agent0:                 episode reward: 0.1936,                 loss: nan
agent1:                 episode reward: -0.1936,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1923s / 27.0174 s
agent0:                 episode reward: 0.4363,                 loss: nan
agent1:                 episode reward: -0.4363,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 27.2122 s
agent0:                 episode reward: 0.0196,                 loss: nan
agent1:                 episode reward: -0.0196,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 27.4144 s
agent0:                 episode reward: 0.3268,                 loss: nan
agent1:                 episode reward: -0.3268,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 27.6155 s
agent0:                 episode reward: 0.2700,                 loss: nan
agent1:                 episode reward: -0.2700,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 27.8117 s
agent0:                 episode reward: 0.4773,                 loss: nan
agent1:                 episode reward: -0.4773,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1624s / 27.9741 s
agent0:                 episode reward: 0.0419,                 loss: nan
agent1:                 episode reward: -0.0419,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2337s / 28.2079 s
agent0:                 episode reward: 0.0088,                 loss: nan
agent1:                 episode reward: -0.0088,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 28.4050 s
agent0:                 episode reward: 0.4045,                 loss: nan
agent1:                 episode reward: -0.4045,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 28.6014 s
agent0:                 episode reward: -0.2337,                 loss: nan
agent1:                 episode reward: 0.2337,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 28.8025 s
agent0:                 episode reward: 0.3878,                 loss: nan
agent1:                 episode reward: -0.3878,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 29.0008 s
agent0:                 episode reward: 0.1772,                 loss: nan
agent1:                 episode reward: -0.1772,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 29.1992 s
agent0:                 episode reward: 0.4158,                 loss: nan
agent1:                 episode reward: -0.4158,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 29.3980 s
agent0:                 episode reward: 0.2718,                 loss: nan
agent1:                 episode reward: -0.2718,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 29.5979 s
agent0:                 episode reward: 0.1733,                 loss: nan
agent1:                 episode reward: -0.1733,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2067s / 29.8047 s
agent0:                 episode reward: 0.0881,                 loss: nan
agent1:                 episode reward: -0.0881,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 30.0040 s
agent0:                 episode reward: 0.0696,                 loss: nan
agent1:                 episode reward: -0.0696,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 30.2049 s
agent0:                 episode reward: 0.0582,                 loss: nan
agent1:                 episode reward: -0.0582,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 30.4038 s
agent0:                 episode reward: 0.4297,                 loss: nan
agent1:                 episode reward: -0.4297,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 30.6024 s
agent0:                 episode reward: 0.4348,                 loss: nan
agent1:                 episode reward: -0.4348,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 30.8032 s
agent0:                 episode reward: 0.5547,                 loss: nan
agent1:                 episode reward: -0.5547,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 31.0012 s
agent0:                 episode reward: 0.3775,                 loss: nan
agent1:                 episode reward: -0.3775,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2052s / 31.2064 s
agent0:                 episode reward: 0.3378,                 loss: nan
agent1:                 episode reward: -0.3378,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 31.4038 s
agent0:                 episode reward: 0.3140,                 loss: nan
agent1:                 episode reward: -0.3140,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 31.6035 s
agent0:                 episode reward: -0.0909,                 loss: nan
agent1:                 episode reward: 0.0909,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 31.8030 s
agent0:                 episode reward: 0.4174,                 loss: nan
agent1:                 episode reward: -0.4174,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 32.0018 s
agent0:                 episode reward: 0.1891,                 loss: nan
agent1:                 episode reward: -0.1891,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 32.2042 s
agent0:                 episode reward: 0.2724,                 loss: nan
agent1:                 episode reward: -0.2724,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 32.4026 s
agent0:                 episode reward: 0.0044,                 loss: nan
agent1:                 episode reward: -0.0044,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2057s / 32.6083 s
agent0:                 episode reward: 0.0303,                 loss: nan
agent1:                 episode reward: -0.0303,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 32.8088 s
agent0:                 episode reward: 0.2884,                 loss: nan
agent1:                 episode reward: -0.2884,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 33.0110 s
agent0:                 episode reward: 0.4149,                 loss: nan
agent1:                 episode reward: -0.4149,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 33.2094 s
agent0:                 episode reward: 0.4169,                 loss: nan
agent1:                 episode reward: -0.4169,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 33.4092 s
agent0:                 episode reward: -0.0208,                 loss: nan
agent1:                 episode reward: 0.0208,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 33.6081 s
agent0:                 episode reward: 0.5096,                 loss: nan
agent1:                 episode reward: -0.5096,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 33.8020 s
agent0:                 episode reward: 0.5821,                 loss: nan
agent1:                 episode reward: -0.5821,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3340s / 34.1360 s
agent0:                 episode reward: -0.2367,                 loss: nan
agent1:                 episode reward: 0.2367,                 loss: 0.4457
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 34.7214 s
agent0:                 episode reward: 0.2227,                 loss: nan
agent1:                 episode reward: -0.2227,                 loss: 0.4455
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5793s / 35.3008 s
agent0:                 episode reward: 0.2021,                 loss: nan
agent1:                 episode reward: -0.2021,                 loss: 0.4441
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5781s / 35.8789 s
agent0:                 episode reward: 0.4200,                 loss: nan
agent1:                 episode reward: -0.4200,                 loss: 0.4419
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 36.4656 s
agent0:                 episode reward: 0.3099,                 loss: nan
agent1:                 episode reward: -0.3099,                 loss: 0.4402
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 37.0536 s
agent0:                 episode reward: 0.2527,                 loss: nan
agent1:                 episode reward: -0.2527,                 loss: 0.4374
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 37.6355 s
agent0:                 episode reward: -0.2757,                 loss: nan
agent1:                 episode reward: 0.2757,                 loss: 0.4333
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5803s / 38.2158 s
agent0:                 episode reward: -0.2191,                 loss: nan
agent1:                 episode reward: 0.2191,                 loss: 0.4285
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 38.7964 s
agent0:                 episode reward: 0.3769,                 loss: nan
agent1:                 episode reward: -0.3769,                 loss: 0.4237
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 39.3776 s
agent0:                 episode reward: -0.1901,                 loss: nan
agent1:                 episode reward: 0.1901,                 loss: 0.4159
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5829s / 39.9604 s
agent0:                 episode reward: 0.0652,                 loss: nan
agent1:                 episode reward: -0.0652,                 loss: 0.4097
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 40.5452 s
agent0:                 episode reward: -0.3294,                 loss: nan
agent1:                 episode reward: 0.3294,                 loss: 0.4024
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5824s / 41.1276 s
agent0:                 episode reward: -0.5388,                 loss: nan
agent1:                 episode reward: 0.5388,                 loss: 0.3952
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5798s / 41.7074 s
agent0:                 episode reward: -0.1404,                 loss: nan
agent1:                 episode reward: 0.1404,                 loss: 0.3921
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 42.2864 s
agent0:                 episode reward: 0.1472,                 loss: nan
agent1:                 episode reward: -0.1472,                 loss: 0.3871
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 42.8762 s
agent0:                 episode reward: -0.1032,                 loss: nan
agent1:                 episode reward: 0.1032,                 loss: 0.3864
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 43.4649 s
agent0:                 episode reward: -0.0015,                 loss: nan
agent1:                 episode reward: 0.0015,                 loss: 0.3832
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5780s / 44.0430 s
agent0:                 episode reward: -0.2142,                 loss: nan
agent1:                 episode reward: 0.2142,                 loss: 0.3592
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 44.6323 s
agent0:                 episode reward: -0.3266,                 loss: nan
agent1:                 episode reward: 0.3266,                 loss: 0.3471
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 45.2232 s
agent0:                 episode reward: -0.2877,                 loss: nan
agent1:                 episode reward: 0.2877,                 loss: 0.3467
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 45.8172 s
agent0:                 episode reward: -0.2925,                 loss: nan
agent1:                 episode reward: 0.2925,                 loss: 0.3479
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 46.4000 s
agent0:                 episode reward: -0.1808,                 loss: nan
agent1:                 episode reward: 0.1808,                 loss: 0.3464
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 46.9812 s
agent0:                 episode reward: -0.4298,                 loss: nan
agent1:                 episode reward: 0.4298,                 loss: 0.3468
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 47.5693 s
agent0:                 episode reward: -0.2539,                 loss: nan
agent1:                 episode reward: 0.2539,                 loss: 0.3447
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5829s / 48.1522 s
agent0:                 episode reward: -0.4415,                 loss: nan
agent1:                 episode reward: 0.4415,                 loss: 0.3481
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 48.7376 s
agent0:                 episode reward: -0.6464,                 loss: nan
agent1:                 episode reward: 0.6464,                 loss: 0.3470
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 49.3291 s
agent0:                 episode reward: -0.7181,                 loss: nan
agent1:                 episode reward: 0.7181,                 loss: 0.3476
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 49.9245 s
agent0:                 episode reward: -0.5099,                 loss: nan
agent1:                 episode reward: 0.5099,                 loss: 0.3455
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 50.5099 s
agent0:                 episode reward: -0.2625,                 loss: nan
agent1:                 episode reward: 0.2625,                 loss: 0.3436
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 51.0967 s
agent0:                 episode reward: -0.2915,                 loss: nan
agent1:                 episode reward: 0.2915,                 loss: 0.3443
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 51.6805 s
agent0:                 episode reward: -0.5899,                 loss: nan
agent1:                 episode reward: 0.5899,                 loss: 0.3427
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 52.2691 s
agent0:                 episode reward: -0.7428,                 loss: nan
agent1:                 episode reward: 0.7428,                 loss: 0.3422
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 52.8606 s
agent0:                 episode reward: -0.3261,                 loss: nan
agent1:                 episode reward: 0.3261,                 loss: 0.3454
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 53.4527 s
agent0:                 episode reward: -0.3889,                 loss: nan
agent1:                 episode reward: 0.3889,                 loss: 0.3429
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 54.0399 s
agent0:                 episode reward: -0.1556,                 loss: nan
agent1:                 episode reward: 0.1556,                 loss: 0.3253
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 54.6205 s
agent0:                 episode reward: -0.0049,                 loss: nan
agent1:                 episode reward: 0.0049,                 loss: 0.3220
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 55.2073 s
agent0:                 episode reward: -0.2569,                 loss: nan
agent1:                 episode reward: 0.2569,                 loss: 0.3257
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 55.7929 s
agent0:                 episode reward: -0.4087,                 loss: nan
agent1:                 episode reward: 0.4087,                 loss: 0.3247
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 56.3775 s
agent0:                 episode reward: -0.4516,                 loss: nan
agent1:                 episode reward: 0.4516,                 loss: 0.3239
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5818s / 56.9593 s
agent0:                 episode reward: -0.0607,                 loss: nan
agent1:                 episode reward: 0.0607,                 loss: 0.3228
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 57.5497 s
agent0:                 episode reward: -0.2672,                 loss: nan
agent1:                 episode reward: 0.2672,                 loss: 0.3223
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 58.1320 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.3197
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 58.7142 s
agent0:                 episode reward: 0.0132,                 loss: nan
agent1:                 episode reward: -0.0132,                 loss: 0.3203
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 59.3069 s
agent0:                 episode reward: 0.0119,                 loss: nan
agent1:                 episode reward: -0.0119,                 loss: 0.3213
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 59.8978 s
agent0:                 episode reward: -0.0100,                 loss: nan
agent1:                 episode reward: 0.0100,                 loss: 0.3226
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 60.4863 s
agent0:                 episode reward: -0.3855,                 loss: nan
agent1:                 episode reward: 0.3855,                 loss: 0.3231
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 61.0827 s
agent0:                 episode reward: -0.1555,                 loss: nan
agent1:                 episode reward: 0.1555,                 loss: 0.3230
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 61.6726 s
agent0:                 episode reward: -0.2926,                 loss: nan
agent1:                 episode reward: 0.2926,                 loss: 0.3217
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 62.2652 s
agent0:                 episode reward: -0.1039,                 loss: nan
agent1:                 episode reward: 0.1039,                 loss: 0.3199
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 62.8584 s
agent0:                 episode reward: -0.1225,                 loss: nan
agent1:                 episode reward: 0.1225,                 loss: 0.3211
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 63.4515 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.3345
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 64.0445 s
agent0:                 episode reward: -0.5727,                 loss: nan
agent1:                 episode reward: 0.5727,                 loss: 0.3549
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 64.6302 s
agent0:                 episode reward: -0.6679,                 loss: nan
agent1:                 episode reward: 0.6679,                 loss: 0.3543
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 65.2240 s
agent0:                 episode reward: -0.4345,                 loss: nan
agent1:                 episode reward: 0.4345,                 loss: 0.3550
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 65.8153 s
agent0:                 episode reward: -0.5632,                 loss: nan
agent1:                 episode reward: 0.5632,                 loss: 0.3507
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 66.4101 s
agent0:                 episode reward: -0.5295,                 loss: nan
agent1:                 episode reward: 0.5295,                 loss: 0.3546
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 67.0019 s
agent0:                 episode reward: -0.4694,                 loss: nan
agent1:                 episode reward: 0.4694,                 loss: 0.3520
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 67.5907 s
agent0:                 episode reward: -0.4557,                 loss: nan
agent1:                 episode reward: 0.4557,                 loss: 0.3511
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 68.1831 s
agent0:                 episode reward: -0.3244,                 loss: nan
agent1:                 episode reward: 0.3244,                 loss: 0.3529
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 68.7768 s
agent0:                 episode reward: -0.3756,                 loss: nan
agent1:                 episode reward: 0.3756,                 loss: 0.3536
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 69.3724 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.3495
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 69.9674 s
agent0:                 episode reward: -0.3144,                 loss: nan
agent1:                 episode reward: 0.3144,                 loss: 0.3492
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 70.5628 s
agent0:                 episode reward: -0.1919,                 loss: nan
agent1:                 episode reward: 0.1919,                 loss: 0.3538
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 71.1579 s
agent0:                 episode reward: -0.4313,                 loss: nan
agent1:                 episode reward: 0.4313,                 loss: 0.3501
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 71.7553 s
agent0:                 episode reward: -0.3410,                 loss: nan
agent1:                 episode reward: 0.3410,                 loss: 0.3477
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 72.3469 s
agent0:                 episode reward: -0.3375,                 loss: nan
agent1:                 episode reward: 0.3375,                 loss: 0.3526
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 72.9377 s
agent0:                 episode reward: -0.2177,                 loss: nan
agent1:                 episode reward: 0.2177,                 loss: 0.3490
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 73.5237 s
agent0:                 episode reward: -0.6433,                 loss: nan
agent1:                 episode reward: 0.6433,                 loss: 0.3531
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 74.1073 s
agent0:                 episode reward: -0.6215,                 loss: nan
agent1:                 episode reward: 0.6215,                 loss: 0.3529
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 74.6975 s
agent0:                 episode reward: -0.2822,                 loss: nan
agent1:                 episode reward: 0.2822,                 loss: 0.3516
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 75.2813 s
agent0:                 episode reward: -0.3833,                 loss: nan
agent1:                 episode reward: 0.3833,                 loss: 0.3526
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5796s / 75.8609 s
agent0:                 episode reward: -0.4228,                 loss: nan
agent1:                 episode reward: 0.4228,                 loss: 0.3505
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 76.4508 s
agent0:                 episode reward: -0.5663,                 loss: nan
agent1:                 episode reward: 0.5663,                 loss: 0.3536
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 77.0338 s
agent0:                 episode reward: -0.2984,                 loss: nan
agent1:                 episode reward: 0.2984,                 loss: 0.3480
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 77.6268 s
agent0:                 episode reward: -0.2651,                 loss: nan
agent1:                 episode reward: 0.2651,                 loss: 0.3512
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 78.2168 s
agent0:                 episode reward: -0.1783,                 loss: nan
agent1:                 episode reward: 0.1783,                 loss: 0.3486
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 78.8026 s
agent0:                 episode reward: -0.0001,                 loss: nan
agent1:                 episode reward: 0.0001,                 loss: 0.3487
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 79.3966 s
agent0:                 episode reward: -0.4922,                 loss: nan
agent1:                 episode reward: 0.4922,                 loss: 0.3508
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 79.9803 s
agent0:                 episode reward: -0.5092,                 loss: nan
agent1:                 episode reward: 0.5092,                 loss: 0.3490
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5778s / 80.5581 s
agent0:                 episode reward: -0.0990,                 loss: nan
agent1:                 episode reward: 0.0990,                 loss: 0.3491
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 81.1459 s
agent0:                 episode reward: -0.2192,                 loss: nan
agent1:                 episode reward: 0.2192,                 loss: 0.3487
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 81.7296 s
agent0:                 episode reward: -0.0029,                 loss: nan
agent1:                 episode reward: 0.0029,                 loss: 0.3492
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 82.3143 s
agent0:                 episode reward: -0.3492,                 loss: nan
agent1:                 episode reward: 0.3492,                 loss: 0.3511
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 82.8962 s
agent0:                 episode reward: -0.5804,                 loss: nan
agent1:                 episode reward: 0.5804,                 loss: 0.3495
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 83.4809 s
agent0:                 episode reward: -0.1927,                 loss: nan
agent1:                 episode reward: 0.1927,                 loss: 0.3392
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5820s / 84.0628 s
agent0:                 episode reward: -0.4299,                 loss: nan
agent1:                 episode reward: 0.4299,                 loss: 0.3398
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 84.6475 s
agent0:                 episode reward: -0.4445,                 loss: nan
agent1:                 episode reward: 0.4445,                 loss: 0.3408
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 85.2426 s
agent0:                 episode reward: 0.0632,                 loss: nan
agent1:                 episode reward: -0.0632,                 loss: 0.3409
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 85.8281 s
agent0:                 episode reward: -0.4235,                 loss: nan
agent1:                 episode reward: 0.4235,                 loss: 0.3367
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 86.4175 s
agent0:                 episode reward: -0.7505,                 loss: nan
agent1:                 episode reward: 0.7505,                 loss: 0.3391
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 87.0143 s
agent0:                 episode reward: -0.5274,                 loss: nan
agent1:                 episode reward: 0.5274,                 loss: 0.3415
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 87.5997 s
agent0:                 episode reward: -0.6871,                 loss: nan
agent1:                 episode reward: 0.6871,                 loss: 0.3401
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 88.1936 s
agent0:                 episode reward: -0.3089,                 loss: nan
agent1:                 episode reward: 0.3089,                 loss: 0.3396
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 88.7818 s
agent0:                 episode reward: -0.5567,                 loss: nan
agent1:                 episode reward: 0.5567,                 loss: 0.3402
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 89.3712 s
agent0:                 episode reward: 0.1484,                 loss: nan
agent1:                 episode reward: -0.1484,                 loss: 0.3367
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 89.9571 s
agent0:                 episode reward: -0.6449,                 loss: nan
agent1:                 episode reward: 0.6449,                 loss: 0.3395
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 90.5505 s
agent0:                 episode reward: -0.2304,                 loss: nan
agent1:                 episode reward: 0.2304,                 loss: 0.3382
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 91.1412 s
agent0:                 episode reward: -0.3715,                 loss: nan
agent1:                 episode reward: 0.3715,                 loss: 0.3380
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 91.7305 s
agent0:                 episode reward: -0.4383,                 loss: nan
agent1:                 episode reward: 0.4383,                 loss: 0.3385
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 92.3187 s
agent0:                 episode reward: -0.7989,                 loss: nan
agent1:                 episode reward: 0.7989,                 loss: 0.3367
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 92.9090 s
agent0:                 episode reward: -0.2722,                 loss: nan
agent1:                 episode reward: 0.2722,                 loss: 0.3423
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 93.5012 s
agent0:                 episode reward: -0.8358,                 loss: nan
agent1:                 episode reward: 0.8358,                 loss: 0.3462
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 94.0877 s
agent0:                 episode reward: -0.7675,                 loss: nan
agent1:                 episode reward: 0.7675,                 loss: 0.3428
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 94.6689 s
agent0:                 episode reward: -0.6431,                 loss: nan
agent1:                 episode reward: 0.6431,                 loss: 0.3432
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 95.2571 s
agent0:                 episode reward: -0.5801,                 loss: nan
agent1:                 episode reward: 0.5801,                 loss: 0.3433
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 95.8506 s
agent0:                 episode reward: -0.7153,                 loss: nan
agent1:                 episode reward: 0.7153,                 loss: 0.3478
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 96.4397 s
agent0:                 episode reward: -0.5186,                 loss: nan
agent1:                 episode reward: 0.5186,                 loss: 0.3430
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 97.0240 s
agent0:                 episode reward: -0.6902,                 loss: nan
agent1:                 episode reward: 0.6902,                 loss: 0.3440
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 97.6117 s
agent0:                 episode reward: -0.2168,                 loss: nan
agent1:                 episode reward: 0.2168,                 loss: 0.3457
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 98.1960 s
agent0:                 episode reward: -0.7097,                 loss: nan
agent1:                 episode reward: 0.7097,                 loss: 0.3407
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 98.7837 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.3454
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 99.3701 s
agent0:                 episode reward: -0.3009,                 loss: nan
agent1:                 episode reward: 0.3009,                 loss: 0.3447
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 99.9623 s
agent0:                 episode reward: -0.7462,                 loss: nan
agent1:                 episode reward: 0.7462,                 loss: 0.3437
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 100.5533 s
agent0:                 episode reward: -0.7361,                 loss: nan
agent1:                 episode reward: 0.7361,                 loss: 0.3414
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 101.1408 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.3437
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 101.7236 s
agent0:                 episode reward: -0.4126,                 loss: nan
agent1:                 episode reward: 0.4126,                 loss: 0.3469
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 102.3208 s
agent0:                 episode reward: -0.1738,                 loss: nan
agent1:                 episode reward: 0.1738,                 loss: 0.3430
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 102.9145 s
agent0:                 episode reward: -0.6710,                 loss: nan
agent1:                 episode reward: 0.6710,                 loss: 0.3389
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 103.5131 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.3371
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 104.1059 s
agent0:                 episode reward: -0.5716,                 loss: nan
agent1:                 episode reward: 0.5716,                 loss: 0.3355
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 104.6989 s
agent0:                 episode reward: -0.7070,                 loss: nan
agent1:                 episode reward: 0.7070,                 loss: 0.3348
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 105.2919 s
agent0:                 episode reward: -0.6406,                 loss: nan
agent1:                 episode reward: 0.6406,                 loss: 0.3352
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 105.8874 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.3343
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 106.4911 s
agent0:                 episode reward: -0.5896,                 loss: nan
agent1:                 episode reward: 0.5896,                 loss: 0.3393
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 107.0870 s
agent0:                 episode reward: -0.8460,                 loss: nan
agent1:                 episode reward: 0.8460,                 loss: 0.3363
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 107.6755 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.3376
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 108.2695 s
agent0:                 episode reward: -0.2960,                 loss: nan
agent1:                 episode reward: 0.2960,                 loss: 0.3361
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 108.8579 s
agent0:                 episode reward: -0.4197,                 loss: nan
agent1:                 episode reward: 0.4197,                 loss: 0.3363
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 109.4477 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.3371
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 110.0411 s
agent0:                 episode reward: -0.5820,                 loss: nan
agent1:                 episode reward: 0.5820,                 loss: 0.3335
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 110.6266 s
agent0:                 episode reward: -0.4652,                 loss: nan
agent1:                 episode reward: 0.4652,                 loss: 0.3348
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 111.2212 s
agent0:                 episode reward: -0.9145,                 loss: nan
agent1:                 episode reward: 0.9145,                 loss: 0.3357
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 111.8120 s
agent0:                 episode reward: -0.5440,                 loss: nan
agent1:                 episode reward: 0.5440,                 loss: 0.3328
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 112.3988 s
agent0:                 episode reward: -0.9472,                 loss: nan
agent1:                 episode reward: 0.9472,                 loss: 0.3338
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 113.0006 s
agent0:                 episode reward: -0.4825,                 loss: nan
agent1:                 episode reward: 0.4825,                 loss: 0.3349
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 113.5924 s
agent0:                 episode reward: -0.4614,                 loss: nan
agent1:                 episode reward: 0.4614,                 loss: 0.3293
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 114.1855 s
agent0:                 episode reward: -0.4515,                 loss: nan
agent1:                 episode reward: 0.4515,                 loss: 0.3304
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 114.7809 s
agent0:                 episode reward: -0.5111,                 loss: nan
agent1:                 episode reward: 0.5111,                 loss: 0.3287
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 115.3784 s
agent0:                 episode reward: -0.2868,                 loss: nan
agent1:                 episode reward: 0.2868,                 loss: 0.3321
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 115.9742 s
agent0:                 episode reward: -0.2991,                 loss: nan
agent1:                 episode reward: 0.2991,                 loss: 0.3300
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 116.5676 s
agent0:                 episode reward: -0.4540,                 loss: nan
agent1:                 episode reward: 0.4540,                 loss: 0.3303
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 117.1528 s
agent0:                 episode reward: -0.7604,                 loss: nan
agent1:                 episode reward: 0.7604,                 loss: 0.3307
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 117.7484 s
agent0:                 episode reward: -0.3312,                 loss: nan
agent1:                 episode reward: 0.3312,                 loss: 0.3296
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 118.3469 s
agent0:                 episode reward: -0.7442,                 loss: nan
agent1:                 episode reward: 0.7442,                 loss: 0.3312
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 118.9392 s
agent0:                 episode reward: -0.5099,                 loss: nan
agent1:                 episode reward: 0.5099,                 loss: 0.3331
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 119.5475 s
agent0:                 episode reward: -0.8816,                 loss: nan
agent1:                 episode reward: 0.8816,                 loss: 0.3292
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 120.1463 s
agent0:                 episode reward: -0.5115,                 loss: nan
agent1:                 episode reward: 0.5115,                 loss: 0.3254
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 120.7469 s
agent0:                 episode reward: -0.6042,                 loss: nan
agent1:                 episode reward: 0.6042,                 loss: 0.3310
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 121.3398 s
agent0:                 episode reward: -0.2405,                 loss: nan
agent1:                 episode reward: 0.2405,                 loss: 0.3281
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 121.9347 s
agent0:                 episode reward: -0.7493,                 loss: nan
agent1:                 episode reward: 0.7493,                 loss: 0.3320
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 122.5344 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.3373
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 123.1370 s
agent0:                 episode reward: -0.5172,                 loss: nan
agent1:                 episode reward: 0.5172,                 loss: 0.3514
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 123.7336 s
agent0:                 episode reward: -0.1329,                 loss: nan
agent1:                 episode reward: 0.1329,                 loss: 0.3524
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 124.3302 s
agent0:                 episode reward: -0.3664,                 loss: nan
agent1:                 episode reward: 0.3664,                 loss: 0.3542
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 124.9305 s
agent0:                 episode reward: -0.7811,                 loss: nan
agent1:                 episode reward: 0.7811,                 loss: 0.3517
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 125.5299 s
agent0:                 episode reward: -0.4467,                 loss: nan
agent1:                 episode reward: 0.4467,                 loss: 0.3514
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 126.1279 s
agent0:                 episode reward: -0.6172,                 loss: nan
agent1:                 episode reward: 0.6172,                 loss: 0.3536
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 126.7322 s
agent0:                 episode reward: -0.4002,                 loss: nan
agent1:                 episode reward: 0.4002,                 loss: 0.3508
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 127.3348 s
agent0:                 episode reward: -0.7677,                 loss: nan
agent1:                 episode reward: 0.7677,                 loss: 0.3547
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5983s / 127.9331 s
agent0:                 episode reward: -0.2992,                 loss: nan
agent1:                 episode reward: 0.2992,                 loss: 0.3537
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 128.5240 s
agent0:                 episode reward: -0.3253,                 loss: nan
agent1:                 episode reward: 0.3253,                 loss: 0.3528
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6115s / 129.1355 s
agent0:                 episode reward: -0.3058,                 loss: nan
agent1:                 episode reward: 0.3058,                 loss: 0.3547
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6079s / 129.7434 s
agent0:                 episode reward: -0.9040,                 loss: nan
agent1:                 episode reward: 0.9040,                 loss: 0.3536
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 130.3509 s
agent0:                 episode reward: -0.5180,                 loss: nan
agent1:                 episode reward: 0.5180,                 loss: 0.3514
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 130.9544 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.3497
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 131.5591 s
agent0:                 episode reward: -1.0704,                 loss: nan
agent1:                 episode reward: 1.0704,                 loss: 0.3509
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6085s / 132.1675 s
agent0:                 episode reward: -0.7127,                 loss: nan
agent1:                 episode reward: 0.7127,                 loss: 0.3482
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6154s / 132.7830 s
agent0:                 episode reward: -0.5844,                 loss: nan
agent1:                 episode reward: 0.5844,                 loss: 0.3294
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6077s / 133.3907 s
agent0:                 episode reward: -0.6497,                 loss: nan
agent1:                 episode reward: 0.6497,                 loss: 0.3231
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6105s / 134.0012 s
agent0:                 episode reward: -0.6662,                 loss: nan
agent1:                 episode reward: 0.6662,                 loss: 0.3241
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 134.6102 s
agent0:                 episode reward: -0.5368,                 loss: nan
agent1:                 episode reward: 0.5368,                 loss: 0.3279
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6152s / 135.2254 s
agent0:                 episode reward: -0.4988,                 loss: nan
agent1:                 episode reward: 0.4988,                 loss: 0.3258
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6146s / 135.8401 s
agent0:                 episode reward: -0.7320,                 loss: nan
agent1:                 episode reward: 0.7320,                 loss: 0.3248
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 136.4522 s
agent0:                 episode reward: -0.5454,                 loss: nan
agent1:                 episode reward: 0.5454,                 loss: 0.3220
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 137.0572 s
agent0:                 episode reward: -0.8271,                 loss: nan
agent1:                 episode reward: 0.8271,                 loss: 0.3227
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6161s / 137.6733 s
agent0:                 episode reward: -0.4534,                 loss: nan
agent1:                 episode reward: 0.4534,                 loss: 0.3268
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 138.2892 s
agent0:                 episode reward: -0.5992,                 loss: nan
agent1:                 episode reward: 0.5992,                 loss: 0.3252
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6123s / 138.9015 s
agent0:                 episode reward: -0.4448,                 loss: nan
agent1:                 episode reward: 0.4448,                 loss: 0.3255
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6160s / 139.5175 s
agent0:                 episode reward: -0.2168,                 loss: nan
agent1:                 episode reward: 0.2168,                 loss: 0.3215
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 140.1345 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: 0.3219
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6167s / 140.7512 s
agent0:                 episode reward: -0.7261,                 loss: nan
agent1:                 episode reward: 0.7261,                 loss: 0.3202
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 141.3619 s
agent0:                 episode reward: -0.5860,                 loss: nan
agent1:                 episode reward: 0.5860,                 loss: 0.3248
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 141.9664 s
agent0:                 episode reward: -0.6537,                 loss: nan
agent1:                 episode reward: 0.6537,                 loss: 0.3234
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6106s / 142.5770 s
agent0:                 episode reward: -0.7069,                 loss: nan
agent1:                 episode reward: 0.7069,                 loss: 0.3231
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6049s / 143.1818 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.3351
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 143.7774 s
agent0:                 episode reward: -0.6822,                 loss: nan
agent1:                 episode reward: 0.6822,                 loss: 0.3326
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 144.3730 s
agent0:                 episode reward: -0.8303,                 loss: nan
agent1:                 episode reward: 0.8303,                 loss: 0.3363
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 144.9685 s
agent0:                 episode reward: -0.5138,                 loss: nan
agent1:                 episode reward: 0.5138,                 loss: 0.3359
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 145.5666 s
agent0:                 episode reward: -0.4363,                 loss: nan
agent1:                 episode reward: 0.4363,                 loss: 0.3346
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 146.1682 s
agent0:                 episode reward: -0.5722,                 loss: nan
agent1:                 episode reward: 0.5722,                 loss: 0.3338
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6056s / 146.7737 s
agent0:                 episode reward: -0.3429,                 loss: nan
agent1:                 episode reward: 0.3429,                 loss: 0.3329
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 147.3701 s
agent0:                 episode reward: -0.6716,                 loss: nan
agent1:                 episode reward: 0.6716,                 loss: 0.3339
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6072s / 147.9773 s
agent0:                 episode reward: -0.5213,                 loss: nan
agent1:                 episode reward: 0.5213,                 loss: 0.3338
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 148.5785 s
agent0:                 episode reward: -0.5181,                 loss: nan
agent1:                 episode reward: 0.5181,                 loss: 0.3361
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 149.1791 s
agent0:                 episode reward: -0.3231,                 loss: nan
agent1:                 episode reward: 0.3231,                 loss: 0.3336
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 149.7791 s
agent0:                 episode reward: -0.6621,                 loss: nan
agent1:                 episode reward: 0.6621,                 loss: 0.3347
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 150.3781 s
agent0:                 episode reward: -0.3916,                 loss: nan
agent1:                 episode reward: 0.3916,                 loss: 0.3356
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 150.9713 s
agent0:                 episode reward: -0.7185,                 loss: nan
agent1:                 episode reward: 0.7185,                 loss: 0.3339
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 151.5567 s
agent0:                 episode reward: -0.8566,                 loss: nan
agent1:                 episode reward: 0.8566,                 loss: 0.3319
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 152.1437 s
agent0:                 episode reward: -0.8309,                 loss: nan
agent1:                 episode reward: 0.8309,                 loss: 0.3358
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 152.7455 s
agent0:                 episode reward: -0.4084,                 loss: nan
agent1:                 episode reward: 0.4084,                 loss: 0.3312
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 153.3375 s
agent0:                 episode reward: -0.5667,                 loss: nan
agent1:                 episode reward: 0.5667,                 loss: 0.3289
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 153.9317 s
agent0:                 episode reward: -0.5310,                 loss: nan
agent1:                 episode reward: 0.5310,                 loss: 0.3285
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 154.5249 s
agent0:                 episode reward: -0.2717,                 loss: nan
agent1:                 episode reward: 0.2717,                 loss: 0.3269
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6105s / 155.1354 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.3269
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 155.7482 s
agent0:                 episode reward: -0.4683,                 loss: nan
agent1:                 episode reward: 0.4683,                 loss: 0.3301
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6069s / 156.3551 s
agent0:                 episode reward: -0.6175,                 loss: nan
agent1:                 episode reward: 0.6175,                 loss: 0.3284
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 156.9497 s
agent0:                 episode reward: -0.9215,                 loss: nan
agent1:                 episode reward: 0.9215,                 loss: 0.3258
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 157.5510 s
agent0:                 episode reward: -0.3085,                 loss: nan
agent1:                 episode reward: 0.3085,                 loss: 0.3291
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 158.1508 s
agent0:                 episode reward: -0.4467,                 loss: nan
agent1:                 episode reward: 0.4467,                 loss: 0.3266
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 158.7482 s
agent0:                 episode reward: -0.5131,                 loss: nan
agent1:                 episode reward: 0.5131,                 loss: 0.3285
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 159.3472 s
agent0:                 episode reward: -0.5937,                 loss: nan
agent1:                 episode reward: 0.5937,                 loss: 0.3299
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 159.9538 s
agent0:                 episode reward: -0.2624,                 loss: nan
agent1:                 episode reward: 0.2624,                 loss: 0.3296
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 160.5540 s
agent0:                 episode reward: -0.8501,                 loss: nan
agent1:                 episode reward: 0.8501,                 loss: 0.3302
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 161.1624 s
agent0:                 episode reward: -0.2714,                 loss: nan
agent1:                 episode reward: 0.2714,                 loss: 0.3252
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6065s / 161.7689 s
agent0:                 episode reward: -0.8452,                 loss: nan
agent1:                 episode reward: 0.8452,                 loss: 0.3320
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 162.3697 s
agent0:                 episode reward: -0.6084,                 loss: nan
agent1:                 episode reward: 0.6084,                 loss: 0.3297
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6067s / 162.9764 s
agent0:                 episode reward: -0.7776,                 loss: nan
agent1:                 episode reward: 0.7776,                 loss: 0.3313
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6061s / 163.5825 s
agent0:                 episode reward: -0.5027,                 loss: nan
agent1:                 episode reward: 0.5027,                 loss: 0.3311
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 164.1854 s
agent0:                 episode reward: -0.4216,                 loss: nan
agent1:                 episode reward: 0.4216,                 loss: 0.3345
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 164.7911 s
agent0:                 episode reward: -0.6835,                 loss: nan
agent1:                 episode reward: 0.6835,                 loss: 0.3327
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 165.3918 s
agent0:                 episode reward: -1.0890,                 loss: nan
agent1:                 episode reward: 1.0890,                 loss: 0.3334
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6147s / 166.0065 s
agent0:                 episode reward: -0.6596,                 loss: nan
agent1:                 episode reward: 0.6596,                 loss: 0.3355
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 166.6141 s
agent0:                 episode reward: -0.4892,                 loss: nan
agent1:                 episode reward: 0.4892,                 loss: 0.3385
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6200s / 167.2341 s
agent0:                 episode reward: -0.8626,                 loss: nan
agent1:                 episode reward: 0.8626,                 loss: 0.3318
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 167.8423 s
agent0:                 episode reward: -0.3876,                 loss: nan
agent1:                 episode reward: 0.3876,                 loss: 0.3299
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6065s / 168.4488 s
agent0:                 episode reward: -0.8840,                 loss: nan
agent1:                 episode reward: 0.8840,                 loss: 0.3314
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 169.0504 s
agent0:                 episode reward: -0.3424,                 loss: nan
agent1:                 episode reward: 0.3424,                 loss: 0.3322
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 169.6540 s
agent0:                 episode reward: -0.6569,                 loss: nan
agent1:                 episode reward: 0.6569,                 loss: 0.3355
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 170.2592 s
agent0:                 episode reward: -0.7128,                 loss: nan
agent1:                 episode reward: 0.7128,                 loss: 0.3314
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6061s / 170.8652 s
agent0:                 episode reward: -0.7711,                 loss: nan
agent1:                 episode reward: 0.7711,                 loss: 0.3319
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 171.4701 s
agent0:                 episode reward: -0.3723,                 loss: nan
agent1:                 episode reward: 0.3723,                 loss: 0.3327
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 172.0808 s
agent0:                 episode reward: -0.8468,                 loss: nan
agent1:                 episode reward: 0.8468,                 loss: 0.3334
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6103s / 172.6911 s
agent0:                 episode reward: -0.5641,                 loss: nan
agent1:                 episode reward: 0.5641,                 loss: 0.3337
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6068s / 173.2978 s
agent0:                 episode reward: -0.4045,                 loss: nan
agent1:                 episode reward: 0.4045,                 loss: 0.3331
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6098s / 173.9077 s
agent0:                 episode reward: -0.7091,                 loss: nan
agent1:                 episode reward: 0.7091,                 loss: 0.3348
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 174.5117 s
agent0:                 episode reward: -0.9005,                 loss: nan
agent1:                 episode reward: 0.9005,                 loss: 0.3336
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 175.1142 s
agent0:                 episode reward: -0.0594,                 loss: nan
agent1:                 episode reward: 0.0594,                 loss: 0.3355
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 175.7164 s
agent0:                 episode reward: -0.8370,                 loss: nan
agent1:                 episode reward: 0.8370,                 loss: 0.3353
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6101s / 176.3265 s
agent0:                 episode reward: -0.4998,                 loss: nan
agent1:                 episode reward: 0.4998,                 loss: 0.3392
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6148s / 176.9413 s
agent0:                 episode reward: -0.6724,                 loss: nan
agent1:                 episode reward: 0.6724,                 loss: 0.3384
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6189s / 177.5602 s
agent0:                 episode reward: -0.8997,                 loss: nan
agent1:                 episode reward: 0.8997,                 loss: 0.3354
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6135s / 178.1737 s
agent0:                 episode reward: -0.5736,                 loss: nan
agent1:                 episode reward: 0.5736,                 loss: 0.3344
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6092s / 178.7828 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.3358
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6208s / 179.4037 s
agent0:                 episode reward: -1.1551,                 loss: nan
agent1:                 episode reward: 1.1551,                 loss: 0.3316
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 180.0111 s
agent0:                 episode reward: -0.6675,                 loss: nan
agent1:                 episode reward: 0.6675,                 loss: 0.3370
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6133s / 180.6244 s
agent0:                 episode reward: -0.8259,                 loss: nan
agent1:                 episode reward: 0.8259,                 loss: 0.3320
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6129s / 181.2373 s
agent0:                 episode reward: -0.4902,                 loss: nan
agent1:                 episode reward: 0.4902,                 loss: 0.3315
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6079s / 181.8452 s
agent0:                 episode reward: -0.8501,                 loss: nan
agent1:                 episode reward: 0.8501,                 loss: 0.3374
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6078s / 182.4529 s
agent0:                 episode reward: -0.2939,                 loss: nan
agent1:                 episode reward: 0.2939,                 loss: 0.3366
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 183.0539 s
agent0:                 episode reward: -0.2420,                 loss: nan
agent1:                 episode reward: 0.2420,                 loss: 0.3289
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 183.6575 s
agent0:                 episode reward: -0.8644,                 loss: nan
agent1:                 episode reward: 0.8644,                 loss: 0.3273
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 184.2661 s
agent0:                 episode reward: -1.0642,                 loss: nan
agent1:                 episode reward: 1.0642,                 loss: 0.3218
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6117s / 184.8778 s
agent0:                 episode reward: -0.6804,                 loss: nan
agent1:                 episode reward: 0.6804,                 loss: 0.3246
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 185.4776 s
agent0:                 episode reward: -0.4268,                 loss: nan
agent1:                 episode reward: 0.4268,                 loss: 0.3307
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6147s / 186.0923 s
agent0:                 episode reward: -0.6015,                 loss: nan
agent1:                 episode reward: 0.6015,                 loss: 0.3281
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6243s / 186.7167 s
agent0:                 episode reward: -0.5075,                 loss: nan
agent1:                 episode reward: 0.5075,                 loss: 0.3267
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6167s / 187.3334 s
agent0:                 episode reward: -0.6159,                 loss: nan
agent1:                 episode reward: 0.6159,                 loss: 0.3292
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 187.9384 s
agent0:                 episode reward: -0.6818,                 loss: nan
agent1:                 episode reward: 0.6818,                 loss: 0.3283
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6061s / 188.5445 s
agent0:                 episode reward: -0.5771,                 loss: nan
agent1:                 episode reward: 0.5771,                 loss: 0.3248
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 189.1488 s
agent0:                 episode reward: -0.7423,                 loss: nan
agent1:                 episode reward: 0.7423,                 loss: 0.3276
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 189.7581 s
agent0:                 episode reward: -0.3248,                 loss: nan
agent1:                 episode reward: 0.3248,                 loss: 0.3307
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6177s / 190.3758 s
agent0:                 episode reward: -0.7306,                 loss: nan
agent1:                 episode reward: 0.7306,                 loss: 0.3262
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6081s / 190.9839 s
agent0:                 episode reward: -0.6732,                 loss: nan
agent1:                 episode reward: 0.6732,                 loss: 0.3293
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6166s / 191.6006 s
agent0:                 episode reward: -0.8621,                 loss: nan
agent1:                 episode reward: 0.8621,                 loss: 0.3251
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6116s / 192.2122 s
agent0:                 episode reward: -0.5058,                 loss: nan
agent1:                 episode reward: 0.5058,                 loss: 0.3302
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6161s / 192.8282 s
agent0:                 episode reward: -0.5885,                 loss: nan
agent1:                 episode reward: 0.5885,                 loss: 0.3269
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6133s / 193.4416 s
agent0:                 episode reward: -0.9675,                 loss: nan
agent1:                 episode reward: 0.9675,                 loss: 0.3373
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 194.0466 s
agent0:                 episode reward: -0.6126,                 loss: nan
agent1:                 episode reward: 0.6126,                 loss: 0.3371
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6113s / 194.6578 s
agent0:                 episode reward: -0.6517,                 loss: nan
agent1:                 episode reward: 0.6517,                 loss: 0.3374
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6218s / 195.2796 s
agent0:                 episode reward: -0.6887,                 loss: nan
agent1:                 episode reward: 0.6887,                 loss: 0.3399
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6131s / 195.8927 s
agent0:                 episode reward: -0.6982,                 loss: nan
agent1:                 episode reward: 0.6982,                 loss: 0.3342
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 196.5034 s
agent0:                 episode reward: -0.6395,                 loss: nan
agent1:                 episode reward: 0.6395,                 loss: 0.3369
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6134s / 197.1168 s
agent0:                 episode reward: -0.3494,                 loss: nan
agent1:                 episode reward: 0.3494,                 loss: 0.3370
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 197.7234 s
agent0:                 episode reward: -0.6874,                 loss: nan
agent1:                 episode reward: 0.6874,                 loss: 0.3346
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6115s / 198.3349 s
agent0:                 episode reward: -0.7511,                 loss: nan
agent1:                 episode reward: 0.7511,                 loss: 0.3380
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6183s / 198.9532 s
agent0:                 episode reward: -0.5932,                 loss: nan
agent1:                 episode reward: 0.5932,                 loss: 0.3324
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6106s / 199.5639 s
agent0:                 episode reward: -0.7735,                 loss: nan
agent1:                 episode reward: 0.7735,                 loss: 0.3392
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6151s / 200.1790 s
agent0:                 episode reward: -0.6733,                 loss: nan
agent1:                 episode reward: 0.6733,                 loss: 0.3365
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 200.7846 s
agent0:                 episode reward: -0.8002,                 loss: nan
agent1:                 episode reward: 0.8002,                 loss: 0.3320
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6139s / 201.3986 s
agent0:                 episode reward: -0.4293,                 loss: nan
agent1:                 episode reward: 0.4293,                 loss: 0.3401
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 202.0038 s
agent0:                 episode reward: -0.5974,                 loss: nan
agent1:                 episode reward: 0.5974,                 loss: 0.3396
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 202.6196 s
agent0:                 episode reward: -0.9638,                 loss: nan
agent1:                 episode reward: 0.9638,                 loss: 0.3396
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6150s / 203.2346 s
agent0:                 episode reward: -0.4119,                 loss: nan
agent1:                 episode reward: 0.4119,                 loss: 0.3358
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6149s / 203.8496 s
agent0:                 episode reward: -0.1474,                 loss: nan
agent1:                 episode reward: 0.1474,                 loss: 0.3389
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6201s / 204.4697 s
agent0:                 episode reward: -0.5558,                 loss: nan
agent1:                 episode reward: 0.5558,                 loss: 0.3341
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6240s / 205.0937 s
agent0:                 episode reward: -0.7405,                 loss: nan
agent1:                 episode reward: 0.7405,                 loss: 0.3316
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6083s / 205.7021 s
agent0:                 episode reward: -0.4694,                 loss: nan
agent1:                 episode reward: 0.4694,                 loss: 0.3350
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6167s / 206.3188 s
agent0:                 episode reward: -0.2332,                 loss: nan
agent1:                 episode reward: 0.2332,                 loss: 0.3354
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6125s / 206.9313 s
agent0:                 episode reward: -0.8892,                 loss: nan
agent1:                 episode reward: 0.8892,                 loss: 0.3349
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6124s / 207.5437 s
agent0:                 episode reward: -0.9454,                 loss: nan
agent1:                 episode reward: 0.9454,                 loss: 0.3363
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 208.1512 s
agent0:                 episode reward: -0.5151,                 loss: nan
agent1:                 episode reward: 0.5151,                 loss: 0.3343
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6142s / 208.7654 s
agent0:                 episode reward: -0.4879,                 loss: nan
agent1:                 episode reward: 0.4879,                 loss: 0.3323
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6239s / 209.3893 s
agent0:                 episode reward: -0.5578,                 loss: nan
agent1:                 episode reward: 0.5578,                 loss: 0.3359
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6157s / 210.0050 s
agent0:                 episode reward: -0.8289,                 loss: nan
agent1:                 episode reward: 0.8289,                 loss: 0.3351
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6137s / 210.6187 s
agent0:                 episode reward: -0.4817,                 loss: nan
agent1:                 episode reward: 0.4817,                 loss: 0.3398
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6174s / 211.2361 s
agent0:                 episode reward: -0.6530,                 loss: nan
agent1:                 episode reward: 0.6530,                 loss: 0.3341
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6178s / 211.8539 s
agent0:                 episode reward: -1.0198,                 loss: nan
agent1:                 episode reward: 1.0198,                 loss: 0.3327
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6139s / 212.4677 s
agent0:                 episode reward: -0.6236,                 loss: nan
agent1:                 episode reward: 0.6236,                 loss: 0.3334
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6178s / 213.0855 s
agent0:                 episode reward: -0.5453,                 loss: nan
agent1:                 episode reward: 0.5453,                 loss: 0.3360
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6117s / 213.6972 s
agent0:                 episode reward: -0.6577,                 loss: nan
agent1:                 episode reward: 0.6577,                 loss: 0.3302
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 214.3014 s
agent0:                 episode reward: -0.9489,                 loss: nan
agent1:                 episode reward: 0.9489,                 loss: 0.3138
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6157s / 214.9170 s
agent0:                 episode reward: -0.3216,                 loss: nan
agent1:                 episode reward: 0.3216,                 loss: 0.3114
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6175s / 215.5346 s
agent0:                 episode reward: -0.6381,                 loss: nan
agent1:                 episode reward: 0.6381,                 loss: 0.3166
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6099s / 216.1445 s
agent0:                 episode reward: -0.5147,                 loss: nan
agent1:                 episode reward: 0.5147,                 loss: 0.3152
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6102s / 216.7547 s
agent0:                 episode reward: -0.5402,                 loss: nan
agent1:                 episode reward: 0.5402,                 loss: 0.3133
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 217.3717 s
agent0:                 episode reward: -0.5436,                 loss: nan
agent1:                 episode reward: 0.5436,                 loss: 0.3141
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6188s / 217.9905 s
agent0:                 episode reward: -0.5940,                 loss: nan
agent1:                 episode reward: 0.5940,                 loss: 0.3122
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6210s / 218.6114 s
agent0:                 episode reward: -0.7915,                 loss: nan
agent1:                 episode reward: 0.7915,                 loss: 0.3085
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6169s / 219.2283 s
agent0:                 episode reward: -0.5160,                 loss: nan
agent1:                 episode reward: 0.5160,                 loss: 0.3135
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6250s / 219.8533 s
agent0:                 episode reward: -0.7186,                 loss: nan
agent1:                 episode reward: 0.7186,                 loss: 0.3102
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6176s / 220.4709 s
agent0:                 episode reward: -0.8523,                 loss: nan
agent1:                 episode reward: 0.8523,                 loss: 0.3148
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6199s / 221.0908 s
agent0:                 episode reward: -0.6969,                 loss: nan
agent1:                 episode reward: 0.6969,                 loss: 0.3133
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 221.7040 s
agent0:                 episode reward: -0.5012,                 loss: nan
agent1:                 episode reward: 0.5012,                 loss: 0.3138
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6177s / 222.3217 s
agent0:                 episode reward: -0.4709,                 loss: nan
agent1:                 episode reward: 0.4709,                 loss: 0.3100
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6227s / 222.9444 s
agent0:                 episode reward: -0.4817,                 loss: nan
agent1:                 episode reward: 0.4817,                 loss: 0.3158
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6250s / 223.5694 s
agent0:                 episode reward: -0.8586,                 loss: nan
agent1:                 episode reward: 0.8586,                 loss: 0.3077
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6234s / 224.1927 s
agent0:                 episode reward: -0.7954,                 loss: nan
agent1:                 episode reward: 0.7954,                 loss: 0.3345
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6203s / 224.8130 s
agent0:                 episode reward: -0.5838,                 loss: nan
agent1:                 episode reward: 0.5838,                 loss: 0.3366
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6214s / 225.4345 s
agent0:                 episode reward: -0.5218,                 loss: nan
agent1:                 episode reward: 0.5218,                 loss: 0.3419
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6194s / 226.0539 s
agent0:                 episode reward: -0.7767,                 loss: nan
agent1:                 episode reward: 0.7767,                 loss: 0.3375
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6293s / 226.6832 s
agent0:                 episode reward: -0.5893,                 loss: nan
agent1:                 episode reward: 0.5893,                 loss: 0.3395
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6273s / 227.3105 s
agent0:                 episode reward: -0.4408,                 loss: nan
agent1:                 episode reward: 0.4408,                 loss: 0.3368
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6265s / 227.9371 s
agent0:                 episode reward: -0.8555,                 loss: nan
agent1:                 episode reward: 0.8555,                 loss: 0.3392
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6308s / 228.5678 s
agent0:                 episode reward: -0.4615,                 loss: nan
agent1:                 episode reward: 0.4615,                 loss: 0.3409
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6272s / 229.1951 s
agent0:                 episode reward: -0.7207,                 loss: nan
agent1:                 episode reward: 0.7207,                 loss: 0.3394
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6220s / 229.8171 s
agent0:                 episode reward: -0.5954,                 loss: nan
agent1:                 episode reward: 0.5954,                 loss: 0.3414
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6244s / 230.4415 s
agent0:                 episode reward: -0.5455,                 loss: nan
agent1:                 episode reward: 0.5455,                 loss: 0.3398
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6284s / 231.0699 s
agent0:                 episode reward: -0.5716,                 loss: nan
agent1:                 episode reward: 0.5716,                 loss: 0.3388
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6298s / 231.6997 s
agent0:                 episode reward: -0.1197,                 loss: nan
agent1:                 episode reward: 0.1197,                 loss: 0.3368
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6256s / 232.3253 s
agent0:                 episode reward: -0.4312,                 loss: nan
agent1:                 episode reward: 0.4312,                 loss: 0.3382
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6273s / 232.9526 s
agent0:                 episode reward: -1.0118,                 loss: nan
agent1:                 episode reward: 1.0118,                 loss: 0.3383
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6209s / 233.5735 s
agent0:                 episode reward: -0.9557,                 loss: nan
agent1:                 episode reward: 0.9557,                 loss: 0.3369
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6154s / 234.1889 s
agent0:                 episode reward: -0.7104,                 loss: nan
agent1:                 episode reward: 0.7104,                 loss: 0.3361
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6342s / 234.8231 s
agent0:                 episode reward: -0.6648,                 loss: nan
agent1:                 episode reward: 0.6648,                 loss: 0.3303
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6138s / 235.4369 s
agent0:                 episode reward: -0.6274,                 loss: nan
agent1:                 episode reward: 0.6274,                 loss: 0.3249
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6220s / 236.0589 s
agent0:                 episode reward: -0.5314,                 loss: nan
agent1:                 episode reward: 0.5314,                 loss: 0.3293
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6322s / 236.6911 s
agent0:                 episode reward: -0.9117,                 loss: nan
agent1:                 episode reward: 0.9117,                 loss: 0.3303
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6284s / 237.3195 s
agent0:                 episode reward: -0.7150,                 loss: nan
agent1:                 episode reward: 0.7150,                 loss: 0.3321
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6264s / 237.9459 s
agent0:                 episode reward: -0.3136,                 loss: nan
agent1:                 episode reward: 0.3136,                 loss: 0.3309
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6219s / 238.5679 s
agent0:                 episode reward: -0.5835,                 loss: nan
agent1:                 episode reward: 0.5835,                 loss: 0.3286
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6309s / 239.1988 s
agent0:                 episode reward: -0.7701,                 loss: nan
agent1:                 episode reward: 0.7701,                 loss: 0.3294
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6220s / 239.8208 s
agent0:                 episode reward: -1.0430,                 loss: nan
agent1:                 episode reward: 1.0430,                 loss: 0.3307
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6204s / 240.4412 s
agent0:                 episode reward: -0.8623,                 loss: nan
agent1:                 episode reward: 0.8623,                 loss: 0.3278
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6284s / 241.0696 s
agent0:                 episode reward: -0.6608,                 loss: nan
agent1:                 episode reward: 0.6608,                 loss: 0.3298
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6245s / 241.6941 s
agent0:                 episode reward: -0.5633,                 loss: nan
agent1:                 episode reward: 0.5633,                 loss: 0.3287
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6227s / 242.3167 s
agent0:                 episode reward: -0.5242,                 loss: nan
agent1:                 episode reward: 0.5242,                 loss: 0.3304
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6297s / 242.9464 s
agent0:                 episode reward: -0.4745,                 loss: nan
agent1:                 episode reward: 0.4745,                 loss: 0.3274
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6327s / 243.5791 s
agent0:                 episode reward: -0.9894,                 loss: nan
agent1:                 episode reward: 0.9894,                 loss: 0.3277
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6298s / 244.2089 s
agent0:                 episode reward: -0.7296,                 loss: nan
agent1:                 episode reward: 0.7296,                 loss: 0.3292
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6240s / 244.8328 s
agent0:                 episode reward: -0.6026,                 loss: nan
agent1:                 episode reward: 0.6026,                 loss: 0.3256
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6246s / 245.4574 s
agent0:                 episode reward: -0.4975,                 loss: nan
agent1:                 episode reward: 0.4975,                 loss: 0.3216
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6168s / 246.0742 s
agent0:                 episode reward: -0.6689,                 loss: nan
agent1:                 episode reward: 0.6689,                 loss: 0.3221
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6197s / 246.6939 s
agent0:                 episode reward: -0.1555,                 loss: nan
agent1:                 episode reward: 0.1555,                 loss: 0.3187
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6250s / 247.3189 s
agent0:                 episode reward: -0.7369,                 loss: nan
agent1:                 episode reward: 0.7369,                 loss: 0.3181
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6438s / 247.9628 s
agent0:                 episode reward: -0.5670,                 loss: nan
agent1:                 episode reward: 0.5670,                 loss: 0.3249
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6346s / 248.5973 s
agent0:                 episode reward: -0.7948,                 loss: nan
agent1:                 episode reward: 0.7948,                 loss: 0.3203
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6273s / 249.2246 s
agent0:                 episode reward: -0.8728,                 loss: nan
agent1:                 episode reward: 0.8728,                 loss: 0.3164
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6296s / 249.8541 s
agent0:                 episode reward: -0.4645,                 loss: nan
agent1:                 episode reward: 0.4645,                 loss: 0.3209
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6259s / 250.4800 s
agent0:                 episode reward: -0.7635,                 loss: nan
agent1:                 episode reward: 0.7635,                 loss: 0.3154
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6298s / 251.1098 s
agent0:                 episode reward: -0.7893,                 loss: nan
agent1:                 episode reward: 0.7893,                 loss: 0.3193
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6301s / 251.7400 s
agent0:                 episode reward: -0.6614,                 loss: nan
agent1:                 episode reward: 0.6614,                 loss: 0.3179
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6251s / 252.3651 s
agent0:                 episode reward: -0.6181,                 loss: nan
agent1:                 episode reward: 0.6181,                 loss: 0.3201
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6344s / 252.9995 s
agent0:                 episode reward: -0.4202,                 loss: nan
agent1:                 episode reward: 0.4202,                 loss: 0.3210
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6367s / 253.6362 s
agent0:                 episode reward: -0.6160,                 loss: nan
agent1:                 episode reward: 0.6160,                 loss: 0.3214
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6315s / 254.2677 s
agent0:                 episode reward: -0.5726,                 loss: nan
agent1:                 episode reward: 0.5726,                 loss: 0.3205
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6327s / 254.9004 s
agent0:                 episode reward: -0.6722,                 loss: nan
agent1:                 episode reward: 0.6722,                 loss: 0.3192
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6258s / 255.5263 s
agent0:                 episode reward: -0.4679,                 loss: nan
agent1:                 episode reward: 0.4679,                 loss: 0.3310
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6280s / 256.1543 s
agent0:                 episode reward: -0.6555,                 loss: nan
agent1:                 episode reward: 0.6555,                 loss: 0.3326
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6292s / 256.7834 s
agent0:                 episode reward: -0.9178,                 loss: nan
agent1:                 episode reward: 0.9178,                 loss: 0.3340
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6232s / 257.4066 s
agent0:                 episode reward: -0.6109,                 loss: nan
agent1:                 episode reward: 0.6109,                 loss: 0.3334
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6272s / 258.0338 s
agent0:                 episode reward: -0.6389,                 loss: nan
agent1:                 episode reward: 0.6389,                 loss: 0.3344
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6294s / 258.6632 s
agent0:                 episode reward: -0.6572,                 loss: nan
agent1:                 episode reward: 0.6572,                 loss: 0.3319
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6337s / 259.2968 s
agent0:                 episode reward: -0.6518,                 loss: nan
agent1:                 episode reward: 0.6518,                 loss: 0.3301
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6337s / 259.9305 s
agent0:                 episode reward: -0.4318,                 loss: nan
agent1:                 episode reward: 0.4318,                 loss: 0.3346
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6268s / 260.5573 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.3325
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6214s / 261.1787 s
agent0:                 episode reward: -0.8357,                 loss: nan
agent1:                 episode reward: 0.8357,                 loss: 0.3332
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6345s / 261.8132 s
agent0:                 episode reward: -0.7531,                 loss: nan
agent1:                 episode reward: 0.7531,                 loss: 0.3293
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6240s / 262.4372 s
agent0:                 episode reward: -0.5761,                 loss: nan
agent1:                 episode reward: 0.5761,                 loss: 0.3302
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6281s / 263.0653 s
agent0:                 episode reward: -0.6846,                 loss: nan
agent1:                 episode reward: 0.6846,                 loss: 0.3311
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6313s / 263.6966 s
agent0:                 episode reward: -0.7557,                 loss: nan
agent1:                 episode reward: 0.7557,                 loss: 0.3316
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6256s / 264.3221 s
agent0:                 episode reward: -0.6844,                 loss: nan
agent1:                 episode reward: 0.6844,                 loss: 0.3306
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6392s / 264.9614 s
agent0:                 episode reward: -1.0113,                 loss: nan
agent1:                 episode reward: 1.0113,                 loss: 0.3325
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6343s / 265.5957 s
agent0:                 episode reward: -0.8886,                 loss: nan
agent1:                 episode reward: 0.8886,                 loss: 0.3299
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6371s / 266.2327 s
agent0:                 episode reward: -0.8692,                 loss: nan
agent1:                 episode reward: 0.8692,                 loss: 0.3124
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6227s / 266.8554 s
agent0:                 episode reward: -0.8150,                 loss: nan
agent1:                 episode reward: 0.8150,                 loss: 0.3162
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6350s / 267.4904 s
agent0:                 episode reward: -0.7061,                 loss: nan
agent1:                 episode reward: 0.7061,                 loss: 0.3175
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6349s / 268.1253 s
agent0:                 episode reward: -0.8437,                 loss: nan
agent1:                 episode reward: 0.8437,                 loss: 0.3127
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6328s / 268.7581 s
agent0:                 episode reward: -0.2711,                 loss: nan
agent1:                 episode reward: 0.2711,                 loss: 0.3190
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6338s / 269.3919 s
agent0:                 episode reward: -0.5156,                 loss: nan
agent1:                 episode reward: 0.5156,                 loss: 0.3182
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6336s / 270.0255 s
agent0:                 episode reward: -0.7758,                 loss: nan
agent1:                 episode reward: 0.7758,                 loss: 0.3151
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6351s / 270.6606 s
agent0:                 episode reward: -0.4753,                 loss: nan
agent1:                 episode reward: 0.4753,                 loss: 0.3178
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6457s / 271.3064 s
agent0:                 episode reward: -0.4124,                 loss: nan
agent1:                 episode reward: 0.4124,                 loss: 0.3199
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6350s / 271.9413 s
agent0:                 episode reward: -0.7061,                 loss: nan
agent1:                 episode reward: 0.7061,                 loss: 0.3152
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6391s / 272.5804 s
agent0:                 episode reward: -0.7911,                 loss: nan
agent1:                 episode reward: 0.7911,                 loss: 0.3169
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6403s / 273.2207 s
agent0:                 episode reward: -0.7118,                 loss: nan
agent1:                 episode reward: 0.7118,                 loss: 0.3146
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6456s / 273.8663 s
agent0:                 episode reward: -0.5513,                 loss: nan
agent1:                 episode reward: 0.5513,                 loss: 0.3127
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6268s / 274.4932 s
agent0:                 episode reward: -0.7214,                 loss: nan
agent1:                 episode reward: 0.7214,                 loss: 0.3141
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6394s / 275.1326 s
agent0:                 episode reward: -0.5108,                 loss: nan
agent1:                 episode reward: 0.5108,                 loss: 0.3144
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6286s / 275.7612 s
agent0:                 episode reward: -0.6996,                 loss: nan
agent1:                 episode reward: 0.6996,                 loss: 0.3180
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6325s / 276.3937 s
agent0:                 episode reward: -0.3890,                 loss: nan
agent1:                 episode reward: 0.3890,                 loss: 0.3141
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6411s / 277.0348 s
agent0:                 episode reward: -0.4386,                 loss: nan
agent1:                 episode reward: 0.4386,                 loss: 0.3147
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6444s / 277.6792 s
agent0:                 episode reward: -0.4526,                 loss: nan
agent1:                 episode reward: 0.4526,                 loss: 0.3163
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6392s / 278.3184 s
agent0:                 episode reward: -0.7265,                 loss: nan
agent1:                 episode reward: 0.7265,                 loss: 0.3181
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6333s / 278.9516 s
agent0:                 episode reward: -0.4371,                 loss: nan
agent1:                 episode reward: 0.4371,                 loss: 0.3132
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6468s / 279.5984 s
agent0:                 episode reward: -0.7713,                 loss: nan
agent1:                 episode reward: 0.7713,                 loss: 0.3111
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6401s / 280.2385 s
agent0:                 episode reward: -0.5679,                 loss: nan
agent1:                 episode reward: 0.5679,                 loss: 0.3075
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6336s / 280.8721 s
agent0:                 episode reward: -0.7155,                 loss: nan
agent1:                 episode reward: 0.7155,                 loss: 0.3099
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6351s / 281.5072 s
agent0:                 episode reward: -0.4941,                 loss: nan
agent1:                 episode reward: 0.4941,                 loss: 0.3086
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6507s / 282.1579 s
agent0:                 episode reward: -0.2304,                 loss: nan
agent1:                 episode reward: 0.2304,                 loss: 0.3127
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6486s / 282.8065 s
agent0:                 episode reward: -0.5116,                 loss: nan
agent1:                 episode reward: 0.5116,                 loss: 0.3140
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6410s / 283.4475 s
agent0:                 episode reward: -0.5195,                 loss: nan
agent1:                 episode reward: 0.5195,                 loss: 0.3160
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6297s / 284.0772 s
agent0:                 episode reward: -0.7190,                 loss: nan
agent1:                 episode reward: 0.7190,                 loss: 0.3133
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6449s / 284.7221 s
agent0:                 episode reward: -0.6851,                 loss: nan
agent1:                 episode reward: 0.6851,                 loss: 0.3107
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6402s / 285.3624 s
agent0:                 episode reward: -0.1722,                 loss: nan
agent1:                 episode reward: 0.1722,                 loss: 0.3118
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6333s / 285.9957 s
agent0:                 episode reward: -0.8248,                 loss: nan
agent1:                 episode reward: 0.8248,                 loss: 0.3090
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6368s / 286.6325 s
agent0:                 episode reward: -0.7991,                 loss: nan
agent1:                 episode reward: 0.7991,                 loss: 0.3119
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6355s / 287.2680 s
agent0:                 episode reward: -0.6814,                 loss: nan
agent1:                 episode reward: 0.6814,                 loss: 0.3363
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6403s / 287.9083 s
agent0:                 episode reward: -0.5613,                 loss: nan
agent1:                 episode reward: 0.5613,                 loss: 0.3366
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6551s / 288.5633 s
agent0:                 episode reward: -0.7353,                 loss: nan
agent1:                 episode reward: 0.7353,                 loss: 0.3324
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6421s / 289.2054 s
agent0:                 episode reward: -0.5405,                 loss: nan
agent1:                 episode reward: 0.5405,                 loss: 0.3340
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6415s / 289.8469 s
agent0:                 episode reward: -0.9622,                 loss: nan
agent1:                 episode reward: 0.9622,                 loss: 0.3342
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6457s / 290.4927 s
agent0:                 episode reward: -0.7262,                 loss: nan
agent1:                 episode reward: 0.7262,                 loss: 0.3344
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6457s / 291.1384 s
agent0:                 episode reward: -0.6696,                 loss: nan
agent1:                 episode reward: 0.6696,                 loss: 0.3332
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6402s / 291.7787 s
agent0:                 episode reward: -0.5081,                 loss: nan
agent1:                 episode reward: 0.5081,                 loss: 0.3328
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6482s / 292.4269 s
agent0:                 episode reward: -0.6471,                 loss: nan
agent1:                 episode reward: 0.6471,                 loss: 0.3325
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6452s / 293.0721 s
agent0:                 episode reward: -0.4997,                 loss: nan
agent1:                 episode reward: 0.4997,                 loss: 0.3361
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6441s / 293.7162 s
agent0:                 episode reward: -0.6515,                 loss: nan
agent1:                 episode reward: 0.6515,                 loss: 0.3380
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6383s / 294.3545 s
agent0:                 episode reward: -0.6184,                 loss: nan
agent1:                 episode reward: 0.6184,                 loss: 0.3309
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6329s / 294.9874 s
agent0:                 episode reward: -0.5742,                 loss: nan
agent1:                 episode reward: 0.5742,                 loss: 0.3320
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6461s / 295.6335 s
agent0:                 episode reward: -0.7946,                 loss: nan
agent1:                 episode reward: 0.7946,                 loss: 0.3322
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6462s / 296.2797 s
agent0:                 episode reward: -0.6852,                 loss: nan
agent1:                 episode reward: 0.6852,                 loss: 0.3349
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6492s / 296.9289 s
agent0:                 episode reward: -0.6039,                 loss: nan
agent1:                 episode reward: 0.6039,                 loss: 0.3376
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6371s / 297.5660 s
agent0:                 episode reward: -0.6165,                 loss: nan
agent1:                 episode reward: 0.6165,                 loss: 0.3343
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6426s / 298.2086 s
agent0:                 episode reward: -0.5667,                 loss: nan
agent1:                 episode reward: 0.5667,                 loss: 0.3024
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6790s / 298.8876 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.2966
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6500s / 299.5376 s
agent0:                 episode reward: -0.2426,                 loss: nan
agent1:                 episode reward: 0.2426,                 loss: 0.2969
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6356s / 300.1731 s
agent0:                 episode reward: -1.0753,                 loss: nan
agent1:                 episode reward: 1.0753,                 loss: 0.2980
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6367s / 300.8099 s
agent0:                 episode reward: -0.5754,                 loss: nan
agent1:                 episode reward: 0.5754,                 loss: 0.2960
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6450s / 301.4549 s
agent0:                 episode reward: -0.6588,                 loss: nan
agent1:                 episode reward: 0.6588,                 loss: 0.2976
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6444s / 302.0993 s
agent0:                 episode reward: -0.5869,                 loss: nan
agent1:                 episode reward: 0.5869,                 loss: 0.2969
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6458s / 302.7451 s
agent0:                 episode reward: -0.4660,                 loss: nan
agent1:                 episode reward: 0.4660,                 loss: 0.2940
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6336s / 303.3787 s
agent0:                 episode reward: -0.8366,                 loss: nan
agent1:                 episode reward: 0.8366,                 loss: 0.2971
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6412s / 304.0199 s
agent0:                 episode reward: -0.3524,                 loss: nan
agent1:                 episode reward: 0.3524,                 loss: 0.2978
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6423s / 304.6621 s
agent0:                 episode reward: -0.5276,                 loss: nan
agent1:                 episode reward: 0.5276,                 loss: 0.2975
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6434s / 305.3055 s
agent0:                 episode reward: -0.4645,                 loss: nan
agent1:                 episode reward: 0.4645,                 loss: 0.2945
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6574s / 305.9629 s
agent0:                 episode reward: -0.5229,                 loss: nan
agent1:                 episode reward: 0.5229,                 loss: 0.2958
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6355s / 306.5984 s
agent0:                 episode reward: -0.5527,                 loss: nan
agent1:                 episode reward: 0.5527,                 loss: 0.2953
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6493s / 307.2477 s
agent0:                 episode reward: -0.5270,                 loss: nan
agent1:                 episode reward: 0.5270,                 loss: 0.2987
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6425s / 307.8902 s
agent0:                 episode reward: -0.6918,                 loss: nan
agent1:                 episode reward: 0.6918,                 loss: 0.2966
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6422s / 308.5325 s
agent0:                 episode reward: -0.7647,                 loss: nan
agent1:                 episode reward: 0.7647,                 loss: 0.3076
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6483s / 309.1807 s
agent0:                 episode reward: -0.7787,                 loss: nan
agent1:                 episode reward: 0.7787,                 loss: 0.3221
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6449s / 309.8256 s
agent0:                 episode reward: -0.6639,                 loss: nan
agent1:                 episode reward: 0.6639,                 loss: 0.3179
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6456s / 310.4712 s
agent0:                 episode reward: -0.2028,                 loss: nan
agent1:                 episode reward: 0.2028,                 loss: 0.3188
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6433s / 311.1145 s
agent0:                 episode reward: -0.8356,                 loss: nan
agent1:                 episode reward: 0.8356,                 loss: 0.3164
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6431s / 311.7575 s
agent0:                 episode reward: -0.6473,                 loss: nan
agent1:                 episode reward: 0.6473,                 loss: 0.3162
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6531s / 312.4107 s
agent0:                 episode reward: -0.5315,                 loss: nan
agent1:                 episode reward: 0.5315,                 loss: 0.3162
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6547s / 313.0654 s
agent0:                 episode reward: -0.6512,                 loss: nan
agent1:                 episode reward: 0.6512,                 loss: 0.3188
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6461s / 313.7116 s
agent0:                 episode reward: -0.7279,                 loss: nan
agent1:                 episode reward: 0.7279,                 loss: 0.3192
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6506s / 314.3622 s
agent0:                 episode reward: -0.4540,                 loss: nan
agent1:                 episode reward: 0.4540,                 loss: 0.3202
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6570s / 315.0192 s
agent0:                 episode reward: -0.8055,                 loss: nan
agent1:                 episode reward: 0.8055,                 loss: 0.3160
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6519s / 315.6711 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.3167
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6605s / 316.3316 s
agent0:                 episode reward: -0.8210,                 loss: nan
agent1:                 episode reward: 0.8210,                 loss: 0.3177
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6522s / 316.9839 s
agent0:                 episode reward: -0.6823,                 loss: nan
agent1:                 episode reward: 0.6823,                 loss: 0.3161
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6395s / 317.6233 s
agent0:                 episode reward: -0.5302,                 loss: nan
agent1:                 episode reward: 0.5302,                 loss: 0.3136
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6504s / 318.2738 s
agent0:                 episode reward: -0.3964,                 loss: nan
agent1:                 episode reward: 0.3964,                 loss: 0.3180
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6551s / 318.9289 s
agent0:                 episode reward: -0.3682,                 loss: nan
agent1:                 episode reward: 0.3682,                 loss: 0.3175
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6567s / 319.5856 s
agent0:                 episode reward: -0.5050,                 loss: nan
agent1:                 episode reward: 0.5050,                 loss: 0.3370
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6481s / 320.2337 s
agent0:                 episode reward: -0.1814,                 loss: nan
agent1:                 episode reward: 0.1814,                 loss: 0.3265
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6572s / 320.8909 s
agent0:                 episode reward: -0.3101,                 loss: nan
agent1:                 episode reward: 0.3101,                 loss: 0.3306
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6556s / 321.5465 s
agent0:                 episode reward: -0.6417,                 loss: nan
agent1:                 episode reward: 0.6417,                 loss: 0.3224
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6542s / 322.2007 s
agent0:                 episode reward: -0.5396,                 loss: nan
agent1:                 episode reward: 0.5396,                 loss: 0.3223
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6491s / 322.8498 s
agent0:                 episode reward: -0.7311,                 loss: nan
agent1:                 episode reward: 0.7311,                 loss: 0.3254
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6473s / 323.4971 s
agent0:                 episode reward: -0.8730,                 loss: nan
agent1:                 episode reward: 0.8730,                 loss: 0.3251
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6526s / 324.1497 s
agent0:                 episode reward: -0.5402,                 loss: nan
agent1:                 episode reward: 0.5402,                 loss: 0.3258
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6465s / 324.7962 s
agent0:                 episode reward: -0.8464,                 loss: nan
agent1:                 episode reward: 0.8464,                 loss: 0.3237
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6581s / 325.4543 s
agent0:                 episode reward: -0.2984,                 loss: nan
agent1:                 episode reward: 0.2984,                 loss: 0.3269
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6517s / 326.1059 s
agent0:                 episode reward: -0.5971,                 loss: nan
agent1:                 episode reward: 0.5971,                 loss: 0.3220
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6551s / 326.7610 s
agent0:                 episode reward: -0.5367,                 loss: nan
agent1:                 episode reward: 0.5367,                 loss: 0.3267
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6535s / 327.4145 s
agent0:                 episode reward: -0.4363,                 loss: nan
agent1:                 episode reward: 0.4363,                 loss: 0.3244
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6432s / 328.0577 s
agent0:                 episode reward: -0.5363,                 loss: nan
agent1:                 episode reward: 0.5363,                 loss: 0.3264
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6484s / 328.7061 s
agent0:                 episode reward: -0.6389,                 loss: nan
agent1:                 episode reward: 0.6389,                 loss: 0.3240
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6503s / 329.3564 s
agent0:                 episode reward: -0.4531,                 loss: nan
agent1:                 episode reward: 0.4531,                 loss: 0.3231
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6579s / 330.0143 s
agent0:                 episode reward: -0.8610,                 loss: nan
agent1:                 episode reward: 0.8610,                 loss: 0.3263
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6560s / 330.6703 s
agent0:                 episode reward: -0.1148,                 loss: nan
agent1:                 episode reward: 0.1148,                 loss: 0.2940
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6506s / 331.3208 s
agent0:                 episode reward: -0.7048,                 loss: nan
agent1:                 episode reward: 0.7048,                 loss: 0.2744
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6464s / 331.9672 s
agent0:                 episode reward: -0.7276,                 loss: nan
agent1:                 episode reward: 0.7276,                 loss: 0.2818
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6527s / 332.6200 s
agent0:                 episode reward: -0.5873,                 loss: nan
agent1:                 episode reward: 0.5873,                 loss: 0.2816
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6439s / 333.2639 s
agent0:                 episode reward: -0.6228,                 loss: nan
agent1:                 episode reward: 0.6228,                 loss: 0.2796
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6544s / 333.9183 s
agent0:                 episode reward: -0.2863,                 loss: nan
agent1:                 episode reward: 0.2863,                 loss: 0.2772
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6527s / 334.5710 s
agent0:                 episode reward: -0.5947,                 loss: nan
agent1:                 episode reward: 0.5947,                 loss: 0.2778
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6494s / 335.2204 s
agent0:                 episode reward: -0.5695,                 loss: nan
agent1:                 episode reward: 0.5695,                 loss: 0.2803
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6533s / 335.8737 s
agent0:                 episode reward: -0.6672,                 loss: nan
agent1:                 episode reward: 0.6672,                 loss: 0.2784
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6495s / 336.5232 s
agent0:                 episode reward: -0.7766,                 loss: nan
agent1:                 episode reward: 0.7766,                 loss: 0.2787
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6542s / 337.1774 s
agent0:                 episode reward: -0.6012,                 loss: nan
agent1:                 episode reward: 0.6012,                 loss: 0.2803
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6504s / 337.8278 s
agent0:                 episode reward: -0.6159,                 loss: nan
agent1:                 episode reward: 0.6159,                 loss: 0.2739
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6569s / 338.4847 s
agent0:                 episode reward: -0.8429,                 loss: nan
agent1:                 episode reward: 0.8429,                 loss: 0.2806
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6638s / 339.1485 s
agent0:                 episode reward: -0.9661,                 loss: nan
agent1:                 episode reward: 0.9661,                 loss: 0.2818
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6447s / 339.7932 s
agent0:                 episode reward: -0.7157,                 loss: nan
agent1:                 episode reward: 0.7157,                 loss: 0.2817
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6592s / 340.4523 s
agent0:                 episode reward: -0.2179,                 loss: nan
agent1:                 episode reward: 0.2179,                 loss: 0.2774
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6590s / 341.1113 s
agent0:                 episode reward: -0.6911,                 loss: nan
agent1:                 episode reward: 0.6911,                 loss: 0.3082
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6586s / 341.7700 s
agent0:                 episode reward: -0.5588,                 loss: nan
agent1:                 episode reward: 0.5588,                 loss: 0.3339
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6612s / 342.4312 s
agent0:                 episode reward: -0.8273,                 loss: nan
agent1:                 episode reward: 0.8273,                 loss: 0.3323
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6541s / 343.0853 s
agent0:                 episode reward: -0.6247,                 loss: nan
agent1:                 episode reward: 0.6247,                 loss: 0.3339
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6541s / 343.7395 s
agent0:                 episode reward: -0.3511,                 loss: nan
agent1:                 episode reward: 0.3511,                 loss: 0.3342
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6515s / 344.3910 s
agent0:                 episode reward: -0.7520,                 loss: nan
agent1:                 episode reward: 0.7520,                 loss: 0.3317
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6453s / 345.0363 s
agent0:                 episode reward: -0.8770,                 loss: nan
agent1:                 episode reward: 0.8770,                 loss: 0.3325
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6612s / 345.6975 s
agent0:                 episode reward: -0.6534,                 loss: nan
agent1:                 episode reward: 0.6534,                 loss: 0.3326
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6566s / 346.3541 s
agent0:                 episode reward: -0.8071,                 loss: nan
agent1:                 episode reward: 0.8071,                 loss: 0.3368
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6665s / 347.0205 s
agent0:                 episode reward: -0.8377,                 loss: nan
agent1:                 episode reward: 0.8377,                 loss: 0.3350
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6496s / 347.6702 s
agent0:                 episode reward: -0.3307,                 loss: nan
agent1:                 episode reward: 0.3307,                 loss: 0.3328
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6610s / 348.3311 s
agent0:                 episode reward: -0.5433,                 loss: nan
agent1:                 episode reward: 0.5433,                 loss: 0.3341
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6626s / 348.9938 s
agent0:                 episode reward: -0.4696,                 loss: nan
agent1:                 episode reward: 0.4696,                 loss: 0.3327
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6512s / 349.6449 s
agent0:                 episode reward: -0.6479,                 loss: nan
agent1:                 episode reward: 0.6479,                 loss: 0.3350
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6626s / 350.3076 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.3334
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6676s / 350.9752 s
agent0:                 episode reward: -0.4781,                 loss: nan
agent1:                 episode reward: 0.4781,                 loss: 0.3334
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6504s / 351.6256 s
agent0:                 episode reward: -0.6047,                 loss: nan
agent1:                 episode reward: 0.6047,                 loss: 0.3340
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6551s / 352.2807 s
agent0:                 episode reward: -0.5175,                 loss: nan
agent1:                 episode reward: 0.5175,                 loss: 0.3349
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6621s / 352.9428 s
agent0:                 episode reward: -0.1199,                 loss: nan
agent1:                 episode reward: 0.1199,                 loss: 0.3171
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6610s / 353.6037 s
agent0:                 episode reward: -0.3886,                 loss: nan
agent1:                 episode reward: 0.3886,                 loss: 0.3163
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6496s / 354.2533 s
agent0:                 episode reward: -0.4921,                 loss: nan
agent1:                 episode reward: 0.4921,                 loss: 0.3151
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6638s / 354.9171 s
agent0:                 episode reward: -0.7695,                 loss: nan
agent1:                 episode reward: 0.7695,                 loss: 0.3135
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6646s / 355.5817 s
agent0:                 episode reward: -0.8160,                 loss: nan
agent1:                 episode reward: 0.8160,                 loss: 0.3184
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6592s / 356.2409 s
agent0:                 episode reward: -0.7257,                 loss: nan
agent1:                 episode reward: 0.7257,                 loss: 0.3131
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6587s / 356.8995 s
agent0:                 episode reward: -0.6958,                 loss: nan
agent1:                 episode reward: 0.6958,                 loss: 0.3126
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6650s / 357.5645 s
agent0:                 episode reward: -0.5101,                 loss: nan
agent1:                 episode reward: 0.5101,                 loss: 0.3120
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6602s / 358.2247 s
agent0:                 episode reward: -0.4833,                 loss: nan
agent1:                 episode reward: 0.4833,                 loss: 0.3157
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6621s / 358.8868 s
agent0:                 episode reward: -0.6463,                 loss: nan
agent1:                 episode reward: 0.6463,                 loss: 0.3174
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6713s / 359.5581 s
agent0:                 episode reward: -0.3836,                 loss: nan
agent1:                 episode reward: 0.3836,                 loss: 0.3156
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6681s / 360.2262 s
agent0:                 episode reward: -0.7488,                 loss: nan
agent1:                 episode reward: 0.7488,                 loss: 0.3136
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6712s / 360.8975 s
agent0:                 episode reward: -0.4242,                 loss: nan
agent1:                 episode reward: 0.4242,                 loss: 0.3151
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6636s / 361.5610 s
agent0:                 episode reward: -0.9141,                 loss: nan
agent1:                 episode reward: 0.9141,                 loss: 0.3148
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6645s / 362.2255 s
agent0:                 episode reward: -0.5233,                 loss: nan
agent1:                 episode reward: 0.5233,                 loss: 0.3154
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6589s / 362.8845 s
agent0:                 episode reward: -0.6299,                 loss: nan
agent1:                 episode reward: 0.6299,                 loss: 0.3177
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6670s / 363.5515 s
agent0:                 episode reward: -0.6088,                 loss: nan
agent1:                 episode reward: 0.6088,                 loss: 0.2845
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6665s / 364.2180 s
agent0:                 episode reward: -0.7209,                 loss: nan
agent1:                 episode reward: 0.7209,                 loss: 0.2646
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6707s / 364.8887 s
agent0:                 episode reward: -0.6823,                 loss: nan
agent1:                 episode reward: 0.6823,                 loss: 0.2655
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6578s / 365.5465 s
agent0:                 episode reward: -0.4918,                 loss: nan
agent1:                 episode reward: 0.4918,                 loss: 0.2623
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6515s / 366.1980 s
agent0:                 episode reward: -0.7516,                 loss: nan
agent1:                 episode reward: 0.7516,                 loss: 0.2659
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6541s / 366.8521 s
agent0:                 episode reward: -0.8533,                 loss: nan
agent1:                 episode reward: 0.8533,                 loss: 0.2626
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6576s / 367.5096 s
agent0:                 episode reward: -0.6759,                 loss: nan
agent1:                 episode reward: 0.6759,                 loss: 0.2577
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6642s / 368.1739 s
agent0:                 episode reward: -0.7500,                 loss: nan
agent1:                 episode reward: 0.7500,                 loss: 0.2593
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6662s / 368.8401 s
agent0:                 episode reward: -0.5819,                 loss: nan
agent1:                 episode reward: 0.5819,                 loss: 0.2603
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6527s / 369.4928 s
agent0:                 episode reward: -0.7387,                 loss: nan
agent1:                 episode reward: 0.7387,                 loss: 0.2611
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6607s / 370.1535 s
agent0:                 episode reward: -0.4944,                 loss: nan
agent1:                 episode reward: 0.4944,                 loss: 0.2618
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6616s / 370.8151 s
agent0:                 episode reward: -0.8868,                 loss: nan
agent1:                 episode reward: 0.8868,                 loss: 0.2608
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6739s / 371.4890 s
agent0:                 episode reward: -0.8667,                 loss: nan
agent1:                 episode reward: 0.8667,                 loss: 0.2606
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6727s / 372.1616 s
agent0:                 episode reward: -0.4138,                 loss: nan
agent1:                 episode reward: 0.4138,                 loss: 0.2591
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6697s / 372.8314 s
agent0:                 episode reward: -0.6907,                 loss: nan
agent1:                 episode reward: 0.6907,                 loss: 0.2605
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6628s / 373.4941 s
agent0:                 episode reward: -0.7011,                 loss: nan
agent1:                 episode reward: 0.7011,                 loss: 0.2602
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6741s / 374.1682 s
agent0:                 episode reward: -0.6826,                 loss: nan
agent1:                 episode reward: 0.6826,                 loss: 0.3093
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6790s / 374.8473 s
agent0:                 episode reward: -0.8051,                 loss: nan
agent1:                 episode reward: 0.8051,                 loss: 0.3423
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6614s / 375.5087 s
agent0:                 episode reward: -0.8051,                 loss: nan
agent1:                 episode reward: 0.8051,                 loss: 0.3416
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6659s / 376.1746 s
agent0:                 episode reward: -0.6110,                 loss: nan
agent1:                 episode reward: 0.6110,                 loss: 0.3427
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6758s / 376.8504 s
agent0:                 episode reward: -0.5411,                 loss: nan
agent1:                 episode reward: 0.5411,                 loss: 0.3428
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6681s / 377.5185 s
agent0:                 episode reward: -0.7070,                 loss: nan
agent1:                 episode reward: 0.7070,                 loss: 0.3456
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6863s / 378.2048 s
agent0:                 episode reward: -0.4418,                 loss: nan
agent1:                 episode reward: 0.4418,                 loss: 0.3401
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6778s / 378.8827 s
agent0:                 episode reward: -0.8535,                 loss: nan
agent1:                 episode reward: 0.8535,                 loss: 0.3434
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6858s / 379.5685 s
agent0:                 episode reward: -0.5941,                 loss: nan
agent1:                 episode reward: 0.5941,                 loss: 0.3410
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6755s / 380.2440 s
agent0:                 episode reward: -0.8179,                 loss: nan
agent1:                 episode reward: 0.8179,                 loss: 0.3415
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6785s / 380.9225 s
agent0:                 episode reward: -0.4044,                 loss: nan
agent1:                 episode reward: 0.4044,                 loss: 0.3436
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6816s / 381.6040 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.3407
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6754s / 382.2794 s
agent0:                 episode reward: -0.8838,                 loss: nan
agent1:                 episode reward: 0.8838,                 loss: 0.3438
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6786s / 382.9581 s
agent0:                 episode reward: -0.7120,                 loss: nan
agent1:                 episode reward: 0.7120,                 loss: 0.3405
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6896s / 383.6477 s
agent0:                 episode reward: -0.7477,                 loss: nan
agent1:                 episode reward: 0.7477,                 loss: 0.3459
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6726s / 384.3203 s
agent0:                 episode reward: -0.7904,                 loss: nan
agent1:                 episode reward: 0.7904,                 loss: 0.3441
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6776s / 384.9979 s
agent0:                 episode reward: -0.5517,                 loss: nan
agent1:                 episode reward: 0.5517,                 loss: 0.3454
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6791s / 385.6770 s
agent0:                 episode reward: -0.6514,                 loss: nan
agent1:                 episode reward: 0.6514,                 loss: 0.3371
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6812s / 386.3582 s
agent0:                 episode reward: -0.8388,                 loss: nan
agent1:                 episode reward: 0.8388,                 loss: 0.3176
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6729s / 387.0311 s
agent0:                 episode reward: -0.1231,                 loss: nan
agent1:                 episode reward: 0.1231,                 loss: 0.3162
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6746s / 387.7057 s
agent0:                 episode reward: -0.2257,                 loss: nan
agent1:                 episode reward: 0.2257,                 loss: 0.3149
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6800s / 388.3857 s
agent0:                 episode reward: -0.3930,                 loss: nan
agent1:                 episode reward: 0.3930,                 loss: 0.3191
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6828s / 389.0685 s
agent0:                 episode reward: -0.4033,                 loss: nan
agent1:                 episode reward: 0.4033,                 loss: 0.3167
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6778s / 389.7463 s
agent0:                 episode reward: -0.4362,                 loss: nan
agent1:                 episode reward: 0.4362,                 loss: 0.3168
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6848s / 390.4311 s
agent0:                 episode reward: -0.5174,                 loss: nan
agent1:                 episode reward: 0.5174,                 loss: 0.3177
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6759s / 391.1070 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.3130
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6791s / 391.7861 s
agent0:                 episode reward: -1.0835,                 loss: nan
agent1:                 episode reward: 1.0835,                 loss: 0.3188
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6796s / 392.4657 s
agent0:                 episode reward: -0.4602,                 loss: nan
agent1:                 episode reward: 0.4602,                 loss: 0.3153
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6793s / 393.1450 s
agent0:                 episode reward: -0.7031,                 loss: nan
agent1:                 episode reward: 0.7031,                 loss: 0.3140
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6628s / 393.8077 s
agent0:                 episode reward: -0.8501,                 loss: nan
agent1:                 episode reward: 0.8501,                 loss: 0.3137
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6679s / 394.4756 s
agent0:                 episode reward: -0.5901,                 loss: nan
agent1:                 episode reward: 0.5901,                 loss: 0.3177
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6785s / 395.1542 s
agent0:                 episode reward: -0.2728,                 loss: nan
agent1:                 episode reward: 0.2728,                 loss: 0.3167
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6883s / 395.8424 s
agent0:                 episode reward: -0.4722,                 loss: nan
agent1:                 episode reward: 0.4722,                 loss: 0.3187
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6744s / 396.5168 s
agent0:                 episode reward: -0.5672,                 loss: nan
agent1:                 episode reward: 0.5672,                 loss: 0.3213
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6948s / 397.2116 s
agent0:                 episode reward: -0.4592,                 loss: nan
agent1:                 episode reward: 0.4592,                 loss: 0.2856
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6772s / 397.8888 s
agent0:                 episode reward: -0.6495,                 loss: nan
agent1:                 episode reward: 0.6495,                 loss: 0.2675
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6884s / 398.5772 s
agent0:                 episode reward: -0.7369,                 loss: nan
agent1:                 episode reward: 0.7369,                 loss: 0.2649
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6785s / 399.2556 s
agent0:                 episode reward: -0.8410,                 loss: nan
agent1:                 episode reward: 0.8410,                 loss: 0.2657
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6875s / 399.9431 s
agent0:                 episode reward: -0.8551,                 loss: nan
agent1:                 episode reward: 0.8551,                 loss: 0.2642
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6698s / 400.6129 s
agent0:                 episode reward: -0.2122,                 loss: nan
agent1:                 episode reward: 0.2122,                 loss: 0.2671
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6822s / 401.2951 s
agent0:                 episode reward: -1.0604,                 loss: nan
agent1:                 episode reward: 1.0604,                 loss: 0.2684
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6767s / 401.9718 s
agent0:                 episode reward: -0.8029,                 loss: nan
agent1:                 episode reward: 0.8029,                 loss: 0.2672
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6821s / 402.6539 s
agent0:                 episode reward: -0.6580,                 loss: nan
agent1:                 episode reward: 0.6580,                 loss: 0.2647
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6819s / 403.3358 s
agent0:                 episode reward: -0.5979,                 loss: nan
agent1:                 episode reward: 0.5979,                 loss: 0.2669
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6844s / 404.0202 s
agent0:                 episode reward: -0.6325,                 loss: nan
agent1:                 episode reward: 0.6325,                 loss: 0.2641
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6900s / 404.7102 s
agent0:                 episode reward: -0.6131,                 loss: nan
agent1:                 episode reward: 0.6131,                 loss: 0.2673
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6760s / 405.3862 s
agent0:                 episode reward: -0.7444,                 loss: nan
agent1:                 episode reward: 0.7444,                 loss: 0.2667
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6803s / 406.0665 s
agent0:                 episode reward: -0.6078,                 loss: nan
agent1:                 episode reward: 0.6078,                 loss: 0.2628
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6769s / 406.7434 s
agent0:                 episode reward: -0.4270,                 loss: nan
agent1:                 episode reward: 0.4270,                 loss: 0.2633
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6790s / 407.4224 s
agent0:                 episode reward: -0.4682,                 loss: nan
agent1:                 episode reward: 0.4682,                 loss: 0.2623
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6751s / 408.0975 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: 0.3091
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6886s / 408.7862 s
agent0:                 episode reward: -0.8425,                 loss: nan
agent1:                 episode reward: 0.8425,                 loss: 0.3420
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6783s / 409.4645 s
agent0:                 episode reward: -0.4639,                 loss: nan
agent1:                 episode reward: 0.4639,                 loss: 0.3447
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6693s / 410.1338 s
agent0:                 episode reward: -0.3846,                 loss: nan
agent1:                 episode reward: 0.3846,                 loss: 0.3427
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6866s / 410.8203 s
agent0:                 episode reward: -0.3747,                 loss: nan
agent1:                 episode reward: 0.3747,                 loss: 0.3419
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6826s / 411.5029 s
agent0:                 episode reward: -0.6518,                 loss: nan
agent1:                 episode reward: 0.6518,                 loss: 0.3466
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6770s / 412.1799 s
agent0:                 episode reward: -0.8866,                 loss: nan
agent1:                 episode reward: 0.8866,                 loss: 0.3444
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6884s / 412.8683 s
agent0:                 episode reward: -0.8766,                 loss: nan
agent1:                 episode reward: 0.8766,                 loss: 0.3429
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6832s / 413.5516 s
agent0:                 episode reward: -0.8920,                 loss: nan
agent1:                 episode reward: 0.8920,                 loss: 0.3401
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6818s / 414.2334 s
agent0:                 episode reward: -0.8576,                 loss: nan
agent1:                 episode reward: 0.8576,                 loss: 0.3419
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6836s / 414.9170 s
agent0:                 episode reward: -0.5785,                 loss: nan
agent1:                 episode reward: 0.5785,                 loss: 0.3427
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6762s / 415.5931 s
agent0:                 episode reward: -0.3064,                 loss: nan
agent1:                 episode reward: 0.3064,                 loss: 0.3418
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6777s / 416.2709 s
agent0:                 episode reward: -0.6000,                 loss: nan
agent1:                 episode reward: 0.6000,                 loss: 0.3405
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6952s / 416.9661 s
agent0:                 episode reward: -0.9341,                 loss: nan
agent1:                 episode reward: 0.9341,                 loss: 0.3437
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6812s / 417.6473 s
agent0:                 episode reward: -0.4533,                 loss: nan
agent1:                 episode reward: 0.4533,                 loss: 0.3442
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6845s / 418.3318 s
agent0:                 episode reward: -0.6419,                 loss: nan
agent1:                 episode reward: 0.6419,                 loss: 0.3438
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6687s / 419.0005 s
agent0:                 episode reward: -0.6527,                 loss: nan
agent1:                 episode reward: 0.6527,                 loss: 0.3449
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6826s / 419.6831 s
agent0:                 episode reward: -0.5874,                 loss: nan
agent1:                 episode reward: 0.5874,                 loss: 0.3245
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6874s / 420.3705 s
agent0:                 episode reward: -0.4805,                 loss: nan
agent1:                 episode reward: 0.4805,                 loss: 0.3105
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6967s / 421.0671 s
agent0:                 episode reward: -0.8597,                 loss: nan
agent1:                 episode reward: 0.8597,                 loss: 0.3123
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6791s / 421.7462 s
agent0:                 episode reward: -0.8526,                 loss: nan
agent1:                 episode reward: 0.8526,                 loss: 0.3150
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6863s / 422.4325 s
agent0:                 episode reward: -0.7664,                 loss: nan
agent1:                 episode reward: 0.7664,                 loss: 0.3153
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6999s / 423.1324 s
agent0:                 episode reward: -0.6612,                 loss: nan
agent1:                 episode reward: 0.6612,                 loss: 0.3080
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6789s / 423.8113 s
agent0:                 episode reward: -0.4088,                 loss: nan
agent1:                 episode reward: 0.4088,                 loss: 0.3110
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6792s / 424.4905 s
agent0:                 episode reward: -0.1114,                 loss: nan
agent1:                 episode reward: 0.1114,                 loss: 0.3100
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6863s / 425.1768 s
agent0:                 episode reward: -0.3408,                 loss: nan
agent1:                 episode reward: 0.3408,                 loss: 0.3142
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6893s / 425.8661 s
agent0:                 episode reward: -0.5700,                 loss: nan
agent1:                 episode reward: 0.5700,                 loss: 0.3100
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6851s / 426.5512 s
agent0:                 episode reward: -0.3122,                 loss: nan
agent1:                 episode reward: 0.3122,                 loss: 0.3101
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6814s / 427.2326 s
agent0:                 episode reward: -0.6497,                 loss: nan
agent1:                 episode reward: 0.6497,                 loss: 0.3095
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6831s / 427.9157 s
agent0:                 episode reward: -0.5133,                 loss: nan
agent1:                 episode reward: 0.5133,                 loss: 0.3094
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6890s / 428.6047 s
agent0:                 episode reward: -0.8828,                 loss: nan
agent1:                 episode reward: 0.8828,                 loss: 0.3114
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6814s / 429.2862 s
agent0:                 episode reward: -0.4431,                 loss: nan
agent1:                 episode reward: 0.4431,                 loss: 0.3093
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6846s / 429.9707 s
agent0:                 episode reward: -0.4156,                 loss: nan
agent1:                 episode reward: 0.4156,                 loss: 0.3107
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6892s / 430.6600 s
agent0:                 episode reward: -0.8689,                 loss: nan
agent1:                 episode reward: 0.8689,                 loss: 0.3122
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6933s / 431.3533 s
agent0:                 episode reward: -0.5463,                 loss: nan
agent1:                 episode reward: 0.5463,                 loss: 0.2855
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6930s / 432.0462 s
agent0:                 episode reward: -0.7519,                 loss: nan
agent1:                 episode reward: 0.7519,                 loss: 0.2722
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6992s / 432.7455 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.2719
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6956s / 433.4411 s
agent0:                 episode reward: -0.9374,                 loss: nan
agent1:                 episode reward: 0.9374,                 loss: 0.2705
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7056s / 434.1466 s
agent0:                 episode reward: -0.3236,                 loss: nan
agent1:                 episode reward: 0.3236,                 loss: 0.2665
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7009s / 434.8475 s
agent0:                 episode reward: -0.6710,                 loss: nan
agent1:                 episode reward: 0.6710,                 loss: 0.2690
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6904s / 435.5379 s
agent0:                 episode reward: -0.6972,                 loss: nan
agent1:                 episode reward: 0.6972,                 loss: 0.2746
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6901s / 436.2281 s
agent0:                 episode reward: -0.5627,                 loss: nan
agent1:                 episode reward: 0.5627,                 loss: 0.2692
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6990s / 436.9271 s
agent0:                 episode reward: -0.4280,                 loss: nan
agent1:                 episode reward: 0.4280,                 loss: 0.2703
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6950s / 437.6221 s
agent0:                 episode reward: -1.0477,                 loss: nan
agent1:                 episode reward: 1.0477,                 loss: 0.2717
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6975s / 438.3196 s
agent0:                 episode reward: -0.5440,                 loss: nan
agent1:                 episode reward: 0.5440,                 loss: 0.2704
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6994s / 439.0190 s
agent0:                 episode reward: -0.7072,                 loss: nan
agent1:                 episode reward: 0.7072,                 loss: 0.2696
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6977s / 439.7167 s
agent0:                 episode reward: -0.9101,                 loss: nan
agent1:                 episode reward: 0.9101,                 loss: 0.2710
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6838s / 440.4005 s
agent0:                 episode reward: -0.6955,                 loss: nan
agent1:                 episode reward: 0.6955,                 loss: 0.2714
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6950s / 441.0955 s
agent0:                 episode reward: -0.6960,                 loss: nan
agent1:                 episode reward: 0.6960,                 loss: 0.2722
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7026s / 441.7981 s
agent0:                 episode reward: -0.6040,                 loss: nan
agent1:                 episode reward: 0.6040,                 loss: 0.2711
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7057s / 442.5038 s
agent0:                 episode reward: -0.4561,                 loss: nan
agent1:                 episode reward: 0.4561,                 loss: 0.3138
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6896s / 443.1934 s
agent0:                 episode reward: -0.6576,                 loss: nan
agent1:                 episode reward: 0.6576,                 loss: 0.3404
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7112s / 443.9045 s
agent0:                 episode reward: -0.7047,                 loss: nan
agent1:                 episode reward: 0.7047,                 loss: 0.3371
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6945s / 444.5990 s
agent0:                 episode reward: -0.6323,                 loss: nan
agent1:                 episode reward: 0.6323,                 loss: 0.3406
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6943s / 445.2933 s
agent0:                 episode reward: -0.3994,                 loss: nan
agent1:                 episode reward: 0.3994,                 loss: 0.3354
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6966s / 445.9899 s
agent0:                 episode reward: -0.8339,                 loss: nan
agent1:                 episode reward: 0.8339,                 loss: 0.3347
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6967s / 446.6866 s
agent0:                 episode reward: -0.7582,                 loss: nan
agent1:                 episode reward: 0.7582,                 loss: 0.3369
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6942s / 447.3808 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.3389
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7020s / 448.0828 s
agent0:                 episode reward: -0.8463,                 loss: nan
agent1:                 episode reward: 0.8463,                 loss: 0.3418
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6986s / 448.7815 s
agent0:                 episode reward: -0.6106,                 loss: nan
agent1:                 episode reward: 0.6106,                 loss: 0.3403
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6875s / 449.4689 s
agent0:                 episode reward: -0.9552,                 loss: nan
agent1:                 episode reward: 0.9552,                 loss: 0.3417
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6973s / 450.1663 s
agent0:                 episode reward: -0.9173,                 loss: nan
agent1:                 episode reward: 0.9173,                 loss: 0.3380
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6972s / 450.8634 s
agent0:                 episode reward: -0.6548,                 loss: nan
agent1:                 episode reward: 0.6548,                 loss: 0.3406
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6945s / 451.5580 s
agent0:                 episode reward: -0.8700,                 loss: nan
agent1:                 episode reward: 0.8700,                 loss: 0.3390
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6986s / 452.2566 s
agent0:                 episode reward: -0.4661,                 loss: nan
agent1:                 episode reward: 0.4661,                 loss: 0.3401
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6941s / 452.9506 s
agent0:                 episode reward: -0.7272,                 loss: nan
agent1:                 episode reward: 0.7272,                 loss: 0.3397
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6945s / 453.6452 s
agent0:                 episode reward: -0.4523,                 loss: nan
agent1:                 episode reward: 0.4523,                 loss: 0.3418
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7030s / 454.3481 s
agent0:                 episode reward: -0.8309,                 loss: nan
agent1:                 episode reward: 0.8309,                 loss: 0.3244
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7088s / 455.0570 s
agent0:                 episode reward: -0.3476,                 loss: nan
agent1:                 episode reward: 0.3476,                 loss: 0.3067
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7081s / 455.7651 s
agent0:                 episode reward: -0.9798,                 loss: nan
agent1:                 episode reward: 0.9798,                 loss: 0.3039
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7012s / 456.4663 s
agent0:                 episode reward: -0.2513,                 loss: nan
agent1:                 episode reward: 0.2513,                 loss: 0.3031
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7164s / 457.1827 s
agent0:                 episode reward: -0.7123,                 loss: nan
agent1:                 episode reward: 0.7123,                 loss: 0.3036
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7128s / 457.8955 s
agent0:                 episode reward: -0.7270,                 loss: nan
agent1:                 episode reward: 0.7270,                 loss: 0.3027
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7030s / 458.5985 s
agent0:                 episode reward: -0.6761,                 loss: nan
agent1:                 episode reward: 0.6761,                 loss: 0.3039
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7155s / 459.3139 s
agent0:                 episode reward: -1.0392,                 loss: nan
agent1:                 episode reward: 1.0392,                 loss: 0.3029
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7111s / 460.0251 s
agent0:                 episode reward: -0.4545,                 loss: nan
agent1:                 episode reward: 0.4545,                 loss: 0.2987
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7046s / 460.7297 s
agent0:                 episode reward: -0.8420,                 loss: nan
agent1:                 episode reward: 0.8420,                 loss: 0.3017
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7143s / 461.4440 s
agent0:                 episode reward: -0.4591,                 loss: nan
agent1:                 episode reward: 0.4591,                 loss: 0.2979
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7075s / 462.1516 s
agent0:                 episode reward: -0.7987,                 loss: nan
agent1:                 episode reward: 0.7987,                 loss: 0.3037
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7110s / 462.8626 s
agent0:                 episode reward: -0.4356,                 loss: nan
agent1:                 episode reward: 0.4356,                 loss: 0.3036
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7114s / 463.5739 s
agent0:                 episode reward: -0.7567,                 loss: nan
agent1:                 episode reward: 0.7567,                 loss: 0.3042
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7234s / 464.2974 s
agent0:                 episode reward: -0.5645,                 loss: nan
agent1:                 episode reward: 0.5645,                 loss: 0.3036
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7160s / 465.0133 s
agent0:                 episode reward: -0.3695,                 loss: nan
agent1:                 episode reward: 0.3695,                 loss: 0.3025
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7211s / 465.7344 s
agent0:                 episode reward: -0.1204,                 loss: nan
agent1:                 episode reward: 0.1204,                 loss: 0.3019
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7196s / 466.4540 s
agent0:                 episode reward: -0.5572,                 loss: nan
agent1:                 episode reward: 0.5572,                 loss: 0.3017
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7366s / 467.1906 s
agent0:                 episode reward: -0.4889,                 loss: nan
agent1:                 episode reward: 0.4889,                 loss: 0.2961
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7133s / 467.9039 s
agent0:                 episode reward: -0.3713,                 loss: nan
agent1:                 episode reward: 0.3713,                 loss: 0.2989
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7250s / 468.6289 s
agent0:                 episode reward: -0.4268,                 loss: nan
agent1:                 episode reward: 0.4268,                 loss: 0.2939
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7188s / 469.3477 s
agent0:                 episode reward: -0.5173,                 loss: nan
agent1:                 episode reward: 0.5173,                 loss: 0.2951
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7107s / 470.0583 s
agent0:                 episode reward: -0.6262,                 loss: nan
agent1:                 episode reward: 0.6262,                 loss: 0.2981
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7198s / 470.7782 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.2937
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7169s / 471.4951 s
agent0:                 episode reward: -0.7349,                 loss: nan
agent1:                 episode reward: 0.7349,                 loss: 0.2966
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7111s / 472.2061 s
agent0:                 episode reward: -0.6486,                 loss: nan
agent1:                 episode reward: 0.6486,                 loss: 0.2925
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7232s / 472.9294 s
agent0:                 episode reward: -0.8013,                 loss: nan
agent1:                 episode reward: 0.8013,                 loss: 0.2948
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7254s / 473.6548 s
agent0:                 episode reward: -0.5158,                 loss: nan
agent1:                 episode reward: 0.5158,                 loss: 0.2924
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7187s / 474.3735 s
agent0:                 episode reward: -0.5208,                 loss: nan
agent1:                 episode reward: 0.5208,                 loss: 0.2934
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7190s / 475.0925 s
agent0:                 episode reward: -0.3391,                 loss: nan
agent1:                 episode reward: 0.3391,                 loss: 0.2939
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7201s / 475.8126 s
agent0:                 episode reward: -0.5343,                 loss: nan
agent1:                 episode reward: 0.5343,                 loss: 0.2907
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7218s / 476.5344 s
agent0:                 episode reward: -0.1067,                 loss: nan
agent1:                 episode reward: 0.1067,                 loss: 0.2929
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7153s / 477.2497 s
agent0:                 episode reward: -0.4740,                 loss: nan
agent1:                 episode reward: 0.4740,                 loss: 0.2954
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7164s / 477.9661 s
agent0:                 episode reward: -0.7906,                 loss: nan
agent1:                 episode reward: 0.7906,                 loss: 0.3212
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7021s / 478.6682 s
agent0:                 episode reward: -0.4075,                 loss: nan
agent1:                 episode reward: 0.4075,                 loss: 0.3378
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7229s / 479.3911 s
agent0:                 episode reward: -0.9203,                 loss: nan
agent1:                 episode reward: 0.9203,                 loss: 0.3376
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7084s / 480.0995 s
agent0:                 episode reward: -0.5267,                 loss: nan
agent1:                 episode reward: 0.5267,                 loss: 0.3373
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7083s / 480.8078 s
agent0:                 episode reward: -0.7122,                 loss: nan
agent1:                 episode reward: 0.7122,                 loss: 0.3386
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7116s / 481.5194 s
agent0:                 episode reward: -0.2773,                 loss: nan
agent1:                 episode reward: 0.2773,                 loss: 0.3427
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7118s / 482.2312 s
agent0:                 episode reward: -0.7449,                 loss: nan
agent1:                 episode reward: 0.7449,                 loss: 0.3377
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7059s / 482.9372 s
agent0:                 episode reward: -0.3505,                 loss: nan
agent1:                 episode reward: 0.3505,                 loss: 0.3411
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7113s / 483.6485 s
agent0:                 episode reward: -0.6297,                 loss: nan
agent1:                 episode reward: 0.6297,                 loss: 0.3398
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7206s / 484.3691 s
agent0:                 episode reward: -0.6563,                 loss: nan
agent1:                 episode reward: 0.6563,                 loss: 0.3380
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7154s / 485.0844 s
agent0:                 episode reward: -0.3044,                 loss: nan
agent1:                 episode reward: 0.3044,                 loss: 0.3361
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7197s / 485.8042 s
agent0:                 episode reward: -0.4014,                 loss: nan
agent1:                 episode reward: 0.4014,                 loss: 0.3372
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7149s / 486.5191 s
agent0:                 episode reward: -0.9818,                 loss: nan
agent1:                 episode reward: 0.9818,                 loss: 0.3401
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7204s / 487.2394 s
agent0:                 episode reward: -0.5739,                 loss: nan
agent1:                 episode reward: 0.5739,                 loss: 0.3365
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7188s / 487.9582 s
agent0:                 episode reward: -0.8940,                 loss: nan
agent1:                 episode reward: 0.8940,                 loss: 0.3371
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7069s / 488.6652 s
agent0:                 episode reward: -1.0424,                 loss: nan
agent1:                 episode reward: 1.0424,                 loss: 0.3397
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7138s / 489.3789 s
agent0:                 episode reward: -0.6928,                 loss: nan
agent1:                 episode reward: 0.6928,                 loss: 0.3360
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7103s / 490.0892 s
agent0:                 episode reward: -0.4814,                 loss: nan
agent1:                 episode reward: 0.4814,                 loss: 0.3258
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7230s / 490.8122 s
agent0:                 episode reward: -0.4507,                 loss: nan
agent1:                 episode reward: 0.4507,                 loss: 0.3062
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7124s / 491.5247 s
agent0:                 episode reward: -0.6246,                 loss: nan
agent1:                 episode reward: 0.6246,                 loss: 0.3099
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7165s / 492.2411 s
agent0:                 episode reward: -0.4146,                 loss: nan
agent1:                 episode reward: 0.4146,                 loss: 0.3083
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7166s / 492.9577 s
agent0:                 episode reward: -0.8084,                 loss: nan
agent1:                 episode reward: 0.8084,                 loss: 0.3040
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7145s / 493.6722 s
agent0:                 episode reward: -0.4490,                 loss: nan
agent1:                 episode reward: 0.4490,                 loss: 0.3049
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7156s / 494.3878 s
agent0:                 episode reward: -0.7999,                 loss: nan
agent1:                 episode reward: 0.7999,                 loss: 0.3078
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7214s / 495.1092 s
agent0:                 episode reward: -0.6488,                 loss: nan
agent1:                 episode reward: 0.6488,                 loss: 0.3070
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7155s / 495.8247 s
agent0:                 episode reward: -0.6802,                 loss: nan
agent1:                 episode reward: 0.6802,                 loss: 0.3045
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7170s / 496.5418 s
agent0:                 episode reward: -0.4007,                 loss: nan
agent1:                 episode reward: 0.4007,                 loss: 0.3069
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7172s / 497.2590 s
agent0:                 episode reward: -0.5878,                 loss: nan
agent1:                 episode reward: 0.5878,                 loss: 0.3074
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7163s / 497.9753 s
agent0:                 episode reward: -0.7345,                 loss: nan
agent1:                 episode reward: 0.7345,                 loss: 0.3059
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7196s / 498.6949 s
agent0:                 episode reward: -0.7951,                 loss: nan
agent1:                 episode reward: 0.7951,                 loss: 0.3121
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7226s / 499.4175 s
agent0:                 episode reward: -0.4571,                 loss: nan
agent1:                 episode reward: 0.4571,                 loss: 0.3074
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7158s / 500.1333 s
agent0:                 episode reward: -0.5984,                 loss: nan
agent1:                 episode reward: 0.5984,                 loss: 0.3054
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7230s / 500.8563 s
agent0:                 episode reward: -0.3276,                 loss: nan
agent1:                 episode reward: 0.3276,                 loss: 0.3064
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7361s / 501.5924 s
agent0:                 episode reward: -0.6749,                 loss: nan
agent1:                 episode reward: 0.6749,                 loss: 0.3118
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7299s / 502.3223 s
agent0:                 episode reward: -0.4001,                 loss: nan
agent1:                 episode reward: 0.4001,                 loss: 0.2915
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7223s / 503.0446 s
agent0:                 episode reward: -0.7662,                 loss: nan
agent1:                 episode reward: 0.7662,                 loss: 0.2845
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7214s / 503.7659 s
agent0:                 episode reward: -0.5103,                 loss: nan
agent1:                 episode reward: 0.5103,                 loss: 0.2821
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7148s / 504.4808 s
agent0:                 episode reward: -0.6144,                 loss: nan
agent1:                 episode reward: 0.6144,                 loss: 0.2842
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7181s / 505.1989 s
agent0:                 episode reward: -0.6763,                 loss: nan
agent1:                 episode reward: 0.6763,                 loss: 0.2807
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7182s / 505.9171 s
agent0:                 episode reward: -0.4421,                 loss: nan
agent1:                 episode reward: 0.4421,                 loss: 0.2785
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7225s / 506.6396 s
agent0:                 episode reward: -0.7255,                 loss: nan
agent1:                 episode reward: 0.7255,                 loss: 0.2786
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7204s / 507.3600 s
agent0:                 episode reward: -0.5136,                 loss: nan
agent1:                 episode reward: 0.5136,                 loss: 0.2793
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7205s / 508.0805 s
agent0:                 episode reward: -0.6364,                 loss: nan
agent1:                 episode reward: 0.6364,                 loss: 0.2809
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7263s / 508.8068 s
agent0:                 episode reward: -0.4217,                 loss: nan
agent1:                 episode reward: 0.4217,                 loss: 0.2810
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7247s / 509.5314 s
agent0:                 episode reward: -0.6027,                 loss: nan
agent1:                 episode reward: 0.6027,                 loss: 0.2804
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7349s / 510.2663 s
agent0:                 episode reward: -0.3862,                 loss: nan
agent1:                 episode reward: 0.3862,                 loss: 0.2814
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7171s / 510.9833 s
agent0:                 episode reward: -0.4192,                 loss: nan
agent1:                 episode reward: 0.4192,                 loss: 0.2804
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7221s / 511.7054 s
agent0:                 episode reward: -0.8204,                 loss: nan
agent1:                 episode reward: 0.8204,                 loss: 0.2797
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7206s / 512.4260 s
agent0:                 episode reward: -0.6795,                 loss: nan
agent1:                 episode reward: 0.6795,                 loss: 0.2816
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7259s / 513.1519 s
agent0:                 episode reward: -0.5813,                 loss: nan
agent1:                 episode reward: 0.5813,                 loss: 0.2833
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7222s / 513.8741 s
agent0:                 episode reward: -0.7403,                 loss: nan
agent1:                 episode reward: 0.7403,                 loss: 0.3281
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7318s / 514.6059 s
agent0:                 episode reward: -0.8122,                 loss: nan
agent1:                 episode reward: 0.8122,                 loss: 0.3323
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7351s / 515.3411 s
agent0:                 episode reward: -0.7453,                 loss: nan
agent1:                 episode reward: 0.7453,                 loss: 0.3299
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7370s / 516.0781 s
agent0:                 episode reward: -0.7798,                 loss: nan
agent1:                 episode reward: 0.7798,                 loss: 0.3298
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7535s / 516.8316 s
agent0:                 episode reward: -0.6672,                 loss: nan
agent1:                 episode reward: 0.6672,                 loss: 0.3280
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7432s / 517.5747 s
agent0:                 episode reward: -0.4250,                 loss: nan
agent1:                 episode reward: 0.4250,                 loss: 0.3292
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7483s / 518.3231 s
agent0:                 episode reward: -0.4984,                 loss: nan
agent1:                 episode reward: 0.4984,                 loss: 0.3331
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7398s / 519.0628 s
agent0:                 episode reward: -0.9161,                 loss: nan
agent1:                 episode reward: 0.9161,                 loss: 0.3284
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7386s / 519.8015 s
agent0:                 episode reward: -0.5800,                 loss: nan
agent1:                 episode reward: 0.5800,                 loss: 0.3278
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7323s / 520.5338 s
agent0:                 episode reward: -0.4972,                 loss: nan
agent1:                 episode reward: 0.4972,                 loss: 0.3348
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7209s / 521.2547 s
agent0:                 episode reward: -0.5966,                 loss: nan
agent1:                 episode reward: 0.5966,                 loss: 0.3296
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7228s / 521.9776 s
agent0:                 episode reward: -0.6152,                 loss: nan
agent1:                 episode reward: 0.6152,                 loss: 0.3330
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7301s / 522.7076 s
agent0:                 episode reward: -0.7283,                 loss: nan
agent1:                 episode reward: 0.7283,                 loss: 0.3299
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7383s / 523.4459 s
agent0:                 episode reward: -0.5474,                 loss: nan
agent1:                 episode reward: 0.5474,                 loss: 0.3281
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7270s / 524.1730 s
agent0:                 episode reward: -0.4370,                 loss: nan
agent1:                 episode reward: 0.4370,                 loss: 0.3307
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7396s / 524.9125 s
agent0:                 episode reward: -0.6138,                 loss: nan
agent1:                 episode reward: 0.6138,                 loss: 0.3281
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7289s / 525.6415 s
agent0:                 episode reward: -0.7475,                 loss: nan
agent1:                 episode reward: 0.7475,                 loss: 0.3340
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7294s / 526.3709 s
agent0:                 episode reward: -0.6449,                 loss: nan
agent1:                 episode reward: 0.6449,                 loss: 0.3209
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7412s / 527.1121 s
agent0:                 episode reward: -0.7545,                 loss: nan
agent1:                 episode reward: 0.7545,                 loss: 0.2927
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7365s / 527.8486 s
agent0:                 episode reward: -0.5152,                 loss: nan
agent1:                 episode reward: 0.5152,                 loss: 0.2981
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7461s / 528.5946 s
agent0:                 episode reward: -0.3940,                 loss: nan
agent1:                 episode reward: 0.3940,                 loss: 0.3009
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7266s / 529.3212 s
agent0:                 episode reward: -0.2405,                 loss: nan
agent1:                 episode reward: 0.2405,                 loss: 0.2969
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7315s / 530.0527 s
agent0:                 episode reward: -0.4126,                 loss: nan
agent1:                 episode reward: 0.4126,                 loss: 0.2924
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7237s / 530.7764 s
agent0:                 episode reward: -0.3907,                 loss: nan
agent1:                 episode reward: 0.3907,                 loss: 0.2956
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7330s / 531.5093 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: 0.2964
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7280s / 532.2374 s
agent0:                 episode reward: -0.6582,                 loss: nan
agent1:                 episode reward: 0.6582,                 loss: 0.2982
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7326s / 532.9700 s
agent0:                 episode reward: -0.3862,                 loss: nan
agent1:                 episode reward: 0.3862,                 loss: 0.2978
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7255s / 533.6955 s
agent0:                 episode reward: -0.9094,                 loss: nan
agent1:                 episode reward: 0.9094,                 loss: 0.2943
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7397s / 534.4352 s
agent0:                 episode reward: -0.7798,                 loss: nan
agent1:                 episode reward: 0.7798,                 loss: 0.2945
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7437s / 535.1788 s
agent0:                 episode reward: -0.8889,                 loss: nan
agent1:                 episode reward: 0.8889,                 loss: 0.2987
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7338s / 535.9127 s
agent0:                 episode reward: -0.5326,                 loss: nan
agent1:                 episode reward: 0.5326,                 loss: 0.2954
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7504s / 536.6631 s
agent0:                 episode reward: -0.6847,                 loss: nan
agent1:                 episode reward: 0.6847,                 loss: 0.2982
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7372s / 537.4003 s
agent0:                 episode reward: -0.5117,                 loss: nan
agent1:                 episode reward: 0.5117,                 loss: 0.3009
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7321s / 538.1323 s
agent0:                 episode reward: -0.5897,                 loss: nan
agent1:                 episode reward: 0.5897,                 loss: 0.2968
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7395s / 538.8718 s
agent0:                 episode reward: -0.2274,                 loss: nan
agent1:                 episode reward: 0.2274,                 loss: 0.3017
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7504s / 539.6222 s
agent0:                 episode reward: -0.5716,                 loss: nan
agent1:                 episode reward: 0.5716,                 loss: 0.2965
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7388s / 540.3610 s
agent0:                 episode reward: -0.6374,                 loss: nan
agent1:                 episode reward: 0.6374,                 loss: 0.2946
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7370s / 541.0980 s
agent0:                 episode reward: -1.0077,                 loss: nan
agent1:                 episode reward: 1.0077,                 loss: 0.2934
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7335s / 541.8315 s
agent0:                 episode reward: -0.6805,                 loss: nan
agent1:                 episode reward: 0.6805,                 loss: 0.2944
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7318s / 542.5633 s
agent0:                 episode reward: -0.5756,                 loss: nan
agent1:                 episode reward: 0.5756,                 loss: 0.2944
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7331s / 543.2965 s
agent0:                 episode reward: -0.8518,                 loss: nan
agent1:                 episode reward: 0.8518,                 loss: 0.2936
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7256s / 544.0221 s
agent0:                 episode reward: -0.4756,                 loss: nan
agent1:                 episode reward: 0.4756,                 loss: 0.2931
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7373s / 544.7593 s
agent0:                 episode reward: -0.7138,                 loss: nan
agent1:                 episode reward: 0.7138,                 loss: 0.2979
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7644s / 545.5237 s
agent0:                 episode reward: -0.6680,                 loss: nan
agent1:                 episode reward: 0.6680,                 loss: 0.2932
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7409s / 546.2646 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.2926
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7500s / 547.0146 s
agent0:                 episode reward: -0.9456,                 loss: nan
agent1:                 episode reward: 0.9456,                 loss: 0.2934
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7528s / 547.7674 s
agent0:                 episode reward: -0.4838,                 loss: nan
agent1:                 episode reward: 0.4838,                 loss: 0.2965
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7482s / 548.5156 s
agent0:                 episode reward: -0.8655,                 loss: nan
agent1:                 episode reward: 0.8655,                 loss: 0.2941
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7630s / 549.2786 s
agent0:                 episode reward: -0.5495,                 loss: nan
agent1:                 episode reward: 0.5495,                 loss: 0.2915
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7482s / 550.0268 s
agent0:                 episode reward: -0.0799,                 loss: nan
agent1:                 episode reward: 0.0799,                 loss: 0.2900
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7536s / 550.7804 s
agent0:                 episode reward: -0.6455,                 loss: nan
agent1:                 episode reward: 0.6455,                 loss: 0.3286
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7494s / 551.5298 s
agent0:                 episode reward: -0.5931,                 loss: nan
agent1:                 episode reward: 0.5931,                 loss: 0.3254
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7453s / 552.2751 s
agent0:                 episode reward: -0.5597,                 loss: nan
agent1:                 episode reward: 0.5597,                 loss: 0.3179
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7560s / 553.0311 s
agent0:                 episode reward: -0.7039,                 loss: nan
agent1:                 episode reward: 0.7039,                 loss: 0.3184
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7453s / 553.7764 s
agent0:                 episode reward: -0.4983,                 loss: nan
agent1:                 episode reward: 0.4983,                 loss: 0.3196
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7424s / 554.5188 s
agent0:                 episode reward: -0.2831,                 loss: nan
agent1:                 episode reward: 0.2831,                 loss: 0.3190
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7480s / 555.2668 s
agent0:                 episode reward: -0.6527,                 loss: nan
agent1:                 episode reward: 0.6527,                 loss: 0.3169
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7627s / 556.0295 s
agent0:                 episode reward: -0.7843,                 loss: nan
agent1:                 episode reward: 0.7843,                 loss: 0.3212
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7503s / 556.7798 s
agent0:                 episode reward: -0.4181,                 loss: nan
agent1:                 episode reward: 0.4181,                 loss: 0.3191
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7563s / 557.5361 s
agent0:                 episode reward: -0.7584,                 loss: nan
agent1:                 episode reward: 0.7584,                 loss: 0.3204
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7425s / 558.2786 s
agent0:                 episode reward: -0.6083,                 loss: nan
agent1:                 episode reward: 0.6083,                 loss: 0.3201
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7375s / 559.0161 s
agent0:                 episode reward: -0.7058,                 loss: nan
agent1:                 episode reward: 0.7058,                 loss: 0.3170
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7504s / 559.7665 s
agent0:                 episode reward: -0.7742,                 loss: nan
agent1:                 episode reward: 0.7742,                 loss: 0.3154
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7489s / 560.5153 s
agent0:                 episode reward: -0.4875,                 loss: nan
agent1:                 episode reward: 0.4875,                 loss: 0.3162
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7499s / 561.2653 s
agent0:                 episode reward: -0.4446,                 loss: nan
agent1:                 episode reward: 0.4446,                 loss: 0.3160
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7418s / 562.0071 s
agent0:                 episode reward: -0.6901,                 loss: nan
agent1:                 episode reward: 0.6901,                 loss: 0.3181
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7431s / 562.7502 s
agent0:                 episode reward: -0.3926,                 loss: nan
agent1:                 episode reward: 0.3926,                 loss: 0.3191
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7539s / 563.5041 s
agent0:                 episode reward: -0.3498,                 loss: nan
agent1:                 episode reward: 0.3498,                 loss: 0.3206
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7667s / 564.2707 s
agent0:                 episode reward: -0.6552,                 loss: nan
agent1:                 episode reward: 0.6552,                 loss: 0.2817
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7467s / 565.0175 s
agent0:                 episode reward: -0.4090,                 loss: nan
agent1:                 episode reward: 0.4090,                 loss: 0.2766
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7631s / 565.7806 s
agent0:                 episode reward: -0.7040,                 loss: nan
agent1:                 episode reward: 0.7040,                 loss: 0.2786
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7453s / 566.5258 s
agent0:                 episode reward: -0.6200,                 loss: nan
agent1:                 episode reward: 0.6200,                 loss: 0.2772
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7389s / 567.2648 s
agent0:                 episode reward: -0.6080,                 loss: nan
agent1:                 episode reward: 0.6080,                 loss: 0.2788
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7410s / 568.0057 s
agent0:                 episode reward: -0.6949,                 loss: nan
agent1:                 episode reward: 0.6949,                 loss: 0.2781
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7563s / 568.7620 s
agent0:                 episode reward: -0.8456,                 loss: nan
agent1:                 episode reward: 0.8456,                 loss: 0.2786
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7593s / 569.5213 s
agent0:                 episode reward: -0.8462,                 loss: nan
agent1:                 episode reward: 0.8462,                 loss: 0.2826
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7515s / 570.2728 s
agent0:                 episode reward: -0.6455,                 loss: nan
agent1:                 episode reward: 0.6455,                 loss: 0.2801
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7536s / 571.0263 s
agent0:                 episode reward: -0.6475,                 loss: nan
agent1:                 episode reward: 0.6475,                 loss: 0.2799
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7600s / 571.7863 s
agent0:                 episode reward: -0.5206,                 loss: nan
agent1:                 episode reward: 0.5206,                 loss: 0.2784
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7616s / 572.5479 s
agent0:                 episode reward: -0.6251,                 loss: nan
agent1:                 episode reward: 0.6251,                 loss: 0.2810
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7482s / 573.2961 s
agent0:                 episode reward: -0.5874,                 loss: nan
agent1:                 episode reward: 0.5874,                 loss: 0.2765
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7507s / 574.0467 s
agent0:                 episode reward: -0.7806,                 loss: nan
agent1:                 episode reward: 0.7806,                 loss: 0.2796
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7490s / 574.7957 s
agent0:                 episode reward: -0.4133,                 loss: nan
agent1:                 episode reward: 0.4133,                 loss: 0.2797
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7455s / 575.5412 s
agent0:                 episode reward: -0.7371,                 loss: nan
agent1:                 episode reward: 0.7371,                 loss: 0.2807
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7556s / 576.2967 s
agent0:                 episode reward: -0.9090,                 loss: nan
agent1:                 episode reward: 0.9090,                 loss: 0.3230
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7518s / 577.0486 s
agent0:                 episode reward: -0.8435,                 loss: nan
agent1:                 episode reward: 0.8435,                 loss: 0.3192
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7468s / 577.7954 s
agent0:                 episode reward: -0.5750,                 loss: nan
agent1:                 episode reward: 0.5750,                 loss: 0.3190
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7460s / 578.5414 s
agent0:                 episode reward: -0.4164,                 loss: nan
agent1:                 episode reward: 0.4164,                 loss: 0.3134
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7529s / 579.2943 s
agent0:                 episode reward: -0.8350,                 loss: nan
agent1:                 episode reward: 0.8350,                 loss: 0.3136
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7494s / 580.0437 s
agent0:                 episode reward: -0.7089,                 loss: nan
agent1:                 episode reward: 0.7089,                 loss: 0.3181
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7581s / 580.8018 s
agent0:                 episode reward: -0.7010,                 loss: nan
agent1:                 episode reward: 0.7010,                 loss: 0.3168
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7426s / 581.5444 s
agent0:                 episode reward: -0.4918,                 loss: nan
agent1:                 episode reward: 0.4918,                 loss: 0.3155
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7653s / 582.3097 s
agent0:                 episode reward: -0.5633,                 loss: nan
agent1:                 episode reward: 0.5633,                 loss: 0.3141
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7582s / 583.0679 s
agent0:                 episode reward: -0.5623,                 loss: nan
agent1:                 episode reward: 0.5623,                 loss: 0.3191
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7521s / 583.8200 s
agent0:                 episode reward: -0.3377,                 loss: nan
agent1:                 episode reward: 0.3377,                 loss: 0.3136
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7584s / 584.5784 s
agent0:                 episode reward: -0.7342,                 loss: nan
agent1:                 episode reward: 0.7342,                 loss: 0.3155
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7545s / 585.3329 s
agent0:                 episode reward: -0.6727,                 loss: nan
agent1:                 episode reward: 0.6727,                 loss: 0.3127
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7655s / 586.0984 s
agent0:                 episode reward: -0.5662,                 loss: nan
agent1:                 episode reward: 0.5662,                 loss: 0.3179
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7552s / 586.8536 s
agent0:                 episode reward: -0.6356,                 loss: nan
agent1:                 episode reward: 0.6356,                 loss: 0.3162
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7572s / 587.6109 s
agent0:                 episode reward: -0.4632,                 loss: nan
agent1:                 episode reward: 0.4632,                 loss: 0.3148
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7542s / 588.3651 s
agent0:                 episode reward: -0.5852,                 loss: nan
agent1:                 episode reward: 0.5852,                 loss: 0.3400
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7545s / 589.1196 s
agent0:                 episode reward: -0.4398,                 loss: nan
agent1:                 episode reward: 0.4398,                 loss: 0.3139
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7613s / 589.8808 s
agent0:                 episode reward: -1.0147,                 loss: nan
agent1:                 episode reward: 1.0147,                 loss: 0.3110
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7575s / 590.6383 s
agent0:                 episode reward: -0.7586,                 loss: nan
agent1:                 episode reward: 0.7586,                 loss: 0.3093
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7644s / 591.4028 s
agent0:                 episode reward: -0.1974,                 loss: nan
agent1:                 episode reward: 0.1974,                 loss: 0.3110
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7590s / 592.1618 s
agent0:                 episode reward: -0.6981,                 loss: nan
agent1:                 episode reward: 0.6981,                 loss: 0.3093
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7678s / 592.9296 s
agent0:                 episode reward: -0.5843,                 loss: nan
agent1:                 episode reward: 0.5843,                 loss: 0.3094
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7601s / 593.6897 s
agent0:                 episode reward: -0.4831,                 loss: nan
agent1:                 episode reward: 0.4831,                 loss: 0.3088
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7568s / 594.4465 s
agent0:                 episode reward: -0.7203,                 loss: nan
agent1:                 episode reward: 0.7203,                 loss: 0.3071
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7658s / 595.2123 s
agent0:                 episode reward: -0.5527,                 loss: nan
agent1:                 episode reward: 0.5527,                 loss: 0.3133
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7709s / 595.9832 s
agent0:                 episode reward: -0.5057,                 loss: nan
agent1:                 episode reward: 0.5057,                 loss: 0.3096
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7537s / 596.7370 s
agent0:                 episode reward: -0.5444,                 loss: nan
agent1:                 episode reward: 0.5444,                 loss: 0.3091
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7571s / 597.4941 s
agent0:                 episode reward: -0.5840,                 loss: nan
agent1:                 episode reward: 0.5840,                 loss: 0.3124
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7715s / 598.2656 s
agent0:                 episode reward: -0.8482,                 loss: nan
agent1:                 episode reward: 0.8482,                 loss: 0.3123
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7582s / 599.0238 s
agent0:                 episode reward: -0.7453,                 loss: nan
agent1:                 episode reward: 0.7453,                 loss: 0.3117
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7561s / 599.7799 s
agent0:                 episode reward: -0.8838,                 loss: nan
agent1:                 episode reward: 0.8838,                 loss: 0.3120
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7875s / 600.5673 s
agent0:                 episode reward: -0.8619,                 loss: nan
agent1:                 episode reward: 0.8619,                 loss: 0.3094
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7627s / 601.3300 s
agent0:                 episode reward: -0.7991,                 loss: nan
agent1:                 episode reward: 0.7991,                 loss: 0.3159
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7648s / 602.0948 s
agent0:                 episode reward: -0.5065,                 loss: nan
agent1:                 episode reward: 0.5065,                 loss: 0.2630
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7632s / 602.8580 s
agent0:                 episode reward: -0.6016,                 loss: nan
agent1:                 episode reward: 0.6016,                 loss: 0.2662
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7752s / 603.6331 s
agent0:                 episode reward: -0.2910,                 loss: nan
agent1:                 episode reward: 0.2910,                 loss: 0.2654
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7708s / 604.4040 s
agent0:                 episode reward: -0.5123,                 loss: nan
agent1:                 episode reward: 0.5123,                 loss: 0.2634
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7618s / 605.1658 s
agent0:                 episode reward: -0.3507,                 loss: nan
agent1:                 episode reward: 0.3507,                 loss: 0.2657
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7648s / 605.9306 s
agent0:                 episode reward: -0.5656,                 loss: nan
agent1:                 episode reward: 0.5656,                 loss: 0.2623
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7616s / 606.6922 s
agent0:                 episode reward: -0.5605,                 loss: nan
agent1:                 episode reward: 0.5605,                 loss: 0.2635
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7792s / 607.4714 s
agent0:                 episode reward: -0.5582,                 loss: nan
agent1:                 episode reward: 0.5582,                 loss: 0.2617
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7803s / 608.2517 s
agent0:                 episode reward: -0.5047,                 loss: nan
agent1:                 episode reward: 0.5047,                 loss: 0.2650
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7913s / 609.0430 s
agent0:                 episode reward: -0.7121,                 loss: nan
agent1:                 episode reward: 0.7121,                 loss: 0.2630
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7874s / 609.8304 s
agent0:                 episode reward: -0.5037,                 loss: nan
agent1:                 episode reward: 0.5037,                 loss: 0.2609
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7791s / 610.6095 s
agent0:                 episode reward: -0.4244,                 loss: nan
agent1:                 episode reward: 0.4244,                 loss: 0.2637
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7661s / 611.3756 s
agent0:                 episode reward: -0.4578,                 loss: nan
agent1:                 episode reward: 0.4578,                 loss: 0.2613
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7718s / 612.1474 s
agent0:                 episode reward: -0.3047,                 loss: nan
agent1:                 episode reward: 0.3047,                 loss: 0.2662
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7559s / 612.9033 s
agent0:                 episode reward: -0.4583,                 loss: nan
agent1:                 episode reward: 0.4583,                 loss: 0.2631
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7600s / 613.6633 s
agent0:                 episode reward: -0.6516,                 loss: nan
agent1:                 episode reward: 0.6516,                 loss: 0.2708
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7732s / 614.4365 s
agent0:                 episode reward: -0.5605,                 loss: nan
agent1:                 episode reward: 0.5605,                 loss: 0.3380
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7717s / 615.2082 s
agent0:                 episode reward: -0.9627,                 loss: nan
agent1:                 episode reward: 0.9627,                 loss: 0.3354
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7726s / 615.9808 s
agent0:                 episode reward: -0.6769,                 loss: nan
agent1:                 episode reward: 0.6769,                 loss: 0.3348
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7677s / 616.7485 s
agent0:                 episode reward: -0.4962,                 loss: nan
agent1:                 episode reward: 0.4962,                 loss: 0.3311
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7678s / 617.5164 s
agent0:                 episode reward: -0.6713,                 loss: nan
agent1:                 episode reward: 0.6713,                 loss: 0.3304
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7666s / 618.2830 s
agent0:                 episode reward: -0.6469,                 loss: nan
agent1:                 episode reward: 0.6469,                 loss: 0.3339
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7808s / 619.0638 s
agent0:                 episode reward: -0.7419,                 loss: nan
agent1:                 episode reward: 0.7419,                 loss: 0.3329
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7624s / 619.8261 s
agent0:                 episode reward: -0.7372,                 loss: nan
agent1:                 episode reward: 0.7372,                 loss: 0.3325
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7745s / 620.6006 s
agent0:                 episode reward: -0.4475,                 loss: nan
agent1:                 episode reward: 0.4475,                 loss: 0.3320
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7744s / 621.3750 s
agent0:                 episode reward: -0.5635,                 loss: nan
agent1:                 episode reward: 0.5635,                 loss: 0.3335
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7709s / 622.1459 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.3359
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7756s / 622.9215 s
agent0:                 episode reward: -0.3032,                 loss: nan
agent1:                 episode reward: 0.3032,                 loss: 0.3328
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7633s / 623.6848 s
agent0:                 episode reward: -0.3270,                 loss: nan
agent1:                 episode reward: 0.3270,                 loss: 0.3299
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7582s / 624.4430 s
agent0:                 episode reward: -0.4260,                 loss: nan
agent1:                 episode reward: 0.4260,                 loss: 0.3313
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7772s / 625.2202 s
agent0:                 episode reward: -0.6881,                 loss: nan
agent1:                 episode reward: 0.6881,                 loss: 0.3305
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7859s / 626.0060 s
agent0:                 episode reward: -0.9292,                 loss: nan
agent1:                 episode reward: 0.9292,                 loss: 0.3342
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8188s / 626.8249 s
agent0:                 episode reward: -0.4116,                 loss: nan
agent1:                 episode reward: 0.4116,                 loss: 0.3431
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7723s / 627.5971 s
agent0:                 episode reward: -0.3420,                 loss: nan
agent1:                 episode reward: 0.3420,                 loss: 0.3052
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7720s / 628.3691 s
agent0:                 episode reward: -0.4631,                 loss: nan
agent1:                 episode reward: 0.4631,                 loss: 0.2980
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7824s / 629.1516 s
agent0:                 episode reward: -0.6946,                 loss: nan
agent1:                 episode reward: 0.6946,                 loss: 0.2960
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7832s / 629.9348 s
agent0:                 episode reward: -0.6470,                 loss: nan
agent1:                 episode reward: 0.6470,                 loss: 0.2963
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7828s / 630.7176 s
agent0:                 episode reward: -0.3776,                 loss: nan
agent1:                 episode reward: 0.3776,                 loss: 0.2974
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7949s / 631.5126 s
agent0:                 episode reward: -0.6152,                 loss: nan
agent1:                 episode reward: 0.6152,                 loss: 0.2950
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7737s / 632.2862 s
agent0:                 episode reward: -0.4860,                 loss: nan
agent1:                 episode reward: 0.4860,                 loss: 0.2968
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7853s / 633.0716 s
agent0:                 episode reward: -0.5697,                 loss: nan
agent1:                 episode reward: 0.5697,                 loss: 0.2964
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7897s / 633.8613 s
agent0:                 episode reward: -0.6989,                 loss: nan
agent1:                 episode reward: 0.6989,                 loss: 0.2963
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7824s / 634.6437 s
agent0:                 episode reward: -0.5380,                 loss: nan
agent1:                 episode reward: 0.5380,                 loss: 0.2958
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7898s / 635.4334 s
agent0:                 episode reward: -0.6704,                 loss: nan
agent1:                 episode reward: 0.6704,                 loss: 0.2972
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7904s / 636.2238 s
agent0:                 episode reward: -0.4660,                 loss: nan
agent1:                 episode reward: 0.4660,                 loss: 0.2939
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7876s / 637.0114 s
agent0:                 episode reward: -0.1791,                 loss: nan
agent1:                 episode reward: 0.1791,                 loss: 0.2956
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7821s / 637.7935 s
agent0:                 episode reward: -0.5623,                 loss: nan
agent1:                 episode reward: 0.5623,                 loss: 0.2938
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7903s / 638.5838 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.2953
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8040s / 639.3878 s
agent0:                 episode reward: -0.6174,                 loss: nan
agent1:                 episode reward: 0.6174,                 loss: 0.2961
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7983s / 640.1862 s
agent0:                 episode reward: -0.3448,                 loss: nan
agent1:                 episode reward: 0.3448,                 loss: 0.3072
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7910s / 640.9771 s
agent0:                 episode reward: -0.5907,                 loss: nan
agent1:                 episode reward: 0.5907,                 loss: 0.2459
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7923s / 641.7694 s
agent0:                 episode reward: -0.4003,                 loss: nan
agent1:                 episode reward: 0.4003,                 loss: 0.2414
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7935s / 642.5629 s
agent0:                 episode reward: -0.5339,                 loss: nan
agent1:                 episode reward: 0.5339,                 loss: 0.2401
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7944s / 643.3573 s
agent0:                 episode reward: -0.5144,                 loss: nan
agent1:                 episode reward: 0.5144,                 loss: 0.2313
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7766s / 644.1339 s
agent0:                 episode reward: -0.5406,                 loss: nan
agent1:                 episode reward: 0.5406,                 loss: 0.2383
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7897s / 644.9236 s
agent0:                 episode reward: -0.6838,                 loss: nan
agent1:                 episode reward: 0.6838,                 loss: 0.2364
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7820s / 645.7056 s
agent0:                 episode reward: -0.5858,                 loss: nan
agent1:                 episode reward: 0.5858,                 loss: 0.2320
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7862s / 646.4917 s
agent0:                 episode reward: -0.5682,                 loss: nan
agent1:                 episode reward: 0.5682,                 loss: 0.2364
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7814s / 647.2732 s
agent0:                 episode reward: -0.4709,                 loss: nan
agent1:                 episode reward: 0.4709,                 loss: 0.2367
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7857s / 648.0589 s
agent0:                 episode reward: -0.3678,                 loss: nan
agent1:                 episode reward: 0.3678,                 loss: 0.2338
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7904s / 648.8492 s
agent0:                 episode reward: -0.5123,                 loss: nan
agent1:                 episode reward: 0.5123,                 loss: 0.2371
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7825s / 649.6317 s
agent0:                 episode reward: -0.3744,                 loss: nan
agent1:                 episode reward: 0.3744,                 loss: 0.2381
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7951s / 650.4268 s
agent0:                 episode reward: -0.7028,                 loss: nan
agent1:                 episode reward: 0.7028,                 loss: 0.2353
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8038s / 651.2306 s
agent0:                 episode reward: -0.3691,                 loss: nan
agent1:                 episode reward: 0.3691,                 loss: 0.2361
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8124s / 652.0430 s
agent0:                 episode reward: -0.6117,                 loss: nan
agent1:                 episode reward: 0.6117,                 loss: 0.2331
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7770s / 652.8200 s
agent0:                 episode reward: -0.7532,                 loss: nan
agent1:                 episode reward: 0.7532,                 loss: 0.2451
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7925s / 653.6125 s
agent0:                 episode reward: -0.4283,                 loss: nan
agent1:                 episode reward: 0.4283,                 loss: 0.3594
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7912s / 654.4037 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.3415
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7917s / 655.1954 s
agent0:                 episode reward: -0.2633,                 loss: nan
agent1:                 episode reward: 0.2633,                 loss: 0.3398
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7855s / 655.9808 s
agent0:                 episode reward: -0.5343,                 loss: nan
agent1:                 episode reward: 0.5343,                 loss: 0.3422
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7870s / 656.7678 s
agent0:                 episode reward: -0.3587,                 loss: nan
agent1:                 episode reward: 0.3587,                 loss: 0.3409
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8078s / 657.5756 s
agent0:                 episode reward: -0.4875,                 loss: nan
agent1:                 episode reward: 0.4875,                 loss: 0.3428
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7923s / 658.3679 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.3391
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7907s / 659.1586 s
agent0:                 episode reward: -0.7136,                 loss: nan
agent1:                 episode reward: 0.7136,                 loss: 0.3452
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7907s / 659.9493 s
agent0:                 episode reward: -0.6829,                 loss: nan
agent1:                 episode reward: 0.6829,                 loss: 0.3396
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7935s / 660.7428 s
agent0:                 episode reward: -0.4943,                 loss: nan
agent1:                 episode reward: 0.4943,                 loss: 0.3405
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7847s / 661.5275 s
agent0:                 episode reward: -0.4554,                 loss: nan
agent1:                 episode reward: 0.4554,                 loss: 0.3423
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7878s / 662.3153 s
agent0:                 episode reward: -0.5111,                 loss: nan
agent1:                 episode reward: 0.5111,                 loss: 0.3431
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7927s / 663.1079 s
agent0:                 episode reward: -0.2999,                 loss: nan
agent1:                 episode reward: 0.2999,                 loss: 0.3419
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7881s / 663.8960 s
agent0:                 episode reward: -0.7994,                 loss: nan
agent1:                 episode reward: 0.7994,                 loss: 0.3417
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8058s / 664.7018 s
agent0:                 episode reward: -0.7359,                 loss: nan
agent1:                 episode reward: 0.7359,                 loss: 0.3415
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8187s / 665.5205 s
agent0:                 episode reward: -0.5321,                 loss: nan
agent1:                 episode reward: 0.5321,                 loss: 0.3390
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7829s / 666.3034 s
agent0:                 episode reward: -0.6016,                 loss: nan
agent1:                 episode reward: 0.6016,                 loss: 0.3383
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7851s / 667.0885 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.3030
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7898s / 667.8783 s
agent0:                 episode reward: -0.7371,                 loss: nan
agent1:                 episode reward: 0.7371,                 loss: 0.2979
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7839s / 668.6622 s
agent0:                 episode reward: -0.6489,                 loss: nan
agent1:                 episode reward: 0.6489,                 loss: 0.2998
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7917s / 669.4540 s
agent0:                 episode reward: -0.5152,                 loss: nan
agent1:                 episode reward: 0.5152,                 loss: 0.2930
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8121s / 670.2660 s
agent0:                 episode reward: -0.5924,                 loss: nan
agent1:                 episode reward: 0.5924,                 loss: 0.2946
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8005s / 671.0665 s
agent0:                 episode reward: -0.6357,                 loss: nan
agent1:                 episode reward: 0.6357,                 loss: 0.2933
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7912s / 671.8577 s
agent0:                 episode reward: -0.4763,                 loss: nan
agent1:                 episode reward: 0.4763,                 loss: 0.2930
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7808s / 672.6385 s
agent0:                 episode reward: -0.8119,                 loss: nan
agent1:                 episode reward: 0.8119,                 loss: 0.2929
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8135s / 673.4520 s
agent0:                 episode reward: -0.7634,                 loss: nan
agent1:                 episode reward: 0.7634,                 loss: 0.2959
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7980s / 674.2501 s
agent0:                 episode reward: -0.9380,                 loss: nan
agent1:                 episode reward: 0.9380,                 loss: 0.2983
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7873s / 675.0373 s
agent0:                 episode reward: -0.5882,                 loss: nan
agent1:                 episode reward: 0.5882,                 loss: 0.2947
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7978s / 675.8351 s
agent0:                 episode reward: -0.6636,                 loss: nan
agent1:                 episode reward: 0.6636,                 loss: 0.2967
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7997s / 676.6348 s
agent0:                 episode reward: -0.7864,                 loss: nan
agent1:                 episode reward: 0.7864,                 loss: 0.2953
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7977s / 677.4325 s
agent0:                 episode reward: -0.5225,                 loss: nan
agent1:                 episode reward: 0.5225,                 loss: 0.2940
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7982s / 678.2307 s
agent0:                 episode reward: -0.5010,                 loss: nan
agent1:                 episode reward: 0.5010,                 loss: 0.2960
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8101s / 679.0408 s
agent0:                 episode reward: -0.8046,                 loss: nan
agent1:                 episode reward: 0.8046,                 loss: 0.2960
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8076s / 679.8484 s
agent0:                 episode reward: -0.5129,                 loss: nan
agent1:                 episode reward: 0.5129,                 loss: 0.2952
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8183s / 680.6667 s
agent0:                 episode reward: -0.1305,                 loss: nan
agent1:                 episode reward: 0.1305,                 loss: 0.2202
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8246s / 681.4913 s
agent0:                 episode reward: -0.3168,                 loss: nan
agent1:                 episode reward: 0.3168,                 loss: 0.2163
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8276s / 682.3189 s
agent0:                 episode reward: -0.4422,                 loss: nan
agent1:                 episode reward: 0.4422,                 loss: 0.2200
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8262s / 683.1452 s
agent0:                 episode reward: -1.0944,                 loss: nan
agent1:                 episode reward: 1.0944,                 loss: 0.2194
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8076s / 683.9528 s
agent0:                 episode reward: -0.8318,                 loss: nan
agent1:                 episode reward: 0.8318,                 loss: 0.2203
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8091s / 684.7619 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.2174
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8081s / 685.5700 s
agent0:                 episode reward: -0.8167,                 loss: nan
agent1:                 episode reward: 0.8167,                 loss: 0.2168
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8076s / 686.3776 s
agent0:                 episode reward: -1.0943,                 loss: nan
agent1:                 episode reward: 1.0943,                 loss: 0.2171
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8101s / 687.1876 s
agent0:                 episode reward: -0.5098,                 loss: nan
agent1:                 episode reward: 0.5098,                 loss: 0.2182
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7980s / 687.9857 s
agent0:                 episode reward: -0.8996,                 loss: nan
agent1:                 episode reward: 0.8996,                 loss: 0.2189
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8073s / 688.7929 s
agent0:                 episode reward: -0.5312,                 loss: nan
agent1:                 episode reward: 0.5312,                 loss: 0.2175
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8015s / 689.5945 s
agent0:                 episode reward: -0.6348,                 loss: nan
agent1:                 episode reward: 0.6348,                 loss: 0.2153
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8018s / 690.3963 s
agent0:                 episode reward: -0.5823,                 loss: nan
agent1:                 episode reward: 0.5823,                 loss: 0.2138
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8120s / 691.2082 s
agent0:                 episode reward: -0.5810,                 loss: nan
agent1:                 episode reward: 0.5810,                 loss: 0.2156
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8058s / 692.0140 s
agent0:                 episode reward: -0.7671,                 loss: nan
agent1:                 episode reward: 0.7671,                 loss: 0.2144
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7972s / 692.8112 s
agent0:                 episode reward: -0.5548,                 loss: nan
agent1:                 episode reward: 0.5548,                 loss: 0.2364
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7860s / 693.5971 s
agent0:                 episode reward: -0.4863,                 loss: nan
agent1:                 episode reward: 0.4863,                 loss: 0.3752
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7945s / 694.3916 s
agent0:                 episode reward: -0.7669,                 loss: nan
agent1:                 episode reward: 0.7669,                 loss: 0.3266
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7976s / 695.1892 s
agent0:                 episode reward: -0.3487,                 loss: nan
agent1:                 episode reward: 0.3487,                 loss: 0.3227
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7984s / 695.9877 s
agent0:                 episode reward: -0.4128,                 loss: nan
agent1:                 episode reward: 0.4128,                 loss: 0.3250
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8049s / 696.7925 s
agent0:                 episode reward: -0.4083,                 loss: nan
agent1:                 episode reward: 0.4083,                 loss: 0.3253
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7915s / 697.5841 s
agent0:                 episode reward: -0.4283,                 loss: nan
agent1:                 episode reward: 0.4283,                 loss: 0.3238
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8262s / 698.4103 s
agent0:                 episode reward: -0.7716,                 loss: nan
agent1:                 episode reward: 0.7716,                 loss: 0.3255
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8209s / 699.2312 s
agent0:                 episode reward: -0.8018,                 loss: nan
agent1:                 episode reward: 0.8018,                 loss: 0.3250
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8102s / 700.0414 s
agent0:                 episode reward: -0.6948,                 loss: nan
agent1:                 episode reward: 0.6948,                 loss: 0.3271
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8115s / 700.8529 s
agent0:                 episode reward: -0.1621,                 loss: nan
agent1:                 episode reward: 0.1621,                 loss: 0.3244
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8192s / 701.6721 s
agent0:                 episode reward: -0.6164,                 loss: nan
agent1:                 episode reward: 0.6164,                 loss: 0.3253
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8067s / 702.4788 s
agent0:                 episode reward: -0.6168,                 loss: nan
agent1:                 episode reward: 0.6168,                 loss: 0.3247
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8068s / 703.2856 s
agent0:                 episode reward: -0.4479,                 loss: nan
agent1:                 episode reward: 0.4479,                 loss: 0.3237
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8009s / 704.0865 s
agent0:                 episode reward: -0.5644,                 loss: nan
agent1:                 episode reward: 0.5644,                 loss: 0.3244
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7976s / 704.8841 s
agent0:                 episode reward: -0.7186,                 loss: nan
agent1:                 episode reward: 0.7186,                 loss: 0.3221
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8148s / 705.6989 s
agent0:                 episode reward: -0.5741,                 loss: nan
agent1:                 episode reward: 0.5741,                 loss: 0.3229
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8102s / 706.5091 s
agent0:                 episode reward: -0.5839,                 loss: nan
agent1:                 episode reward: 0.5839,                 loss: 0.3328
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8018s / 707.3109 s
agent0:                 episode reward: -0.5744,                 loss: nan
agent1:                 episode reward: 0.5744,                 loss: 0.2959
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8077s / 708.1186 s
agent0:                 episode reward: -0.5395,                 loss: nan
agent1:                 episode reward: 0.5395,                 loss: 0.2903
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8069s / 708.9255 s
agent0:                 episode reward: -0.5649,                 loss: nan
agent1:                 episode reward: 0.5649,                 loss: 0.2910
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8043s / 709.7298 s
agent0:                 episode reward: -0.5567,                 loss: nan
agent1:                 episode reward: 0.5567,                 loss: 0.2871
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8225s / 710.5523 s
agent0:                 episode reward: -0.3850,                 loss: nan
agent1:                 episode reward: 0.3850,                 loss: 0.2919
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8129s / 711.3652 s
agent0:                 episode reward: -0.7508,                 loss: nan
agent1:                 episode reward: 0.7508,                 loss: 0.2891
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8247s / 712.1899 s
agent0:                 episode reward: -0.6880,                 loss: nan
agent1:                 episode reward: 0.6880,                 loss: 0.2918
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8171s / 713.0070 s
agent0:                 episode reward: -0.6442,                 loss: nan
agent1:                 episode reward: 0.6442,                 loss: 0.2887
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7984s / 713.8054 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.2893
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8141s / 714.6194 s
agent0:                 episode reward: -0.6814,                 loss: nan
agent1:                 episode reward: 0.6814,                 loss: 0.2894
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8064s / 715.4259 s
agent0:                 episode reward: -0.7787,                 loss: nan
agent1:                 episode reward: 0.7787,                 loss: 0.2843
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8088s / 716.2347 s
agent0:                 episode reward: -0.8020,                 loss: nan
agent1:                 episode reward: 0.8020,                 loss: 0.2884
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8036s / 717.0383 s
agent0:                 episode reward: -0.9159,                 loss: nan
agent1:                 episode reward: 0.9159,                 loss: 0.2863
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8078s / 717.8461 s
agent0:                 episode reward: -0.5362,                 loss: nan
agent1:                 episode reward: 0.5362,                 loss: 0.2887
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8170s / 718.6631 s
agent0:                 episode reward: -0.4955,                 loss: nan
agent1:                 episode reward: 0.4955,                 loss: 0.2887
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8122s / 719.4753 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.2871
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8195s / 720.2948 s
agent0:                 episode reward: -0.5386,                 loss: nan
agent1:                 episode reward: 0.5386,                 loss: 0.2875
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8333s / 721.1281 s
agent0:                 episode reward: -0.5078,                 loss: nan
agent1:                 episode reward: 0.5078,                 loss: 0.2284
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8213s / 721.9494 s
agent0:                 episode reward: -0.3814,                 loss: nan
agent1:                 episode reward: 0.3814,                 loss: 0.2287
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8137s / 722.7631 s
agent0:                 episode reward: -0.6566,                 loss: nan
agent1:                 episode reward: 0.6566,                 loss: 0.2245
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8146s / 723.5778 s
agent0:                 episode reward: -0.8007,                 loss: nan
agent1:                 episode reward: 0.8007,                 loss: 0.2252
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8105s / 724.3883 s
agent0:                 episode reward: -0.7859,                 loss: nan
agent1:                 episode reward: 0.7859,                 loss: 0.2253
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8101s / 725.1984 s
agent0:                 episode reward: -0.6890,                 loss: nan
agent1:                 episode reward: 0.6890,                 loss: 0.2227
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8273s / 726.0256 s
agent0:                 episode reward: -0.7116,                 loss: nan
agent1:                 episode reward: 0.7116,                 loss: 0.2244
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8448s / 726.8704 s
agent0:                 episode reward: -0.9917,                 loss: nan
agent1:                 episode reward: 0.9917,                 loss: 0.2270
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8183s / 727.6887 s
agent0:                 episode reward: -0.4664,                 loss: nan
agent1:                 episode reward: 0.4664,                 loss: 0.2278
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8092s / 728.4979 s
agent0:                 episode reward: -0.7828,                 loss: nan
agent1:                 episode reward: 0.7828,                 loss: 0.2246
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8265s / 729.3245 s
agent0:                 episode reward: -0.5416,                 loss: nan
agent1:                 episode reward: 0.5416,                 loss: 0.2243
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8078s / 730.1323 s
agent0:                 episode reward: -0.3812,                 loss: nan
agent1:                 episode reward: 0.3812,                 loss: 0.2236
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8259s / 730.9582 s
agent0:                 episode reward: -0.8420,                 loss: nan
agent1:                 episode reward: 0.8420,                 loss: 0.2237
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8263s / 731.7844 s
agent0:                 episode reward: -0.4342,                 loss: nan
agent1:                 episode reward: 0.4342,                 loss: 0.2219
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8160s / 732.6004 s
agent0:                 episode reward: -0.1681,                 loss: nan
agent1:                 episode reward: 0.1681,                 loss: 0.2245
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8308s / 733.4312 s
agent0:                 episode reward: -0.5722,                 loss: nan
agent1:                 episode reward: 0.5722,                 loss: 0.2439
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8378s / 734.2691 s
agent0:                 episode reward: -0.6712,                 loss: nan
agent1:                 episode reward: 0.6712,                 loss: 0.3645
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8088s / 735.0778 s
agent0:                 episode reward: -0.3541,                 loss: nan
agent1:                 episode reward: 0.3541,                 loss: 0.2976
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8189s / 735.8967 s
agent0:                 episode reward: -0.5111,                 loss: nan
agent1:                 episode reward: 0.5111,                 loss: 0.2970
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8189s / 736.7157 s
agent0:                 episode reward: -0.3526,                 loss: nan
agent1:                 episode reward: 0.3526,                 loss: 0.2966
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8257s / 737.5414 s
agent0:                 episode reward: -0.1819,                 loss: nan
agent1:                 episode reward: 0.1819,                 loss: 0.2980
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8392s / 738.3806 s
agent0:                 episode reward: -0.5006,                 loss: nan
agent1:                 episode reward: 0.5006,                 loss: 0.3008
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8280s / 739.2085 s
agent0:                 episode reward: -0.2410,                 loss: nan
agent1:                 episode reward: 0.2410,                 loss: 0.2967
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8335s / 740.0420 s
agent0:                 episode reward: -0.7365,                 loss: nan
agent1:                 episode reward: 0.7365,                 loss: 0.2976
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8518s / 740.8938 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.2990
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8238s / 741.7176 s
agent0:                 episode reward: -0.8666,                 loss: nan
agent1:                 episode reward: 0.8666,                 loss: 0.2961
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8318s / 742.5495 s
agent0:                 episode reward: -0.6595,                 loss: nan
agent1:                 episode reward: 0.6595,                 loss: 0.3001
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8366s / 743.3861 s
agent0:                 episode reward: -0.6378,                 loss: nan
agent1:                 episode reward: 0.6378,                 loss: 0.2948
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8232s / 744.2093 s
agent0:                 episode reward: -0.5310,                 loss: nan
agent1:                 episode reward: 0.5310,                 loss: 0.2980
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8336s / 745.0429 s
agent0:                 episode reward: -0.7792,                 loss: nan
agent1:                 episode reward: 0.7792,                 loss: 0.2912
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8488s / 745.8917 s
agent0:                 episode reward: -0.8269,                 loss: nan
agent1:                 episode reward: 0.8269,                 loss: 0.2948
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8332s / 746.7249 s
agent0:                 episode reward: -0.5650,                 loss: nan
agent1:                 episode reward: 0.5650,                 loss: 0.2953
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8332s / 747.5581 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.3238
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8227s / 748.3807 s
agent0:                 episode reward: -0.4970,                 loss: nan
agent1:                 episode reward: 0.4970,                 loss: 0.2892
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8326s / 749.2133 s
agent0:                 episode reward: -0.5927,                 loss: nan
agent1:                 episode reward: 0.5927,                 loss: 0.2814
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8368s / 750.0501 s
agent0:                 episode reward: -0.4711,                 loss: nan
agent1:                 episode reward: 0.4711,                 loss: 0.2780
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8349s / 750.8850 s
agent0:                 episode reward: -0.8960,                 loss: nan
agent1:                 episode reward: 0.8960,                 loss: 0.2802
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8314s / 751.7165 s
agent0:                 episode reward: -0.4277,                 loss: nan
agent1:                 episode reward: 0.4277,                 loss: 0.2798
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8248s / 752.5413 s
agent0:                 episode reward: -0.5412,                 loss: nan
agent1:                 episode reward: 0.5412,                 loss: 0.2827
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8419s / 753.3832 s
agent0:                 episode reward: -0.8805,                 loss: nan
agent1:                 episode reward: 0.8805,                 loss: 0.2806
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8366s / 754.2199 s
agent0:                 episode reward: -0.4774,                 loss: nan
agent1:                 episode reward: 0.4774,                 loss: 0.2831
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8274s / 755.0473 s
agent0:                 episode reward: -0.5358,                 loss: nan
agent1:                 episode reward: 0.5358,                 loss: 0.2806
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8285s / 755.8757 s
agent0:                 episode reward: -0.5009,                 loss: nan
agent1:                 episode reward: 0.5009,                 loss: 0.2790
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8487s / 756.7244 s
agent0:                 episode reward: -0.3874,                 loss: nan
agent1:                 episode reward: 0.3874,                 loss: 0.2781
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8408s / 757.5652 s
agent0:                 episode reward: -0.4957,                 loss: nan
agent1:                 episode reward: 0.4957,                 loss: 0.2813
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8308s / 758.3960 s
agent0:                 episode reward: -0.5715,                 loss: nan
agent1:                 episode reward: 0.5715,                 loss: 0.2810
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8485s / 759.2445 s
agent0:                 episode reward: -0.6374,                 loss: nan
agent1:                 episode reward: 0.6374,                 loss: 0.2792
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8338s / 760.0783 s
agent0:                 episode reward: -0.2527,                 loss: nan
agent1:                 episode reward: 0.2527,                 loss: 0.2796
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8364s / 760.9147 s
agent0:                 episode reward: -0.6930,                 loss: nan
agent1:                 episode reward: 0.6930,                 loss: 0.2792
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8392s / 761.7538 s
agent0:                 episode reward: -0.4207,                 loss: nan
agent1:                 episode reward: 0.4207,                 loss: 0.2866
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8453s / 762.5991 s
agent0:                 episode reward: -0.3661,                 loss: nan
agent1:                 episode reward: 0.3661,                 loss: 0.2695
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8394s / 763.4386 s
agent0:                 episode reward: -0.4205,                 loss: nan
agent1:                 episode reward: 0.4205,                 loss: 0.2713
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8347s / 764.2733 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.2677
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8552s / 765.1285 s
agent0:                 episode reward: -0.4236,                 loss: nan
agent1:                 episode reward: 0.4236,                 loss: 0.2699
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8391s / 765.9676 s
agent0:                 episode reward: -0.6418,                 loss: nan
agent1:                 episode reward: 0.6418,                 loss: 0.2743
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8498s / 766.8174 s
agent0:                 episode reward: -0.6677,                 loss: nan
agent1:                 episode reward: 0.6677,                 loss: 0.2707
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8494s / 767.6667 s
agent0:                 episode reward: -0.7947,                 loss: nan
agent1:                 episode reward: 0.7947,                 loss: 0.2700
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8433s / 768.5100 s
agent0:                 episode reward: -0.3679,                 loss: nan
agent1:                 episode reward: 0.3679,                 loss: 0.2704
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8432s / 769.3532 s
agent0:                 episode reward: -0.1465,                 loss: nan
agent1:                 episode reward: 0.1465,                 loss: 0.2702
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8461s / 770.1993 s
agent0:                 episode reward: -0.1698,                 loss: nan
agent1:                 episode reward: 0.1698,                 loss: 0.2725
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8377s / 771.0371 s
agent0:                 episode reward: -0.4488,                 loss: nan
agent1:                 episode reward: 0.4488,                 loss: 0.2714
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8437s / 771.8808 s
agent0:                 episode reward: -0.2966,                 loss: nan
agent1:                 episode reward: 0.2966,                 loss: 0.2727
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8320s / 772.7128 s
agent0:                 episode reward: -0.3280,                 loss: nan
agent1:                 episode reward: 0.3280,                 loss: 0.2694
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8370s / 773.5498 s
agent0:                 episode reward: -0.3096,                 loss: nan
agent1:                 episode reward: 0.3096,                 loss: 0.2710
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8294s / 774.3791 s
agent0:                 episode reward: -0.7341,                 loss: nan
agent1:                 episode reward: 0.7341,                 loss: 0.2704
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8379s / 775.2171 s
agent0:                 episode reward: -0.2855,                 loss: nan
agent1:                 episode reward: 0.2855,                 loss: 0.2875
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8500s / 776.0671 s
agent0:                 episode reward: -0.4821,                 loss: nan
agent1:                 episode reward: 0.4821,                 loss: 0.3337
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8473s / 776.9144 s
agent0:                 episode reward: -0.6661,                 loss: nan
agent1:                 episode reward: 0.6661,                 loss: 0.2841
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8377s / 777.7520 s
agent0:                 episode reward: -0.6882,                 loss: nan
agent1:                 episode reward: 0.6882,                 loss: 0.2822
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8380s / 778.5900 s
agent0:                 episode reward: -0.6814,                 loss: nan
agent1:                 episode reward: 0.6814,                 loss: 0.2808
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8334s / 779.4234 s
agent0:                 episode reward: -0.4715,                 loss: nan
agent1:                 episode reward: 0.4715,                 loss: 0.2839
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8475s / 780.2709 s
agent0:                 episode reward: -0.4505,                 loss: nan
agent1:                 episode reward: 0.4505,                 loss: 0.2854
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8589s / 781.1299 s
agent0:                 episode reward: -0.4642,                 loss: nan
agent1:                 episode reward: 0.4642,                 loss: 0.2834
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8436s / 781.9735 s
agent0:                 episode reward: -0.4559,                 loss: nan
agent1:                 episode reward: 0.4559,                 loss: 0.2832
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8558s / 782.8293 s
agent0:                 episode reward: -0.5392,                 loss: nan
agent1:                 episode reward: 0.5392,                 loss: 0.2832
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8709s / 783.7002 s
agent0:                 episode reward: -0.7537,                 loss: nan
agent1:                 episode reward: 0.7537,                 loss: 0.2824
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8485s / 784.5487 s
agent0:                 episode reward: -0.6487,                 loss: nan
agent1:                 episode reward: 0.6487,                 loss: 0.2807
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8517s / 785.4004 s
agent0:                 episode reward: -0.5020,                 loss: nan
agent1:                 episode reward: 0.5020,                 loss: 0.2862
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8403s / 786.2407 s
agent0:                 episode reward: -0.5419,                 loss: nan
agent1:                 episode reward: 0.5419,                 loss: 0.2829
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8722s / 787.1129 s
agent0:                 episode reward: -0.8089,                 loss: nan
agent1:                 episode reward: 0.8089,                 loss: 0.2833
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8629s / 787.9758 s
agent0:                 episode reward: -0.6635,                 loss: nan
agent1:                 episode reward: 0.6635,                 loss: 0.2827
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8579s / 788.8337 s
agent0:                 episode reward: -0.5772,                 loss: nan
agent1:                 episode reward: 0.5772,                 loss: 0.2813
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8425s / 789.6762 s
agent0:                 episode reward: -0.5230,                 loss: nan
agent1:                 episode reward: 0.5230,                 loss: 0.3237
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8522s / 790.5284 s
agent0:                 episode reward: -0.2688,                 loss: nan
agent1:                 episode reward: 0.2688,                 loss: 0.2714
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8548s / 791.3832 s
agent0:                 episode reward: -0.6981,                 loss: nan
agent1:                 episode reward: 0.6981,                 loss: 0.2597
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8480s / 792.2313 s
agent0:                 episode reward: -0.4666,                 loss: nan
agent1:                 episode reward: 0.4666,                 loss: 0.2531
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8496s / 793.0809 s
agent0:                 episode reward: -0.5591,                 loss: nan
agent1:                 episode reward: 0.5591,                 loss: 0.2529
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8452s / 793.9261 s
agent0:                 episode reward: -0.8861,                 loss: nan
agent1:                 episode reward: 0.8861,                 loss: 0.2549
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8521s / 794.7782 s
agent0:                 episode reward: -0.6403,                 loss: nan
agent1:                 episode reward: 0.6403,                 loss: 0.2547
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8462s / 795.6244 s
agent0:                 episode reward: -0.3262,                 loss: nan
agent1:                 episode reward: 0.3262,                 loss: 0.2538
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8575s / 796.4820 s
agent0:                 episode reward: -0.7584,                 loss: nan
agent1:                 episode reward: 0.7584,                 loss: 0.2512
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8436s / 797.3256 s
agent0:                 episode reward: -0.5775,                 loss: nan
agent1:                 episode reward: 0.5775,                 loss: 0.2518
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8534s / 798.1789 s
agent0:                 episode reward: -0.7363,                 loss: nan
agent1:                 episode reward: 0.7363,                 loss: 0.2541
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8440s / 799.0229 s
agent0:                 episode reward: -0.6060,                 loss: nan
agent1:                 episode reward: 0.6060,                 loss: 0.2523
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8451s / 799.8681 s
agent0:                 episode reward: -0.5777,                 loss: nan
agent1:                 episode reward: 0.5777,                 loss: 0.2534
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8706s / 800.7387 s
agent0:                 episode reward: -0.5522,                 loss: nan
agent1:                 episode reward: 0.5522,                 loss: 0.2505
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8763s / 801.6150 s
agent0:                 episode reward: -0.6175,                 loss: nan
agent1:                 episode reward: 0.6175,                 loss: 0.2559
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8482s / 802.4631 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: 0.2503
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8508s / 803.3139 s
agent0:                 episode reward: -0.5691,                 loss: nan
agent1:                 episode reward: 0.5691,                 loss: 0.2559
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8418s / 804.1557 s
agent0:                 episode reward: -0.1089,                 loss: nan
agent1:                 episode reward: 0.1089,                 loss: 0.3109
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8558s / 805.0116 s
agent0:                 episode reward: -0.4281,                 loss: nan
agent1:                 episode reward: 0.4281,                 loss: 0.3186
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8613s / 805.8728 s
agent0:                 episode reward: -0.4981,                 loss: nan
agent1:                 episode reward: 0.4981,                 loss: 0.3152
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8567s / 806.7295 s
agent0:                 episode reward: -0.5488,                 loss: nan
agent1:                 episode reward: 0.5488,                 loss: 0.3148
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8763s / 807.6058 s
agent0:                 episode reward: -0.4069,                 loss: nan
agent1:                 episode reward: 0.4069,                 loss: 0.3104
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8728s / 808.4787 s
agent0:                 episode reward: -0.8198,                 loss: nan
agent1:                 episode reward: 0.8198,                 loss: 0.3151
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8671s / 809.3457 s
agent0:                 episode reward: -0.8860,                 loss: nan
agent1:                 episode reward: 0.8860,                 loss: 0.3100
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8584s / 810.2041 s
agent0:                 episode reward: -0.9612,                 loss: nan
agent1:                 episode reward: 0.9612,                 loss: 0.3120
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8547s / 811.0588 s
agent0:                 episode reward: -0.3115,                 loss: nan
agent1:                 episode reward: 0.3115,                 loss: 0.3127
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8513s / 811.9101 s
agent0:                 episode reward: -0.7671,                 loss: nan
agent1:                 episode reward: 0.7671,                 loss: 0.3109
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8841s / 812.7943 s
agent0:                 episode reward: -0.8143,                 loss: nan
agent1:                 episode reward: 0.8143,                 loss: 0.3130
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8654s / 813.6597 s
agent0:                 episode reward: -0.4278,                 loss: nan
agent1:                 episode reward: 0.4278,                 loss: 0.3113
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8711s / 814.5307 s
agent0:                 episode reward: -0.7352,                 loss: nan
agent1:                 episode reward: 0.7352,                 loss: 0.3165
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8523s / 815.3830 s
agent0:                 episode reward: -0.7267,                 loss: nan
agent1:                 episode reward: 0.7267,                 loss: 0.3118
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8551s / 816.2381 s
agent0:                 episode reward: -0.6108,                 loss: nan
agent1:                 episode reward: 0.6108,                 loss: 0.3092
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8561s / 817.0942 s
agent0:                 episode reward: -0.7599,                 loss: nan
agent1:                 episode reward: 0.7599,                 loss: 0.3143
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8629s / 817.9571 s
agent0:                 episode reward: -0.0917,                 loss: nan
agent1:                 episode reward: 0.0917,                 loss: 0.3241
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8728s / 818.8299 s
agent0:                 episode reward: -0.4393,                 loss: nan
agent1:                 episode reward: 0.4393,                 loss: 0.3248
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8541s / 819.6840 s
agent0:                 episode reward: -0.8676,                 loss: nan
agent1:                 episode reward: 0.8676,                 loss: 0.2855
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8594s / 820.5434 s
agent0:                 episode reward: -0.4636,                 loss: nan
agent1:                 episode reward: 0.4636,                 loss: 0.2869
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8656s / 821.4090 s
agent0:                 episode reward: -0.7387,                 loss: nan
agent1:                 episode reward: 0.7387,                 loss: 0.2838
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8668s / 822.2758 s
agent0:                 episode reward: -0.6081,                 loss: nan
agent1:                 episode reward: 0.6081,                 loss: 0.2842
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8774s / 823.1532 s
agent0:                 episode reward: -0.6353,                 loss: nan
agent1:                 episode reward: 0.6353,                 loss: 0.2866
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8666s / 824.0198 s
agent0:                 episode reward: -0.6786,                 loss: nan
agent1:                 episode reward: 0.6786,                 loss: 0.2859
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8621s / 824.8819 s
agent0:                 episode reward: -0.3190,                 loss: nan
agent1:                 episode reward: 0.3190,                 loss: 0.2840
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8708s / 825.7526 s
agent0:                 episode reward: -0.8163,                 loss: nan
agent1:                 episode reward: 0.8163,                 loss: 0.2870
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8572s / 826.6098 s
agent0:                 episode reward: -0.3971,                 loss: nan
agent1:                 episode reward: 0.3971,                 loss: 0.2850
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8624s / 827.4722 s
agent0:                 episode reward: -0.7242,                 loss: nan
agent1:                 episode reward: 0.7242,                 loss: 0.2848
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8877s / 828.3598 s
agent0:                 episode reward: -0.6933,                 loss: nan
agent1:                 episode reward: 0.6933,                 loss: 0.2869
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8971s / 829.2570 s
agent0:                 episode reward: -0.3875,                 loss: nan
agent1:                 episode reward: 0.3875,                 loss: 0.2832
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8616s / 830.1186 s
agent0:                 episode reward: -0.8288,                 loss: nan
agent1:                 episode reward: 0.8288,                 loss: 0.2851
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8633s / 830.9819 s
agent0:                 episode reward: -0.6620,                 loss: nan
agent1:                 episode reward: 0.6620,                 loss: 0.2841
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8575s / 831.8394 s
agent0:                 episode reward: -0.7943,                 loss: nan
agent1:                 episode reward: 0.7943,                 loss: 0.2868
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8642s / 832.7035 s
agent0:                 episode reward: -0.5759,                 loss: nan
agent1:                 episode reward: 0.5759,                 loss: 0.3197
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8707s / 833.5743 s
agent0:                 episode reward: -0.8220,                 loss: nan
agent1:                 episode reward: 0.8220,                 loss: 0.2578
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8722s / 834.4465 s
agent0:                 episode reward: -0.3935,                 loss: nan
agent1:                 episode reward: 0.3935,                 loss: 0.2468
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8681s / 835.3146 s
agent0:                 episode reward: -0.6569,                 loss: nan
agent1:                 episode reward: 0.6569,                 loss: 0.2477
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8766s / 836.1911 s
agent0:                 episode reward: -0.8062,                 loss: nan
agent1:                 episode reward: 0.8062,                 loss: 0.2436
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8764s / 837.0676 s
agent0:                 episode reward: -0.9188,                 loss: nan
agent1:                 episode reward: 0.9188,                 loss: 0.2439
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8872s / 837.9548 s
agent0:                 episode reward: -0.6900,                 loss: nan
agent1:                 episode reward: 0.6900,                 loss: 0.2438
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8889s / 838.8437 s
agent0:                 episode reward: -0.6057,                 loss: nan
agent1:                 episode reward: 0.6057,                 loss: 0.2452
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8673s / 839.7109 s
agent0:                 episode reward: -0.6398,                 loss: nan
agent1:                 episode reward: 0.6398,                 loss: 0.2421
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8745s / 840.5854 s
agent0:                 episode reward: -0.4696,                 loss: nan
agent1:                 episode reward: 0.4696,                 loss: 0.2415
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8691s / 841.4545 s
agent0:                 episode reward: -0.4185,                 loss: nan
agent1:                 episode reward: 0.4185,                 loss: 0.2407
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8789s / 842.3334 s
agent0:                 episode reward: -0.5208,                 loss: nan
agent1:                 episode reward: 0.5208,                 loss: 0.2414
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8728s / 843.2062 s
agent0:                 episode reward: -0.0724,                 loss: nan
agent1:                 episode reward: 0.0724,                 loss: 0.2459
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8826s / 844.0888 s
agent0:                 episode reward: -0.4926,                 loss: nan
agent1:                 episode reward: 0.4926,                 loss: 0.2432
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8768s / 844.9656 s
agent0:                 episode reward: -0.5396,                 loss: nan
agent1:                 episode reward: 0.5396,                 loss: 0.2432
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8896s / 845.8552 s
agent0:                 episode reward: -0.6256,                 loss: nan
agent1:                 episode reward: 0.6256,                 loss: 0.2431
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8617s / 846.7169 s
agent0:                 episode reward: -0.4813,                 loss: nan
agent1:                 episode reward: 0.4813,                 loss: 0.2403
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8811s / 847.5979 s
agent0:                 episode reward: -0.6908,                 loss: nan
agent1:                 episode reward: 0.6908,                 loss: 0.3198
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8773s / 848.4752 s
agent0:                 episode reward: -0.7137,                 loss: nan
agent1:                 episode reward: 0.7137,                 loss: 0.3288
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8771s / 849.3523 s
agent0:                 episode reward: -0.3304,                 loss: nan
agent1:                 episode reward: 0.3304,                 loss: 0.3294
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8813s / 850.2336 s
agent0:                 episode reward: -0.8822,                 loss: nan
agent1:                 episode reward: 0.8822,                 loss: 0.3320
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8647s / 851.0983 s
agent0:                 episode reward: -0.7157,                 loss: nan
agent1:                 episode reward: 0.7157,                 loss: 0.3289
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8879s / 851.9861 s
agent0:                 episode reward: -0.5577,                 loss: nan
agent1:                 episode reward: 0.5577,                 loss: 0.3297
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9014s / 852.8876 s
agent0:                 episode reward: -0.6975,                 loss: nan
agent1:                 episode reward: 0.6975,                 loss: 0.3318
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8806s / 853.7682 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.3289
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8807s / 854.6488 s
agent0:                 episode reward: -0.6763,                 loss: nan
agent1:                 episode reward: 0.6763,                 loss: 0.3293
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8714s / 855.5202 s
agent0:                 episode reward: -0.6283,                 loss: nan
agent1:                 episode reward: 0.6283,                 loss: 0.3308
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8829s / 856.4031 s
agent0:                 episode reward: -0.4038,                 loss: nan
agent1:                 episode reward: 0.4038,                 loss: 0.3284
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8778s / 857.2810 s
agent0:                 episode reward: -0.1294,                 loss: nan
agent1:                 episode reward: 0.1294,                 loss: 0.3280
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8824s / 858.1634 s
agent0:                 episode reward: -0.4726,                 loss: nan
agent1:                 episode reward: 0.4726,                 loss: 0.3305
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8779s / 859.0413 s
agent0:                 episode reward: -0.2862,                 loss: nan
agent1:                 episode reward: 0.2862,                 loss: 0.3291
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8749s / 859.9162 s
agent0:                 episode reward: -0.5284,                 loss: nan
agent1:                 episode reward: 0.5284,                 loss: 0.3294
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8797s / 860.7959 s
agent0:                 episode reward: -0.5930,                 loss: nan
agent1:                 episode reward: 0.5930,                 loss: 0.3306
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8879s / 861.6838 s
agent0:                 episode reward: -0.3892,                 loss: nan
agent1:                 episode reward: 0.3892,                 loss: 0.3412
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8889s / 862.5727 s
agent0:                 episode reward: -0.5313,                 loss: nan
agent1:                 episode reward: 0.5313,                 loss: 0.3126
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8860s / 863.4587 s
agent0:                 episode reward: -0.4887,                 loss: nan
agent1:                 episode reward: 0.4887,                 loss: 0.2701
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8782s / 864.3369 s
agent0:                 episode reward: -0.3611,                 loss: nan
agent1:                 episode reward: 0.3611,                 loss: 0.2723
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8834s / 865.2204 s
agent0:                 episode reward: -0.8785,                 loss: nan
agent1:                 episode reward: 0.8785,                 loss: 0.2688
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8960s / 866.1164 s
agent0:                 episode reward: -0.5826,                 loss: nan
agent1:                 episode reward: 0.5826,                 loss: 0.2696
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8854s / 867.0018 s
agent0:                 episode reward: -0.6657,                 loss: nan
agent1:                 episode reward: 0.6657,                 loss: 0.2712
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8806s / 867.8824 s
agent0:                 episode reward: -0.3755,                 loss: nan
agent1:                 episode reward: 0.3755,                 loss: 0.2658
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8926s / 868.7750 s
agent0:                 episode reward: -0.2870,                 loss: nan
agent1:                 episode reward: 0.2870,                 loss: 0.2705
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9130s / 869.6880 s
agent0:                 episode reward: -0.4921,                 loss: nan
agent1:                 episode reward: 0.4921,                 loss: 0.2705
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8907s / 870.5787 s
agent0:                 episode reward: -0.7970,                 loss: nan
agent1:                 episode reward: 0.7970,                 loss: 0.2733
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8924s / 871.4711 s
agent0:                 episode reward: -0.6886,                 loss: nan
agent1:                 episode reward: 0.6886,                 loss: 0.2688
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8935s / 872.3646 s
agent0:                 episode reward: -0.5196,                 loss: nan
agent1:                 episode reward: 0.5196,                 loss: 0.2709
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8936s / 873.2582 s
agent0:                 episode reward: -0.6541,                 loss: nan
agent1:                 episode reward: 0.6541,                 loss: 0.2691
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8915s / 874.1497 s
agent0:                 episode reward: -0.4334,                 loss: nan
agent1:                 episode reward: 0.4334,                 loss: 0.2695
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8857s / 875.0354 s
agent0:                 episode reward: -0.6779,                 loss: nan
agent1:                 episode reward: 0.6779,                 loss: 0.2703
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8929s / 875.9283 s
agent0:                 episode reward: -0.7680,                 loss: nan
agent1:                 episode reward: 0.7680,                 loss: 0.2695
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8810s / 876.8093 s
agent0:                 episode reward: -0.5774,                 loss: nan
agent1:                 episode reward: 0.5774,                 loss: 0.3215
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8898s / 877.6991 s
agent0:                 episode reward: -0.5701,                 loss: nan
agent1:                 episode reward: 0.5701,                 loss: 0.2320
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8958s / 878.5949 s
agent0:                 episode reward: -0.5266,                 loss: nan
agent1:                 episode reward: 0.5266,                 loss: 0.2211
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8910s / 879.4859 s
agent0:                 episode reward: -0.4389,                 loss: nan
agent1:                 episode reward: 0.4389,                 loss: 0.2181
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8967s / 880.3827 s
agent0:                 episode reward: -0.3380,                 loss: nan
agent1:                 episode reward: 0.3380,                 loss: 0.2182
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8975s / 881.2802 s
agent0:                 episode reward: -0.2129,                 loss: nan
agent1:                 episode reward: 0.2129,                 loss: 0.2188
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8823s / 882.1625 s
agent0:                 episode reward: -0.7646,                 loss: nan
agent1:                 episode reward: 0.7646,                 loss: 0.2174
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8961s / 883.0586 s
agent0:                 episode reward: -0.6083,                 loss: nan
agent1:                 episode reward: 0.6083,                 loss: 0.2188
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8850s / 883.9436 s
agent0:                 episode reward: -0.6624,                 loss: nan
agent1:                 episode reward: 0.6624,                 loss: 0.2166
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8893s / 884.8330 s
agent0:                 episode reward: -0.6951,                 loss: nan
agent1:                 episode reward: 0.6951,                 loss: 0.2181
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9005s / 885.7335 s
agent0:                 episode reward: -0.5430,                 loss: nan
agent1:                 episode reward: 0.5430,                 loss: 0.2149
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8948s / 886.6283 s
agent0:                 episode reward: -0.4824,                 loss: nan
agent1:                 episode reward: 0.4824,                 loss: 0.2187
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8844s / 887.5128 s
agent0:                 episode reward: -0.5076,                 loss: nan
agent1:                 episode reward: 0.5076,                 loss: 0.2206
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9101s / 888.4229 s
agent0:                 episode reward: -0.7655,                 loss: nan
agent1:                 episode reward: 0.7655,                 loss: 0.2217
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8943s / 889.3172 s
agent0:                 episode reward: -0.4678,                 loss: nan
agent1:                 episode reward: 0.4678,                 loss: 0.2192
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9007s / 890.2179 s
agent0:                 episode reward: -0.4537,                 loss: nan
agent1:                 episode reward: 0.4537,                 loss: 0.2183
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8998s / 891.1177 s
agent0:                 episode reward: -0.1503,                 loss: nan
agent1:                 episode reward: 0.1503,                 loss: 0.2179
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8914s / 892.0091 s
agent0:                 episode reward: -0.4187,                 loss: nan
agent1:                 episode reward: 0.4187,                 loss: 0.3482
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9027s / 892.9118 s
agent0:                 episode reward: -0.6294,                 loss: nan
agent1:                 episode reward: 0.6294,                 loss: 0.3432
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8881s / 893.7999 s
agent0:                 episode reward: -0.6949,                 loss: nan
agent1:                 episode reward: 0.6949,                 loss: 0.3407
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9169s / 894.7169 s
agent0:                 episode reward: -0.7010,                 loss: nan
agent1:                 episode reward: 0.7010,                 loss: 0.3411
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8999s / 895.6168 s
agent0:                 episode reward: -0.6965,                 loss: nan
agent1:                 episode reward: 0.6965,                 loss: 0.3389
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8869s / 896.5037 s
agent0:                 episode reward: -0.8715,                 loss: nan
agent1:                 episode reward: 0.8715,                 loss: 0.3425
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8930s / 897.3967 s
agent0:                 episode reward: -0.7219,                 loss: nan
agent1:                 episode reward: 0.7219,                 loss: 0.3415
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8911s / 898.2879 s
agent0:                 episode reward: -0.4637,                 loss: nan
agent1:                 episode reward: 0.4637,                 loss: 0.3400
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9010s / 899.1889 s
agent0:                 episode reward: -0.9368,                 loss: nan
agent1:                 episode reward: 0.9368,                 loss: 0.3425
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9056s / 900.0946 s
agent0:                 episode reward: -0.4514,                 loss: nan
agent1:                 episode reward: 0.4514,                 loss: 0.3403
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9087s / 901.0033 s
agent0:                 episode reward: -0.6269,                 loss: nan
agent1:                 episode reward: 0.6269,                 loss: 0.3402
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9044s / 901.9077 s
agent0:                 episode reward: -0.7588,                 loss: nan
agent1:                 episode reward: 0.7588,                 loss: 0.3388
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9121s / 902.8198 s
agent0:                 episode reward: -0.7469,                 loss: nan
agent1:                 episode reward: 0.7469,                 loss: 0.3438
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9058s / 903.7256 s
agent0:                 episode reward: -0.5825,                 loss: nan
agent1:                 episode reward: 0.5825,                 loss: 0.3390
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8982s / 904.6238 s
agent0:                 episode reward: -0.6059,                 loss: nan
agent1:                 episode reward: 0.6059,                 loss: 0.3365
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9038s / 905.5275 s
agent0:                 episode reward: -0.6845,                 loss: nan
agent1:                 episode reward: 0.6845,                 loss: 0.3410
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8940s / 906.4215 s
agent0:                 episode reward: -0.5169,                 loss: nan
agent1:                 episode reward: 0.5169,                 loss: 0.3423
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8950s / 907.3165 s
agent0:                 episode reward: -0.9864,                 loss: nan
agent1:                 episode reward: 0.9864,                 loss: 0.3050
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9042s / 908.2207 s
agent0:                 episode reward: -0.7109,                 loss: nan
agent1:                 episode reward: 0.7109,                 loss: 0.2904
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8907s / 909.1114 s
agent0:                 episode reward: -0.6405,                 loss: nan
agent1:                 episode reward: 0.6405,                 loss: 0.2898
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8889s / 910.0003 s
agent0:                 episode reward: -0.1449,                 loss: nan
agent1:                 episode reward: 0.1449,                 loss: 0.2901
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9124s / 910.9128 s
agent0:                 episode reward: -0.6497,                 loss: nan
agent1:                 episode reward: 0.6497,                 loss: 0.2899
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8871s / 911.7999 s
agent0:                 episode reward: -0.4114,                 loss: nan
agent1:                 episode reward: 0.4114,                 loss: 0.2873
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9045s / 912.7043 s
agent0:                 episode reward: -0.2338,                 loss: nan
agent1:                 episode reward: 0.2338,                 loss: 0.2853
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9050s / 913.6093 s
agent0:                 episode reward: -0.2913,                 loss: nan
agent1:                 episode reward: 0.2913,                 loss: 0.2928
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9135s / 914.5228 s
agent0:                 episode reward: -0.4514,                 loss: nan
agent1:                 episode reward: 0.4514,                 loss: 0.2872
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9154s / 915.4382 s
agent0:                 episode reward: -0.7221,                 loss: nan
agent1:                 episode reward: 0.7221,                 loss: 0.2917
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9156s / 916.3539 s
agent0:                 episode reward: -0.7707,                 loss: nan
agent1:                 episode reward: 0.7707,                 loss: 0.2833
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9158s / 917.2696 s
agent0:                 episode reward: -0.8859,                 loss: nan
agent1:                 episode reward: 0.8859,                 loss: 0.2881
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9155s / 918.1851 s
agent0:                 episode reward: -0.5727,                 loss: nan
agent1:                 episode reward: 0.5727,                 loss: 0.2882
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9053s / 919.0904 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.2856
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9165s / 920.0070 s
agent0:                 episode reward: -0.7409,                 loss: nan
agent1:                 episode reward: 0.7409,                 loss: 0.2885
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9050s / 920.9120 s
agent0:                 episode reward: -0.9163,                 loss: nan
agent1:                 episode reward: 0.9163,                 loss: 0.2904
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9143s / 921.8263 s
agent0:                 episode reward: -0.4621,                 loss: nan
agent1:                 episode reward: 0.4621,                 loss: 0.3103
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9117s / 922.7380 s
agent0:                 episode reward: -0.3921,                 loss: nan
agent1:                 episode reward: 0.3921,                 loss: 0.2250
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9190s / 923.6570 s
agent0:                 episode reward: -0.5946,                 loss: nan
agent1:                 episode reward: 0.5946,                 loss: 0.2181
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9013s / 924.5583 s
agent0:                 episode reward: 0.1607,                 loss: nan
agent1:                 episode reward: -0.1607,                 loss: 0.2170
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9203s / 925.4787 s
agent0:                 episode reward: -0.0006,                 loss: nan
agent1:                 episode reward: 0.0006,                 loss: 0.2167
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9062s / 926.3849 s
agent0:                 episode reward: -0.3635,                 loss: nan
agent1:                 episode reward: 0.3635,                 loss: 0.2141
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9318s / 927.3167 s
agent0:                 episode reward: -0.4910,                 loss: nan
agent1:                 episode reward: 0.4910,                 loss: 0.2129
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9136s / 928.2303 s
agent0:                 episode reward: -0.7887,                 loss: nan
agent1:                 episode reward: 0.7887,                 loss: 0.2115
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9085s / 929.1389 s
agent0:                 episode reward: -0.6876,                 loss: nan
agent1:                 episode reward: 0.6876,                 loss: 0.2121
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9280s / 930.0668 s
agent0:                 episode reward: -0.4736,                 loss: nan
agent1:                 episode reward: 0.4736,                 loss: 0.2144
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9307s / 930.9975 s
agent0:                 episode reward: -0.5830,                 loss: nan
agent1:                 episode reward: 0.5830,                 loss: 0.2120
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9219s / 931.9194 s
agent0:                 episode reward: -0.6930,                 loss: nan
agent1:                 episode reward: 0.6930,                 loss: 0.2118
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9371s / 932.8565 s
agent0:                 episode reward: -0.7343,                 loss: nan
agent1:                 episode reward: 0.7343,                 loss: 0.2133
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9140s / 933.7705 s
agent0:                 episode reward: -0.7346,                 loss: nan
agent1:                 episode reward: 0.7346,                 loss: 0.2107
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9269s / 934.6973 s
agent0:                 episode reward: -0.1571,                 loss: nan
agent1:                 episode reward: 0.1571,                 loss: 0.2144
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9170s / 935.6144 s
agent0:                 episode reward: -0.6877,                 loss: nan
agent1:                 episode reward: 0.6877,                 loss: 0.2136
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9114s / 936.5258 s
agent0:                 episode reward: -0.7479,                 loss: nan
agent1:                 episode reward: 0.7479,                 loss: 0.2123
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9372s / 937.4630 s
agent0:                 episode reward: -0.6561,                 loss: nan
agent1:                 episode reward: 0.6561,                 loss: 0.3671
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9135s / 938.3765 s
agent0:                 episode reward: -1.0273,                 loss: nan
agent1:                 episode reward: 1.0273,                 loss: 0.3232
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9193s / 939.2959 s
agent0:                 episode reward: -0.7276,                 loss: nan
agent1:                 episode reward: 0.7276,                 loss: 0.3187
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9197s / 940.2156 s
agent0:                 episode reward: -0.7027,                 loss: nan
agent1:                 episode reward: 0.7027,                 loss: 0.3166
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9197s / 941.1352 s
agent0:                 episode reward: -0.6253,                 loss: nan
agent1:                 episode reward: 0.6253,                 loss: 0.3160
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9198s / 942.0551 s
agent0:                 episode reward: -0.7445,                 loss: nan
agent1:                 episode reward: 0.7445,                 loss: 0.3232
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9249s / 942.9800 s
agent0:                 episode reward: -0.3158,                 loss: nan
agent1:                 episode reward: 0.3158,                 loss: 0.3161
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9236s / 943.9036 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.3145
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9256s / 944.8292 s
agent0:                 episode reward: -0.7170,                 loss: nan
agent1:                 episode reward: 0.7170,                 loss: 0.3128
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9147s / 945.7439 s
agent0:                 episode reward: -0.6870,                 loss: nan
agent1:                 episode reward: 0.6870,                 loss: 0.3194
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9195s / 946.6634 s
agent0:                 episode reward: -0.7467,                 loss: nan
agent1:                 episode reward: 0.7467,                 loss: 0.3162
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9226s / 947.5860 s
agent0:                 episode reward: -0.4899,                 loss: nan
agent1:                 episode reward: 0.4899,                 loss: 0.3195
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9392s / 948.5252 s
agent0:                 episode reward: -0.3945,                 loss: nan
agent1:                 episode reward: 0.3945,                 loss: 0.3171
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9281s / 949.4533 s
agent0:                 episode reward: -0.6459,                 loss: nan
agent1:                 episode reward: 0.6459,                 loss: 0.3174
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9315s / 950.3848 s
agent0:                 episode reward: -0.5965,                 loss: nan
agent1:                 episode reward: 0.5965,                 loss: 0.3172
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9321s / 951.3169 s
agent0:                 episode reward: -0.7304,                 loss: nan
agent1:                 episode reward: 0.7304,                 loss: 0.3155
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9321s / 952.2490 s
agent0:                 episode reward: -0.7992,                 loss: nan
agent1:                 episode reward: 0.7992,                 loss: 0.3229
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9285s / 953.1775 s
agent0:                 episode reward: -0.4205,                 loss: nan
agent1:                 episode reward: 0.4205,                 loss: 0.3078
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9217s / 954.0993 s
agent0:                 episode reward: -0.9215,                 loss: nan
agent1:                 episode reward: 0.9215,                 loss: 0.2866
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9240s / 955.0233 s
agent0:                 episode reward: -0.5301,                 loss: nan
agent1:                 episode reward: 0.5301,                 loss: 0.2845
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9277s / 955.9509 s
agent0:                 episode reward: -0.9879,                 loss: nan
agent1:                 episode reward: 0.9879,                 loss: 0.2892
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9239s / 956.8748 s
agent0:                 episode reward: -0.5616,                 loss: nan
agent1:                 episode reward: 0.5616,                 loss: 0.2900
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9390s / 957.8138 s
agent0:                 episode reward: -0.7879,                 loss: nan
agent1:                 episode reward: 0.7879,                 loss: 0.2866
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9414s / 958.7552 s
agent0:                 episode reward: -0.4276,                 loss: nan
agent1:                 episode reward: 0.4276,                 loss: 0.2884
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9458s / 959.7010 s
agent0:                 episode reward: -0.5365,                 loss: nan
agent1:                 episode reward: 0.5365,                 loss: 0.2896
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9464s / 960.6474 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.2893
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9260s / 961.5734 s
agent0:                 episode reward: -0.4303,                 loss: nan
agent1:                 episode reward: 0.4303,                 loss: 0.2844
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9451s / 962.5186 s
agent0:                 episode reward: -0.6410,                 loss: nan
agent1:                 episode reward: 0.6410,                 loss: 0.2857
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9455s / 963.4641 s
agent0:                 episode reward: -0.7163,                 loss: nan
agent1:                 episode reward: 0.7163,                 loss: 0.2883
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9234s / 964.3875 s
agent0:                 episode reward: -0.6520,                 loss: nan
agent1:                 episode reward: 0.6520,                 loss: 0.2857
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9263s / 965.3138 s
agent0:                 episode reward: -0.4223,                 loss: nan
agent1:                 episode reward: 0.4223,                 loss: 0.2843
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9342s / 966.2480 s
agent0:                 episode reward: -0.5634,                 loss: nan
agent1:                 episode reward: 0.5634,                 loss: 0.2853
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9351s / 967.1831 s
agent0:                 episode reward: -0.8526,                 loss: nan
agent1:                 episode reward: 0.8526,                 loss: 0.2856
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9249s / 968.1080 s
agent0:                 episode reward: -0.4654,                 loss: nan
agent1:                 episode reward: 0.4654,                 loss: 0.2958
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9501s / 969.0581 s
agent0:                 episode reward: -0.5991,                 loss: nan
agent1:                 episode reward: 0.5991,                 loss: 0.2491
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9310s / 969.9891 s
agent0:                 episode reward: -0.4635,                 loss: nan
agent1:                 episode reward: 0.4635,                 loss: 0.2390
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9354s / 970.9244 s
agent0:                 episode reward: -0.9719,                 loss: nan
agent1:                 episode reward: 0.9719,                 loss: 0.2405
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9409s / 971.8654 s
agent0:                 episode reward: -0.7232,                 loss: nan
agent1:                 episode reward: 0.7232,                 loss: 0.2443
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9470s / 972.8124 s
agent0:                 episode reward: -0.5867,                 loss: nan
agent1:                 episode reward: 0.5867,                 loss: 0.2393
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9312s / 973.7436 s
agent0:                 episode reward: -0.8745,                 loss: nan
agent1:                 episode reward: 0.8745,                 loss: 0.2419
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9359s / 974.6794 s
agent0:                 episode reward: -0.6087,                 loss: nan
agent1:                 episode reward: 0.6087,                 loss: 0.2387
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9416s / 975.6211 s
agent0:                 episode reward: -0.5598,                 loss: nan
agent1:                 episode reward: 0.5598,                 loss: 0.2405
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9287s / 976.5498 s
agent0:                 episode reward: -0.3526,                 loss: nan
agent1:                 episode reward: 0.3526,                 loss: 0.2415
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9305s / 977.4803 s
agent0:                 episode reward: -0.9167,                 loss: nan
agent1:                 episode reward: 0.9167,                 loss: 0.2376
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9341s / 978.4144 s
agent0:                 episode reward: -0.6790,                 loss: nan
agent1:                 episode reward: 0.6790,                 loss: 0.2443
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9343s / 979.3486 s
agent0:                 episode reward: -0.3428,                 loss: nan
agent1:                 episode reward: 0.3428,                 loss: 0.2402
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9428s / 980.2914 s
agent0:                 episode reward: -0.6801,                 loss: nan
agent1:                 episode reward: 0.6801,                 loss: 0.2374
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9398s / 981.2312 s
agent0:                 episode reward: -0.3804,                 loss: nan
agent1:                 episode reward: 0.3804,                 loss: 0.2391/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9819s / 982.2131 s
agent0:                 episode reward: -0.9434,                 loss: nan
agent1:                 episode reward: 0.9434,                 loss: 0.2419
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9660s / 983.1791 s
agent0:                 episode reward: -0.5074,                 loss: nan
agent1:                 episode reward: 0.5074,                 loss: 0.2378
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9434s / 984.1224 s
agent0:                 episode reward: -0.3357,                 loss: nan
agent1:                 episode reward: 0.3357,                 loss: 0.3637
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9502s / 985.0727 s
agent0:                 episode reward: -0.6359,                 loss: nan
agent1:                 episode reward: 0.6359,                 loss: 0.3122
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9345s / 986.0071 s
agent0:                 episode reward: -0.6708,                 loss: nan
agent1:                 episode reward: 0.6708,                 loss: 0.3085
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9651s / 986.9723 s
agent0:                 episode reward: -0.2719,                 loss: nan
agent1:                 episode reward: 0.2719,                 loss: 0.3062
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9689s / 987.9411 s
agent0:                 episode reward: -0.7554,                 loss: nan
agent1:                 episode reward: 0.7554,                 loss: 0.3062
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9660s / 988.9071 s
agent0:                 episode reward: -0.6558,                 loss: nan
agent1:                 episode reward: 0.6558,                 loss: 0.3044
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9461s / 989.8533 s
agent0:                 episode reward: -0.4874,                 loss: nan
agent1:                 episode reward: 0.4874,                 loss: 0.3028
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9537s / 990.8069 s
agent0:                 episode reward: -0.4521,                 loss: nan
agent1:                 episode reward: 0.4521,                 loss: 0.3062
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9487s / 991.7556 s
agent0:                 episode reward: -0.4813,                 loss: nan
agent1:                 episode reward: 0.4813,                 loss: 0.3042
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9639s / 992.7194 s
agent0:                 episode reward: -0.5324,                 loss: nan
agent1:                 episode reward: 0.5324,                 loss: 0.3008
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9378s / 993.6572 s
agent0:                 episode reward: -0.4196,                 loss: nan
agent1:                 episode reward: 0.4196,                 loss: 0.3028
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9586s / 994.6158 s
agent0:                 episode reward: -0.8197,                 loss: nan
agent1:                 episode reward: 0.8197,                 loss: 0.3044
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9620s / 995.5779 s
agent0:                 episode reward: -0.6585,                 loss: nan
agent1:                 episode reward: 0.6585,                 loss: 0.3079
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9308s / 996.5087 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.3057
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9170s / 997.4257 s
agent0:                 episode reward: -0.7483,                 loss: nan
agent1:                 episode reward: 0.7483,                 loss: 0.3043
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9260s / 998.3516 s
agent0:                 episode reward: -0.5855,                 loss: nan
agent1:                 episode reward: 0.5855,                 loss: 0.3062
