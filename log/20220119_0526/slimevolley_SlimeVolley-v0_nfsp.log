pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=1024, bias=True)
      (1): Tanh()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Tanh()
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Linear(in_features=1024, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=1024, bias=True)
      (1): Tanh()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Tanh()
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Linear(in_features=1024, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 1000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [1024, 1024, 1024], 'hidden_activation': 'Tanh', 'output_activation': False}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526/slimevolley_SlimeVolley-v0_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526/slimevolley_SlimeVolley-v0_nfsp.
Episode: 1/10000 (0.0100%),                 avg. length: 484.0,                last time consumption/overall running time: 4.3789s / 4.3789 s
env0_first_0:                 episode reward: -3.0000,                 loss: nan
env0_second_0:                 episode reward: 3.0000,                 loss: nan
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 557.75,                last time consumption/overall running time: 324.7183s / 329.0972 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0072
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0082
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 583.95,                last time consumption/overall running time: 375.6934s / 704.7906 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0128
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 598.85,                last time consumption/overall running time: 391.2844s / 1096.0750 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0125
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 590.35,                last time consumption/overall running time: 391.0340s / 1487.1090 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0133
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 636.55,                last time consumption/overall running time: 425.4118s / 1912.5208 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0136
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0154
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 570.25,                last time consumption/overall running time: 384.9946s / 2297.5154 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0157
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0170
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 575.75,                last time consumption/overall running time: 389.1545s / 2686.6699 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0180
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0191
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 564.6,                last time consumption/overall running time: 382.6343s / 3069.3042 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0186
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0209
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 566.2,                last time consumption/overall running time: 385.1460s / 3454.4502 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0173
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0205
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 609.75,                last time consumption/overall running time: 414.8807s / 3869.3309 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0178
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0204
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 613.05,                last time consumption/overall running time: 416.3819s / 4285.7128 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0184
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0211
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 562.25,                last time consumption/overall running time: 383.4437s / 4669.1565 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0193
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0217
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 616.35,                last time consumption/overall running time: 418.7601s / 5087.9166 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0217
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0217
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 614.5,                last time consumption/overall running time: 419.2093s / 5507.1260 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0227
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0240
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 629.85,                last time consumption/overall running time: 428.7778s / 5935.9038 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0218
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0236
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 629.15,                last time consumption/overall running time: 428.0293s / 6363.9330 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0208
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0217
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 628.85,                last time consumption/overall running time: 427.1348s / 6791.0679 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0192
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0197
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 581.75,                last time consumption/overall running time: 396.4891s / 7187.5570 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0193
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0201
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 621.95,                last time consumption/overall running time: 423.4066s / 7610.9635 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0194
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0198
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 601.85,                last time consumption/overall running time: 408.8894s / 8019.8529 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0197
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0192
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 603.15,                last time consumption/overall running time: 411.0976s / 8430.9505 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0194
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0210
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 623.6,                last time consumption/overall running time: 424.8116s / 8855.7621 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0197
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0201
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 583.15,                last time consumption/overall running time: 397.0250s / 9252.7871 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0210
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0198
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 594.2,                last time consumption/overall running time: 405.2114s / 9657.9986 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0198
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0192
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 634.9,                last time consumption/overall running time: 432.5972s / 10090.5957 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0187
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0202
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 586.75,                last time consumption/overall running time: 399.5879s / 10490.1836 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0194
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0206
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 576.9,                last time consumption/overall running time: 393.0342s / 10883.2178 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0207
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0202
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 622.75,                last time consumption/overall running time: 424.3927s / 11307.6105 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0205
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0196
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 634.15,                last time consumption/overall running time: 432.3213s / 11739.9317 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0191
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0187
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 543.6,                last time consumption/overall running time: 369.7824s / 12109.7141 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0198
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0186
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 650.9,                last time consumption/overall running time: 442.2179s / 12551.9320 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0211
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0183
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 600.35,                last time consumption/overall running time: 407.2715s / 12959.2035 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0219
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0198
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 652.9,                last time consumption/overall running time: 442.7270s / 13401.9305 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0201
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0213
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 636.85,                last time consumption/overall running time: 433.8914s / 13835.8219 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0196
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0232
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 595.2,                last time consumption/overall running time: 405.6366s / 14241.4585 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0192
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0226
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 628.25,                last time consumption/overall running time: 427.2338s / 14668.6923 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0194
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0212
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 576.95,                last time consumption/overall running time: 392.7952s / 15061.4875 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0201
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0196
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 617.85,                last time consumption/overall running time: 420.7948s / 15482.2824 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0206
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0201
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 594.9,                last time consumption/overall running time: 405.2496s / 15887.5320 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0203
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0207
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 615.35,                last time consumption/overall running time: 419.1553s / 16306.6873 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0192
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0196
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 663.4,                last time consumption/overall running time: 451.8949s / 16758.5822 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0192
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0205
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 634.9,                last time consumption/overall running time: 431.3986s / 17189.9808 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0186
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0212
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 610.7,                last time consumption/overall running time: 414.0106s / 17603.9914 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0196
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0210
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 748.25,                last time consumption/overall running time: 507.2917s / 18111.2831 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0198
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0192
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 793.25,                last time consumption/overall running time: 537.6697s / 18648.9529 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0181
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0185
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 848.45,                last time consumption/overall running time: 575.7746s / 19224.7275 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0169
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0184
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 801.55,                last time consumption/overall running time: 544.8626s / 19769.5901 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0172
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0175
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 818.3,                last time consumption/overall running time: 554.4852s / 20324.0753 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0176
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0159
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 878.2,                last time consumption/overall running time: 595.6452s / 20919.7205 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0149
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0146
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 932.4,                last time consumption/overall running time: 635.1328s / 21554.8533 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0134
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0132
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1023.25,                last time consumption/overall running time: 696.4626s / 22251.3159 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0124
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1000.9,                last time consumption/overall running time: 680.4131s / 22931.7290 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0094
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0106
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 977.7,                last time consumption/overall running time: 663.7279s / 23595.4568 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0094
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0103
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1195.65,                last time consumption/overall running time: 813.0851s / 24408.5419 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0090
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0095
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1515.55,                last time consumption/overall running time: 1029.4219s / 25437.9638 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0078
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0081
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1315.1,                last time consumption/overall running time: 892.3016s / 26330.2654 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0061
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0074
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1257.85,                last time consumption/overall running time: 856.7320s / 27186.9974 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0093
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1046.8,                last time consumption/overall running time: 711.7333s / 27898.7307 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0063
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0079
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1115.3,                last time consumption/overall running time: 758.0515s / 28656.7823 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0067
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0075
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1180.55,                last time consumption/overall running time: 798.7806s / 29455.5629 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0076
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0083
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1413.95,                last time consumption/overall running time: 960.5741s / 30416.1370 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0071
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0080
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1449.1,                last time consumption/overall running time: 983.5583s / 31399.6954 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0066
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0065
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1272.6,                last time consumption/overall running time: 866.0855s / 32265.7809 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0064
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0064
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1363.75,                last time consumption/overall running time: 926.0511s / 33191.8320 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0069
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0068
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1288.95,                last time consumption/overall running time: 875.5625s / 34067.3945 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0072
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0070
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1275.1,                last time consumption/overall running time: 867.4237s / 34934.8182 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0071
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0066
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1118.35,                last time consumption/overall running time: 759.3796s / 35694.1979 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0075
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0068
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1250.65,                last time consumption/overall running time: 848.4746s / 36542.6724 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0080
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0071
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1416.5,                last time consumption/overall running time: 1012.3072s / 37554.9796 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.0076
env0_second_0:                 episode reward: -3.1000,                 loss: 0.0068
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1152.75,                last time consumption/overall running time: 930.9108s / 38485.8904 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0063
env0_second_0:                 episode reward: -2.5500,                 loss: 0.0062
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1145.4,                last time consumption/overall running time: 928.6851s / 39414.5756 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0066
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0066
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1471.1,                last time consumption/overall running time: 1192.3459s / 40606.9214 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0065
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0086
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1599.45,                last time consumption/overall running time: 1297.4852s / 41904.4066 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0058
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0070
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1112.4,                last time consumption/overall running time: 902.2245s / 42806.6311 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0061
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0069
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1380.4,                last time consumption/overall running time: 1119.8931s / 43926.5242 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0065
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0076
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1620.4,                last time consumption/overall running time: 1313.7360s / 45240.2602 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0062
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0065
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1352.25,                last time consumption/overall running time: 1099.8117s / 46340.0719 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0060
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0063
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1295.9,                last time consumption/overall running time: 1052.6142s / 47392.6861 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0065
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0066
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1227.5,                last time consumption/overall running time: 998.4509s / 48391.1370 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0071
env0_second_0:                 episode reward: -1.7500,                 loss: 0.0071
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1307.35,                last time consumption/overall running time: 1063.3564s / 49454.4934 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0077
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0075
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1332.5,                last time consumption/overall running time: 1083.5025s / 50537.9959 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0074
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0075
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1548.6,                last time consumption/overall running time: 1260.1635s / 51798.1594 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0067
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0065
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1276.6,                last time consumption/overall running time: 1038.5359s / 52836.6952 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0068
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0072
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1336.9,                last time consumption/overall running time: 1087.0001s / 53923.6953 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0076
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0075
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1496.85,                last time consumption/overall running time: 1216.0055s / 55139.7008 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0078
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0071
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1503.9,                last time consumption/overall running time: 1223.3972s / 56363.0981 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0071
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0062
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1448.7,                last time consumption/overall running time: 1178.5745s / 57541.6725 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0069
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0064
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1407.7,                last time consumption/overall running time: 1145.5559s / 58687.2285 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0067
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0068
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1383.35,                last time consumption/overall running time: 1124.9883s / 59812.2168 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0069
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0074
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1572.45,                last time consumption/overall running time: 1280.4019s / 61092.6187 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0069
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0073
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1856.3,                last time consumption/overall running time: 1509.3881s / 62602.0067 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0061
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0064
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1214.95,                last time consumption/overall running time: 988.5960s / 63590.6028 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0061
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0058
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1555.95,                last time consumption/overall running time: 1265.4402s / 64856.0430 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0063
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0061
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1359.4,                last time consumption/overall running time: 1105.8253s / 65961.8683 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0062
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0066
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1407.3,                last time consumption/overall running time: 1147.4183s / 67109.2866 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0065
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0076
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1501.0,                last time consumption/overall running time: 1221.7060s / 68330.9926 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0070
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0074
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1300.45,                last time consumption/overall running time: 1058.7196s / 69389.7121 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0062
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0065
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 1362.55,                last time consumption/overall running time: 1108.7796s / 70498.4917 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0068
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0073
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1759.8,                last time consumption/overall running time: 1431.1667s / 71929.6584 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0060
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0071
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1492.85,                last time consumption/overall running time: 1213.2906s / 73142.9490 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0057
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0067
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1855.0,                last time consumption/overall running time: 1509.4521s / 74652.4011 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0062
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0068
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1329.6,                last time consumption/overall running time: 1081.8118s / 75734.2130 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0061
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0059
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1422.7,                last time consumption/overall running time: 1157.3762s / 76891.5892 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0070
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0063
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1519.6,                last time consumption/overall running time: 1236.3831s / 78127.9723 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0066
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0059
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1310.7,                last time consumption/overall running time: 1065.7331s / 79193.7054 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0067
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0060
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1435.1,                last time consumption/overall running time: 1165.7392s / 80359.4445 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0070
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0068
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 1591.5,                last time consumption/overall running time: 1292.0292s / 81651.4737 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0070
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0066
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1449.5,                last time consumption/overall running time: 1178.3878s / 82829.8615 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0064
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0068
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1534.3,                last time consumption/overall running time: 1248.3222s / 84078.1838 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0061
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0065
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1378.0,                last time consumption/overall running time: 1120.5137s / 85198.6975 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0059
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0068
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 1200.55,                last time consumption/overall running time: 974.8460s / 86173.5435 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0068
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0075
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 1389.15,                last time consumption/overall running time: 1130.5064s / 87304.0499 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0073
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0078
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 1476.1,                last time consumption/overall running time: 1200.4948s / 88504.5447 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0069
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0076
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 1568.5,                last time consumption/overall running time: 1279.0162s / 89783.5609 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0061
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0068
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 1446.95,                last time consumption/overall running time: 1176.1549s / 90959.7157 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0066
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1400.6,                last time consumption/overall running time: 1139.4633s / 92099.1791 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0062
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0070
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1241.2,                last time consumption/overall running time: 1010.1267s / 93109.3058 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0064
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0071
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1525.7,                last time consumption/overall running time: 1244.5762s / 94353.8820 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0066
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0076
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1822.1,                last time consumption/overall running time: 1484.7121s / 95838.5941 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0060
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0066
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 1526.0,                last time consumption/overall running time: 1242.5838s / 97081.1779 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0064
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1598.35,                last time consumption/overall running time: 1303.6825s / 98384.8605 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0069
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0068
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1298.95,                last time consumption/overall running time: 1058.7334s / 99443.5939 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0063
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0072
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1443.65,                last time consumption/overall running time: 1175.1797s / 100618.7735 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0065
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0068
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1303.85,                last time consumption/overall running time: 1058.5199s / 101677.2934 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0065
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0069
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1494.45,                last time consumption/overall running time: 1215.8196s / 102893.1130 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0076
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0074
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 1535.6,                last time consumption/overall running time: 1250.5613s / 104143.6743 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0070
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0069
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1292.45,                last time consumption/overall running time: 1050.9431s / 105194.6174 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0070
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0068
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1528.85,                last time consumption/overall running time: 1246.3041s / 106440.9215 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0078
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0073
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1343.55,                last time consumption/overall running time: 1093.1345s / 107534.0560 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0077
env0_second_0:                 episode reward: -2.1500,                 loss: 0.0065
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1562.1,                last time consumption/overall running time: 1273.7965s / 108807.8525 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0074
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0067
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1572.0,                last time consumption/overall running time: 1279.7922s / 110087.6446 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0068
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0069
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1436.2,                last time consumption/overall running time: 1170.2354s / 111257.8801 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0065
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0063
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 1505.65,                last time consumption/overall running time: 1226.0784s / 112483.9584 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0065
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0073
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1422.55,                last time consumption/overall running time: 1160.0413s / 113643.9997 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0061
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0082
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 1663.55,                last time consumption/overall running time: 1353.6480s / 114997.6477 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0065
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0079
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1572.8,                last time consumption/overall running time: 1279.1974s / 116276.8451 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0065
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0071
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1894.05,                last time consumption/overall running time: 1540.3879s / 117817.2330 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0065
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0064
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 1464.35,                last time consumption/overall running time: 1191.2692s / 119008.5022 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0064
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0060
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1758.25,                last time consumption/overall running time: 1432.8786s / 120441.3808 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0060
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0063
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1470.45,                last time consumption/overall running time: 1196.5046s / 121637.8853 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0058
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0060
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1401.65,                last time consumption/overall running time: 1141.5826s / 122779.4679 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0069
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0065
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1668.75,                last time consumption/overall running time: 1359.1919s / 124138.6599 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0066
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0069
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1544.85,                last time consumption/overall running time: 1258.3703s / 125397.0302 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0061
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0059
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1877.95,                last time consumption/overall running time: 1529.5858s / 126926.6160 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0055
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0058
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1510.95,                last time consumption/overall running time: 1229.8097s / 128156.4257 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0063
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 2069.0,                last time consumption/overall running time: 1684.3384s / 129840.7640 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0059
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0061
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1524.9,                last time consumption/overall running time: 1243.8690s / 131084.6330 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0058
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0059
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 1484.0,                last time consumption/overall running time: 1209.7480s / 132294.3810 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0063
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0066
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1255.95,                last time consumption/overall running time: 1023.4932s / 133317.8741 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0062
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0067
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1910.9,                last time consumption/overall running time: 1557.2162s / 134875.0903 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0071
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1463.5,                last time consumption/overall running time: 1194.0636s / 136069.1539 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0052
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0071
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1641.75,                last time consumption/overall running time: 1336.2506s / 137405.4044 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0064
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0071
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1398.35,                last time consumption/overall running time: 1137.3648s / 138542.7692 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0064
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0066
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1432.05,                last time consumption/overall running time: 1165.2223s / 139707.9915 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0066
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0071
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1550.7,                last time consumption/overall running time: 1263.9616s / 140971.9531 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0074
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0073
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1454.7,                last time consumption/overall running time: 1186.5466s / 142158.4997 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0072
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0075
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1304.3,                last time consumption/overall running time: 1063.9912s / 143222.4909 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0071
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0073
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1384.2,                last time consumption/overall running time: 1101.5865s / 144324.0775 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0071
env0_second_0:                 episode reward: -2.1500,                 loss: 0.0070
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1591.8,                last time consumption/overall running time: 1210.6033s / 145534.6807 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0066
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0070
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1432.0,                last time consumption/overall running time: 1045.8242s / 146580.5049 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0064
env0_second_0:                 episode reward: -1.7500,                 loss: 0.0064
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1382.65,                last time consumption/overall running time: 974.4261s / 147554.9310 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0067
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0071
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1242.25,                last time consumption/overall running time: 848.5782s / 148403.5092 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0072
env0_second_0:                 episode reward: -1.8000,                 loss: 0.0075
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1419.6,                last time consumption/overall running time: 968.7173s / 149372.2265 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0070
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0076
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1599.2,                last time consumption/overall running time: 1092.2676s / 150464.4941 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0070
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0072
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1410.8,                last time consumption/overall running time: 965.4735s / 151429.9676 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0066
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0065
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1639.5,                last time consumption/overall running time: 1119.6911s / 152549.6586 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0066
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0068
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1353.2,                last time consumption/overall running time: 925.4932s / 153475.1519 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0069
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0073
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1862.65,                last time consumption/overall running time: 1272.1541s / 154747.3059 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0069
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0077
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1397.1,                last time consumption/overall running time: 953.6682s / 155700.9741 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0063
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0067
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1648.7,                last time consumption/overall running time: 1124.8419s / 156825.8160 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0069
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0070
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1405.4,                last time consumption/overall running time: 960.1661s / 157785.9821 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0068
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0063
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1652.3,                last time consumption/overall running time: 1128.2369s / 158914.2190 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0073
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0065
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1385.4,                last time consumption/overall running time: 946.3955s / 159860.6145 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0075
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0066
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1807.85,                last time consumption/overall running time: 1234.2069s / 161094.8214 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0066
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0066
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1536.65,                last time consumption/overall running time: 1050.0828s / 162144.9042 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0069
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0066
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1694.45,                last time consumption/overall running time: 1155.2468s / 163300.1510 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0065
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0061
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 1611.45,                last time consumption/overall running time: 1097.1748s / 164397.3258 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0059
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0062
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1368.65,                last time consumption/overall running time: 932.7921s / 165330.1179 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0066
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0070
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1419.9,                last time consumption/overall running time: 968.4545s / 166298.5724 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0070
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0073
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1200.9,                last time consumption/overall running time: 819.8090s / 167118.3814 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0072
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0079
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1412.2,                last time consumption/overall running time: 963.0001s / 168081.3815 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0077
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0087
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1505.2,                last time consumption/overall running time: 1026.2182s / 169107.5997 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0075
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0084
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1613.15,                last time consumption/overall running time: 1100.0829s / 170207.6826 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0071
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0080
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1356.25,                last time consumption/overall running time: 924.1153s / 171131.7979 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0072
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0079
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1395.75,                last time consumption/overall running time: 952.4260s / 172084.2239 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0071
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0080
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1121.9,                last time consumption/overall running time: 764.3079s / 172848.5318 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0071
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0078
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1427.15,                last time consumption/overall running time: 972.9127s / 173821.4444 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0075
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0073
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1351.05,                last time consumption/overall running time: 922.0708s / 174743.5153 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0072
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0070
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 1304.05,                last time consumption/overall running time: 887.3365s / 175630.8518 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0077
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0072
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 1346.6,                last time consumption/overall running time: 916.4083s / 176547.2601 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0077
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0078
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1578.95,                last time consumption/overall running time: 1075.6548s / 177622.9149 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0074
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0077
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1466.0,                last time consumption/overall running time: 995.7524s / 178618.6673 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0072
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0073
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 1423.3,                last time consumption/overall running time: 968.7520s / 179587.4193 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0078
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0068
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1164.8,                last time consumption/overall running time: 793.7439s / 180381.1631 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0077
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0071
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1188.65,                last time consumption/overall running time: 811.2921s / 181192.4553 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0081
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0082
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1185.0,                last time consumption/overall running time: 807.4578s / 181999.9131 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0089
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0088
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1666.15,                last time consumption/overall running time: 1133.2678s / 183133.1809 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0085
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0085
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1435.4,                last time consumption/overall running time: 978.5203s / 184111.7011 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0074
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0064
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1111.15,                last time consumption/overall running time: 756.0092s / 184867.7103 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0080
env0_second_0:                 episode reward: -2.5500,                 loss: 0.0069
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1429.65,                last time consumption/overall running time: 972.6995s / 185840.4098 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0087
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0080
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1591.0,                last time consumption/overall running time: 1085.5660s / 186925.9758 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0069
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0068
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 1307.05,                last time consumption/overall running time: 891.9462s / 187817.9220 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0073
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0070
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1712.25,                last time consumption/overall running time: 1165.9094s / 188983.8314 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0075
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0073
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1341.5,                last time consumption/overall running time: 913.0704s / 189896.9018 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0066
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0077
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 1704.8,                last time consumption/overall running time: 1160.4186s / 191057.3204 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0073
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0073
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 1449.95,                last time consumption/overall running time: 985.7576s / 192043.0779 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0067
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0069
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 1761.1,                last time consumption/overall running time: 1197.1001s / 193240.1780 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0071
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0068
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1373.3,                last time consumption/overall running time: 933.8136s / 194173.9916 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0063
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0064
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 1221.65,                last time consumption/overall running time: 831.1303s / 195005.1219 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0071
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0073
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1385.2,                last time consumption/overall running time: 942.8399s / 195947.9618 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0082
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0079
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 1391.45,                last time consumption/overall running time: 947.4082s / 196895.3700 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0085
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0074
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 1910.95,                last time consumption/overall running time: 1300.4450s / 198195.8151 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0073
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0065
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 1544.25,                last time consumption/overall running time: 1049.2317s / 199245.0467 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0067
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0058
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 1670.65,                last time consumption/overall running time: 1136.3317s / 200381.3784 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0066
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0065
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 1758.95,                last time consumption/overall running time: 1197.7174s / 201579.0958 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0059
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0060
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 1891.6,                last time consumption/overall running time: 1287.1735s / 202866.2693 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0060
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0058
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 1466.7,                last time consumption/overall running time: 997.3757s / 203863.6450 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0063
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0057
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 1801.5,                last time consumption/overall running time: 1227.9501s / 205091.5951 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0071
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0064
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 1437.75,                last time consumption/overall running time: 979.9919s / 206071.5870 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0066
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0068
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 1471.8,                last time consumption/overall running time: 1002.7818s / 207074.3688 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0067
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0072
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1499.0,                last time consumption/overall running time: 1022.1808s / 208096.5496 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0074
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0073
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1670.9,                last time consumption/overall running time: 1139.8107s / 209236.3603 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0070
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0067
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1765.6,                last time consumption/overall running time: 1201.6498s / 210438.0101 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0063
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0065
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 1508.15,                last time consumption/overall running time: 1025.3869s / 211463.3971 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0063
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0063
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1577.25,                last time consumption/overall running time: 1074.1159s / 212537.5130 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0060
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0064
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1542.35,                last time consumption/overall running time: 1051.1557s / 213588.6687 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0068
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0069
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1514.65,                last time consumption/overall running time: 1033.8245s / 214622.4932 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0063
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0069
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1999.1,                last time consumption/overall running time: 1362.3514s / 215984.8446 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0060
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0065
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1641.6,                last time consumption/overall running time: 1117.6256s / 217102.4702 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0060
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0063
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1625.3,                last time consumption/overall running time: 1104.8800s / 218207.3501 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0067
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0066
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1678.8,                last time consumption/overall running time: 1140.4717s / 219347.8218 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0066
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0063
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1735.35,                last time consumption/overall running time: 1180.8525s / 220528.6743 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0062
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0060
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1845.5,                last time consumption/overall running time: 1254.6117s / 221783.2860 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0060
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0060
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 2075.6,                last time consumption/overall running time: 1412.0312s / 223195.3171 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0060
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0056
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1751.2,                last time consumption/overall running time: 1189.7393s / 224385.0564 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0053
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0051
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1690.25,                last time consumption/overall running time: 1147.9828s / 225533.0392 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0056
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1832.55,                last time consumption/overall running time: 1243.6050s / 226776.6442 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0057
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0058
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1211.85,                last time consumption/overall running time: 821.8888s / 227598.5330 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0059
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1339.4,                last time consumption/overall running time: 908.5130s / 228507.0460 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0067
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0066
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1571.55,                last time consumption/overall running time: 1065.9081s / 229572.9541 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0072
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0074
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1524.75,                last time consumption/overall running time: 1033.9954s / 230606.9495 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0064
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0067
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1568.5,                last time consumption/overall running time: 1064.7328s / 231671.6823 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0067
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0071
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1837.05,                last time consumption/overall running time: 1249.8162s / 232921.4984 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0067
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0067
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1477.5,                last time consumption/overall running time: 1003.1603s / 233924.6587 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0059
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0058
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1694.4,                last time consumption/overall running time: 1150.4672s / 235075.1259 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0065
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0066
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1488.4,                last time consumption/overall running time: 1009.9492s / 236085.0751 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0060
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0065
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 1549.05,                last time consumption/overall running time: 1050.4506s / 237135.5257 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0063
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0062
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1578.6,                last time consumption/overall running time: 1070.1125s / 238205.6382 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0063
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0063
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1726.9,                last time consumption/overall running time: 1169.5843s / 239375.2225 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0059
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0068
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1518.35,                last time consumption/overall running time: 1030.6528s / 240405.8752 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0060
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0066
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 1847.65,                last time consumption/overall running time: 1255.9704s / 241661.8457 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0059
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0063
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1584.75,                last time consumption/overall running time: 1077.2848s / 242739.1305 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0059
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0063
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1452.55,                last time consumption/overall running time: 986.7191s / 243725.8496 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0065
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0068
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 1872.05,                last time consumption/overall running time: 1274.8996s / 245000.7491 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0064
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0075
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1901.95,                last time consumption/overall running time: 1291.6865s / 246292.4356 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0057
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0058
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1607.1,                last time consumption/overall running time: 1092.0148s / 247384.4504 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0069
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1327.45,                last time consumption/overall running time: 900.4036s / 248284.8540 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0066
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0081
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 1831.45,                last time consumption/overall running time: 1243.9014s / 249528.7553 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0068
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0073
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1530.35,                last time consumption/overall running time: 1041.2838s / 250570.0391 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0060
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0066
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1732.1,                last time consumption/overall running time: 1176.8433s / 251746.8824 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0067
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0066
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1519.95,                last time consumption/overall running time: 1032.2705s / 252779.1529 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0061
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0064
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1596.55,                last time consumption/overall running time: 1087.4481s / 253866.6011 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0065
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0060
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1538.95,                last time consumption/overall running time: 1044.1751s / 254910.7762 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0066
env0_second_0:                 episode reward: -1.7500,                 loss: 0.0067
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1910.8,                last time consumption/overall running time: 1297.6630s / 256208.4392 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0065
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0069
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1763.55,                last time consumption/overall running time: 1196.8623s / 257405.3015 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0065
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0067
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1550.05,                last time consumption/overall running time: 1053.1840s / 258458.4855 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0063
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0063
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1977.8,                last time consumption/overall running time: 1342.6150s / 259801.1005 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0062
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0065
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1804.9,                last time consumption/overall running time: 1225.0156s / 261026.1161 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0055
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0061
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1968.95,                last time consumption/overall running time: 1335.3641s / 262361.4801 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0061
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0061
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 1719.95,                last time consumption/overall running time: 1165.7020s / 263527.1822 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0061
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 1669.4,                last time consumption/overall running time: 1132.8841s / 264660.0663 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0057
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0064
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 1696.9,                last time consumption/overall running time: 1152.0035s / 265812.0698 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0064
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0067
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 1561.8,                last time consumption/overall running time: 1059.6420s / 266871.7117 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0061
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0071
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 2110.95,                last time consumption/overall running time: 1429.6411s / 268301.3529 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0063
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 1824.4,                last time consumption/overall running time: 1236.3277s / 269537.6805 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0051
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0057
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1759.45,                last time consumption/overall running time: 1195.0495s / 270732.7301 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0063
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0062
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1416.0,                last time consumption/overall running time: 961.2531s / 271693.9831 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0060
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0061
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 1386.1,                last time consumption/overall running time: 940.3183s / 272634.3015 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0062
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0066
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1513.85,                last time consumption/overall running time: 1025.6202s / 273659.9217 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0065
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0065
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 1588.95,                last time consumption/overall running time: 1076.5167s / 274736.4384 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0069
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0066
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1727.55,                last time consumption/overall running time: 1172.3799s / 275908.8183 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0066
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0062
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1607.75,                last time consumption/overall running time: 1090.2618s / 276999.0800 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0060
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0066
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 1612.25,                last time consumption/overall running time: 1093.9916s / 278093.0716 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0062
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0064
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 1477.95,                last time consumption/overall running time: 1002.8772s / 279095.9489 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0069
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0065
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 1885.35,                last time consumption/overall running time: 1279.2337s / 280375.1826 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0064
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0066
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 1450.65,                last time consumption/overall running time: 984.4482s / 281359.6308 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0064
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0060
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 1792.75,                last time consumption/overall running time: 1216.8097s / 282576.4404 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0063
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0063
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 1706.0,                last time consumption/overall running time: 1157.3822s / 283733.8226 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0058
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0059
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 1720.6,                last time consumption/overall running time: 1165.7755s / 284899.5981 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0056
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0056
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 1782.1,                last time consumption/overall running time: 1208.7378s / 286108.3359 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0057
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0058
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 1436.25,                last time consumption/overall running time: 974.1654s / 287082.5013 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0058
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0064
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 1531.75,                last time consumption/overall running time: 1038.6630s / 288121.1643 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0064
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0069
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 2193.25,                last time consumption/overall running time: 1488.5177s / 289609.6820 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0064
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 1447.2,                last time consumption/overall running time: 980.8585s / 290590.5405 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0054
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0054
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 1658.55,                last time consumption/overall running time: 1122.3279s / 291712.8684 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0063
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0061
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 2116.9,                last time consumption/overall running time: 1432.4703s / 293145.3387 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0058
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0058
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 1263.0,                last time consumption/overall running time: 855.0319s / 294000.3706 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0056
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0057
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 1450.3,                last time consumption/overall running time: 983.4975s / 294983.8680 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0070
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0069
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 1589.25,                last time consumption/overall running time: 1076.1833s / 296060.0513 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0061
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0065
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 1545.95,                last time consumption/overall running time: 1045.4845s / 297105.5358 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0060
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0067
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 1571.3,                last time consumption/overall running time: 1062.3280s / 298167.8638 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0066
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0066
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 1437.55,                last time consumption/overall running time: 972.2941s / 299140.1580 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0064
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0064
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1766.6,                last time consumption/overall running time: 1194.0896s / 300334.2476 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0065
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0065
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 1777.85,                last time consumption/overall running time: 1201.2514s / 301535.4989 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0061
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0058
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 2231.55,                last time consumption/overall running time: 1507.6927s / 303043.1916 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0057
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 2038.6,                last time consumption/overall running time: 1379.1370s / 304422.3286 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0050
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0050
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 1844.1,                last time consumption/overall running time: 1244.8185s / 305667.1471 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0055
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0052
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 2040.5,                last time consumption/overall running time: 1378.0216s / 307045.1687 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0054
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0057
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 1576.05,                last time consumption/overall running time: 1063.9389s / 308109.1076 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0061
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0058
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 1797.55,                last time consumption/overall running time: 1212.7153s / 309321.8229 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0060
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0063
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 1777.6,                last time consumption/overall running time: 1200.1107s / 310521.9337 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0054
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0059
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 1459.8,                last time consumption/overall running time: 985.4253s / 311507.3590 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0060
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0062
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 1924.75,                last time consumption/overall running time: 1299.1367s / 312806.4957 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0057
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0061
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 1654.75,                last time consumption/overall running time: 1118.4796s / 313924.9752 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0055
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0056
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 1914.6,                last time consumption/overall running time: 1294.1981s / 315219.1734 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0064
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0061
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 1984.55,                last time consumption/overall running time: 1336.2377s / 316555.4110 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0052
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0054
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 1668.6,                last time consumption/overall running time: 1124.6129s / 317680.0240 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0051
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0056
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 1797.4,                last time consumption/overall running time: 1210.2942s / 318890.3182 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0056
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0056
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 1860.55,                last time consumption/overall running time: 1256.0765s / 320146.3947 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0060
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0056
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 1834.55,                last time consumption/overall running time: 1237.4812s / 321383.8758 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0059
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0057
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 1526.45,                last time consumption/overall running time: 1031.6407s / 322415.5165 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0060
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0062
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 1865.2,                last time consumption/overall running time: 1255.0154s / 323670.5319 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0058
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0059
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 1637.65,                last time consumption/overall running time: 1102.5150s / 324773.0468 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0058
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0062
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 1505.5,                last time consumption/overall running time: 1015.3339s / 325788.3807 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0062
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0062
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 1515.6,                last time consumption/overall running time: 1022.4785s / 326810.8592 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0064
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0062
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 1655.6,                last time consumption/overall running time: 1112.4994s / 327923.3586 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0065
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0066
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 1915.15,                last time consumption/overall running time: 1289.0985s / 329212.4571 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0054
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0058
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 1942.7,                last time consumption/overall running time: 1307.0841s / 330519.5412 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0054
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0048
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 1739.65,                last time consumption/overall running time: 1170.0348s / 331689.5760 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0058
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0053
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 2013.2,                last time consumption/overall running time: 1356.9663s / 333046.5423 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0054
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0052
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 1463.3,                last time consumption/overall running time: 984.7136s / 334031.2559 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0053
env0_second_0:                 episode reward: -1.9500,                 loss: 0.0053
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 1664.45,                last time consumption/overall running time: 1119.3755s / 335150.6313 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0063
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0065
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 1892.1,                last time consumption/overall running time: 1272.1307s / 336422.7620 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0058
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0057
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 1591.65,                last time consumption/overall running time: 1072.6534s / 337495.4154 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0058
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0056
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 1504.5,                last time consumption/overall running time: 1012.3788s / 338507.7943 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0063
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0064
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 1834.45,                last time consumption/overall running time: 1232.9490s / 339740.7432 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0059
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0060
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 2143.3,                last time consumption/overall running time: 1443.8938s / 341184.6371 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0053
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0052
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 2021.2,                last time consumption/overall running time: 1358.5894s / 342543.2264 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0051
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0051
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 1956.4,                last time consumption/overall running time: 1318.4054s / 343861.6319 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0052
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0055
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 1833.25,                last time consumption/overall running time: 1234.8642s / 345096.4961 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0059
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0058
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 1966.35,                last time consumption/overall running time: 1320.8544s / 346417.3505 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0054
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0055
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 1605.75,                last time consumption/overall running time: 1084.2221s / 347501.5726 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0058
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 1750.7,                last time consumption/overall running time: 1179.8066s / 348681.3793 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0062
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 1898.15,                last time consumption/overall running time: 1278.7332s / 349960.1124 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0060
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0058
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1433.4,                last time consumption/overall running time: 963.8286s / 350923.9410 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0060
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0061
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 1546.95,                last time consumption/overall running time: 1039.3167s / 351963.2577 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0066
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0065
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 1627.7,                last time consumption/overall running time: 1093.4361s / 353056.6937 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0069
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0067
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 1929.5,                last time consumption/overall running time: 1294.2544s / 354350.9481 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0065
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0063
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 1978.1,                last time consumption/overall running time: 1328.9873s / 355679.9354 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0054
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0054
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 2126.0,                last time consumption/overall running time: 1430.7707s / 357110.7061 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0054
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0052
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 1747.5,                last time consumption/overall running time: 1175.5413s / 358286.2474 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0054
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0055
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 1844.4,                last time consumption/overall running time: 1241.9540s / 359528.2014 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0061
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0065
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 1606.95,                last time consumption/overall running time: 1080.5356s / 360608.7371 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0058
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0059
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 1289.8,                last time consumption/overall running time: 868.5269s / 361477.2640 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0064
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0066
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 1807.4,                last time consumption/overall running time: 1214.5838s / 362691.8478 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0067
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0067
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 1926.95,                last time consumption/overall running time: 1299.3275s / 363991.1753 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0060
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 1594.6,                last time consumption/overall running time: 1072.6474s / 365063.8227 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0059
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0060
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 1786.05,                last time consumption/overall running time: 1202.7122s / 366266.5349 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0059
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0061
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 1825.9,                last time consumption/overall running time: 1226.2477s / 367492.7827 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0055
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0056
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 1467.55,                last time consumption/overall running time: 988.1665s / 368480.9491 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0060
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0064
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 1698.35,                last time consumption/overall running time: 1143.4060s / 369624.3551 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0064
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0066
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 1657.85,                last time consumption/overall running time: 1114.9050s / 370739.2601 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0060
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0055
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 1582.75,                last time consumption/overall running time: 1062.4941s / 371801.7542 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0061
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0063
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 1777.0,                last time consumption/overall running time: 1192.5914s / 372994.3456 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0064
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 1791.9,                last time consumption/overall running time: 1202.8640s / 374197.2095 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0059
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0058
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 1705.45,                last time consumption/overall running time: 1144.3833s / 375341.5928 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0059
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0058
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 1869.75,                last time consumption/overall running time: 1252.9839s / 376594.5768 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0058
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0056
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 1539.45,                last time consumption/overall running time: 1031.8655s / 377626.4423 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0059
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0060
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 2056.05,                last time consumption/overall running time: 1381.5865s / 379008.0288 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0060
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0063
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 1777.7,                last time consumption/overall running time: 1191.1936s / 380199.2224 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0054
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0047
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 1872.55,                last time consumption/overall running time: 1255.0722s / 381454.2947 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0051
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0054
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 1434.8,                last time consumption/overall running time: 960.9028s / 382415.1974 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0058
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0059
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 1729.55,                last time consumption/overall running time: 1159.7879s / 383574.9853 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0063
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0062
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 1819.95,                last time consumption/overall running time: 1218.6249s / 384793.6102 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0054
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0055
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 1489.9,                last time consumption/overall running time: 1145.6119s / 385939.2221 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0060
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0057
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 1495.65,                last time consumption/overall running time: 1226.2108s / 387165.4329 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.0064
env0_second_0:                 episode reward: -2.2500,                 loss: 0.0060
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 2099.15,                last time consumption/overall running time: 1721.3020s / 388886.7349 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0059
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0060
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 1837.05,                last time consumption/overall running time: 1507.2406s / 390393.9755 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0049
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0048
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 1613.05,                last time consumption/overall running time: 1323.3448s / 391717.3203 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0057
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0054
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 1445.55,                last time consumption/overall running time: 1184.3109s / 392901.6312 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0062
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0066
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 1964.05,                last time consumption/overall running time: 1606.2891s / 394507.9203 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0062
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0063
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 1402.2,                last time consumption/overall running time: 1147.7319s / 395655.6522 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0055
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0056
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 1564.7,                last time consumption/overall running time: 1279.4276s / 396935.0798 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0065
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0069
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 1958.3,                last time consumption/overall running time: 1605.4270s / 398540.5068 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0062
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0066
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 1781.7,                last time consumption/overall running time: 1459.8709s / 400000.3777 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0056
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0057
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 1527.5,                last time consumption/overall running time: 1249.8044s / 401250.1821 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0061
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0060
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 1496.3,                last time consumption/overall running time: 1225.8676s / 402476.0497 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0067
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0065
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 1658.6,                last time consumption/overall running time: 1361.8422s / 403837.8919 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0070
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0068
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 1624.7,                last time consumption/overall running time: 1333.7039s / 405171.5958 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0061
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0061
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 1570.75,                last time consumption/overall running time: 1286.7916s / 406458.3874 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0063
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0067
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 1752.8,                last time consumption/overall running time: 1438.8688s / 407897.2561 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0060
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0060
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 1968.05,                last time consumption/overall running time: 1614.4571s / 409511.7132 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0058
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 2111.15,                last time consumption/overall running time: 1730.6449s / 411242.3581 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0053
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0055
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 1676.1,                last time consumption/overall running time: 1374.1432s / 412616.5013 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0053
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0057
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 2191.2,                last time consumption/overall running time: 1797.3180s / 414413.8192 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0052
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0052
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 1842.3,                last time consumption/overall running time: 1512.1727s / 415925.9920 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0055
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0053
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 1539.2,                last time consumption/overall running time: 1263.5140s / 417189.5060 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0053
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0055
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 1440.7,                last time consumption/overall running time: 1182.6656s / 418372.1716 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0065
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0063
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 2066.55,                last time consumption/overall running time: 1694.5040s / 420066.6756 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0064
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0060
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 1838.25,                last time consumption/overall running time: 1507.4024s / 421574.0780 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0054
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0051
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 1878.1,                last time consumption/overall running time: 1541.4546s / 423115.5326 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0059
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0057
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 1975.9,                last time consumption/overall running time: 1621.3294s / 424736.8620 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0053
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0054
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 2082.9,                last time consumption/overall running time: 1706.3973s / 426443.2592 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0053
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0053
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 1854.0,                last time consumption/overall running time: 1521.0099s / 427964.2691 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0051
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0053
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 1797.5,                last time consumption/overall running time: 1474.3777s / 429438.6468 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0054
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0052
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 1905.8,                last time consumption/overall running time: 1563.4189s / 431002.0657 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0053
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0053
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 1519.6,                last time consumption/overall running time: 1246.0280s / 432248.0937 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0051
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0054
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 1744.15,                last time consumption/overall running time: 1429.9171s / 433678.0108 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0057
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0060
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 1850.85,                last time consumption/overall running time: 1517.3436s / 435195.3544 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0057
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0056
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 1588.0,                last time consumption/overall running time: 1301.1391s / 436496.4935 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0059
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 1876.35,                last time consumption/overall running time: 1538.5010s / 438034.9945 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0059
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0062
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 1960.35,                last time consumption/overall running time: 1607.1357s / 439642.1302 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0054
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0055
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 1484.5,                last time consumption/overall running time: 1219.0254s / 440861.1555 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0056
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0062
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 1608.9,                last time consumption/overall running time: 1320.8225s / 442181.9780 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0064
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0072
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 1799.55,                last time consumption/overall running time: 1477.6964s / 443659.6744 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0062
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0062
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 1707.85,                last time consumption/overall running time: 1399.8144s / 445059.4888 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0066
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0063
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 1641.5,                last time consumption/overall running time: 1348.4796s / 446407.9684 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0063
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0064
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 1986.85,                last time consumption/overall running time: 1633.0712s / 448041.0396 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0060
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0062
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 1850.05,                last time consumption/overall running time: 1519.1276s / 449560.1673 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0055
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0054
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 1672.5,                last time consumption/overall running time: 1374.4556s / 450934.6228 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0054
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0057
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 1698.7,                last time consumption/overall running time: 1396.0480s / 452330.6708 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0060
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0059
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 1692.65,                last time consumption/overall running time: 1389.9033s / 453720.5741 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0060
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0055
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 1873.4,                last time consumption/overall running time: 1539.2700s / 455259.8441 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0060
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0054
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 1721.55,                last time consumption/overall running time: 1415.5882s / 456675.4323 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0053
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0059
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 1914.55,                last time consumption/overall running time: 1572.3540s / 458247.7863 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0054
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0057
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 1627.15,                last time consumption/overall running time: 1336.8252s / 459584.6115 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0060
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 2042.45,                last time consumption/overall running time: 1680.8118s / 461265.4233 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0057
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0059
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 1406.1,                last time consumption/overall running time: 1155.4531s / 462420.8764 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0054
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0056
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 1352.2,                last time consumption/overall running time: 1110.8964s / 463531.7728 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0063
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0066
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 2054.4,                last time consumption/overall running time: 1687.4123s / 465219.1850 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0059
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0057
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 2094.15,                last time consumption/overall running time: 1808.7051s / 467027.8902 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0052
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0053
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 1879.0,                last time consumption/overall running time: 1782.8949s / 468810.7851 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0051
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0050
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 1621.85,                last time consumption/overall running time: 1537.0383s / 470347.8234 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0056
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0058
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 1907.55,                last time consumption/overall running time: 1806.7451s / 472154.5685 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0063
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0065
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 1807.95,                last time consumption/overall running time: 1711.2733s / 473865.8418 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0052
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0052
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 2116.0,                last time consumption/overall running time: 2004.2848s / 475870.1266 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0054
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0054
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 1898.0,                last time consumption/overall running time: 1797.8363s / 477667.9629 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0053
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0049
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 1835.15,                last time consumption/overall running time: 1738.6488s / 479406.6117 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0055
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0051
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 1833.1,                last time consumption/overall running time: 1736.9966s / 481143.6083 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0051
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0054
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 1724.5,                last time consumption/overall running time: 1633.4572s / 482777.0656 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0054
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 1384.75,                last time consumption/overall running time: 1312.2713s / 484089.3369 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0067
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0063
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 2115.5,                last time consumption/overall running time: 2001.8677s / 486091.2046 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0062
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0063
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 1885.5,                last time consumption/overall running time: 1784.5781s / 487875.7827 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0052
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0053
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 2151.35,                last time consumption/overall running time: 2036.7471s / 489912.5299 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0051
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0056
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 1942.15,                last time consumption/overall running time: 1839.8289s / 491752.3587 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0055
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0056
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 1807.4,                last time consumption/overall running time: 1712.1458s / 493464.5046 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0052
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0057
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 2057.4,                last time consumption/overall running time: 1948.0886s / 495412.5932 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0054
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0055
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 1559.9,                last time consumption/overall running time: 1478.2145s / 496890.8076 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0053
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0056
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 2130.1,                last time consumption/overall running time: 2018.3264s / 498909.1341 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0060
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0056
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 1803.2,                last time consumption/overall running time: 1708.4257s / 500617.5598 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0052
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0049
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 1739.0,                last time consumption/overall running time: 1645.1833s / 502262.7432 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0056
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0057
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 1655.25,                last time consumption/overall running time: 1566.3437s / 503829.0869 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0058
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0059
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 1468.55,                last time consumption/overall running time: 1390.7587s / 505219.8455 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0062
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0067
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 1999.9,                last time consumption/overall running time: 1895.2746s / 507115.1201 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0065
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0065
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 1786.3,                last time consumption/overall running time: 1700.1751s / 508815.2951 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0059
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0057
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 1840.7,                last time consumption/overall running time: 1748.6832s / 510563.9783 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0054
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0057
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 1822.8,                last time consumption/overall running time: 1730.0343s / 512294.0126 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0056
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0059
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 1555.95,                last time consumption/overall running time: 1476.1731s / 513770.1857 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0062
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 1751.5,                last time consumption/overall running time: 1664.7180s / 515434.9037 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0060
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0064
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 1795.5,                last time consumption/overall running time: 1704.8328s / 517139.7365 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0054
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0059
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 1899.6,                last time consumption/overall running time: 1803.3848s / 518943.1214 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0054
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0056
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 2034.45,                last time consumption/overall running time: 1931.2694s / 520874.3908 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0052
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0049
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 1535.55,                last time consumption/overall running time: 1459.2278s / 522333.6185 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0053
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0054
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 1370.85,                last time consumption/overall running time: 1302.5146s / 523636.1331 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0058
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0060
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 1784.45,                last time consumption/overall running time: 1673.2633s / 525309.3965 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0062
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0068
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 1921.15,                last time consumption/overall running time: 1728.9712s / 527038.3677 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0057
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0055
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 1522.9,                last time consumption/overall running time: 1371.8408s / 528410.2084 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0052
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0053
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 1930.55,                last time consumption/overall running time: 1738.7114s / 530148.9198 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0058
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0056
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 1765.15,                last time consumption/overall running time: 1591.8000s / 531740.7198 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0055
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0053
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 1690.3,                last time consumption/overall running time: 1522.1061s / 533262.8259 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0052
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0055
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 1759.15,                last time consumption/overall running time: 1583.9539s / 534846.7798 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0053
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0057
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 1812.85,                last time consumption/overall running time: 1632.6091s / 536479.3889 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0052
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0058
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 1949.65,                last time consumption/overall running time: 1751.4208s / 538230.8097 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0053
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0056
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 1546.75,                last time consumption/overall running time: 1390.7621s / 539621.5718 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0052
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0055
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 1584.6,                last time consumption/overall running time: 1424.0885s / 541045.6603 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0065
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 1897.4,                last time consumption/overall running time: 1703.4705s / 542749.1308 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0059
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0062
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 1816.05,                last time consumption/overall running time: 1632.5120s / 544381.6428 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0056
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0053
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 1938.0,                last time consumption/overall running time: 1739.2159s / 546120.8587 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0051
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0052
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 1806.15,                last time consumption/overall running time: 1620.8259s / 547741.6847 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0055
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0057
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 1898.7,                last time consumption/overall running time: 1700.6518s / 549442.3365 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0055
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0058
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 1527.85,                last time consumption/overall running time: 1369.8722s / 550812.2087 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0060
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0060
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 2101.05,                last time consumption/overall running time: 1884.7690s / 552696.9777 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0055
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0059
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 1521.5,                last time consumption/overall running time: 1364.9884s / 554061.9661 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0046
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0053
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 1789.45,                last time consumption/overall running time: 1606.1614s / 555668.1276 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0054
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0060
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 1692.35,                last time consumption/overall running time: 1518.1675s / 557186.2951 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0056
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0056
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 1650.3,                last time consumption/overall running time: 1480.7985s / 558667.0936 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0059
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0059
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 1504.05,                last time consumption/overall running time: 1348.1205s / 560015.2141 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0055
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 1521.35,                last time consumption/overall running time: 1362.4120s / 561377.6261 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0062
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0060
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 1661.8,                last time consumption/overall running time: 1488.8763s / 562866.5024 sLoad SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rollout.py:21: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rollout_normal(env, model, save_id, args)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arrays = [asanyarray(arr) for arr in arrays]
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -0.8000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0060
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 1608.95,                last time consumption/overall running time: 1438.5855s / 564305.0879 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0052
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0057
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 1803.1,                last time consumption/overall running time: 1612.7255s / 565917.8134 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0056
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0060
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 1876.65,                last time consumption/overall running time: 1678.5539s / 567596.3674 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0057
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0059
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 1991.1,                last time consumption/overall running time: 1782.0548s / 569378.4221 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0056
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0055
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 1808.1,                last time consumption/overall running time: 1618.0535s / 570996.4757 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0057
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0059
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 1634.2,                last time consumption/overall running time: 1462.3426s / 572458.8183 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0057
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0059
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 1552.1,                last time consumption/overall running time: 1389.2179s / 573848.0362 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0062
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 2003.4,                last time consumption/overall running time: 1792.2392s / 575640.2754 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0061
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0057
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 1784.35,                last time consumption/overall running time: 1596.7747s / 577237.0501 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0058
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0057
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 2137.15,                last time consumption/overall running time: 1912.3975s / 579149.4475 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0050
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0056
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
