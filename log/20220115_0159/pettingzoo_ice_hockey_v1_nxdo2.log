pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
ice_hockey_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [66, 59]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=18, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'ice_hockey_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 10, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220115_0159/pettingzoo_ice_hockey_v1_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220115_0159/pettingzoo_ice_hockey_v1_nxdo2.
{'env_name': 'ice_hockey_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 10, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
ice_hockey_v1 pettingzoo
Load ice_hockey_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 77
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=18, bias=True)
    )
  )
)
Episode: 1/10000 (0.0100%),                 avg. length: 2715.0,                last time consumption/overall running time: 28.3801s / 28.3801 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0003
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 2759.6,                last time consumption/overall running time: 560.0470s / 588.4271 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0035
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 2807.75,                last time consumption/overall running time: 589.3641s / 1177.7912 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0074
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 2822.5,                last time consumption/overall running time: 594.6535s / 1772.4448 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0064
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 2833.4,                last time consumption/overall running time: 593.5554s / 2366.0002 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0035
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 2823.25,                last time consumption/overall running time: 592.8666s / 2958.8667 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0014
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 2850.65,                last time consumption/overall running time: 597.5297s / 3556.3965 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0011
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 2882.5,                last time consumption/overall running time: 598.9133s / 4155.3097 s
env0_first_0:                 episode reward: 3.6500,                 loss: nan
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Score delta: 10.2, save the model to .//data/model/20220115_0159/pettingzoo_ice_hockey_v1_nxdo2/137_0.
Episode: 161/10000 (1.6100%),                 avg. length: 2841.55,                last time consumption/overall running time: 587.2262s / 4742.5360 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0065
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 2831.0,                last time consumption/overall running time: 591.9033s / 5334.4392 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0104
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 2848.7,                last time consumption/overall running time: 595.2844s / 5929.7237 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0068
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 2860.55,                last time consumption/overall running time: 590.6669s / 6520.3906 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0048
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 2909.85,                last time consumption/overall running time: 599.3448s / 7119.7354 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0023
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 2839.65,                last time consumption/overall running time: 584.6977s / 7704.4331 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0014
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 2853.65,                last time consumption/overall running time: 594.1588s / 8298.5919 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0012
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 2876.25,                last time consumption/overall running time: 599.6239s / 8898.2158 s
env0_first_0:                 episode reward: -0.3000,                 loss: nan
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0010
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 2914.45,                last time consumption/overall running time: 609.4360s / 9507.6518 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0012
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 2906.6,                last time consumption/overall running time: 605.2075s / 10112.8593 s
env0_first_0:                 episode reward: -0.2500,                 loss: nan
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0016
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 2903.25,                last time consumption/overall running time: 596.6301s / 10709.4894 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0013
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 2876.45,                last time consumption/overall running time: 601.3705s / 11310.8599 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0010
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 2898.2,                last time consumption/overall running time: 601.9442s / 11912.8041 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0009
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 2887.95,                last time consumption/overall running time: 606.8368s / 12519.6409 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0008
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 2898.3,                last time consumption/overall running time: 604.2784s / 13123.9193 s
env0_first_0:                 episode reward: 1.5000,                 loss: nan
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0008
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 2865.9,                last time consumption/overall running time: 596.9746s / 13720.8939 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0009
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 2864.05,                last time consumption/overall running time: 599.3242s / 14320.2181 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0008
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 2854.35,                last time consumption/overall running time: 593.7033s / 14913.9214 s
env0_first_0:                 episode reward: -0.3500,                 loss: nan
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0008
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 2872.9,                last time consumption/overall running time: 593.4272s / 15507.3486 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0008
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 2855.0,                last time consumption/overall running time: 592.4168s / 16099.7654 s
env0_first_0:                 episode reward: -0.2000,                 loss: nan
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0008
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 2886.55,                last time consumption/overall running time: 597.8604s / 16697.6258 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0008
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 2861.2,                last time consumption/overall running time: 591.6361s / 17289.2619 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0008
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 2842.35,                last time consumption/overall running time: 591.6266s / 17880.8885 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0008
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 2841.3,                last time consumption/overall running time: 591.1301s / 18472.0186 s
env0_first_0:                 episode reward: -0.4000,                 loss: nan
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0007
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 2852.35,                last time consumption/overall running time: 597.3358s / 19069.3543 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0007
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 2844.7,                last time consumption/overall running time: 598.6834s / 19668.0378 s
env0_first_0:                 episode reward: -0.6000,                 loss: nan
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0007
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 2866.55,                last time consumption/overall running time: 600.8282s / 20268.8660 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0008
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 2874.7,                last time consumption/overall running time: 595.2732s / 20864.1392 s
env0_first_0:                 episode reward: -0.7500,                 loss: nan
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0007
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 2844.2,                last time consumption/overall running time: 592.5364s / 21456.6756 s
env0_first_0:                 episode reward: -0.2500,                 loss: nan
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0008
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 2834.7,                last time consumption/overall running time: 600.9965s / 22057.6722 s
env0_first_0:                 episode reward: -0.1000,                 loss: nan
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0009
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 2869.05,                last time consumption/overall running time: 593.8361s / 22651.5082 s
env0_first_0:                 episode reward: 0.1000,                 loss: nan
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0009
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 2847.35,                last time consumption/overall running time: 595.6720s / 23247.1802 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0008
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 2841.35,                last time consumption/overall running time: 594.1608s / 23841.3410 s
env0_first_0:                 episode reward: -0.2000,                 loss: nan
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 2836.65,                last time consumption/overall running time: 594.3944s / 24435.7353 s
env0_first_0:                 episode reward: -0.4500,                 loss: nan
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0008
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 2869.05,                last time consumption/overall running time: 597.1300s / 25032.8653 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0008
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 2853.35,                last time consumption/overall running time: 594.3506s / 25627.2159 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0009
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 2851.6,                last time consumption/overall running time: 591.0169s / 26218.2328 s
env0_first_0:                 episode reward: -0.0500,                 loss: nan
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0008
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 2830.1,                last time consumption/overall running time: 583.9142s / 26802.1470 s
env0_first_0:                 episode reward: 0.9500,                 loss: nan
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0008
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 2834.25,                last time consumption/overall running time: 588.1683s / 27390.3153 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0007
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 2843.25,                last time consumption/overall running time: 592.2493s / 27982.5646 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0008
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 2881.35,                last time consumption/overall running time: 596.0920s / 28578.6566 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0008
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 2852.35,                last time consumption/overall running time: 591.4807s / 29170.1372 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0009
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 2843.45,                last time consumption/overall running time: 589.8972s / 29760.0345 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0009
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 2842.2,                last time consumption/overall running time: 592.5049s / 30352.5394 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0007
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 2867.1,                last time consumption/overall running time: 588.9547s / 30941.4940 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0008
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 2837.2,                last time consumption/overall running time: 586.1164s / 31527.6104 s
env0_first_0:                 episode reward: 0.9500,                 loss: nan
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0010
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 2826.55,                last time consumption/overall running time: 585.6081s / 32113.2185 s
env0_first_0:                 episode reward: 0.2000,                 loss: nan
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0008
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 2850.25,                last time consumption/overall running time: 592.1806s / 32705.3991 s
env0_first_0:                 episode reward: -0.1000,                 loss: nan
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0009
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 2814.45,                last time consumption/overall running time: 568.6914s / 33274.0905 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0010
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 2864.75,                last time consumption/overall running time: 586.7470s / 33860.8376 s
env0_first_0:                 episode reward: 0.1000,                 loss: nan
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0009
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 2873.65,                last time consumption/overall running time: 601.0582s / 34461.8957 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0008
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 2819.15,                last time consumption/overall running time: 578.3225s / 35040.2183 s
env0_first_0:                 episode reward: -0.7000,                 loss: nan
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 2826.75,                last time consumption/overall running time: 579.4003s / 35619.6186 s
env0_first_0:                 episode reward: 1.8000,                 loss: nan
env0_second_0:                 episode reward: -1.8000,                 loss: 0.0008
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 2809.75,                last time consumption/overall running time: 572.6901s / 36192.3087 s
env0_first_0:                 episode reward: -0.2500,                 loss: nan
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0008
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 2820.85,                last time consumption/overall running time: 594.3988s / 36786.7075 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 2836.05,                last time consumption/overall running time: 581.3508s / 37368.0583 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0012
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 2829.9,                last time consumption/overall running time: 586.5418s / 37954.6001 s
env0_first_0:                 episode reward: -0.2000,                 loss: nan
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0024
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 2844.3,                last time consumption/overall running time: 599.3138s / 38553.9138 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0028
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 2801.8,                last time consumption/overall running time: 571.6280s / 39125.5418 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0030
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 2845.65,                last time consumption/overall running time: 585.0389s / 39710.5807 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0024
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 2814.25,                last time consumption/overall running time: 581.4262s / 40292.0069 s
env0_first_0:                 episode reward: -0.9000,                 loss: nan
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0023
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 2831.75,                last time consumption/overall running time: 572.4175s / 40864.4244 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0037
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 2813.55,                last time consumption/overall running time: 581.4626s / 41445.8870 s
env0_first_0:                 episode reward: 0.0000,                 loss: nan
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0040
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 2835.15,                last time consumption/overall running time: 582.1189s / 42028.0058 s
env0_first_0:                 episode reward: -0.2500,                 loss: nan
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0036
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 2817.65,                last time consumption/overall running time: 586.1226s / 42614.1285 s
env0_first_0:                 episode reward: 0.0000,                 loss: nan
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0031
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 2819.75,                last time consumption/overall running time: 581.2638s / 43195.3923 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0024
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 2807.45,                last time consumption/overall running time: 570.3020s / 43765.6943 s
env0_first_0:                 episode reward: 0.0000,                 loss: nan
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0019
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 2839.0,                last time consumption/overall running time: 579.6064s / 44345.3007 s
env0_first_0:                 episode reward: 0.1000,                 loss: nan
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0019
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 2844.75,                last time consumption/overall running time: 586.9456s / 44932.2463 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0021
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 2824.7,                last time consumption/overall running time: 587.3334s / 45519.5798 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0015
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 2850.9,                last time consumption/overall running time: 577.7056s / 46097.2854 s
env0_first_0:                 episode reward: -0.3500,                 loss: nan
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0013
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 2830.4,                last time consumption/overall running time: 584.8908s / 46682.1762 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0015
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 2825.35,                last time consumption/overall running time: 576.9343s / 47259.1105 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0016
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 2821.4,                last time consumption/overall running time: 577.7671s / 47836.8775 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0015
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 2838.6,                last time consumption/overall running time: 596.8399s / 48433.7174 s
env0_first_0:                 episode reward: 0.2000,                 loss: nan
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0022
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 2844.35,                last time consumption/overall running time: 592.4279s / 49026.1454 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0028
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 2839.0,                last time consumption/overall running time: 597.8895s / 49624.0348 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0024
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 2812.6,                last time consumption/overall running time: 588.6304s / 50212.6653 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0020
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 2837.15,                last time consumption/overall running time: 580.5629s / 50793.2282 s
env0_first_0:                 episode reward: -0.3000,                 loss: nan
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0017
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 2840.25,                last time consumption/overall running time: 595.8210s / 51389.0492 s
env0_first_0:                 episode reward: -0.2500,                 loss: nan
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0020
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 2809.85,                last time consumption/overall running time: 589.4755s / 51978.5247 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0018
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 2846.8,                last time consumption/overall running time: 596.9659s / 52575.4906 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0015
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 2817.45,                last time consumption/overall running time: 574.2596s / 53149.7502 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0016
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 2818.0,                last time consumption/overall running time: 584.7766s / 53734.5269 s
env0_first_0:                 episode reward: 0.9500,                 loss: nan
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0018
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 2826.3,                last time consumption/overall running time: 604.0795s / 54338.6063 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0020
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 2806.1,                last time consumption/overall running time: 581.7056s / 54920.3120 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0023
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 2805.55,                last time consumption/overall running time: 571.4459s / 55491.7578 s
env0_first_0:                 episode reward: 0.9500,                 loss: nan
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0030
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 2832.0,                last time consumption/overall running time: 594.1676s / 56085.9254 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0034
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 2811.75,                last time consumption/overall running time: 591.9098s / 56677.8352 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0047
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 2808.3,                last time consumption/overall running time: 586.9699s / 57264.8051 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0090
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 2797.25,                last time consumption/overall running time: 577.1514s / 57841.9565 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0143
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2847.0,                last time consumption/overall running time: 585.6948s / 58427.6513 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0160
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 2823.65,                last time consumption/overall running time: 581.7318s / 59009.3831 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0210
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 2832.15,                last time consumption/overall running time: 575.0279s / 59584.4110 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0165
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 2806.4,                last time consumption/overall running time: 582.1591s / 60166.5701 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0181
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 2805.6,                last time consumption/overall running time: 585.4278s / 60751.9979 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0374
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 2813.2,                last time consumption/overall running time: 582.8695s / 61334.8674 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0362
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 2813.3,                last time consumption/overall running time: 579.9474s / 61914.8148 s
env0_first_0:                 episode reward: 1.3000,                 loss: nan
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0271
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 2800.3,                last time consumption/overall running time: 592.8128s / 62507.6276 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0285
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2811.75,                last time consumption/overall running time: 582.3406s / 63089.9682 s
env0_first_0:                 episode reward: 1.4500,                 loss: nan
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0299
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2827.85,                last time consumption/overall running time: 578.7513s / 63668.7195 s
env0_first_0:                 episode reward: -0.0500,                 loss: nan
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0299
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 2804.15,                last time consumption/overall running time: 576.3077s / 64245.0272 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0300
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 2811.45,                last time consumption/overall running time: 587.2063s / 64832.2335 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0249
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 2829.3,                last time consumption/overall running time: 595.6230s / 65427.8565 s
env0_first_0:                 episode reward: 1.9000,                 loss: nan
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0305
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 2831.35,                last time consumption/overall running time: 594.3658s / 66022.2223 s
env0_first_0:                 episode reward: 1.4500,                 loss: nan
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0267
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 2828.3,                last time consumption/overall running time: 587.4160s / 66609.6383 s
env0_first_0:                 episode reward: 1.0500,                 loss: nan
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0261
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 2797.25,                last time consumption/overall running time: 585.9851s / 67195.6234 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0261
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 2798.25,                last time consumption/overall running time: 568.9654s / 67764.5888 s
env0_first_0:                 episode reward: 0.9500,                 loss: nan
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0290
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 2828.15,                last time consumption/overall running time: 564.8871s / 68329.4758 s
env0_first_0:                 episode reward: 1.0500,                 loss: nan
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0338
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 2795.7,                last time consumption/overall running time: 574.8917s / 68904.3676 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0354
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 2841.3,                last time consumption/overall running time: 585.9733s / 69490.3409 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0256
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 2789.4,                last time consumption/overall running time: 567.7827s / 70058.1236 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0198
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 2822.95,                last time consumption/overall running time: 577.7149s / 70635.8385 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0138
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 2819.55,                last time consumption/overall running time: 583.1338s / 71218.9723 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0097
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 2811.75,                last time consumption/overall running time: 580.3654s / 71799.3376 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0073
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 2830.9,                last time consumption/overall running time: 593.4540s / 72392.7917 s
env0_first_0:                 episode reward: 1.2000,                 loss: nan
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0083
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 2843.25,                last time consumption/overall running time: 590.7402s / 72983.5319 s
env0_first_0:                 episode reward: 0.0000,                 loss: nan
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0060
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 2848.3,                last time consumption/overall running time: 603.3575s / 73586.8894 s
env0_first_0:                 episode reward: 1.1000,                 loss: nan
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0059
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2820.2,                last time consumption/overall running time: 593.2643s / 74180.1536 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0076
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 2828.2,                last time consumption/overall running time: 583.8255s / 74763.9792 s
env0_first_0:                 episode reward: 1.2000,                 loss: nan
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0090
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 2815.35,                last time consumption/overall running time: 591.1892s / 75355.1684 s
env0_first_0:                 episode reward: -0.0500,                 loss: nan
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0097
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 2821.35,                last time consumption/overall running time: 591.8499s / 75947.0183 s
env0_first_0:                 episode reward: 1.1000,                 loss: nan
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0066
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 2837.55,                last time consumption/overall running time: 591.1599s / 76538.1782 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0071
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 2835.0,                last time consumption/overall running time: 585.4900s / 77123.6682 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0083
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 2791.75,                last time consumption/overall running time: 576.2753s / 77699.9435 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0050
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 2847.85,                last time consumption/overall running time: 587.0282s / 78286.9716 s
env0_first_0:                 episode reward: 1.4000,                 loss: nan
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0042
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 2824.0,                last time consumption/overall running time: 588.3461s / 78875.3178 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0076
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 2821.25,                last time consumption/overall running time: 584.6780s / 79459.9958 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 2819.9,                last time consumption/overall running time: 588.0152s / 80048.0110 s
env0_first_0:                 episode reward: 0.1000,                 loss: nan
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0115
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 2802.55,                last time consumption/overall running time: 582.6920s / 80630.7030 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0113
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 2818.35,                last time consumption/overall running time: 585.3771s / 81216.0801 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0044
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 2824.45,                last time consumption/overall running time: 592.3595s / 81808.4396 s
env0_first_0:                 episode reward: 1.3000,                 loss: nan
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0030
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 2793.05,                last time consumption/overall running time: 575.3113s / 82383.7510 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0018
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 2835.3,                last time consumption/overall running time: 588.1424s / 82971.8934 s
env0_first_0:                 episode reward: 1.1000,                 loss: nan
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0015
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 2824.15,                last time consumption/overall running time: 588.9938s / 83560.8872 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0013
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 2832.15,                last time consumption/overall running time: 573.0799s / 84133.9671 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0008
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 2872.35,                last time consumption/overall running time: 585.8495s / 84719.8166 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0008
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 2860.55,                last time consumption/overall running time: 588.1083s / 85307.9249 s
env0_first_0:                 episode reward: 1.1000,                 loss: nan
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0008
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 2831.55,                last time consumption/overall running time: 595.8297s / 85903.7546 s
env0_first_0:                 episode reward: -0.2000,                 loss: nan
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0007
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 2867.95,                last time consumption/overall running time: 593.2477s / 86497.0023 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0006
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 2816.3,                last time consumption/overall running time: 579.9483s / 87076.9506 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0006
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 2824.65,                last time consumption/overall running time: 584.2930s / 87661.2436 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0005
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 2846.4,                last time consumption/overall running time: 559.1762s / 88220.4198 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 2832.5,                last time consumption/overall running time: 559.5675s / 88779.9872 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 2834.3,                last time consumption/overall running time: 529.9018s / 89309.8891 s
env0_first_0:                 episode reward: -0.6000,                 loss: nan
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 2822.05,                last time consumption/overall running time: 551.8699s / 89861.7590 s
env0_first_0:                 episode reward: 0.1000,                 loss: nan
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0007
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 2825.15,                last time consumption/overall running time: 535.3745s / 90397.1335 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0016
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 2823.75,                last time consumption/overall running time: 525.6719s / 90922.8054 s
env0_first_0:                 episode reward: 1.7000,                 loss: nan
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0020
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 2831.9,                last time consumption/overall running time: 555.4538s / 91478.2592 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0024
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 2773.95,                last time consumption/overall running time: 536.8372s / 92015.0964 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0024
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 2795.75,                last time consumption/overall running time: 539.3459s / 92554.4422 s
env0_first_0:                 episode reward: -0.3000,                 loss: nan
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0023
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 2788.1,                last time consumption/overall running time: 535.9534s / 93090.3956 s
env0_first_0:                 episode reward: 0.2000,                 loss: nan
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0019
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 2814.05,                last time consumption/overall running time: 532.7550s / 93623.1506 s
env0_first_0:                 episode reward: 1.2500,                 loss: nan
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0013
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 2872.65,                last time consumption/overall running time: 556.3265s / 94179.4771 s
env0_first_0:                 episode reward: 1.4500,                 loss: nan
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0013
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 2843.8,                last time consumption/overall running time: 548.7085s / 94728.1856 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0011
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 2813.85,                last time consumption/overall running time: 535.5989s / 95263.7845 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0009
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 2838.4,                last time consumption/overall running time: 538.0637s / 95801.8482 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0007
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 2861.65,                last time consumption/overall running time: 551.6869s / 96353.5351 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0007
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 2828.3,                last time consumption/overall running time: 539.1956s / 96892.7307 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 2860.2,                last time consumption/overall running time: 550.1904s / 97442.9211 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 2867.8,                last time consumption/overall running time: 544.4616s / 97987.3827 s
env0_first_0:                 episode reward: 0.2000,                 loss: nan
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 2878.2,                last time consumption/overall running time: 554.0158s / 98541.3985 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 2841.6,                last time consumption/overall running time: 552.5800s / 99093.9785 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0005
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 2914.65,                last time consumption/overall running time: 566.1347s / 99660.1132 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0005
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 2832.2,                last time consumption/overall running time: 543.3490s / 100203.4622 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0005
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 2850.25,                last time consumption/overall running time: 535.1845s / 100738.6467 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 2841.35,                last time consumption/overall running time: 543.1778s / 101281.8246 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 2859.5,                last time consumption/overall running time: 541.6203s / 101823.4449 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 2837.05,                last time consumption/overall running time: 539.3982s / 102362.8430 s
env0_first_0:                 episode reward: -0.0500,                 loss: nan
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 2843.85,                last time consumption/overall running time: 553.1926s / 102916.0356 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 2874.95,                last time consumption/overall running time: 551.4619s / 103467.4975 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 2900.0,                last time consumption/overall running time: 551.7290s / 104019.2265 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 2845.3,                last time consumption/overall running time: 526.5294s / 104545.7559 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0010
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 2855.5,                last time consumption/overall running time: 526.1481s / 105071.9040 s
env0_first_0:                 episode reward: 1.0500,                 loss: nan
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 2822.9,                last time consumption/overall running time: 529.9819s / 105601.8859 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0005
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 2847.65,                last time consumption/overall running time: 541.9215s / 106143.8074 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 2858.15,                last time consumption/overall running time: 549.9182s / 106693.7256 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 2848.85,                last time consumption/overall running time: 543.4137s / 107237.1392 s
env0_first_0:                 episode reward: -0.1000,                 loss: nan
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0005
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 2856.55,                last time consumption/overall running time: 545.9374s / 107783.0767 s
env0_first_0:                 episode reward: 1.6500,                 loss: nan
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0005
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 2862.25,                last time consumption/overall running time: 551.0009s / 108334.0775 s
env0_first_0:                 episode reward: -0.2500,                 loss: nan
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0006
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 2894.45,                last time consumption/overall running time: 559.6415s / 108893.7190 s
env0_first_0:                 episode reward: 1.1000,                 loss: nan
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0007
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 2858.95,                last time consumption/overall running time: 549.3355s / 109443.0545 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 2857.35,                last time consumption/overall running time: 557.7858s / 110000.8403 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 2839.4,                last time consumption/overall running time: 553.1551s / 110553.9954 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 2820.5,                last time consumption/overall running time: 476.4793s / 111030.4748 s
env0_first_0:                 episode reward: 1.4000,                 loss: nan
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 2848.6,                last time consumption/overall running time: 494.9455s / 111525.4202 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 2836.45,                last time consumption/overall running time: 468.3335s / 111993.7538 s
env0_first_0:                 episode reward: 1.5000,                 loss: nan
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 2866.15,                last time consumption/overall running time: 481.1480s / 112474.9018 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0006
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 2841.9,                last time consumption/overall running time: 461.5783s / 112936.4801 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 2879.05,                last time consumption/overall running time: 484.2370s / 113420.7171 s
env0_first_0:                 episode reward: 1.5000,                 loss: nan
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 2844.95,                last time consumption/overall running time: 482.7127s / 113903.4298 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 2843.5,                last time consumption/overall running time: 449.7436s / 114353.1733 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0007
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 2829.5,                last time consumption/overall running time: 456.4489s / 114809.6223 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0007
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 2855.6,                last time consumption/overall running time: 470.7668s / 115280.3891 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 2809.65,                last time consumption/overall running time: 477.0523s / 115757.4414 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 2837.1,                last time consumption/overall running time: 487.1144s / 116244.5558 s
env0_first_0:                 episode reward: 0.9500,                 loss: nan
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 2856.7,                last time consumption/overall running time: 473.7806s / 116718.3364 s
env0_first_0:                 episode reward: 1.4500,                 loss: nan
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 2872.0,                last time consumption/overall running time: 480.4762s / 117198.8127 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 2857.55,                last time consumption/overall running time: 480.7769s / 117679.5896 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0007
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 2854.55,                last time consumption/overall running time: 479.0805s / 118158.6701 s
env0_first_0:                 episode reward: 1.1000,                 loss: nan
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0007
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 2848.25,                last time consumption/overall running time: 461.1017s / 118619.7719 s
env0_first_0:                 episode reward: -0.2000,                 loss: nan
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 2865.8,                last time consumption/overall running time: 470.9426s / 119090.7144 s
env0_first_0:                 episode reward: 1.6500,                 loss: nan
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0007
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 2885.3,                last time consumption/overall running time: 473.2428s / 119563.9572 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0007
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 2836.4,                last time consumption/overall running time: 459.7973s / 120023.7545 s
env0_first_0:                 episode reward: 1.5000,                 loss: nan
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 2896.65,                last time consumption/overall running time: 490.6948s / 120514.4493 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 2833.6,                last time consumption/overall running time: 482.1516s / 120996.6009 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 2857.15,                last time consumption/overall running time: 466.6387s / 121463.2396 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 2847.05,                last time consumption/overall running time: 467.1217s / 121930.3613 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 2824.65,                last time consumption/overall running time: 473.0562s / 122403.4174 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 2855.3,                last time consumption/overall running time: 472.5740s / 122875.9914 s
env0_first_0:                 episode reward: -0.0500,                 loss: nan
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0006
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 2856.15,                last time consumption/overall running time: 491.9892s / 123367.9806 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 2846.95,                last time consumption/overall running time: 469.0723s / 123837.0529 s
env0_first_0:                 episode reward: 1.1000,                 loss: nan
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 2845.6,                last time consumption/overall running time: 485.1875s / 124322.2404 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 2851.1,                last time consumption/overall running time: 468.0497s / 124790.2901 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 2859.55,                last time consumption/overall running time: 482.7271s / 125273.0172 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 2853.65,                last time consumption/overall running time: 482.1088s / 125755.1260 s
env0_first_0:                 episode reward: 1.4500,                 loss: nan
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 2886.6,                last time consumption/overall running time: 479.5808s / 126234.7068 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 2839.15,                last time consumption/overall running time: 469.8594s / 126704.5662 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 2829.2,                last time consumption/overall running time: 477.6488s / 127182.2150 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0005
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 2867.45,                last time consumption/overall running time: 491.2986s / 127673.5137 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 2859.55,                last time consumption/overall running time: 475.3370s / 128148.8506 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 2860.55,                last time consumption/overall running time: 484.5409s / 128633.3916 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0007
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 2840.4,                last time consumption/overall running time: 470.5469s / 129103.9385 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0006
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 2890.6,                last time consumption/overall running time: 485.9229s / 129589.8614 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 2874.1,                last time consumption/overall running time: 494.5216s / 130084.3830 s
env0_first_0:                 episode reward: 1.2500,                 loss: nan
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0006
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 2834.7,                last time consumption/overall running time: 467.6698s / 130552.0528 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 2887.6,                last time consumption/overall running time: 466.5298s / 131018.5826 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 2852.8,                last time consumption/overall running time: 460.6155s / 131479.1981 s
env0_first_0:                 episode reward: 1.7500,                 loss: nan
env0_second_0:                 episode reward: -1.7500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 2877.15,                last time consumption/overall running time: 475.0650s / 131954.2631 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 2873.4,                last time consumption/overall running time: 489.7307s / 132443.9938 s
env0_first_0:                 episode reward: 1.4000,                 loss: nan
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0006
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 2850.2,                last time consumption/overall running time: 476.1912s / 132920.1850 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0005
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 2859.1,                last time consumption/overall running time: 468.9390s / 133389.1240 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0005
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 2902.6,                last time consumption/overall running time: 450.9244s / 133840.0484 s
env0_first_0:                 episode reward: 2.2000,                 loss: nan
env0_second_0:                 episode reward: -2.2000,                 loss: 0.0006
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 2860.75,                last time consumption/overall running time: 475.9168s / 134315.9652 s
env0_first_0:                 episode reward: 1.2000,                 loss: nan
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0006
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 2825.3,                last time consumption/overall running time: 459.7247s / 134775.6900 s
env0_first_0:                 episode reward: 1.2500,                 loss: nan
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 2850.2,                last time consumption/overall running time: 480.7431s / 135256.4331 s
env0_first_0:                 episode reward: -0.2000,                 loss: nan
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 2868.3,                last time consumption/overall running time: 494.0918s / 135750.5248 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 2845.5,                last time consumption/overall running time: 438.5826s / 136189.1074 s
env0_first_0:                 episode reward: 1.2500,                 loss: nan
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 2867.0,                last time consumption/overall running time: 447.1107s / 136636.2180 s
env0_first_0:                 episode reward: 0.0000,                 loss: nan
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0005
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 2856.7,                last time consumption/overall running time: 419.9594s / 137056.1775 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 2806.55,                last time consumption/overall running time: 458.7017s / 137514.8791 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 2864.2,                last time consumption/overall running time: 440.1729s / 137955.0520 s
env0_first_0:                 episode reward: 0.9500,                 loss: nan
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 2840.8,                last time consumption/overall running time: 440.1636s / 138395.2156 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 2842.25,                last time consumption/overall running time: 413.9235s / 138809.1390 s
env0_first_0:                 episode reward: -0.1500,                 loss: nan
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0008
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 2875.85,                last time consumption/overall running time: 437.5526s / 139246.6917 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0009
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 2859.85,                last time consumption/overall running time: 468.7027s / 139715.3943 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0010
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 2863.3,                last time consumption/overall running time: 461.8398s / 140177.2341 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0010
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 2828.0,                last time consumption/overall running time: 452.4329s / 140629.6669 s
env0_first_0:                 episode reward: 0.1000,                 loss: nan
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0008
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 2824.95,                last time consumption/overall running time: 493.2361s / 141122.9030 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0007
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 2852.8,                last time consumption/overall running time: 429.2101s / 141552.1131 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0006
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 2841.35,                last time consumption/overall running time: 426.0612s / 141978.1743 s
env0_first_0:                 episode reward: 1.4000,                 loss: nan
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0005
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 2859.75,                last time consumption/overall running time: 442.3113s / 142420.4856 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 2852.75,                last time consumption/overall running time: 463.9725s / 142884.4582 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 2842.6,                last time consumption/overall running time: 472.9347s / 143357.3929 s
env0_first_0:                 episode reward: 1.4000,                 loss: nan
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0020
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 2813.15,                last time consumption/overall running time: 453.0105s / 143810.4034 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0063
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 2838.35,                last time consumption/overall running time: 444.9903s / 144255.3937 s
env0_first_0:                 episode reward: 1.4500,                 loss: nan
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0078
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 2831.45,                last time consumption/overall running time: 451.2996s / 144706.6932 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0042
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 2824.3,                last time consumption/overall running time: 453.6611s / 145160.3543 s
env0_first_0:                 episode reward: -0.3000,                 loss: nan
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0043
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 2824.3,                last time consumption/overall running time: 458.5730s / 145618.9273 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0031
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 2813.7,                last time consumption/overall running time: 454.6117s / 146073.5390 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0039
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 2834.0,                last time consumption/overall running time: 480.1333s / 146553.6723 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0020
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 2841.15,                last time consumption/overall running time: 478.9286s / 147032.6010 s
env0_first_0:                 episode reward: 0.0000,                 loss: nan
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0014
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 2827.5,                last time consumption/overall running time: 474.3711s / 147506.9721 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0014
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 2833.45,                last time consumption/overall running time: 475.7916s / 147982.7637 s
env0_first_0:                 episode reward: -0.4500,                 loss: nan
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0013
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 2843.05,                last time consumption/overall running time: 466.4964s / 148449.2601 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0014
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 2826.55,                last time consumption/overall running time: 471.6219s / 148920.8820 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0011
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 2832.65,                last time consumption/overall running time: 471.3872s / 149392.2692 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0015
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 2817.95,                last time consumption/overall running time: 472.9010s / 149865.1702 s
env0_first_0:                 episode reward: -0.2000,                 loss: nan
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0018
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 2854.2,                last time consumption/overall running time: 459.0553s / 150324.2255 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0011
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 2844.8,                last time consumption/overall running time: 456.0235s / 150780.2490 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0018
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 2833.1,                last time consumption/overall running time: 450.8156s / 151231.0646 s
env0_first_0:                 episode reward: 0.2000,                 loss: nan
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0017
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 2826.7,                last time consumption/overall running time: 461.8562s / 151692.9208 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0013
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 2846.5,                last time consumption/overall running time: 464.6634s / 152157.5842 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0009
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 2856.1,                last time consumption/overall running time: 466.1407s / 152623.7249 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0008
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 2832.8,                last time consumption/overall running time: 460.4233s / 153084.1482 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 2846.1,                last time consumption/overall running time: 473.8972s / 153558.0454 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0005
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 2853.7,                last time consumption/overall running time: 468.3482s / 154026.3936 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0005
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 2846.0,                last time consumption/overall running time: 481.6211s / 154508.0147 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0014
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 2843.5,                last time consumption/overall running time: 454.7640s / 154962.7787 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0008
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 2817.05,                last time consumption/overall running time: 453.1532s / 155415.9320 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0011
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 2852.3,                last time consumption/overall running time: 458.6680s / 155874.6000 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0008
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 2871.65,                last time consumption/overall running time: 473.7237s / 156348.3237 s
env0_first_0:                 episode reward: 1.2000,                 loss: nan
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 2858.75,                last time consumption/overall running time: 470.3583s / 156818.6820 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 2891.25,                last time consumption/overall running time: 463.3501s / 157282.0321 s
env0_first_0:                 episode reward: 1.5500,                 loss: nan
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0006
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 2840.25,                last time consumption/overall running time: 465.0689s / 157747.1009 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 2840.5,                last time consumption/overall running time: 456.5836s / 158203.6845 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0005
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 2872.8,                last time consumption/overall running time: 478.8153s / 158682.4998 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 2855.55,                last time consumption/overall running time: 438.7220s / 159121.2219 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 2845.55,                last time consumption/overall running time: 442.2589s / 159563.4808 s
env0_first_0:                 episode reward: 0.2000,                 loss: nan
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0005
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 2835.05,                last time consumption/overall running time: 413.8568s / 159977.3376 s
env0_first_0:                 episode reward: -0.2500,                 loss: nan
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 2835.7,                last time consumption/overall running time: 459.2901s / 160436.6277 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 2866.8,                last time consumption/overall running time: 479.7408s / 160916.3685 s
env0_first_0:                 episode reward: 1.5500,                 loss: nan
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 2819.95,                last time consumption/overall running time: 470.8694s / 161387.2379 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 2859.2,                last time consumption/overall running time: 482.1775s / 161869.4154 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 2863.65,                last time consumption/overall running time: 468.8913s / 162338.3067 s
env0_first_0:                 episode reward: 1.6500,                 loss: nan
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 2843.9,                last time consumption/overall running time: 466.5007s / 162804.8074 s
env0_first_0:                 episode reward: 1.0500,                 loss: nan
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 2853.8,                last time consumption/overall running time: 471.0102s / 163275.8176 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 2870.1,                last time consumption/overall running time: 488.1558s / 163763.9734 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 2854.3,                last time consumption/overall running time: 480.0559s / 164244.0293 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 2843.95,                last time consumption/overall running time: 468.1190s / 164712.1484 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 2824.5,                last time consumption/overall running time: 457.1587s / 165169.3071 s
env0_first_0:                 episode reward: 1.2500,                 loss: nan
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 2882.7,                last time consumption/overall running time: 479.0143s / 165648.3214 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 2862.5,                last time consumption/overall running time: 482.6796s / 166131.0010 s
env0_first_0:                 episode reward: 1.3000,                 loss: nan
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 2870.15,                last time consumption/overall running time: 466.6726s / 166597.6736 s
env0_first_0:                 episode reward: 1.4500,                 loss: nan
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 2871.3,                last time consumption/overall running time: 454.4482s / 167052.1218 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0006
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 2862.0,                last time consumption/overall running time: 456.8858s / 167509.0075 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 2873.45,                last time consumption/overall running time: 472.7569s / 167981.7645 s
env0_first_0:                 episode reward: 1.3000,                 loss: nan
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 2869.0,                last time consumption/overall running time: 456.3064s / 168438.0709 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 2857.65,                last time consumption/overall running time: 455.5577s / 168893.6286 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 2842.6,                last time consumption/overall running time: 457.1287s / 169350.7573 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 2874.05,                last time consumption/overall running time: 458.5360s / 169809.2933 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0005
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 2815.25,                last time consumption/overall running time: 457.0755s / 170266.3689 s
env0_first_0:                 episode reward: -0.3500,                 loss: nan
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 2848.35,                last time consumption/overall running time: 477.2156s / 170743.5844 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 2852.25,                last time consumption/overall running time: 467.0347s / 171210.6191 s
env0_first_0:                 episode reward: 1.1000,                 loss: nan
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0005
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 2838.55,                last time consumption/overall running time: 461.6934s / 171672.3125 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 2851.95,                last time consumption/overall running time: 459.8703s / 172132.1828 s
env0_first_0:                 episode reward: 0.3000,                 loss: nan
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0004
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 2849.75,                last time consumption/overall running time: 456.8621s / 172589.0449 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0005
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 2859.15,                last time consumption/overall running time: 450.2143s / 173039.2592 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 2862.4,                last time consumption/overall running time: 449.4664s / 173488.7256 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 2874.85,                last time consumption/overall running time: 469.4763s / 173958.2019 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0006
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 2889.1,                last time consumption/overall running time: 457.9397s / 174416.1415 s
env0_first_0:                 episode reward: 0.9500,                 loss: nan
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 2853.05,                last time consumption/overall running time: 442.5439s / 174858.6855 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 2873.65,                last time consumption/overall running time: 442.9321s / 175301.6176 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 2846.65,                last time consumption/overall running time: 462.3318s / 175763.9493 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 2878.1,                last time consumption/overall running time: 475.7322s / 176239.6816 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0006
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 2894.95,                last time consumption/overall running time: 488.9334s / 176728.6150 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 2876.0,                last time consumption/overall running time: 478.8280s / 177207.4429 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 2811.7,                last time consumption/overall running time: 465.6122s / 177673.0551 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 2858.95,                last time consumption/overall running time: 455.2513s / 178128.3064 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 2832.2,                last time consumption/overall running time: 455.0001s / 178583.3065 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0005
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 2826.35,                last time consumption/overall running time: 444.2815s / 179027.5880 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 2855.25,                last time consumption/overall running time: 449.6051s / 179477.1931 s
env0_first_0:                 episode reward: -0.4000,                 loss: nan
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 2834.4,                last time consumption/overall running time: 452.8677s / 179930.0608 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 2853.95,                last time consumption/overall running time: 474.7278s / 180404.7886 s
env0_first_0:                 episode reward: 1.4000,                 loss: nan
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 2862.7,                last time consumption/overall running time: 478.3786s / 180883.1672 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 2850.95,                last time consumption/overall running time: 469.8485s / 181353.0156 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 2844.8,                last time consumption/overall running time: 456.6770s / 181809.6926 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 2859.7,                last time consumption/overall running time: 458.3491s / 182268.0417 s
env0_first_0:                 episode reward: 1.1000,                 loss: nan
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0005
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 2838.05,                last time consumption/overall running time: 471.3389s / 182739.3806 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 2801.2,                last time consumption/overall running time: 470.6147s / 183209.9953 s
env0_first_0:                 episode reward: 0.1000,                 loss: nan
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 2870.2,                last time consumption/overall running time: 476.9063s / 183686.9016 s
env0_first_0:                 episode reward: 0.2000,                 loss: nan
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0005
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 2820.6,                last time consumption/overall running time: 469.4541s / 184156.3557 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 2844.15,                last time consumption/overall running time: 459.7136s / 184616.0693 s
env0_first_0:                 episode reward: 0.3500,                 loss: nan
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 2842.8,                last time consumption/overall running time: 446.9717s / 185063.0411 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 2863.8,                last time consumption/overall running time: 477.5328s / 185540.5739 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 2871.4,                last time consumption/overall running time: 490.6922s / 186031.2660 s
env0_first_0:                 episode reward: 1.2500,                 loss: nan
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0006
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 2856.45,                last time consumption/overall running time: 478.0769s / 186509.3429 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 2848.9,                last time consumption/overall running time: 491.1703s / 187000.5132 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 2810.6,                last time consumption/overall running time: 478.2168s / 187478.7300 s
env0_first_0:                 episode reward: -0.0500,                 loss: nan
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 2873.15,                last time consumption/overall running time: 480.0289s / 187958.7588 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 2859.05,                last time consumption/overall running time: 487.2259s / 188445.9848 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 2869.15,                last time consumption/overall running time: 467.2755s / 188913.2603 s
env0_first_0:                 episode reward: -0.1500,                 loss: nan
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 2878.4,                last time consumption/overall running time: 469.8751s / 189383.1354 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0006
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 2894.35,                last time consumption/overall running time: 500.3357s / 189883.4711 s
env0_first_0:                 episode reward: 1.8500,                 loss: nan
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0007
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 2880.2,                last time consumption/overall running time: 492.2908s / 190375.7619 s
env0_first_0:                 episode reward: -0.5500,                 loss: nan
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 2847.75,                last time consumption/overall running time: 471.7113s / 190847.4732 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0006
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 2850.65,                last time consumption/overall running time: 461.4799s / 191308.9531 s
env0_first_0:                 episode reward: -0.3500,                 loss: nan
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 2872.3,                last time consumption/overall running time: 469.2324s / 191778.1855 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 2868.9,                last time consumption/overall running time: 481.3250s / 192259.5105 s
env0_first_0:                 episode reward: 1.5000,                 loss: nan
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 2837.8,                last time consumption/overall running time: 473.1465s / 192732.6570 s
env0_first_0:                 episode reward: 0.1000,                 loss: nan
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 2864.1,                last time consumption/overall running time: 485.7894s / 193218.4464 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 2864.25,                last time consumption/overall running time: 479.0448s / 193697.4912 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0005
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 2850.75,                last time consumption/overall running time: 465.6669s / 194163.1581 s
env0_first_0:                 episode reward: -0.0500,                 loss: nan
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 2844.1,                last time consumption/overall running time: 475.1696s / 194638.3277 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 2839.65,                last time consumption/overall running time: 477.9468s / 195116.2745 s
env0_first_0:                 episode reward: 1.1500,                 loss: nan
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 2871.3,                last time consumption/overall running time: 478.5253s / 195594.7998 s
env0_first_0:                 episode reward: 1.0000,                 loss: nan
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0010
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 2852.55,                last time consumption/overall running time: 478.6509s / 196073.4507 s
env0_first_0:                 episode reward: 1.5000,                 loss: nan
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0027
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 2846.2,                last time consumption/overall running time: 460.1903s / 196533.6410 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0019
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 2824.85,                last time consumption/overall running time: 459.8635s / 196993.5045 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0009
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 2835.65,                last time consumption/overall running time: 465.0110s / 197458.5155 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 2824.2,                last time consumption/overall running time: 444.9286s / 197903.4440 s
env0_first_0:                 episode reward: -0.2000,                 loss: nan
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0149
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 2848.6,                last time consumption/overall running time: 484.7535s / 198388.1975 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0422
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 2839.95,                last time consumption/overall running time: 479.3476s / 198867.5451 s
env0_first_0:                 episode reward: 0.7000,                 loss: nan
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0337
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 2829.75,                last time consumption/overall running time: 477.1556s / 199344.7007 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0262
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 2839.25,                last time consumption/overall running time: 471.9783s / 199816.6791 s
env0_first_0:                 episode reward: 0.0000,                 loss: nan
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0097
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 2817.05,                last time consumption/overall running time: 462.1065s / 200278.7856 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0045
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 2848.6,                last time consumption/overall running time: 471.3770s / 200750.1626 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 2828.1,                last time consumption/overall running time: 475.8987s / 201226.0613 s
env0_first_0:                 episode reward: -0.2000,                 loss: nan
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0005
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 2851.1,                last time consumption/overall running time: 483.2925s / 201709.3539 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0006
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 2833.65,                last time consumption/overall running time: 463.3714s / 202172.7252 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0006
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 2889.25,                last time consumption/overall running time: 476.7642s / 202649.4895 s
env0_first_0:                 episode reward: 0.9500,                 loss: nan
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 2860.65,                last time consumption/overall running time: 475.8493s / 203125.3388 s
env0_first_0:                 episode reward: 0.9000,                 loss: nan
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 2844.75,                last time consumption/overall running time: 480.6676s / 203606.0064 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0006
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 2806.0,                last time consumption/overall running time: 479.7680s / 204085.7744 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0006
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 2824.95,                last time consumption/overall running time: 479.6796s / 204565.4540 s
env0_first_0:                 episode reward: 0.4500,                 loss: nan
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0005
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 2876.5,                last time consumption/overall running time: 487.5042s / 205052.9582 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0006
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 2863.05,                last time consumption/overall running time: 479.7629s / 205532.7211 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0006
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 2845.45,                last time consumption/overall running time: 466.3750s / 205999.0960 s
env0_first_0:                 episode reward: 1.3000,                 loss: nan
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 2834.2,                last time consumption/overall running time: 475.7970s / 206474.8930 s
env0_first_0:                 episode reward: 0.4000,                 loss: nan
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0005
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 2862.6,                last time consumption/overall running time: 483.5781s / 206958.4711 s
env0_first_0:                 episode reward: 1.3000,                 loss: nan
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0006
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 2869.65,                last time consumption/overall running time: 480.2132s / 207438.6843 s
env0_first_0:                 episode reward: -0.2500,                 loss: nan
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0006
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 2840.9,                last time consumption/overall running time: 469.4674s / 207908.1518 s
env0_first_0:                 episode reward: -0.0500,                 loss: nan
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 2874.5,                last time consumption/overall running time: 487.0004s / 208395.1522 s
env0_first_0:                 episode reward: 1.7500,                 loss: nan
env0_second_0:                 episode reward: -1.7500,                 loss: 0.0006
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 2804.05,                last time consumption/overall running time: 465.2757s / 208860.4279 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0006
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 2877.0,                last time consumption/overall running time: 458.3895s / 209318.8174 s
env0_first_0:                 episode reward: 0.8500,                 loss: nan
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 2828.25,                last time consumption/overall running time: 435.6561s / 209754.4735 s
env0_first_0:                 episode reward: 0.0000,                 loss: nan
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0007
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 2851.85,                last time consumption/overall running time: 445.9657s / 210200.4392 s
env0_first_0:                 episode reward: -0.2500,                 loss: nan
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 2855.85,                last time consumption/overall running time: 459.6554s / 210660.0946 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0005
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 2845.25,                last time consumption/overall running time: 469.2898s / 211129.3844 s
env0_first_0:                 episode reward: 0.8000,                 loss: nan
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 2876.8,                last time consumption/overall running time: 470.0102s / 211599.3946 s
env0_first_0:                 episode reward: 0.2000,                 loss: nan
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0005
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 2846.0,                last time consumption/overall running time: 454.9754s / 212054.3700 s
env0_first_0:                 episode reward: 0.6500,                 loss: nan
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 2831.4,                last time consumption/overall running time: 479.6416s / 212534.0116 s
env0_first_0:                 episode reward: -0.0500,                 loss: nan
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 2877.0,                last time consumption/overall running time: 501.7669s / 213035.7785 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0006
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 2830.0,                last time consumption/overall running time: 483.8541s / 213519.6326 s
env0_first_0:                 episode reward: -0.2000,                 loss: nan
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0006
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 2849.45,                last time consumption/overall running time: 485.4426s / 214005.0752 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 2833.1,                last time consumption/overall running time: 467.9573s / 214473.0325 s
env0_first_0:                 episode reward: 1.3000,                 loss: nan
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0005
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 2838.75,                last time consumption/overall running time: 464.5897s / 214937.6223 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 2878.6,                last time consumption/overall running time: 505.6931s / 215443.3154 s
env0_first_0:                 episode reward: 0.2500,                 loss: nan
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0005
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 2856.1,                last time consumption/overall running time: 496.8177s / 215940.1331 s
env0_first_0:                 episode reward: 0.2000,                 loss: nan
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 2822.3,                last time consumption/overall running time: 487.1456s / 216427.2787 s
env0_first_0:                 episode reward: 0.5500,                 loss: nan
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0006
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 2828.35,                last time consumption/overall running time: 493.9825s / 216921.2612 s
env0_first_0:                 episode reward: 0.5000,                 loss: nan
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0006
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 2861.6,                last time consumption/overall running time: 495.8516s / 217417.1129 s
env0_first_0:                 episode reward: 0.7500,                 loss: nan
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0006
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 2827.3,                last time consumption/overall running time: 489.1023s / 217906.2151 s
env0_first_0:                 episode reward: 0.6000,                 loss: nan
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0006