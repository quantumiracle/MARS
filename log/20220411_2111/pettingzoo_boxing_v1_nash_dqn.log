pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [23, 24]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=18, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 100000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220411_2111/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220411_2111/pettingzoo_boxing_v1_nash_dqn.
Episode: 1/100000 (0.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 19.5491s / 19.5491 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0075
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/100000 (0.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 664.2355s / 683.7846 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0057
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 41/100000 (0.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 668.9388s / 1352.7234 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0055
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 61/100000 (0.0610%),                 avg. length: 299.0,                last time consumption/overall running time: 666.2164s / 2018.9398 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0053
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 81/100000 (0.0810%),                 avg. length: 299.0,                last time consumption/overall running time: 668.2162s / 2687.1559 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0051
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 101/100000 (0.1010%),                 avg. length: 299.0,                last time consumption/overall running time: 671.1365s / 3358.2925 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0049
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 121/100000 (0.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 673.2477s / 4031.5402 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0056
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 141/100000 (0.1410%),                 avg. length: 299.0,                last time consumption/overall running time: 673.1387s / 4704.6788 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0051
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 161/100000 (0.1610%),                 avg. length: 299.0,                last time consumption/overall running time: 675.8291s / 5380.5079 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0047
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 181/100000 (0.1810%),                 avg. length: 299.0,                last time consumption/overall running time: 677.6502s / 6058.1581 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0045
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 201/100000 (0.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 682.5734s / 6740.7315 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0043
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 221/100000 (0.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 681.2989s / 7422.0304 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 241/100000 (0.2410%),                 avg. length: 299.0,                last time consumption/overall running time: 683.2412s / 8105.2716 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0046
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 261/100000 (0.2610%),                 avg. length: 299.0,                last time consumption/overall running time: 686.7988s / 8792.0704 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0040
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 281/100000 (0.2810%),                 avg. length: 299.0,                last time consumption/overall running time: 687.8127s / 9479.8831 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0043
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 301/100000 (0.3010%),                 avg. length: 299.0,                last time consumption/overall running time: 689.8788s / 10169.7619 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0040
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 321/100000 (0.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 692.5312s / 10862.2931 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0041
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 341/100000 (0.3410%),                 avg. length: 299.0,                last time consumption/overall running time: 693.9103s / 11556.2034 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0039
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 361/100000 (0.3610%),                 avg. length: 299.0,                last time consumption/overall running time: 697.8578s / 12254.0612 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 381/100000 (0.3810%),                 avg. length: 299.0,                last time consumption/overall running time: 699.5941s / 12953.6552 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0038
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 401/100000 (0.4010%),                 avg. length: 299.0,                last time consumption/overall running time: 699.8019s / 13653.4571 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0037
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 421/100000 (0.4210%),                 avg. length: 299.0,                last time consumption/overall running time: 696.3536s / 14349.8107 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0041
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 441/100000 (0.4410%),                 avg. length: 299.0,                last time consumption/overall running time: 696.1461s / 15045.9568 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0043
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 461/100000 (0.4610%),                 avg. length: 299.0,                last time consumption/overall running time: 694.9717s / 15740.9285 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0045
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 481/100000 (0.4810%),                 avg. length: 299.0,                last time consumption/overall running time: 697.0671s / 16437.9956 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0045
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 501/100000 (0.5010%),                 avg. length: 299.0,                last time consumption/overall running time: 695.4407s / 17133.4363 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0047
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 521/100000 (0.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 696.5337s / 17829.9700 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0045
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 541/100000 (0.5410%),                 avg. length: 299.0,                last time consumption/overall running time: 714.8529s / 18544.8229 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0045
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 561/100000 (0.5610%),                 avg. length: 299.0,                last time consumption/overall running time: 698.1284s / 19242.9513 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0047
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 581/100000 (0.5810%),                 avg. length: 299.0,                last time consumption/overall running time: 696.1163s / 19939.0676 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0048
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 601/100000 (0.6010%),                 avg. length: 299.0,                last time consumption/overall running time: 698.4276s / 20637.4952 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0046
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 621/100000 (0.6210%),                 avg. length: 299.0,                last time consumption/overall running time: 699.2305s / 21336.7257 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0047
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 641/100000 (0.6410%),                 avg. length: 299.0,                last time consumption/overall running time: 702.6499s / 22039.3756 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0049
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 661/100000 (0.6610%),                 avg. length: 299.0,                last time consumption/overall running time: 699.8647s / 22739.2402 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0052
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 681/100000 (0.6810%),                 avg. length: 299.0,                last time consumption/overall running time: 697.8328s / 23437.0731 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0056
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 701/100000 (0.7010%),                 avg. length: 299.0,                last time consumption/overall running time: 699.4274s / 24136.5005 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 721/100000 (0.7210%),                 avg. length: 299.0,                last time consumption/overall running time: 699.5434s / 24836.0438 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0057
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 741/100000 (0.7410%),                 avg. length: 299.0,                last time consumption/overall running time: 696.5922s / 25532.6360 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 761/100000 (0.7610%),                 avg. length: 299.0,                last time consumption/overall running time: 696.1098s / 26228.7458 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0065
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 781/100000 (0.7810%),                 avg. length: 299.0,                last time consumption/overall running time: 694.1297s / 26922.8754 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0081
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 801/100000 (0.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 693.8324s / 27616.7079 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0084
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 821/100000 (0.8210%),                 avg. length: 299.0,                last time consumption/overall running time: 691.2126s / 28307.9205 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0089
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 841/100000 (0.8410%),                 avg. length: 299.0,                last time consumption/overall running time: 688.3198s / 28996.2402 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0091
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 861/100000 (0.8610%),                 avg. length: 299.0,                last time consumption/overall running time: 687.7439s / 29683.9841 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 881/100000 (0.8810%),                 avg. length: 299.0,                last time consumption/overall running time: 687.7280s / 30371.7122 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0101
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 901/100000 (0.9010%),                 avg. length: 299.0,                last time consumption/overall running time: 682.3066s / 31054.0188 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0097
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 921/100000 (0.9210%),                 avg. length: 299.0,                last time consumption/overall running time: 685.8487s / 31739.8675 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0114
env0_second_0:                 episode reward: 3.2000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 941/100000 (0.9410%),                 avg. length: 299.0,                last time consumption/overall running time: 684.5558s / 32424.4233 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0125
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 961/100000 (0.9610%),                 avg. length: 299.0,                last time consumption/overall running time: 681.9032s / 33106.3265 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 981/100000 (0.9810%),                 avg. length: 299.0,                last time consumption/overall running time: 681.0539s / 33787.3805 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0126
env0_second_0:                 episode reward: 2.1000,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1001/100000 (1.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 681.3923s / 34468.7728 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0139
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 1021/100000 (1.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 682.9087s / 35151.6815 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0153
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1041/100000 (1.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 683.2740s / 35834.9555 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0178
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1061/100000 (1.0610%),                 avg. length: 299.0,                last time consumption/overall running time: 680.4343s / 36515.3898 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0180
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1081/100000 (1.0810%),                 avg. length: 299.0,                last time consumption/overall running time: 682.1625s / 37197.5522 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0178
env0_second_0:                 episode reward: 2.7000,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 1101/100000 (1.1010%),                 avg. length: 299.0,                last time consumption/overall running time: 678.9066s / 37876.4588 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0218
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1121/100000 (1.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 677.8870s / 38554.3458 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0210
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1141/100000 (1.1410%),                 avg. length: 299.0,                last time consumption/overall running time: 678.0190s / 39232.3648 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0231
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 1161/100000 (1.1610%),                 avg. length: 299.0,                last time consumption/overall running time: 677.3238s / 39909.6886 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0250
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1181/100000 (1.1810%),                 avg. length: 299.0,                last time consumption/overall running time: 677.1001s / 40586.7887 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0232
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1201/100000 (1.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 678.6645s / 41265.4532 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0237
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1221/100000 (1.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 679.4741s / 41944.9273 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0278
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1241/100000 (1.2410%),                 avg. length: 299.0,                last time consumption/overall running time: 677.0388s / 42621.9661 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0275
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 1261/100000 (1.2610%),                 avg. length: 299.0,                last time consumption/overall running time: 678.3770s / 43300.3431 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0265
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 1281/100000 (1.2810%),                 avg. length: 299.0,                last time consumption/overall running time: 681.9331s / 43982.2762 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0247
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1301/100000 (1.3010%),                 avg. length: 299.0,                last time consumption/overall running time: 679.4388s / 44661.7150 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0307
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 1321/100000 (1.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 673.6735s / 45335.3884 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0356
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1341/100000 (1.3410%),                 avg. length: 299.0,                last time consumption/overall running time: 679.8260s / 46015.2144 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0299
env0_second_0:                 episode reward: 3.1000,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1361/100000 (1.3610%),                 avg. length: 299.0,                last time consumption/overall running time: 676.2269s / 46691.4413 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0343
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1381/100000 (1.3810%),                 avg. length: 299.0,                last time consumption/overall running time: 673.3968s / 47364.8381 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0391
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1401/100000 (1.4010%),                 avg. length: 299.0,                last time consumption/overall running time: 675.9460s / 48040.7840 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0359
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 1421/100000 (1.4210%),                 avg. length: 299.0,                last time consumption/overall running time: 674.3285s / 48715.1126 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0414
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1441/100000 (1.4410%),                 avg. length: 299.0,                last time consumption/overall running time: 675.3829s / 49390.4955 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0420
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1461/100000 (1.4610%),                 avg. length: 299.0,                last time consumption/overall running time: 673.4917s / 50063.9872 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0445
env0_second_0:                 episode reward: 2.8500,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 1481/100000 (1.4810%),                 avg. length: 299.0,                last time consumption/overall running time: 671.6285s / 50735.6156 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0499
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1501/100000 (1.5010%),                 avg. length: 299.0,                last time consumption/overall running time: 670.0056s / 51405.6213 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0504
env0_second_0:                 episode reward: 1.6000,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 1521/100000 (1.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 672.2063s / 52077.8276 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0518
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 1541/100000 (1.5410%),                 avg. length: 299.0,                last time consumption/overall running time: 672.4571s / 52750.2847 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.0532
env0_second_0:                 episode reward: 5.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1561/100000 (1.5610%),                 avg. length: 299.0,                last time consumption/overall running time: 672.6415s / 53422.9262 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0516
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 1581/100000 (1.5810%),                 avg. length: 299.0,                last time consumption/overall running time: 670.7987s / 54093.7249 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0555
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 1601/100000 (1.6010%),                 avg. length: 299.0,                last time consumption/overall running time: 669.5958s / 54763.3206 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0596
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 1621/100000 (1.6210%),                 avg. length: 299.0,                last time consumption/overall running time: 669.1553s / 55432.4759 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0572
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1641/100000 (1.6410%),                 avg. length: 299.0,                last time consumption/overall running time: 672.2682s / 56104.7441 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0552
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1661/100000 (1.6610%),                 avg. length: 299.0,                last time consumption/overall running time: 669.6773s / 56774.4215 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0626
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 1681/100000 (1.6810%),                 avg. length: 299.0,                last time consumption/overall running time: 670.3733s / 57444.7948 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0658
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1701/100000 (1.7010%),                 avg. length: 299.0,                last time consumption/overall running time: 671.6862s / 58116.4810 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0625
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 1721/100000 (1.7210%),                 avg. length: 299.0,                last time consumption/overall running time: 675.0577s / 58791.5386 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0644
env0_second_0:                 episode reward: 2.2000,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 1741/100000 (1.7410%),                 avg. length: 299.0,                last time consumption/overall running time: 666.7153s / 59458.2540 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0755
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1761/100000 (1.7610%),                 avg. length: 299.0,                last time consumption/overall running time: 665.4814s / 60123.7353 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0778
env0_second_0:                 episode reward: 4.0000,                 loss: nan
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 1781/100000 (1.7810%),                 avg. length: 299.0,                last time consumption/overall running time: 668.9350s / 60792.6703 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0749
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1801/100000 (1.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 665.4969s / 61458.1672 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0834
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 1821/100000 (1.8210%),                 avg. length: 299.0,                last time consumption/overall running time: 665.9020s / 62124.0692 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0914
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 1841/100000 (1.8410%),                 avg. length: 299.0,                last time consumption/overall running time: 665.6133s / 62789.6825 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0948
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 1861/100000 (1.8610%),                 avg. length: 299.0,                last time consumption/overall running time: 669.2458s / 63458.9283 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0931
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 1881/100000 (1.8810%),                 avg. length: 299.0,                last time consumption/overall running time: 666.9719s / 64125.9002 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0945
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1901/100000 (1.9010%),                 avg. length: 299.0,                last time consumption/overall running time: 667.6629s / 64793.5632 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0992
env0_second_0:                 episode reward: 5.3000,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 1921/100000 (1.9210%),                 avg. length: 299.0,                last time consumption/overall running time: 668.5033s / 65462.0665 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0888
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 1941/100000 (1.9410%),                 avg. length: 299.0,                last time consumption/overall running time: 664.1730s / 66126.2395 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0984
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1961/100000 (1.9610%),                 avg. length: 299.0,                last time consumption/overall running time: 665.3827s / 66791.6222 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.1005
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1981/100000 (1.9810%),                 avg. length: 299.0,                last time consumption/overall running time: 669.2183s / 67460.8405 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0963
env0_second_0:                 episode reward: 4.9500,                 loss: nan
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 2001/100000 (2.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 665.7382s / 68126.5787 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0991
env0_second_0:                 episode reward: 2.4000,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 2021/100000 (2.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 668.1762s / 68794.7550 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.1074
env0_second_0:                 episode reward: 1.8500,                 loss: nan
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 2041/100000 (2.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 667.7306s / 69462.4856 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0997
env0_second_0:                 episode reward: 4.5500,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 2061/100000 (2.0610%),                 avg. length: 299.0,                last time consumption/overall running time: 667.5048s / 70129.9904 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0897
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2081/100000 (2.0810%),                 avg. length: 299.0,                last time consumption/overall running time: 668.5378s / 70798.5282 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0935
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2101/100000 (2.1010%),                 avg. length: 299.0,                last time consumption/overall running time: 704.1090s / 71502.6372 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0982
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 2121/100000 (2.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 800.8544s / 72303.4917 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1026
env0_second_0:                 episode reward: 3.7000,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2141/100000 (2.1410%),                 avg. length: 299.0,                last time consumption/overall running time: 799.1975s / 73102.6892 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.1064
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 2161/100000 (2.1610%),                 avg. length: 299.0,                last time consumption/overall running time: 798.4671s / 73901.1563 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1131
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 2181/100000 (2.1810%),                 avg. length: 299.0,                last time consumption/overall running time: 801.6281s / 74702.7844 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.1215
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 2201/100000 (2.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 800.6541s / 75503.4385 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1170
env0_second_0:                 episode reward: 3.6000,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 2221/100000 (2.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 796.9521s / 76300.3906 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.1316
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 2241/100000 (2.2410%),                 avg. length: 299.0,                last time consumption/overall running time: 799.2523s / 77099.6429 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.1331
env0_second_0:                 episode reward: 4.6000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2261/100000 (2.2610%),                 avg. length: 299.0,                last time consumption/overall running time: 794.0730s / 77893.7159 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.1413
env0_second_0:                 episode reward: 2.2500,                 loss: nan
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 2281/100000 (2.2810%),                 avg. length: 299.0,                last time consumption/overall running time: 794.7573s / 78688.4732 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.1506
env0_second_0:                 episode reward: 3.0000,                 loss: nan
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 2301/100000 (2.3010%),                 avg. length: 299.0,                last time consumption/overall running time: 790.4728s / 79478.9460 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.1482
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 2321/100000 (2.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 793.9300s / 80272.8760 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.1389
env0_second_0:                 episode reward: 2.6500,                 loss: nan
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 2341/100000 (2.3410%),                 avg. length: 299.0,                last time consumption/overall running time: 793.9601s / 81066.8361 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1387
env0_second_0:                 episode reward: 4.2500,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 2361/100000 (2.3610%),                 avg. length: 299.0,                last time consumption/overall running time: 788.5058s / 81855.3419 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.1505
env0_second_0:                 episode reward: 2.1500,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 2381/100000 (2.3810%),                 avg. length: 299.0,                last time consumption/overall running time: 791.3727s / 82646.7146 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.1467
env0_second_0:                 episode reward: 1.3000,                 loss: nan
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 2401/100000 (2.4010%),                 avg. length: 299.0,                last time consumption/overall running time: 788.3198s / 83435.0344 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1558
env0_second_0:                 episode reward: 4.1500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2421/100000 (2.4210%),                 avg. length: 299.0,                last time consumption/overall running time: 789.0962s / 84224.1305 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.1597
env0_second_0:                 episode reward: 3.1500,                 loss: nan
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 2441/100000 (2.4410%),                 avg. length: 299.0,                last time consumption/overall running time: 789.3926s / 85013.5231 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1688
env0_second_0:                 episode reward: 3.5000,                 loss: nan
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 2461/100000 (2.4610%),                 avg. length: 299.0,                last time consumption/overall running time: 786.8208s / 85800.3440 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1770
env0_second_0:                 episode reward: 3.8500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2481/100000 (2.4810%),                 avg. length: 299.0,                last time consumption/overall running time: 787.3988s / 86587.7428 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.1865
env0_second_0:                 episode reward: 5.7500,                 loss: nan
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 2501/100000 (2.5010%),                 avg. length: 299.0,                last time consumption/overall running time: 789.3431s / 87377.0859 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.1714
env0_second_0:                 episode reward: 4.5500,                 loss: nan
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 2521/100000 (2.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 786.2820s / 88163.3679 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1805
env0_second_0:                 episode reward: 3.5500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2541/100000 (2.5410%),                 avg. length: 299.0,                last time consumption/overall running time: 786.5807s / 88949.9486 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.1882
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 2561/100000 (2.5610%),                 avg. length: 299.0,                last time consumption/overall running time: 786.1874s / 89736.1361 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.1910
env0_second_0:                 episode reward: 8.6500,                 loss: nan
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 2581/100000 (2.5810%),                 avg. length: 299.0,                last time consumption/overall running time: 786.4242s / 90522.5603 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.2087
env0_second_0:                 episode reward: 6.7500,                 loss: nan
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 2601/100000 (2.6010%),                 avg. length: 299.0,                last time consumption/overall running time: 783.2056s / 91305.7658 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.2412
env0_second_0:                 episode reward: 5.5500,                 loss: nan
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 2621/100000 (2.6210%),                 avg. length: 299.0,                last time consumption/overall running time: 790.2523s / 92096.0181 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2419
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 2641/100000 (2.6410%),                 avg. length: 299.0,                last time consumption/overall running time: 788.5490s / 92884.5671 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.2499
env0_second_0:                 episode reward: 9.0000,                 loss: nan
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 2661/100000 (2.6610%),                 avg. length: 299.0,                last time consumption/overall running time: 785.1628s / 93669.7299 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.2390
env0_second_0:                 episode reward: 3.9000,                 loss: nan
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 2681/100000 (2.6810%),                 avg. length: 299.0,                last time consumption/overall running time: 787.5350s / 94457.2649 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.2342
env0_second_0:                 episode reward: 3.4500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2701/100000 (2.7010%),                 avg. length: 299.0,                last time consumption/overall running time: 784.4744s / 95241.7394 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.2447
env0_second_0:                 episode reward: 7.6000,                 loss: nan
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 2721/100000 (2.7210%),                 avg. length: 299.0,                last time consumption/overall running time: 782.9561s / 96024.6955 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.2532
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 2741/100000 (2.7410%),                 avg. length: 299.0,                last time consumption/overall running time: 783.4734s / 96808.1688 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.2585
env0_second_0:                 episode reward: 6.5500,                 loss: nan
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 2761/100000 (2.7610%),                 avg. length: 299.0,                last time consumption/overall running time: 786.6424s / 97594.8112 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.2557
env0_second_0:                 episode reward: 3.4500,                 loss: nan
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 2781/100000 (2.7810%),                 avg. length: 299.0,                last time consumption/overall running time: 786.0422s / 98380.8534 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.2717
env0_second_0:                 episode reward: 5.0000,                 loss: nan
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 2801/100000 (2.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 787.0850s / 99167.9384 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.2685
env0_second_0:                 episode reward: 5.1500,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 2821/100000 (2.8210%),                 avg. length: 299.0,                last time consumption/overall running time: 785.5905s / 99953.5289 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2820
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 2841/100000 (2.8410%),                 avg. length: 299.0,                last time consumption/overall running time: 788.3619s / 100741.8908 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.2802
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2861/100000 (2.8610%),                 avg. length: 299.0,                last time consumption/overall running time: 784.9486s / 101526.8393 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.2953
env0_second_0:                 episode reward: 4.3500,                 loss: nan
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 2881/100000 (2.8810%),                 avg. length: 299.0,                last time consumption/overall running time: 783.4323s / 102310.2716 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.3220
env0_second_0:                 episode reward: 7.4500,                 loss: nan
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 2901/100000 (2.9010%),                 avg. length: 299.0,                last time consumption/overall running time: 785.0184s / 103095.2900 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.3299
env0_second_0:                 episode reward: 5.2000,                 loss: nan
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 2921/100000 (2.9210%),                 avg. length: 299.0,                last time consumption/overall running time: 783.6138s / 103878.9038 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3149
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 2941/100000 (2.9410%),                 avg. length: 299.0,                last time consumption/overall running time: 787.5805s / 104666.4843 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.3251
env0_second_0:                 episode reward: 6.4000,                 loss: nan
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 2961/100000 (2.9610%),                 avg. length: 299.0,                last time consumption/overall running time: 784.3030s / 105450.7873 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3597
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 2981/100000 (2.9810%),                 avg. length: 299.0,                last time consumption/overall running time: 783.5241s / 106234.3114 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.3806
env0_second_0:                 episode reward: 3.3500,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 3001/100000 (3.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 785.7431s / 107020.0545 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.3918
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 3021/100000 (3.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 783.8112s / 107803.8657 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.4234
env0_second_0:                 episode reward: 7.9500,                 loss: nan
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 3041/100000 (3.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 781.0122s / 108584.8779 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.4348
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 3061/100000 (3.0610%),                 avg. length: 299.0,                last time consumption/overall running time: 784.5711s / 109369.4490 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.4423
env0_second_0:                 episode reward: 9.1500,                 loss: nan
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 3081/100000 (3.0810%),                 avg. length: 299.0,                last time consumption/overall running time: 781.7268s / 110151.1758 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.4984
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 3101/100000 (3.1010%),                 avg. length: 299.0,                last time consumption/overall running time: 787.9659s / 110939.1417 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.5012
env0_second_0:                 episode reward: 3.3500,                 loss: nan
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 3121/100000 (3.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 784.6032s / 111723.7449 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.5286
env0_second_0:                 episode reward: 6.9500,                 loss: nan
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 3141/100000 (3.1410%),                 avg. length: 299.0,                last time consumption/overall running time: 787.3032s / 112511.0481 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.5269
env0_second_0:                 episode reward: 5.0500,                 loss: nan
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 3161/100000 (3.1610%),                 avg. length: 299.0,                last time consumption/overall running time: 783.9076s / 113294.9557 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.5589
env0_second_0:                 episode reward: 7.4000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 3181/100000 (3.1810%),                 avg. length: 299.0,                last time consumption/overall running time: 783.6343s / 114078.5900 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.5748
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 3201/100000 (3.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 786.3278s / 114864.9178 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.5735
env0_second_0:                 episode reward: 6.7000,                 loss: nan
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 3221/100000 (3.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 784.0666s / 115648.9844 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.6061
env0_second_0:                 episode reward: 6.0000,                 loss: nan
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 3241/100000 (3.2410%),                 avg. length: 299.0,                last time consumption/overall running time: 782.6363s / 116431.6207 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.6072
env0_second_0:                 episode reward: 9.6500,                 loss: nan
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 3261/100000 (3.2610%),                 avg. length: 299.0,                last time consumption/overall running time: 783.8640s / 117215.4847 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.6737
env0_second_0:                 episode reward: 10.8500,                 loss: nan
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 3281/100000 (3.2810%),                 avg. length: 299.0,                last time consumption/overall running time: 781.6251s / 117997.1098 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.7348
env0_second_0:                 episode reward: 8.2000,                 loss: nan
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 3301/100000 (3.3010%),                 avg. length: 299.0,                last time consumption/overall running time: 782.3293s / 118779.4391 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.7468
env0_second_0:                 episode reward: 11.7000,                 loss: nan
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 3321/100000 (3.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 781.5024s / 119560.9414 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.7770
env0_second_0:                 episode reward: 10.2500,                 loss: nan
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 3341/100000 (3.3410%),                 avg. length: 299.0,                last time consumption/overall running time: 775.4719s / 120336.4134 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.8102
env0_second_0:                 episode reward: 5.1500,                 loss: nan
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 3361/100000 (3.3610%),                 avg. length: 299.0,                last time consumption/overall running time: 777.2520s / 121113.6654 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.8589
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 3381/100000 (3.3810%),                 avg. length: 299.0,                last time consumption/overall running time: 767.0782s / 121880.7435 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.9196
env0_second_0:                 episode reward: 6.1500,                 loss: nan
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 3401/100000 (3.4010%),                 avg. length: 299.0,                last time consumption/overall running time: 765.9312s / 122646.6747 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.9686
env0_second_0:                 episode reward: 7.1000,                 loss: nan
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 3421/100000 (3.4210%),                 avg. length: 299.0,                last time consumption/overall running time: 765.9081s / 123412.5828 s
env0_first_0:                 episode reward: -5.5000,                 loss: 1.0063
env0_second_0:                 episode reward: 5.5000,                 loss: nan
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 3441/100000 (3.4410%),                 avg. length: 299.0,                last time consumption/overall running time: 770.3686s / 124182.9514 s
env0_first_0:                 episode reward: -8.3000,                 loss: 1.0007
env0_second_0:                 episode reward: 8.3000,                 loss: nan
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 3461/100000 (3.4610%),                 avg. length: 299.0,                last time consumption/overall running time: 769.9002s / 124952.8516 s
env0_first_0:                 episode reward: -5.7000,                 loss: 1.0527
env0_second_0:                 episode reward: 5.7000,                 loss: nan
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 3481/100000 (3.4810%),                 avg. length: 299.0,                last time consumption/overall running time: 765.6006s / 125718.4521 s
env0_first_0:                 episode reward: -7.1000,                 loss: 1.0952
env0_second_0:                 episode reward: 7.1000,                 loss: nan
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 3501/100000 (3.5010%),                 avg. length: 299.0,                last time consumption/overall running time: 765.7001s / 126484.1523 s
env0_first_0:                 episode reward: -2.3000,                 loss: 1.2487
env0_second_0:                 episode reward: 2.3000,                 loss: nan
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 3521/100000 (3.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 763.4012s / 127247.5534 s
env0_first_0:                 episode reward: -10.1500,                 loss: 1.3060
env0_second_0:                 episode reward: 10.1500,                 loss: nan
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 3541/100000 (3.5410%),                 avg. length: 299.0,                last time consumption/overall running time: 763.7316s / 128011.2850 s
env0_first_0:                 episode reward: -7.9000,                 loss: 1.2280
env0_second_0:                 episode reward: 7.9000,                 loss: nan
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 3561/100000 (3.5610%),                 avg. length: 299.0,                last time consumption/overall running time: 761.7536s / 128773.0387 s
env0_first_0:                 episode reward: -7.1000,                 loss: 1.3028
env0_second_0:                 episode reward: 7.1000,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 3581/100000 (3.5810%),                 avg. length: 299.0,                last time consumption/overall running time: 757.4409s / 129530.4796 s
env0_first_0:                 episode reward: -13.9000,                 loss: 1.3219
env0_second_0:                 episode reward: 13.9000,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 3601/100000 (3.6010%),                 avg. length: 299.0,                last time consumption/overall running time: 761.4593s / 130291.9389 s
env0_first_0:                 episode reward: -8.4500,                 loss: 1.3568
env0_second_0:                 episode reward: 8.4500,                 loss: nan
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 3621/100000 (3.6210%),                 avg. length: 299.0,                last time consumption/overall running time: 763.8220s / 131055.7608 s
env0_first_0:                 episode reward: -10.2000,                 loss: 1.4162
env0_second_0:                 episode reward: 10.2000,                 loss: nan
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 3641/100000 (3.6410%),                 avg. length: 299.0,                last time consumption/overall running time: 762.0807s / 131817.8415 s
env0_first_0:                 episode reward: -3.1000,                 loss: 1.4003
env0_second_0:                 episode reward: 3.1000,                 loss: nan
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 3661/100000 (3.6610%),                 avg. length: 299.0,                last time consumption/overall running time: 760.0675s / 132577.9090 s
env0_first_0:                 episode reward: -12.0500,                 loss: 1.4502
env0_second_0:                 episode reward: 12.0500,                 loss: nan
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 3681/100000 (3.6810%),                 avg. length: 299.0,                last time consumption/overall running time: 763.4863s / 133341.3953 s
env0_first_0:                 episode reward: -7.3500,                 loss: 1.4113
env0_second_0:                 episode reward: 7.3500,                 loss: nan
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 3701/100000 (3.7010%),                 avg. length: 299.0,                last time consumption/overall running time: 764.4656s / 134105.8609 s
env0_first_0:                 episode reward: -6.0000,                 loss: 1.3520
env0_second_0:                 episode reward: 6.0000,                 loss: nan
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 3721/100000 (3.7210%),                 avg. length: 299.0,                last time consumption/overall running time: 760.7378s / 134866.5987 s
env0_first_0:                 episode reward: -6.4000,                 loss: 1.3828
env0_second_0:                 episode reward: 6.4000,                 loss: nan
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 3741/100000 (3.7410%),                 avg. length: 299.0,                last time consumption/overall running time: 755.9583s / 135622.5570 s
env0_first_0:                 episode reward: -11.8500,                 loss: 1.4295
env0_second_0:                 episode reward: 11.8500,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 3761/100000 (3.7610%),                 avg. length: 299.0,                last time consumption/overall running time: 760.5286s / 136383.0856 s
env0_first_0:                 episode reward: -7.7000,                 loss: 1.5066
env0_second_0:                 episode reward: 7.7000,                 loss: nan
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 3781/100000 (3.7810%),                 avg. length: 299.0,                last time consumption/overall running time: 762.2448s / 137145.3304 s
env0_first_0:                 episode reward: -4.2500,                 loss: 1.6531
env0_second_0:                 episode reward: 4.2500,                 loss: nan
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 3801/100000 (3.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 763.0091s / 137908.3394 s
env0_first_0:                 episode reward: -2.9500,                 loss: 1.5891
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 3821/100000 (3.8210%),                 avg. length: 299.0,                last time consumption/overall running time: 762.5213s / 138670.8607 s
env0_first_0:                 episode reward: -2.3000,                 loss: 1.5029
env0_second_0:                 episode reward: 2.3000,                 loss: nan
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 3841/100000 (3.8410%),                 avg. length: 299.0,                last time consumption/overall running time: 761.0216s / 139431.8823 s
env0_first_0:                 episode reward: -7.2000,                 loss: 1.4750
env0_second_0:                 episode reward: 7.2000,                 loss: nan
env1_first_0:                 episode reward: -16.8500,                 loss: nan
env1_second_0:                 episode reward: 16.8500,                 loss: nan
Episode: 3861/100000 (3.8610%),                 avg. length: 299.0,                last time consumption/overall running time: 762.9203s / 140194.8026 s
env0_first_0:                 episode reward: -15.5500,                 loss: 1.4661
env0_second_0:                 episode reward: 15.5500,                 loss: nan
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 3881/100000 (3.8810%),                 avg. length: 299.0,                last time consumption/overall running time: 765.3834s / 140960.1860 s
env0_first_0:                 episode reward: -6.9500,                 loss: 1.5227
env0_second_0:                 episode reward: 6.9500,                 loss: nan
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 3901/100000 (3.9010%),                 avg. length: 299.0,                last time consumption/overall running time: 762.8567s / 141723.0427 s
env0_first_0:                 episode reward: -16.4500,                 loss: 1.5948
env0_second_0:                 episode reward: 16.4500,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 3921/100000 (3.9210%),                 avg. length: 299.0,                last time consumption/overall running time: 762.0198s / 142485.0625 s
env0_first_0:                 episode reward: -4.7500,                 loss: 1.5731
env0_second_0:                 episode reward: 4.7500,                 loss: nan
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 3941/100000 (3.9410%),                 avg. length: 299.0,                last time consumption/overall running time: 764.9148s / 143249.9774 s
env0_first_0:                 episode reward: -12.8500,                 loss: 1.6027
env0_second_0:                 episode reward: 12.8500,                 loss: nan
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 3961/100000 (3.9610%),                 avg. length: 299.0,                last time consumption/overall running time: 762.0342s / 144012.0115 s
env0_first_0:                 episode reward: -13.7500,                 loss: 1.7205
env0_second_0:                 episode reward: 13.7500,                 loss: nan
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 3981/100000 (3.9810%),                 avg. length: 299.0,                last time consumption/overall running time: 764.0801s / 144776.0916 s
env0_first_0:                 episode reward: -12.2500,                 loss: 1.7091
env0_second_0:                 episode reward: 12.2500,                 loss: nan
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 4001/100000 (4.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 759.2600s / 145535.3517 s
env0_first_0:                 episode reward: -11.5000,                 loss: 1.6300
env0_second_0:                 episode reward: 11.5000,                 loss: nan
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 4021/100000 (4.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 758.7134s / 146294.0650 s
env0_first_0:                 episode reward: -7.5000,                 loss: 1.6786
env0_second_0:                 episode reward: 7.5000,                 loss: nan
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 4041/100000 (4.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 763.1293s / 147057.1944 s
env0_first_0:                 episode reward: -11.3000,                 loss: 1.8649
env0_second_0:                 episode reward: 11.3000,                 loss: nan
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 4061/100000 (4.0610%),                 avg. length: 299.0,                last time consumption/overall running time: 761.0487s / 147818.2431 s
env0_first_0:                 episode reward: -10.6000,                 loss: 1.8628
env0_second_0:                 episode reward: 10.6000,                 loss: nan
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 4081/100000 (4.0810%),                 avg. length: 299.0,                last time consumption/overall running time: 763.0902s / 148581.3333 s
env0_first_0:                 episode reward: -16.2000,                 loss: 1.8152
env0_second_0:                 episode reward: 16.2000,                 loss: nan
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 4101/100000 (4.1010%),                 avg. length: 299.0,                last time consumption/overall running time: 760.2673s / 149341.6006 s
env0_first_0:                 episode reward: -9.5500,                 loss: 2.0443
env0_second_0:                 episode reward: 9.5500,                 loss: nan
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 4121/100000 (4.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 763.4998s / 150105.1004 s
env0_first_0:                 episode reward: -9.0000,                 loss: 2.0054
env0_second_0:                 episode reward: 9.0000,                 loss: nan
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 4141/100000 (4.1410%),                 avg. length: 299.0,                last time consumption/overall running time: 764.0897s / 150869.1901 s
env0_first_0:                 episode reward: -2.9500,                 loss: 1.9519
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 4161/100000 (4.1610%),                 avg. length: 299.0,                last time consumption/overall running time: 762.2731s / 151631.4632 s
env0_first_0:                 episode reward: -4.3000,                 loss: 1.9343
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 4181/100000 (4.1810%),                 avg. length: 299.0,                last time consumption/overall running time: 762.4170s / 152393.8801 s
env0_first_0:                 episode reward: -10.7500,                 loss: 1.8355
env0_second_0:                 episode reward: 10.7500,                 loss: nan
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 4201/100000 (4.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 760.9152s / 153154.7953 s
env0_first_0:                 episode reward: -7.0500,                 loss: 1.8921
env0_second_0:                 episode reward: 7.0500,                 loss: nan
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 4221/100000 (4.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 766.3744s / 153921.1697 s
env0_first_0:                 episode reward: -9.2500,                 loss: 2.1021
env0_second_0:                 episode reward: 9.2500,                 loss: nan
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 4241/100000 (4.2410%),                 avg. length: 299.0,                last time consumption/overall running time: 760.2540s / 154681.4237 s
env0_first_0:                 episode reward: -8.9500,                 loss: 2.1852
env0_second_0:                 episode reward: 8.9500,                 loss: nan
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 4261/100000 (4.2610%),                 avg. length: 299.0,                last time consumption/overall running time: 765.4011s / 155446.8249 s
env0_first_0:                 episode reward: -12.2000,                 loss: 2.2551
env0_second_0:                 episode reward: 12.2000,                 loss: nan
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 4281/100000 (4.2810%),                 avg. length: 299.0,                last time consumption/overall running time: 764.0817s / 156210.9066 s
env0_first_0:                 episode reward: -10.9500,                 loss: 2.1927
env0_second_0:                 episode reward: 10.9500,                 loss: nan
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 4301/100000 (4.3010%),                 avg. length: 299.0,                last time consumption/overall running time: 765.2088s / 156976.1153 s
env0_first_0:                 episode reward: -10.2500,                 loss: 2.1700
env0_second_0:                 episode reward: 10.2500,                 loss: nan
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 4321/100000 (4.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 764.1479s / 157740.2632 s
env0_first_0:                 episode reward: -22.4000,                 loss: 2.2517
env0_second_0:                 episode reward: 22.4000,                 loss: nan
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 4341/100000 (4.3410%),                 avg. length: 299.0,                last time consumption/overall running time: 765.1836s / 158505.4468 s
env0_first_0:                 episode reward: -10.1500,                 loss: 2.3316
env0_second_0:                 episode reward: 10.1500,                 loss: nan
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 4361/100000 (4.3610%),                 avg. length: 299.0,                last time consumption/overall running time: 769.3583s / 159274.8051 s
env0_first_0:                 episode reward: -10.9000,                 loss: 2.3691
env0_second_0:                 episode reward: 10.9000,                 loss: nan
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 4381/100000 (4.3810%),                 avg. length: 298.6,                last time consumption/overall running time: 779.8139s / 160054.6190 s
env0_first_0:                 episode reward: -20.4000,                 loss: 2.3472
env0_second_0:                 episode reward: 20.4000,                 loss: nan
env1_first_0:                 episode reward: -17.7000,                 loss: nan
env1_second_0:                 episode reward: 17.7000,                 loss: nan
Episode: 4401/100000 (4.4010%),                 avg. length: 299.0,                last time consumption/overall running time: 780.6448s / 160835.2638 s
env0_first_0:                 episode reward: -19.2000,                 loss: 2.3629
env0_second_0:                 episode reward: 19.2000,                 loss: nan
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 4421/100000 (4.4210%),                 avg. length: 299.0,                last time consumption/overall running time: 782.0184s / 161617.2822 s
env0_first_0:                 episode reward: -18.0000,                 loss: 2.4363
env0_second_0:                 episode reward: 18.0000,                 loss: nan
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 4441/100000 (4.4410%),                 avg. length: 299.0,                last time consumption/overall running time: 778.5323s / 162395.8145 s
env0_first_0:                 episode reward: -18.5000,                 loss: 2.5554
env0_second_0:                 episode reward: 18.5000,                 loss: nan
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 4461/100000 (4.4610%),                 avg. length: 299.0,                last time consumption/overall running time: 780.0281s / 163175.8426 s
env0_first_0:                 episode reward: -11.4500,                 loss: 2.6446
env0_second_0:                 episode reward: 11.4500,                 loss: nan
env1_first_0:                 episode reward: -16.7500,                 loss: nan
env1_second_0:                 episode reward: 16.7500,                 loss: nan
Episode: 4481/100000 (4.4810%),                 avg. length: 297.9,                last time consumption/overall running time: 781.1229s / 163956.9656 s
env0_first_0:                 episode reward: -22.0500,                 loss: 2.6184
env0_second_0:                 episode reward: 22.0500,                 loss: nan
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 4501/100000 (4.5010%),                 avg. length: 299.0,                last time consumption/overall running time: 777.7606s / 164734.7262 s
env0_first_0:                 episode reward: -7.7500,                 loss: 2.6505
env0_second_0:                 episode reward: 7.7500,                 loss: nan
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 4521/100000 (4.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 775.6466s / 165510.3727 s
env0_first_0:                 episode reward: -14.5000,                 loss: 2.7181
env0_second_0:                 episode reward: 14.5000,                 loss: nan
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 4541/100000 (4.5410%),                 avg. length: 299.0,                last time consumption/overall running time: 777.1602s / 166287.5329 s
env0_first_0:                 episode reward: -15.8500,                 loss: 2.8455
env0_second_0:                 episode reward: 15.8500,                 loss: nan
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 4561/100000 (4.5610%),                 avg. length: 299.0,                last time consumption/overall running time: 771.0403s / 167058.5732 s
env0_first_0:                 episode reward: -9.7500,                 loss: 2.9487
env0_second_0:                 episode reward: 9.7500,                 loss: nan
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 4581/100000 (4.5810%),                 avg. length: 299.0,                last time consumption/overall running time: 763.5973s / 167822.1705 s
env0_first_0:                 episode reward: -18.0000,                 loss: 2.9337
env0_second_0:                 episode reward: 18.0000,                 loss: nan
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 4601/100000 (4.6010%),                 avg. length: 299.0,                last time consumption/overall running time: 763.5350s / 168585.7055 s
env0_first_0:                 episode reward: -6.3500,                 loss: 2.9786
env0_second_0:                 episode reward: 6.3500,                 loss: nan
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 4621/100000 (4.6210%),                 avg. length: 299.0,                last time consumption/overall running time: 767.9266s / 169353.6321 s
env0_first_0:                 episode reward: -3.0500,                 loss: 2.8734
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 4641/100000 (4.6410%),                 avg. length: 299.0,                last time consumption/overall running time: 765.9809s / 170119.6131 s
env0_first_0:                 episode reward: -15.5500,                 loss: 2.7389
env0_second_0:                 episode reward: 15.5500,                 loss: nan
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 4661/100000 (4.6610%),                 avg. length: 299.0,                last time consumption/overall running time: 765.6742s / 170885.2873 s
env0_first_0:                 episode reward: -5.2500,                 loss: 2.6412
env0_second_0:                 episode reward: 5.2500,                 loss: nan
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 4681/100000 (4.6810%),                 avg. length: 299.0,                last time consumption/overall running time: 767.3342s / 171652.6214 s
env0_first_0:                 episode reward: -21.5500,                 loss: 2.5869
env0_second_0:                 episode reward: 21.5500,                 loss: nan
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 4701/100000 (4.7010%),                 avg. length: 299.0,                last time consumption/overall running time: 766.6715s / 172419.2929 s
env0_first_0:                 episode reward: -10.8000,                 loss: 2.8331
env0_second_0:                 episode reward: 10.8000,                 loss: nan
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 4721/100000 (4.7210%),                 avg. length: 299.0,                last time consumption/overall running time: 766.1441s / 173185.4370 s
env0_first_0:                 episode reward: -21.4000,                 loss: 2.7617
env0_second_0:                 episode reward: 21.4000,                 loss: nan
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 4741/100000 (4.7410%),                 avg. length: 299.0,                last time consumption/overall running time: 767.2188s / 173952.6559 s
env0_first_0:                 episode reward: -12.1000,                 loss: 2.8092
env0_second_0:                 episode reward: 12.1000,                 loss: nan
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 4761/100000 (4.7610%),                 avg. length: 299.0,                last time consumption/overall running time: 766.6472s / 174719.3031 s
env0_first_0:                 episode reward: -24.8500,                 loss: 2.8810
env0_second_0:                 episode reward: 24.8500,                 loss: nan
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 4781/100000 (4.7810%),                 avg. length: 299.0,                last time consumption/overall running time: 770.9515s / 175490.2546 s
env0_first_0:                 episode reward: -7.5500,                 loss: 2.7770
env0_second_0:                 episode reward: 7.5500,                 loss: nan
env1_first_0:                 episode reward: -20.3500,                 loss: nan
env1_second_0:                 episode reward: 20.3500,                 loss: nan
Episode: 4801/100000 (4.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 769.4168s / 176259.6714 s
env0_first_0:                 episode reward: -7.2000,                 loss: 2.7158
env0_second_0:                 episode reward: 7.2000,                 loss: nan
env1_first_0:                 episode reward: -19.1500,                 loss: nan
env1_second_0:                 episode reward: 19.1500,                 loss: nan
Episode: 4821/100000 (4.8210%),                 avg. length: 299.0,                last time consumption/overall running time: 771.0093s / 177030.6807 s
env0_first_0:                 episode reward: -0.7000,                 loss: 2.8066
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
Episode: 4841/100000 (4.8410%),                 avg. length: 299.0,                last time consumption/overall running time: 767.3596s / 177798.0403 s
env0_first_0:                 episode reward: -11.3000,                 loss: 2.8749
env0_second_0:                 episode reward: 11.3000,                 loss: nan
env1_first_0:                 episode reward: -18.0000,                 loss: nan
env1_second_0:                 episode reward: 18.0000,                 loss: nan
Episode: 4861/100000 (4.8610%),                 avg. length: 299.0,                last time consumption/overall running time: 769.0883s / 178567.1286 s
env0_first_0:                 episode reward: -20.9500,                 loss: 2.9080
env0_second_0:                 episode reward: 20.9500,                 loss: nan
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
Episode: 4881/100000 (4.8810%),                 avg. length: 299.0,                last time consumption/overall running time: 765.7301s / 179332.8587 s
env0_first_0:                 episode reward: -11.8500,                 loss: 3.0794
env0_second_0:                 episode reward: 11.8500,                 loss: nan
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 4901/100000 (4.9010%),                 avg. length: 299.0,                last time consumption/overall running time: 763.2322s / 180096.0909 s
env0_first_0:                 episode reward: -20.5500,                 loss: 3.1137
env0_second_0:                 episode reward: 20.5500,                 loss: nan
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 4921/100000 (4.9210%),                 avg. length: 299.0,                last time consumption/overall running time: 760.6238s / 180856.7147 s
env0_first_0:                 episode reward: -12.4000,                 loss: 2.9986
env0_second_0:                 episode reward: 12.4000,                 loss: nan
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 4941/100000 (4.9410%),                 avg. length: 299.0,                last time consumption/overall running time: 763.4097s / 181620.1244 s
env0_first_0:                 episode reward: -20.4000,                 loss: 3.0197
env0_second_0:                 episode reward: 20.4000,                 loss: nan
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 4961/100000 (4.9610%),                 avg. length: 299.0,                last time consumption/overall running time: 763.1973s / 182383.3216 s
env0_first_0:                 episode reward: -16.3500,                 loss: 3.0448
env0_second_0:                 episode reward: 16.3500,                 loss: nan
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 4981/100000 (4.9810%),                 avg. length: 298.35,                last time consumption/overall running time: 761.0495s / 183144.3711 s
env0_first_0:                 episode reward: -9.9000,                 loss: 3.1106
env0_second_0:                 episode reward: 9.9000,                 loss: nan
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 5001/100000 (5.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 763.3188s / 183907.6900 s
env0_first_0:                 episode reward: -13.4000,                 loss: 3.1297
env0_second_0:                 episode reward: 13.4000,                 loss: nan
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 5021/100000 (5.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 764.2599s / 184671.9499 s
env0_first_0:                 episode reward: -15.7500,                 loss: 3.1361
env0_second_0:                 episode reward: 15.7500,                 loss: nan
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 5041/100000 (5.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 768.9986s / 185440.9485 s
env0_first_0:                 episode reward: -21.6000,                 loss: 3.0175
env0_second_0:                 episode reward: 21.6000,                 loss: nan
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 5061/100000 (5.0610%),                 avg. length: 299.0,                last time consumption/overall running time: 763.4281s / 186204.3766 s
env0_first_0:                 episode reward: -7.4000,                 loss: 3.0747
env0_second_0:                 episode reward: 7.4000,                 loss: nan
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 5081/100000 (5.0810%),                 avg. length: 299.0,                last time consumption/overall running time: 765.6588s / 186970.0354 s
env0_first_0:                 episode reward: -11.6500,                 loss: 3.1092
env0_second_0:                 episode reward: 11.6500,                 loss: nan
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 5101/100000 (5.1010%),                 avg. length: 299.0,                last time consumption/overall running time: 766.8462s / 187736.8815 s
env0_first_0:                 episode reward: -17.7500,                 loss: 3.1602
env0_second_0:                 episode reward: 17.7500,                 loss: nan
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 5121/100000 (5.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 766.3798s / 188503.2614 s
env0_first_0:                 episode reward: -4.2500,                 loss: 3.0726
env0_second_0:                 episode reward: 4.2500,                 loss: nan
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 5141/100000 (5.1410%),                 avg. length: 296.55,                last time consumption/overall running time: 757.5926s / 189260.8540 s
env0_first_0:                 episode reward: -7.3000,                 loss: 3.2183
env0_second_0:                 episode reward: 7.3000,                 loss: nan
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 5161/100000 (5.1610%),                 avg. length: 298.95,                last time consumption/overall running time: 764.7842s / 190025.6381 s
env0_first_0:                 episode reward: -16.4500,                 loss: 3.2342
env0_second_0:                 episode reward: 16.4500,                 loss: nan
env1_first_0:                 episode reward: -27.5500,                 loss: nan
env1_second_0:                 episode reward: 27.5500,                 loss: nan
Episode: 5181/100000 (5.1810%),                 avg. length: 299.0,                last time consumption/overall running time: 764.2752s / 190789.9133 s
env0_first_0:                 episode reward: -8.8500,                 loss: 3.3610
env0_second_0:                 episode reward: 8.8500,                 loss: nan
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 5201/100000 (5.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 766.8277s / 191556.7410 s
env0_first_0:                 episode reward: -18.3500,                 loss: 3.2680
env0_second_0:                 episode reward: 18.3500,                 loss: nan
env1_first_0:                 episode reward: -25.8000,                 loss: nan
env1_second_0:                 episode reward: 25.8000,                 loss: nan
Episode: 5221/100000 (5.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 758.3090s / 192315.0500 s
env0_first_0:                 episode reward: -23.1000,                 loss: 3.2035
env0_second_0:                 episode reward: 23.1000,                 loss: nan
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 5241/100000 (5.2410%),                 avg. length: 299.0,                last time consumption/overall running time: 753.9107s / 193068.9607 s
env0_first_0:                 episode reward: -8.6500,                 loss: 3.0654
env0_second_0:                 episode reward: 8.6500,                 loss: nan
env1_first_0:                 episode reward: -29.2500,                 loss: nan
env1_second_0:                 episode reward: 29.2500,                 loss: nan
Episode: 5261/100000 (5.2610%),                 avg. length: 299.0,                last time consumption/overall running time: 762.9192s / 193831.8799 s
env0_first_0:                 episode reward: -22.1000,                 loss: 3.0437
env0_second_0:                 episode reward: 22.1000,                 loss: nan
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 5281/100000 (5.2810%),                 avg. length: 299.0,                last time consumption/overall running time: 768.8420s / 194600.7219 s
env0_first_0:                 episode reward: -13.4000,                 loss: 3.0957
env0_second_0:                 episode reward: 13.4000,                 loss: nan
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 5301/100000 (5.3010%),                 avg. length: 299.0,                last time consumption/overall running time: 764.0857s / 195364.8076 s
env0_first_0:                 episode reward: -10.8500,                 loss: 3.1083
env0_second_0:                 episode reward: 10.8500,                 loss: nan
env1_first_0:                 episode reward: -28.0000,                 loss: nan
env1_second_0:                 episode reward: 28.0000,                 loss: nan
Episode: 5321/100000 (5.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 769.2869s / 196134.0945 s
env0_first_0:                 episode reward: -9.0000,                 loss: 3.1958
env0_second_0:                 episode reward: 9.0000,                 loss: nan
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 5341/100000 (5.3410%),                 avg. length: 299.0,                last time consumption/overall running time: 769.5370s / 196903.6315 s
env0_first_0:                 episode reward: -25.9500,                 loss: 3.3044
env0_second_0:                 episode reward: 25.9500,                 loss: nan
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 5361/100000 (5.3610%),                 avg. length: 299.0,                last time consumption/overall running time: 765.6996s / 197669.3311 s
env0_first_0:                 episode reward: -16.2000,                 loss: 3.5372
env0_second_0:                 episode reward: 16.2000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5381/100000 (5.3810%),                 avg. length: 299.0,                last time consumption/overall running time: 768.4698s / 198437.8009 s
env0_first_0:                 episode reward: -21.3000,                 loss: 3.5739
env0_second_0:                 episode reward: 21.3000,                 loss: nan
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 5401/100000 (5.4010%),                 avg. length: 299.0,                last time consumption/overall running time: 769.3078s / 199207.1087 s
env0_first_0:                 episode reward: -17.1500,                 loss: 3.4538
env0_second_0:                 episode reward: 17.1500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 5421/100000 (5.4210%),                 avg. length: 299.0,                last time consumption/overall running time: 769.7472s / 199976.8559 s
env0_first_0:                 episode reward: -28.7000,                 loss: 3.5936
env0_second_0:                 episode reward: 28.7000,                 loss: nan
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 5441/100000 (5.4410%),                 avg. length: 299.0,                last time consumption/overall running time: 767.5354s / 200744.3913 s
env0_first_0:                 episode reward: -8.7500,                 loss: 3.5942
env0_second_0:                 episode reward: 8.7500,                 loss: nan
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 5461/100000 (5.4610%),                 avg. length: 299.0,                last time consumption/overall running time: 765.2875s / 201509.6788 s
env0_first_0:                 episode reward: -15.5000,                 loss: 3.5085
env0_second_0:                 episode reward: 15.5000,                 loss: nan
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 5481/100000 (5.4810%),                 avg. length: 299.0,                last time consumption/overall running time: 764.5355s / 202274.2143 s
env0_first_0:                 episode reward: -15.9000,                 loss: 3.7464
env0_second_0:                 episode reward: 15.9000,                 loss: nan
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 5501/100000 (5.5010%),                 avg. length: 299.0,                last time consumption/overall running time: 765.3318s / 203039.5460 s
env0_first_0:                 episode reward: -11.2500,                 loss: 3.8288
env0_second_0:                 episode reward: 11.2500,                 loss: nan
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 5521/100000 (5.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 766.6649s / 203806.2109 s
env0_first_0:                 episode reward: -20.1500,                 loss: 3.8250
env0_second_0:                 episode reward: 20.1500,                 loss: nan
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 5541/100000 (5.5410%),                 avg. length: 299.0,                last time consumption/overall running time: 764.6409s / 204570.8517 s
env0_first_0:                 episode reward: -12.8500,                 loss: 3.6898
env0_second_0:                 episode reward: 12.8500,                 loss: nan
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 5561/100000 (5.5610%),                 avg. length: 299.0,                last time consumption/overall running time: 769.9686s / 205340.8203 s
env0_first_0:                 episode reward: -25.7000,                 loss: 3.7138
env0_second_0:                 episode reward: 25.7000,                 loss: nan
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 5581/100000 (5.5810%),                 avg. length: 299.0,                last time consumption/overall running time: 763.6551s / 206104.4754 s
env0_first_0:                 episode reward: -30.4000,                 loss: 3.7003
env0_second_0:                 episode reward: 30.4000,                 loss: nan
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 5601/100000 (5.6010%),                 avg. length: 297.0,                last time consumption/overall running time: 763.8138s / 206868.2892 s
env0_first_0:                 episode reward: -34.2000,                 loss: 3.9039
env0_second_0:                 episode reward: 34.2000,                 loss: nan
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 5621/100000 (5.6210%),                 avg. length: 298.05,                last time consumption/overall running time: 762.1625s / 207630.4517 s
env0_first_0:                 episode reward: -25.4500,                 loss: 4.1033
env0_second_0:                 episode reward: 25.4500,                 loss: nan
env1_first_0:                 episode reward: -23.4500,                 loss: nan
env1_second_0:                 episode reward: 23.4500,                 loss: nan
Episode: 5641/100000 (5.6410%),                 avg. length: 299.0,                last time consumption/overall running time: 767.5747s / 208398.0264 s
env0_first_0:                 episode reward: -20.0000,                 loss: 4.0894
env0_second_0:                 episode reward: 20.0000,                 loss: nan
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 5661/100000 (5.6610%),                 avg. length: 297.7,                last time consumption/overall running time: 761.9794s / 209160.0058 s
env0_first_0:                 episode reward: -23.2500,                 loss: 4.0988
env0_second_0:                 episode reward: 23.2500,                 loss: nan
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
Episode: 5681/100000 (5.6810%),                 avg. length: 296.55,                last time consumption/overall running time: 760.9065s / 209920.9123 s
env0_first_0:                 episode reward: -16.2500,                 loss: 3.8559
env0_second_0:                 episode reward: 16.2500,                 loss: nan
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 5701/100000 (5.7010%),                 avg. length: 296.5,                last time consumption/overall running time: 760.5894s / 210681.5017 s
env0_first_0:                 episode reward: -24.2000,                 loss: 3.6580
env0_second_0:                 episode reward: 24.2000,                 loss: nan
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 5721/100000 (5.7210%),                 avg. length: 296.65,                last time consumption/overall running time: 757.8904s / 211439.3921 s
env0_first_0:                 episode reward: -16.7500,                 loss: 3.6512
env0_second_0:                 episode reward: 16.7500,                 loss: nan
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 5741/100000 (5.7410%),                 avg. length: 299.0,                last time consumption/overall running time: 766.1021s / 212205.4942 s
env0_first_0:                 episode reward: -13.0000,                 loss: 3.7874
env0_second_0:                 episode reward: 13.0000,                 loss: nan
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 5761/100000 (5.7610%),                 avg. length: 298.85,                last time consumption/overall running time: 765.8836s / 212971.3779 s
env0_first_0:                 episode reward: -31.6500,                 loss: 3.9043
env0_second_0:                 episode reward: 31.6500,                 loss: nan
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 5781/100000 (5.7810%),                 avg. length: 296.05,                last time consumption/overall running time: 757.7809s / 213729.1587 s
env0_first_0:                 episode reward: -22.2500,                 loss: 4.0215
env0_second_0:                 episode reward: 22.2500,                 loss: nan
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 5801/100000 (5.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 761.9987s / 214491.1574 s
env0_first_0:                 episode reward: -18.5500,                 loss: 4.0437
env0_second_0:                 episode reward: 18.5500,                 loss: nan
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 5821/100000 (5.8210%),                 avg. length: 296.55,                last time consumption/overall running time: 763.3001s / 215254.4575 s
env0_first_0:                 episode reward: -14.3500,                 loss: 4.0162
env0_second_0:                 episode reward: 14.3500,                 loss: nan
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 5841/100000 (5.8410%),                 avg. length: 299.0,                last time consumption/overall running time: 770.5951s / 216025.0526 s
env0_first_0:                 episode reward: -16.9000,                 loss: 3.9547
env0_second_0:                 episode reward: 16.9000,                 loss: nan
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 5861/100000 (5.8610%),                 avg. length: 298.85,                last time consumption/overall running time: 767.7008s / 216792.7533 s
env0_first_0:                 episode reward: -14.2500,                 loss: 3.9230
env0_second_0:                 episode reward: 14.2500,                 loss: nan
env1_first_0:                 episode reward: -18.7500,                 loss: nan
env1_second_0:                 episode reward: 18.7500,                 loss: nan
Episode: 5881/100000 (5.8810%),                 avg. length: 299.0,                last time consumption/overall running time: 766.4430s / 217559.1963 s
env0_first_0:                 episode reward: -7.7500,                 loss: 3.8894
env0_second_0:                 episode reward: 7.7500,                 loss: nan
env1_first_0:                 episode reward: -40.3500,                 loss: nan
env1_second_0:                 episode reward: 40.3500,                 loss: nan
Episode: 5901/100000 (5.9010%),                 avg. length: 299.0,                last time consumption/overall running time: 765.6323s / 218324.8286 s
env0_first_0:                 episode reward: -25.1500,                 loss: 3.9250
env0_second_0:                 episode reward: 25.1500,                 loss: nan
env1_first_0:                 episode reward: -39.0000,                 loss: nan
env1_second_0:                 episode reward: 39.0000,                 loss: nan
Episode: 5921/100000 (5.9210%),                 avg. length: 297.75,                last time consumption/overall running time: 768.1397s / 219092.9683 s
env0_first_0:                 episode reward: -18.9000,                 loss: 3.9656
env0_second_0:                 episode reward: 18.9000,                 loss: nan
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 5941/100000 (5.9410%),                 avg. length: 299.0,                last time consumption/overall running time: 771.4520s / 219864.4204 s
env0_first_0:                 episode reward: -15.2500,                 loss: 4.0699
env0_second_0:                 episode reward: 15.2500,                 loss: nan
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 5961/100000 (5.9610%),                 avg. length: 299.0,                last time consumption/overall running time: 766.0868s / 220630.5071 s
env0_first_0:                 episode reward: -27.1000,                 loss: 4.0592
env0_second_0:                 episode reward: 27.1000,                 loss: nan
env1_first_0:                 episode reward: -31.9500,                 loss: nan
env1_second_0:                 episode reward: 31.9500,                 loss: nan
Episode: 5981/100000 (5.9810%),                 avg. length: 299.0,                last time consumption/overall running time: 769.3049s / 221399.8120 s
env0_first_0:                 episode reward: -33.0500,                 loss: 3.9880
env0_second_0:                 episode reward: 33.0500,                 loss: nan
env1_first_0:                 episode reward: -28.5000,                 loss: nan
env1_second_0:                 episode reward: 28.5000,                 loss: nan
Episode: 6001/100000 (6.0010%),                 avg. length: 292.65,                last time consumption/overall running time: 754.3112s / 222154.1232 s
env0_first_0:                 episode reward: -31.6000,                 loss: 3.8529
env0_second_0:                 episode reward: 31.6000,                 loss: nan
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 6021/100000 (6.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 768.5789s / 222922.7021 s
env0_first_0:                 episode reward: -29.8000,                 loss: 3.9120
env0_second_0:                 episode reward: 29.8000,                 loss: nan
env1_first_0:                 episode reward: -18.7500,                 loss: nan
env1_second_0:                 episode reward: 18.7500,                 loss: nan
Episode: 6041/100000 (6.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 769.0477s / 223691.7498 s
env0_first_0:                 episode reward: -16.3500,                 loss: 3.8316
env0_second_0:                 episode reward: 16.3500,                 loss: nan
env1_first_0:                 episode reward: -34.9000,                 loss: nan
env1_second_0:                 episode reward: 34.9000,                 loss: nan
Episode: 6061/100000 (6.0610%),                 avg. length: 298.8,                last time consumption/overall running time: 766.1187s / 224457.8684 s
env0_first_0:                 episode reward: -20.9000,                 loss: 3.8477
env0_second_0:                 episode reward: 20.9000,                 loss: nan
env1_first_0:                 episode reward: -26.8000,                 loss: nan
env1_second_0:                 episode reward: 26.8000,                 loss: nan
Episode: 6081/100000 (6.0810%),                 avg. length: 296.4,                last time consumption/overall running time: 762.1744s / 225220.0428 s
env0_first_0:                 episode reward: -16.0500,                 loss: 3.8359
env0_second_0:                 episode reward: 16.0500,                 loss: nan
env1_first_0:                 episode reward: -30.1500,                 loss: nan
env1_second_0:                 episode reward: 30.1500,                 loss: nan
Episode: 6101/100000 (6.1010%),                 avg. length: 297.05,                last time consumption/overall running time: 759.0729s / 225979.1157 s
env0_first_0:                 episode reward: -22.0500,                 loss: 3.9099
env0_second_0:                 episode reward: 22.0500,                 loss: nan
env1_first_0:                 episode reward: -30.3000,                 loss: nan
env1_second_0:                 episode reward: 30.3000,                 loss: nan
Episode: 6121/100000 (6.1210%),                 avg. length: 297.8,                last time consumption/overall running time: 765.9525s / 226745.0682 s
env0_first_0:                 episode reward: -40.0500,                 loss: 3.9209
env0_second_0:                 episode reward: 40.0500,                 loss: nan
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 6141/100000 (6.1410%),                 avg. length: 297.35,                last time consumption/overall running time: 753.8458s / 227498.9140 s
env0_first_0:                 episode reward: -21.2500,                 loss: 3.9561
env0_second_0:                 episode reward: 21.2500,                 loss: nan
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 6161/100000 (6.1610%),                 avg. length: 298.9,                last time consumption/overall running time: 756.3014s / 228255.2154 s
env0_first_0:                 episode reward: -9.3500,                 loss: 3.9748
env0_second_0:                 episode reward: 9.3500,                 loss: nan
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 6181/100000 (6.1810%),                 avg. length: 298.7,                last time consumption/overall running time: 752.4955s / 229007.7109 s
env0_first_0:                 episode reward: -1.8000,                 loss: 3.8850
env0_second_0:                 episode reward: 1.8000,                 loss: nan
env1_first_0:                 episode reward: -30.9500,                 loss: nan
env1_second_0:                 episode reward: 30.9500,                 loss: nan
Episode: 6201/100000 (6.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 753.2585s / 229760.9694 s
env0_first_0:                 episode reward: -11.5500,                 loss: 3.8044
env0_second_0:                 episode reward: 11.5500,                 loss: nan
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 6221/100000 (6.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 751.7170s / 230512.6864 s
env0_first_0:                 episode reward: -24.4500,                 loss: 3.8107
env0_second_0:                 episode reward: 24.4500,                 loss: nan
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 6241/100000 (6.2410%),                 avg. length: 294.0,                last time consumption/overall running time: 744.8753s / 231257.5617 s
env0_first_0:                 episode reward: -28.5000,                 loss: 4.0130
env0_second_0:                 episode reward: 28.5000,                 loss: nan
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 6261/100000 (6.2610%),                 avg. length: 295.95,                last time consumption/overall running time: 746.0034s / 232003.5652 s
env0_first_0:                 episode reward: -14.3500,                 loss: 4.1009
env0_second_0:                 episode reward: 14.3500,                 loss: nan
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 6281/100000 (6.2810%),                 avg. length: 296.4,                last time consumption/overall running time: 744.7939s / 232748.3591 s
env0_first_0:                 episode reward: -13.7500,                 loss: 4.0332
env0_second_0:                 episode reward: 13.7500,                 loss: nan
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 6301/100000 (6.3010%),                 avg. length: 298.4,                last time consumption/overall running time: 750.9771s / 233499.3362 s
env0_first_0:                 episode reward: -3.2500,                 loss: 4.1069
env0_second_0:                 episode reward: 3.2500,                 loss: nan
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 6321/100000 (6.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 756.0874s / 234255.4236 s
env0_first_0:                 episode reward: -27.6000,                 loss: 3.8746
env0_second_0:                 episode reward: 27.6000,                 loss: nan
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 6341/100000 (6.3410%),                 avg. length: 296.8,                last time consumption/overall running time: 748.0169s / 235003.4405 s
env0_first_0:                 episode reward: -19.0500,                 loss: 3.7867
env0_second_0:                 episode reward: 19.0500,                 loss: nan
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 6361/100000 (6.3610%),                 avg. length: 298.8,                last time consumption/overall running time: 752.9336s / 235756.3742 s
env0_first_0:                 episode reward: -29.0000,                 loss: 3.8792
env0_second_0:                 episode reward: 29.0000,                 loss: nan
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 6381/100000 (6.3810%),                 avg. length: 297.25,                last time consumption/overall running time: 743.4180s / 236499.7922 s
env0_first_0:                 episode reward: -15.9500,                 loss: 4.2443
env0_second_0:                 episode reward: 15.9500,                 loss: nan
env1_first_0:                 episode reward: -28.6000,                 loss: nan
env1_second_0:                 episode reward: 28.6000,                 loss: nan
Episode: 6401/100000 (6.4010%),                 avg. length: 296.95,                last time consumption/overall running time: 745.1448s / 237244.9370 s
env0_first_0:                 episode reward: -7.3500,                 loss: 4.2563
env0_second_0:                 episode reward: 7.3500,                 loss: nan
env1_first_0:                 episode reward: -19.0500,                 loss: nan
env1_second_0:                 episode reward: 19.0500,                 loss: nan
Episode: 6421/100000 (6.4210%),                 avg. length: 298.65,                last time consumption/overall running time: 750.3950s / 237995.3320 s
env0_first_0:                 episode reward: -28.8000,                 loss: 4.1822
env0_second_0:                 episode reward: 28.8000,                 loss: nan
env1_first_0:                 episode reward: -17.4000,                 loss: nan
env1_second_0:                 episode reward: 17.4000,                 loss: nan
Episode: 6441/100000 (6.4410%),                 avg. length: 297.8,                last time consumption/overall running time: 745.6199s / 238740.9519 s
env0_first_0:                 episode reward: -22.5000,                 loss: 4.3121
env0_second_0:                 episode reward: 22.5000,                 loss: nan
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 6461/100000 (6.4610%),                 avg. length: 298.9,                last time consumption/overall running time: 746.6947s / 239487.6466 s
env0_first_0:                 episode reward: -1.6000,                 loss: 4.3421
env0_second_0:                 episode reward: 1.6000,                 loss: nan
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 6481/100000 (6.4810%),                 avg. length: 297.5,                last time consumption/overall running time: 749.3234s / 240236.9700 s
env0_first_0:                 episode reward: -11.0000,                 loss: 4.1745
env0_second_0:                 episode reward: 11.0000,                 loss: nan
env1_first_0:                 episode reward: -26.1000,                 loss: nan
env1_second_0:                 episode reward: 26.1000,                 loss: nan
Episode: 6501/100000 (6.5010%),                 avg. length: 297.15,                last time consumption/overall running time: 749.7633s / 240986.7333 s
env0_first_0:                 episode reward: -19.9500,                 loss: 4.1072
env0_second_0:                 episode reward: 19.9500,                 loss: nan
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 6521/100000 (6.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 753.3697s / 241740.1031 s
env0_first_0:                 episode reward: -23.8500,                 loss: 4.1367
env0_second_0:                 episode reward: 23.8500,                 loss: nan
env1_first_0:                 episode reward: -18.7000,                 loss: nan
env1_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 6541/100000 (6.5410%),                 avg. length: 297.8,                last time consumption/overall running time: 751.6645s / 242491.7675 s
env0_first_0:                 episode reward: -16.0000,                 loss: 4.2400
env0_second_0:                 episode reward: 16.0000,                 loss: nan
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 6561/100000 (6.5610%),                 avg. length: 293.6,                last time consumption/overall running time: 738.7852s / 243230.5528 s
env0_first_0:                 episode reward: -22.4500,                 loss: 4.1979
env0_second_0:                 episode reward: 22.4500,                 loss: nan
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 6581/100000 (6.5810%),                 avg. length: 298.45,                last time consumption/overall running time: 751.2798s / 243981.8325 s
env0_first_0:                 episode reward: -11.4000,                 loss: 4.0143
env0_second_0:                 episode reward: 11.4000,                 loss: nan
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 6601/100000 (6.6010%),                 avg. length: 299.0,                last time consumption/overall running time: 755.3272s / 244737.1597 s
env0_first_0:                 episode reward: -19.3500,                 loss: 3.8742
env0_second_0:                 episode reward: 19.3500,                 loss: nan
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 6621/100000 (6.6210%),                 avg. length: 287.35,                last time consumption/overall running time: 721.2870s / 245458.4468 s
env0_first_0:                 episode reward: -35.8000,                 loss: 3.9525
env0_second_0:                 episode reward: 35.8000,                 loss: nan
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 6641/100000 (6.6410%),                 avg. length: 291.0,                last time consumption/overall running time: 734.4707s / 246192.9175 s
env0_first_0:                 episode reward: -27.6500,                 loss: 4.0769
env0_second_0:                 episode reward: 27.6500,                 loss: nan
env1_first_0:                 episode reward: -29.3000,                 loss: nan
env1_second_0:                 episode reward: 29.3000,                 loss: nan
Episode: 6661/100000 (6.6610%),                 avg. length: 299.0,                last time consumption/overall running time: 754.0049s / 246946.9224 s
env0_first_0:                 episode reward: -40.5000,                 loss: 4.0344
env0_second_0:                 episode reward: 40.5000,                 loss: nan
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 6681/100000 (6.6810%),                 avg. length: 295.15,                last time consumption/overall running time: 749.8331s / 247696.7555 s
env0_first_0:                 episode reward: -24.5500,                 loss: 4.0371
env0_second_0:                 episode reward: 24.5500,                 loss: nan
env1_first_0:                 episode reward: -38.0000,                 loss: nan
env1_second_0:                 episode reward: 38.0000,                 loss: nan
Episode: 6701/100000 (6.7010%),                 avg. length: 293.5,                last time consumption/overall running time: 740.8677s / 248437.6232 s
env0_first_0:                 episode reward: -30.8000,                 loss: 4.2586
env0_second_0:                 episode reward: 30.8000,                 loss: nan
env1_first_0:                 episode reward: -23.9000,                 loss: nan
env1_second_0:                 episode reward: 23.9000,                 loss: nan
Episode: 6721/100000 (6.7210%),                 avg. length: 295.3,                last time consumption/overall running time: 743.9795s / 249181.6027 s
env0_first_0:                 episode reward: -20.3000,                 loss: 4.2208
env0_second_0:                 episode reward: 20.3000,                 loss: nan
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 6741/100000 (6.7410%),                 avg. length: 297.25,                last time consumption/overall running time: 748.7088s / 249930.3115 s
env0_first_0:                 episode reward: -15.2500,                 loss: 4.1437
env0_second_0:                 episode reward: 15.2500,                 loss: nan
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 6761/100000 (6.7610%),                 avg. length: 296.45,                last time consumption/overall running time: 744.6900s / 250675.0015 s
env0_first_0:                 episode reward: -9.1500,                 loss: 4.1592
env0_second_0:                 episode reward: 9.1500,                 loss: nan
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 6781/100000 (6.7810%),                 avg. length: 296.35,                last time consumption/overall running time: 747.6460s / 251422.6475 s
env0_first_0:                 episode reward: -19.9500,                 loss: 4.0185
env0_second_0:                 episode reward: 19.9500,                 loss: nan
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 6801/100000 (6.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 755.0429s / 252177.6904 s
env0_first_0:                 episode reward: -13.7000,                 loss: 3.9122
env0_second_0:                 episode reward: 13.7000,                 loss: nan
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 6821/100000 (6.8210%),                 avg. length: 298.35,                last time consumption/overall running time: 751.6673s / 252929.3578 s
env0_first_0:                 episode reward: -16.6500,                 loss: 4.0815
env0_second_0:                 episode reward: 16.6500,                 loss: nan
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 6841/100000 (6.8410%),                 avg. length: 293.15,                last time consumption/overall running time: 741.8766s / 253671.2343 s
env0_first_0:                 episode reward: -29.2000,                 loss: 4.1732
env0_second_0:                 episode reward: 29.2000,                 loss: nan
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 6861/100000 (6.8610%),                 avg. length: 296.3,                last time consumption/overall running time: 752.2260s / 254423.4603 s
env0_first_0:                 episode reward: -33.2500,                 loss: 4.0943
env0_second_0:                 episode reward: 33.2500,                 loss: nan
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 6881/100000 (6.8810%),                 avg. length: 293.95,                last time consumption/overall running time: 744.7868s / 255168.2471 s
env0_first_0:                 episode reward: -27.3500,                 loss: 4.1979
env0_second_0:                 episode reward: 27.3500,                 loss: nan
env1_first_0:                 episode reward: -39.6500,                 loss: nan
env1_second_0:                 episode reward: 39.6500,                 loss: nan
Episode: 6901/100000 (6.9010%),                 avg. length: 291.35,                last time consumption/overall running time: 736.1125s / 255904.3596 s
env0_first_0:                 episode reward: -35.5500,                 loss: 4.2233
env0_second_0:                 episode reward: 35.5500,                 loss: nan
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 6921/100000 (6.9210%),                 avg. length: 291.6,                last time consumption/overall running time: 737.5630s / 256641.9226 s
env0_first_0:                 episode reward: -21.9000,                 loss: 4.2592
env0_second_0:                 episode reward: 21.9000,                 loss: nan
env1_first_0:                 episode reward: -34.2500,                 loss: nan
env1_second_0:                 episode reward: 34.2500,                 loss: nan
Episode: 6941/100000 (6.9410%),                 avg. length: 295.25,                last time consumption/overall running time: 750.3468s / 257392.2694 s
env0_first_0:                 episode reward: -28.9500,                 loss: 4.5591
env0_second_0:                 episode reward: 28.9500,                 loss: nan
env1_first_0:                 episode reward: -32.9500,                 loss: nan
env1_second_0:                 episode reward: 32.9500,                 loss: nan
Episode: 6961/100000 (6.9610%),                 avg. length: 288.6,                last time consumption/overall running time: 732.6938s / 258124.9632 s
env0_first_0:                 episode reward: -2.5500,                 loss: 4.5769
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -44.0500,                 loss: nan
env1_second_0:                 episode reward: 44.0500,                 loss: nan
Episode: 6981/100000 (6.9810%),                 avg. length: 294.6,                last time consumption/overall running time: 746.8945s / 258871.8577 s
env0_first_0:                 episode reward: -34.1500,                 loss: 4.5765
env0_second_0:                 episode reward: 34.1500,                 loss: nan
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 7001/100000 (7.0010%),                 avg. length: 295.85,                last time consumption/overall running time: 749.6294s / 259621.4871 s
env0_first_0:                 episode reward: -30.1000,                 loss: 4.3661
env0_second_0:                 episode reward: 30.1000,                 loss: nan
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 7021/100000 (7.0210%),                 avg. length: 293.7,                last time consumption/overall running time: 746.6258s / 260368.1129 s
env0_first_0:                 episode reward: -4.0500,                 loss: 4.2912
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 7041/100000 (7.0410%),                 avg. length: 293.05,                last time consumption/overall running time: 745.2955s / 261113.4085 s
env0_first_0:                 episode reward: -15.1500,                 loss: 4.1608
env0_second_0:                 episode reward: 15.1500,                 loss: nan
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 7061/100000 (7.0610%),                 avg. length: 290.25,                last time consumption/overall running time: 737.2331s / 261850.6416 s
env0_first_0:                 episode reward: -16.4500,                 loss: 4.2190
env0_second_0:                 episode reward: 16.4500,                 loss: nan
env1_first_0:                 episode reward: -19.4500,                 loss: nan
env1_second_0:                 episode reward: 19.4500,                 loss: nan
Episode: 7081/100000 (7.0810%),                 avg. length: 291.5,                last time consumption/overall running time: 740.0833s / 262590.7249 s
env0_first_0:                 episode reward: -28.5500,                 loss: 4.2732
env0_second_0:                 episode reward: 28.5500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7101/100000 (7.1010%),                 avg. length: 297.7,                last time consumption/overall running time: 754.5684s / 263345.2933 s
env0_first_0:                 episode reward: -17.7500,                 loss: 4.3382
env0_second_0:                 episode reward: 17.7500,                 loss: nan
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 7121/100000 (7.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 759.7592s / 264105.0524 s
env0_first_0:                 episode reward: -17.9000,                 loss: 4.3583
env0_second_0:                 episode reward: 17.9000,                 loss: nan
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 7141/100000 (7.1410%),                 avg. length: 294.2,                last time consumption/overall running time: 743.7690s / 264848.8214 s
env0_first_0:                 episode reward: -25.7500,                 loss: 4.2574
env0_second_0:                 episode reward: 25.7500,                 loss: nan
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 7161/100000 (7.1610%),                 avg. length: 298.1,                last time consumption/overall running time: 752.0236s / 265600.8450 s
env0_first_0:                 episode reward: -26.7000,                 loss: 4.3073
env0_second_0:                 episode reward: 26.7000,                 loss: nan
env1_first_0:                 episode reward: -19.4000,                 loss: nan
env1_second_0:                 episode reward: 19.4000,                 loss: nan
Episode: 7181/100000 (7.1810%),                 avg. length: 289.1,                last time consumption/overall running time: 733.4623s / 266334.3073 s
env0_first_0:                 episode reward: -30.5500,                 loss: 4.1405
env0_second_0:                 episode reward: 30.5500,                 loss: nan
env1_first_0:                 episode reward: -30.2500,                 loss: nan
env1_second_0:                 episode reward: 30.2500,                 loss: nan
Episode: 7201/100000 (7.2010%),                 avg. length: 290.85,                last time consumption/overall running time: 734.6845s / 267068.9918 s
env0_first_0:                 episode reward: -33.1000,                 loss: 4.0754
env0_second_0:                 episode reward: 33.1000,                 loss: nan
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
Episode: 7221/100000 (7.2210%),                 avg. length: 294.95,                last time consumption/overall running time: 741.1914s / 267810.1832 s
env0_first_0:                 episode reward: -30.8000,                 loss: 4.0426
env0_second_0:                 episode reward: 30.8000,                 loss: nan
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 7241/100000 (7.2410%),                 avg. length: 295.4,                last time consumption/overall running time: 748.5223s / 268558.7055 s
env0_first_0:                 episode reward: -24.1000,                 loss: 3.9922
env0_second_0:                 episode reward: 24.1000,                 loss: nan
env1_first_0:                 episode reward: -35.7500,                 loss: nan
env1_second_0:                 episode reward: 35.7500,                 loss: nan
Episode: 7261/100000 (7.2610%),                 avg. length: 293.85,                last time consumption/overall running time: 745.1236s / 269303.8291 s
env0_first_0:                 episode reward: -29.0000,                 loss: 3.9960
env0_second_0:                 episode reward: 29.0000,                 loss: nan
env1_first_0:                 episode reward: -26.6500,                 loss: nan
env1_second_0:                 episode reward: 26.6500,                 loss: nan
Episode: 7281/100000 (7.2810%),                 avg. length: 297.65,                last time consumption/overall running time: 755.0397s / 270058.8688 s
env0_first_0:                 episode reward: -11.2000,                 loss: 4.0256
env0_second_0:                 episode reward: 11.2000,                 loss: nan
env1_first_0:                 episode reward: -22.4500,                 loss: nan
env1_second_0:                 episode reward: 22.4500,                 loss: nan
Episode: 7301/100000 (7.3010%),                 avg. length: 293.7,                last time consumption/overall running time: 741.6389s / 270800.5077 s
env0_first_0:                 episode reward: -38.8500,                 loss: 4.0631
env0_second_0:                 episode reward: 38.8500,                 loss: nan
env1_first_0:                 episode reward: -38.5500,                 loss: nan
env1_second_0:                 episode reward: 38.5500,                 loss: nan
Episode: 7321/100000 (7.3210%),                 avg. length: 294.8,                last time consumption/overall running time: 741.9704s / 271542.4781 s
env0_first_0:                 episode reward: -28.5500,                 loss: 4.0608
env0_second_0:                 episode reward: 28.5500,                 loss: nan
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 7341/100000 (7.3410%),                 avg. length: 289.95,                last time consumption/overall running time: 730.1779s / 272272.6560 s
env0_first_0:                 episode reward: -46.3000,                 loss: 3.8740
env0_second_0:                 episode reward: 46.3000,                 loss: nan
env1_first_0:                 episode reward: -33.2500,                 loss: nan
env1_second_0:                 episode reward: 33.2500,                 loss: nan
Episode: 7361/100000 (7.3610%),                 avg. length: 293.65,                last time consumption/overall running time: 745.0836s / 273017.7396 s
env0_first_0:                 episode reward: -29.8000,                 loss: 3.8032
env0_second_0:                 episode reward: 29.8000,                 loss: nan
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 7381/100000 (7.3810%),                 avg. length: 294.15,                last time consumption/overall running time: 745.5997s / 273763.3392 s
env0_first_0:                 episode reward: -47.6000,                 loss: 3.9231
env0_second_0:                 episode reward: 47.6000,                 loss: nan
env1_first_0:                 episode reward: -28.3000,                 loss: nan
env1_second_0:                 episode reward: 28.3000,                 loss: nan
Episode: 7401/100000 (7.4010%),                 avg. length: 291.6,                last time consumption/overall running time: 740.3315s / 274503.6707 s
env0_first_0:                 episode reward: -45.2000,                 loss: 3.8485
env0_second_0:                 episode reward: 45.2000,                 loss: nan
env1_first_0:                 episode reward: -20.2000,                 loss: nan
env1_second_0:                 episode reward: 20.2000,                 loss: nan
Episode: 7421/100000 (7.4210%),                 avg. length: 285.4,                last time consumption/overall running time: 738.1986s / 275241.8693 s
env0_first_0:                 episode reward: -6.3000,                 loss: 3.7288
env0_second_0:                 episode reward: 6.3000,                 loss: nan
env1_first_0:                 episode reward: -37.3500,                 loss: nan