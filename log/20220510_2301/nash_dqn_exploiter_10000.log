2022-05-10 23:51:54.885436: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 23:51:54.885506: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 23:51:54.885511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
random seed: 609
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f51dc0eb160>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 10, 'log_interval': 10, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510143601_exploit_10000/mdp_arbitrary_mdp_nash_dqn_exploiter. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510143601_exploit_10000/mdp_arbitrary_mdp_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8275s / 0.8275 s
agent0:                 episode reward: -1.4608,                 loss: nan
agent1:                 episode reward: 1.4608,                 loss: nan
Episode: 11/10000 (0.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1136s / 0.9410 s
agent0:                 episode reward: 1.6152,                 loss: nan
agent1:                 episode reward: -1.6152,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1158s / 1.0568 s
agent0:                 episode reward: 1.3004,                 loss: nan
agent1:                 episode reward: -1.3004,                 loss: nan
Episode: 31/10000 (0.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1135s / 1.1704 s
agent0:                 episode reward: 1.3789,                 loss: nan
agent1:                 episode reward: -1.3789,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1160s / 1.2863 s
agent0:                 episode reward: 0.2867,                 loss: nan
agent1:                 episode reward: -0.2867,                 loss: nan
Episode: 51/10000 (0.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1119s / 1.3982 s
agent0:                 episode reward: 1.5361,                 loss: nan
agent1:                 episode reward: -1.5361,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1165s / 1.5148 s
agent0:                 episode reward: 0.1821,                 loss: nan
agent1:                 episode reward: -0.1821,                 loss: nan
Episode: 71/10000 (0.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.3698s / 1.8846 s
agent0:                 episode reward: 0.9459,                 loss: nan
agent1:                 episode reward: -0.9459,                 loss: 0.5297
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4558s / 2.3403 s
agent0:                 episode reward: 1.9003,                 loss: nan
agent1:                 episode reward: -1.9003,                 loss: 0.4176
Episode: 91/10000 (0.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4484s / 2.7888 s
agent0:                 episode reward: 1.0722,                 loss: nan
agent1:                 episode reward: -1.0722,                 loss: 0.4071
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4955s / 3.2843 s
agent0:                 episode reward: 1.4644,                 loss: nan
agent1:                 episode reward: -1.4644,                 loss: 0.4020
Episode: 111/10000 (1.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4544s / 3.7386 s
agent0:                 episode reward: 0.2842,                 loss: nan
agent1:                 episode reward: -0.2842,                 loss: 0.3957
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4502s / 4.1888 s
agent0:                 episode reward: 2.3046,                 loss: nan
agent1:                 episode reward: -2.3046,                 loss: 0.3896
Episode: 131/10000 (1.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4443s / 4.6332 s
agent0:                 episode reward: 0.9839,                 loss: nan
agent1:                 episode reward: -0.9839,                 loss: 0.3832
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4987s / 5.1318 s
agent0:                 episode reward: 1.6881,                 loss: nan
agent1:                 episode reward: -1.6881,                 loss: 0.3790
Episode: 151/10000 (1.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4537s / 5.5855 s
agent0:                 episode reward: 1.2787,                 loss: nan
agent1:                 episode reward: -1.2787,                 loss: 0.3771
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4603s / 6.0458 s
agent0:                 episode reward: -0.2150,                 loss: nan
agent1:                 episode reward: 0.2150,                 loss: 0.3718
Episode: 171/10000 (1.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4533s / 6.4991 s
agent0:                 episode reward: 0.6803,                 loss: nan
agent1:                 episode reward: -0.6803,                 loss: 0.3925
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4544s / 6.9535 s
agent0:                 episode reward: 0.1357,                 loss: nan
agent1:                 episode reward: -0.1357,                 loss: 0.4017
Episode: 191/10000 (1.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4507s / 7.4042 s
agent0:                 episode reward: 1.3328,                 loss: nan
agent1:                 episode reward: -1.3328,                 loss: 0.4017
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4573s / 7.8615 s
agent0:                 episode reward: 0.3493,                 loss: nan
agent1:                 episode reward: -0.3493,                 loss: 0.4028
Episode: 211/10000 (2.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4714s / 8.3329 s
agent0:                 episode reward: 1.3704,                 loss: nan
agent1:                 episode reward: -1.3704,                 loss: 0.4040
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4772s / 8.8101 s
agent0:                 episode reward: 0.8786,                 loss: nan
agent1:                 episode reward: -0.8786,                 loss: 0.4051
Episode: 231/10000 (2.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4590s / 9.2692 s
agent0:                 episode reward: 0.2649,                 loss: nan
agent1:                 episode reward: -0.2649,                 loss: 0.4049
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4684s / 9.7375 s
agent0:                 episode reward: 1.1218,                 loss: nan
agent1:                 episode reward: -1.1218,                 loss: 0.4044
Episode: 251/10000 (2.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4807s / 10.2182 s
agent0:                 episode reward: 0.9005,                 loss: nan
agent1:                 episode reward: -0.9005,                 loss: 0.4042
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4582s / 10.6765 s
agent0:                 episode reward: 0.4613,                 loss: nan
agent1:                 episode reward: -0.4613,                 loss: 0.4035
Episode: 271/10000 (2.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4621s / 11.1386 s
agent0:                 episode reward: 1.0666,                 loss: nan
agent1:                 episode reward: -1.0666,                 loss: 0.4198
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4617s / 11.6003 s
agent0:                 episode reward: 0.5590,                 loss: nan
agent1:                 episode reward: -0.5590,                 loss: 0.4252
Episode: 291/10000 (2.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4612s / 12.0615 s
agent0:                 episode reward: 1.0827,                 loss: nan
agent1:                 episode reward: -1.0827,                 loss: 0.4249
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4631s / 12.5246 s
agent0:                 episode reward: 1.1772,                 loss: nan
agent1:                 episode reward: -1.1772,                 loss: 0.4252
Episode: 311/10000 (3.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4634s / 12.9880 s
agent0:                 episode reward: -0.4621,                 loss: nan
agent1:                 episode reward: 0.4621,                 loss: 0.4237
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4585s / 13.4465 s
agent0:                 episode reward: 0.8542,                 loss: nan
agent1:                 episode reward: -0.8542,                 loss: 0.4259
Episode: 331/10000 (3.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4654s / 13.9119 s
agent0:                 episode reward: 0.6700,                 loss: nan
agent1:                 episode reward: -0.6700,                 loss: 0.4250
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4768s / 14.3887 s
agent0:                 episode reward: 2.3160,                 loss: nan
agent1:                 episode reward: -2.3160,                 loss: 0.4251
Episode: 351/10000 (3.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4690s / 14.8577 s
agent0:                 episode reward: 1.1355,                 loss: nan
agent1:                 episode reward: -1.1355,                 loss: 0.4255
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5003s / 15.3580 s
agent0:                 episode reward: 1.3471,                 loss: nan
agent1:                 episode reward: -1.3471,                 loss: 0.4255
Episode: 371/10000 (3.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4606s / 15.8186 s
agent0:                 episode reward: 0.2081,                 loss: nan
agent1:                 episode reward: -0.2081,                 loss: 0.4340
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4728s / 16.2914 s
agent0:                 episode reward: 2.3736,                 loss: nan
agent1:                 episode reward: -2.3736,                 loss: 0.4385
Episode: 391/10000 (3.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4774s / 16.7688 s
agent0:                 episode reward: -0.1844,                 loss: nan
agent1:                 episode reward: 0.1844,                 loss: 0.4381
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4788s / 17.2477 s
agent0:                 episode reward: 1.1829,                 loss: nan
agent1:                 episode reward: -1.1829,                 loss: 0.4387
Episode: 411/10000 (4.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4666s / 17.7143 s
agent0:                 episode reward: 0.4428,                 loss: nan
agent1:                 episode reward: -0.4428,                 loss: 0.4376
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4819s / 18.1961 s
agent0:                 episode reward: 1.4653,                 loss: nan
agent1:                 episode reward: -1.4653,                 loss: 0.4363
Episode: 431/10000 (4.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4772s / 18.6734 s
agent0:                 episode reward: 1.1473,                 loss: nan
agent1:                 episode reward: -1.1473,                 loss: 0.4359
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4772s / 19.1506 s
agent0:                 episode reward: 1.4322,                 loss: nan
agent1:                 episode reward: -1.4322,                 loss: 0.4372
Episode: 451/10000 (4.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4713s / 19.6219 s
agent0:                 episode reward: 1.4792,                 loss: nan
agent1:                 episode reward: -1.4792,                 loss: 0.4362
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4749s / 20.0968 s
agent0:                 episode reward: 1.1579,                 loss: nan
agent1:                 episode reward: -1.1579,                 loss: 0.4371
Episode: 471/10000 (4.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4727s / 20.5695 s
agent0:                 episode reward: 0.5094,                 loss: nan
agent1:                 episode reward: -0.5094,                 loss: 0.4461
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4781s / 21.0476 s
agent0:                 episode reward: 0.5863,                 loss: nan
agent1:                 episode reward: -0.5863,                 loss: 0.4483
Episode: 491/10000 (4.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4809s / 21.5285 s
agent0:                 episode reward: 1.2034,                 loss: nan
agent1:                 episode reward: -1.2034,                 loss: 0.4476
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4707s / 21.9992 s
agent0:                 episode reward: 0.5931,                 loss: nan
agent1:                 episode reward: -0.5931,                 loss: 0.4465
Episode: 511/10000 (5.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4918s / 22.4910 s
agent0:                 episode reward: 1.2291,                 loss: nan
agent1:                 episode reward: -1.2291,                 loss: 0.4467
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4783s / 22.9693 s
agent0:                 episode reward: 0.4682,                 loss: nan
agent1:                 episode reward: -0.4682,                 loss: 0.4464
Episode: 531/10000 (5.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4924s / 23.4617 s
agent0:                 episode reward: 1.1560,                 loss: nan
agent1:                 episode reward: -1.1560,                 loss: 0.4451
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4863s / 23.9480 s
agent0:                 episode reward: 1.5310,                 loss: nan
agent1:                 episode reward: -1.5310,                 loss: 0.4458
Episode: 551/10000 (5.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4719s / 24.4199 s
agent0:                 episode reward: -0.5798,                 loss: nan
agent1:                 episode reward: 0.5798,                 loss: 0.4445
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4964s / 24.9162 s
agent0:                 episode reward: 0.8925,                 loss: nan
agent1:                 episode reward: -0.8925,                 loss: 0.4449
Episode: 571/10000 (5.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5012s / 25.4174 s
agent0:                 episode reward: 1.0987,                 loss: nan
agent1:                 episode reward: -1.0987,                 loss: 0.4518
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5150s / 25.9324 s
agent0:                 episode reward: 2.0114,                 loss: nan
agent1:                 episode reward: -2.0114,                 loss: 0.4518
Episode: 591/10000 (5.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5006s / 26.4330 s
agent0:                 episode reward: 0.8243,                 loss: nan
agent1:                 episode reward: -0.8243,                 loss: 0.4499
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4907s / 26.9237 s
agent0:                 episode reward: 0.9379,                 loss: nan
agent1:                 episode reward: -0.9379,                 loss: 0.4493
Episode: 611/10000 (6.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4870s / 27.4107 s
agent0:                 episode reward: -0.4153,                 loss: nan
agent1:                 episode reward: 0.4153,                 loss: 0.4489
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4872s / 27.8979 s
agent0:                 episode reward: 0.9887,                 loss: nan
agent1:                 episode reward: -0.9887,                 loss: 0.4481
Episode: 631/10000 (6.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4906s / 28.3885 s
agent0:                 episode reward: 0.8269,                 loss: nan
agent1:                 episode reward: -0.8269,                 loss: 0.4473
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4728s / 28.8614 s
agent0:                 episode reward: 0.7621,                 loss: nan
agent1:                 episode reward: -0.7621,                 loss: 0.4471
Episode: 651/10000 (6.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5009s / 29.3623 s
agent0:                 episode reward: 1.9751,                 loss: nan
agent1:                 episode reward: -1.9751,                 loss: 0.4467
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4894s / 29.8517 s
agent0:                 episode reward: 1.1812,                 loss: nan
agent1:                 episode reward: -1.1812,                 loss: 0.4468
Episode: 671/10000 (6.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4877s / 30.3395 s
agent0:                 episode reward: 1.2600,                 loss: nan
agent1:                 episode reward: -1.2600,                 loss: 0.4363
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4887s / 30.8281 s
agent0:                 episode reward: -0.1850,                 loss: nan
agent1:                 episode reward: 0.1850,                 loss: 0.4248
Episode: 691/10000 (6.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4934s / 31.3215 s
agent0:                 episode reward: 1.1354,                 loss: nan
agent1:                 episode reward: -1.1354,                 loss: 0.4221
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5020s / 31.8236 s
agent0:                 episode reward: 0.4234,                 loss: nan
agent1:                 episode reward: -0.4234,                 loss: 0.4226
Episode: 711/10000 (7.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4953s / 32.3188 s
agent0:                 episode reward: 0.6767,                 loss: nan
agent1:                 episode reward: -0.6767,                 loss: 0.4198
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5059s / 32.8247 s
agent0:                 episode reward: 1.5604,                 loss: nan
agent1:                 episode reward: -1.5604,                 loss: 0.4203
Episode: 731/10000 (7.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4901s / 33.3148 s
agent0:                 episode reward: 0.6621,                 loss: nan
agent1:                 episode reward: -0.6621,                 loss: 0.4183
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5242s / 33.8390 s
agent0:                 episode reward: 1.5864,                 loss: nan
agent1:                 episode reward: -1.5864,                 loss: 0.4179
Episode: 751/10000 (7.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4992s / 34.3382 s
agent0:                 episode reward: 1.2829,                 loss: nan
agent1:                 episode reward: -1.2829,                 loss: 0.4172
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5173s / 34.8555 s
agent0:                 episode reward: 1.0071,                 loss: nan
agent1:                 episode reward: -1.0071,                 loss: 0.4180
Episode: 771/10000 (7.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5045s / 35.3600 s
agent0:                 episode reward: -0.1483,                 loss: nan
agent1:                 episode reward: 0.1483,                 loss: 0.3793
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5485s / 35.9085 s
agent0:                 episode reward: 0.9400,                 loss: nan
agent1:                 episode reward: -0.9400,                 loss: 0.3575
Episode: 791/10000 (7.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5019s / 36.4104 s
agent0:                 episode reward: 0.4709,                 loss: nan
agent1:                 episode reward: -0.4709,                 loss: 0.3555
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5176s / 36.9280 s
agent0:                 episode reward: 1.1811,                 loss: nan
agent1:                 episode reward: -1.1811,                 loss: 0.3507
Episode: 811/10000 (8.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4969s / 37.4249 s
agent0:                 episode reward: 0.3319,                 loss: nan
agent1:                 episode reward: -0.3319,                 loss: 0.3533
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5092s / 37.9341 s
agent0:                 episode reward: 0.6074,                 loss: nan
agent1:                 episode reward: -0.6074,                 loss: 0.3521
Episode: 831/10000 (8.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5138s / 38.4478 s
agent0:                 episode reward: 1.2479,                 loss: nan
agent1:                 episode reward: -1.2479,                 loss: 0.3474
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5170s / 38.9649 s
agent0:                 episode reward: 1.8517,                 loss: nan
agent1:                 episode reward: -1.8517,                 loss: 0.3452
Episode: 851/10000 (8.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5012s / 39.4661 s
agent0:                 episode reward: 0.6634,                 loss: nan
agent1:                 episode reward: -0.6634,                 loss: 0.3445
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4986s / 39.9647 s
agent0:                 episode reward: 1.1606,                 loss: nan
agent1:                 episode reward: -1.1606,                 loss: 0.3439
Episode: 871/10000 (8.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4985s / 40.4632 s
agent0:                 episode reward: 0.1364,                 loss: nan
agent1:                 episode reward: -0.1364,                 loss: 0.3090
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5077s / 40.9708 s
agent0:                 episode reward: 0.2468,                 loss: nan
agent1:                 episode reward: -0.2468,                 loss: 0.2945
Episode: 891/10000 (8.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5118s / 41.4826 s
agent0:                 episode reward: 0.6477,                 loss: nan
agent1:                 episode reward: -0.6477,                 loss: 0.2900
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5010s / 41.9837 s
agent0:                 episode reward: 1.3122,                 loss: nan
agent1:                 episode reward: -1.3122,                 loss: 0.2906
Episode: 911/10000 (9.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5155s / 42.4992 s
agent0:                 episode reward: 1.1239,                 loss: nan
agent1:                 episode reward: -1.1239,                 loss: 0.2888
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5362s / 43.0354 s
agent0:                 episode reward: 1.5400,                 loss: nan
agent1:                 episode reward: -1.5400,                 loss: 0.2824
Episode: 931/10000 (9.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5165s / 43.5519 s
agent0:                 episode reward: 1.3429,                 loss: nan
agent1:                 episode reward: -1.3429,                 loss: 0.2823
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5051s / 44.0570 s
agent0:                 episode reward: 0.6581,                 loss: nan
agent1:                 episode reward: -0.6581,                 loss: 0.2812
Episode: 951/10000 (9.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5229s / 44.5800 s
agent0:                 episode reward: 1.1101,                 loss: nan
agent1:                 episode reward: -1.1101,                 loss: 0.2788
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5164s / 45.0964 s
agent0:                 episode reward: 1.1922,                 loss: nan
agent1:                 episode reward: -1.1922,                 loss: 0.2782
Episode: 971/10000 (9.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5273s / 45.6237 s
agent0:                 episode reward: 0.3017,                 loss: nan
agent1:                 episode reward: -0.3017,                 loss: 0.2657
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5520s / 46.1757 s
agent0:                 episode reward: 0.9152,                 loss: nan
agent1:                 episode reward: -0.9152,                 loss: 0.2572
Episode: 991/10000 (9.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5187s / 46.6944 s
agent0:                 episode reward: 0.7178,                 loss: nan
agent1:                 episode reward: -0.7178,                 loss: 0.2544
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5379s / 47.2323 s
agent0:                 episode reward: 0.3860,                 loss: nan
agent1:                 episode reward: -0.3860,                 loss: 0.2529
Episode: 1011/10000 (10.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5163s / 47.7485 s
agent0:                 episode reward: 1.2519,                 loss: nan
agent1:                 episode reward: -1.2519,                 loss: 0.2524
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5045s / 48.2530 s
agent0:                 episode reward: -0.1567,                 loss: nan
agent1:                 episode reward: 0.1567,                 loss: 0.2518
Episode: 1031/10000 (10.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5012s / 48.7542 s
agent0:                 episode reward: 1.2018,                 loss: nan
agent1:                 episode reward: -1.2018,                 loss: 0.2512
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5115s / 49.2657 s
agent0:                 episode reward: 1.1207,                 loss: nan
agent1:                 episode reward: -1.1207,                 loss: 0.2502
Episode: 1051/10000 (10.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5125s / 49.7782 s
agent0:                 episode reward: 0.5326,                 loss: nan
agent1:                 episode reward: -0.5326,                 loss: 0.2499
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5209s / 50.2991 s
agent0:                 episode reward: 1.2512,                 loss: nan
agent1:                 episode reward: -1.2512,                 loss: 0.2473
Episode: 1071/10000 (10.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5121s / 50.8112 s
agent0:                 episode reward: 0.9517,                 loss: nan
agent1:                 episode reward: -0.9517,                 loss: 0.2501
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5335s / 51.3446 s
agent0:                 episode reward: 0.5485,                 loss: nan
agent1:                 episode reward: -0.5485,                 loss: 0.2535
Episode: 1091/10000 (10.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5209s / 51.8655 s
agent0:                 episode reward: 1.0120,                 loss: nan
agent1:                 episode reward: -1.0120,                 loss: 0.2511
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5038s / 52.3693 s
agent0:                 episode reward: 0.8546,                 loss: nan
agent1:                 episode reward: -0.8546,                 loss: 0.2490
Episode: 1111/10000 (11.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5108s / 52.8801 s
agent0:                 episode reward: 1.0050,                 loss: nan
agent1:                 episode reward: -1.0050,                 loss: 0.2469
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5242s / 53.4043 s
agent0:                 episode reward: 0.8010,                 loss: nan
agent1:                 episode reward: -0.8010,                 loss: 0.2493
Episode: 1131/10000 (11.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5104s / 53.9147 s
agent0:                 episode reward: 1.3157,                 loss: nan
agent1:                 episode reward: -1.3157,                 loss: 0.2462
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5186s / 54.4333 s
agent0:                 episode reward: 1.5314,                 loss: nan
agent1:                 episode reward: -1.5314,                 loss: 0.2464
Episode: 1151/10000 (11.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5040s / 54.9373 s
agent0:                 episode reward: 2.1350,                 loss: nan
agent1:                 episode reward: -2.1350,                 loss: 0.2460
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5126s / 55.4499 s
agent0:                 episode reward: 1.3345,                 loss: nan
agent1:                 episode reward: -1.3345,                 loss: 0.2466
Episode: 1171/10000 (11.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5153s / 55.9652 s
agent0:                 episode reward: 0.4675,                 loss: nan
agent1:                 episode reward: -0.4675,                 loss: 0.2582
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5727s / 56.5379 s
agent0:                 episode reward: 0.5690,                 loss: nan
agent1:                 episode reward: -0.5690,                 loss: 0.2620
Episode: 1191/10000 (11.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5062s / 57.0440 s
agent0:                 episode reward: 1.0788,                 loss: nan
agent1:                 episode reward: -1.0788,                 loss: 0.2623
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5072s / 57.5513 s
agent0:                 episode reward: 1.8826,                 loss: nan
agent1:                 episode reward: -1.8826,                 loss: 0.2622
Episode: 1211/10000 (12.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5145s / 58.0658 s
agent0:                 episode reward: 1.4484,                 loss: nan
agent1:                 episode reward: -1.4484,                 loss: 0.2582
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5191s / 58.5849 s
agent0:                 episode reward: 1.7435,                 loss: nan
agent1:                 episode reward: -1.7435,                 loss: 0.2594
Episode: 1231/10000 (12.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5099s / 59.0948 s
agent0:                 episode reward: 0.7877,                 loss: nan
agent1:                 episode reward: -0.7877,                 loss: 0.2616
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5441s / 59.6390 s
agent0:                 episode reward: 0.9009,                 loss: nan
agent1:                 episode reward: -0.9009,                 loss: 0.2596
Episode: 1251/10000 (12.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5221s / 60.1611 s
agent0:                 episode reward: 0.1681,                 loss: nan
agent1:                 episode reward: -0.1681,                 loss: 0.2614
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5194s / 60.6805 s
agent0:                 episode reward: 0.9216,                 loss: nan
agent1:                 episode reward: -0.9216,                 loss: 0.2617
Episode: 1271/10000 (12.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5092s / 61.1897 s
agent0:                 episode reward: 1.1397,                 loss: nan
agent1:                 episode reward: -1.1397,                 loss: 0.2771
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5127s / 61.7024 s
agent0:                 episode reward: 0.8149,                 loss: nan
agent1:                 episode reward: -0.8149,                 loss: 0.2821
Episode: 1291/10000 (12.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5248s / 62.2272 s
agent0:                 episode reward: 2.0647,                 loss: nan
agent1:                 episode reward: -2.0647,                 loss: 0.2808
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5330s / 62.7602 s
agent0:                 episode reward: 0.4721,                 loss: nan
agent1:                 episode reward: -0.4721,                 loss: 0.2785
Episode: 1311/10000 (13.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5209s / 63.2811 s
agent0:                 episode reward: 1.5836,                 loss: nan
agent1:                 episode reward: -1.5836,                 loss: 0.2770
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5167s / 63.7978 s
agent0:                 episode reward: 0.6513,                 loss: nan
agent1:                 episode reward: -0.6513,                 loss: 0.2787
Episode: 1331/10000 (13.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5218s / 64.3196 s
agent0:                 episode reward: 0.2605,                 loss: nan
agent1:                 episode reward: -0.2605,                 loss: 0.2784
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5154s / 64.8350 s
agent0:                 episode reward: 1.9736,                 loss: nan
agent1:                 episode reward: -1.9736,                 loss: 0.2790
Episode: 1351/10000 (13.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5127s / 65.3478 s
agent0:                 episode reward: 0.0517,                 loss: nan
agent1:                 episode reward: -0.0517,                 loss: 0.2772
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5101s / 65.8579 s
agent0:                 episode reward: 0.7190,                 loss: nan
agent1:                 episode reward: -0.7190,                 loss: 0.2777
Episode: 1371/10000 (13.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5457s / 66.4036 s
agent0:                 episode reward: 0.8473,                 loss: nan
agent1:                 episode reward: -0.8473,                 loss: 0.3003
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5478s / 66.9514 s
agent0:                 episode reward: 1.5819,                 loss: nan
agent1:                 episode reward: -1.5819,                 loss: 0.3027
Episode: 1391/10000 (13.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5326s / 67.4839 s
agent0:                 episode reward: -0.5551,                 loss: nan
agent1:                 episode reward: 0.5551,                 loss: 0.3046
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5656s / 68.0496 s
agent0:                 episode reward: 0.8239,                 loss: nan
agent1:                 episode reward: -0.8239,                 loss: 0.3065
Episode: 1411/10000 (14.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5927s / 68.6423 s
agent0:                 episode reward: 0.1259,                 loss: nan
agent1:                 episode reward: -0.1259,                 loss: 0.3051
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5459s / 69.1882 s
agent0:                 episode reward: 1.2777,                 loss: nan
agent1:                 episode reward: -1.2777,                 loss: 0.3039
Episode: 1431/10000 (14.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5794s / 69.7676 s
agent0:                 episode reward: 0.3827,                 loss: nan
agent1:                 episode reward: -0.3827,                 loss: 0.3057
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5916s / 70.3592 s
agent0:                 episode reward: 1.0252,                 loss: nan
agent1:                 episode reward: -1.0252,                 loss: 0.3050
Episode: 1451/10000 (14.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5840s / 70.9432 s
agent0:                 episode reward: 0.1789,                 loss: nan
agent1:                 episode reward: -0.1789,                 loss: 0.3020
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5620s / 71.5052 s
agent0:                 episode reward: 1.1741,                 loss: nan
agent1:                 episode reward: -1.1741,                 loss: 0.3009
Episode: 1471/10000 (14.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5260s / 72.0312 s
agent0:                 episode reward: 0.7773,                 loss: nan
agent1:                 episode reward: -0.7773,                 loss: 0.3238
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6074s / 72.6386 s
agent0:                 episode reward: 1.3965,                 loss: nan
agent1:                 episode reward: -1.3965,                 loss: 0.3288
Episode: 1491/10000 (14.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5889s / 73.2275 s
agent0:                 episode reward: 1.0557,                 loss: nan
agent1:                 episode reward: -1.0557,                 loss: 0.3270
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5760s / 73.8035 s
agent0:                 episode reward: 1.0910,                 loss: nan
agent1:                 episode reward: -1.0910,                 loss: 0.3284
Episode: 1511/10000 (15.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5802s / 74.3837 s
agent0:                 episode reward: 1.5598,                 loss: nan
agent1:                 episode reward: -1.5598,                 loss: 0.3264
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5813s / 74.9650 s
agent0:                 episode reward: 0.9473,                 loss: nan
agent1:                 episode reward: -0.9473,                 loss: 0.3233
Episode: 1531/10000 (15.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5738s / 75.5388 s
agent0:                 episode reward: 0.6596,                 loss: nan
agent1:                 episode reward: -0.6596,                 loss: 0.3272
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5795s / 76.1182 s
agent0:                 episode reward: 0.1674,                 loss: nan
agent1:                 episode reward: -0.1674,                 loss: 0.3275
Episode: 1551/10000 (15.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6708s / 76.7890 s
agent0:                 episode reward: 1.6746,                 loss: nan
agent1:                 episode reward: -1.6746,                 loss: 0.3255
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5899s / 77.3789 s
agent0:                 episode reward: 1.2470,                 loss: nan
agent1:                 episode reward: -1.2470,                 loss: 0.3239
Episode: 1571/10000 (15.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5896s / 77.9684 s
agent0:                 episode reward: 0.9879,                 loss: nan
agent1:                 episode reward: -0.9879,                 loss: 0.3326
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5743s / 78.5427 s
agent0:                 episode reward: 0.6206,                 loss: nan
agent1:                 episode reward: -0.6206,                 loss: 0.3287
Episode: 1591/10000 (15.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5797s / 79.1224 s
agent0:                 episode reward: 1.0367,                 loss: nan
agent1:                 episode reward: -1.0367,                 loss: 0.3291
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5781s / 79.7005 s
agent0:                 episode reward: 0.8380,                 loss: nan
agent1:                 episode reward: -0.8380,                 loss: 0.3306
Episode: 1611/10000 (16.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5949s / 80.2954 s
agent0:                 episode reward: 0.7868,                 loss: nan
agent1:                 episode reward: -0.7868,                 loss: 0.3274
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6063s / 80.9018 s
agent0:                 episode reward: 0.3027,                 loss: nan
agent1:                 episode reward: -0.3027,                 loss: 0.3299
Episode: 1631/10000 (16.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5818s / 81.4835 s
agent0:                 episode reward: 0.5676,                 loss: nan
agent1:                 episode reward: -0.5676,                 loss: 0.3261
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5854s / 82.0690 s
agent0:                 episode reward: 0.4727,                 loss: nan
agent1:                 episode reward: -0.4727,                 loss: 0.3277
Episode: 1651/10000 (16.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5802s / 82.6491 s
agent0:                 episode reward: 1.2807,                 loss: nan
agent1:                 episode reward: -1.2807,                 loss: 0.3286
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6012s / 83.2503 s
agent0:                 episode reward: 1.1458,                 loss: nan
agent1:                 episode reward: -1.1458,                 loss: 0.3254
Episode: 1671/10000 (16.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5933s / 83.8436 s
agent0:                 episode reward: 2.1554,                 loss: nan
agent1:                 episode reward: -2.1554,                 loss: 0.3391
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5832s / 84.4268 s
agent0:                 episode reward: 0.6334,                 loss: nan
agent1:                 episode reward: -0.6334,                 loss: 0.3347
Episode: 1691/10000 (16.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6053s / 85.0321 s
agent0:                 episode reward: 0.2992,                 loss: nan
agent1:                 episode reward: -0.2992,                 loss: 0.3345
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5899s / 85.6219 s
agent0:                 episode reward: 2.0570,                 loss: nan
agent1:                 episode reward: -2.0570,                 loss: 0.3330
Episode: 1711/10000 (17.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5917s / 86.2136 s
agent0:                 episode reward: 0.7821,                 loss: nan
agent1:                 episode reward: -0.7821,                 loss: 0.3341
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5970s / 86.8106 s
agent0:                 episode reward: 0.8294,                 loss: nan
agent1:                 episode reward: -0.8294,                 loss: 0.3318
Episode: 1731/10000 (17.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6565s / 87.4671 s
agent0:                 episode reward: -0.0225,                 loss: nan
agent1:                 episode reward: 0.0225,                 loss: 0.3318
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5953s / 88.0624 s
agent0:                 episode reward: 0.4038,                 loss: nan
agent1:                 episode reward: -0.4038,                 loss: 0.3300
Episode: 1751/10000 (17.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5902s / 88.6525 s
agent0:                 episode reward: 1.0132,                 loss: nan
agent1:                 episode reward: -1.0132,                 loss: 0.3298
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5905s / 89.2430 s
agent0:                 episode reward: 1.5486,                 loss: nan
agent1:                 episode reward: -1.5486,                 loss: 0.3305
Episode: 1771/10000 (17.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5977s / 89.8407 s
agent0:                 episode reward: 0.9008,                 loss: nan
agent1:                 episode reward: -0.9008,                 loss: 0.3419
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5916s / 90.4323 s
agent0:                 episode reward: 0.7364,                 loss: nan
agent1:                 episode reward: -0.7364,                 loss: 0.3462
Episode: 1791/10000 (17.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5925s / 91.0248 s
agent0:                 episode reward: 1.4006,                 loss: nan
agent1:                 episode reward: -1.4006,                 loss: 0.3439
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5953s / 91.6201 s
agent0:                 episode reward: 0.2552,                 loss: nan
agent1:                 episode reward: -0.2552,                 loss: 0.3415
Episode: 1811/10000 (18.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5918s / 92.2119 s
agent0:                 episode reward: 1.2102,                 loss: nan
agent1:                 episode reward: -1.2102,                 loss: 0.3412
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6210s / 92.8329 s
agent0:                 episode reward: 0.0706,                 loss: nan
agent1:                 episode reward: -0.0706,                 loss: 0.3405
Episode: 1831/10000 (18.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6059s / 93.4388 s
agent0:                 episode reward: 0.8593,                 loss: nan
agent1:                 episode reward: -0.8593,                 loss: 0.3399
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5949s / 94.0337 s
agent0:                 episode reward: 1.1196,                 loss: nan
agent1:                 episode reward: -1.1196,                 loss: 0.3389
Episode: 1851/10000 (18.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5907s / 94.6244 s
agent0:                 episode reward: 0.9476,                 loss: nan
agent1:                 episode reward: -0.9476,                 loss: 0.3380
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6005s / 95.2249 s
agent0:                 episode reward: 0.7218,                 loss: nan
agent1:                 episode reward: -0.7218,                 loss: 0.3389
Episode: 1871/10000 (18.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6109s / 95.8358 s
agent0:                 episode reward: 0.0447,                 loss: nan
agent1:                 episode reward: -0.0447,                 loss: 0.3597
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5954s / 96.4312 s
agent0:                 episode reward: 1.2766,                 loss: nan
agent1:                 episode reward: -1.2766,                 loss: 0.3684
Episode: 1891/10000 (18.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6180s / 97.0492 s
agent0:                 episode reward: 1.5008,                 loss: nan
agent1:                 episode reward: -1.5008,                 loss: 0.3668
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6647s / 97.7139 s
agent0:                 episode reward: 1.0885,                 loss: nan
agent1:                 episode reward: -1.0885,                 loss: 0.3647
Episode: 1911/10000 (19.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5966s / 98.3105 s
agent0:                 episode reward: 0.4624,                 loss: nan
agent1:                 episode reward: -0.4624,                 loss: 0.3639
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6065s / 98.9171 s
agent0:                 episode reward: 0.0781,                 loss: nan
agent1:                 episode reward: -0.0781,                 loss: 0.3656
Episode: 1931/10000 (19.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6004s / 99.5175 s
agent0:                 episode reward: 0.3876,                 loss: nan
agent1:                 episode reward: -0.3876,                 loss: 0.3649
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5992s / 100.1167 s
agent0:                 episode reward: 1.7589,                 loss: nan
agent1:                 episode reward: -1.7589,                 loss: 0.3636
Episode: 1951/10000 (19.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5935s / 100.7102 s
agent0:                 episode reward: 0.8292,                 loss: nan
agent1:                 episode reward: -0.8292,                 loss: 0.3628
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6219s / 101.3321 s
agent0:                 episode reward: 0.2772,                 loss: nan
agent1:                 episode reward: -0.2772,                 loss: 0.3638
Episode: 1971/10000 (19.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6059s / 101.9381 s
agent0:                 episode reward: 0.9483,                 loss: nan
agent1:                 episode reward: -0.9483,                 loss: 0.3917
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5994s / 102.5374 s
agent0:                 episode reward: 1.4025,                 loss: nan
agent1:                 episode reward: -1.4025,                 loss: 0.4018
Episode: 1991/10000 (19.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5991s / 103.1365 s
agent0:                 episode reward: 1.1410,                 loss: nan
agent1:                 episode reward: -1.1410,                 loss: 0.4022
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6158s / 103.7523 s
agent0:                 episode reward: 1.2224,                 loss: nan
agent1:                 episode reward: -1.2224,                 loss: 0.4015
Episode: 2011/10000 (20.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5994s / 104.3516 s
agent0:                 episode reward: 0.4064,                 loss: nan
agent1:                 episode reward: -0.4064,                 loss: 0.4016
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6072s / 104.9588 s
agent0:                 episode reward: 0.1784,                 loss: nan
agent1:                 episode reward: -0.1784,                 loss: 0.4014
Episode: 2031/10000 (20.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5992s / 105.5580 s
agent0:                 episode reward: -0.1444,                 loss: nan
agent1:                 episode reward: 0.1444,                 loss: 0.4005
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6021s / 106.1602 s
agent0:                 episode reward: 0.6098,                 loss: nan
agent1:                 episode reward: -0.6098,                 loss: 0.3992
Episode: 2051/10000 (20.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5970s / 106.7572 s
agent0:                 episode reward: 2.1244,                 loss: nan
agent1:                 episode reward: -2.1244,                 loss: 0.3990
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6015s / 107.3587 s
agent0:                 episode reward: 0.4357,                 loss: nan
agent1:                 episode reward: -0.4357,                 loss: 0.4001
Episode: 2071/10000 (20.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6850s / 108.0437 s
agent0:                 episode reward: 1.5737,                 loss: nan
agent1:                 episode reward: -1.5737,                 loss: 0.4184
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6021s / 108.6458 s
agent0:                 episode reward: 1.7677,                 loss: nan
agent1:                 episode reward: -1.7677,                 loss: 0.4197
Episode: 2091/10000 (20.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5986s / 109.2444 s
agent0:                 episode reward: 0.3890,                 loss: nan
agent1:                 episode reward: -0.3890,                 loss: 0.4179
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6203s / 109.8646 s
agent0:                 episode reward: 1.2925,                 loss: nan
agent1:                 episode reward: -1.2925,                 loss: 0.4161
Episode: 2111/10000 (21.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6004s / 110.4650 s
agent0:                 episode reward: 0.0681,                 loss: nan
agent1:                 episode reward: -0.0681,                 loss: 0.4163
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6176s / 111.0826 s
agent0:                 episode reward: 0.7378,                 loss: nan
agent1:                 episode reward: -0.7378,                 loss: 0.4156
Episode: 2131/10000 (21.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5994s / 111.6820 s
agent0:                 episode reward: 0.3276,                 loss: nan
agent1:                 episode reward: -0.3276,                 loss: 0.4150
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6052s / 112.2872 s
agent0:                 episode reward: 1.1316,                 loss: nan
agent1:                 episode reward: -1.1316,                 loss: 0.4145
Episode: 2151/10000 (21.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6054s / 112.8926 s
agent0:                 episode reward: 0.9760,                 loss: nan
agent1:                 episode reward: -0.9760,                 loss: 0.4136
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6178s / 113.5104 s
agent0:                 episode reward: -0.1338,                 loss: nan
agent1:                 episode reward: 0.1338,                 loss: 0.4133
Episode: 2171/10000 (21.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6113s / 114.1217 s
agent0:                 episode reward: 0.6074,                 loss: nan
agent1:                 episode reward: -0.6074,                 loss: 0.3818
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6053s / 114.7270 s
agent0:                 episode reward: 0.2800,                 loss: nan
agent1:                 episode reward: -0.2800,                 loss: 0.3466
Episode: 2191/10000 (21.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6052s / 115.3322 s
agent0:                 episode reward: 0.9094,                 loss: nan
agent1:                 episode reward: -0.9094,                 loss: 0.3460
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6006s / 115.9328 s
agent0:                 episode reward: 1.1670,                 loss: nan
agent1:                 episode reward: -1.1670,                 loss: 0.3435
Episode: 2211/10000 (22.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6025s / 116.5354 s
agent0:                 episode reward: -0.4378,                 loss: nan
agent1:                 episode reward: 0.4378,                 loss: 0.3445
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6703s / 117.2056 s
agent0:                 episode reward: -0.3671,                 loss: nan
agent1:                 episode reward: 0.3671,                 loss: 0.3451
Episode: 2231/10000 (22.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7178s / 117.9234 s
agent0:                 episode reward: 0.9998,                 loss: nan
agent1:                 episode reward: -0.9998,                 loss: 0.3445
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6108s / 118.5342 s
agent0:                 episode reward: 1.3409,                 loss: nan
agent1:                 episode reward: -1.3409,                 loss: 0.3449
Episode: 2251/10000 (22.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6096s / 119.1438 s
agent0:                 episode reward: 0.7234,                 loss: nan
agent1:                 episode reward: -0.7234,                 loss: 0.3414
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6160s / 119.7598 s
agent0:                 episode reward: 1.6967,                 loss: nan
agent1:                 episode reward: -1.6967,                 loss: 0.3444
Episode: 2271/10000 (22.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6165s / 120.3763 s
agent0:                 episode reward: 2.2846,                 loss: nan
agent1:                 episode reward: -2.2846,                 loss: 0.2807
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6169s / 120.9932 s
agent0:                 episode reward: 1.5730,                 loss: nan
agent1:                 episode reward: -1.5730,                 loss: 0.2409
Episode: 2291/10000 (22.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6086s / 121.6018 s
agent0:                 episode reward: 0.2808,                 loss: nan
agent1:                 episode reward: -0.2808,                 loss: 0.2370
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6107s / 122.2125 s
agent0:                 episode reward: 1.2061,                 loss: nan
agent1:                 episode reward: -1.2061,                 loss: 0.2365
Episode: 2311/10000 (23.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6175s / 122.8300 s
agent0:                 episode reward: 0.5636,                 loss: nan
agent1:                 episode reward: -0.5636,                 loss: 0.2386
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6176s / 123.4476 s
agent0:                 episode reward: 1.3097,                 loss: nan
agent1:                 episode reward: -1.3097,                 loss: 0.2383
Episode: 2331/10000 (23.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6236s / 124.0711 s
agent0:                 episode reward: 0.9535,                 loss: nan
agent1:                 episode reward: -0.9535,                 loss: 0.2359
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6112s / 124.6824 s
agent0:                 episode reward: 0.8827,                 loss: nan
agent1:                 episode reward: -0.8827,                 loss: 0.2374
Episode: 2351/10000 (23.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6169s / 125.2992 s
agent0:                 episode reward: 0.8233,                 loss: nan
agent1:                 episode reward: -0.8233,                 loss: 0.2389
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6366s / 125.9358 s
agent0:                 episode reward: 0.2845,                 loss: nan
agent1:                 episode reward: -0.2845,                 loss: 0.2364
Episode: 2371/10000 (23.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6404s / 126.5763 s
agent0:                 episode reward: 1.6810,                 loss: nan
agent1:                 episode reward: -1.6810,                 loss: 0.2246
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6223s / 127.1986 s
agent0:                 episode reward: 0.9647,                 loss: nan
agent1:                 episode reward: -0.9647,                 loss: 0.2149
Episode: 2391/10000 (23.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6137s / 127.8123 s
agent0:                 episode reward: 1.7858,                 loss: nan
agent1:                 episode reward: -1.7858,                 loss: 0.2150
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6857s / 128.4980 s
agent0:                 episode reward: 0.0877,                 loss: nan
agent1:                 episode reward: -0.0877,                 loss: 0.2132
Episode: 2411/10000 (24.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6347s / 129.1327 s
agent0:                 episode reward: 1.7469,                 loss: nan
agent1:                 episode reward: -1.7469,                 loss: 0.2118
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6163s / 129.7490 s
agent0:                 episode reward: 1.5706,                 loss: nan
agent1:                 episode reward: -1.5706,                 loss: 0.2138
Episode: 2431/10000 (24.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6202s / 130.3692 s
agent0:                 episode reward: 1.0997,                 loss: nan
agent1:                 episode reward: -1.0997,                 loss: 0.2131
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6146s / 130.9838 s
agent0:                 episode reward: 1.4469,                 loss: nan
agent1:                 episode reward: -1.4469,                 loss: 0.2122
Episode: 2451/10000 (24.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6219s / 131.6056 s
agent0:                 episode reward: 1.4455,                 loss: nan
agent1:                 episode reward: -1.4455,                 loss: 0.2137
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6283s / 132.2339 s
agent0:                 episode reward: 0.3766,                 loss: nan
agent1:                 episode reward: -0.3766,                 loss: 0.2148
Episode: 2471/10000 (24.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6413s / 132.8753 s
agent0:                 episode reward: 0.2484,                 loss: nan
agent1:                 episode reward: -0.2484,                 loss: 0.2291
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6197s / 133.4949 s
agent0:                 episode reward: 0.5435,                 loss: nan
agent1:                 episode reward: -0.5435,                 loss: 0.2306
Episode: 2491/10000 (24.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6427s / 134.1376 s
agent0:                 episode reward: 1.1387,                 loss: nan
agent1:                 episode reward: -1.1387,                 loss: 0.2293
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6866s / 134.8242 s
agent0:                 episode reward: 0.0842,                 loss: nan
agent1:                 episode reward: -0.0842,                 loss: 0.2325
Episode: 2511/10000 (25.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6276s / 135.4518 s
agent0:                 episode reward: 1.6405,                 loss: nan
agent1:                 episode reward: -1.6405,                 loss: 0.2295
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6239s / 136.0757 s
agent0:                 episode reward: 0.4662,                 loss: nan
agent1:                 episode reward: -0.4662,                 loss: 0.2286
Episode: 2531/10000 (25.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6259s / 136.7016 s
agent0:                 episode reward: 0.9098,                 loss: nan
agent1:                 episode reward: -0.9098,                 loss: 0.2300
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6189s / 137.3205 s
agent0:                 episode reward: 1.5321,                 loss: nan
agent1:                 episode reward: -1.5321,                 loss: 0.2298
Episode: 2551/10000 (25.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6256s / 137.9461 s
agent0:                 episode reward: 1.3093,                 loss: nan
agent1:                 episode reward: -1.3093,                 loss: 0.2308
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7273s / 138.6734 s
agent0:                 episode reward: 1.2583,                 loss: nan
agent1:                 episode reward: -1.2583,                 loss: 0.2315
Episode: 2571/10000 (25.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6277s / 139.3011 s
agent0:                 episode reward: 1.9150,                 loss: nan
agent1:                 episode reward: -1.9150,                 loss: 0.2581
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6338s / 139.9349 s
agent0:                 episode reward: 0.6716,                 loss: nan
agent1:                 episode reward: -0.6716,                 loss: 0.2639
Episode: 2591/10000 (25.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6327s / 140.5675 s
agent0:                 episode reward: 1.0200,                 loss: nan
agent1:                 episode reward: -1.0200,                 loss: 0.2641
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6522s / 141.2198 s
agent0:                 episode reward: 0.6443,                 loss: nan
agent1:                 episode reward: -0.6443,                 loss: 0.2655
Episode: 2611/10000 (26.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6337s / 141.8535 s
agent0:                 episode reward: 1.6806,                 loss: nan
agent1:                 episode reward: -1.6806,                 loss: 0.2657
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6623s / 142.5158 s
agent0:                 episode reward: 0.8906,                 loss: nan
agent1:                 episode reward: -0.8906,                 loss: 0.2637
Episode: 2631/10000 (26.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6635s / 143.1793 s
agent0:                 episode reward: 1.4864,                 loss: nan
agent1:                 episode reward: -1.4864,                 loss: 0.2638
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6453s / 143.8245 s
agent0:                 episode reward: 1.2972,                 loss: nan
agent1:                 episode reward: -1.2972,                 loss: 0.2641
Episode: 2651/10000 (26.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6454s / 144.4699 s
agent0:                 episode reward: 1.2852,                 loss: nan
agent1:                 episode reward: -1.2852,                 loss: 0.2635
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6360s / 145.1059 s
agent0:                 episode reward: 0.4108,                 loss: nan
agent1:                 episode reward: -0.4108,                 loss: 0.2647
Episode: 2671/10000 (26.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6337s / 145.7396 s
agent0:                 episode reward: 1.3661,                 loss: nan
agent1:                 episode reward: -1.3661,                 loss: 0.2941
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6411s / 146.3807 s
agent0:                 episode reward: 0.0267,                 loss: nan
agent1:                 episode reward: -0.0267,                 loss: 0.2982
Episode: 2691/10000 (26.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6544s / 147.0350 s
agent0:                 episode reward: 0.5051,                 loss: nan
agent1:                 episode reward: -0.5051,                 loss: 0.2946
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6376s / 147.6727 s
agent0:                 episode reward: -0.3529,                 loss: nan
agent1:                 episode reward: 0.3529,                 loss: 0.2941
Episode: 2711/10000 (27.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6408s / 148.3134 s
agent0:                 episode reward: 0.3732,                 loss: nan
agent1:                 episode reward: -0.3732,                 loss: 0.2945
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7104s / 149.0239 s
agent0:                 episode reward: 0.6008,                 loss: nan
agent1:                 episode reward: -0.6008,                 loss: 0.2913
Episode: 2731/10000 (27.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6510s / 149.6748 s
agent0:                 episode reward: 1.3483,                 loss: nan
agent1:                 episode reward: -1.3483,                 loss: 0.2924
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6598s / 150.3346 s
agent0:                 episode reward: 0.5509,                 loss: nan
agent1:                 episode reward: -0.5509,                 loss: 0.2941
Episode: 2751/10000 (27.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6637s / 150.9983 s
agent0:                 episode reward: 0.2670,                 loss: nan
agent1:                 episode reward: -0.2670,                 loss: 0.2915
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6536s / 151.6518 s
agent0:                 episode reward: 2.0800,                 loss: nan
agent1:                 episode reward: -2.0800,                 loss: 0.2948
Episode: 2771/10000 (27.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6392s / 152.2911 s
agent0:                 episode reward: 1.0839,                 loss: nan
agent1:                 episode reward: -1.0839,                 loss: 0.3221
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6508s / 152.9418 s
agent0:                 episode reward: 1.3478,                 loss: nan
agent1:                 episode reward: -1.3478,                 loss: 0.3177
Episode: 2791/10000 (27.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6364s / 153.5783 s
agent0:                 episode reward: 0.8047,                 loss: nan
agent1:                 episode reward: -0.8047,                 loss: 0.3164
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6561s / 154.2344 s
agent0:                 episode reward: 1.2696,                 loss: nan
agent1:                 episode reward: -1.2696,                 loss: 0.3159
Episode: 2811/10000 (28.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6439s / 154.8783 s
agent0:                 episode reward: 0.9625,                 loss: nan
agent1:                 episode reward: -0.9625,                 loss: 0.3149
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6465s / 155.5248 s
agent0:                 episode reward: 0.6293,                 loss: nan
agent1:                 episode reward: -0.6293,                 loss: 0.3149
Episode: 2831/10000 (28.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6659s / 156.1907 s
agent0:                 episode reward: 0.2375,                 loss: nan
agent1:                 episode reward: -0.2375,                 loss: 0.3129
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6392s / 156.8299 s
agent0:                 episode reward: 1.0475,                 loss: nan
agent1:                 episode reward: -1.0475,                 loss: 0.3116
Episode: 2851/10000 (28.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6512s / 157.4811 s
agent0:                 episode reward: 0.2207,                 loss: nan
agent1:                 episode reward: -0.2207,                 loss: 0.3107
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6503s / 158.1314 s
agent0:                 episode reward: 0.9106,                 loss: nan
agent1:                 episode reward: -0.9106,                 loss: 0.3111
Episode: 2871/10000 (28.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6752s / 158.8066 s
agent0:                 episode reward: 0.5861,                 loss: nan
agent1:                 episode reward: -0.5861,                 loss: 0.3230
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7202s / 159.5268 s
agent0:                 episode reward: 1.4619,                 loss: nan
agent1:                 episode reward: -1.4619,                 loss: 0.3109
Episode: 2891/10000 (28.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6459s / 160.1727 s
agent0:                 episode reward: 1.1550,                 loss: nan
agent1:                 episode reward: -1.1550,                 loss: 0.3073
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6541s / 160.8268 s
agent0:                 episode reward: 1.8479,                 loss: nan
agent1:                 episode reward: -1.8479,                 loss: 0.3072
Episode: 2911/10000 (29.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6471s / 161.4738 s
agent0:                 episode reward: 0.2595,                 loss: nan
agent1:                 episode reward: -0.2595,                 loss: 0.3064
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6606s / 162.1344 s
agent0:                 episode reward: 1.0420,                 loss: nan
agent1:                 episode reward: -1.0420,                 loss: 0.3047
Episode: 2931/10000 (29.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6525s / 162.7870 s
agent0:                 episode reward: 1.1140,                 loss: nan
agent1:                 episode reward: -1.1140,                 loss: 0.3046
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6514s / 163.4384 s
agent0:                 episode reward: 1.1157,                 loss: nan
agent1:                 episode reward: -1.1157,                 loss: 0.3040
Episode: 2951/10000 (29.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6510s / 164.0894 s
agent0:                 episode reward: 1.3166,                 loss: nan
agent1:                 episode reward: -1.3166,                 loss: 0.3049
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6609s / 164.7503 s
agent0:                 episode reward: 0.0658,                 loss: nan
agent1:                 episode reward: -0.0658,                 loss: 0.3041
Episode: 2971/10000 (29.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6591s / 165.4094 s
agent0:                 episode reward: 0.7783,                 loss: nan
agent1:                 episode reward: -0.7783,                 loss: 0.3267
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6544s / 166.0637 s
agent0:                 episode reward: 2.1005,                 loss: nan
agent1:                 episode reward: -2.1005,                 loss: 0.3303
Episode: 2991/10000 (29.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6552s / 166.7190 s
agent0:                 episode reward: 0.4763,                 loss: nan
agent1:                 episode reward: -0.4763,                 loss: 0.3288
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6730s / 167.3920 s
agent0:                 episode reward: 0.4055,                 loss: nan
agent1:                 episode reward: -0.4055,                 loss: 0.3283
Episode: 3011/10000 (30.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6642s / 168.0562 s
agent0:                 episode reward: 0.4227,                 loss: nan
agent1:                 episode reward: -0.4227,                 loss: 0.3280
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6586s / 168.7148 s
agent0:                 episode reward: 0.0219,                 loss: nan
agent1:                 episode reward: -0.0219,                 loss: 0.3288
Episode: 3031/10000 (30.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7375s / 169.4523 s
agent0:                 episode reward: 0.6372,                 loss: nan
agent1:                 episode reward: -0.6372,                 loss: 0.3267
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6745s / 170.1268 s
agent0:                 episode reward: 0.2820,                 loss: nan
agent1:                 episode reward: -0.2820,                 loss: 0.3278
Episode: 3051/10000 (30.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6647s / 170.7915 s
agent0:                 episode reward: 1.6180,                 loss: nan
agent1:                 episode reward: -1.6180,                 loss: 0.3253
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6647s / 171.4562 s
agent0:                 episode reward: 0.4747,                 loss: nan
agent1:                 episode reward: -0.4747,                 loss: 0.3262
Episode: 3071/10000 (30.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6581s / 172.1144 s
agent0:                 episode reward: 1.3447,                 loss: nan
agent1:                 episode reward: -1.3447,                 loss: 0.3732
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6520s / 172.7664 s
agent0:                 episode reward: 0.9849,                 loss: nan
agent1:                 episode reward: -0.9849,                 loss: 0.3855
Episode: 3091/10000 (30.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6619s / 173.4283 s
agent0:                 episode reward: 0.9589,                 loss: nan
agent1:                 episode reward: -0.9589,                 loss: 0.3819
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6845s / 174.1128 s
agent0:                 episode reward: 0.7325,                 loss: nan
agent1:                 episode reward: -0.7325,                 loss: 0.3832
Episode: 3111/10000 (31.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6770s / 174.7898 s
agent0:                 episode reward: 1.2419,                 loss: nan
agent1:                 episode reward: -1.2419,                 loss: 0.3819
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6622s / 175.4519 s
agent0:                 episode reward: 0.1282,                 loss: nan
agent1:                 episode reward: -0.1282,                 loss: 0.3819
Episode: 3131/10000 (31.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7157s / 176.1676 s
agent0:                 episode reward: 1.6261,                 loss: nan
agent1:                 episode reward: -1.6261,                 loss: 0.3820
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6683s / 176.8360 s
agent0:                 episode reward: 1.5165,                 loss: nan
agent1:                 episode reward: -1.5165,                 loss: 0.3808
Episode: 3151/10000 (31.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6777s / 177.5136 s
agent0:                 episode reward: -0.1730,                 loss: nan
agent1:                 episode reward: 0.1730,                 loss: 0.3802
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6662s / 178.1799 s
agent0:                 episode reward: 0.8499,                 loss: nan
agent1:                 episode reward: -0.8499,                 loss: 0.3807
Episode: 3171/10000 (31.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6630s / 178.8429 s
agent0:                 episode reward: 0.0518,                 loss: nan
agent1:                 episode reward: -0.0518,                 loss: 0.3941
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7393s / 179.5822 s
agent0:                 episode reward: 1.0962,                 loss: nan
agent1:                 episode reward: -1.0962,                 loss: 0.3783
Episode: 3191/10000 (31.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6680s / 180.2502 s
agent0:                 episode reward: -0.1711,                 loss: nan
agent1:                 episode reward: 0.1711,                 loss: 0.3771
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6632s / 180.9135 s
agent0:                 episode reward: 1.5607,                 loss: nan
agent1:                 episode reward: -1.5607,                 loss: 0.3792
Episode: 3211/10000 (32.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6644s / 181.5779 s
agent0:                 episode reward: 1.0429,                 loss: nan
agent1:                 episode reward: -1.0429,                 loss: 0.3791
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6638s / 182.2417 s
agent0:                 episode reward: -0.0084,                 loss: nan
agent1:                 episode reward: 0.0084,                 loss: 0.3773
Episode: 3231/10000 (32.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6786s / 182.9203 s
agent0:                 episode reward: -0.4690,                 loss: nan
agent1:                 episode reward: 0.4690,                 loss: 0.3797
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6645s / 183.5848 s
agent0:                 episode reward: 0.5107,                 loss: nan
agent1:                 episode reward: -0.5107,                 loss: 0.3765
Episode: 3251/10000 (32.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7210s / 184.3058 s
agent0:                 episode reward: 1.2369,                 loss: nan
agent1:                 episode reward: -1.2369,                 loss: 0.3760
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6772s / 184.9830 s
agent0:                 episode reward: -0.3427,                 loss: nan
agent1:                 episode reward: 0.3427,                 loss: 0.3777
Episode: 3271/10000 (32.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6740s / 185.6570 s
agent0:                 episode reward: 1.6381,                 loss: nan
agent1:                 episode reward: -1.6381,                 loss: 0.3092
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6797s / 186.3367 s
agent0:                 episode reward: 1.3596,                 loss: nan
agent1:                 episode reward: -1.3596,                 loss: 0.2590
Episode: 3291/10000 (32.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6765s / 187.0132 s
agent0:                 episode reward: 1.1737,                 loss: nan
agent1:                 episode reward: -1.1737,                 loss: 0.2575
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6755s / 187.6887 s
agent0:                 episode reward: 1.2000,                 loss: nan
agent1:                 episode reward: -1.2000,                 loss: 0.2591
Episode: 3311/10000 (33.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6796s / 188.3683 s
agent0:                 episode reward: -0.4504,                 loss: nan
agent1:                 episode reward: 0.4504,                 loss: 0.2590
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6817s / 189.0500 s
agent0:                 episode reward: 0.8924,                 loss: nan
agent1:                 episode reward: -0.8924,                 loss: 0.2608
Episode: 3331/10000 (33.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7452s / 189.7951 s
agent0:                 episode reward: 0.5383,                 loss: nan
agent1:                 episode reward: -0.5383,                 loss: 0.2589
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6775s / 190.4727 s
agent0:                 episode reward: 0.9544,                 loss: nan
agent1:                 episode reward: -0.9544,                 loss: 0.2568
Episode: 3351/10000 (33.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6711s / 191.1438 s
agent0:                 episode reward: 1.0471,                 loss: nan
agent1:                 episode reward: -1.0471,                 loss: 0.2572
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6835s / 191.8273 s
agent0:                 episode reward: 0.9774,                 loss: nan
agent1:                 episode reward: -0.9774,                 loss: 0.2586
Episode: 3371/10000 (33.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7033s / 192.5306 s
agent0:                 episode reward: 0.4923,                 loss: nan
agent1:                 episode reward: -0.4923,                 loss: 0.2292
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6802s / 193.2108 s
agent0:                 episode reward: 1.1068,                 loss: nan
agent1:                 episode reward: -1.1068,                 loss: 0.2122
Episode: 3391/10000 (33.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6683s / 193.8792 s
agent0:                 episode reward: 1.2180,                 loss: nan
agent1:                 episode reward: -1.2180,                 loss: 0.2111
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6931s / 194.5723 s
agent0:                 episode reward: 0.7242,                 loss: nan
agent1:                 episode reward: -0.7242,                 loss: 0.2101
Episode: 3411/10000 (34.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6895s / 195.2618 s
agent0:                 episode reward: 0.9356,                 loss: nan
agent1:                 episode reward: -0.9356,                 loss: 0.2098
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6739s / 195.9357 s
agent0:                 episode reward: 0.8717,                 loss: nan
agent1:                 episode reward: -0.8717,                 loss: 0.2092
Episode: 3431/10000 (34.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6849s / 196.6205 s
agent0:                 episode reward: 0.2097,                 loss: nan
agent1:                 episode reward: -0.2097,                 loss: 0.2075
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6698s / 197.2903 s
agent0:                 episode reward: 0.3566,                 loss: nan
agent1:                 episode reward: -0.3566,                 loss: 0.2094
Episode: 3451/10000 (34.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6867s / 197.9771 s
agent0:                 episode reward: 1.1308,                 loss: nan
agent1:                 episode reward: -1.1308,                 loss: 0.2078
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7001s / 198.6772 s
agent0:                 episode reward: 1.0510,                 loss: nan
agent1:                 episode reward: -1.0510,                 loss: 0.2080
Episode: 3471/10000 (34.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6852s / 199.3624 s
agent0:                 episode reward: 1.2972,                 loss: nan
agent1:                 episode reward: -1.2972,                 loss: 0.2193
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7595s / 200.1219 s
agent0:                 episode reward: 1.5264,                 loss: nan
agent1:                 episode reward: -1.5264,                 loss: 0.2229
Episode: 3491/10000 (34.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7110s / 200.8329 s
agent0:                 episode reward: 0.1199,                 loss: nan
agent1:                 episode reward: -0.1199,                 loss: 0.2220
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6848s / 201.5177 s
agent0:                 episode reward: 0.5516,                 loss: nan
agent1:                 episode reward: -0.5516,                 loss: 0.2220
Episode: 3511/10000 (35.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6835s / 202.2012 s
agent0:                 episode reward: 0.7824,                 loss: nan
agent1:                 episode reward: -0.7824,                 loss: 0.2220
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6840s / 202.8852 s
agent0:                 episode reward: 0.2219,                 loss: nan
agent1:                 episode reward: -0.2219,                 loss: 0.2232
Episode: 3531/10000 (35.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6849s / 203.5701 s
agent0:                 episode reward: 0.5443,                 loss: nan
agent1:                 episode reward: -0.5443,                 loss: 0.2213
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6954s / 204.2655 s
agent0:                 episode reward: 0.0375,                 loss: nan
agent1:                 episode reward: -0.0375,                 loss: 0.2226
Episode: 3551/10000 (35.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6925s / 204.9580 s
agent0:                 episode reward: 1.1642,                 loss: nan
agent1:                 episode reward: -1.1642,                 loss: 0.2213
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6912s / 205.6492 s
agent0:                 episode reward: 1.3930,                 loss: nan
agent1:                 episode reward: -1.3930,                 loss: 0.2203
Episode: 3571/10000 (35.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6898s / 206.3390 s
agent0:                 episode reward: 1.5602,                 loss: nan
agent1:                 episode reward: -1.5602,                 loss: 0.2466
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7089s / 207.0479 s
agent0:                 episode reward: 0.4498,                 loss: nan
agent1:                 episode reward: -0.4498,                 loss: 0.2526
Episode: 3591/10000 (35.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6977s / 207.7456 s
agent0:                 episode reward: -0.1591,                 loss: nan
agent1:                 episode reward: 0.1591,                 loss: 0.2529
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6864s / 208.4320 s
agent0:                 episode reward: 1.2207,                 loss: nan
agent1:                 episode reward: -1.2207,                 loss: 0.2531
Episode: 3611/10000 (36.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7024s / 209.1344 s
agent0:                 episode reward: 0.6858,                 loss: nan
agent1:                 episode reward: -0.6858,                 loss: 0.2526
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7007s / 209.8351 s
agent0:                 episode reward: 0.4497,                 loss: nan
agent1:                 episode reward: -0.4497,                 loss: 0.2519
Episode: 3631/10000 (36.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7674s / 210.6025 s
agent0:                 episode reward: 0.7087,                 loss: nan
agent1:                 episode reward: -0.7087,                 loss: 0.2497
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6919s / 211.2944 s
agent0:                 episode reward: 2.3118,                 loss: nan
agent1:                 episode reward: -2.3118,                 loss: 0.2521
Episode: 3651/10000 (36.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6922s / 211.9866 s
agent0:                 episode reward: 1.2673,                 loss: nan
agent1:                 episode reward: -1.2673,                 loss: 0.2521
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6887s / 212.6753 s
agent0:                 episode reward: 0.1204,                 loss: nan
agent1:                 episode reward: -0.1204,                 loss: 0.2526
Episode: 3671/10000 (36.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7032s / 213.3785 s
agent0:                 episode reward: 1.5195,                 loss: nan
agent1:                 episode reward: -1.5195,                 loss: 0.2873
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6994s / 214.0779 s
agent0:                 episode reward: 1.0024,                 loss: nan
agent1:                 episode reward: -1.0024,                 loss: 0.2920
Episode: 3691/10000 (36.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6965s / 214.7744 s
agent0:                 episode reward: 0.4077,                 loss: nan
agent1:                 episode reward: -0.4077,                 loss: 0.2929
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7132s / 215.4876 s
agent0:                 episode reward: 0.2611,                 loss: nan
agent1:                 episode reward: -0.2611,                 loss: 0.2921
Episode: 3711/10000 (37.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7035s / 216.1911 s
agent0:                 episode reward: 1.8035,                 loss: nan
agent1:                 episode reward: -1.8035,                 loss: 0.2925
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6951s / 216.8862 s
agent0:                 episode reward: 1.5613,                 loss: nan
agent1:                 episode reward: -1.5613,                 loss: 0.2919
Episode: 3731/10000 (37.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7092s / 217.5954 s
agent0:                 episode reward: -0.3219,                 loss: nan
agent1:                 episode reward: 0.3219,                 loss: 0.2914
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6859s / 218.2812 s
agent0:                 episode reward: 1.9115,                 loss: nan
agent1:                 episode reward: -1.9115,                 loss: 0.2928
Episode: 3751/10000 (37.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6992s / 218.9804 s
agent0:                 episode reward: 0.6725,                 loss: nan
agent1:                 episode reward: -0.6725,                 loss: 0.2906
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7040s / 219.6844 s
agent0:                 episode reward: 0.3570,                 loss: nan
agent1:                 episode reward: -0.3570,                 loss: 0.2935
Episode: 3771/10000 (37.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7229s / 220.4073 s
agent0:                 episode reward: 0.0485,                 loss: nan
agent1:                 episode reward: -0.0485,                 loss: 0.3209
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7351s / 221.1424 s
agent0:                 episode reward: 0.5006,                 loss: nan
agent1:                 episode reward: -0.5006,                 loss: 0.3254
Episode: 3791/10000 (37.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6986s / 221.8410 s
agent0:                 episode reward: 1.9561,                 loss: nan
agent1:                 episode reward: -1.9561,                 loss: 0.3236
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7018s / 222.5428 s
agent0:                 episode reward: 0.8539,                 loss: nan
agent1:                 episode reward: -0.8539,                 loss: 0.3229
Episode: 3811/10000 (38.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7241s / 223.2669 s
agent0:                 episode reward: 0.4396,                 loss: nan
agent1:                 episode reward: -0.4396,                 loss: 0.3233
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7046s / 223.9715 s
agent0:                 episode reward: 1.7263,                 loss: nan
agent1:                 episode reward: -1.7263,                 loss: 0.3235
Episode: 3831/10000 (38.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7039s / 224.6754 s
agent0:                 episode reward: 0.0470,                 loss: nan
agent1:                 episode reward: -0.0470,                 loss: 0.3223
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7310s / 225.4064 s
agent0:                 episode reward: 1.1028,                 loss: nan
agent1:                 episode reward: -1.1028,                 loss: 0.3204
Episode: 3851/10000 (38.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7041s / 226.1105 s
agent0:                 episode reward: 0.8086,                 loss: nan
agent1:                 episode reward: -0.8086,                 loss: 0.3193
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7045s / 226.8150 s
agent0:                 episode reward: 0.8347,                 loss: nan
agent1:                 episode reward: -0.8347,                 loss: 0.3217
Episode: 3871/10000 (38.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7029s / 227.5179 s
agent0:                 episode reward: 0.3112,                 loss: nan
agent1:                 episode reward: -0.3112,                 loss: 0.3429
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7206s / 228.2385 s
agent0:                 episode reward: -0.3390,                 loss: nan
agent1:                 episode reward: 0.3390,                 loss: 0.3424
Episode: 3891/10000 (38.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7010s / 228.9395 s
agent0:                 episode reward: 0.8346,                 loss: nan
agent1:                 episode reward: -0.8346,                 loss: 0.3410
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6978s / 229.6373 s
agent0:                 episode reward: 1.5714,                 loss: nan
agent1:                 episode reward: -1.5714,                 loss: 0.3413
Episode: 3911/10000 (39.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7027s / 230.3400 s
agent0:                 episode reward: 0.8301,                 loss: nan
agent1:                 episode reward: -0.8301,                 loss: 0.3416
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7545s / 231.0945 s
agent0:                 episode reward: 0.2182,                 loss: nan
agent1:                 episode reward: -0.2182,                 loss: 0.3396
Episode: 3931/10000 (39.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7085s / 231.8030 s
agent0:                 episode reward: -0.1279,                 loss: nan
agent1:                 episode reward: 0.1279,                 loss: 0.3409
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7092s / 232.5122 s
agent0:                 episode reward: 0.2968,                 loss: nan
agent1:                 episode reward: -0.2968,                 loss: 0.3397
Episode: 3951/10000 (39.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7089s / 233.2211 s
agent0:                 episode reward: 0.2586,                 loss: nan
agent1:                 episode reward: -0.2586,                 loss: 0.3394
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7260s / 233.9471 s
agent0:                 episode reward: 0.5275,                 loss: nan
agent1:                 episode reward: -0.5275,                 loss: 0.3401
Episode: 3971/10000 (39.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7004s / 234.6475 s
agent0:                 episode reward: 0.8606,                 loss: nan
agent1:                 episode reward: -0.8606,                 loss: 0.3521
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7117s / 235.3592 s
agent0:                 episode reward: 1.0235,                 loss: nan
agent1:                 episode reward: -1.0235,                 loss: 0.3407
Episode: 3991/10000 (39.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6985s / 236.0577 s
agent0:                 episode reward: 1.4375,                 loss: nan
agent1:                 episode reward: -1.4375,                 loss: 0.3390
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7064s / 236.7641 s
agent0:                 episode reward: 0.2909,                 loss: nan
agent1:                 episode reward: -0.2909,                 loss: 0.3376
Episode: 4011/10000 (40.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7198s / 237.4839 s
agent0:                 episode reward: -0.1241,                 loss: nan
agent1:                 episode reward: 0.1241,                 loss: 0.3379
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7252s / 238.2091 s
agent0:                 episode reward: 0.4738,                 loss: nan
agent1:                 episode reward: -0.4738,                 loss: 0.3372
Episode: 4031/10000 (40.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7070s / 238.9161 s
agent0:                 episode reward: 1.5469,                 loss: nan
agent1:                 episode reward: -1.5469,                 loss: 0.3371
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7068s / 239.6228 s
agent0:                 episode reward: 0.6235,                 loss: nan
agent1:                 episode reward: -0.6235,                 loss: 0.3370
Episode: 4051/10000 (40.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7198s / 240.3426 s
agent0:                 episode reward: 0.1165,                 loss: nan
agent1:                 episode reward: -0.1165,                 loss: 0.3377
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7692s / 241.1118 s
agent0:                 episode reward: 0.5480,                 loss: nan
agent1:                 episode reward: -0.5480,                 loss: 0.3366
Episode: 4071/10000 (40.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7321s / 241.8439 s
agent0:                 episode reward: 1.1184,                 loss: nan
agent1:                 episode reward: -1.1184,                 loss: 0.3509
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7216s / 242.5655 s
agent0:                 episode reward: -0.1239,                 loss: nan
agent1:                 episode reward: 0.1239,                 loss: 0.3447
Episode: 4091/10000 (40.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7281s / 243.2936 s
agent0:                 episode reward: 1.3243,                 loss: nan
agent1:                 episode reward: -1.3243,                 loss: 0.3406
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7132s / 244.0068 s
agent0:                 episode reward: 0.6861,                 loss: nan
agent1:                 episode reward: -0.6861,                 loss: 0.3420
Episode: 4111/10000 (41.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7185s / 244.7253 s
agent0:                 episode reward: 1.0996,                 loss: nan
agent1:                 episode reward: -1.0996,                 loss: 0.3389
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7284s / 245.4538 s
agent0:                 episode reward: 0.3988,                 loss: nan
agent1:                 episode reward: -0.3988,                 loss: 0.3374
Episode: 4131/10000 (41.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7317s / 246.1854 s
agent0:                 episode reward: -0.1957,                 loss: nan
agent1:                 episode reward: 0.1957,                 loss: 0.3345
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7124s / 246.8978 s
agent0:                 episode reward: 0.4694,                 loss: nan
agent1:                 episode reward: -0.4694,                 loss: 0.3372
Episode: 4151/10000 (41.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7135s / 247.6113 s
agent0:                 episode reward: 0.6830,                 loss: nan
agent1:                 episode reward: -0.6830,                 loss: 0.3377
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7073s / 248.3187 s
agent0:                 episode reward: 0.6812,                 loss: nan
agent1:                 episode reward: -0.6812,                 loss: 0.3381
Episode: 4171/10000 (41.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7167s / 249.0354 s
agent0:                 episode reward: 0.0773,                 loss: nan
agent1:                 episode reward: -0.0773,                 loss: 0.3456
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7246s / 249.7600 s
agent0:                 episode reward: 0.7468,                 loss: nan
agent1:                 episode reward: -0.7468,                 loss: 0.3263
Episode: 4191/10000 (41.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7401s / 250.5001 s
agent0:                 episode reward: 1.2406,                 loss: nan
agent1:                 episode reward: -1.2406,                 loss: 0.3227
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7453s / 251.2454 s
agent0:                 episode reward: 0.9881,                 loss: nan
agent1:                 episode reward: -0.9881,                 loss: 0.3233
Episode: 4211/10000 (42.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7583s / 252.0037 s
agent0:                 episode reward: 0.6106,                 loss: nan
agent1:                 episode reward: -0.6106,                 loss: 0.3218
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7234s / 252.7270 s
agent0:                 episode reward: 0.5776,                 loss: nan
agent1:                 episode reward: -0.5776,                 loss: 0.3194
Episode: 4231/10000 (42.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7197s / 253.4467 s
agent0:                 episode reward: 0.5307,                 loss: nan
agent1:                 episode reward: -0.5307,                 loss: 0.3190
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7217s / 254.1684 s
agent0:                 episode reward: 0.3299,                 loss: nan
agent1:                 episode reward: -0.3299,                 loss: 0.3184
Episode: 4251/10000 (42.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7191s / 254.8874 s
agent0:                 episode reward: 0.8063,                 loss: nan
agent1:                 episode reward: -0.8063,                 loss: 0.3191
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7362s / 255.6237 s
agent0:                 episode reward: 1.1547,                 loss: nan
agent1:                 episode reward: -1.1547,                 loss: 0.3181
Episode: 4271/10000 (42.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7298s / 256.3535 s
agent0:                 episode reward: 1.4755,                 loss: nan
agent1:                 episode reward: -1.4755,                 loss: 0.2840
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7252s / 257.0787 s
agent0:                 episode reward: 0.4492,                 loss: nan
agent1:                 episode reward: -0.4492,                 loss: 0.2271
Episode: 4291/10000 (42.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7244s / 257.8031 s
agent0:                 episode reward: 1.8280,                 loss: nan
agent1:                 episode reward: -1.8280,                 loss: 0.2254
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7580s / 258.5611 s
agent0:                 episode reward: 1.2189,                 loss: nan
agent1:                 episode reward: -1.2189,                 loss: 0.2247
Episode: 4311/10000 (43.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7334s / 259.2945 s
agent0:                 episode reward: 1.1921,                 loss: nan
agent1:                 episode reward: -1.1921,                 loss: 0.2265
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7279s / 260.0224 s
agent0:                 episode reward: 0.8034,                 loss: nan
agent1:                 episode reward: -0.8034,                 loss: 0.2227
Episode: 4331/10000 (43.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7309s / 260.7533 s
agent0:                 episode reward: 1.9138,                 loss: nan
agent1:                 episode reward: -1.9138,                 loss: 0.2231
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7802s / 261.5335 s
agent0:                 episode reward: 1.8816,                 loss: nan
agent1:                 episode reward: -1.8816,                 loss: 0.2251
Episode: 4351/10000 (43.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7364s / 262.2699 s
agent0:                 episode reward: 0.0697,                 loss: nan
agent1:                 episode reward: -0.0697,                 loss: 0.2209
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7251s / 262.9950 s
agent0:                 episode reward: 0.3840,                 loss: nan
agent1:                 episode reward: -0.3840,                 loss: 0.2217
Episode: 4371/10000 (43.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7279s / 263.7229 s
agent0:                 episode reward: 1.4386,                 loss: nan
agent1:                 episode reward: -1.4386,                 loss: 0.2055
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7448s / 264.4677 s
agent0:                 episode reward: -0.0264,                 loss: nan
agent1:                 episode reward: 0.0264,                 loss: 0.1845
Episode: 4391/10000 (43.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7318s / 265.1995 s
agent0:                 episode reward: 0.3763,                 loss: nan
agent1:                 episode reward: -0.3763,                 loss: 0.1835
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7358s / 265.9353 s
agent0:                 episode reward: 0.9293,                 loss: nan
agent1:                 episode reward: -0.9293,                 loss: 0.1849
Episode: 4411/10000 (44.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7302s / 266.6655 s
agent0:                 episode reward: 1.4967,                 loss: nan
agent1:                 episode reward: -1.4967,                 loss: 0.1796
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7553s / 267.4208 s
agent0:                 episode reward: 0.0367,                 loss: nan
agent1:                 episode reward: -0.0367,                 loss: 0.1819
Episode: 4431/10000 (44.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7469s / 268.1677 s
agent0:                 episode reward: -0.2080,                 loss: nan
agent1:                 episode reward: 0.2080,                 loss: 0.1795
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7265s / 268.8942 s
agent0:                 episode reward: 0.6883,                 loss: nan
agent1:                 episode reward: -0.6883,                 loss: 0.1812
Episode: 4451/10000 (44.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7279s / 269.6221 s
agent0:                 episode reward: 0.9823,                 loss: nan
agent1:                 episode reward: -0.9823,                 loss: 0.1801
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7750s / 270.3971 s
agent0:                 episode reward: 0.4520,                 loss: nan
agent1:                 episode reward: -0.4520,                 loss: 0.1803
Episode: 4471/10000 (44.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7375s / 271.1345 s
agent0:                 episode reward: 0.5721,                 loss: nan
agent1:                 episode reward: -0.5721,                 loss: 0.2242
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7674s / 271.9019 s
agent0:                 episode reward: 0.7564,                 loss: nan
agent1:                 episode reward: -0.7564,                 loss: 0.2388
Episode: 4491/10000 (44.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7388s / 272.6408 s
agent0:                 episode reward: -0.2063,                 loss: nan
agent1:                 episode reward: 0.2063,                 loss: 0.2379
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7787s / 273.4194 s
agent0:                 episode reward: 0.7984,                 loss: nan
agent1:                 episode reward: -0.7984,                 loss: 0.2365
Episode: 4511/10000 (45.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7381s / 274.1575 s
agent0:                 episode reward: 1.1350,                 loss: nan
agent1:                 episode reward: -1.1350,                 loss: 0.2362
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7281s / 274.8857 s
agent0:                 episode reward: 1.3502,                 loss: nan
agent1:                 episode reward: -1.3502,                 loss: 0.2383
Episode: 4531/10000 (45.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7784s / 275.6641 s
agent0:                 episode reward: 1.0005,                 loss: nan
agent1:                 episode reward: -1.0005,                 loss: 0.2373
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7503s / 276.4144 s
agent0:                 episode reward: 0.6381,                 loss: nan
agent1:                 episode reward: -0.6381,                 loss: 0.2348
Episode: 4551/10000 (45.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7366s / 277.1511 s
agent0:                 episode reward: 1.1703,                 loss: nan
agent1:                 episode reward: -1.1703,                 loss: 0.2353
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7366s / 277.8876 s
agent0:                 episode reward: 0.5695,                 loss: nan
agent1:                 episode reward: -0.5695,                 loss: 0.2354
Episode: 4571/10000 (45.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7321s / 278.6198 s
agent0:                 episode reward: 0.2391,                 loss: nan
agent1:                 episode reward: -0.2391,                 loss: 0.2617
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7399s / 279.3597 s
agent0:                 episode reward: 0.9993,                 loss: nan
agent1:                 episode reward: -0.9993,                 loss: 0.2692
Episode: 4591/10000 (45.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7375s / 280.0972 s
agent0:                 episode reward: 0.0553,                 loss: nan
agent1:                 episode reward: -0.0553,                 loss: 0.2697
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7277s / 280.8249 s
agent0:                 episode reward: 0.5084,                 loss: nan
agent1:                 episode reward: -0.5084,                 loss: 0.2687
Episode: 4611/10000 (46.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7403s / 281.5652 s
agent0:                 episode reward: 0.3102,                 loss: nan
agent1:                 episode reward: -0.3102,                 loss: 0.2685
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7838s / 282.3489 s
agent0:                 episode reward: 0.3170,                 loss: nan
agent1:                 episode reward: -0.3170,                 loss: 0.2688
Episode: 4631/10000 (46.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7419s / 283.0908 s
agent0:                 episode reward: -0.0121,                 loss: nan
agent1:                 episode reward: 0.0121,                 loss: 0.2666
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7593s / 283.8500 s
agent0:                 episode reward: 1.1969,                 loss: nan
agent1:                 episode reward: -1.1969,                 loss: 0.2684
Episode: 4651/10000 (46.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7478s / 284.5978 s
agent0:                 episode reward: 0.4977,                 loss: nan
agent1:                 episode reward: -0.4977,                 loss: 0.2699
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7507s / 285.3485 s
agent0:                 episode reward: 0.8565,                 loss: nan
agent1:                 episode reward: -0.8565,                 loss: 0.2650
Episode: 4671/10000 (46.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7585s / 286.1070 s
agent0:                 episode reward: -0.3025,                 loss: nan
agent1:                 episode reward: 0.3025,                 loss: 0.2923
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7430s / 286.8500 s
agent0:                 episode reward: 0.2321,                 loss: nan
agent1:                 episode reward: -0.2321,                 loss: 0.3009
Episode: 4691/10000 (46.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7417s / 287.5917 s
agent0:                 episode reward: 0.2403,                 loss: nan
agent1:                 episode reward: -0.2403,                 loss: 0.3008
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7412s / 288.3329 s
agent0:                 episode reward: 0.6899,                 loss: nan
agent1:                 episode reward: -0.6899,                 loss: 0.3005
Episode: 4711/10000 (47.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7414s / 289.0742 s
agent0:                 episode reward: 1.2649,                 loss: nan
agent1:                 episode reward: -1.2649,                 loss: 0.2993
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7391s / 289.8133 s
agent0:                 episode reward: -0.6187,                 loss: nan
agent1:                 episode reward: 0.6187,                 loss: 0.3003
Episode: 4731/10000 (47.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7368s / 290.5502 s
agent0:                 episode reward: 0.3501,                 loss: nan
agent1:                 episode reward: -0.3501,                 loss: 0.2987
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7589s / 291.3090 s
agent0:                 episode reward: 1.5425,                 loss: nan
agent1:                 episode reward: -1.5425,                 loss: 0.2976
Episode: 4751/10000 (47.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7630s / 292.0720 s
agent0:                 episode reward: 0.3508,                 loss: nan
agent1:                 episode reward: -0.3508,                 loss: 0.2984
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8035s / 292.8755 s
agent0:                 episode reward: 0.3462,                 loss: nan
agent1:                 episode reward: -0.3462,                 loss: 0.2990
Episode: 4771/10000 (47.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7476s / 293.6231 s
agent0:                 episode reward: 0.8565,                 loss: nan
agent1:                 episode reward: -0.8565,                 loss: 0.3232
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7477s / 294.3708 s
agent0:                 episode reward: -0.2433,                 loss: nan
agent1:                 episode reward: 0.2433,                 loss: 0.3261
Episode: 4791/10000 (47.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7420s / 295.1128 s
agent0:                 episode reward: 1.8352,                 loss: nan
agent1:                 episode reward: -1.8352,                 loss: 0.3271
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7405s / 295.8533 s
agent0:                 episode reward: 0.2664,                 loss: nan
agent1:                 episode reward: -0.2664,                 loss: 0.3276
Episode: 4811/10000 (48.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7712s / 296.6245 s
agent0:                 episode reward: 0.7185,                 loss: nan
agent1:                 episode reward: -0.7185,                 loss: 0.3239
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7432s / 297.3676 s
agent0:                 episode reward: 1.6763,                 loss: nan
agent1:                 episode reward: -1.6763,                 loss: 0.3278
Episode: 4831/10000 (48.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7498s / 298.1175 s
agent0:                 episode reward: 0.7465,                 loss: nan
agent1:                 episode reward: -0.7465,                 loss: 0.3254
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7369s / 298.8544 s
agent0:                 episode reward: 0.3058,                 loss: nan
agent1:                 episode reward: -0.3058,                 loss: 0.3249
Episode: 4851/10000 (48.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7520s / 299.6064 s
agent0:                 episode reward: 0.7898,                 loss: nan
agent1:                 episode reward: -0.7898,                 loss: 0.3227
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7802s / 300.3866 s
agent0:                 episode reward: 0.4790,                 loss: nan
agent1:                 episode reward: -0.4790,                 loss: 0.3216
Episode: 4871/10000 (48.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7600s / 301.1465 s
agent0:                 episode reward: 1.4091,                 loss: nan
agent1:                 episode reward: -1.4091,                 loss: 0.3391
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7500s / 301.8966 s
agent0:                 episode reward: 0.1114,                 loss: nan
agent1:                 episode reward: -0.1114,                 loss: 0.3387
Episode: 4891/10000 (48.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7994s / 302.6959 s
agent0:                 episode reward: 0.8728,                 loss: nan
agent1:                 episode reward: -0.8728,                 loss: 0.3375
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7536s / 303.4495 s
agent0:                 episode reward: 0.4752,                 loss: nan
agent1:                 episode reward: -0.4752,                 loss: 0.3356
Episode: 4911/10000 (49.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7464s / 304.1960 s
agent0:                 episode reward: -0.4668,                 loss: nan
agent1:                 episode reward: 0.4668,                 loss: 0.3344
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7484s / 304.9444 s
agent0:                 episode reward: 1.3897,                 loss: nan
agent1:                 episode reward: -1.3897,                 loss: 0.3355
Episode: 4931/10000 (49.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7590s / 305.7033 s
agent0:                 episode reward: 0.3198,                 loss: nan
agent1:                 episode reward: -0.3198,                 loss: 0.3361
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7701s / 306.4734 s
agent0:                 episode reward: 0.9037,                 loss: nan
agent1:                 episode reward: -0.9037,                 loss: 0.3332
Episode: 4951/10000 (49.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7798s / 307.2532 s
agent0:                 episode reward: 0.3993,                 loss: nan
agent1:                 episode reward: -0.3993,                 loss: 0.3364
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7777s / 308.0309 s
agent0:                 episode reward: 1.3989,                 loss: nan
agent1:                 episode reward: -1.3989,                 loss: 0.3348
Episode: 4971/10000 (49.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7774s / 308.8083 s
agent0:                 episode reward: 0.3842,                 loss: nan
agent1:                 episode reward: -0.3842,                 loss: 0.3466
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7757s / 309.5840 s
agent0:                 episode reward: 1.0412,                 loss: nan
agent1:                 episode reward: -1.0412,                 loss: 0.3452
Episode: 4991/10000 (49.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7501s / 310.3341 s
agent0:                 episode reward: -0.0285,                 loss: nan
agent1:                 episode reward: 0.0285,                 loss: 0.3450
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7586s / 311.0927 s
agent0:                 episode reward: 0.2539,                 loss: nan
agent1:                 episode reward: -0.2539,                 loss: 0.3437
Episode: 5011/10000 (50.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7584s / 311.8511 s
agent0:                 episode reward: 0.2528,                 loss: nan
agent1:                 episode reward: -0.2528,                 loss: 0.3432
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7683s / 312.6194 s
agent0:                 episode reward: 0.3412,                 loss: nan
agent1:                 episode reward: -0.3412,                 loss: 0.3462
Episode: 5031/10000 (50.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8216s / 313.4409 s
agent0:                 episode reward: 0.0345,                 loss: nan
agent1:                 episode reward: -0.0345,                 loss: 0.3429
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7601s / 314.2010 s
agent0:                 episode reward: -0.3358,                 loss: nan
agent1:                 episode reward: 0.3358,                 loss: 0.3431
Episode: 5051/10000 (50.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7589s / 314.9599 s
agent0:                 episode reward: 0.1881,                 loss: nan
agent1:                 episode reward: -0.1881,                 loss: 0.3417
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7618s / 315.7216 s
agent0:                 episode reward: -0.4827,                 loss: nan
agent1:                 episode reward: 0.4827,                 loss: 0.3432
Episode: 5071/10000 (50.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7810s / 316.5027 s
agent0:                 episode reward: -0.2652,                 loss: nan
agent1:                 episode reward: 0.2652,                 loss: 0.3603
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7615s / 317.2642 s
agent0:                 episode reward: 0.9332,                 loss: nan
agent1:                 episode reward: -0.9332,                 loss: 0.3636
Episode: 5091/10000 (50.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7559s / 318.0201 s
agent0:                 episode reward: 0.8998,                 loss: nan
agent1:                 episode reward: -0.8998,                 loss: 0.3649
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7677s / 318.7878 s
agent0:                 episode reward: 0.1776,                 loss: nan
agent1:                 episode reward: -0.1776,                 loss: 0.3621
Episode: 5111/10000 (51.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7590s / 319.5469 s
agent0:                 episode reward: 1.4570,                 loss: nan
agent1:                 episode reward: -1.4570,                 loss: 0.3609
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7614s / 320.3082 s
agent0:                 episode reward: 1.4577,                 loss: nan
agent1:                 episode reward: -1.4577,                 loss: 0.3620
Episode: 5131/10000 (51.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7553s / 321.0635 s
agent0:                 episode reward: 1.2270,                 loss: nan
agent1:                 episode reward: -1.2270,                 loss: 0.3609
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7958s / 321.8594 s
agent0:                 episode reward: 1.2531,                 loss: nan
agent1:                 episode reward: -1.2531,                 loss: 0.3599
Episode: 5151/10000 (51.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7707s / 322.6301 s
agent0:                 episode reward: 1.2118,                 loss: nan
agent1:                 episode reward: -1.2118,                 loss: 0.3605
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7966s / 323.4267 s
agent0:                 episode reward: 0.7632,                 loss: nan
agent1:                 episode reward: -0.7632,                 loss: 0.3603
Episode: 5171/10000 (51.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7694s / 324.1960 s
agent0:                 episode reward: 0.4300,                 loss: nan
agent1:                 episode reward: -0.4300,                 loss: 0.3526
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7932s / 324.9892 s
agent0:                 episode reward: 0.9275,                 loss: nan
agent1:                 episode reward: -0.9275,                 loss: 0.3406
Episode: 5191/10000 (51.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7718s / 325.7610 s
agent0:                 episode reward: 0.8718,                 loss: nan
agent1:                 episode reward: -0.8718,                 loss: 0.3380
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8013s / 326.5623 s
agent0:                 episode reward: 1.2766,                 loss: nan
agent1:                 episode reward: -1.2766,                 loss: 0.3341
Episode: 5211/10000 (52.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7743s / 327.3366 s
agent0:                 episode reward: 1.1902,                 loss: nan
agent1:                 episode reward: -1.1902,                 loss: 0.3359
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7698s / 328.1064 s
agent0:                 episode reward: 0.3992,                 loss: nan
agent1:                 episode reward: -0.3992,                 loss: 0.3369
Episode: 5231/10000 (52.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7680s / 328.8744 s
agent0:                 episode reward: 0.6606,                 loss: nan
agent1:                 episode reward: -0.6606,                 loss: 0.3371
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7885s / 329.6629 s
agent0:                 episode reward: 0.9035,                 loss: nan
agent1:                 episode reward: -0.9035,                 loss: 0.3335
Episode: 5251/10000 (52.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7846s / 330.4475 s
agent0:                 episode reward: 1.1009,                 loss: nan
agent1:                 episode reward: -1.1009,                 loss: 0.3342
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7683s / 331.2158 s
agent0:                 episode reward: 0.8868,                 loss: nan
agent1:                 episode reward: -0.8868,                 loss: 0.3337
Episode: 5271/10000 (52.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7650s / 331.9808 s
agent0:                 episode reward: 0.3045,                 loss: nan
agent1:                 episode reward: -0.3045,                 loss: 0.2883
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7672s / 332.7480 s
agent0:                 episode reward: 0.4688,                 loss: nan
agent1:                 episode reward: -0.4688,                 loss: 0.2465
Episode: 5291/10000 (52.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8259s / 333.5738 s
agent0:                 episode reward: 1.2638,                 loss: nan
agent1:                 episode reward: -1.2638,                 loss: 0.2463
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7704s / 334.3442 s
agent0:                 episode reward: 1.5637,                 loss: nan
agent1:                 episode reward: -1.5637,                 loss: 0.2441
Episode: 5311/10000 (53.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7744s / 335.1186 s
agent0:                 episode reward: 1.0215,                 loss: nan
agent1:                 episode reward: -1.0215,                 loss: 0.2455
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7740s / 335.8926 s
agent0:                 episode reward: 0.8898,                 loss: nan
agent1:                 episode reward: -0.8898,                 loss: 0.2432
Episode: 5331/10000 (53.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7980s / 336.6906 s
agent0:                 episode reward: 1.1460,                 loss: nan
agent1:                 episode reward: -1.1460,                 loss: 0.2452
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7646s / 337.4552 s
agent0:                 episode reward: 0.8359,                 loss: nan
agent1:                 episode reward: -0.8359,                 loss: 0.2437
Episode: 5351/10000 (53.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7671s / 338.2223 s
agent0:                 episode reward: 1.3189,                 loss: nan
agent1:                 episode reward: -1.3189,                 loss: 0.2448
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7849s / 339.0072 s
agent0:                 episode reward: 0.6378,                 loss: nan
agent1:                 episode reward: -0.6378,                 loss: 0.2424
Episode: 5371/10000 (53.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7970s / 339.8043 s
agent0:                 episode reward: 0.6270,                 loss: nan
agent1:                 episode reward: -0.6270,                 loss: 0.2124
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7792s / 340.5834 s
agent0:                 episode reward: 0.4484,                 loss: nan
agent1:                 episode reward: -0.4484,                 loss: 0.1883
Episode: 5391/10000 (53.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7938s / 341.3772 s
agent0:                 episode reward: -0.3789,                 loss: nan
agent1:                 episode reward: 0.3789,                 loss: 0.1847
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7973s / 342.1745 s
agent0:                 episode reward: 0.9552,                 loss: nan
agent1:                 episode reward: -0.9552,                 loss: 0.1874
Episode: 5411/10000 (54.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7794s / 342.9540 s
agent0:                 episode reward: 0.9788,                 loss: nan
agent1:                 episode reward: -0.9788,                 loss: 0.1865
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8082s / 343.7622 s
agent0:                 episode reward: 0.2497,                 loss: nan
agent1:                 episode reward: -0.2497,                 loss: 0.1873
Episode: 5431/10000 (54.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8033s / 344.5655 s
agent0:                 episode reward: 0.9895,                 loss: nan
agent1:                 episode reward: -0.9895,                 loss: 0.1835
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7873s / 345.3528 s
agent0:                 episode reward: -0.1757,                 loss: nan
agent1:                 episode reward: 0.1757,                 loss: 0.1847
Episode: 5451/10000 (54.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7840s / 346.1368 s
agent0:                 episode reward: 0.8044,                 loss: nan
agent1:                 episode reward: -0.8044,                 loss: 0.1841
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7850s / 346.9218 s
agent0:                 episode reward: 1.3053,                 loss: nan
agent1:                 episode reward: -1.3053,                 loss: 0.1842
Episode: 5471/10000 (54.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7862s / 347.7081 s
agent0:                 episode reward: 1.7697,                 loss: nan
agent1:                 episode reward: -1.7697,                 loss: 0.2077
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8017s / 348.5098 s
agent0:                 episode reward: 0.7318,                 loss: nan
agent1:                 episode reward: -0.7318,                 loss: 0.2144
Episode: 5491/10000 (54.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7801s / 349.2899 s
agent0:                 episode reward: -0.5557,                 loss: nan
agent1:                 episode reward: 0.5557,                 loss: 0.2140
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7949s / 350.0848 s
agent0:                 episode reward: 0.1427,                 loss: nan
agent1:                 episode reward: -0.1427,                 loss: 0.2134
Episode: 5511/10000 (55.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7830s / 350.8678 s
agent0:                 episode reward: 1.5584,                 loss: nan
agent1:                 episode reward: -1.5584,                 loss: 0.2148
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7976s / 351.6654 s
agent0:                 episode reward: 0.7773,                 loss: nan
agent1:                 episode reward: -0.7773,                 loss: 0.2123
Episode: 5531/10000 (55.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7887s / 352.4541 s
agent0:                 episode reward: 1.7159,                 loss: nan
agent1:                 episode reward: -1.7159,                 loss: 0.2120
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7840s / 353.2381 s
agent0:                 episode reward: 0.3357,                 loss: nan
agent1:                 episode reward: -0.3357,                 loss: 0.2107
Episode: 5551/10000 (55.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8538s / 354.0919 s
agent0:                 episode reward: 0.0061,                 loss: nan
agent1:                 episode reward: -0.0061,                 loss: 0.2131
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7885s / 354.8804 s
agent0:                 episode reward: -0.1376,                 loss: nan
agent1:                 episode reward: 0.1376,                 loss: 0.2128
Episode: 5571/10000 (55.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7834s / 355.6638 s
agent0:                 episode reward: 1.0461,                 loss: nan
agent1:                 episode reward: -1.0461,                 loss: 0.2374
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7948s / 356.4586 s
agent0:                 episode reward: 0.3742,                 loss: nan
agent1:                 episode reward: -0.3742,                 loss: 0.2443
Episode: 5591/10000 (55.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7991s / 357.2577 s
agent0:                 episode reward: 1.1682,                 loss: nan
agent1:                 episode reward: -1.1682,                 loss: 0.2412
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8169s / 358.0746 s
agent0:                 episode reward: 0.4629,                 loss: nan
agent1:                 episode reward: -0.4629,                 loss: 0.2443
Episode: 5611/10000 (56.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7840s / 358.8586 s
agent0:                 episode reward: 0.7040,                 loss: nan
agent1:                 episode reward: -0.7040,                 loss: 0.2433
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7894s / 359.6480 s
agent0:                 episode reward: 0.2046,                 loss: nan
agent1:                 episode reward: -0.2046,                 loss: 0.2412
Episode: 5631/10000 (56.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7977s / 360.4457 s
agent0:                 episode reward: -0.0484,                 loss: nan
agent1:                 episode reward: 0.0484,                 loss: 0.2432
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7989s / 361.2445 s
agent0:                 episode reward: 0.5390,                 loss: nan
agent1:                 episode reward: -0.5390,                 loss: 0.2420
Episode: 5651/10000 (56.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7951s / 362.0397 s
agent0:                 episode reward: 0.9076,                 loss: nan
agent1:                 episode reward: -0.9076,                 loss: 0.2431
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7988s / 362.8385 s
agent0:                 episode reward: 1.1507,                 loss: nan
agent1:                 episode reward: -1.1507,                 loss: 0.2460
Episode: 5671/10000 (56.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8148s / 363.6533 s
agent0:                 episode reward: -0.0123,                 loss: nan
agent1:                 episode reward: 0.0123,                 loss: 0.2646
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8359s / 364.4892 s
agent0:                 episode reward: 0.7826,                 loss: nan
agent1:                 episode reward: -0.7826,                 loss: 0.2728
Episode: 5691/10000 (56.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8098s / 365.2990 s
agent0:                 episode reward: 0.3204,                 loss: nan
agent1:                 episode reward: -0.3204,                 loss: 0.2718
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8023s / 366.1013 s
agent0:                 episode reward: -0.5098,                 loss: nan
agent1:                 episode reward: 0.5098,                 loss: 0.2710
Episode: 5711/10000 (57.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8288s / 366.9300 s
agent0:                 episode reward: -0.8508,                 loss: nan
agent1:                 episode reward: 0.8508,                 loss: 0.2720
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8001s / 367.7301 s
agent0:                 episode reward: 1.6438,                 loss: nan
agent1:                 episode reward: -1.6438,                 loss: 0.2715
Episode: 5731/10000 (57.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7937s / 368.5238 s
agent0:                 episode reward: 0.3647,                 loss: nan
agent1:                 episode reward: -0.3647,                 loss: 0.2726
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7943s / 369.3181 s
agent0:                 episode reward: 0.7301,                 loss: nan
agent1:                 episode reward: -0.7301,                 loss: 0.2728
Episode: 5751/10000 (57.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8043s / 370.1224 s
agent0:                 episode reward: 0.5666,                 loss: nan
agent1:                 episode reward: -0.5666,                 loss: 0.2696
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7968s / 370.9192 s
agent0:                 episode reward: 1.0391,                 loss: nan
agent1:                 episode reward: -1.0391,                 loss: 0.2702
Episode: 5771/10000 (57.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8041s / 371.7232 s
agent0:                 episode reward: 1.0866,                 loss: nan
agent1:                 episode reward: -1.0866,                 loss: 0.2942
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8096s / 372.5328 s
agent0:                 episode reward: 1.2787,                 loss: nan
agent1:                 episode reward: -1.2787,                 loss: 0.2996
Episode: 5791/10000 (57.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8025s / 373.3353 s
agent0:                 episode reward: 1.2556,                 loss: nan
agent1:                 episode reward: -1.2556,                 loss: 0.2986
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8464s / 374.1817 s
agent0:                 episode reward: 1.3745,                 loss: nan
agent1:                 episode reward: -1.3745,                 loss: 0.2968
Episode: 5811/10000 (58.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8174s / 374.9991 s
agent0:                 episode reward: 1.1832,                 loss: nan
agent1:                 episode reward: -1.1832,                 loss: 0.2979
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8100s / 375.8091 s
agent0:                 episode reward: 0.8227,                 loss: nan
agent1:                 episode reward: -0.8227,                 loss: 0.2982
Episode: 5831/10000 (58.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7985s / 376.6076 s
agent0:                 episode reward: 0.4927,                 loss: nan
agent1:                 episode reward: -0.4927,                 loss: 0.2981
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8095s / 377.4171 s
agent0:                 episode reward: 2.0749,                 loss: nan
agent1:                 episode reward: -2.0749,                 loss: 0.2972
Episode: 5851/10000 (58.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8107s / 378.2278 s
agent0:                 episode reward: -0.3167,                 loss: nan
agent1:                 episode reward: 0.3167,                 loss: 0.2970
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8002s / 379.0280 s
agent0:                 episode reward: 0.2473,                 loss: nan
agent1:                 episode reward: -0.2473,                 loss: 0.2960
Episode: 5871/10000 (58.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8002s / 379.8282 s
agent0:                 episode reward: 0.4734,                 loss: nan
agent1:                 episode reward: -0.4734,                 loss: 0.3130
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8039s / 380.6321 s
agent0:                 episode reward: 0.6258,                 loss: nan
agent1:                 episode reward: -0.6258,                 loss: 0.3139
Episode: 5891/10000 (58.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8185s / 381.4506 s
agent0:                 episode reward: 1.1806,                 loss: nan
agent1:                 episode reward: -1.1806,                 loss: 0.3128
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8098s / 382.2604 s
agent0:                 episode reward: 0.3396,                 loss: nan
agent1:                 episode reward: -0.3396,                 loss: 0.3135
Episode: 5911/10000 (59.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8137s / 383.0740 s
agent0:                 episode reward: 0.1989,                 loss: nan
agent1:                 episode reward: -0.1989,                 loss: 0.3099
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8140s / 383.8881 s
agent0:                 episode reward: 1.1259,                 loss: nan
agent1:                 episode reward: -1.1259,                 loss: 0.3111
Episode: 5931/10000 (59.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8645s / 384.7525 s
agent0:                 episode reward: 1.2276,                 loss: nan
agent1:                 episode reward: -1.2276,                 loss: 0.3103
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8119s / 385.5644 s
agent0:                 episode reward: 1.0585,                 loss: nan
agent1:                 episode reward: -1.0585,                 loss: 0.3113
Episode: 5951/10000 (59.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8059s / 386.3703 s
agent0:                 episode reward: 0.6956,                 loss: nan
agent1:                 episode reward: -0.6956,                 loss: 0.3094
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8090s / 387.1793 s
agent0:                 episode reward: 0.1427,                 loss: nan
agent1:                 episode reward: -0.1427,                 loss: 0.3120
Episode: 5971/10000 (59.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8658s / 388.0451 s
agent0:                 episode reward: -0.5748,                 loss: nan
agent1:                 episode reward: 0.5748,                 loss: 0.3249
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8113s / 388.8564 s
agent0:                 episode reward: 1.2213,                 loss: nan
agent1:                 episode reward: -1.2213,                 loss: 0.3247
Episode: 5991/10000 (59.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8119s / 389.6683 s
agent0:                 episode reward: -0.1116,                 loss: nan
agent1:                 episode reward: 0.1116,                 loss: 0.3209
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8190s / 390.4873 s
agent0:                 episode reward: 0.2385,                 loss: nan
agent1:                 episode reward: -0.2385,                 loss: 0.3196
Episode: 6011/10000 (60.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8230s / 391.3102 s
agent0:                 episode reward: 0.4638,                 loss: nan
agent1:                 episode reward: -0.4638,                 loss: 0.3222
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8108s / 392.1211 s
agent0:                 episode reward: 0.7658,                 loss: nan
agent1:                 episode reward: -0.7658,                 loss: 0.3230
Episode: 6031/10000 (60.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8021s / 392.9232 s
agent0:                 episode reward: 0.4760,                 loss: nan
agent1:                 episode reward: -0.4760,                 loss: 0.3210
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8112s / 393.7344 s
agent0:                 episode reward: -0.4783,                 loss: nan
agent1:                 episode reward: 0.4783,                 loss: 0.3199
Episode: 6051/10000 (60.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8212s / 394.5556 s
agent0:                 episode reward: 0.8979,                 loss: nan
agent1:                 episode reward: -0.8979,                 loss: 0.3185
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8544s / 395.4100 s
agent0:                 episode reward: 1.1076,                 loss: nan
agent1:                 episode reward: -1.1076,                 loss: 0.3196
Episode: 6071/10000 (60.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8171s / 396.2270 s
agent0:                 episode reward: 1.0632,                 loss: nan
agent1:                 episode reward: -1.0632,                 loss: 0.3252
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8153s / 397.0423 s
agent0:                 episode reward: 0.0914,                 loss: nan
agent1:                 episode reward: -0.0914,                 loss: 0.3219
Episode: 6091/10000 (60.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8236s / 397.8660 s
agent0:                 episode reward: 0.3620,                 loss: nan
agent1:                 episode reward: -0.3620,                 loss: 0.3183
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8093s / 398.6753 s
agent0:                 episode reward: 1.5061,                 loss: nan
agent1:                 episode reward: -1.5061,                 loss: 0.3171
Episode: 6111/10000 (61.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8373s / 399.5126 s
agent0:                 episode reward: 0.3849,                 loss: nan
agent1:                 episode reward: -0.3849,                 loss: 0.3158
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8297s / 400.3423 s
agent0:                 episode reward: 0.3499,                 loss: nan
agent1:                 episode reward: -0.3499,                 loss: 0.3170
Episode: 6131/10000 (61.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8181s / 401.1604 s
agent0:                 episode reward: 1.1342,                 loss: nan
agent1:                 episode reward: -1.1342,                 loss: 0.3183
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8108s / 401.9712 s
agent0:                 episode reward: 1.1729,                 loss: nan
agent1:                 episode reward: -1.1729,                 loss: 0.3190
Episode: 6151/10000 (61.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8168s / 402.7880 s
agent0:                 episode reward: -0.0259,                 loss: nan
agent1:                 episode reward: 0.0259,                 loss: 0.3164
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8156s / 403.6036 s
agent0:                 episode reward: -0.3855,                 loss: nan
agent1:                 episode reward: 0.3855,                 loss: 0.3178
Episode: 6171/10000 (61.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8125s / 404.4161 s
agent0:                 episode reward: 1.1458,                 loss: nan
agent1:                 episode reward: -1.1458,                 loss: 0.3311
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8738s / 405.2899 s
agent0:                 episode reward: -0.0043,                 loss: nan
agent1:                 episode reward: 0.0043,                 loss: 0.3307
Episode: 6191/10000 (61.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8207s / 406.1106 s
agent0:                 episode reward: 0.9055,                 loss: nan
agent1:                 episode reward: -0.9055,                 loss: 0.3294
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8231s / 406.9337 s
agent0:                 episode reward: 0.5583,                 loss: nan
agent1:                 episode reward: -0.5583,                 loss: 0.3288
Episode: 6211/10000 (62.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8269s / 407.7607 s
agent0:                 episode reward: 0.8485,                 loss: nan
agent1:                 episode reward: -0.8485,                 loss: 0.3274
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8486s / 408.6092 s
agent0:                 episode reward: 1.3612,                 loss: nan
agent1:                 episode reward: -1.3612,                 loss: 0.3288
Episode: 6231/10000 (62.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8166s / 409.4259 s
agent0:                 episode reward: 1.1402,                 loss: nan
agent1:                 episode reward: -1.1402,                 loss: 0.3301
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8238s / 410.2497 s
agent0:                 episode reward: 0.7203,                 loss: nan
agent1:                 episode reward: -0.7203,                 loss: 0.3268
Episode: 6251/10000 (62.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8251s / 411.0748 s
agent0:                 episode reward: 0.3925,                 loss: nan
agent1:                 episode reward: -0.3925,                 loss: 0.3279
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8296s / 411.9044 s
agent0:                 episode reward: 0.5510,                 loss: nan
agent1:                 episode reward: -0.5510,                 loss: 0.3277
Episode: 6271/10000 (62.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8247s / 412.7292 s
agent0:                 episode reward: 0.4568,                 loss: nan
agent1:                 episode reward: -0.4568,                 loss: 0.3429
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8232s / 413.5524 s
agent0:                 episode reward: 0.7315,                 loss: nan
agent1:                 episode reward: -0.7315,                 loss: 0.3409
Episode: 6291/10000 (62.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8320s / 414.3844 s
agent0:                 episode reward: 1.5035,                 loss: nan
agent1:                 episode reward: -1.5035,                 loss: 0.3401
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8793s / 415.2637 s
agent0:                 episode reward: 0.8458,                 loss: nan
agent1:                 episode reward: -0.8458,                 loss: 0.3387
Episode: 6311/10000 (63.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8430s / 416.1068 s
agent0:                 episode reward: 1.5014,                 loss: nan
agent1:                 episode reward: -1.5014,                 loss: 0.3374
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8223s / 416.9290 s
agent0:                 episode reward: -0.0550,                 loss: nan
agent1:                 episode reward: 0.0550,                 loss: 0.3368
Episode: 6331/10000 (63.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8393s / 417.7684 s
agent0:                 episode reward: 0.4434,                 loss: nan
agent1:                 episode reward: -0.4434,                 loss: 0.3375
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8369s / 418.6053 s
agent0:                 episode reward: -0.0892,                 loss: nan
agent1:                 episode reward: 0.0892,                 loss: 0.3385
Episode: 6351/10000 (63.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8341s / 419.4394 s
agent0:                 episode reward: 1.0870,                 loss: nan
agent1:                 episode reward: -1.0870,                 loss: 0.3354
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8298s / 420.2691 s
agent0:                 episode reward: 1.1646,                 loss: nan
agent1:                 episode reward: -1.1646,                 loss: 0.3360
Episode: 6371/10000 (63.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8951s / 421.1642 s
agent0:                 episode reward: 0.1939,                 loss: nan
agent1:                 episode reward: -0.1939,                 loss: 0.2880
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8341s / 421.9983 s
agent0:                 episode reward: -0.0956,                 loss: nan
agent1:                 episode reward: 0.0956,                 loss: 0.2491
Episode: 6391/10000 (63.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8205s / 422.8188 s
agent0:                 episode reward: 0.2133,                 loss: nan
agent1:                 episode reward: -0.2133,                 loss: 0.2428
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8591s / 423.6778 s
agent0:                 episode reward: 1.8467,                 loss: nan
agent1:                 episode reward: -1.8467,                 loss: 0.2405
Episode: 6411/10000 (64.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8535s / 424.5313 s
agent0:                 episode reward: 1.1711,                 loss: nan
agent1:                 episode reward: -1.1711,                 loss: 0.2390
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8735s / 425.4049 s
agent0:                 episode reward: 0.2637,                 loss: nan
agent1:                 episode reward: -0.2637,                 loss: 0.2377
Episode: 6431/10000 (64.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8428s / 426.2477 s
agent0:                 episode reward: 1.3669,                 loss: nan
agent1:                 episode reward: -1.3669,                 loss: 0.2364
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8372s / 427.0849 s
agent0:                 episode reward: -0.4070,                 loss: nan
agent1:                 episode reward: 0.4070,                 loss: 0.2357
Episode: 6451/10000 (64.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8461s / 427.9311 s
agent0:                 episode reward: 1.3612,                 loss: nan
agent1:                 episode reward: -1.3612,                 loss: 0.2372
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8363s / 428.7674 s
agent0:                 episode reward: 1.3773,                 loss: nan
agent1:                 episode reward: -1.3773,                 loss: 0.2369
Episode: 6471/10000 (64.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8595s / 429.6269 s
agent0:                 episode reward: 0.6926,                 loss: nan
agent1:                 episode reward: -0.6926,                 loss: 0.1954
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8686s / 430.4955 s
agent0:                 episode reward: 1.4009,                 loss: nan
agent1:                 episode reward: -1.4009,                 loss: 0.1652
Episode: 6491/10000 (64.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8443s / 431.3398 s
agent0:                 episode reward: 0.3446,                 loss: nan
agent1:                 episode reward: -0.3446,                 loss: 0.1610
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8395s / 432.1792 s
agent0:                 episode reward: 1.0044,                 loss: nan
agent1:                 episode reward: -1.0044,                 loss: 0.1592
Episode: 6511/10000 (65.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8625s / 433.0417 s
agent0:                 episode reward: -0.2674,                 loss: nan
agent1:                 episode reward: 0.2674,                 loss: 0.1600
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8367s / 433.8784 s
agent0:                 episode reward: 0.8570,                 loss: nan
agent1:                 episode reward: -0.8570,                 loss: 0.1586
Episode: 6531/10000 (65.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8376s / 434.7161 s
agent0:                 episode reward: -0.3786,                 loss: nan
agent1:                 episode reward: 0.3786,                 loss: 0.1571
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8783s / 435.5944 s
agent0:                 episode reward: -0.0923,                 loss: nan
agent1:                 episode reward: 0.0923,                 loss: 0.1579
Episode: 6551/10000 (65.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8648s / 436.4592 s
agent0:                 episode reward: 1.2909,                 loss: nan
agent1:                 episode reward: -1.2909,                 loss: 0.1585
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8468s / 437.3060 s
agent0:                 episode reward: -0.7267,                 loss: nan
agent1:                 episode reward: 0.7267,                 loss: 0.1575
Episode: 6571/10000 (65.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8575s / 438.1635 s
agent0:                 episode reward: 0.1003,                 loss: nan
agent1:                 episode reward: -0.1003,                 loss: 0.1732
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8469s / 439.0104 s
agent0:                 episode reward: 0.6049,                 loss: nan
agent1:                 episode reward: -0.6049,                 loss: 0.1757
Episode: 6591/10000 (65.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8381s / 439.8485 s
agent0:                 episode reward: 0.8561,                 loss: nan
agent1:                 episode reward: -0.8561,                 loss: 0.1765
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8379s / 440.6863 s
agent0:                 episode reward: 1.0762,                 loss: nan
agent1:                 episode reward: -1.0762,                 loss: 0.1769
Episode: 6611/10000 (66.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8603s / 441.5467 s
agent0:                 episode reward: 0.9649,                 loss: nan
agent1:                 episode reward: -0.9649,                 loss: 0.1749
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8401s / 442.3868 s
agent0:                 episode reward: 0.6756,                 loss: nan
agent1:                 episode reward: -0.6756,                 loss: 0.1769
Episode: 6631/10000 (66.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8505s / 443.2373 s
agent0:                 episode reward: 1.0381,                 loss: nan
agent1:                 episode reward: -1.0381,                 loss: 0.1736
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8472s / 444.0845 s
agent0:                 episode reward: 0.6507,                 loss: nan
agent1:                 episode reward: -0.6507,                 loss: 0.1754
Episode: 6651/10000 (66.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8434s / 444.9279 s
agent0:                 episode reward: -0.5665,                 loss: nan
agent1:                 episode reward: 0.5665,                 loss: 0.1761
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8632s / 445.7910 s
agent0:                 episode reward: -0.0342,                 loss: nan
agent1:                 episode reward: 0.0342,                 loss: 0.1752
Episode: 6671/10000 (66.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8721s / 446.6632 s
agent0:                 episode reward: 1.3889,                 loss: nan
agent1:                 episode reward: -1.3889,                 loss: 0.2054
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8597s / 447.5228 s
agent0:                 episode reward: 0.2039,                 loss: nan
agent1:                 episode reward: -0.2039,                 loss: 0.2138
Episode: 6691/10000 (66.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8805s / 448.4033 s
agent0:                 episode reward: 0.9483,                 loss: nan
agent1:                 episode reward: -0.9483,                 loss: 0.2117
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8645s / 449.2678 s
agent0:                 episode reward: 0.5236,                 loss: nan
agent1:                 episode reward: -0.5236,                 loss: 0.2094
Episode: 6711/10000 (67.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8643s / 450.1321 s
agent0:                 episode reward: 1.1051,                 loss: nan
agent1:                 episode reward: -1.1051,                 loss: 0.2123
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8747s / 451.0068 s
agent0:                 episode reward: 0.7942,                 loss: nan
agent1:                 episode reward: -0.7942,                 loss: 0.2100
Episode: 6731/10000 (67.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8525s / 451.8594 s
agent0:                 episode reward: 0.0759,                 loss: nan
agent1:                 episode reward: -0.0759,                 loss: 0.2112
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8575s / 452.7169 s
agent0:                 episode reward: 1.5390,                 loss: nan
agent1:                 episode reward: -1.5390,                 loss: 0.2077
Episode: 6751/10000 (67.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8672s / 453.5841 s
agent0:                 episode reward: 1.7178,                 loss: nan
agent1:                 episode reward: -1.7178,                 loss: 0.2117
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8512s / 454.4353 s
agent0:                 episode reward: 0.8215,                 loss: nan
agent1:                 episode reward: -0.8215,                 loss: 0.2114
Episode: 6771/10000 (67.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8612s / 455.2965 s
agent0:                 episode reward: 0.8592,                 loss: nan
agent1:                 episode reward: -0.8592,                 loss: 0.2478
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9007s / 456.1973 s
agent0:                 episode reward: 1.2735,                 loss: nan
agent1:                 episode reward: -1.2735,                 loss: 0.2572
Episode: 6791/10000 (67.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8681s / 457.0654 s
agent0:                 episode reward: 0.3238,                 loss: nan
agent1:                 episode reward: -0.3238,                 loss: 0.2567
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8667s / 457.9320 s
agent0:                 episode reward: 0.0286,                 loss: nan
agent1:                 episode reward: -0.0286,                 loss: 0.2569
Episode: 6811/10000 (68.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8764s / 458.8085 s
agent0:                 episode reward: -0.8629,                 loss: nan
agent1:                 episode reward: 0.8629,                 loss: 0.2542
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8662s / 459.6747 s
agent0:                 episode reward: 1.4249,                 loss: nan
agent1:                 episode reward: -1.4249,                 loss: 0.2549
Episode: 6831/10000 (68.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8575s / 460.5322 s
agent0:                 episode reward: 2.0176,                 loss: nan
agent1:                 episode reward: -2.0176,                 loss: 0.2538
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8632s / 461.3953 s
agent0:                 episode reward: 0.4049,                 loss: nan
agent1:                 episode reward: -0.4049,                 loss: 0.2545
Episode: 6851/10000 (68.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8599s / 462.2552 s
agent0:                 episode reward: 1.0639,                 loss: nan
agent1:                 episode reward: -1.0639,                 loss: 0.2566
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8696s / 463.1248 s
agent0:                 episode reward: 1.2815,                 loss: nan
agent1:                 episode reward: -1.2815,                 loss: 0.2546
Episode: 6871/10000 (68.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8595s / 463.9842 s
agent0:                 episode reward: 0.9439,                 loss: nan
agent1:                 episode reward: -0.9439,                 loss: 0.2864
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8550s / 464.8393 s
agent0:                 episode reward: 0.6277,                 loss: nan
agent1:                 episode reward: -0.6277,                 loss: 0.2975
Episode: 6891/10000 (68.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8779s / 465.7172 s
agent0:                 episode reward: 0.3515,                 loss: nan
agent1:                 episode reward: -0.3515,                 loss: 0.2940
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9258s / 466.6430 s
agent0:                 episode reward: 0.3716,                 loss: nan
agent1:                 episode reward: -0.3716,                 loss: 0.2931
Episode: 6911/10000 (69.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8629s / 467.5059 s
agent0:                 episode reward: 0.8952,                 loss: nan
agent1:                 episode reward: -0.8952,                 loss: 0.2933
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8741s / 468.3800 s
agent0:                 episode reward: 0.4722,                 loss: nan
agent1:                 episode reward: -0.4722,                 loss: 0.2928
Episode: 6931/10000 (69.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8752s / 469.2552 s
agent0:                 episode reward: 0.3885,                 loss: nan
agent1:                 episode reward: -0.3885,                 loss: 0.2930
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8640s / 470.1192 s
agent0:                 episode reward: 0.5774,                 loss: nan
agent1:                 episode reward: -0.5774,                 loss: 0.2921
Episode: 6951/10000 (69.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8705s / 470.9898 s
agent0:                 episode reward: 0.0698,                 loss: nan
agent1:                 episode reward: -0.0698,                 loss: 0.2889
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8717s / 471.8615 s
agent0:                 episode reward: 1.2395,                 loss: nan
agent1:                 episode reward: -1.2395,                 loss: 0.2936
Episode: 6971/10000 (69.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8701s / 472.7316 s
agent0:                 episode reward: 0.3386,                 loss: nan
agent1:                 episode reward: -0.3386,                 loss: 0.3271
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8677s / 473.5993 s
agent0:                 episode reward: 0.2156,                 loss: nan
agent1:                 episode reward: -0.2156,                 loss: 0.3322
Episode: 6991/10000 (69.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8816s / 474.4808 s
agent0:                 episode reward: 0.0598,                 loss: nan
agent1:                 episode reward: -0.0598,                 loss: 0.3333
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8656s / 475.3465 s
agent0:                 episode reward: -0.2729,                 loss: nan
agent1:                 episode reward: 0.2729,                 loss: 0.3310
Episode: 7011/10000 (70.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8678s / 476.2143 s
agent0:                 episode reward: 0.1394,                 loss: nan
agent1:                 episode reward: -0.1394,                 loss: 0.3335
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9114s / 477.1257 s
agent0:                 episode reward: 0.7130,                 loss: nan
agent1:                 episode reward: -0.7130,                 loss: 0.3311
Episode: 7031/10000 (70.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8886s / 478.0144 s
agent0:                 episode reward: 0.1958,                 loss: nan
agent1:                 episode reward: -0.1958,                 loss: 0.3283
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8780s / 478.8924 s
agent0:                 episode reward: 0.1742,                 loss: nan
agent1:                 episode reward: -0.1742,                 loss: 0.3288
Episode: 7051/10000 (70.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8696s / 479.7620 s
agent0:                 episode reward: 1.1738,                 loss: nan
agent1:                 episode reward: -1.1738,                 loss: 0.3318
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8708s / 480.6328 s
agent0:                 episode reward: 0.3122,                 loss: nan
agent1:                 episode reward: -0.3122,                 loss: 0.3282
Episode: 7071/10000 (70.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8805s / 481.5133 s
agent0:                 episode reward: 0.2966,                 loss: nan
agent1:                 episode reward: -0.2966,                 loss: 0.3403
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8638s / 482.3771 s
agent0:                 episode reward: -0.2027,                 loss: nan
agent1:                 episode reward: 0.2027,                 loss: 0.3305
Episode: 7091/10000 (70.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8751s / 483.2523 s
agent0:                 episode reward: 0.6757,                 loss: nan
agent1:                 episode reward: -0.6757,                 loss: 0.3296
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8891s / 484.1414 s
agent0:                 episode reward: 0.3542,                 loss: nan
agent1:                 episode reward: -0.3542,                 loss: 0.3295
Episode: 7111/10000 (71.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8710s / 485.0124 s
agent0:                 episode reward: 0.4481,                 loss: nan
agent1:                 episode reward: -0.4481,                 loss: 0.3297
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8790s / 485.8914 s
agent0:                 episode reward: 1.0972,                 loss: nan
agent1:                 episode reward: -1.0972,                 loss: 0.3298
Episode: 7131/10000 (71.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9074s / 486.7989 s
agent0:                 episode reward: 1.0631,                 loss: nan
agent1:                 episode reward: -1.0631,                 loss: 0.3281
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8981s / 487.6970 s
agent0:                 episode reward: 0.2437,                 loss: nan
agent1:                 episode reward: -0.2437,                 loss: 0.3278
Episode: 7151/10000 (71.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8835s / 488.5805 s
agent0:                 episode reward: 1.0040,                 loss: nan
agent1:                 episode reward: -1.0040,                 loss: 0.3259
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8766s / 489.4571 s
agent0:                 episode reward: 0.3152,                 loss: nan
agent1:                 episode reward: -0.3152,                 loss: 0.3255
Episode: 7171/10000 (71.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8839s / 490.3410 s
agent0:                 episode reward: 0.2375,                 loss: nan
agent1:                 episode reward: -0.2375,                 loss: 0.3387
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8985s / 491.2395 s
agent0:                 episode reward: 0.5236,                 loss: nan
agent1:                 episode reward: -0.5236,                 loss: 0.3345
Episode: 7191/10000 (71.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8811s / 492.1206 s
agent0:                 episode reward: 0.5997,                 loss: nan
agent1:                 episode reward: -0.5997,                 loss: 0.3330
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8846s / 493.0051 s
agent0:                 episode reward: 0.3635,                 loss: nan
agent1:                 episode reward: -0.3635,                 loss: 0.3293
Episode: 7211/10000 (72.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8868s / 493.8920 s
agent0:                 episode reward: 0.6558,                 loss: nan
agent1:                 episode reward: -0.6558,                 loss: 0.3299
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9069s / 494.7989 s
agent0:                 episode reward: 0.9834,                 loss: nan
agent1:                 episode reward: -0.9834,                 loss: 0.3274
Episode: 7231/10000 (72.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8875s / 495.6864 s
agent0:                 episode reward: 1.3914,                 loss: nan
agent1:                 episode reward: -1.3914,                 loss: 0.3295
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9015s / 496.5878 s
agent0:                 episode reward: 0.3884,                 loss: nan
agent1:                 episode reward: -0.3884,                 loss: 0.3287
Episode: 7251/10000 (72.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9280s / 497.5158 s
agent0:                 episode reward: 0.7346,                 loss: nan
agent1:                 episode reward: -0.7346,                 loss: 0.3292
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8865s / 498.4023 s
agent0:                 episode reward: 0.2204,                 loss: nan
agent1:                 episode reward: -0.2204,                 loss: 0.3283
Episode: 7271/10000 (72.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9215s / 499.3238 s
agent0:                 episode reward: 1.1756,                 loss: nan
agent1:                 episode reward: -1.1756,                 loss: 0.3516
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8893s / 500.2132 s
agent0:                 episode reward: 0.8781,                 loss: nan
agent1:                 episode reward: -0.8781,                 loss: 0.3510
Episode: 7291/10000 (72.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8857s / 501.0988 s
agent0:                 episode reward: 0.0148,                 loss: nan
agent1:                 episode reward: -0.0148,                 loss: 0.3488
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8921s / 501.9910 s
agent0:                 episode reward: 0.6892,                 loss: nan
agent1:                 episode reward: -0.6892,                 loss: 0.3493
Episode: 7311/10000 (73.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8801s / 502.8711 s
agent0:                 episode reward: 0.2275,                 loss: nan
agent1:                 episode reward: -0.2275,                 loss: 0.3473
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8917s / 503.7628 s
agent0:                 episode reward: 0.9791,                 loss: nan
agent1:                 episode reward: -0.9791,                 loss: 0.3454
Episode: 7331/10000 (73.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8817s / 504.6445 s
agent0:                 episode reward: 0.5976,                 loss: nan
agent1:                 episode reward: -0.5976,                 loss: 0.3470
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8924s / 505.5369 s
agent0:                 episode reward: 0.0609,                 loss: nan
agent1:                 episode reward: -0.0609,                 loss: 0.3451
Episode: 7351/10000 (73.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8955s / 506.4324 s
agent0:                 episode reward: 0.6642,                 loss: nan
agent1:                 episode reward: -0.6642,                 loss: 0.3470
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9242s / 507.3566 s
agent0:                 episode reward: 0.5767,                 loss: nan
agent1:                 episode reward: -0.5767,                 loss: 0.3458
Episode: 7371/10000 (73.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9014s / 508.2580 s
agent0:                 episode reward: 0.3208,                 loss: nan
agent1:                 episode reward: -0.3208,                 loss: 0.3004
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9049s / 509.1629 s
agent0:                 episode reward: 1.3569,                 loss: nan
agent1:                 episode reward: -1.3569,                 loss: 0.2582
Episode: 7391/10000 (73.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8930s / 510.0559 s
agent0:                 episode reward: 0.7855,                 loss: nan
agent1:                 episode reward: -0.7855,                 loss: 0.2596
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9027s / 510.9586 s
agent0:                 episode reward: 0.2510,                 loss: nan
agent1:                 episode reward: -0.2510,                 loss: 0.2598
Episode: 7411/10000 (74.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8899s / 511.8485 s
agent0:                 episode reward: 0.8758,                 loss: nan
agent1:                 episode reward: -0.8758,                 loss: 0.2566
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8879s / 512.7363 s
agent0:                 episode reward: 1.3558,                 loss: nan
agent1:                 episode reward: -1.3558,                 loss: 0.2572
Episode: 7431/10000 (74.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8937s / 513.6300 s
agent0:                 episode reward: 0.4842,                 loss: nan
agent1:                 episode reward: -0.4842,                 loss: 0.2543
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8988s / 514.5288 s
agent0:                 episode reward: 0.0132,                 loss: nan
agent1:                 episode reward: -0.0132,                 loss: 0.2566
Episode: 7451/10000 (74.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9003s / 515.4291 s
agent0:                 episode reward: 0.2874,                 loss: nan
agent1:                 episode reward: -0.2874,                 loss: 0.2552
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9172s / 516.3463 s
agent0:                 episode reward: 1.0383,                 loss: nan
agent1:                 episode reward: -1.0383,                 loss: 0.2546
Episode: 7471/10000 (74.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9200s / 517.2663 s
agent0:                 episode reward: 0.4881,                 loss: nan
agent1:                 episode reward: -0.4881,                 loss: 0.2236
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9632s / 518.2295 s
agent0:                 episode reward: 0.7450,                 loss: nan
agent1:                 episode reward: -0.7450,                 loss: 0.2050
Episode: 7491/10000 (74.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9280s / 519.1575 s
agent0:                 episode reward: 0.8067,                 loss: nan
agent1:                 episode reward: -0.8067,                 loss: 0.2042
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9120s / 520.0694 s
agent0:                 episode reward: 0.2453,                 loss: nan
agent1:                 episode reward: -0.2453,                 loss: 0.2053
Episode: 7511/10000 (75.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9008s / 520.9702 s
agent0:                 episode reward: 0.3332,                 loss: nan
agent1:                 episode reward: -0.3332,                 loss: 0.2047
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9109s / 521.8812 s
agent0:                 episode reward: 0.1114,                 loss: nan
agent1:                 episode reward: -0.1114,                 loss: 0.2049
Episode: 7531/10000 (75.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9031s / 522.7843 s
agent0:                 episode reward: 0.8944,                 loss: nan
agent1:                 episode reward: -0.8944,                 loss: 0.2026
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9051s / 523.6893 s
agent0:                 episode reward: 0.2661,                 loss: nan
agent1:                 episode reward: -0.2661,                 loss: 0.2022
Episode: 7551/10000 (75.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9229s / 524.6122 s
agent0:                 episode reward: 0.6365,                 loss: nan
agent1:                 episode reward: -0.6365,                 loss: 0.2054
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9067s / 525.5189 s
agent0:                 episode reward: 1.3227,                 loss: nan
agent1:                 episode reward: -1.3227,                 loss: 0.2037
Episode: 7571/10000 (75.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9193s / 526.4383 s
agent0:                 episode reward: 0.5383,                 loss: nan
agent1:                 episode reward: -0.5383,                 loss: 0.2135
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9098s / 527.3481 s
agent0:                 episode reward: 0.1756,                 loss: nan
agent1:                 episode reward: -0.1756,                 loss: 0.2172
Episode: 7591/10000 (75.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9324s / 528.2805 s
agent0:                 episode reward: 0.1438,                 loss: nan
agent1:                 episode reward: -0.1438,                 loss: 0.2147
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9193s / 529.1998 s
agent0:                 episode reward: 1.0014,                 loss: nan
agent1:                 episode reward: -1.0014,                 loss: 0.2155
Episode: 7611/10000 (76.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9049s / 530.1047 s
agent0:                 episode reward: 1.7123,                 loss: nan
agent1:                 episode reward: -1.7123,                 loss: 0.2137
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9082s / 531.0129 s
agent0:                 episode reward: 0.1308,                 loss: nan
agent1:                 episode reward: -0.1308,                 loss: 0.2134
Episode: 7631/10000 (76.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9208s / 531.9337 s
agent0:                 episode reward: 0.2859,                 loss: nan
agent1:                 episode reward: -0.2859,                 loss: 0.2159
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9302s / 532.8639 s
agent0:                 episode reward: 1.1192,                 loss: nan
agent1:                 episode reward: -1.1192,                 loss: 0.2135
Episode: 7651/10000 (76.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9160s / 533.7799 s
agent0:                 episode reward: 0.7642,                 loss: nan
agent1:                 episode reward: -0.7642,                 loss: 0.2123
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9449s / 534.7249 s
agent0:                 episode reward: 0.1410,                 loss: nan
agent1:                 episode reward: -0.1410,                 loss: 0.2137
Episode: 7671/10000 (76.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9151s / 535.6400 s
agent0:                 episode reward: 0.3563,                 loss: nan
agent1:                 episode reward: -0.3563,                 loss: 0.2365
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9423s / 536.5823 s
agent0:                 episode reward: 0.5586,                 loss: nan
agent1:                 episode reward: -0.5586,                 loss: 0.2411
Episode: 7691/10000 (76.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9153s / 537.4976 s
agent0:                 episode reward: 0.1829,                 loss: nan
agent1:                 episode reward: -0.1829,                 loss: 0.2432
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9719s / 538.4695 s
agent0:                 episode reward: -0.2335,                 loss: nan
agent1:                 episode reward: 0.2335,                 loss: 0.2420
Episode: 7711/10000 (77.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9341s / 539.4036 s
agent0:                 episode reward: 0.0326,                 loss: nan
agent1:                 episode reward: -0.0326,                 loss: 0.2425
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9265s / 540.3301 s
agent0:                 episode reward: 0.6981,                 loss: nan
agent1:                 episode reward: -0.6981,                 loss: 0.2405
Episode: 7731/10000 (77.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9409s / 541.2710 s
agent0:                 episode reward: 1.2418,                 loss: nan
agent1:                 episode reward: -1.2418,                 loss: 0.2406
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9329s / 542.2039 s
agent0:                 episode reward: 0.5826,                 loss: nan
agent1:                 episode reward: -0.5826,                 loss: 0.2425
Episode: 7751/10000 (77.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9108s / 543.1147 s
agent0:                 episode reward: 1.2863,                 loss: nan
agent1:                 episode reward: -1.2863,                 loss: 0.2417
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9280s / 544.0427 s
agent0:                 episode reward: 0.1979,                 loss: nan
agent1:                 episode reward: -0.1979,                 loss: 0.2409
Episode: 7771/10000 (77.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9297s / 544.9724 s
agent0:                 episode reward: 0.3422,                 loss: nan
agent1:                 episode reward: -0.3422,                 loss: 0.2567
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9245s / 545.8969 s
agent0:                 episode reward: 0.9435,                 loss: nan
agent1:                 episode reward: -0.9435,                 loss: 0.2636
Episode: 7791/10000 (77.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9263s / 546.8232 s
agent0:                 episode reward: 0.7820,                 loss: nan
agent1:                 episode reward: -0.7820,                 loss: 0.2613
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9492s / 547.7724 s
agent0:                 episode reward: 1.5184,                 loss: nan
agent1:                 episode reward: -1.5184,                 loss: 0.2626
Episode: 7811/10000 (78.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9655s / 548.7379 s
agent0:                 episode reward: 1.2240,                 loss: nan
agent1:                 episode reward: -1.2240,                 loss: 0.2657
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9529s / 549.6909 s
agent0:                 episode reward: 0.5744,                 loss: nan
agent1:                 episode reward: -0.5744,                 loss: 0.2638
Episode: 7831/10000 (78.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9390s / 550.6299 s
agent0:                 episode reward: 1.0283,                 loss: nan
agent1:                 episode reward: -1.0283,                 loss: 0.2633
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9251s / 551.5550 s
agent0:                 episode reward: 0.1666,                 loss: nan
agent1:                 episode reward: -0.1666,                 loss: 0.2620
Episode: 7851/10000 (78.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9259s / 552.4809 s
agent0:                 episode reward: -0.1506,                 loss: nan
agent1:                 episode reward: 0.1506,                 loss: 0.2637
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9401s / 553.4210 s
agent0:                 episode reward: 0.2088,                 loss: nan
agent1:                 episode reward: -0.2088,                 loss: 0.2624
Episode: 7871/10000 (78.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9309s / 554.3519 s
agent0:                 episode reward: -0.5128,                 loss: nan
agent1:                 episode reward: 0.5128,                 loss: 0.2898
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9369s / 555.2887 s
agent0:                 episode reward: 1.0452,                 loss: nan
agent1:                 episode reward: -1.0452,                 loss: 0.2985
Episode: 7891/10000 (78.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9664s / 556.2551 s
agent0:                 episode reward: 1.2724,                 loss: nan
agent1:                 episode reward: -1.2724,                 loss: 0.2987
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9638s / 557.2189 s
agent0:                 episode reward: -0.0967,                 loss: nan
agent1:                 episode reward: 0.0967,                 loss: 0.2974
Episode: 7911/10000 (79.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9379s / 558.1568 s
agent0:                 episode reward: -0.7867,                 loss: nan
agent1:                 episode reward: 0.7867,                 loss: 0.2986
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9829s / 559.1398 s
agent0:                 episode reward: 0.6994,                 loss: nan
agent1:                 episode reward: -0.6994,                 loss: 0.2972
Episode: 7931/10000 (79.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9445s / 560.0843 s
agent0:                 episode reward: 0.0354,                 loss: nan
agent1:                 episode reward: -0.0354,                 loss: 0.2988
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9407s / 561.0250 s
agent0:                 episode reward: 0.5044,                 loss: nan
agent1:                 episode reward: -0.5044,                 loss: 0.2943
Episode: 7951/10000 (79.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9341s / 561.9590 s
agent0:                 episode reward: 1.2489,                 loss: nan
agent1:                 episode reward: -1.2489,                 loss: 0.2979
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9456s / 562.9047 s
agent0:                 episode reward: 0.9030,                 loss: nan
agent1:                 episode reward: -0.9030,                 loss: 0.3024
Episode: 7971/10000 (79.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9421s / 563.8468 s
agent0:                 episode reward: 0.7364,                 loss: nan
agent1:                 episode reward: -0.7364,                 loss: 0.3201
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9483s / 564.7951 s
agent0:                 episode reward: 0.4768,                 loss: nan
agent1:                 episode reward: -0.4768,                 loss: 0.3300
Episode: 7991/10000 (79.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9858s / 565.7809 s
agent0:                 episode reward: 0.1060,                 loss: nan
agent1:                 episode reward: -0.1060,                 loss: 0.3287
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9481s / 566.7290 s
agent0:                 episode reward: 0.1629,                 loss: nan
agent1:                 episode reward: -0.1629,                 loss: 0.3278
Episode: 8011/10000 (80.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9522s / 567.6812 s
agent0:                 episode reward: 0.4542,                 loss: nan
agent1:                 episode reward: -0.4542,                 loss: 0.3273
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9670s / 568.6482 s
agent0:                 episode reward: 0.8628,                 loss: nan
agent1:                 episode reward: -0.8628,                 loss: 0.3294
Episode: 8031/10000 (80.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9943s / 569.6425 s
agent0:                 episode reward: 1.3693,                 loss: nan
agent1:                 episode reward: -1.3693,                 loss: 0.3278
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9459s / 570.5883 s
agent0:                 episode reward: 0.6364,                 loss: nan
agent1:                 episode reward: -0.6364,                 loss: 0.3283
Episode: 8051/10000 (80.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9586s / 571.5470 s
agent0:                 episode reward: 1.1037,                 loss: nan
agent1:                 episode reward: -1.1037,                 loss: 0.3258
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9505s / 572.4975 s
agent0:                 episode reward: 0.6883,                 loss: nan
agent1:                 episode reward: -0.6883,                 loss: 0.3266
Episode: 8071/10000 (80.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9442s / 573.4417 s
agent0:                 episode reward: 0.3974,                 loss: nan
agent1:                 episode reward: -0.3974,                 loss: 0.3450
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9697s / 574.4114 s
agent0:                 episode reward: 0.3978,                 loss: nan
agent1:                 episode reward: -0.3978,                 loss: 0.3470
Episode: 8091/10000 (80.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9506s / 575.3620 s
agent0:                 episode reward: 0.1981,                 loss: nan
agent1:                 episode reward: -0.1981,                 loss: 0.3450
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9547s / 576.3167 s
agent0:                 episode reward: 0.7986,                 loss: nan
agent1:                 episode reward: -0.7986,                 loss: 0.3464
Episode: 8111/10000 (81.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9553s / 577.2720 s
agent0:                 episode reward: 0.7042,                 loss: nan
agent1:                 episode reward: -0.7042,                 loss: 0.3440
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9947s / 578.2666 s
agent0:                 episode reward: 0.6009,                 loss: nan
agent1:                 episode reward: -0.6009,                 loss: 0.3456
Episode: 8131/10000 (81.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9996s / 579.2662 s
agent0:                 episode reward: -0.2672,                 loss: nan
agent1:                 episode reward: 0.2672,                 loss: 0.3448
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9696s / 580.2358 s
agent0:                 episode reward: 0.1511,                 loss: nan
agent1:                 episode reward: -0.1511,                 loss: 0.3442
Episode: 8151/10000 (81.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9482s / 581.1840 s
agent0:                 episode reward: 0.3113,                 loss: nan
agent1:                 episode reward: -0.3113,                 loss: 0.3441
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9622s / 582.1462 s
agent0:                 episode reward: 1.3224,                 loss: nan
agent1:                 episode reward: -1.3224,                 loss: 0.3440
Episode: 8171/10000 (81.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9623s / 583.1085 s
agent0:                 episode reward: 0.2600,                 loss: nan
agent1:                 episode reward: -0.2600,                 loss: 0.3553
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9730s / 584.0815 s
agent0:                 episode reward: 0.3528,                 loss: nan
agent1:                 episode reward: -0.3528,                 loss: 0.3550
Episode: 8191/10000 (81.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9542s / 585.0357 s
agent0:                 episode reward: 1.2746,                 loss: nan
agent1:                 episode reward: -1.2746,                 loss: 0.3536
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9552s / 585.9909 s
agent0:                 episode reward: 0.1487,                 loss: nan
agent1:                 episode reward: -0.1487,                 loss: 0.3561
Episode: 8211/10000 (82.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9618s / 586.9526 s
agent0:                 episode reward: 0.5407,                 loss: nan
agent1:                 episode reward: -0.5407,                 loss: 0.3523
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9591s / 587.9117 s
agent0:                 episode reward: -0.3969,                 loss: nan
agent1:                 episode reward: 0.3969,                 loss: 0.3534
Episode: 8231/10000 (82.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9546s / 588.8664 s
agent0:                 episode reward: 0.1022,                 loss: nan
agent1:                 episode reward: -0.1022,                 loss: 0.3518
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0330s / 589.8993 s
agent0:                 episode reward: -0.2863,                 loss: nan
agent1:                 episode reward: 0.2863,                 loss: 0.3514
Episode: 8251/10000 (82.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0287s / 590.9280 s
agent0:                 episode reward: -0.0853,                 loss: nan
agent1:                 episode reward: 0.0853,                 loss: 0.3506
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9546s / 591.8826 s
agent0:                 episode reward: 0.1632,                 loss: nan
agent1:                 episode reward: -0.1632,                 loss: 0.3523
Episode: 8271/10000 (82.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9593s / 592.8419 s
agent0:                 episode reward: 1.2118,                 loss: nan
agent1:                 episode reward: -1.2118,                 loss: 0.3652
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9645s / 593.8064 s
agent0:                 episode reward: 0.1939,                 loss: nan
agent1:                 episode reward: -0.1939,                 loss: 0.3689
Episode: 8291/10000 (82.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9611s / 594.7675 s
agent0:                 episode reward: 0.7944,                 loss: nan
agent1:                 episode reward: -0.7944,                 loss: 0.3674
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9740s / 595.7415 s
agent0:                 episode reward: 0.3666,                 loss: nan
agent1:                 episode reward: -0.3666,                 loss: 0.3693
Episode: 8311/10000 (83.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9726s / 596.7141 s
agent0:                 episode reward: 0.6224,                 loss: nan
agent1:                 episode reward: -0.6224,                 loss: 0.3696
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9636s / 597.6777 s
agent0:                 episode reward: 1.7748,                 loss: nan
agent1:                 episode reward: -1.7748,                 loss: 0.3682
Episode: 8331/10000 (83.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9933s / 598.6709 s
agent0:                 episode reward: 0.2621,                 loss: nan
agent1:                 episode reward: -0.2621,                 loss: 0.3669
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0200s / 599.6909 s
agent0:                 episode reward: 0.8131,                 loss: nan
agent1:                 episode reward: -0.8131,                 loss: 0.3650
Episode: 8351/10000 (83.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9869s / 600.6779 s
agent0:                 episode reward: 0.0864,                 loss: nan
agent1:                 episode reward: -0.0864,                 loss: 0.3655
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9814s / 601.6593 s
agent0:                 episode reward: 0.3727,                 loss: nan
agent1:                 episode reward: -0.3727,                 loss: 0.3668
Episode: 8371/10000 (83.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9627s / 602.6220 s
agent0:                 episode reward: 0.1534,                 loss: nan
agent1:                 episode reward: -0.1534,                 loss: 0.3750
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9763s / 603.5983 s
agent0:                 episode reward: 0.1247,                 loss: nan
agent1:                 episode reward: -0.1247,                 loss: 0.3736
Episode: 8391/10000 (83.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9708s / 604.5691 s
agent0:                 episode reward: 0.4336,                 loss: nan
agent1:                 episode reward: -0.4336,                 loss: 0.3765
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9730s / 605.5422 s
agent0:                 episode reward: 0.4680,                 loss: nan
agent1:                 episode reward: -0.4680,                 loss: 0.3732
Episode: 8411/10000 (84.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9725s / 606.5147 s
agent0:                 episode reward: -0.0773,                 loss: nan
agent1:                 episode reward: 0.0773,                 loss: 0.3744
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9948s / 607.5095 s
agent0:                 episode reward: 1.1323,                 loss: nan
agent1:                 episode reward: -1.1323,                 loss: 0.3743
Episode: 8431/10000 (84.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9640s / 608.4735 s
agent0:                 episode reward: 0.2618,                 loss: nan
agent1:                 episode reward: -0.2618,                 loss: 0.3743
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9767s / 609.4502 s
agent0:                 episode reward: 0.1242,                 loss: nan
agent1:                 episode reward: -0.1242,                 loss: 0.3745
Episode: 8451/10000 (84.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0298s / 610.4800 s
agent0:                 episode reward: 0.7571,                 loss: nan
agent1:                 episode reward: -0.7571,                 loss: 0.3730
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9746s / 611.4547 s
agent0:                 episode reward: 1.3901,                 loss: nan
agent1:                 episode reward: -1.3901,                 loss: 0.3737
Episode: 8471/10000 (84.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9887s / 612.4433 s
agent0:                 episode reward: 0.6614,                 loss: nan
agent1:                 episode reward: -0.6614,                 loss: 0.3474
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9846s / 613.4279 s
agent0:                 episode reward: 0.7967,                 loss: nan
agent1:                 episode reward: -0.7967,                 loss: 0.3281
Episode: 8491/10000 (84.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9848s / 614.4127 s
agent0:                 episode reward: -0.2014,                 loss: nan
agent1:                 episode reward: 0.2014,                 loss: 0.3251
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0008s / 615.4135 s
agent0:                 episode reward: -0.1578,                 loss: nan
agent1:                 episode reward: 0.1578,                 loss: 0.3264
Episode: 8511/10000 (85.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0005s / 616.4140 s
agent0:                 episode reward: -0.1855,                 loss: nan
agent1:                 episode reward: 0.1855,                 loss: 0.3245
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9832s / 617.3972 s
agent0:                 episode reward: 0.3180,                 loss: nan
agent1:                 episode reward: -0.3180,                 loss: 0.3242
Episode: 8531/10000 (85.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9854s / 618.3827 s
agent0:                 episode reward: 0.4312,                 loss: nan
agent1:                 episode reward: -0.4312,                 loss: 0.3237
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9944s / 619.3770 s
agent0:                 episode reward: 0.2166,                 loss: nan
agent1:                 episode reward: -0.2166,                 loss: 0.3242
Episode: 8551/10000 (85.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0353s / 620.4124 s
agent0:                 episode reward: 0.4218,                 loss: nan
agent1:                 episode reward: -0.4218,                 loss: 0.3219
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9933s / 621.4057 s
agent0:                 episode reward: -0.1084,                 loss: nan
agent1:                 episode reward: 0.1084,                 loss: 0.3241
Episode: 8571/10000 (85.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9869s / 622.3926 s
agent0:                 episode reward: -0.6660,                 loss: nan
agent1:                 episode reward: 0.6660,                 loss: 0.2731
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9960s / 623.3886 s
agent0:                 episode reward: 0.2619,                 loss: nan
agent1:                 episode reward: -0.2619,                 loss: 0.2454
Episode: 8591/10000 (85.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9886s / 624.3772 s
agent0:                 episode reward: 0.7244,                 loss: nan
agent1:                 episode reward: -0.7244,                 loss: 0.2427
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9964s / 625.3737 s
agent0:                 episode reward: -0.4888,                 loss: nan
agent1:                 episode reward: 0.4888,                 loss: 0.2421
Episode: 8611/10000 (86.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9917s / 626.3653 s
agent0:                 episode reward: 0.5263,                 loss: nan
agent1:                 episode reward: -0.5263,                 loss: 0.2418
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9884s / 627.3537 s
agent0:                 episode reward: 0.1384,                 loss: nan
agent1:                 episode reward: -0.1384,                 loss: 0.2383
Episode: 8631/10000 (86.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9856s / 628.3393 s
agent0:                 episode reward: -0.3588,                 loss: nan
agent1:                 episode reward: 0.3588,                 loss: 0.2416
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9920s / 629.3314 s
agent0:                 episode reward: 0.4140,                 loss: nan
agent1:                 episode reward: -0.4140,                 loss: 0.2373
Episode: 8651/10000 (86.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0614s / 630.3927 s
agent0:                 episode reward: 0.3110,                 loss: nan
agent1:                 episode reward: -0.3110,                 loss: 0.2395
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9980s / 631.3908 s
agent0:                 episode reward: 0.3341,                 loss: nan
agent1:                 episode reward: -0.3341,                 loss: 0.2388
Episode: 8671/10000 (86.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0207s / 632.4115 s
agent0:                 episode reward: 1.4620,                 loss: nan
agent1:                 episode reward: -1.4620,                 loss: 0.2276
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9985s / 633.4100 s
agent0:                 episode reward: 0.9467,                 loss: nan
agent1:                 episode reward: -0.9467,                 loss: 0.2184
Episode: 8691/10000 (86.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0172s / 634.4272 s
agent0:                 episode reward: -0.4110,                 loss: nan
agent1:                 episode reward: 0.4110,                 loss: 0.2174
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0019s / 635.4291 s
agent0:                 episode reward: 0.4232,                 loss: nan
agent1:                 episode reward: -0.4232,                 loss: 0.2186
Episode: 8711/10000 (87.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9945s / 636.4236 s
agent0:                 episode reward: 0.0055,                 loss: nan
agent1:                 episode reward: -0.0055,                 loss: 0.2177
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9986s / 637.4222 s
agent0:                 episode reward: 0.1092,                 loss: nan
agent1:                 episode reward: -0.1092,                 loss: 0.2182
Episode: 8731/10000 (87.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0012s / 638.4234 s
agent0:                 episode reward: 0.4349,                 loss: nan
agent1:                 episode reward: -0.4349,                 loss: 0.2143
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9880s / 639.4114 s
agent0:                 episode reward: 0.6426,                 loss: nan
agent1:                 episode reward: -0.6426,                 loss: 0.2168
Episode: 8751/10000 (87.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0504s / 640.4618 s
agent0:                 episode reward: -0.4952,                 loss: nan
agent1:                 episode reward: 0.4952,                 loss: 0.2167
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0048s / 641.4666 s
agent0:                 episode reward: 0.9163,                 loss: nan
agent1:                 episode reward: -0.9163,                 loss: 0.2159
Episode: 8771/10000 (87.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0017s / 642.4683 s
agent0:                 episode reward: 0.5038,                 loss: nan
agent1:                 episode reward: -0.5038,                 loss: 0.2336
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0150s / 643.4833 s
agent0:                 episode reward: 1.1880,                 loss: nan
agent1:                 episode reward: -1.1880,                 loss: 0.2407
Episode: 8791/10000 (87.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0112s / 644.4945 s
agent0:                 episode reward: 1.0913,                 loss: nan
agent1:                 episode reward: -1.0913,                 loss: 0.2388
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0067s / 645.5012 s
agent0:                 episode reward: 0.5655,                 loss: nan
agent1:                 episode reward: -0.5655,                 loss: 0.2392
Episode: 8811/10000 (88.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0153s / 646.5165 s
agent0:                 episode reward: 0.2204,                 loss: nan
agent1:                 episode reward: -0.2204,                 loss: 0.2393
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9999s / 647.5164 s
agent0:                 episode reward: 1.2618,                 loss: nan
agent1:                 episode reward: -1.2618,                 loss: 0.2384
Episode: 8831/10000 (88.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0245s / 648.5409 s
agent0:                 episode reward: 0.1948,                 loss: nan
agent1:                 episode reward: -0.1948,                 loss: 0.2372
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0204s / 649.5614 s
agent0:                 episode reward: 0.6169,                 loss: nan
agent1:                 episode reward: -0.6169,                 loss: 0.2395
Episode: 8851/10000 (88.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0386s / 650.6000 s
agent0:                 episode reward: 0.9164,                 loss: nan
agent1:                 episode reward: -0.9164,                 loss: 0.2378
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0082s / 651.6082 s
agent0:                 episode reward: 0.8763,                 loss: nan
agent1:                 episode reward: -0.8763,                 loss: 0.2385
Episode: 8871/10000 (88.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0233s / 652.6314 s
agent0:                 episode reward: -0.4838,                 loss: nan
agent1:                 episode reward: 0.4838,                 loss: 0.2618
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0018s / 653.6332 s
agent0:                 episode reward: 0.5896,                 loss: nan
agent1:                 episode reward: -0.5896,                 loss: 0.2699
Episode: 8891/10000 (88.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0224s / 654.6556 s
agent0:                 episode reward: 1.4637,                 loss: nan
agent1:                 episode reward: -1.4637,                 loss: 0.2694
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0296s / 655.6851 s
agent0:                 episode reward: 0.0184,                 loss: nan
agent1:                 episode reward: -0.0184,                 loss: 0.2690
Episode: 8911/10000 (89.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0312s / 656.7163 s
agent0:                 episode reward: -0.1764,                 loss: nan
agent1:                 episode reward: 0.1764,                 loss: 0.2695
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0131s / 657.7295 s
agent0:                 episode reward: 1.6873,                 loss: nan
agent1:                 episode reward: -1.6873,                 loss: 0.2718
Episode: 8931/10000 (89.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0210s / 658.7505 s
agent0:                 episode reward: -0.0964,                 loss: nan
agent1:                 episode reward: 0.0964,                 loss: 0.2691
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0212s / 659.7718 s
agent0:                 episode reward: 0.4700,                 loss: nan
agent1:                 episode reward: -0.4700,                 loss: 0.2709
Episode: 8951/10000 (89.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0450s / 660.8167 s
agent0:                 episode reward: -0.0812,                 loss: nan
agent1:                 episode reward: 0.0812,                 loss: 0.2709
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0287s / 661.8454 s
agent0:                 episode reward: 0.0483,                 loss: nan
agent1:                 episode reward: -0.0483,                 loss: 0.2704
Episode: 8971/10000 (89.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0194s / 662.8649 s
agent0:                 episode reward: 0.6631,                 loss: nan
agent1:                 episode reward: -0.6631,                 loss: 0.2984
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0230s / 663.8879 s
agent0:                 episode reward: 0.5842,                 loss: nan
agent1:                 episode reward: -0.5842,                 loss: 0.3082
Episode: 8991/10000 (89.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0428s / 664.9307 s
agent0:                 episode reward: 0.7956,                 loss: nan
agent1:                 episode reward: -0.7956,                 loss: 0.3097
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0348s / 665.9654 s
agent0:                 episode reward: -0.9015,                 loss: nan
agent1:                 episode reward: 0.9015,                 loss: 0.3091
Episode: 9011/10000 (90.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0455s / 667.0110 s
agent0:                 episode reward: 0.7146,                 loss: nan
agent1:                 episode reward: -0.7146,                 loss: 0.3081
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0313s / 668.0422 s
agent0:                 episode reward: 0.8186,                 loss: nan
agent1:                 episode reward: -0.8186,                 loss: 0.3073
Episode: 9031/10000 (90.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0294s / 669.0717 s
agent0:                 episode reward: 0.0000,                 loss: nan
agent1:                 episode reward: -0.0000,                 loss: 0.3080
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0225s / 670.0942 s
agent0:                 episode reward: 0.4081,                 loss: nan
agent1:                 episode reward: -0.4081,                 loss: 0.3090
Episode: 9051/10000 (90.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0857s / 671.1799 s
agent0:                 episode reward: -0.0575,                 loss: nan
agent1:                 episode reward: 0.0575,                 loss: 0.3067
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0876s / 672.2675 s
agent0:                 episode reward: 0.9989,                 loss: nan
agent1:                 episode reward: -0.9989,                 loss: 0.3063
Episode: 9071/10000 (90.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0483s / 673.3158 s
agent0:                 episode reward: 0.6582,                 loss: nan
agent1:                 episode reward: -0.6582,                 loss: 0.3274
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0286s / 674.3444 s
agent0:                 episode reward: 0.9254,                 loss: nan
agent1:                 episode reward: -0.9254,                 loss: 0.3357
Episode: 9091/10000 (90.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0385s / 675.3829 s
agent0:                 episode reward: 1.1223,                 loss: nan
agent1:                 episode reward: -1.1223,                 loss: 0.3345
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0384s / 676.4213 s
agent0:                 episode reward: 0.6710,                 loss: nan
agent1:                 episode reward: -0.6710,                 loss: 0.3320
Episode: 9111/10000 (91.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0276s / 677.4489 s
agent0:                 episode reward: -0.2447,                 loss: nan
agent1:                 episode reward: 0.2447,                 loss: 0.3311
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0344s / 678.4832 s
agent0:                 episode reward: 1.0810,                 loss: nan
agent1:                 episode reward: -1.0810,                 loss: 0.3356
Episode: 9131/10000 (91.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0618s / 679.5450 s
agent0:                 episode reward: -0.7518,                 loss: nan
agent1:                 episode reward: 0.7518,                 loss: 0.3350
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0306s / 680.5756 s
agent0:                 episode reward: 0.2501,                 loss: nan
agent1:                 episode reward: -0.2501,                 loss: 0.3329
Episode: 9151/10000 (91.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0758s / 681.6514 s
agent0:                 episode reward: 0.2980,                 loss: nan
agent1:                 episode reward: -0.2980,                 loss: 0.3323
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0339s / 682.6853 s
agent0:                 episode reward: -0.0892,                 loss: nan
agent1:                 episode reward: 0.0892,                 loss: 0.3327
Episode: 9171/10000 (91.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0271s / 683.7124 s
agent0:                 episode reward: -0.0552,                 loss: nan
agent1:                 episode reward: 0.0552,                 loss: 0.3488
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0321s / 684.7445 s
agent0:                 episode reward: -0.2035,                 loss: nan
agent1:                 episode reward: 0.2035,                 loss: 0.3508
Episode: 9191/10000 (91.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0518s / 685.7963 s
agent0:                 episode reward: 1.3427,                 loss: nan
agent1:                 episode reward: -1.3427,                 loss: 0.3484
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0347s / 686.8310 s
agent0:                 episode reward: 1.0257,                 loss: nan
agent1:                 episode reward: -1.0257,                 loss: 0.3480
Episode: 9211/10000 (92.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0299s / 687.8609 s
agent0:                 episode reward: 0.1004,                 loss: nan
agent1:                 episode reward: -0.1004,                 loss: 0.3531
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0298s / 688.8908 s
agent0:                 episode reward: 0.3395,                 loss: nan
agent1:                 episode reward: -0.3395,                 loss: 0.3514
Episode: 9231/10000 (92.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0406s / 689.9314 s
agent0:                 episode reward: 1.1614,                 loss: nan
agent1:                 episode reward: -1.1614,                 loss: 0.3498
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0322s / 690.9636 s
agent0:                 episode reward: 1.1917,                 loss: nan
agent1:                 episode reward: -1.1917,                 loss: 0.3471
Episode: 9251/10000 (92.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1206s / 692.0843 s
agent0:                 episode reward: 0.6649,                 loss: nan
agent1:                 episode reward: -0.6649,                 loss: 0.3509
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0276s / 693.1118 s
agent0:                 episode reward: 0.2372,                 loss: nan
agent1:                 episode reward: -0.2372,                 loss: 0.3506
Episode: 9271/10000 (92.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0378s / 694.1496 s
agent0:                 episode reward: -0.3197,                 loss: nan
agent1:                 episode reward: 0.3197,                 loss: 0.3628
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0370s / 695.1866 s
agent0:                 episode reward: 0.0713,                 loss: nan
agent1:                 episode reward: -0.0713,                 loss: 0.3638
Episode: 9291/10000 (92.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0376s / 696.2243 s
agent0:                 episode reward: 0.3315,                 loss: nan
agent1:                 episode reward: -0.3315,                 loss: 0.3634
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0462s / 697.2705 s
agent0:                 episode reward: 0.2737,                 loss: nan
agent1:                 episode reward: -0.2737,                 loss: 0.3618
Episode: 9311/10000 (93.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0700s / 698.3404 s
agent0:                 episode reward: 0.2520,                 loss: nan
agent1:                 episode reward: -0.2520,                 loss: 0.3609
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0398s / 699.3802 s
agent0:                 episode reward: 0.5263,                 loss: nan
agent1:                 episode reward: -0.5263,                 loss: 0.3620
Episode: 9331/10000 (93.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0538s / 700.4340 s
agent0:                 episode reward: -0.4028,                 loss: nan
agent1:                 episode reward: 0.4028,                 loss: 0.3625
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0485s / 701.4824 s
agent0:                 episode reward: 0.1616,                 loss: nan
agent1:                 episode reward: -0.1616,                 loss: 0.3612
Episode: 9351/10000 (93.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0781s / 702.5605 s
agent0:                 episode reward: 0.9270,                 loss: nan
agent1:                 episode reward: -0.9270,                 loss: 0.3618
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0520s / 703.6126 s
agent0:                 episode reward: 0.6538,                 loss: nan
agent1:                 episode reward: -0.6538,                 loss: 0.3619
Episode: 9371/10000 (93.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0395s / 704.6521 s
agent0:                 episode reward: 0.5368,                 loss: nan
agent1:                 episode reward: -0.5368,                 loss: 0.3697
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0433s / 705.6954 s
agent0:                 episode reward: 0.7207,                 loss: nan
agent1:                 episode reward: -0.7207,                 loss: 0.3726
Episode: 9391/10000 (93.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0865s / 706.7820 s
agent0:                 episode reward: -0.2334,                 loss: nan
agent1:                 episode reward: 0.2334,                 loss: 0.3731
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0438s / 707.8258 s
agent0:                 episode reward: -0.8003,                 loss: nan
agent1:                 episode reward: 0.8003,                 loss: 0.3735
Episode: 9411/10000 (94.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0513s / 708.8771 s
agent0:                 episode reward: 0.8434,                 loss: nan
agent1:                 episode reward: -0.8434,                 loss: 0.3723
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0581s / 709.9352 s
agent0:                 episode reward: -0.2935,                 loss: nan
agent1:                 episode reward: 0.2935,                 loss: 0.3712
Episode: 9431/10000 (94.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0495s / 710.9847 s
agent0:                 episode reward: 1.2815,                 loss: nan
agent1:                 episode reward: -1.2815,                 loss: 0.3721
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0815s / 712.0662 s
agent0:                 episode reward: 0.8087,                 loss: nan
agent1:                 episode reward: -0.8087,                 loss: 0.3723
Episode: 9451/10000 (94.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0734s / 713.1396 s
agent0:                 episode reward: 0.3223,                 loss: nan
agent1:                 episode reward: -0.3223,                 loss: 0.3720
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0472s / 714.1867 s
agent0:                 episode reward: 0.4402,                 loss: nan
agent1:                 episode reward: -0.4402,                 loss: 0.3702
Episode: 9471/10000 (94.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0887s / 715.2755 s
agent0:                 episode reward: 0.7752,                 loss: nan
agent1:                 episode reward: -0.7752,                 loss: 0.3768
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0528s / 716.3283 s
agent0:                 episode reward: -0.4017,                 loss: nan
agent1:                 episode reward: 0.4017,                 loss: 0.3742
Episode: 9491/10000 (94.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0614s / 717.3897 s
agent0:                 episode reward: 0.7251,                 loss: nan
agent1:                 episode reward: -0.7251,                 loss: 0.3745
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0639s / 718.4536 s
agent0:                 episode reward: 0.2173,                 loss: nan
agent1:                 episode reward: -0.2173,                 loss: 0.3755
Episode: 9511/10000 (95.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0494s / 719.5030 s
agent0:                 episode reward: 0.4654,                 loss: nan
agent1:                 episode reward: -0.4654,                 loss: 0.3743
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0540s / 720.5569 s
agent0:                 episode reward: 0.2811,                 loss: nan
agent1:                 episode reward: -0.2811,                 loss: 0.3747
Episode: 9531/10000 (95.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0925s / 721.6494 s
agent0:                 episode reward: -0.3232,                 loss: nan
agent1:                 episode reward: 0.3232,                 loss: 0.3721
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1279s / 722.7773 s
agent0:                 episode reward: 1.4370,                 loss: nan
agent1:                 episode reward: -1.4370,                 loss: 0.3729
Episode: 9551/10000 (95.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0861s / 723.8635 s
agent0:                 episode reward: 0.6243,                 loss: nan
agent1:                 episode reward: -0.6243,                 loss: 0.3746
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0675s / 724.9309 s
agent0:                 episode reward: 0.3286,                 loss: nan
agent1:                 episode reward: -0.3286,                 loss: 0.3732
Episode: 9571/10000 (95.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0562s / 725.9871 s
agent0:                 episode reward: 0.3826,                 loss: nan
agent1:                 episode reward: -0.3826,                 loss: 0.3314
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0607s / 727.0478 s
agent0:                 episode reward: 0.5124,                 loss: nan
agent1:                 episode reward: -0.5124,                 loss: 0.3078
Episode: 9591/10000 (95.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0731s / 728.1209 s
agent0:                 episode reward: 0.2908,                 loss: nan
agent1:                 episode reward: -0.2908,                 loss: 0.3082
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0618s / 729.1827 s
agent0:                 episode reward: -0.1357,                 loss: nan
agent1:                 episode reward: 0.1357,                 loss: 0.3065
Episode: 9611/10000 (96.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0602s / 730.2429 s
agent0:                 episode reward: 1.4047,                 loss: nan
agent1:                 episode reward: -1.4047,                 loss: 0.3081
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0841s / 731.3270 s
agent0:                 episode reward: 0.0935,                 loss: nan
agent1:                 episode reward: -0.0935,                 loss: 0.3073
Episode: 9631/10000 (96.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0882s / 732.4151 s
agent0:                 episode reward: 0.5939,                 loss: nan
agent1:                 episode reward: -0.5939,                 loss: 0.3048
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1249s / 733.5400 s
agent0:                 episode reward: 0.0592,                 loss: nan
agent1:                 episode reward: -0.0592,                 loss: 0.3071
Episode: 9651/10000 (96.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0671s / 734.6071 s
agent0:                 episode reward: 0.8144,                 loss: nan
agent1:                 episode reward: -0.8144,                 loss: 0.3052
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0568s / 735.6639 s
agent0:                 episode reward: 0.3905,                 loss: nan
agent1:                 episode reward: -0.3905,                 loss: 0.3037
Episode: 9671/10000 (96.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0785s / 736.7425 s
agent0:                 episode reward: 0.4017,                 loss: nan
agent1:                 episode reward: -0.4017,                 loss: 0.2627
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0658s / 737.8083 s
agent0:                 episode reward: 0.6554,                 loss: nan
agent1:                 episode reward: -0.6554,                 loss: 0.2413
Episode: 9691/10000 (96.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0734s / 738.8817 s
agent0:                 episode reward: -0.3687,                 loss: nan
agent1:                 episode reward: 0.3687,                 loss: 0.2424
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0827s / 739.9644 s
agent0:                 episode reward: 0.6014,                 loss: nan
agent1:                 episode reward: -0.6014,                 loss: 0.2403
Episode: 9711/10000 (97.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0716s / 741.0359 s
agent0:                 episode reward: 0.5320,                 loss: nan
agent1:                 episode reward: -0.5320,                 loss: 0.2398
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0967s / 742.1326 s
agent0:                 episode reward: -0.5254,                 loss: nan
agent1:                 episode reward: 0.5254,                 loss: 0.2404
Episode: 9731/10000 (97.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1115s / 743.2441 s
agent0:                 episode reward: 0.0973,                 loss: nan
agent1:                 episode reward: -0.0973,                 loss: 0.2377
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0827s / 744.3269 s
agent0:                 episode reward: 1.4441,                 loss: nan
agent1:                 episode reward: -1.4441,                 loss: 0.2378
Episode: 9751/10000 (97.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0804s / 745.4073 s
agent0:                 episode reward: -0.2000,                 loss: nan
agent1:                 episode reward: 0.2000,                 loss: 0.2383
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0773s / 746.4846 s
agent0:                 episode reward: 0.1771,                 loss: nan
agent1:                 episode reward: -0.1771,                 loss: 0.2370
Episode: 9771/10000 (97.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0736s / 747.5582 s
agent0:                 episode reward: 0.0160,                 loss: nan
agent1:                 episode reward: -0.0160,                 loss: 0.2270
Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1077s / 748.6659 s
agent0:                 episode reward: 1.2405,                 loss: nan
agent1:                 episode reward: -1.2405,                 loss: 0.2214
Episode: 9791/10000 (97.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0750s / 749.7409 s
agent0:                 episode reward: 1.5535,                 loss: nan
agent1:                 episode reward: -1.5535,                 loss: 0.2219
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0762s / 750.8171 s
agent0:                 episode reward: 1.3470,                 loss: nan
agent1:                 episode reward: -1.3470,                 loss: 0.2199
Episode: 9811/10000 (98.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0805s / 751.8977 s
agent0:                 episode reward: 0.3436,                 loss: nan
agent1:                 episode reward: -0.3436,                 loss: 0.2225
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0996s / 752.9973 s
agent0:                 episode reward: 0.5170,                 loss: nan
agent1:                 episode reward: -0.5170,                 loss: 0.2200
Episode: 9831/10000 (98.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1255s / 754.1228 s
agent0:                 episode reward: 0.0136,                 loss: nan
agent1:                 episode reward: -0.0136,                 loss: 0.2198
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1019s / 755.2246 s
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
agent0:                 episode reward: -0.3328,                 loss: nan
agent1:                 episode reward: 0.3328,                 loss: 0.2202
Episode: 9851/10000 (98.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0931s / 756.3177 s
agent0:                 episode reward: -0.0429,                 loss: nan
agent1:                 episode reward: 0.0429,                 loss: 0.2199
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0861s / 757.4038 s
agent0:                 episode reward: 1.1721,                 loss: nan
agent1:                 episode reward: -1.1721,                 loss: 0.2205
Episode: 9871/10000 (98.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0777s / 758.4815 s
agent0:                 episode reward: 0.8716,                 loss: nan
agent1:                 episode reward: -0.8716,                 loss: 0.2382
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0797s / 759.5612 s
agent0:                 episode reward: 1.3846,                 loss: nan
agent1:                 episode reward: -1.3846,                 loss: 0.2430
Episode: 9891/10000 (98.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0890s / 760.6502 s
agent0:                 episode reward: 1.9987,                 loss: nan
agent1:                 episode reward: -1.9987,                 loss: 0.2400
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0863s / 761.7365 s
agent0:                 episode reward: 0.9788,                 loss: nan
agent1:                 episode reward: -0.9788,                 loss: 0.2418
Episode: 9911/10000 (99.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0954s / 762.8319 s
agent0:                 episode reward: 0.0383,                 loss: nan
agent1:                 episode reward: -0.0383,                 loss: 0.2414
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1259s / 763.9579 s
agent0:                 episode reward: -0.0711,                 loss: nan
agent1:                 episode reward: 0.0711,                 loss: 0.2412
Episode: 9931/10000 (99.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0990s / 765.0568 s
agent0:                 episode reward: 0.3236,                 loss: nan
agent1:                 episode reward: -0.3236,                 loss: 0.2408
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0867s / 766.1436 s
agent0:                 episode reward: 0.7678,                 loss: nan
agent1:                 episode reward: -0.7678,                 loss: 0.2413
Episode: 9951/10000 (99.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0916s / 767.2352 s
agent0:                 episode reward: 0.8186,                 loss: nan
agent1:                 episode reward: -0.8186,                 loss: 0.2433
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0866s / 768.3217 s
agent0:                 episode reward: -0.1961,                 loss: nan
agent1:                 episode reward: 0.1961,                 loss: 0.2418
Episode: 9971/10000 (99.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0980s / 769.4198 s
agent0:                 episode reward: 0.9260,                 loss: nan
agent1:                 episode reward: -0.9260,                 loss: 0.2604
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0869s / 770.5067 s
agent0:                 episode reward: -0.8107,                 loss: nan
agent1:                 episode reward: 0.8107,                 loss: 0.2712
Episode: 9991/10000 (99.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0873s / 771.5940 s
agent0:                 episode reward: 0.2392,                 loss: nan
agent1:                 episode reward: -0.2392,                 loss: 0.2684
