pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=1024, bias=True)
      (1): Tanh()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Tanh()
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Linear(in_features=1024, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=1024, bias=True)
      (1): Tanh()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Tanh()
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Linear(in_features=1024, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [1024, 1024, 1024], 'hidden_activation': 'Tanh', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0521/slimevolley_SlimeVolley-v0_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0521/slimevolley_SlimeVolley-v0_nash_dqn.
Episode: 1/10000 (0.0100%),                 avg. length: 458.0,                last time consumption/overall running time: 3.7437s / 3.7437 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0194
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0152
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 582.9,                last time consumption/overall running time: 101.0770s / 104.8207 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0139
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0139
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 584.95,                last time consumption/overall running time: 159.8417s / 264.6624 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0126
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 552.75,                last time consumption/overall running time: 240.8518s / 505.5142 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0118
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0137
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 605.0,                last time consumption/overall running time: 299.6210s / 805.1352 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 590.4,                last time consumption/overall running time: 313.8490s / 1118.9842 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0127
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 575.95,                last time consumption/overall running time: 319.7158s / 1438.6999 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 530.9,                last time consumption/overall running time: 301.6986s / 1740.3985 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0148
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0143
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 554.7,                last time consumption/overall running time: 323.0565s / 2063.4550 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0162
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0157
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 604.2,                last time consumption/overall running time: 354.6994s / 2418.1544 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0163
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0162
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 620.05,                last time consumption/overall running time: 365.1217s / 2783.2761 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0167
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0182
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 590.7,                last time consumption/overall running time: 352.2989s / 3135.5750 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0178
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0192
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 591.4,                last time consumption/overall running time: 357.3279s / 3492.9029 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0196
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0164
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 575.9,                last time consumption/overall running time: 343.9264s / 3836.8294 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0194
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0199
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 628.7,                last time consumption/overall running time: 379.3070s / 4216.1364 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0193
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0201
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 612.65,                last time consumption/overall running time: 370.8274s / 4586.9638 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0218
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0208
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 566.05,                last time consumption/overall running time: 343.6865s / 4930.6504 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0203
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0210
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 601.05,                last time consumption/overall running time: 361.8956s / 5292.5459 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0196
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0233
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 542.3,                last time consumption/overall running time: 327.3953s / 5619.9412 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0204
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0229
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 570.45,                last time consumption/overall running time: 342.2690s / 5962.2103 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0202
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0222
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 560.05,                last time consumption/overall running time: 335.6943s / 6297.9046 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0235
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0220
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 570.15,                last time consumption/overall running time: 342.9671s / 6640.8717 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0202
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0217
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 575.0,                last time consumption/overall running time: 348.3291s / 6989.2008 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0217
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0225
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 552.6,                last time consumption/overall running time: 337.0912s / 7326.2920 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0204
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0202
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 569.7,                last time consumption/overall running time: 344.5155s / 7670.8075 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0196
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0215
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 590.25,                last time consumption/overall running time: 356.7877s / 8027.5953 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0195
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0201
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 585.0,                last time consumption/overall running time: 357.6550s / 8385.2503 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0216
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0218
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 598.35,                last time consumption/overall running time: 362.1631s / 8747.4134 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0209
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0213
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 556.8,                last time consumption/overall running time: 333.5865s / 9080.9999 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0215
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0215
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 573.0,                last time consumption/overall running time: 349.2769s / 9430.2768 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0207
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0212
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 527.05,                last time consumption/overall running time: 318.7017s / 9748.9785 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0208
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0216
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 629.75,                last time consumption/overall running time: 380.1031s / 10129.0816 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0206
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0199
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 570.5,                last time consumption/overall running time: 344.9972s / 10474.0787 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0222
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0211
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 566.55,                last time consumption/overall running time: 338.4297s / 10812.5084 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0216
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0213
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 548.1,                last time consumption/overall running time: 332.8345s / 11145.3429 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0211
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0204
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 562.4,                last time consumption/overall running time: 341.5397s / 11486.8826 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0244
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0203
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 556.35,                last time consumption/overall running time: 333.0603s / 11819.9429 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0218
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0205
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 561.25,                last time consumption/overall running time: 342.2015s / 12162.1444 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0205
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0201
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 575.5,                last time consumption/overall running time: 347.1532s / 12509.2976 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0214
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0205
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 532.15,                last time consumption/overall running time: 323.0428s / 12832.3404 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0203
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0190
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 592.95,                last time consumption/overall running time: 356.8370s / 13189.1774 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0200
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0199
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 549.5,                last time consumption/overall running time: 333.3316s / 13522.5090 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0199
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0206
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 568.75,                last time consumption/overall running time: 344.5484s / 13867.0574 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0209
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0193
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 557.95,                last time consumption/overall running time: 335.0186s / 14202.0760 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0214
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0209
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 596.1,                last time consumption/overall running time: 363.0829s / 14565.1589 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0226
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0222
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 559.2,                last time consumption/overall running time: 336.7787s / 14901.9376 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0218
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0221
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 543.3,                last time consumption/overall running time: 329.8472s / 15231.7848 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0224
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0214
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 588.5,                last time consumption/overall running time: 356.6228s / 15588.4075 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0215
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0206
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 577.7,                last time consumption/overall running time: 348.3965s / 15936.8041 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0225
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0228
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 599.0,                last time consumption/overall running time: 361.8593s / 16298.6634 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0224
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0214
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 564.45,                last time consumption/overall running time: 341.7184s / 16640.3818 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0237
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0213
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 575.55,                last time consumption/overall running time: 345.1504s / 16985.5322 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0221
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0210
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 579.75,                last time consumption/overall running time: 347.2684s / 17332.8006 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0198
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0224
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 557.5,                last time consumption/overall running time: 332.3017s / 17665.1023 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0199
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0213
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 562.9,                last time consumption/overall running time: 335.8439s / 18000.9462 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0198
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0211
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 563.45,                last time consumption/overall running time: 338.4835s / 18339.4297 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0217
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0223
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 564.55,                last time consumption/overall running time: 341.3834s / 18680.8131 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0209
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 539.85,                last time consumption/overall running time: 323.5282s / 19004.3413 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0224
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0213
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 568.2,                last time consumption/overall running time: 343.1147s / 19347.4560 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0242
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 559.3,                last time consumption/overall running time: 336.2582s / 19683.7142 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0238
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0229
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 579.4,                last time consumption/overall running time: 346.5772s / 20030.2914 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0243
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0207
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 576.95,                last time consumption/overall running time: 347.3347s / 20377.6260 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0230
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0219
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 547.8,                last time consumption/overall running time: 327.3493s / 20704.9753 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0243
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0213
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 574.4,                last time consumption/overall running time: 344.8758s / 21049.8511 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0241
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0222
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 595.5,                last time consumption/overall running time: 360.0508s / 21409.9019 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0246
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0233
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 573.5,                last time consumption/overall running time: 345.1277s / 21755.0296 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0237
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0226
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 592.3,                last time consumption/overall running time: 363.2195s / 22118.2492 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0233
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0228
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 553.7,                last time consumption/overall running time: 336.8917s / 22455.1409 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0227
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0222
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 567.45,                last time consumption/overall running time: 344.1292s / 22799.2701 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0235
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 584.35,                last time consumption/overall running time: 355.8739s / 23155.1440 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0248
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0225
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 583.1,                last time consumption/overall running time: 352.4370s / 23507.5810 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0252
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 577.05,                last time consumption/overall running time: 348.2090s / 23855.7900 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0232
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0234
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 594.45,                last time consumption/overall running time: 357.2619s / 24213.0520 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0228
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0227
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 566.0,                last time consumption/overall running time: 342.2145s / 24555.2665 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0227
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0241
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 577.15,                last time consumption/overall running time: 350.2750s / 24905.5415 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0224
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0228
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 555.0,                last time consumption/overall running time: 334.6271s / 25240.1686 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0228
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0221
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 575.1,                last time consumption/overall running time: 348.9357s / 25589.1043 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0218
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0213
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 605.75,                last time consumption/overall running time: 365.1532s / 25954.2575 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0225
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0225
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 560.0,                last time consumption/overall running time: 336.8670s / 26291.1244 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0225
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0234
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 552.85,                last time consumption/overall running time: 334.6187s / 26625.7431 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0226
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0237
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 562.3,                last time consumption/overall running time: 342.2201s / 26967.9633 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0225
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0226
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 556.5,                last time consumption/overall running time: 335.6759s / 27303.6392 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0226
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0251
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 551.8,                last time consumption/overall running time: 333.1313s / 27636.7705 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0230
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 572.3,                last time consumption/overall running time: 350.0796s / 27986.8501 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0233
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 579.45,                last time consumption/overall running time: 348.7784s / 28335.6285 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0227
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0260
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 562.6,                last time consumption/overall running time: 342.6495s / 28678.2780 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0220
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 557.65,                last time consumption/overall running time: 336.9207s / 29015.1987 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0242
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0236
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 560.3,                last time consumption/overall running time: 339.6595s / 29354.8582 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0232
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0245
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 582.6,                last time consumption/overall running time: 351.2107s / 29706.0688 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0258
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0243
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 587.15,                last time consumption/overall running time: 355.1347s / 30061.2036 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0251
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0236
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 598.4,                last time consumption/overall running time: 361.2619s / 30422.4654 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0235
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0224
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 548.05,                last time consumption/overall running time: 334.2269s / 30756.6924 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0236
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0223
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 551.05,                last time consumption/overall running time: 335.6913s / 31092.3837 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0235
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0225
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 547.7,                last time consumption/overall running time: 329.5141s / 31421.8978 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0234
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0231
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 632.25,                last time consumption/overall running time: 383.4900s / 31805.3877 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0254
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0228
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 576.55,                last time consumption/overall running time: 354.0035s / 32159.3912 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0223
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0242
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 572.25,                last time consumption/overall running time: 348.6796s / 32508.0708 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0228
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0251
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 581.8,                last time consumption/overall running time: 351.5627s / 32859.6335 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0219
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 556.75,                last time consumption/overall running time: 337.8738s / 33197.5073 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0219
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0229
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 569.15,                last time consumption/overall running time: 343.8269s / 33541.3341 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0229
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0239
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 578.0,                last time consumption/overall running time: 344.8865s / 33886.2206 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0231
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 586.0,                last time consumption/overall running time: 354.1783s / 34240.3989 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0225
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0242
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 579.65,                last time consumption/overall running time: 352.7013s / 34593.1002 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0224
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0218
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 599.5,                last time consumption/overall running time: 364.7477s / 34957.8479 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0220
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0240
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 577.05,                last time consumption/overall running time: 349.8245s / 35307.6724 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0215
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0223
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 567.65,                last time consumption/overall running time: 339.6290s / 35647.3014 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0234
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 550.1,                last time consumption/overall running time: 332.0620s / 35979.3634 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0242
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0219
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 555.6,                last time consumption/overall running time: 333.9437s / 36313.3071 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0258
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0229
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 619.85,                last time consumption/overall running time: 373.3728s / 36686.6799 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0231
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0236
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 549.3,                last time consumption/overall running time: 329.0288s / 37015.7088 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0249
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0232
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 592.65,                last time consumption/overall running time: 363.5759s / 37379.2846 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0244
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0238
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 576.8,                last time consumption/overall running time: 384.6710s / 37763.9557 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0242
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0229
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 553.6,                last time consumption/overall running time: 395.2252s / 38159.1809 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0254
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0242
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 587.7,                last time consumption/overall running time: 422.1782s / 38581.3590 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0230
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0232
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 604.6,                last time consumption/overall running time: 444.5720s / 39025.9310 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0255
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0230
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 614.25,                last time consumption/overall running time: 444.6371s / 39470.5681 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0217
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0223
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 585.3,                last time consumption/overall running time: 420.7997s / 39891.3677 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0229
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0224
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 551.8,                last time consumption/overall running time: 397.5345s / 40288.9022 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0214
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 578.8,                last time consumption/overall running time: 417.3459s / 40706.2481 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0224
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0237
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 569.9,                last time consumption/overall running time: 411.7915s / 41118.0396 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0206
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0245
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 587.6,                last time consumption/overall running time: 425.4874s / 41543.5269 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0224
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0233
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 582.35,                last time consumption/overall running time: 420.5384s / 41964.0653 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0218
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0230
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 567.55,                last time consumption/overall running time: 410.2993s / 42374.3646 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0216
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0244
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 561.3,                last time consumption/overall running time: 406.0664s / 42780.4310 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0221
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0244
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 594.3,                last time consumption/overall running time: 430.8904s / 43211.3214 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0245
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0256
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 520.35,                last time consumption/overall running time: 379.2156s / 43590.5371 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0224
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0242
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 572.15,                last time consumption/overall running time: 414.4392s / 44004.9762 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 591.6,                last time consumption/overall running time: 428.5434s / 44433.5196 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0257
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 582.15,                last time consumption/overall running time: 420.1758s / 44853.6954 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0245
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0267
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 542.25,                last time consumption/overall running time: 392.8764s / 45246.5718 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0244
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 576.55,                last time consumption/overall running time: 416.3010s / 45662.8728 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0231
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0220
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 599.3,                last time consumption/overall running time: 438.1792s / 46101.0520 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0207
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0226
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 573.1,                last time consumption/overall running time: 415.0434s / 46516.0954 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0209
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0216
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 568.05,                last time consumption/overall running time: 420.3306s / 46936.4260 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0219
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0243
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 592.3,                last time consumption/overall running time: 429.9041s / 47366.3302 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0205
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0227
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 552.6,                last time consumption/overall running time: 407.3276s / 47773.6578 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0229
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0232
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 595.85,                last time consumption/overall running time: 431.8919s / 48205.5496 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0212
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0239
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 604.35,                last time consumption/overall running time: 438.1619s / 48643.7115 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0215
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0239
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 579.7,                last time consumption/overall running time: 424.9575s / 49068.6690 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0227
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0250
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 565.45,                last time consumption/overall running time: 415.9840s / 49484.6530 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0227
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0236
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 586.1,                last time consumption/overall running time: 427.4467s / 49912.0997 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0226
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 544.35,                last time consumption/overall running time: 394.0138s / 50306.1135 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0204
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 571.05,                last time consumption/overall running time: 413.6040s / 50719.7175 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0218
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0239
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 567.95,                last time consumption/overall running time: 411.7998s / 51131.5173 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0221
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0246
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 571.6,                last time consumption/overall running time: 417.6817s / 51549.1990 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0208
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0249
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 587.2,                last time consumption/overall running time: 434.0184s / 51983.2174 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0218
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0268
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 593.05,                last time consumption/overall running time: 434.2522s / 52417.4696 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0220
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0255
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 542.8,                last time consumption/overall running time: 395.4731s / 52812.9428 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0235
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0238
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 581.55,                last time consumption/overall running time: 424.2928s / 53237.2356 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0217
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0248
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 571.0,                last time consumption/overall running time: 417.3276s / 53654.5631 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0204
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 585.35,                last time consumption/overall running time: 426.7057s / 54081.2689 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0235
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0212
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 590.55,                last time consumption/overall running time: 428.7612s / 54510.0301 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0227
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0219
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 559.3,                last time consumption/overall running time: 409.1209s / 54919.1510 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0225
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0241
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 550.45,                last time consumption/overall running time: 400.1584s / 55319.3094 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0228
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0238
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 552.1,                last time consumption/overall running time: 405.8868s / 55725.1962 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0247
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0243
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 572.4,                last time consumption/overall running time: 412.7628s / 56137.9590 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0233
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0236
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 566.4,                last time consumption/overall running time: 410.8926s / 56548.8516 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0260
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0236
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 554.55,                last time consumption/overall running time: 403.5433s / 56952.3949 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0242
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 538.35,                last time consumption/overall running time: 392.2063s / 57344.6012 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0241
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0217
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 584.2,                last time consumption/overall running time: 425.2942s / 57769.8954 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0243
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0237
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 542.75,                last time consumption/overall running time: 395.0270s / 58164.9224 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0219
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0247
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 574.7,                last time consumption/overall running time: 417.4623s / 58582.3846 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0255
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0242
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 570.25,                last time consumption/overall running time: 413.3563s / 58995.7409 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0231
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0257
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 590.2,                last time consumption/overall running time: 429.1564s / 59424.8973 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0245
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 590.2,                last time consumption/overall running time: 424.7377s / 59849.6350 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0227
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0238
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 564.4,                last time consumption/overall running time: 404.6160s / 60254.2510 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0253
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0235
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 576.3,                last time consumption/overall running time: 417.1118s / 60671.3628 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0232
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0246
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 596.45,                last time consumption/overall running time: 436.5917s / 61107.9545 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0245
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0235
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 552.65,                last time consumption/overall running time: 402.6075s / 61510.5620 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0235
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0244
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 576.15,                last time consumption/overall running time: 421.8160s / 61932.3780 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0227
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0222
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 561.0,                last time consumption/overall running time: 409.7431s / 62342.1211 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0235
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0253
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 581.85,                last time consumption/overall running time: 421.1244s / 62763.2455 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0223
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0252
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 592.15,                last time consumption/overall running time: 432.7784s / 63196.0239 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0221
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0257
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 561.1,                last time consumption/overall running time: 411.9090s / 63607.9330 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0248
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0221
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 592.85,                last time consumption/overall running time: 431.9969s / 64039.9299 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0230
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0241
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 511.05,                last time consumption/overall running time: 372.3674s / 64412.2973 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0251
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0260
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 570.35,                last time consumption/overall running time: 415.8433s / 64828.1405 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0238
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0231
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 573.65,                last time consumption/overall running time: 416.3455s / 65244.4860 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0235
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0240
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 553.1,                last time consumption/overall running time: 403.6155s / 65648.1015 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0233
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0215
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 600.95,                last time consumption/overall running time: 436.2307s / 66084.3322 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0246
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 586.8,                last time consumption/overall running time: 432.0281s / 66516.3603 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0222
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0260
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 594.6,                last time consumption/overall running time: 432.8089s / 66949.1692 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0233
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 569.0,                last time consumption/overall running time: 408.9239s / 67358.0931 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0248
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0246
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 576.05,                last time consumption/overall running time: 418.5708s / 67776.6639 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0238
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0231
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 553.0,                last time consumption/overall running time: 404.4141s / 68181.0780 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0241
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0249
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 553.8,                last time consumption/overall running time: 405.0336s / 68586.1116 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0233
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0252
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 550.85,                last time consumption/overall running time: 407.0106s / 68993.1223 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0220
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0246
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 568.0,                last time consumption/overall running time: 417.6930s / 69410.8152 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0227
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0236
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 535.5,                last time consumption/overall running time: 389.2993s / 69800.1145 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0230
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 561.1,                last time consumption/overall running time: 409.2388s / 70209.3534 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0256
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0234
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 561.7,                last time consumption/overall running time: 411.6092s / 70620.9626 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0225
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0237
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 636.3,                last time consumption/overall running time: 461.1468s / 71082.1094 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0241
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 551.8,                last time consumption/overall running time: 401.6539s / 71483.7633 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0223
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0224
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 564.8,                last time consumption/overall running time: 408.4111s / 71892.1744 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0241
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0228
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 557.5,                last time consumption/overall running time: 401.8094s / 72293.9838 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0216
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0218
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 564.25,                last time consumption/overall running time: 408.3059s / 72702.2897 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0236
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0213
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 578.75,                last time consumption/overall running time: 417.1297s / 73119.4195 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0215
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0220
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 585.65,                last time consumption/overall running time: 419.6432s / 73539.0626 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0216
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0214
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 590.15,                last time consumption/overall running time: 426.3199s / 73965.3825 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0234
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0209
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 546.95,                last time consumption/overall running time: 394.4751s / 74359.8576 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0233
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0218
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 576.55,                last time consumption/overall running time: 421.3211s / 74781.1786 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0250
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0253
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 589.05,                last time consumption/overall running time: 431.6719s / 75212.8506 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0262
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0233
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 574.65,                last time consumption/overall running time: 416.7382s / 75629.5888 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0269
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0240
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 577.0,                last time consumption/overall running time: 423.0216s / 76052.6103 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 573.05,                last time consumption/overall running time: 418.3035s / 76470.9138 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0246
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0253
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 567.15,                last time consumption/overall running time: 413.3809s / 76884.2948 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0253
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0247
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 563.8,                last time consumption/overall running time: 409.2965s / 77293.5913 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0243
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0230
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 543.95,                last time consumption/overall running time: 395.2987s / 77688.8900 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0263
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0221
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 606.7,                last time consumption/overall running time: 446.0458s / 78134.9358 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0236
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0215
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 563.2,                last time consumption/overall running time: 414.9629s / 78549.8987 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0225
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0226
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 528.2,                last time consumption/overall running time: 380.3776s / 78930.2763 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0240
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0235
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 561.75,                last time consumption/overall running time: 404.0075s / 79334.2838 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0227
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0218
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 600.15,                last time consumption/overall running time: 436.1845s / 79770.4683 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0242
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0231
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 578.1,                last time consumption/overall running time: 421.4287s / 80191.8970 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0225
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0228
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 601.45,                last time consumption/overall running time: 443.5021s / 80635.3991 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0218
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0232
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 603.9,                last time consumption/overall running time: 443.9946s / 81079.3937 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0219
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0221
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 553.15,                last time consumption/overall running time: 402.5615s / 81481.9552 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0239
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0225
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 584.15,                last time consumption/overall running time: 426.4551s / 81908.4104 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0234
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0229
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 564.15,                last time consumption/overall running time: 411.8128s / 82320.2232 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0243
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0201
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 565.25,                last time consumption/overall running time: 418.3815s / 82738.6047 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0223
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 583.5,                last time consumption/overall running time: 427.2589s / 83165.8636 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0245
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0237
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 596.85,                last time consumption/overall running time: 436.0440s / 83601.9076 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0259
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0213
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 558.85,                last time consumption/overall running time: 405.5479s / 84007.4555 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0263
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0245
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 567.2,                last time consumption/overall running time: 414.6800s / 84422.1354 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0236
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0235
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 571.6,                last time consumption/overall running time: 410.0840s / 84832.2194 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0233
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 558.3,                last time consumption/overall running time: 407.5229s / 85239.7423 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0250
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0229
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 544.9,                last time consumption/overall running time: 394.1145s / 85633.8568 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0238
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0241
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 566.0,                last time consumption/overall running time: 517.9970s / 86151.8539 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0251
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0238
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 595.55,                last time consumption/overall running time: 434.5040s / 86586.3579 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0242
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 587.0,                last time consumption/overall running time: 427.9402s / 87014.2981 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0227
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0254
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 538.55,                last time consumption/overall running time: 392.9976s / 87407.2957 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0229
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0242
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 569.25,                last time consumption/overall running time: 413.8201s / 87821.1158 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0247
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0250
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 573.35,                last time consumption/overall running time: 419.1691s / 88240.2849 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0253
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 561.4,                last time consumption/overall running time: 409.5684s / 88649.8533 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0247
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 588.4,                last time consumption/overall running time: 431.2884s / 89081.1417 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0230
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0254
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 550.15,                last time consumption/overall running time: 402.9287s / 89484.0704 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0228
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 609.95,                last time consumption/overall running time: 445.4894s / 89929.5598 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0242
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 544.7,                last time consumption/overall running time: 400.9775s / 90330.5374 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0249
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0255
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 566.9,                last time consumption/overall running time: 410.6735s / 90741.2109 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0272
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0241
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 569.15,                last time consumption/overall running time: 415.3468s / 91156.5576 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0253
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0255
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 571.3,                last time consumption/overall running time: 414.2231s / 91570.7808 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0256
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0240
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 542.3,                last time consumption/overall running time: 396.7263s / 91967.5070 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0244
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0236
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 586.95,                last time consumption/overall running time: 435.9661s / 92403.4731 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0246
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0214
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 602.4,                last time consumption/overall running time: 438.2769s / 92841.7501 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0247
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0230
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 624.6,                last time consumption/overall running time: 456.5468s / 93298.2969 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0258
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0237
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 530.55,                last time consumption/overall running time: 388.4829s / 93686.7798 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0251
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0228
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 573.5,                last time consumption/overall running time: 419.8938s / 94106.6736 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0227
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 559.85,                last time consumption/overall running time: 413.5634s / 94520.2370 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0246
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0224
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 615.2,                last time consumption/overall running time: 448.5110s / 94968.7480 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0252
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0241
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 516.8,                last time consumption/overall running time: 378.3005s / 95347.0485 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0258
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0202
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 567.15,                last time consumption/overall running time: 415.0969s / 95762.1455 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0259
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0239
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 539.95,                last time consumption/overall running time: 392.1233s / 96154.2687 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0262
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0238
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 536.2,                last time consumption/overall running time: 389.8299s / 96544.0986 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0241
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0228
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 555.5,                last time consumption/overall running time: 406.5011s / 96950.5998 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0248
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 538.3,                last time consumption/overall running time: 392.7248s / 97343.3246 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0220
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0236
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 576.3,                last time consumption/overall running time: 414.9244s / 97758.2490 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0255
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0227
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 571.2,                last time consumption/overall running time: 409.9741s / 98168.2231 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0252
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0228
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 574.4,                last time consumption/overall running time: 413.3844s / 98581.6075 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0261
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0239
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 594.7,                last time consumption/overall running time: 422.4281s / 99004.0356 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0244
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0244
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 577.05,                last time consumption/overall running time: 411.3035s / 99415.3390 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0250
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0230
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 586.05,                last time consumption/overall running time: 417.0683s / 99832.4073 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0235
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0241
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 491.3,                last time consumption/overall running time: 348.6837s / 100181.0910 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0234
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0213
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 527.6,                last time consumption/overall running time: 372.3847s / 100553.4757 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0222
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0233
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 578.1,                last time consumption/overall running time: 410.3075s / 100963.7832 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0247
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0233
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 586.95,                last time consumption/overall running time: 414.0851s / 101377.8683 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0253
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0223
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 562.85,                last time consumption/overall running time: 404.4450s / 101782.3134 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0239
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0234
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 549.1,                last time consumption/overall running time: 393.7837s / 102176.0971 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0228
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0238
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 568.9,                last time consumption/overall running time: 408.3169s / 102584.4140 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0239
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0222
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 583.0,                last time consumption/overall running time: 417.3629s / 103001.7769 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0265
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0215
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 581.75,                last time consumption/overall running time: 419.6256s / 103421.4025 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0252
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0227
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 572.85,                last time consumption/overall running time: 412.4379s / 103833.8403 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0242
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 583.75,                last time consumption/overall running time: 415.9112s / 104249.7515 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0240
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0248
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 539.95,                last time consumption/overall running time: 384.7018s / 104634.4534 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0253
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0252
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 574.5,                last time consumption/overall running time: 409.0106s / 105043.4640 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0228
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0236
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 542.9,                last time consumption/overall running time: 391.9876s / 105435.4516 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0233
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0231
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 556.0,                last time consumption/overall running time: 404.0260s / 105839.4776 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0235
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0252
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 545.05,                last time consumption/overall running time: 393.7280s / 106233.2056 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0210
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0248
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 537.45,                last time consumption/overall running time: 384.8648s / 106618.0703 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0225
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0242
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 604.3,                last time consumption/overall running time: 431.7433s / 107049.8137 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0227
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0239
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 546.25,                last time consumption/overall running time: 392.0593s / 107441.8730 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0225
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 561.0,                last time consumption/overall running time: 401.0074s / 107842.8803 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0210
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 573.15,                last time consumption/overall running time: 412.3147s / 108255.1950 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0222
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0233
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 564.1,                last time consumption/overall running time: 403.2992s / 108658.4942 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0223
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0214
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 610.55,                last time consumption/overall running time: 439.0385s / 109097.5327 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0232
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 587.65,                last time consumption/overall running time: 421.8294s / 109519.3620 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0260
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0244
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 563.85,                last time consumption/overall running time: 403.0019s / 109922.3639 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0242
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0255
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 581.2,                last time consumption/overall running time: 411.4747s / 110333.8386 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0252
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0246
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 587.65,                last time consumption/overall running time: 417.1367s / 110750.9753 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0229
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 578.45,                last time consumption/overall running time: 415.8603s / 111166.8356 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0244
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0247
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 577.1,                last time consumption/overall running time: 417.9124s / 111584.7481 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0256
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0255
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 582.6,                last time consumption/overall running time: 417.8865s / 112002.6346 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0237
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0236
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 579.25,                last time consumption/overall running time: 415.1094s / 112417.7440 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0266
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0236
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 580.75,                last time consumption/overall running time: 412.6733s / 112830.4173 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0225
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0215
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 557.1,                last time consumption/overall running time: 399.0332s / 113229.4505 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0242
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0232
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 541.75,                last time consumption/overall running time: 388.8984s / 113618.3489 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0253
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0239
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 566.8,                last time consumption/overall running time: 405.1209s / 114023.4698 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0240
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 551.3,                last time consumption/overall running time: 397.1233s / 114420.5931 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0238
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 583.75,                last time consumption/overall running time: 415.7896s / 114836.3827 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0257
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0248
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 585.15,                last time consumption/overall running time: 422.8587s / 115259.2413 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0214
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0224
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 544.5,                last time consumption/overall running time: 391.5908s / 115650.8321 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0229
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 525.35,                last time consumption/overall running time: 378.6289s / 116029.4610 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0243
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0224
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 535.55,                last time consumption/overall running time: 384.4953s / 116413.9563 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0227
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0222
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 583.9,                last time consumption/overall running time: 418.3246s / 116832.2809 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0233
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 593.6,                last time consumption/overall running time: 426.0519s / 117258.3328 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0244
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0236
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 604.25,                last time consumption/overall running time: 432.5336s / 117690.8664 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0255
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0225
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 599.4,                last time consumption/overall running time: 423.9586s / 118114.8250 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0267
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0239
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 542.4,                last time consumption/overall running time: 383.9776s / 118498.8025 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0260
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0259
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 563.35,                last time consumption/overall running time: 396.5484s / 118895.3510 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0264
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 600.35,                last time consumption/overall running time: 431.0612s / 119326.4122 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0237
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0226
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 551.65,                last time consumption/overall running time: 390.8971s / 119717.3093 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0233
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0235
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 596.9,                last time consumption/overall running time: 428.3929s / 120145.7022 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0221
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0238
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 568.85,                last time consumption/overall running time: 405.9143s / 120551.6164 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0244
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0216
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 607.0,                last time consumption/overall running time: 435.6336s / 120987.2500 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0242
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0241
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 550.1,                last time consumption/overall running time: 391.5378s / 121378.7878 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0256
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0245
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 554.0,                last time consumption/overall running time: 395.6896s / 121774.4773 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0237
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 572.0,                last time consumption/overall running time: 407.6364s / 122182.1137 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0232
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0238
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 548.55,                last time consumption/overall running time: 393.4223s / 122575.5360 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0245
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0257
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 562.2,                last time consumption/overall running time: 400.3279s / 122975.8639 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0229
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0256
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 561.6,                last time consumption/overall running time: 397.3084s / 123373.1723 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0251
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 580.5,                last time consumption/overall running time: 418.5557s / 123791.7280 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0234
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0261
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 582.15,                last time consumption/overall running time: 417.9703s / 124209.6983 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0260
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0247
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 585.05,                last time consumption/overall running time: 420.7982s / 124630.4965 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0249
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0262
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 548.7,                last time consumption/overall running time: 390.6453s / 125021.1418 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0231
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0237
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 605.0,                last time consumption/overall running time: 436.3616s / 125457.5035 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0241
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0238
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 572.5,                last time consumption/overall running time: 405.8034s / 125863.3069 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0243
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 574.3,                last time consumption/overall running time: 409.5533s / 126272.8602 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0232
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0253
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 526.45,                last time consumption/overall running time: 377.0505s / 126649.9108 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0230
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 565.55,                last time consumption/overall running time: 406.0390s / 127055.9498 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0235
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0250
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 593.05,                last time consumption/overall running time: 422.0697s / 127478.0195 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0228
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0245
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 558.95,                last time consumption/overall running time: 398.6120s / 127876.6315 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0247
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0253
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 588.6,                last time consumption/overall running time: 422.6349s / 128299.2664 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0248
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0244
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 584.05,                last time consumption/overall running time: 413.8601s / 128713.1264 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0253
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0222
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 592.7,                last time consumption/overall running time: 423.3487s / 129136.4751 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0253
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0236
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 531.7,                last time consumption/overall running time: 378.0144s / 129514.4896 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0245
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 589.4,                last time consumption/overall running time: 421.5420s / 129936.0316 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0242
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0249
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 575.25,                last time consumption/overall running time: 417.2787s / 130353.3103 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0222
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0236
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 565.5,                last time consumption/overall running time: 403.9784s / 130757.2887 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0232
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 575.8,                last time consumption/overall running time: 408.7963s / 131166.0850 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0238
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0253
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 582.45,                last time consumption/overall running time: 416.6015s / 131582.6865 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0246
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0245
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 606.5,                last time consumption/overall running time: 434.0785s / 132016.7650 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0233
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 579.5,                last time consumption/overall running time: 412.1247s / 132428.8897 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0220
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0265
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 568.9,                last time consumption/overall running time: 403.8278s / 132832.7176 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0237
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0232
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 563.1,                last time consumption/overall running time: 403.4098s / 133236.1274 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0240
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0250
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 574.25,                last time consumption/overall running time: 410.3043s / 133646.4316 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0252
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0249
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 531.8,                last time consumption/overall running time: 381.9407s / 134028.3723 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0234
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 560.3,                last time consumption/overall running time: 393.8994s / 134422.2717 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0241
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0273
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 606.75,                last time consumption/overall running time: 436.5319s / 134858.8036 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0230
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0255
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 558.6,                last time consumption/overall running time: 399.3633s / 135258.1669 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0252
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0256
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 550.25,                last time consumption/overall running time: 394.8497s / 135653.0166 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0243
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0253
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 592.15,                last time consumption/overall running time: 429.3097s / 136082.3263 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0250
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0256
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 579.6,                last time consumption/overall running time: 411.2172s / 136493.5435 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0253
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0230
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 574.05,                last time consumption/overall running time: 414.1312s / 136907.6747 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0256
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 574.35,                last time consumption/overall running time: 412.2383s / 137319.9130 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0252
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0241
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 557.5,                last time consumption/overall running time: 403.0074s / 137722.9204 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0236
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0237
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 598.85,                last time consumption/overall running time: 430.2426s / 138153.1630 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0255
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0226
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 575.65,                last time consumption/overall running time: 410.0239s / 138563.1869 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0243
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0231
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 596.65,                last time consumption/overall running time: 422.8438s / 138986.0308 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0246
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 580.2,                last time consumption/overall running time: 412.7135s / 139398.7443 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0230
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0237
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 561.75,                last time consumption/overall running time: 393.5144s / 139792.2587 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0248
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0226
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 577.15,                last time consumption/overall running time: 407.9875s / 140200.2463 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0211
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0241
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 584.7,                last time consumption/overall running time: 418.3924s / 140618.6387 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0223
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0219
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 556.95,                last time consumption/overall running time: 399.1228s / 141017.7615 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0221
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0242
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 559.25,                last time consumption/overall running time: 401.1716s / 141418.9331 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0236
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 608.25,                last time consumption/overall running time: 433.4004s / 141852.3335 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0222
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 554.9,                last time consumption/overall running time: 391.5656s / 142243.8991 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0248
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0227
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 564.7,                last time consumption/overall running time: 397.0879s / 142640.9869 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0222
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0211
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 585.4,                last time consumption/overall running time: 418.1615s / 143059.1485 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0240
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0220
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 551.2,                last time consumption/overall running time: 391.0450s / 143450.1935 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0229
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 549.15,                last time consumption/overall running time: 395.8650s / 143846.0585 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0238
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0242
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 582.5,                last time consumption/overall running time: 418.9187s / 144264.9772 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0247
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0217
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 584.85,                last time consumption/overall running time: 412.4517s / 144677.4289 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0236
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 553.0,                last time consumption/overall running time: 390.9547s / 145068.3836 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0222
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0231
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 546.55,                last time consumption/overall running time: 386.3290s / 145454.7126 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0260
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0226
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 569.4,                last time consumption/overall running time: 395.5015s / 145850.2140 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0240
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0216
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 593.75,                last time consumption/overall running time: 416.8594s / 146267.0735 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0230
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 577.9,                last time consumption/overall running time: 401.1416s / 146668.2150 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0230
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0243
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 560.7,                last time consumption/overall running time: 394.0731s / 147062.2881 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0246
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0216
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 539.5,                last time consumption/overall running time: 371.1428s / 147433.4308 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0240
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0255
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 574.35,                last time consumption/overall running time: 395.7937s / 147829.2246 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0233
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 583.75,                last time consumption/overall running time: 400.7325s / 148229.9571 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 593.65,                last time consumption/overall running time: 407.6047s / 148637.5618 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0219
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0257
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 564.1,                last time consumption/overall running time: 389.6188s / 149027.1806 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0229
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0235
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 599.15,                last time consumption/overall running time: 412.4253s / 149439.6060 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0237
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 547.85,                last time consumption/overall running time: 381.8437s / 149821.4497 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0233
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 585.3,                last time consumption/overall running time: 407.0967s / 150228.5464 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0233
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0238
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 559.1,                last time consumption/overall running time: 391.8720s / 150620.4184 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0209
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 556.4,                last time consumption/overall running time: 384.7848s / 151005.2032 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0220
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0252
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 611.75,                last time consumption/overall running time: 420.8665s / 151426.0697 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0235
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0247
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 639.15,                last time consumption/overall running time: 443.2532s / 151869.3229 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0245
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 570.55,                last time consumption/overall running time: 395.2861s / 152264.6090 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0245
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0231
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 581.45,                last time consumption/overall running time: 398.5077s / 152663.1166 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0242
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0223
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 606.2,                last time consumption/overall running time: 418.9689s / 153082.0855 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0237
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0247
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 581.6,                last time consumption/overall running time: 406.0455s / 153488.1310 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0230
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0235
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 598.0,                last time consumption/overall running time: 408.4521s / 153896.5831 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0223
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0260
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 584.15,                last time consumption/overall running time: 404.1157s / 154300.6988 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0221
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 575.6,                last time consumption/overall running time: 395.9979s / 154696.6968 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0222
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0237
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 591.65,                last time consumption/overall running time: 405.7116s / 155102.4083 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0206
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0237
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 559.1,                last time consumption/overall running time: 383.4692s / 155485.8775 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0229
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0266
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 594.85,                last time consumption/overall running time: 412.8874s / 155898.7649 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0227
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0240
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 560.25,                last time consumption/overall running time: 386.7139s / 156285.4788 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0227
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0253
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 559.35,                last time consumption/overall running time: 388.0184s / 156673.4972 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0225
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0246
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 574.8,                last time consumption/overall running time: 395.5377s / 157069.0349 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0218
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 582.65,                last time consumption/overall running time: 401.3416s / 157470.3765 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0224
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0229
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 569.85,                last time consumption/overall running time: 395.6501s / 157866.0266 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0229
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0227
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 562.1,                last time consumption/overall running time: 386.2043s / 158252.2309 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0243
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0231
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 602.85,                last time consumption/overall running time: 416.1026s / 158668.3335 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0225
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0236
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 583.75,                last time consumption/overall running time: 407.0225s / 159075.3560 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0227
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0232
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 564.6,                last time consumption/overall running time: 389.7206s / 159465.0766 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0231
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 582.65,                last time consumption/overall running time: 402.2725s / 159867.3490 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0232
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0245
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 586.2,                last time consumption/overall running time: 405.8449s / 160273.1940 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0216
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0251
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 557.9,                last time consumption/overall running time: 382.0482s / 160655.2422 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0242
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0245
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 518.1,                last time consumption/overall running time: 358.4178s / 161013.6600 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0231
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0235
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 592.4,                last time consumption/overall running time: 408.0368s / 161421.6968 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0232
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0273
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 547.7,                last time consumption/overall running time: 371.7987s / 161793.4955 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0249
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0244
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 567.35,                last time consumption/overall running time: 384.8103s / 162178.3058 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0245
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0259
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 590.15,                last time consumption/overall running time: 396.4797s / 162574.7855 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0246
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 596.0,                last time consumption/overall running time: 401.4546s / 162976.2401 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0245
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0234
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 584.3,                last time consumption/overall running time: 395.7460s / 163371.9861 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0249
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0245
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 538.45,                last time consumption/overall running time: 368.8491s / 163740.8352 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0224
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0227
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 586.7,                last time consumption/overall running time: 402.0635s / 164142.8987 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0227
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0240
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 583.35,                last time consumption/overall running time: 397.2377s / 164540.1365 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0240
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0238
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 590.75,                last time consumption/overall running time: 400.6537s / 164940.7902 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0239
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0245
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 560.65,                last time consumption/overall running time: 380.6458s / 165321.4360 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0228
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0231
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 557.3,                last time consumption/overall running time: 384.1782s / 165705.6142 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0226
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 536.15,                last time consumption/overall running time: 364.5039s / 166070.1181 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0234
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0225
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 610.0,                last time consumption/overall running time: 414.8946s / 166485.0127 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0217
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0240
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 558.55,                last time consumption/overall running time: 381.3258s / 166866.3385 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0230
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0228
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 542.25,                last time consumption/overall running time: 370.4992s / 167236.8377 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0241
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0240
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 568.85,                last time consumption/overall running time: 387.1073s / 167623.9450 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0218
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0236
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 558.45,                last time consumption/overall running time: 381.4244s / 168005.3694 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0210
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0224
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 576.2,                last time consumption/overall running time: 393.0082s / 168398.3776 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0222
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0221
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 536.6,                last time consumption/overall running time: 364.5558s / 168762.9334 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0220
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0229
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 531.6,                last time consumption/overall running time: 359.4496s / 169122.3830 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0236
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0226
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 581.25,                last time consumption/overall running time: 396.9344s / 169519.3174 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0211
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0225
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 529.0,                last time consumption/overall running time: 359.9135s / 169879.2309 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0230
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0244
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 579.75,                last time consumption/overall running time: 388.6750s / 170267.9059 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0233
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 567.4,                last time consumption/overall running time: 383.1784s / 170651.0843 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0241
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0246
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 609.35,                last time consumption/overall running time: 407.9291s / 171059.0134 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0244
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 606.2,                last time consumption/overall running time: 408.8767s / 171467.8901 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0230
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0232
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 529.3,                last time consumption/overall running time: 360.6017s / 171828.4918 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0237
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0274
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 583.0,                last time consumption/overall running time: 395.7439s / 172224.2357 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0235
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0253
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 546.65,                last time consumption/overall running time: 371.8667s / 172596.1024 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0245
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0263
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 567.4,                last time consumption/overall running time: 381.5676s / 172977.6700 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0241
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0258
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 571.8,                last time consumption/overall running time: 386.5634s / 173364.2334 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0229
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 594.95,                last time consumption/overall running time: 402.1004s / 173766.3338 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0236
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0260
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 567.5,                last time consumption/overall running time: 381.4808s / 174147.8146 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0242
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0248
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 579.0,                last time consumption/overall running time: 390.6476s / 174538.4622 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0227
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0253
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 572.6,                last time consumption/overall running time: 387.0553s / 174925.5175 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0244
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0228
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 558.55,                last time consumption/overall running time: 377.3248s / 175302.8424 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0243
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0237
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 557.05,                last time consumption/overall running time: 374.4432s / 175677.2855 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0234
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0227
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 571.75,                last time consumption/overall running time: 381.0070s / 176058.2925 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0227
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0243
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 610.8,                last time consumption/overall running time: 414.5087s / 176472.8013 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0232
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0230
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 561.6,                last time consumption/overall running time: 379.1766s / 176851.9779 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0234
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0235
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 548.1,                last time consumption/overall running time: 369.3874s / 177221.3652 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0245
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0246
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 608.6,                last time consumption/overall running time: 411.8046s / 177633.1698 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0222
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0260
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 539.15,                last time consumption/overall running time: 364.7066s / 177997.8764 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0233
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 594.15,                last time consumption/overall running time: 392.9618s / 178390.8382 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0243
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0234
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 571.85,                last time consumption/overall running time: 379.4616s / 178770.2998 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0237
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0236
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 559.1,                last time consumption/overall running time: 372.7329s / 179143.0327 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0236
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 600.6,                last time consumption/overall running time: 396.0050s / 179539.0377 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0247
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0245
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 589.1,                last time consumption/overall running time: 393.6806s / 179932.7183 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0228
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 565.8,                last time consumption/overall running time: 378.9107s / 180311.6291 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0234
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0239
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 587.35,                last time consumption/overall running time: 392.0131s / 180703.6422 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0234
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0231
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 594.3,                last time consumption/overall running time: 397.3917s / 181101.0339 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0239
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 572.45,                last time consumption/overall running time: 381.0093s / 181482.0432 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0244
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0272
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 554.85,                last time consumption/overall running time: 368.4394s / 181850.4827 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0230
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0250
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 582.85,                last time consumption/overall running time: 389.2668s / 182239.7494 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0241
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0251
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 570.0,                last time consumption/overall running time: 381.2648s / 182621.0143 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0221
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0229
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 553.8,                last time consumption/overall running time: 371.0748s / 182992.0890 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0231
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0228
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 585.1,                last time consumption/overall running time: 392.2020s / 183384.2910 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0229
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 574.85,                last time consumption/overall running time: 388.6584s / 183772.9494 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0235
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 547.65,                last time consumption/overall running time: 366.3840s / 184139.3334 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0241
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0228
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 577.85,                last time consumption/overall running time: 384.0974s / 184523.4309 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0256
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0214
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 558.3,                last time consumption/overall running time: 376.5782s / 184900.0091 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0231
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 575.3,                last time consumption/overall running time: 389.1681s / 185289.1772 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0224
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0254
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 615.2,                last time consumption/overall running time: 413.4435s / 185702.6207 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0253
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0241
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 561.15,                last time consumption/overall running time: 372.1664s / 186074.7870 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0242
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 576.75,                last time consumption/overall running time: 382.9393s / 186457.7263 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0226
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 553.0,                last time consumption/overall running time: 370.8235s / 186828.5499 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0261
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0230
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 503.4,                last time consumption/overall running time: 336.4343s / 187164.9842 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0257
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 591.95,                last time consumption/overall running time: 394.7506s / 187559.7347 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0252
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0242
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 595.45,                last time consumption/overall running time: 391.9831s / 187951.7178 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0237
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0242
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 581.95,                last time consumption/overall running time: 388.2810s / 188339.9988 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0237
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 516.5,                last time consumption/overall running time: 347.4460s / 188687.4447 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0224
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0255
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 620.4,                last time consumption/overall running time: 411.2558s / 189098.7005 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0239
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0242
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 572.45,                last time consumption/overall running time: 383.8029s / 189482.5034 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0234
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0242
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 576.7,                last time consumption/overall running time: 380.4762s / 189862.9796 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0233
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0217
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 585.25,                last time consumption/overall running time: 387.1626s / 190250.1422 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0237
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0223
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 593.7,                last time consumption/overall running time: 391.7478s / 190641.8901 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0239
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0233
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 603.8,                last time consumption/overall running time: 401.5904s / 191043.4804 sLoad SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rl/agents/nash_dqn.py:293: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  action = torch.FloatTensor(action).to(self.device)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: 0.5500,                 loss: 0.0244
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0226
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 541.05,                last time consumption/overall running time: 353.5975s / 191397.0779 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0236
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0229
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 577.0,                last time consumption/overall running time: 379.3793s / 191776.4571 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0241
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0229
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 605.35,                last time consumption/overall running time: 395.5764s / 192172.0335 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0224
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 538.8,                last time consumption/overall running time: 351.9283s / 192523.9618 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0246
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0226
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 583.95,                last time consumption/overall running time: 376.4030s / 192900.3648 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0236
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 575.3,                last time consumption/overall running time: 375.3773s / 193275.7421 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0234
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 595.0,                last time consumption/overall running time: 387.0761s / 193662.8182 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0223
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0240
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 596.55,                last time consumption/overall running time: 385.9100s / 194048.7282 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0251
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 572.1,                last time consumption/overall running time: 371.7284s / 194420.4566 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0239
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0213
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 566.35,                last time consumption/overall running time: 368.5406s / 194788.9972 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0228
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0237
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
