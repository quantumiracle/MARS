pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [89, 96]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 50, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220115_0159/pettingzoo_tennis_v2_nxdo2.
{'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 50, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 55
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Episode: 1/10000 (0.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 98.0331s / 98.0331 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0064
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 2809.25,                last time consumption/overall running time: 569.2667s / 667.2998 s
env0_first_0:                 episode reward: 14.8000,                 loss: 0.0049
env0_second_0:                 episode reward: -14.8000,                 loss: nan
env1_first_0:                 episode reward: 13.7000,                 loss: nan
env1_second_0:                 episode reward: -13.7000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1486.6,                last time consumption/overall running time: 306.9226s / 974.2224 s
env0_first_0:                 episode reward: 21.2000,                 loss: 0.0052
env0_second_0:                 episode reward: -21.2000,                 loss: nan
env1_first_0:                 episode reward: 21.2000,                 loss: nan
env1_second_0:                 episode reward: -21.2000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1379.55,                last time consumption/overall running time: 287.3322s / 1261.5546 s
env0_first_0:                 episode reward: 23.2500,                 loss: 0.0025
env0_second_0:                 episode reward: -23.2500,                 loss: nan
env1_first_0:                 episode reward: 24.3000,                 loss: nan
env1_second_0:                 episode reward: -24.3000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1356.45,                last time consumption/overall running time: 281.6757s / 1543.2303 s
env0_first_0:                 episode reward: 23.5000,                 loss: 0.0016
env0_second_0:                 episode reward: -23.5000,                 loss: nan
env1_first_0:                 episode reward: 24.0000,                 loss: nan
env1_second_0:                 episode reward: -24.0000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1866.35,                last time consumption/overall running time: 387.7481s / 1930.9785 s
env0_first_0:                 episode reward: 12.7000,                 loss: 0.0018
env0_second_0:                 episode reward: -12.7000,                 loss: nan
env1_first_0:                 episode reward: 12.3000,                 loss: nan
env1_second_0:                 episode reward: -12.3000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1378.65,                last time consumption/overall running time: 285.5367s / 2216.5151 s
env0_first_0:                 episode reward: 24.5000,                 loss: 0.0033
env0_second_0:                 episode reward: -24.5000,                 loss: nan
env1_first_0:                 episode reward: 25.0000,                 loss: nan
env1_second_0:                 episode reward: -25.0000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 2236.7,                last time consumption/overall running time: 451.8830s / 2668.3982 s
env0_first_0:                 episode reward: -2.6000,                 loss: nan
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Score delta: 50.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/123_0.
Episode: 161/10000 (1.6100%),                 avg. length: 1777.1,                last time consumption/overall running time: 367.6919s / 3036.0901 s
env0_first_0:                 episode reward: -15.7500,                 loss: nan
env0_second_0:                 episode reward: 15.7500,                 loss: 0.0059
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1550.95,                last time consumption/overall running time: 319.6628s / 3355.7529 s
env0_first_0:                 episode reward: -21.5500,                 loss: nan
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0047
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1424.3,                last time consumption/overall running time: 297.0574s / 3652.8103 s
env0_first_0:                 episode reward: -22.6500,                 loss: nan
env0_second_0:                 episode reward: 22.6500,                 loss: 0.0031
env1_first_0:                 episode reward: -22.1500,                 loss: nan
env1_second_0:                 episode reward: 22.1500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1439.9,                last time consumption/overall running time: 388.8069s / 4041.6172 s
env0_first_0:                 episode reward: -24.0500,                 loss: nan
env0_second_0:                 episode reward: 24.0500,                 loss: nan
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Score delta: 50.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/216_1.
Episode: 241/10000 (2.4100%),                 avg. length: 2262.95,                last time consumption/overall running time: 475.1253s / 4516.7425 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0042
env0_second_0:                 episode reward: -2.9000,                 loss: nan
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 2098.35,                last time consumption/overall running time: 459.3082s / 4976.0507 s
env0_first_0:                 episode reward: 19.7500,                 loss: nan
env0_second_0:                 episode reward: -19.7500,                 loss: nan
env1_first_0:                 episode reward: 17.2000,                 loss: nan
env1_second_0:                 episode reward: -17.2000,                 loss: nan
Score delta: 50.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/255_0.
Episode: 281/10000 (2.8100%),                 avg. length: 3592.0,                last time consumption/overall running time: 741.9380s / 5717.9888 s
env0_first_0:                 episode reward: -4.5000,                 loss: nan
env0_second_0:                 episode reward: 4.5000,                 loss: 0.0047
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 2144.3,                last time consumption/overall running time: 441.6757s / 6159.6644 s
env0_first_0:                 episode reward: -19.4000,                 loss: nan
env0_second_0:                 episode reward: 19.4000,                 loss: 0.0042
env1_first_0:                 episode reward: -18.5000,                 loss: nan
env1_second_0:                 episode reward: 18.5000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1832.75,                last time consumption/overall running time: 375.8996s / 6535.5640 s
env0_first_0:                 episode reward: -20.4500,                 loss: nan
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0040
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1770.1,                last time consumption/overall running time: 363.2934s / 6898.8574 s
env0_first_0:                 episode reward: -20.8500,                 loss: nan
env0_second_0:                 episode reward: 20.8500,                 loss: 0.0034
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1620.95,                last time consumption/overall running time: 333.2279s / 7232.0853 s
env0_first_0:                 episode reward: -22.5500,                 loss: nan
env0_second_0:                 episode reward: 22.5500,                 loss: 0.0037
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1662.2,                last time consumption/overall running time: 344.6535s / 7576.7388 s
env0_first_0:                 episode reward: -22.9000,                 loss: nan
env0_second_0:                 episode reward: 22.9000,                 loss: 0.0033
env1_first_0:                 episode reward: -23.1500,                 loss: nan
env1_second_0:                 episode reward: 23.1500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1721.55,                last time consumption/overall running time: 358.1729s / 7934.9117 s
env0_first_0:                 episode reward: -21.2000,                 loss: nan
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0025
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1821.5,                last time consumption/overall running time: 374.8192s / 8309.7309 s
env0_first_0:                 episode reward: -18.3000,                 loss: nan
env0_second_0:                 episode reward: 18.3000,                 loss: 0.0031
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1596.9,                last time consumption/overall running time: 334.8205s / 8644.5514 s
env0_first_0:                 episode reward: -23.2500,                 loss: nan
env0_second_0:                 episode reward: 23.2500,                 loss: 0.0034
env1_first_0:                 episode reward: -22.7500,                 loss: nan
env1_second_0:                 episode reward: 22.7500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1603.75,                last time consumption/overall running time: 328.1800s / 8972.7314 s
env0_first_0:                 episode reward: -22.4500,                 loss: nan
env0_second_0:                 episode reward: 22.4500,                 loss: 0.0026
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1627.75,                last time consumption/overall running time: 335.7490s / 9308.4803 s
env0_first_0:                 episode reward: -23.0000,                 loss: nan
env0_second_0:                 episode reward: 23.0000,                 loss: 0.0023
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1566.6,                last time consumption/overall running time: 325.8986s / 9634.3789 s
env0_first_0:                 episode reward: -23.0000,                 loss: nan
env0_second_0:                 episode reward: 23.0000,                 loss: 0.0022
env1_first_0:                 episode reward: -23.1000,                 loss: nan
env1_second_0:                 episode reward: 23.1000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1706.1,                last time consumption/overall running time: 356.6032s / 9990.9821 s
env0_first_0:                 episode reward: -23.6500,                 loss: nan
env0_second_0:                 episode reward: 23.6500,                 loss: 0.0021
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1601.3,                last time consumption/overall running time: 326.8680s / 10317.8501 s
env0_first_0:                 episode reward: -22.5500,                 loss: nan
env0_second_0:                 episode reward: 22.5500,                 loss: 0.0023
env1_first_0:                 episode reward: -23.5000,                 loss: nan
env1_second_0:                 episode reward: 23.5000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1605.15,                last time consumption/overall running time: 331.2138s / 10649.0639 s
env0_first_0:                 episode reward: -23.0500,                 loss: nan
env0_second_0:                 episode reward: 23.0500,                 loss: 0.0020
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1588.9,                last time consumption/overall running time: 329.5067s / 10978.5706 s
env0_first_0:                 episode reward: -23.5500,                 loss: nan
env0_second_0:                 episode reward: 23.5500,                 loss: 0.0021
env1_first_0:                 episode reward: -22.7000,                 loss: nan
env1_second_0:                 episode reward: 22.7000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1583.95,                last time consumption/overall running time: 327.6850s / 11306.2556 s
env0_first_0:                 episode reward: -22.5500,                 loss: nan
env0_second_0:                 episode reward: 22.5500,                 loss: 0.0021
env1_first_0:                 episode reward: -23.6000,                 loss: nan
env1_second_0:                 episode reward: 23.6000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1540.8,                last time consumption/overall running time: 319.0104s / 11625.2659 s
env0_first_0:                 episode reward: -23.8000,                 loss: nan
env0_second_0:                 episode reward: 23.8000,                 loss: 0.0019
env1_first_0:                 episode reward: -22.8500,                 loss: nan
env1_second_0:                 episode reward: 22.8500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 3797.55,                last time consumption/overall running time: 926.7877s / 12552.0536 s
env0_first_0:                 episode reward: -27.6500,                 loss: nan
env0_second_0:                 episode reward: 27.6500,                 loss: nan
env1_first_0:                 episode reward: -30.4500,                 loss: nan
env1_second_0:                 episode reward: 30.4500,                 loss: nan
Score delta: 51.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/627_1.
Episode: 661/10000 (6.6100%),                 avg. length: 2316.75,                last time consumption/overall running time: 476.3171s / 13028.3707 s
env0_first_0:                 episode reward: 19.3500,                 loss: 0.0080
env0_second_0:                 episode reward: -19.3500,                 loss: nan
env1_first_0:                 episode reward: 22.3500,                 loss: nan
env1_second_0:                 episode reward: -22.3500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 3116.45,                last time consumption/overall running time: 639.0567s / 13667.4274 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0071
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 3343.8,                last time consumption/overall running time: 725.7915s / 14393.2189 s
env0_first_0:                 episode reward: -7.1000,                 loss: nan
env0_second_0:                 episode reward: 7.1000,                 loss: nan
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Score delta: 52.6, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/687_0.
Episode: 721/10000 (7.2100%),                 avg. length: 3581.05,                last time consumption/overall running time: 1001.8644s / 15395.0833 s
env0_first_0:                 episode reward: -38.7500,                 loss: nan
env0_second_0:                 episode reward: 38.7500,                 loss: nan
env1_first_0:                 episode reward: -46.4500,                 loss: nan
env1_second_0:                 episode reward: 46.4500,                 loss: nan
Score delta: 168.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/708_1.
Episode: 741/10000 (7.4100%),                 avg. length: 3243.9,                last time consumption/overall running time: 668.4522s / 16063.5355 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0070
env0_second_0:                 episode reward: -2.4500,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 2640.9,                last time consumption/overall running time: 543.2649s / 16606.8005 s
env0_first_0:                 episode reward: 15.5000,                 loss: 0.0064
env0_second_0:                 episode reward: -15.5000,                 loss: nan
env1_first_0:                 episode reward: 16.0000,                 loss: nan
env1_second_0:                 episode reward: -16.0000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 2247.85,                last time consumption/overall running time: 606.7971s / 17213.5976 s
env0_first_0:                 episode reward: 17.9500,                 loss: nan
env0_second_0:                 episode reward: -17.9500,                 loss: nan
env1_first_0:                 episode reward: 20.4000,                 loss: nan
env1_second_0:                 episode reward: -20.4000,                 loss: nan
Score delta: 51.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/777_0.
Episode: 801/10000 (8.0100%),                 avg. length: 5350.7,                last time consumption/overall running time: 1449.2720s / 18662.8696 s
env0_first_0:                 episode reward: -60.1000,                 loss: nan
env0_second_0:                 episode reward: 60.1000,                 loss: nan
env1_first_0:                 episode reward: -70.5500,                 loss: nan
env1_second_0:                 episode reward: 70.5500,                 loss: nan
Score delta: 215.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/798_1.
Episode: 821/10000 (8.2100%),                 avg. length: 2963.7,                last time consumption/overall running time: 620.2845s / 19283.1541 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0072
env0_second_0:                 episode reward: 6.7500,                 loss: nan
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 3167.25,                last time consumption/overall running time: 651.4275s / 19934.5815 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0066
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 2263.9,                last time consumption/overall running time: 467.7873s / 20402.3688 s
env0_first_0:                 episode reward: 15.3500,                 loss: 0.0071
env0_second_0:                 episode reward: -15.3500,                 loss: nan
env1_first_0:                 episode reward: 16.5500,                 loss: nan
env1_second_0:                 episode reward: -16.5500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 2167.55,                last time consumption/overall running time: 447.0150s / 20849.3838 s
env0_first_0:                 episode reward: 21.6000,                 loss: 0.0054
env0_second_0:                 episode reward: -21.6000,                 loss: nan
env1_first_0:                 episode reward: 24.8500,                 loss: nan
env1_second_0:                 episode reward: -24.8500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 5403.2,                last time consumption/overall running time: 1334.8067s / 22184.1906 s
env0_first_0:                 episode reward: -19.2000,                 loss: nan
env0_second_0:                 episode reward: 19.2000,                 loss: nan
env1_first_0:                 episode reward: -35.7000,                 loss: nan
env1_second_0:                 episode reward: 35.7000,                 loss: nan
Score delta: 51.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/886_0.
Episode: 921/10000 (9.2100%),                 avg. length: 2884.7,                last time consumption/overall running time: 898.3180s / 23082.5086 s
env0_first_0:                 episode reward: -43.6000,                 loss: nan
env0_second_0:                 episode reward: 43.6000,                 loss: nan
env1_first_0:                 episode reward: -42.2500,                 loss: nan
env1_second_0:                 episode reward: 42.2500,                 loss: nan
Score delta: 120.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/907_1.
Episode: 941/10000 (9.4100%),                 avg. length: 6450.55,                last time consumption/overall running time: 1344.3487s / 24426.8574 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.0068
env0_second_0:                 episode reward: 16.2000,                 loss: nan
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 7251.5,                last time consumption/overall running time: 1785.8059s / 26212.6633 s
env0_first_0:                 episode reward: 16.2000,                 loss: nan
env0_second_0:                 episode reward: -16.2000,                 loss: nan
env1_first_0:                 episode reward: 11.6500,                 loss: nan
env1_second_0:                 episode reward: -11.6500,                 loss: nan
Score delta: 65.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/945_0.
Episode: 981/10000 (9.8100%),                 avg. length: 3402.75,                last time consumption/overall running time: 692.5976s / 26905.2609 s
env0_first_0:                 episode reward: -15.1500,                 loss: nan
env0_second_0:                 episode reward: 15.1500,                 loss: 0.0036
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 2532.95,                last time consumption/overall running time: 526.6751s / 27431.9360 s
env0_first_0:                 episode reward: -15.5500,                 loss: nan
env0_second_0:                 episode reward: 15.5500,                 loss: 0.0028
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 2156.65,                last time consumption/overall running time: 447.4213s / 27879.3573 s
env0_first_0:                 episode reward: -19.8000,                 loss: nan
env0_second_0:                 episode reward: 19.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 2313.75,                last time consumption/overall running time: 474.5502s / 28353.9076 s
env0_first_0:                 episode reward: -23.4000,                 loss: nan
env0_second_0:                 episode reward: 23.4000,                 loss: 0.0029
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 5774.2,                last time consumption/overall running time: 1721.2144s / 30075.1220 s
env0_first_0:                 episode reward: -3.4500,                 loss: nan
env0_second_0:                 episode reward: 3.4500,                 loss: nan
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Score delta: 54.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1054_1.
Episode: 1081/10000 (10.8100%),                 avg. length: 8141.45,                last time consumption/overall running time: 2076.0588s / 32151.1808 s
env0_first_0:                 episode reward: 54.2500,                 loss: nan
env0_second_0:                 episode reward: -54.2500,                 loss: nan
env1_first_0:                 episode reward: 39.5000,                 loss: nan
env1_second_0:                 episode reward: -39.5000,                 loss: nan
Score delta: 95.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1075_0.
Episode: 1101/10000 (11.0100%),                 avg. length: 5298.35,                last time consumption/overall running time: 1688.0047s / 33839.1855 s
env0_first_0:                 episode reward: -16.2500,                 loss: nan
env0_second_0:                 episode reward: 16.2500,                 loss: nan
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Score delta: 53.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1099_1.
Episode: 1121/10000 (11.2100%),                 avg. length: 2876.05,                last time consumption/overall running time: 592.2946s / 34431.4801 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0064
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 13.2000,                 loss: nan
env1_second_0:                 episode reward: -13.2000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 2066.6,                last time consumption/overall running time: 911.6778s / 35343.1579 s
env0_first_0:                 episode reward: 21.3500,                 loss: nan
env0_second_0:                 episode reward: -21.3500,                 loss: nan
env1_first_0:                 episode reward: 25.3000,                 loss: nan
env1_second_0:                 episode reward: -25.3000,                 loss: nan
Score delta: 50.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1140_0.
Episode: 1161/10000 (11.6100%),                 avg. length: 7767.2,                last time consumption/overall running time: 2161.1068s / 37504.2647 s
env0_first_0:                 episode reward: -56.3000,                 loss: nan
env0_second_0:                 episode reward: 56.3000,                 loss: 0.0075
env1_first_0:                 episode reward: -41.3000,                 loss: nan
env1_second_0:                 episode reward: 41.3000,                 loss: nan
Score delta: 162.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1161_1.
Episode: 1181/10000 (11.8100%),                 avg. length: 2557.4,                last time consumption/overall running time: 529.8198s / 38034.0846 s
env0_first_0:                 episode reward: 16.6500,                 loss: 0.0051
env0_second_0:                 episode reward: -16.6500,                 loss: nan
env1_first_0:                 episode reward: 15.4500,                 loss: nan
env1_second_0:                 episode reward: -15.4500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 2498.3,                last time consumption/overall running time: 518.7656s / 38552.8502 s
env0_first_0:                 episode reward: 18.9500,                 loss: 0.0049
env0_second_0:                 episode reward: -18.9500,                 loss: nan
env1_first_0:                 episode reward: 21.7500,                 loss: nan
env1_second_0:                 episode reward: -21.7500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 5183.35,                last time consumption/overall running time: 1617.0723s / 40169.9225 s
env0_first_0:                 episode reward: -17.7000,                 loss: nan
env0_second_0:                 episode reward: 17.7000,                 loss: nan
env1_first_0:                 episode reward: 6.7000,                 loss: nan
env1_second_0:                 episode reward: -6.7000,                 loss: nan
Score delta: 54.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1208_0.
Episode: 1241/10000 (12.4100%),                 avg. length: 5209.55,                last time consumption/overall running time: 1806.0829s / 41976.0053 s
env0_first_0:                 episode reward: -32.1500,                 loss: nan
env0_second_0:                 episode reward: 32.1500,                 loss: nan
env1_first_0:                 episode reward: -40.4500,                 loss: nan
env1_second_0:                 episode reward: 40.4500,                 loss: nan
Score delta: 160.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1229_1.
Episode: 1261/10000 (12.6100%),                 avg. length: 2793.05,                last time consumption/overall running time: 568.9952s / 42545.0005 s
env0_first_0:                 episode reward: 10.7500,                 loss: 0.0061
env0_second_0:                 episode reward: -10.7500,                 loss: nan
env1_first_0:                 episode reward: 9.6000,                 loss: nan
env1_second_0:                 episode reward: -9.6000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 2701.7,                last time consumption/overall running time: 552.3975s / 43097.3980 s
env0_first_0:                 episode reward: 14.4500,                 loss: 0.0060
env0_second_0:                 episode reward: -14.4500,                 loss: nan
env1_first_0:                 episode reward: 12.0500,                 loss: nan
env1_second_0:                 episode reward: -12.0500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 2492.65,                last time consumption/overall running time: 501.6914s / 43599.0893 s
env0_first_0:                 episode reward: 18.8000,                 loss: 0.0053
env0_second_0:                 episode reward: -18.8000,                 loss: nan
env1_first_0:                 episode reward: 16.1500,                 loss: nan
env1_second_0:                 episode reward: -16.1500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 5664.05,                last time consumption/overall running time: 1734.4911s / 45333.5804 s
env0_first_0:                 episode reward: 10.6500,                 loss: nan
env0_second_0:                 episode reward: -10.6500,                 loss: nan
env1_first_0:                 episode reward: 11.6500,                 loss: nan
env1_second_0:                 episode reward: -11.6500,                 loss: nan
Score delta: 53.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1306_0.
Episode: 1341/10000 (13.4100%),                 avg. length: 7035.7,                last time consumption/overall running time: 2310.2577s / 47643.8382 s
env0_first_0:                 episode reward: -15.0000,                 loss: nan
env0_second_0:                 episode reward: 15.0000,                 loss: nan
env1_first_0:                 episode reward: -28.6000,                 loss: nan
env1_second_0:                 episode reward: 28.6000,                 loss: nan
Score delta: 86.6, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1334_1.
Episode: 1361/10000 (13.6100%),                 avg. length: 2469.95,                last time consumption/overall running time: 512.3751s / 48156.2133 s
env0_first_0:                 episode reward: 7.5500,                 loss: 0.0064
env0_second_0:                 episode reward: -7.5500,                 loss: nan
env1_first_0:                 episode reward: 10.3500,                 loss: nan
env1_second_0:                 episode reward: -10.3500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 2752.75,                last time consumption/overall running time: 1129.4233s / 49285.6366 s
env0_first_0:                 episode reward: 27.9500,                 loss: nan
env0_second_0:                 episode reward: -27.9500,                 loss: nan
env1_first_0:                 episode reward: 26.6000,                 loss: nan
env1_second_0:                 episode reward: -26.6000,                 loss: nan
Score delta: 50.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1370_0.
Episode: 1401/10000 (14.0100%),                 avg. length: 7363.0,                last time consumption/overall running time: 1512.6254s / 50798.2620 s
env0_first_0:                 episode reward: 8.1000,                 loss: nan
env0_second_0:                 episode reward: -8.1000,                 loss: 0.0047
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 6315.45,                last time consumption/overall running time: 1305.4364s / 52103.6984 s
env0_first_0:                 episode reward: -2.2000,                 loss: nan
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0058
env1_first_0:                 episode reward: -17.4000,                 loss: nan
env1_second_0:                 episode reward: 17.4000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 3791.55,                last time consumption/overall running time: 1745.8392s / 53849.5376 s
env0_first_0:                 episode reward: -10.0500,                 loss: nan
env0_second_0:                 episode reward: 10.0500,                 loss: nan
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Score delta: 53.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1424_1.
Episode: 1461/10000 (14.6100%),                 avg. length: 2322.55,                last time consumption/overall running time: 480.4863s / 54330.0239 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0064
env0_second_0:                 episode reward: -21.0000,                 loss: nan
env1_first_0:                 episode reward: 21.8500,                 loss: nan
env1_second_0:                 episode reward: -21.8500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 3889.5,                last time consumption/overall running time: 1517.8730s / 55847.8968 s
env0_first_0:                 episode reward: 25.8000,                 loss: nan
env0_second_0:                 episode reward: -25.8000,                 loss: nan
env1_first_0:                 episode reward: 17.8000,                 loss: nan
env1_second_0:                 episode reward: -17.8000,                 loss: nan
Score delta: 51.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1475_0.
Episode: 1501/10000 (15.0100%),                 avg. length: 5709.7,                last time consumption/overall running time: 1188.1993s / 57036.0961 s
env0_first_0:                 episode reward: -16.2500,                 loss: nan
env0_second_0:                 episode reward: 16.2500,                 loss: 0.0044
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 6529.7,                last time consumption/overall running time: 2092.3953s / 59128.4914 s
env0_first_0:                 episode reward: -9.6500,                 loss: nan
env0_second_0:                 episode reward: 9.6500,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Score delta: 51.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1512_1.
Episode: 1541/10000 (15.4100%),                 avg. length: 3890.4,                last time consumption/overall running time: 792.9687s / 59921.4600 s
env0_first_0:                 episode reward: 8.0000,                 loss: 0.0044
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 13.6500,                 loss: nan
env1_second_0:                 episode reward: -13.6500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 2736.7,                last time consumption/overall running time: 570.4370s / 60491.8970 s
env0_first_0:                 episode reward: 13.9000,                 loss: 0.0035
env0_second_0:                 episode reward: -13.9000,                 loss: nan
env1_first_0:                 episode reward: 18.1500,                 loss: nan
env1_second_0:                 episode reward: -18.1500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 2559.25,                last time consumption/overall running time: 529.3752s / 61021.2722 s
env0_first_0:                 episode reward: 16.5000,                 loss: 0.0034
env0_second_0:                 episode reward: -16.5000,                 loss: nan
env1_first_0:                 episode reward: 14.1500,                 loss: nan
env1_second_0:                 episode reward: -14.1500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 4035.9,                last time consumption/overall running time: 1496.9846s / 62518.2568 s
env0_first_0:                 episode reward: -46.9000,                 loss: nan
env0_second_0:                 episode reward: 46.9000,                 loss: nan
env1_first_0:                 episode reward: -50.7000,                 loss: nan
env1_second_0:                 episode reward: 50.7000,                 loss: nan
Score delta: 52.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1584_0.
Episode: 1621/10000 (16.2100%),                 avg. length: 4052.6,                last time consumption/overall running time: 1981.5755s / 64499.8323 s
env0_first_0:                 episode reward: -20.3500,                 loss: nan
env0_second_0:                 episode reward: 20.3500,                 loss: nan
env1_first_0:                 episode reward: -27.8000,                 loss: nan
env1_second_0:                 episode reward: 27.8000,                 loss: nan
Score delta: 181.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1605_1.
Episode: 1641/10000 (16.4100%),                 avg. length: 6022.0,                last time consumption/overall running time: 1233.1844s / 65733.0167 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0059
env0_second_0:                 episode reward: 8.1000,                 loss: nan
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 7358.5,                last time consumption/overall running time: 1514.4338s / 67247.4505 s
env0_first_0:                 episode reward: 9.5500,                 loss: 0.0063
env0_second_0:                 episode reward: -9.5500,                 loss: nan
env1_first_0:                 episode reward: 10.9000,                 loss: nan
env1_second_0:                 episode reward: -10.9000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 5319.0,                last time consumption/overall running time: 1741.8782s / 68989.3288 s
env0_first_0:                 episode reward: 6.2500,                 loss: nan
env0_second_0:                 episode reward: -6.2500,                 loss: nan
env1_first_0:                 episode reward: 24.3500,                 loss: nan
env1_second_0:                 episode reward: -24.3500,                 loss: nan
Score delta: 53.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1665_0.
Episode: 1701/10000 (17.0100%),                 avg. length: 3698.55,                last time consumption/overall running time: 1859.4055s / 70848.7343 s
env0_first_0:                 episode reward: -22.3500,                 loss: nan
env0_second_0:                 episode reward: 22.3500,                 loss: nan
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Score delta: 63.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/1699_1.
Episode: 1721/10000 (17.2100%),                 avg. length: 4157.6,                last time consumption/overall running time: 847.7893s / 71696.5236 s
env0_first_0:                 episode reward: 13.7000,                 loss: 0.0043
env0_second_0:                 episode reward: -13.7000,                 loss: nan
env1_first_0:                 episode reward: 12.1000,                 loss: nan
env1_second_0:                 episode reward: -12.1000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 2632.05,                last time consumption/overall running time: 536.4922s / 72233.0158 s
env0_first_0:                 episode reward: 17.3500,                 loss: 0.0036
env0_second_0:                 episode reward: -17.3500,                 loss: nan
env1_first_0:                 episode reward: 19.6500,                 loss: nan
env1_second_0:                 episode reward: -19.6500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 2289.85,                last time consumption/overall running time: 466.7483s / 72699.7641 s
env0_first_0:                 episode reward: 18.1000,                 loss: 0.0032
env0_second_0:                 episode reward: -18.1000,                 loss: nan
env1_first_0:                 episode reward: 18.3000,                 loss: nan
env1_second_0:                 episode reward: -18.3000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 2324.75,                last time consumption/overall running time: 474.8272s / 73174.5913 s
env0_first_0:                 episode reward: 19.0000,                 loss: 0.0036
env0_second_0:                 episode reward: -19.0000,                 loss: nan
env1_first_0:                 episode reward: 16.7500,                 loss: nan
env1_second_0:                 episode reward: -16.7500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1988.8,                last time consumption/overall running time: 408.7107s / 73583.3019 s
env0_first_0:                 episode reward: 16.0500,                 loss: 0.0033
env0_second_0:                 episode reward: -16.0500,                 loss: nan
env1_first_0:                 episode reward: 21.4500,                 loss: nan
env1_second_0:                 episode reward: -21.4500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 2067.75,                last time consumption/overall running time: 428.3771s / 74011.6790 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0032
env0_second_0:                 episode reward: -20.6500,                 loss: nan
env1_first_0:                 episode reward: 18.1000,                 loss: nan
env1_second_0:                 episode reward: -18.1000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1856.6,                last time consumption/overall running time: 380.0723s / 74391.7513 s
env0_first_0:                 episode reward: 21.4000,                 loss: 0.0026
env0_second_0:                 episode reward: -21.4000,                 loss: nan
env1_first_0:                 episode reward: 18.7500,                 loss: nan
env1_second_0:                 episode reward: -18.7500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1716.75,                last time consumption/overall running time: 354.7195s / 74746.4708 s
env0_first_0:                 episode reward: 19.2500,                 loss: 0.0023
env0_second_0:                 episode reward: -19.2500,                 loss: nan
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1864.95,                last time consumption/overall running time: 381.9436s / 75128.4144 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0021
env0_second_0:                 episode reward: -20.6500,                 loss: nan
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1799.55,                last time consumption/overall running time: 373.8109s / 75502.2253 s
env0_first_0:                 episode reward: 19.8500,                 loss: 0.0025
env0_second_0:                 episode reward: -19.8500,                 loss: nan
env1_first_0:                 episode reward: 17.8000,                 loss: nan
env1_second_0:                 episode reward: -17.8000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1987.1,                last time consumption/overall running time: 405.3702s / 75907.5955 s
env0_first_0:                 episode reward: 15.5500,                 loss: 0.0027
env0_second_0:                 episode reward: -15.5500,                 loss: nan
env1_first_0:                 episode reward: 17.3500,                 loss: nan
env1_second_0:                 episode reward: -17.3500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 2117.4,                last time consumption/overall running time: 438.6158s / 76346.2112 s
env0_first_0:                 episode reward: 17.1000,                 loss: 0.0028
env0_second_0:                 episode reward: -17.1000,                 loss: nan
env1_first_0:                 episode reward: 17.2000,                 loss: nan
env1_second_0:                 episode reward: -17.2000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 1701.05,                last time consumption/overall running time: 354.7528s / 76700.9640 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.0031
env0_second_0:                 episode reward: -20.5000,                 loss: nan
env1_first_0:                 episode reward: 19.9500,                 loss: nan
env1_second_0:                 episode reward: -19.9500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1962.3,                last time consumption/overall running time: 401.5642s / 77102.5282 s
env0_first_0:                 episode reward: 22.0500,                 loss: 0.0027
env0_second_0:                 episode reward: -22.0500,                 loss: nan
env1_first_0:                 episode reward: 17.5500,                 loss: nan
env1_second_0:                 episode reward: -17.5500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1848.45,                last time consumption/overall running time: 380.7093s / 77483.2375 s
env0_first_0:                 episode reward: 20.2500,                 loss: 0.0030
env0_second_0:                 episode reward: -20.2500,                 loss: nan
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 2030.15,                last time consumption/overall running time: 414.0085s / 77897.2461 s
env0_first_0:                 episode reward: 19.9000,                 loss: 0.0031
env0_second_0:                 episode reward: -19.9000,                 loss: nan
env1_first_0:                 episode reward: 20.3000,                 loss: nan
env1_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1838.25,                last time consumption/overall running time: 381.2024s / 78278.4484 s
env0_first_0:                 episode reward: 21.6500,                 loss: 0.0031
env0_second_0:                 episode reward: -21.6500,                 loss: nan
env1_first_0:                 episode reward: 20.5000,                 loss: nan
env1_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1883.4,                last time consumption/overall running time: 385.3214s / 78663.7698 s
env0_first_0:                 episode reward: 19.4500,                 loss: 0.0027
env0_second_0:                 episode reward: -19.4500,                 loss: nan
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1661.85,                last time consumption/overall running time: 339.9851s / 79003.7549 s
env0_first_0:                 episode reward: 21.8500,                 loss: 0.0025
env0_second_0:                 episode reward: -21.8500,                 loss: nan
env1_first_0:                 episode reward: 21.6000,                 loss: nan
env1_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1710.6,                last time consumption/overall running time: 354.6142s / 79358.3691 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0020
env0_second_0:                 episode reward: -21.0000,                 loss: nan
env1_first_0:                 episode reward: 19.6500,                 loss: nan
env1_second_0:                 episode reward: -19.6500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1650.3,                last time consumption/overall running time: 341.1754s / 79699.5445 s
env0_first_0:                 episode reward: 21.6000,                 loss: 0.0020
env0_second_0:                 episode reward: -21.6000,                 loss: nan
env1_first_0:                 episode reward: 20.1000,                 loss: nan
env1_second_0:                 episode reward: -20.1000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2045.4,                last time consumption/overall running time: 417.2454s / 80116.7899 s
env0_first_0:                 episode reward: 20.1500,                 loss: 0.0022
env0_second_0:                 episode reward: -20.1500,                 loss: nan
env1_first_0:                 episode reward: 21.5500,                 loss: nan
env1_second_0:                 episode reward: -21.5500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1991.6,                last time consumption/overall running time: 411.4008s / 80528.1907 s
env0_first_0:                 episode reward: 17.1500,                 loss: 0.0028
env0_second_0:                 episode reward: -17.1500,                 loss: nan
env1_first_0:                 episode reward: 19.1500,                 loss: nan
env1_second_0:                 episode reward: -19.1500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1865.05,                last time consumption/overall running time: 390.8902s / 80919.0809 s
env0_first_0:                 episode reward: 22.0500,                 loss: 0.0029
env0_second_0:                 episode reward: -22.0500,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1833.95,                last time consumption/overall running time: 377.8785s / 81296.9593 s
env0_first_0:                 episode reward: 19.9000,                 loss: 0.0023
env0_second_0:                 episode reward: -19.9000,                 loss: nan
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 2031.35,                last time consumption/overall running time: 995.4675s / 82292.4268 s
env0_first_0:                 episode reward: 23.2000,                 loss: 0.0027
env0_second_0:                 episode reward: -23.2000,                 loss: nan
env1_first_0:                 episode reward: 24.8000,                 loss: nan
env1_second_0:                 episode reward: -24.8000,                 loss: nan
Score delta: 51.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/2221_0.
Episode: 2241/10000 (22.4100%),                 avg. length: 4415.65,                last time consumption/overall running time: 909.3303s / 83201.7572 s
env0_first_0:                 episode reward: -15.9500,                 loss: nan
env0_second_0:                 episode reward: 15.9500,                 loss: 0.0061
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 4241.7,                last time consumption/overall running time: 1997.1238s / 85198.8810 s
env0_first_0:                 episode reward: -6.7500,                 loss: nan
env0_second_0:                 episode reward: 6.7500,                 loss: nan
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Score delta: 71.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/2244_1.
Episode: 2281/10000 (22.8100%),                 avg. length: 2601.85,                last time consumption/overall running time: 527.8242s / 85726.7052 s
env0_first_0:                 episode reward: 13.9000,                 loss: 0.0042
env0_second_0:                 episode reward: -13.9000,                 loss: nan
env1_first_0:                 episode reward: 14.4500,                 loss: nan
env1_second_0:                 episode reward: -14.4500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 2219.9,                last time consumption/overall running time: 452.3335s / 86179.0388 s
env0_first_0:                 episode reward: 17.0000,                 loss: 0.0034
env0_second_0:                 episode reward: -17.0000,                 loss: nan
env1_first_0:                 episode reward: 18.0500,                 loss: nan
env1_second_0:                 episode reward: -18.0500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 2095.6,                last time consumption/overall running time: 434.3963s / 86613.4351 s
env0_first_0:                 episode reward: 21.1500,                 loss: 0.0034
env0_second_0:                 episode reward: -21.1500,                 loss: nan
env1_first_0:                 episode reward: 18.9000,                 loss: nan
env1_second_0:                 episode reward: -18.9000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 2084.1,                last time consumption/overall running time: 432.5806s / 87046.0157 s
env0_first_0:                 episode reward: 19.6500,                 loss: 0.0033
env0_second_0:                 episode reward: -19.6500,                 loss: nan
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1910.4,                last time consumption/overall running time: 390.1415s / 87436.1572 s
env0_first_0:                 episode reward: 18.1000,                 loss: 0.0033
env0_second_0:                 episode reward: -18.1000,                 loss: nan
env1_first_0:                 episode reward: 20.1500,                 loss: nan
env1_second_0:                 episode reward: -20.1500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1902.15,                last time consumption/overall running time: 395.0894s / 87831.2466 s
env0_first_0:                 episode reward: 19.1500,                 loss: 0.0028
env0_second_0:                 episode reward: -19.1500,                 loss: nan
env1_first_0:                 episode reward: 18.5500,                 loss: nan
env1_second_0:                 episode reward: -18.5500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 2109.8,                last time consumption/overall running time: 403.6581s / 88234.9047 s
env0_first_0:                 episode reward: 18.5000,                 loss: 0.0033
env0_second_0:                 episode reward: -18.5000,                 loss: nan
env1_first_0:                 episode reward: 16.7500,                 loss: nan
env1_second_0:                 episode reward: -16.7500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1872.8,                last time consumption/overall running time: 350.5259s / 88585.4306 s
env0_first_0:                 episode reward: 19.2500,                 loss: 0.0033
env0_second_0:                 episode reward: -19.2500,                 loss: nan
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 2161.05,                last time consumption/overall running time: 400.9740s / 88986.4046 s
env0_first_0:                 episode reward: 12.0500,                 loss: 0.0034
env0_second_0:                 episode reward: -12.0500,                 loss: nan
env1_first_0:                 episode reward: 12.8000,                 loss: nan
env1_second_0:                 episode reward: -12.8000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1856.1,                last time consumption/overall running time: 353.4465s / 89339.8511 s
env0_first_0:                 episode reward: 18.6000,                 loss: 0.0031
env0_second_0:                 episode reward: -18.6000,                 loss: nan
env1_first_0:                 episode reward: 18.8500,                 loss: nan
env1_second_0:                 episode reward: -18.8500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1900.7,                last time consumption/overall running time: 360.4657s / 89700.3167 s
env0_first_0:                 episode reward: 20.0500,                 loss: 0.0024
env0_second_0:                 episode reward: -20.0500,                 loss: nan
env1_first_0:                 episode reward: 19.0500,                 loss: nan
env1_second_0:                 episode reward: -19.0500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1898.55,                last time consumption/overall running time: 361.9880s / 90062.3047 s
env0_first_0:                 episode reward: 19.4000,                 loss: 0.0028
env0_second_0:                 episode reward: -19.4000,                 loss: nan
env1_first_0:                 episode reward: 18.8500,                 loss: nan
env1_second_0:                 episode reward: -18.8500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2016.75,                last time consumption/overall running time: 379.9334s / 90442.2380 s
env0_first_0:                 episode reward: 13.9500,                 loss: 0.0031
env0_second_0:                 episode reward: -13.9500,                 loss: nan
env1_first_0:                 episode reward: 14.6500,                 loss: nan
env1_second_0:                 episode reward: -14.6500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1886.0,                last time consumption/overall running time: 353.9830s / 90796.2210 s
env0_first_0:                 episode reward: 18.5000,                 loss: 0.0032
env0_second_0:                 episode reward: -18.5000,                 loss: nan
env1_first_0:                 episode reward: 20.3000,                 loss: nan
env1_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 2047.6,                last time consumption/overall running time: 387.7898s / 91184.0108 s
env0_first_0:                 episode reward: 20.2500,                 loss: 0.0027
env0_second_0:                 episode reward: -20.2500,                 loss: nan
env1_first_0:                 episode reward: 18.8500,                 loss: nan
env1_second_0:                 episode reward: -18.8500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1825.75,                last time consumption/overall running time: 349.2029s / 91533.2137 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0027
env0_second_0:                 episode reward: -20.5500,                 loss: nan
env1_first_0:                 episode reward: 20.0000,                 loss: nan
env1_second_0:                 episode reward: -20.0000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1814.4,                last time consumption/overall running time: 348.8137s / 91882.0274 s
env0_first_0:                 episode reward: 21.3500,                 loss: 0.0024
env0_second_0:                 episode reward: -21.3500,                 loss: nan
env1_first_0:                 episode reward: 22.0500,                 loss: nan
env1_second_0:                 episode reward: -22.0500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1879.15,                last time consumption/overall running time: 356.1618s / 92238.1893 s
env0_first_0:                 episode reward: 21.1500,                 loss: 0.0028
env0_second_0:                 episode reward: -21.1500,                 loss: nan
env1_first_0:                 episode reward: 18.0500,                 loss: nan
env1_second_0:                 episode reward: -18.0500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1827.05,                last time consumption/overall running time: 349.9172s / 92588.1065 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0027
env0_second_0:                 episode reward: -20.8000,                 loss: nan
env1_first_0:                 episode reward: 21.6000,                 loss: nan
env1_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 4631.75,                last time consumption/overall running time: 1492.2380s / 94080.3445 s
env0_first_0:                 episode reward: 0.1500,                 loss: nan
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Score delta: 52.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/2649_0.
Episode: 2681/10000 (26.8100%),                 avg. length: 4728.8,                last time consumption/overall running time: 2170.9604s / 96251.3048 s
env0_first_0:                 episode reward: -23.6500,                 loss: nan
env0_second_0:                 episode reward: 23.6500,                 loss: nan
env1_first_0:                 episode reward: -18.2000,                 loss: nan
env1_second_0:                 episode reward: 18.2000,                 loss: nan
Score delta: 101.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/2670_1.
Episode: 2701/10000 (27.0100%),                 avg. length: 3597.45,                last time consumption/overall running time: 693.9562s / 96945.2610 s
env0_first_0:                 episode reward: 12.0500,                 loss: 0.0042
env0_second_0:                 episode reward: -12.0500,                 loss: nan
env1_first_0:                 episode reward: 17.9000,                 loss: nan
env1_second_0:                 episode reward: -17.9000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 4773.65,                last time consumption/overall running time: 1554.8609s / 98500.1219 s
env0_first_0:                 episode reward: 39.1000,                 loss: nan
env0_second_0:                 episode reward: -39.1000,                 loss: nan
env1_first_0:                 episode reward: 35.4000,                 loss: nan
env1_second_0:                 episode reward: -35.4000,                 loss: nan
Score delta: 53.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/2716_0.
Episode: 2741/10000 (27.4100%),                 avg. length: 7587.7,                last time consumption/overall running time: 2441.6907s / 100941.8126 s
env0_first_0:                 episode reward: -32.9000,                 loss: nan
env0_second_0:                 episode reward: 32.9000,                 loss: nan
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Score delta: 136.6, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/2737_1.
Episode: 2761/10000 (27.6100%),                 avg. length: 3708.85,                last time consumption/overall running time: 701.9908s / 101643.8034 s
env0_first_0:                 episode reward: 17.2000,                 loss: 0.0050
env0_second_0:                 episode reward: -17.2000,                 loss: nan
env1_first_0:                 episode reward: 13.2500,                 loss: nan
env1_second_0:                 episode reward: -13.2500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 6170.6,                last time consumption/overall running time: 1872.4249s / 103516.2283 s
env0_first_0:                 episode reward: -14.4000,                 loss: nan
env0_second_0:                 episode reward: 14.4000,                 loss: nan
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Score delta: 52.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/2766_0.
Episode: 2801/10000 (28.0100%),                 avg. length: 7823.5,                last time consumption/overall running time: 2739.1081s / 106255.3364 s
env0_first_0:                 episode reward: -59.5500,                 loss: nan
env0_second_0:                 episode reward: 59.5500,                 loss: nan
env1_first_0:                 episode reward: -59.5500,                 loss: nan
env1_second_0:                 episode reward: 59.5500,                 loss: nan
Score delta: 198.6, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/2787_1.
Episode: 2821/10000 (28.2100%),                 avg. length: 3829.25,                last time consumption/overall running time: 729.2771s / 106984.6135 s
env0_first_0:                 episode reward: 8.3000,                 loss: 0.0048
env0_second_0:                 episode reward: -8.3000,                 loss: nan
env1_first_0:                 episode reward: 7.2000,                 loss: nan
env1_second_0:                 episode reward: -7.2000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 3175.55,                last time consumption/overall running time: 601.3843s / 107585.9978 s
env0_first_0:                 episode reward: 12.0500,                 loss: 0.0046
env0_second_0:                 episode reward: -12.0500,                 loss: nan
env1_first_0:                 episode reward: 8.0500,                 loss: nan
env1_second_0:                 episode reward: -8.0500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 2936.45,                last time consumption/overall running time: 549.8124s / 108135.8103 s
env0_first_0:                 episode reward: 15.3000,                 loss: 0.0046
env0_second_0:                 episode reward: -15.3000,                 loss: nan
env1_first_0:                 episode reward: 16.2000,                 loss: nan
env1_second_0:                 episode reward: -16.2000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 2368.3,                last time consumption/overall running time: 448.5513s / 108584.3615 s
env0_first_0:                 episode reward: 19.2000,                 loss: 0.0037
env0_second_0:                 episode reward: -19.2000,                 loss: nan
env1_first_0:                 episode reward: 16.5000,                 loss: nan
env1_second_0:                 episode reward: -16.5000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 2378.85,                last time consumption/overall running time: 452.9643s / 109037.3258 s
env0_first_0:                 episode reward: 15.7000,                 loss: 0.0031
env0_second_0:                 episode reward: -15.7000,                 loss: nan
env1_first_0:                 episode reward: 15.2500,                 loss: nan
env1_second_0:                 episode reward: -15.2500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 2486.4,                last time consumption/overall running time: 464.7528s / 109502.0786 s
env0_first_0:                 episode reward: 14.9500,                 loss: 0.0039
env0_second_0:                 episode reward: -14.9500,                 loss: nan
env1_first_0:                 episode reward: 16.9000,                 loss: nan
env1_second_0:                 episode reward: -16.9000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 2530.55,                last time consumption/overall running time: 478.0708s / 109980.1494 s
env0_first_0:                 episode reward: 16.4000,                 loss: 0.0042
env0_second_0:                 episode reward: -16.4000,                 loss: nan
env1_first_0:                 episode reward: 16.0500,                 loss: nan
env1_second_0:                 episode reward: -16.0500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 2212.75,                last time consumption/overall running time: 416.0383s / 110396.1877 s
env0_first_0:                 episode reward: 18.7500,                 loss: 0.0040
env0_second_0:                 episode reward: -18.7500,                 loss: nan
env1_first_0:                 episode reward: 18.6000,                 loss: nan
env1_second_0:                 episode reward: -18.6000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 2079.8,                last time consumption/overall running time: 356.9690s / 110753.1567 s
env0_first_0:                 episode reward: 20.1500,                 loss: 0.0032
env0_second_0:                 episode reward: -20.1500,                 loss: nan
env1_first_0:                 episode reward: 18.8500,                 loss: nan
env1_second_0:                 episode reward: -18.8500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 2033.35,                last time consumption/overall running time: 335.8804s / 111089.0371 s
env0_first_0:                 episode reward: 18.0000,                 loss: 0.0029
env0_second_0:                 episode reward: -18.0000,                 loss: nan
env1_first_0:                 episode reward: 20.5000,                 loss: nan
env1_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 2040.3,                last time consumption/overall running time: 351.4238s / 111440.4609 s
env0_first_0:                 episode reward: 19.3000,                 loss: 0.0030
env0_second_0:                 episode reward: -19.3000,                 loss: nan
env1_first_0:                 episode reward: 21.2000,                 loss: nan
env1_second_0:                 episode reward: -21.2000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 5947.5,                last time consumption/overall running time: 1719.3424s / 113159.8033 s
env0_first_0:                 episode reward: -15.3500,                 loss: nan
env0_second_0:                 episode reward: 15.3500,                 loss: nan
env1_first_0:                 episode reward: -38.2000,                 loss: nan
env1_second_0:                 episode reward: 38.2000,                 loss: nan
Score delta: 50.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3026_0.
Episode: 3061/10000 (30.6100%),                 avg. length: 6529.05,                last time consumption/overall running time: 2344.6258s / 115504.4291 s
env0_first_0:                 episode reward: -39.4500,                 loss: nan
env0_second_0:                 episode reward: 39.4500,                 loss: nan
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Score delta: 133.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3047_1.
Episode: 3081/10000 (30.8100%),                 avg. length: 3587.0,                last time consumption/overall running time: 574.0837s / 116078.5128 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0051
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 4393.15,                last time consumption/overall running time: 715.4427s / 116793.9556 s
env0_first_0:                 episode reward: 7.2500,                 loss: 0.0052
env0_second_0:                 episode reward: -7.2500,                 loss: nan
env1_first_0:                 episode reward: 8.4500,                 loss: nan
env1_second_0:                 episode reward: -8.4500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 6845.15,                last time consumption/overall running time: 1866.7686s / 118660.7242 s
env0_first_0:                 episode reward: 18.4000,                 loss: nan
env0_second_0:                 episode reward: -18.4000,                 loss: nan
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Score delta: 70.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3102_0.
Episode: 3141/10000 (31.4100%),                 avg. length: 3357.5,                last time consumption/overall running time: 1864.6008s / 120525.3250 s
env0_first_0:                 episode reward: -9.2500,                 loss: nan
env0_second_0:                 episode reward: 9.2500,                 loss: nan
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Score delta: 50.6, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3124_1.
Episode: 3161/10000 (31.6100%),                 avg. length: 2827.2,                last time consumption/overall running time: 470.9003s / 120996.2253 s
env0_first_0:                 episode reward: 16.4000,                 loss: 0.0039
env0_second_0:                 episode reward: -16.4000,                 loss: nan
env1_first_0:                 episode reward: 13.1500,                 loss: nan
env1_second_0:                 episode reward: -13.1500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 6196.25,                last time consumption/overall running time: 1775.7846s / 122772.0099 s
env0_first_0:                 episode reward: 5.3500,                 loss: nan
env0_second_0:                 episode reward: -5.3500,                 loss: nan
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
Score delta: 50.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3165_0.
Episode: 3201/10000 (32.0100%),                 avg. length: 4586.5,                last time consumption/overall running time: 2092.1476s / 124864.1575 s
env0_first_0:                 episode reward: -8.0000,                 loss: nan
env0_second_0:                 episode reward: 8.0000,                 loss: nan
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Score delta: 57.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3192_1.
Episode: 3221/10000 (32.2100%),                 avg. length: 2924.1,                last time consumption/overall running time: 490.0585s / 125354.2160 s
env0_first_0:                 episode reward: 17.5500,                 loss: 0.0041
env0_second_0:                 episode reward: -17.5500,                 loss: nan
env1_first_0:                 episode reward: 24.3500,                 loss: nan
env1_second_0:                 episode reward: -24.3500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 2549.7,                last time consumption/overall running time: 423.5656s / 125777.7816 s
env0_first_0:                 episode reward: 18.6000,                 loss: 0.0036
env0_second_0:                 episode reward: -18.6000,                 loss: nan
env1_first_0:                 episode reward: 20.3500,                 loss: nan
env1_second_0:                 episode reward: -20.3500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 2656.0,                last time consumption/overall running time: 439.1290s / 126216.9106 s
env0_first_0:                 episode reward: 6.0500,                 loss: 0.0032
env0_second_0:                 episode reward: -6.0500,                 loss: nan
env1_first_0:                 episode reward: 9.5000,                 loss: nan
env1_second_0:                 episode reward: -9.5000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 3010.8,                last time consumption/overall running time: 477.6436s / 126694.5541 s
env0_first_0:                 episode reward: 15.4500,                 loss: 0.0047
env0_second_0:                 episode reward: -15.4500,                 loss: nan
env1_first_0:                 episode reward: 13.4000,                 loss: nan
env1_second_0:                 episode reward: -13.4000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 2498.3,                last time consumption/overall running time: 403.2827s / 127097.8368 s
env0_first_0:                 episode reward: 19.0000,                 loss: 0.0035
env0_second_0:                 episode reward: -19.0000,                 loss: nan
env1_first_0:                 episode reward: 14.6000,                 loss: nan
env1_second_0:                 episode reward: -14.6000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 2590.15,                last time consumption/overall running time: 422.6723s / 127520.5091 s
env0_first_0:                 episode reward: 15.7000,                 loss: 0.0034
env0_second_0:                 episode reward: -15.7000,                 loss: nan
env1_first_0:                 episode reward: 20.5000,                 loss: nan
env1_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 2096.5,                last time consumption/overall running time: 337.8120s / 127858.3211 s
env0_first_0:                 episode reward: 18.1000,                 loss: 0.0031
env0_second_0:                 episode reward: -18.1000,                 loss: nan
env1_first_0:                 episode reward: 15.7500,                 loss: nan
env1_second_0:                 episode reward: -15.7500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 3565.2,                last time consumption/overall running time: 597.5082s / 128455.8292 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0054
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 2082.05,                last time consumption/overall running time: 326.0487s / 128781.8779 s
env0_first_0:                 episode reward: 17.7500,                 loss: 0.0036
env0_second_0:                 episode reward: -17.7500,                 loss: nan
env1_first_0:                 episode reward: 19.0500,                 loss: nan
env1_second_0:                 episode reward: -19.0500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 2579.95,                last time consumption/overall running time: 420.7076s / 129202.5855 s
env0_first_0:                 episode reward: 16.6500,                 loss: 0.0030
env0_second_0:                 episode reward: -16.6500,                 loss: nan
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 2872.4,                last time consumption/overall running time: 489.5894s / 129692.1749 s
env0_first_0:                 episode reward: 9.3500,                 loss: 0.0041
env0_second_0:                 episode reward: -9.3500,                 loss: nan
env1_first_0:                 episode reward: 9.0500,                 loss: nan
env1_second_0:                 episode reward: -9.0500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 3017.2,                last time consumption/overall running time: 518.5505s / 130210.7254 s
env0_first_0:                 episode reward: 7.6000,                 loss: 0.0041
env0_second_0:                 episode reward: -7.6000,                 loss: nan
env1_first_0:                 episode reward: 13.2000,                 loss: nan
env1_second_0:                 episode reward: -13.2000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 2444.9,                last time consumption/overall running time: 432.4288s / 130643.1542 s
env0_first_0:                 episode reward: 13.9500,                 loss: 0.0046
env0_second_0:                 episode reward: -13.9500,                 loss: nan
env1_first_0:                 episode reward: 13.1500,                 loss: nan
env1_second_0:                 episode reward: -13.1500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 2668.25,                last time consumption/overall running time: 454.0580s / 131097.2122 s
env0_first_0:                 episode reward: 26.4500,                 loss: 0.0036
env0_second_0:                 episode reward: -26.4500,                 loss: nan
env1_first_0:                 episode reward: 23.5000,                 loss: nan
env1_second_0:                 episode reward: -23.5000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 5985.2,                last time consumption/overall running time: 1733.0339s / 132830.2461 s
env0_first_0:                 episode reward: -6.8000,                 loss: nan
env0_second_0:                 episode reward: 6.8000,                 loss: nan
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Score delta: 76.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3482_0.
Episode: 3521/10000 (35.2100%),                 avg. length: 5176.15,                last time consumption/overall running time: 2041.5838s / 134871.8299 s
env0_first_0:                 episode reward: -24.6500,                 loss: nan
env0_second_0:                 episode reward: 24.6500,                 loss: nan
env1_first_0:                 episode reward: -22.4500,                 loss: nan
env1_second_0:                 episode reward: 22.4500,                 loss: nan
Score delta: 60.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3515_1.
Episode: 3541/10000 (35.4100%),                 avg. length: 3364.95,                last time consumption/overall running time: 552.9622s / 135424.7921 s
env0_first_0:                 episode reward: 18.2000,                 loss: 0.0052
env0_second_0:                 episode reward: -18.2000,                 loss: nan
env1_first_0:                 episode reward: 11.8500,                 loss: nan
env1_second_0:                 episode reward: -11.8500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 3091.95,                last time consumption/overall running time: 509.6320s / 135934.4241 s
env0_first_0:                 episode reward: 16.2500,                 loss: 0.0040
env0_second_0:                 episode reward: -16.2500,                 loss: nan
env1_first_0:                 episode reward: 14.3500,                 loss: nan
env1_second_0:                 episode reward: -14.3500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 3069.7,                last time consumption/overall running time: 468.2215s / 136402.6455 s
env0_first_0:                 episode reward: 9.6000,                 loss: 0.0045
env0_second_0:                 episode reward: -9.6000,                 loss: nan
env1_first_0:                 episode reward: 10.5500,                 loss: nan
env1_second_0:                 episode reward: -10.5500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 3997.6,                last time consumption/overall running time: 612.9630s / 137015.6086 s
env0_first_0:                 episode reward: 7.7000,                 loss: 0.0052
env0_second_0:                 episode reward: -7.7000,                 loss: nan
env1_first_0:                 episode reward: 10.7500,                 loss: nan
env1_second_0:                 episode reward: -10.7500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 2858.75,                last time consumption/overall running time: 428.1874s / 137443.7959 s
env0_first_0:                 episode reward: 14.4000,                 loss: 0.0046
env0_second_0:                 episode reward: -14.4000,                 loss: nan
env1_first_0:                 episode reward: 19.9000,                 loss: nan
env1_second_0:                 episode reward: -19.9000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 2683.35,                last time consumption/overall running time: 408.8788s / 137852.6747 s
env0_first_0:                 episode reward: 17.1000,                 loss: 0.0034
env0_second_0:                 episode reward: -17.1000,                 loss: nan
env1_first_0:                 episode reward: 17.5500,                 loss: nan
env1_second_0:                 episode reward: -17.5500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 3135.3,                last time consumption/overall running time: 1210.8761s / 139063.5508 s
env0_first_0:                 episode reward: 21.6000,                 loss: nan
env0_second_0:                 episode reward: -21.6000,                 loss: nan
env1_first_0:                 episode reward: 14.3500,                 loss: nan
env1_second_0:                 episode reward: -14.3500,                 loss: nan
Score delta: 50.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3656_0.
Episode: 3681/10000 (36.8100%),                 avg. length: 7264.0,                last time consumption/overall running time: 1127.0646s / 140190.6155 s
env0_first_0:                 episode reward: 2.5000,                 loss: nan
env0_second_0:                 episode reward: -2.5000,                 loss: 0.0042
env1_first_0:                 episode reward: 11.2500,                 loss: nan
env1_second_0:                 episode reward: -11.2500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 6483.8,                last time consumption/overall running time: 1038.5901s / 141229.2056 s
env0_first_0:                 episode reward: -3.7500,                 loss: nan
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0046
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 6011.0,                last time consumption/overall running time: 911.6272s / 142140.8328 s
env0_first_0:                 episode reward: -3.9000,                 loss: nan
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0050
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 6316.55,                last time consumption/overall running time: 905.1781s / 143046.0109 s
env0_first_0:                 episode reward: -10.5000,                 loss: nan
env0_second_0:                 episode reward: 10.5000,                 loss: 0.0052
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 4753.75,                last time consumption/overall running time: 711.3428s / 143757.3537 s
env0_first_0:                 episode reward: -14.2500,                 loss: nan
env0_second_0:                 episode reward: 14.2500,                 loss: 0.0036
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 5701.3,                last time consumption/overall running time: 891.2451s / 144648.5988 s
env0_first_0:                 episode reward: -13.7500,                 loss: nan
env0_second_0:                 episode reward: 13.7500,                 loss: 0.0063
env1_first_0:                 episode reward: -26.0000,                 loss: nan
env1_second_0:                 episode reward: 26.0000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 6153.0,                last time consumption/overall running time: 970.8522s / 145619.4509 s
env0_first_0:                 episode reward: 6.8000,                 loss: nan
env0_second_0:                 episode reward: -6.8000,                 loss: 0.0061
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 5550.45,                last time consumption/overall running time: 892.3529s / 146511.8038 s
env0_first_0:                 episode reward: -19.3000,                 loss: nan
env0_second_0:                 episode reward: 19.3000,                 loss: 0.0040
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 6211.55,                last time consumption/overall running time: 995.3325s / 147507.1363 s
env0_first_0:                 episode reward: -4.6500,                 loss: nan
env0_second_0:                 episode reward: 4.6500,                 loss: 0.0047
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 6095.5,                last time consumption/overall running time: 971.2358s / 148478.3722 s
env0_first_0:                 episode reward: -16.8500,                 loss: nan
env0_second_0:                 episode reward: 16.8500,                 loss: 0.0049
env1_first_0:                 episode reward: -20.6500,                 loss: nan
env1_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 5864.6,                last time consumption/overall running time: 895.9818s / 149374.3539 s
env0_first_0:                 episode reward: -17.9000,                 loss: nan
env0_second_0:                 episode reward: 17.9000,                 loss: 0.0042
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 5592.8,                last time consumption/overall running time: 1851.8277s / 151226.1817 s
env0_first_0:                 episode reward: -18.3500,                 loss: nan
env0_second_0:                 episode reward: 18.3500,                 loss: nan
env1_first_0:                 episode reward: -23.0500,                 loss: nan
env1_second_0:                 episode reward: 23.0500,                 loss: nan
Score delta: 50.6, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3900_1.
Episode: 3921/10000 (39.2100%),                 avg. length: 3069.35,                last time consumption/overall running time: 484.2318s / 151710.4134 s
env0_first_0:                 episode reward: 16.6000,                 loss: 0.0042
env0_second_0:                 episode reward: -16.6000,                 loss: nan
env1_first_0:                 episode reward: 17.1000,                 loss: nan
env1_second_0:                 episode reward: -17.1000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 3298.25,                last time consumption/overall running time: 533.9632s / 152244.3766 s
env0_first_0:                 episode reward: 16.1500,                 loss: 0.0043
env0_second_0:                 episode reward: -16.1500,                 loss: nan
env1_first_0:                 episode reward: 23.1500,                 loss: nan
env1_second_0:                 episode reward: -23.1500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 6622.3,                last time consumption/overall running time: 1865.0487s / 154109.4253 s
env0_first_0:                 episode reward: -11.5500,                 loss: nan
env0_second_0:                 episode reward: 11.5500,                 loss: nan
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Score delta: 64.6, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3944_0.
Episode: 3981/10000 (39.8100%),                 avg. length: 4756.15,                last time consumption/overall running time: 2012.5014s / 156121.9267 s
env0_first_0:                 episode reward: 1.2000,                 loss: nan
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Score delta: 134.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/3965_1.
Episode: 4001/10000 (40.0100%),                 avg. length: 2787.65,                last time consumption/overall running time: 460.0229s / 156581.9496 s
env0_first_0:                 episode reward: 15.0000,                 loss: 0.0041
env0_second_0:                 episode reward: -15.0000,                 loss: nan
env1_first_0:                 episode reward: 16.9000,                 loss: nan
env1_second_0:                 episode reward: -16.9000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 7053.8,                last time consumption/overall running time: 1861.7756s / 158443.7252 s
env0_first_0:                 episode reward: 3.0500,                 loss: nan
env0_second_0:                 episode reward: -3.0500,                 loss: nan
env1_first_0:                 episode reward: 21.4500,                 loss: nan
env1_second_0:                 episode reward: -21.4500,                 loss: nan
Score delta: 69.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4006_0.
Episode: 4041/10000 (40.4100%),                 avg. length: 7250.65,                last time consumption/overall running time: 2572.7743s / 161016.4995 s
env0_first_0:                 episode reward: -47.8000,                 loss: nan
env0_second_0:                 episode reward: 47.8000,                 loss: nan
env1_first_0:                 episode reward: -59.3000,                 loss: nan
env1_second_0:                 episode reward: 59.3000,                 loss: nan
Score delta: 79.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4027_1.
Episode: 4061/10000 (40.6100%),                 avg. length: 3321.85,                last time consumption/overall running time: 543.4933s / 161559.9928 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0052
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 9.2000,                 loss: nan
env1_second_0:                 episode reward: -9.2000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 3625.15,                last time consumption/overall running time: 596.2457s / 162156.2385 s
env0_first_0:                 episode reward: 11.9000,                 loss: 0.0042
env0_second_0:                 episode reward: -11.9000,                 loss: nan
env1_first_0:                 episode reward: 12.1500,                 loss: nan
env1_second_0:                 episode reward: -12.1500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 3159.75,                last time consumption/overall running time: 515.0475s / 162671.2859 s
env0_first_0:                 episode reward: 13.9000,                 loss: 0.0037
env0_second_0:                 episode reward: -13.9000,                 loss: nan
env1_first_0:                 episode reward: 16.3000,                 loss: nan
env1_second_0:                 episode reward: -16.3000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 2652.35,                last time consumption/overall running time: 421.0541s / 163092.3401 s
env0_first_0:                 episode reward: 14.1000,                 loss: 0.0040
env0_second_0:                 episode reward: -14.1000,                 loss: nan
env1_first_0:                 episode reward: 12.8000,                 loss: nan
env1_second_0:                 episode reward: -12.8000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 3030.5,                last time consumption/overall running time: 507.5223s / 163599.8624 s
env0_first_0:                 episode reward: 15.5500,                 loss: 0.0036
env0_second_0:                 episode reward: -15.5500,                 loss: nan
env1_first_0:                 episode reward: 14.0500,                 loss: nan
env1_second_0:                 episode reward: -14.0500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 2369.5,                last time consumption/overall running time: 388.2560s / 163988.1183 s
env0_first_0:                 episode reward: 16.8500,                 loss: 0.0036
env0_second_0:                 episode reward: -16.8500,                 loss: nan
env1_first_0:                 episode reward: 18.0000,                 loss: nan
env1_second_0:                 episode reward: -18.0000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 4941.6,                last time consumption/overall running time: 1676.2414s / 165664.3597 s
env0_first_0:                 episode reward: 11.3500,                 loss: nan
env0_second_0:                 episode reward: -11.3500,                 loss: nan
env1_first_0:                 episode reward: 14.4500,                 loss: nan
env1_second_0:                 episode reward: -14.4500,                 loss: nan
Score delta: 59.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4174_0.
Episode: 4201/10000 (42.0100%),                 avg. length: 7478.45,                last time consumption/overall running time: 1219.0678s / 166883.4275 s
env0_first_0:                 episode reward: -0.8500,                 loss: nan
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0033
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 7332.05,                last time consumption/overall running time: 1192.1898s / 168075.6174 s
env0_first_0:                 episode reward: -13.7500,                 loss: nan
env0_second_0:                 episode reward: 13.7500,                 loss: 0.0035
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 6610.15,                last time consumption/overall running time: 1069.9216s / 169145.5390 s
env0_first_0:                 episode reward: -11.8500,                 loss: nan
env0_second_0:                 episode reward: 11.8500,                 loss: 0.0034
env1_first_0:                 episode reward: 9.0000,                 loss: nan
env1_second_0:                 episode reward: -9.0000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 8036.95,                last time consumption/overall running time: 1297.7395s / 170443.2785 s
env0_first_0:                 episode reward: 36.0500,                 loss: nan
env0_second_0:                 episode reward: -36.0500,                 loss: 0.0050
env1_first_0:                 episode reward: 24.6500,                 loss: nan
env1_second_0:                 episode reward: -24.6500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 7902.75,                last time consumption/overall running time: 1282.9358s / 171726.2143 s
env0_first_0:                 episode reward: 3.5500,                 loss: nan
env0_second_0:                 episode reward: -3.5500,                 loss: 0.0060
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 4006.2,                last time consumption/overall running time: 2152.7226s / 173878.9369 s
env0_first_0:                 episode reward: -0.8500,                 loss: nan
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: 12.6500,                 loss: nan
env1_second_0:                 episode reward: -12.6500,                 loss: nan
Score delta: 58.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4283_1.
Episode: 4321/10000 (43.2100%),                 avg. length: 3135.25,                last time consumption/overall running time: 1334.2687s / 175213.2056 s
env0_first_0:                 episode reward: 22.4000,                 loss: 0.0046
env0_second_0:                 episode reward: -22.4000,                 loss: nan
env1_first_0:                 episode reward: 21.8000,                 loss: nan
env1_second_0:                 episode reward: -21.8000,                 loss: nan
Score delta: 53.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4321_0.
Episode: 4341/10000 (43.4100%),                 avg. length: 6973.55,                last time consumption/overall running time: 1083.4665s / 176296.6722 s
env0_first_0:                 episode reward: -1.3000,                 loss: nan
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0044
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 8306.1,                last time consumption/overall running time: 2869.2619s / 179165.9341 s
env0_first_0:                 episode reward: -8.9000,                 loss: nan
env0_second_0:                 episode reward: 8.9000,                 loss: nan
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Score delta: 53.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4359_1.
Episode: 4381/10000 (43.8100%),                 avg. length: 3662.5,                last time consumption/overall running time: 583.7441s / 179749.6783 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.0062
env0_second_0:                 episode reward: 4.6500,                 loss: nan
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 4120.4,                last time consumption/overall running time: 643.2923s / 180392.9705 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0057
env0_second_0:                 episode reward: 3.6500,                 loss: nan
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 3186.65,                last time consumption/overall running time: 515.7922s / 180908.7627 s
env0_first_0:                 episode reward: 10.1000,                 loss: 0.0047
env0_second_0:                 episode reward: -10.1000,                 loss: nan
env1_first_0:                 episode reward: 17.9000,                 loss: nan
env1_second_0:                 episode reward: -17.9000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 3865.45,                last time consumption/overall running time: 1677.9922s / 182586.7550 s
env0_first_0:                 episode reward: 37.2000,                 loss: nan
env0_second_0:                 episode reward: -37.2000,                 loss: nan
env1_first_0:                 episode reward: 31.3500,                 loss: nan
env1_second_0:                 episode reward: -31.3500,                 loss: nan
Score delta: 62.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4437_0.
Episode: 4461/10000 (44.6100%),                 avg. length: 7678.45,                last time consumption/overall running time: 1254.5581s / 183841.3130 s
env0_first_0:                 episode reward: -0.9500,                 loss: nan
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0051
env1_first_0:                 episode reward: 17.6500,                 loss: nan
env1_second_0:                 episode reward: -17.6500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 5021.9,                last time consumption/overall running time: 2215.9030s / 186057.2160 s
env0_first_0:                 episode reward: -20.7000,                 loss: nan
env0_second_0:                 episode reward: 20.7000,                 loss: nan
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Score delta: 50.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4464_1.
Episode: 4501/10000 (45.0100%),                 avg. length: 3848.75,                last time consumption/overall running time: 630.9365s / 186688.1525 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0057
env0_second_0:                 episode reward: 10.7500,                 loss: nan
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 3789.65,                last time consumption/overall running time: 626.8635s / 187315.0160 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0058
env0_second_0:                 episode reward: 5.2500,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 3113.5,                last time consumption/overall running time: 515.2502s / 187830.2662 s
env0_first_0:                 episode reward: 17.8500,                 loss: 0.0043
env0_second_0:                 episode reward: -17.8500,                 loss: nan
env1_first_0:                 episode reward: 10.6000,                 loss: nan
env1_second_0:                 episode reward: -10.6000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 3696.1,                last time consumption/overall running time: 1615.5846s / 189445.8508 s
env0_first_0:                 episode reward: 16.2500,                 loss: 0.0048
env0_second_0:                 episode reward: -16.2500,                 loss: nan
env1_first_0:                 episode reward: 17.7500,                 loss: nan
env1_second_0:                 episode reward: -17.7500,                 loss: nan
Score delta: 68.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4561_0.
Episode: 4581/10000 (45.8100%),                 avg. length: 6345.6,                last time consumption/overall running time: 1037.5083s / 190483.3591 s
env0_first_0:                 episode reward: -39.4000,                 loss: nan
env0_second_0:                 episode reward: 39.4000,                 loss: 0.0064
env1_first_0:                 episode reward: -45.4000,                 loss: nan
env1_second_0:                 episode reward: 45.4000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 4943.15,                last time consumption/overall running time: 2050.6868s / 192534.0459 s
env0_first_0:                 episode reward: 0.0500,                 loss: nan
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Score delta: 170.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4582_1.
Episode: 4621/10000 (46.2100%),                 avg. length: 5741.2,                last time consumption/overall running time: 2154.5339s / 194688.5798 s
env0_first_0:                 episode reward: 10.0500,                 loss: nan
env0_second_0:                 episode reward: -10.0500,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Score delta: 53.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4619_0.
Episode: 4641/10000 (46.4100%),                 avg. length: 7117.1,                last time consumption/overall running time: 1185.3206s / 195873.9004 s
env0_first_0:                 episode reward: -10.2000,                 loss: nan
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0054
env1_first_0:                 episode reward: 8.1500,                 loss: nan
env1_second_0:                 episode reward: -8.1500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 7846.55,                last time consumption/overall running time: 2990.9554s / 198864.8558 s
env0_first_0:                 episode reward: -53.8500,                 loss: nan
env0_second_0:                 episode reward: 53.8500,                 loss: nan
env1_first_0:                 episode reward: -54.0500,                 loss: nan
env1_second_0:                 episode reward: 54.0500,                 loss: nan
Score delta: 81.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4646_1.
Episode: 4681/10000 (46.8100%),                 avg. length: 5801.3,                last time consumption/overall running time: 954.5335s / 199819.3893 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0046
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 9.7000,                 loss: nan
env1_second_0:                 episode reward: -9.7000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 5638.7,                last time consumption/overall running time: 931.1200s / 200750.5094 s
env0_first_0:                 episode reward: 9.6500,                 loss: 0.0042
env0_second_0:                 episode reward: -9.6500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 3674.55,                last time consumption/overall running time: 606.6210s / 201357.1304 s
env0_first_0:                 episode reward: 10.3500,                 loss: 0.0039
env0_second_0:                 episode reward: -10.3500,                 loss: nan
env1_first_0:                 episode reward: 13.8500,                 loss: nan
env1_second_0:                 episode reward: -13.8500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 5014.25,                last time consumption/overall running time: 817.3334s / 202174.4638 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.0036
env0_second_0:                 episode reward: -3.2500,                 loss: nan
env1_first_0:                 episode reward: 7.5500,                 loss: nan
env1_second_0:                 episode reward: -7.5500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 4649.35,                last time consumption/overall running time: 754.9892s / 202929.4530 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0043
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: 5.5000,                 loss: nan
env1_second_0:                 episode reward: -5.5000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 5034.5,                last time consumption/overall running time: 811.4503s / 203740.9033 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0046
env0_second_0:                 episode reward: 11.4500,                 loss: nan
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 6106.7,                last time consumption/overall running time: 1006.5924s / 204747.4957 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0059
env0_second_0:                 episode reward: 1.5000,                 loss: nan
env1_first_0:                 episode reward: 10.3500,                 loss: nan
env1_second_0:                 episode reward: -10.3500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 5307.25,                last time consumption/overall running time: 882.0454s / 205629.5411 s
env0_first_0:                 episode reward: 10.3500,                 loss: 0.0055
env0_second_0:                 episode reward: -10.3500,                 loss: nan
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 6813.4,                last time consumption/overall running time: 1112.3741s / 206741.9152 s
env0_first_0:                 episode reward: -21.2500,                 loss: 0.0065
env0_second_0:                 episode reward: 21.2500,                 loss: nan
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 7202.9,                last time consumption/overall running time: 1200.6304s / 207942.5456 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0076
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 5438.5,                last time consumption/overall running time: 2168.8444s / 210111.3900 s
env0_first_0:                 episode reward: 3.9500,                 loss: nan
env0_second_0:                 episode reward: -3.9500,                 loss: nan
env1_first_0:                 episode reward: 12.6000,                 loss: nan
env1_second_0:                 episode reward: -12.6000,                 loss: nan
Score delta: 55.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4876_0.
Episode: 4901/10000 (49.0100%),                 avg. length: 5256.1,                last time consumption/overall running time: 2346.3844s / 212457.7744 s
env0_first_0:                 episode reward: -10.5000,                 loss: nan
env0_second_0:                 episode reward: 10.5000,                 loss: nan
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Score delta: 61.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4897_1.
Episode: 4921/10000 (49.2100%),                 avg. length: 6008.35,                last time consumption/overall running time: 960.4712s / 213418.2456 s
env0_first_0:                 episode reward: 12.3000,                 loss: 0.0052
env0_second_0:                 episode reward: -12.3000,                 loss: nan
env1_first_0:                 episode reward: 15.3500,                 loss: nan
env1_second_0:                 episode reward: -15.3500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 4179.9,                last time consumption/overall running time: 2039.2746s / 215457.5202 s
env0_first_0:                 episode reward: 4.8500,                 loss: nan
env0_second_0:                 episode reward: -4.8500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Score delta: 62.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4930_0.
Episode: 4961/10000 (49.6100%),                 avg. length: 5151.2,                last time consumption/overall running time: 2622.2064s / 218079.7266 s
env0_first_0:                 episode reward: -18.4500,                 loss: nan
env0_second_0:                 episode reward: 18.4500,                 loss: nan
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Score delta: 68.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/4957_1.
Episode: 4981/10000 (49.8100%),                 avg. length: 7210.45,                last time consumption/overall running time: 1207.4191s / 219287.1458 s
env0_first_0:                 episode reward: -27.1000,                 loss: 0.0056
env0_second_0:                 episode reward: 27.1000,                 loss: nan
env1_first_0:                 episode reward: -28.2500,                 loss: nan
env1_second_0:                 episode reward: 28.2500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 7101.05,                last time consumption/overall running time: 1176.7094s / 220463.8552 s
env0_first_0:                 episode reward: -17.9000,                 loss: 0.0057
env0_second_0:                 episode reward: 17.9000,                 loss: nan
env1_first_0:                 episode reward: -18.6500,                 loss: nan
env1_second_0:                 episode reward: 18.6500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 7786.15,                last time consumption/overall running time: 1308.9207s / 221772.7759 s
env0_first_0:                 episode reward: -19.9500,                 loss: 0.0060
env0_second_0:                 episode reward: 19.9500,                 loss: nan
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 5454.4,                last time consumption/overall running time: 2306.5657s / 224079.3416 s
env0_first_0:                 episode reward: -6.6500,                 loss: nan
env0_second_0:                 episode reward: 6.6500,                 loss: nan
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Score delta: 65.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5024_0.
Episode: 5061/10000 (50.6100%),                 avg. length: 6593.35,                last time consumption/overall running time: 2713.1697s / 226792.5113 s
env0_first_0:                 episode reward: -31.5000,                 loss: nan
env0_second_0:                 episode reward: 31.5000,                 loss: nan
env1_first_0:                 episode reward: -30.4000,                 loss: nan
env1_second_0:                 episode reward: 30.4000,                 loss: nan
Score delta: 58.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5045_1.
Episode: 5081/10000 (50.8100%),                 avg. length: 7851.65,                last time consumption/overall running time: 3052.4001s / 229844.9114 s
env0_first_0:                 episode reward: 7.3000,                 loss: nan
env0_second_0:                 episode reward: -7.3000,                 loss: nan
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Score delta: 75.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5078_0.
Episode: 5101/10000 (51.0100%),                 avg. length: 6154.8,                last time consumption/overall running time: 2277.9486s / 232122.8600 s
env0_first_0:                 episode reward: -29.9500,                 loss: nan
env0_second_0:                 episode reward: 29.9500,                 loss: nan
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Score delta: 50.6, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5100_1.
Episode: 5121/10000 (51.2100%),                 avg. length: 8562.35,                last time consumption/overall running time: 3256.8736s / 235379.7336 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0061
env0_second_0:                 episode reward: 12.2000,                 loss: nan
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
Score delta: 52.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5121_0.
Episode: 5141/10000 (51.4100%),                 avg. length: 6694.7,                last time consumption/overall running time: 1167.8691s / 236547.6027 s
env0_first_0:                 episode reward: -45.5500,                 loss: nan
env0_second_0:                 episode reward: 45.5500,                 loss: 0.0085
env1_first_0:                 episode reward: -49.7500,                 loss: nan
env1_second_0:                 episode reward: 49.7500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 3967.4,                last time consumption/overall running time: 2424.0757s / 238971.6785 s
env0_first_0:                 episode reward: -38.2000,                 loss: nan
env0_second_0:                 episode reward: 38.2000,                 loss: nan
env1_first_0:                 episode reward: -52.9500,                 loss: nan
env1_second_0:                 episode reward: 52.9500,                 loss: nan
Score delta: 144.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5142_1.
Episode: 5181/10000 (51.8100%),                 avg. length: 7714.3,                last time consumption/overall running time: 1347.8757s / 240319.5542 s
env0_first_0:                 episode reward: -34.5500,                 loss: 0.0052
env0_second_0:                 episode reward: 34.5500,                 loss: nan
env1_first_0:                 episode reward: -29.3000,                 loss: nan
env1_second_0:                 episode reward: 29.3000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 7895.45,                last time consumption/overall running time: 1399.7897s / 241719.3439 s
env0_first_0:                 episode reward: -25.9500,                 loss: 0.0048
env0_second_0:                 episode reward: 25.9500,                 loss: nan
env1_first_0:                 episode reward: -31.1000,                 loss: nan
env1_second_0:                 episode reward: 31.1000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 7612.2,                last time consumption/overall running time: 1332.0766s / 243051.4205 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0050
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 7412.7,                last time consumption/overall running time: 2953.8169s / 246005.2373 s
env0_first_0:                 episode reward: 13.8500,                 loss: nan
env0_second_0:                 episode reward: -13.8500,                 loss: nan
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Score delta: 59.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5240_0.
Episode: 5261/10000 (52.6100%),                 avg. length: 6782.1,                last time consumption/overall running time: 2651.9323s / 248657.1697 s
env0_first_0:                 episode reward: -19.6500,                 loss: nan
env0_second_0:                 episode reward: 19.6500,                 loss: 0.0075
env1_first_0:                 episode reward: -38.2500,                 loss: nan
env1_second_0:                 episode reward: 38.2500,                 loss: nan
Score delta: 86.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5261_1.
Episode: 5281/10000 (52.8100%),                 avg. length: 7460.25,                last time consumption/overall running time: 1298.1665s / 249955.3361 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.0048
env0_second_0:                 episode reward: -3.2500,                 loss: nan
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 6085.55,                last time consumption/overall running time: 2869.6508s / 252824.9870 s
env0_first_0:                 episode reward: 29.0500,                 loss: nan
env0_second_0:                 episode reward: -29.0500,                 loss: nan
env1_first_0:                 episode reward: 38.8500,                 loss: nan
env1_second_0:                 episode reward: -38.8500,                 loss: nan
Score delta: 65.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5297_0.
Episode: 5321/10000 (53.2100%),                 avg. length: 8276.45,                last time consumption/overall running time: 3047.1110s / 255872.0979 s
env0_first_0:                 episode reward: -2.7500,                 loss: nan
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0062
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Score delta: 61.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5321_1.
Episode: 5341/10000 (53.4100%),                 avg. length: 5369.0,                last time consumption/overall running time: 1284.0232s / 257156.1211 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.0062
env0_second_0:                 episode reward: 14.7000,                 loss: nan
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 5622.85,                last time consumption/overall running time: 1428.3682s / 258584.4893 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0058
env0_second_0:                 episode reward: 10.2000,                 loss: nan
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 4342.15,                last time consumption/overall running time: 1096.8366s / 259681.3259 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0065
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 7066.3,                last time consumption/overall running time: 1635.7350s / 261317.0609 s
env0_first_0:                 episode reward: 13.4500,                 loss: 0.0062
env0_second_0:                 episode reward: -13.4500,                 loss: nan
env1_first_0:                 episode reward: 9.3500,                 loss: nan
env1_second_0:                 episode reward: -9.3500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 5227.4,                last time consumption/overall running time: 4183.8047s / 265500.8657 s
env0_first_0:                 episode reward: -1.5500,                 loss: nan
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Score delta: 58.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5402_0.
Episode: 5441/10000 (54.4100%),                 avg. length: 7025.45,                last time consumption/overall running time: 1507.7984s / 267008.6641 s
env0_first_0:                 episode reward: 6.3000,                 loss: nan
env0_second_0:                 episode reward: -6.3000,                 loss: 0.0055
env1_first_0:                 episode reward: 11.6000,                 loss: nan
env1_second_0:                 episode reward: -11.6000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 6457.25,                last time consumption/overall running time: 1817.4012s / 268826.0653 s
env0_first_0:                 episode reward: 2.6000,                 loss: nan
env0_second_0:                 episode reward: -2.6000,                 loss: 0.0068
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 6350.25,                last time consumption/overall running time: 5328.2597s / 274154.3251 s
env0_first_0:                 episode reward: -47.9500,                 loss: nan
env0_second_0:                 episode reward: 47.9500,                 loss: nan
env1_first_0:                 episode reward: -33.4000,                 loss: nan
env1_second_0:                 episode reward: 33.4000,                 loss: nan
Score delta: 62.0, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5469_1.
Episode: 5501/10000 (55.0100%),                 avg. length: 5704.0,                last time consumption/overall running time: 1460.5172s / 275614.8422 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0053
env0_second_0:                 episode reward: 7.5500,                 loss: nan
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 6579.75,                last time consumption/overall running time: 4640.8946s / 280255.7368 s
env0_first_0:                 episode reward: 42.2000,                 loss: nan
env0_second_0:                 episode reward: -42.2000,                 loss: nan
env1_first_0:                 episode reward: 44.8000,                 loss: nan
env1_second_0:                 episode reward: -44.8000,                 loss: nan
Score delta: 79.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5512_0.
Episode: 5541/10000 (55.4100%),                 avg. length: 6459.15,                last time consumption/overall running time: 1650.0102s / 281905.7470 s
env0_first_0:                 episode reward: 1.9000,                 loss: nan
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0045
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 5566.15,                last time consumption/overall running time: 4737.2245s / 286642.9714 s
env0_first_0:                 episode reward: -15.1500,                 loss: nan
env0_second_0:                 episode reward: 15.1500,                 loss: 0.0053
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Score delta: 57.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5561_1.
Episode: 5581/10000 (55.8100%),                 avg. length: 6341.5,                last time consumption/overall running time: 1607.5349s / 288250.5063 s
env0_first_0:                 episode reward: -43.1000,                 loss: 0.0063
env0_second_0:                 episode reward: 43.1000,                 loss: nan
env1_first_0:                 episode reward: -48.6000,                 loss: nan
env1_second_0:                 episode reward: 48.6000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 5249.35,                last time consumption/overall running time: 1339.3933s / 289589.8996 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.0042
env0_second_0:                 episode reward: 13.7000,                 loss: nan
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 4636.75,                last time consumption/overall running time: 1181.6238s / 290771.5235 s
env0_first_0:                 episode reward: 10.5000,                 loss: 0.0033
env0_second_0:                 episode reward: -10.5000,                 loss: nan
env1_first_0:                 episode reward: 8.5000,                 loss: nan
env1_second_0:                 episode reward: -8.5000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 5067.15,                last time consumption/overall running time: 1291.0365s / 292062.5600 s
env0_first_0:                 episode reward: 7.3000,                 loss: 0.0034
env0_second_0:                 episode reward: -7.3000,                 loss: nan
env1_first_0:                 episode reward: 7.2000,                 loss: nan
env1_second_0:                 episode reward: -7.2000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 5223.4,                last time consumption/overall running time: 1322.8085s / 293385.3685 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 5038.55,                last time consumption/overall running time: 1280.7599s / 294666.1284 s
env0_first_0:                 episode reward: 17.0500,                 loss: 0.0045
env0_second_0:                 episode reward: -17.0500,                 loss: nan
env1_first_0:                 episode reward: 7.3500,                 loss: nan
env1_second_0:                 episode reward: -7.3500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 5766.55,                last time consumption/overall running time: 1466.6690s / 296132.7974 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0046
env0_second_0:                 episode reward: 8.4500,                 loss: nan
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 5555.6,                last time consumption/overall running time: 1412.7760s / 297545.5733 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0041
env0_second_0:                 episode reward: 9.1000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 3758.9,                last time consumption/overall running time: 954.4633s / 298500.0366 s
env0_first_0:                 episode reward: 7.9500,                 loss: 0.0044
env0_second_0:                 episode reward: -7.9500,                 loss: nan
env1_first_0:                 episode reward: 13.4500,                 loss: nan
env1_second_0:                 episode reward: -13.4500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 4421.3,                last time consumption/overall running time: 1124.5757s / 299624.6123 s
env0_first_0:                 episode reward: 13.7000,                 loss: 0.0042
env0_second_0:                 episode reward: -13.7000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 7599.4,                last time consumption/overall running time: 4848.3834s / 304472.9957 s
env0_first_0:                 episode reward: 32.6500,                 loss: nan
env0_second_0:                 episode reward: -32.6500,                 loss: nan
env1_first_0:                 episode reward: 21.7000,                 loss: nan
env1_second_0:                 episode reward: -21.7000,                 loss: nan
Score delta: 53.2, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5763_0.
Episode: 5801/10000 (58.0100%),                 avg. length: 5076.5,                last time consumption/overall running time: 4655.1440s / 309128.1397 s
env0_first_0:                 episode reward: -8.3000,                 loss: nan
env0_second_0:                 episode reward: 8.3000,                 loss: nan
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Score delta: 67.8, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5790_1.
Episode: 5821/10000 (58.2100%),                 avg. length: 5256.0,                last time consumption/overall running time: 1330.5917s / 310458.7315 s
env0_first_0:                 episode reward: 10.1000,                 loss: 0.0041
env0_second_0:                 episode reward: -10.1000,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 6180.1,                last time consumption/overall running time: 1569.8272s / 312028.5587 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0049
env0_second_0:                 episode reward: 1.6000,                 loss: nan
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 5108.05,                last time consumption/overall running time: 1295.8123s / 313324.3710 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0060
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 6078.5,                last time consumption/overall running time: 1541.8054s / 314866.1764 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0059
env0_second_0:                 episode reward: 8.7000,                 loss: nan
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 5223.2,                last time consumption/overall running time: 1324.9699s / 316191.1464 s
env0_first_0:                 episode reward: 19.0000,                 loss: 0.0055
env0_second_0:                 episode reward: -19.0000,                 loss: nan
env1_first_0:                 episode reward: 15.6500,                 loss: nan
env1_second_0:                 episode reward: -15.6500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 7109.0,                last time consumption/overall running time: 5076.9799s / 321268.1263 s
env0_first_0:                 episode reward: 23.2500,                 loss: nan
env0_second_0:                 episode reward: -23.2500,                 loss: nan
env1_first_0:                 episode reward: 19.3000,                 loss: nan
env1_second_0:                 episode reward: -19.3000,                 loss: nan
Score delta: 64.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5903_0.
Episode: 5941/10000 (59.4100%),                 avg. length: 5612.25,                last time consumption/overall running time: 5279.9494s / 326548.0757 s
env0_first_0:                 episode reward: -14.7500,                 loss: nan
env0_second_0:                 episode reward: 14.7500,                 loss: nan
env1_first_0:                 episode reward: -19.1500,                 loss: nan
env1_second_0:                 episode reward: 19.1500,                 loss: nan
Score delta: 52.6, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/5928_1.
Episode: 5961/10000 (59.6100%),                 avg. length: 7537.15,                last time consumption/overall running time: 1895.3916s / 328443.4673 s
env0_first_0:                 episode reward: -72.9000,                 loss: 0.0075
env0_second_0:                 episode reward: 72.9000,                 loss: nan
env1_first_0:                 episode reward: -81.2500,                 loss: nan
env1_second_0:                 episode reward: 81.2500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 6194.8,                last time consumption/overall running time: 1558.9967s / 330002.4640 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0063
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 6554.9,                last time consumption/overall running time: 1656.7260s / 331659.1900 s
env0_first_0:                 episode reward: 7.2000,                 loss: 0.0051
env0_second_0:                 episode reward: -7.2000,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 6026.8,                last time consumption/overall running time: 1517.3435s / 333176.5334 s
env0_first_0:                 episode reward: -19.7000,                 loss: 0.0063
env0_second_0:                 episode reward: 19.7000,                 loss: nan
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 5207.25,                last time consumption/overall running time: 1313.4404s / 334489.9738 s
env0_first_0:                 episode reward: 4.6000,                 loss: 0.0054
env0_second_0:                 episode reward: -4.6000,                 loss: nan
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 4219.0,                last time consumption/overall running time: 1058.5692s / 335548.5431 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0053
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 3811.8,                last time consumption/overall running time: 958.6430s / 336507.1861 s
env0_first_0:                 episode reward: 14.2000,                 loss: 0.0047
env0_second_0:                 episode reward: -14.2000,                 loss: nan
env1_first_0:                 episode reward: 11.9000,                 loss: nan
env1_second_0:                 episode reward: -11.9000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 3612.3,                last time consumption/overall running time: 909.9657s / 337417.1518 s
env0_first_0:                 episode reward: 7.1000,                 loss: 0.0045
env0_second_0:                 episode reward: -7.1000,                 loss: nan
env1_first_0:                 episode reward: 11.6500,                 loss: nan
env1_second_0:                 episode reward: -11.6500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 4875.0,                last time consumption/overall running time: 3912.0573s / 341329.2091 s
env0_first_0:                 episode reward: 23.1500,                 loss: nan
env0_second_0:                 episode reward: -23.1500,                 loss: nan
env1_first_0:                 episode reward: 13.2500,                 loss: nan
env1_second_0:                 episode reward: -13.2500,                 loss: nan
Score delta: 52.6, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/6111_0.
Episode: 6141/10000 (61.4100%),                 avg. length: 5579.6,                last time consumption/overall running time: 1397.9980s / 342727.2071 s
env0_first_0:                 episode reward: 3.4500,                 loss: nan
env0_second_0:                 episode reward: -3.4500,                 loss: 0.0040
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 5011.3,                last time consumption/overall running time: 1257.1613s / 343984.3684 s
env0_first_0:                 episode reward: 6.2000,                 loss: nan
env0_second_0:                 episode reward: -6.2000,                 loss: 0.0046
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 6579.15,                last time consumption/overall running time: 1650.6559s / 345635.0243 s
env0_first_0:                 episode reward: 3.3000,                 loss: nan
env0_second_0:                 episode reward: -3.3000,                 loss: 0.0052
env1_first_0:                 episode reward: 7.9500,                 loss: nan
env1_second_0:                 episode reward: -7.9500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 4504.1,                last time consumption/overall running time: 1127.3897s / 346762.4140 s
env0_first_0:                 episode reward: -3.9500,                 loss: nan
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0058
env1_first_0:                 episode reward: 8.8500,                 loss: nan
env1_second_0:                 episode reward: -8.8500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 3143.7,                last time consumption/overall running time: 4775.4732s / 351537.8873 s
env0_first_0:                 episode reward: -34.3500,                 loss: nan
env0_second_0:                 episode reward: 34.3500,                 loss: nan
env1_first_0:                 episode reward: -40.0500,                 loss: nan
env1_second_0:                 episode reward: 40.0500,                 loss: nan
Score delta: 63.4, save the model to .//data/model/20220115_0159/pettingzoo_tennis_v2_nxdo2/6205_1.
Episode: 6241/10000 (62.4100%),                 avg. length: 5012.5,                last time consumption/overall running time: 1163.5148s / 352701.4021 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0046
env0_second_0:                 episode reward: 7.7000,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 7133.1,                last time consumption/overall running time: 1651.3989s / 354352.8010 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0044
env0_second_0:                 episode reward: 12.9500,                 loss: nan
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 7921.95,                last time consumption/overall running time: 1834.7566s / 356187.5576 s