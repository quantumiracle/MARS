pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'Tanh', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'Tanh', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220124_1038/slimevolley_SlimeVolley-v0_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220124_1038/slimevolley_SlimeVolley-v0_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 493.0,                last time consumption/overall running time: 3.9859s / 3.9859 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0261
env0_second_0:                 episode reward: 1.0000,                 loss: -0.0301
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 629.4,                last time consumption/overall running time: 65.5498s / 69.5356 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0725
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0860
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 607.85,                last time consumption/overall running time: 70.9990s / 140.5347 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2010
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2020
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 551.85,                last time consumption/overall running time: 75.2059s / 215.7406 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.1596
env0_second_0:                 episode reward: -0.8500,                 loss: 0.1537
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 591.85,                last time consumption/overall running time: 79.9993s / 295.7400 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2207
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2020
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 597.6,                last time consumption/overall running time: 80.7899s / 376.5298 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.1680
env0_second_0:                 episode reward: -1.5500,                 loss: 0.1677
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 618.6,                last time consumption/overall running time: 84.5021s / 461.0319 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.1803
env0_second_0:                 episode reward: -0.8000,                 loss: 0.1788
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 543.1,                last time consumption/overall running time: 73.3291s / 534.3610 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.1843
env0_second_0:                 episode reward: -1.5500,                 loss: 0.1909
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 561.45,                last time consumption/overall running time: 77.8312s / 612.1922 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1917
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1908
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 549.85,                last time consumption/overall running time: 75.9683s / 688.1605 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.1908
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1872
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 603.05,                last time consumption/overall running time: 80.6538s / 768.8143 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.1718
env0_second_0:                 episode reward: -0.3500,                 loss: 0.1683
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 605.95,                last time consumption/overall running time: 81.9721s / 850.7864 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.1774
env0_second_0:                 episode reward: -0.3500,                 loss: 0.1700
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 561.8,                last time consumption/overall running time: 76.1084s / 926.8947 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.1997
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1968
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 572.2,                last time consumption/overall running time: 76.4236s / 1003.3183 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.1990
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1867
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 578.65,                last time consumption/overall running time: 77.7092s / 1081.0275 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2189
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2245
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 532.8,                last time consumption/overall running time: 74.6262s / 1155.6537 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2082
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2040
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 584.35,                last time consumption/overall running time: 79.2921s / 1234.9458 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2151
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2219
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 583.25,                last time consumption/overall running time: 81.0721s / 1316.0179 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.1882
env0_second_0:                 episode reward: -0.4000,                 loss: 0.1803
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 570.3,                last time consumption/overall running time: 78.3839s / 1394.4018 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.1954
env0_second_0:                 episode reward: -0.5500,                 loss: 0.1850
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 572.15,                last time consumption/overall running time: 79.8277s / 1474.2294 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2132
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2146
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 555.25,                last time consumption/overall running time: 78.3793s / 1552.6087 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2281
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2246
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 605.25,                last time consumption/overall running time: 82.9101s / 1635.5188 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2370
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2339
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 579.95,                last time consumption/overall running time: 79.8719s / 1715.3907 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2314
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2394
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 570.8,                last time consumption/overall running time: 80.4886s / 1795.8792 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2259
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2334
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 551.0,                last time consumption/overall running time: 78.5204s / 1874.3996 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2566
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2563
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 560.95,                last time consumption/overall running time: 78.0644s / 1952.4640 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2473
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2511
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 553.6,                last time consumption/overall running time: 77.2380s / 2029.7020 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2380
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2396
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 573.5,                last time consumption/overall running time: 78.5151s / 2108.2171 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2453
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2401
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 591.9,                last time consumption/overall running time: 82.0739s / 2190.2909 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2424
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2402
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 596.3,                last time consumption/overall running time: 82.2413s / 2272.5322 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2471
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2443
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 564.85,                last time consumption/overall running time: 79.5863s / 2352.1186 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2450
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2444
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 595.9,                last time consumption/overall running time: 81.9865s / 2434.1051 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2779
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2719
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 534.4,                last time consumption/overall running time: 76.1673s / 2510.2724 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2633
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2615
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 561.75,                last time consumption/overall running time: 77.9965s / 2588.2689 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2600
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2624
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 566.9,                last time consumption/overall running time: 79.2519s / 2667.5208 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2505
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2493
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 572.25,                last time consumption/overall running time: 80.2508s / 2747.7716 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2797
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2697
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 573.4,                last time consumption/overall running time: 80.1684s / 2827.9400 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2475
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2387
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 561.65,                last time consumption/overall running time: 79.8110s / 2907.7510 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2479
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2464
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 574.25,                last time consumption/overall running time: 79.8536s / 2987.6046 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2568
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2508
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 540.5,                last time consumption/overall running time: 76.3032s / 3063.9078 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2617
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2521
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 546.9,                last time consumption/overall running time: 77.1826s / 3141.0904 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2472
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2448
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 554.85,                last time consumption/overall running time: 78.5779s / 3219.6682 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2668
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2807
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 543.35,                last time consumption/overall running time: 76.7401s / 3296.4084 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2585
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2647
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 585.7,                last time consumption/overall running time: 82.3566s / 3378.7649 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2394
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2463
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 599.6,                last time consumption/overall running time: 83.0165s / 3461.7814 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2707
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2672
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 592.7,                last time consumption/overall running time: 81.6419s / 3543.4233 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2518
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2518
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 611.6,                last time consumption/overall running time: 85.3407s / 3628.7640 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2508
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2547
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 575.1,                last time consumption/overall running time: 81.1963s / 3709.9603 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2530
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2586
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 596.5,                last time consumption/overall running time: 82.1450s / 3792.1053 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2519
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2455
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 573.9,                last time consumption/overall running time: 79.8486s / 3871.9539 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2554
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2573
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 555.2,                last time consumption/overall running time: 78.1388s / 3950.0927 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2448
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2513
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 550.4,                last time consumption/overall running time: 77.7880s / 4027.8807 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2625
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2671
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 576.6,                last time consumption/overall running time: 79.8795s / 4107.7602 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2421
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2438
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 594.5,                last time consumption/overall running time: 83.0744s / 4190.8345 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2440
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2529
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 577.95,                last time consumption/overall running time: 81.0680s / 4271.9025 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2447
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2613
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 566.35,                last time consumption/overall running time: 78.3326s / 4350.2351 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2481
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2553
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 540.8,                last time consumption/overall running time: 77.5364s / 4427.7716 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2464
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2503
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 525.5,                last time consumption/overall running time: 74.0172s / 4501.7888 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2580
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2630
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 570.55,                last time consumption/overall running time: 79.7903s / 4581.5791 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2725
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2689
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 573.7,                last time consumption/overall running time: 81.1730s / 4662.7521 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2527
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2601
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 590.25,                last time consumption/overall running time: 81.9335s / 4744.6856 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2756
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2801
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 561.0,                last time consumption/overall running time: 79.0871s / 4823.7728 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2644
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2716
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 592.75,                last time consumption/overall running time: 82.5445s / 4906.3173 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.2489
env0_second_0:                 episode reward: -1.3000,                 loss: 0.2559
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 572.85,                last time consumption/overall running time: 80.5118s / 4986.8291 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2532
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2484
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 571.05,                last time consumption/overall running time: 79.9415s / 5066.7705 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2391
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2356
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 563.5,                last time consumption/overall running time: 77.9800s / 5144.7505 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2791
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2731
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 594.15,                last time consumption/overall running time: 81.1242s / 5225.8747 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2477
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2368
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 547.15,                last time consumption/overall running time: 77.1457s / 5303.0204 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2584
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2431
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 586.5,                last time consumption/overall running time: 81.3722s / 5384.3927 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2572
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2534
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 614.4,                last time consumption/overall running time: 83.4503s / 5467.8430 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2615
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2567
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 593.45,                last time consumption/overall running time: 82.9848s / 5550.8278 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2515
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2390
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 589.15,                last time consumption/overall running time: 81.8448s / 5632.6726 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2453
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2436
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 564.25,                last time consumption/overall running time: 78.1004s / 5710.7730 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2583
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2547
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 561.25,                last time consumption/overall running time: 78.5526s / 5789.3256 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2640
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2614
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 559.3,                last time consumption/overall running time: 78.7568s / 5868.0824 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2726
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2661
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 592.65,                last time consumption/overall running time: 82.0613s / 5950.1436 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2607
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2657
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 563.95,                last time consumption/overall running time: 79.7351s / 6029.8788 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2664
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2599
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 562.5,                last time consumption/overall running time: 79.6016s / 6109.4803 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2551
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2493
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 566.75,                last time consumption/overall running time: 79.0002s / 6188.4805 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2181
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2186
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 601.8,                last time consumption/overall running time: 82.2709s / 6270.7514 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2440
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2336
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 561.15,                last time consumption/overall running time: 76.9396s / 6347.6910 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2451
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2443
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 550.75,                last time consumption/overall running time: 75.2885s / 6422.9795 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2675
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2672
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 524.15,                last time consumption/overall running time: 74.1804s / 6497.1599 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2724
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2805
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 560.85,                last time consumption/overall running time: 78.1930s / 6575.3530 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2481
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2484
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 600.55,                last time consumption/overall running time: 81.9806s / 6657.3336 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2658
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2562
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 522.45,                last time consumption/overall running time: 74.2708s / 6731.6044 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2515
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2544
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 613.0,                last time consumption/overall running time: 83.7744s / 6815.3788 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2506
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2502
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 571.65,                last time consumption/overall running time: 80.0487s / 6895.4275 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2530
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2537
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 564.5,                last time consumption/overall running time: 79.4802s / 6974.9077 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2598
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2528
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 567.1,                last time consumption/overall running time: 79.7801s / 7054.6879 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2659
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2632
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 581.8,                last time consumption/overall running time: 81.4630s / 7136.1509 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2534
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2595
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 537.4,                last time consumption/overall running time: 76.6601s / 7212.8110 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2536
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2501
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 579.6,                last time consumption/overall running time: 81.3271s / 7294.1381 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2577
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2612
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 556.2,                last time consumption/overall running time: 78.0571s / 7372.1952 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2581
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2583
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 598.65,                last time consumption/overall running time: 82.5295s / 7454.7247 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2813
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2892
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 574.85,                last time consumption/overall running time: 80.3843s / 7535.1090 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2410
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2365
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 565.5,                last time consumption/overall running time: 79.2042s / 7614.3132 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2541
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2582
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 565.2,                last time consumption/overall running time: 78.2726s / 7692.5858 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2860
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2770
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 548.7,                last time consumption/overall running time: 77.5846s / 7770.1704 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2641
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2681
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 552.2,                last time consumption/overall running time: 77.8536s / 7848.0240 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2679
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2715
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 580.05,                last time consumption/overall running time: 80.6882s / 7928.7122 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2447
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2498
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 597.85,                last time consumption/overall running time: 83.0135s / 8011.7257 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2599
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2476
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 587.35,                last time consumption/overall running time: 82.7324s / 8094.4581 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2544
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2503
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 614.9,                last time consumption/overall running time: 84.2494s / 8178.7075 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2575
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2539
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 566.55,                last time consumption/overall running time: 79.9911s / 8258.6986 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2611
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2527
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 591.35,                last time consumption/overall running time: 81.5626s / 8340.2612 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2532
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2507
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 591.95,                last time consumption/overall running time: 82.0351s / 8422.2963 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2691
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2670
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 540.3,                last time consumption/overall running time: 76.4701s / 8498.7664 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2620
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2543
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 554.75,                last time consumption/overall running time: 77.6888s / 8576.4552 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2677
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2684
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 580.65,                last time consumption/overall running time: 81.1289s / 8657.5840 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2618
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2537
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 561.3,                last time consumption/overall running time: 79.5475s / 8737.1315 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2673
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2539
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 597.9,                last time consumption/overall running time: 83.9329s / 8821.0644 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2632
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2612
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 571.2,                last time consumption/overall running time: 79.4665s / 8900.5309 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2584
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2491
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 567.1,                last time consumption/overall running time: 79.8717s / 8980.4027 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2639
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2476
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 593.75,                last time consumption/overall running time: 81.7692s / 9062.1719 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2361
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2398
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 578.05,                last time consumption/overall running time: 80.5054s / 9142.6772 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2443
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2427
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 562.65,                last time consumption/overall running time: 78.3513s / 9221.0285 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2677
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2546
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 570.65,                last time consumption/overall running time: 80.9596s / 9301.9880 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2430
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2319
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 580.75,                last time consumption/overall running time: 79.8988s / 9381.8868 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2456
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2394
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 575.45,                last time consumption/overall running time: 80.5072s / 9462.3940 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2555
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2659
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 566.5,                last time consumption/overall running time: 78.7883s / 9541.1823 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2429
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2403
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 598.65,                last time consumption/overall running time: 83.6260s / 9624.8083 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2731
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2642
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 592.7,                last time consumption/overall running time: 81.7017s / 9706.5100 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2544
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2522
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 530.95,                last time consumption/overall running time: 74.7197s / 9781.2298 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2498
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2535
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 567.15,                last time consumption/overall running time: 80.1177s / 9861.3475 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2570
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2571
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 530.65,                last time consumption/overall running time: 75.7050s / 9937.0525 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2616
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2495
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 586.25,                last time consumption/overall running time: 81.3695s / 10018.4220 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2690
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2781
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 551.5,                last time consumption/overall running time: 75.9527s / 10094.3747 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2633
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2628
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 572.5,                last time consumption/overall running time: 79.2938s / 10173.6686 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2616
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2601
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 566.3,                last time consumption/overall running time: 79.2642s / 10252.9327 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2830
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2835
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 606.55,                last time consumption/overall running time: 83.6091s / 10336.5419 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2729
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2633
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 549.6,                last time consumption/overall running time: 77.4715s / 10414.0134 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2678
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2682
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 584.0,                last time consumption/overall running time: 81.3913s / 10495.4047 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2717
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2780
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 573.05,                last time consumption/overall running time: 80.1683s / 10575.5730 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2831
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2844
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 594.7,                last time consumption/overall running time: 82.0521s / 10657.6251 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2603
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2531
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 571.3,                last time consumption/overall running time: 79.2917s / 10736.9168 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2685
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2654
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 577.85,                last time consumption/overall running time: 80.4315s / 10817.3483 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2436
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2465
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 564.25,                last time consumption/overall running time: 79.1214s / 10896.4697 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2689
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2626
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 573.85,                last time consumption/overall running time: 80.6761s / 10977.1458 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2799
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2830
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 544.9,                last time consumption/overall running time: 76.7295s / 11053.8752 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2825
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2797
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 547.45,                last time consumption/overall running time: 78.2376s / 11132.1128 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2552
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2470
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 535.5,                last time consumption/overall running time: 75.3579s / 11207.4707 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2776
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2774
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 573.7,                last time consumption/overall running time: 78.7408s / 11286.2115 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2754
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2739
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 535.3,                last time consumption/overall running time: 76.4613s / 11362.6729 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2554
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2667
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 570.2,                last time consumption/overall running time: 80.5484s / 11443.2212 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2474
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2470
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 569.0,                last time consumption/overall running time: 80.3064s / 11523.5277 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2549
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2597
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 592.15,                last time consumption/overall running time: 81.9082s / 11605.4359 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2716
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2779
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 546.2,                last time consumption/overall running time: 77.1461s / 11682.5820 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2589
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2644
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 587.35,                last time consumption/overall running time: 81.4774s / 11764.0594 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2758
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2754
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 566.0,                last time consumption/overall running time: 78.8339s / 11842.8933 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2507
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2528
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 557.9,                last time consumption/overall running time: 77.6971s / 11920.5904 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2560
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2519
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 560.4,                last time consumption/overall running time: 78.3302s / 11998.9206 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2746
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2738
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 536.35,                last time consumption/overall running time: 75.5732s / 12074.4938 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2539
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2484
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 571.0,                last time consumption/overall running time: 78.9282s / 12153.4220 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2529
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2463
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 557.05,                last time consumption/overall running time: 77.8738s / 12231.2958 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2636
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2590
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 576.15,                last time consumption/overall running time: 80.4577s / 12311.7535 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2552
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2581
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 528.0,                last time consumption/overall running time: 74.1490s / 12385.9026 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2405
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2451
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 565.8,                last time consumption/overall running time: 79.3926s / 12465.2951 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2700
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2717
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 580.5,                last time consumption/overall running time: 79.7573s / 12545.0525 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2381
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2371
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 554.9,                last time consumption/overall running time: 78.5186s / 12623.5710 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2467
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2463
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 567.6,                last time consumption/overall running time: 79.3368s / 12702.9079 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2470
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2531
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 536.45,                last time consumption/overall running time: 75.0901s / 12777.9979 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2480
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2491
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 590.85,                last time consumption/overall running time: 81.7985s / 12859.7964 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2722
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2839
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 549.7,                last time consumption/overall running time: 77.5532s / 12937.3496 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2403
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2419
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 560.75,                last time consumption/overall running time: 78.9213s / 13016.2710 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2639
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2743
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 553.65,                last time consumption/overall running time: 78.3384s / 13094.6094 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2534
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2462
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 582.65,                last time consumption/overall running time: 80.7152s / 13175.3246 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2667
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2731
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 564.0,                last time consumption/overall running time: 79.2270s / 13254.5515 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2437
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2427
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 560.9,                last time consumption/overall running time: 79.8363s / 13334.3878 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2611
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2585
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 559.3,                last time consumption/overall running time: 77.9936s / 13412.3814 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2607
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2582
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 590.2,                last time consumption/overall running time: 81.7736s / 13494.1550 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2788
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2868
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 583.15,                last time consumption/overall running time: 81.5229s / 13575.6778 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2586
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2584
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 552.3,                last time consumption/overall running time: 78.0936s / 13653.7715 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2657
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2611
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 576.9,                last time consumption/overall running time: 79.9851s / 13733.7565 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2778
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2732
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 575.7,                last time consumption/overall running time: 81.3149s / 13815.0715 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2935
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2851
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 589.15,                last time consumption/overall running time: 82.0282s / 13897.0997 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2609
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2547
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 556.2,                last time consumption/overall running time: 78.3790s / 13975.4787 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2767
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2741
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 572.45,                last time consumption/overall running time: 79.9847s / 14055.4633 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2474
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2338
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 558.8,                last time consumption/overall running time: 76.6863s / 14132.1497 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2841
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2800
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 599.25,                last time consumption/overall running time: 82.7753s / 14214.9250 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2647
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2585
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 568.8,                last time consumption/overall running time: 79.3773s / 14294.3022 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2563
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2541
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 541.0,                last time consumption/overall running time: 76.0391s / 14370.3413 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2723
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2721
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 572.0,                last time consumption/overall running time: 79.4845s / 14449.8257 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2449
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2526
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 545.85,                last time consumption/overall running time: 77.0875s / 14526.9133 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2557
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2598
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 596.95,                last time consumption/overall running time: 82.7092s / 14609.6225 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2656
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2619
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 576.85,                last time consumption/overall running time: 81.0512s / 14690.6736 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2681
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2610
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 509.95,                last time consumption/overall running time: 71.7226s / 14762.3962 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2500
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2580
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 547.85,                last time consumption/overall running time: 75.4689s / 14837.8651 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2510
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2491
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 547.1,                last time consumption/overall running time: 76.1817s / 14914.0468 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2675
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2659
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 593.45,                last time consumption/overall running time: 81.5428s / 14995.5896 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2903
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2953
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 522.65,                last time consumption/overall running time: 74.8308s / 15070.4204 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2691
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2732
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 563.55,                last time consumption/overall running time: 78.9863s / 15149.4066 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2629
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2638
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 534.05,                last time consumption/overall running time: 76.3205s / 15225.7271 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2556
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2448
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 559.45,                last time consumption/overall running time: 77.5296s / 15303.2567 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2582
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2530
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 558.65,                last time consumption/overall running time: 77.5914s / 15380.8480 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2659
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2662
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 569.4,                last time consumption/overall running time: 79.7063s / 15460.5543 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2678
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2656
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 539.15,                last time consumption/overall running time: 75.4622s / 15536.0166 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2592
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2605
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 583.65,                last time consumption/overall running time: 81.2640s / 15617.2805 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2909
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2832
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 601.85,                last time consumption/overall running time: 83.1456s / 15700.4261 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2672
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2620
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 572.35,                last time consumption/overall running time: 79.0112s / 15779.4373 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2922
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2991
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 567.2,                last time consumption/overall running time: 79.1427s / 15858.5800 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2874
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2877
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 591.55,                last time consumption/overall running time: 81.7633s / 15940.3433 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2716
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2592
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 558.25,                last time consumption/overall running time: 80.9079s / 16021.2511 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2797
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2841
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 573.1,                last time consumption/overall running time: 81.4567s / 16102.7079 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2685
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2741
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 565.4,                last time consumption/overall running time: 78.8347s / 16181.5426 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2890
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2891
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 588.9,                last time consumption/overall running time: 82.7620s / 16264.3046 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2717
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2665
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 564.9,                last time consumption/overall running time: 80.0188s / 16344.3234 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2652
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2633
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 552.35,                last time consumption/overall running time: 78.1499s / 16422.4733 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2482
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2417
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 600.25,                last time consumption/overall running time: 83.5992s / 16506.0725 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2660
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2719
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 560.95,                last time consumption/overall running time: 78.5744s / 16584.6469 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2612
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2578
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 602.45,                last time consumption/overall running time: 83.4056s / 16668.0525 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2794
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2704
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 564.6,                last time consumption/overall running time: 79.1097s / 16747.1622 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2813
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2695
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 558.25,                last time consumption/overall running time: 78.7547s / 16825.9168 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2823
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2860
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 533.85,                last time consumption/overall running time: 75.8809s / 16901.7978 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2429
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2522
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 571.35,                last time consumption/overall running time: 81.0497s / 16982.8475 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2679
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2658
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 557.45,                last time consumption/overall running time: 78.3594s / 17061.2069 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2765
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2838
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 591.5,                last time consumption/overall running time: 82.0699s / 17143.2768 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2874
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2813
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 550.1,                last time consumption/overall running time: 78.4862s / 17221.7629 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2552
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2564
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 570.5,                last time consumption/overall running time: 79.2565s / 17301.0194 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2841
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2766
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 516.95,                last time consumption/overall running time: 74.9593s / 17375.9787 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2705
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2690
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 578.25,                last time consumption/overall running time: 80.0376s / 17456.0163 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2771
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2790
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 568.3,                last time consumption/overall running time: 79.2221s / 17535.2384 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2681
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2695
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 628.4,                last time consumption/overall running time: 86.8570s / 17622.0954 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2670
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2597
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 574.9,                last time consumption/overall running time: 80.8937s / 17702.9891 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2626
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2662
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 559.8,                last time consumption/overall running time: 79.2003s / 17782.1894 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2734
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2627
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 559.15,                last time consumption/overall running time: 78.7025s / 17860.8919 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2564
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2609
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 575.5,                last time consumption/overall running time: 80.5434s / 17941.4353 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2824
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2749
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 541.0,                last time consumption/overall running time: 76.7005s / 18018.1358 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2453
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2428
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 534.75,                last time consumption/overall running time: 75.0832s / 18093.2190 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2748
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2594
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 576.05,                last time consumption/overall running time: 79.9084s / 18173.1274 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2744
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2701
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 543.15,                last time consumption/overall running time: 76.9547s / 18250.0821 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2582
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2593
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 574.75,                last time consumption/overall running time: 79.1814s / 18329.2635 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2804
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2761
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 548.8,                last time consumption/overall running time: 77.3147s / 18406.5782 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2713
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2766
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 550.6,                last time consumption/overall running time: 77.4071s / 18483.9853 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2787
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2724
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 568.9,                last time consumption/overall running time: 78.4979s / 18562.4832 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2799
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2790
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 556.65,                last time consumption/overall running time: 79.2019s / 18641.6852 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2554
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2458
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 587.65,                last time consumption/overall running time: 81.4063s / 18723.0914 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2764
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2684
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 556.9,                last time consumption/overall running time: 79.3387s / 18802.4302 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2639
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2641
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 590.9,                last time consumption/overall running time: 81.6097s / 18884.0399 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2804
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2700
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 549.8,                last time consumption/overall running time: 77.5434s / 18961.5833 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2747
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2785
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 578.15,                last time consumption/overall running time: 80.7631s / 19042.3464 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2620
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2553
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 575.65,                last time consumption/overall running time: 81.3024s / 19123.6487 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2733
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2712
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 563.75,                last time consumption/overall running time: 79.1222s / 19202.7709 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2889
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2879
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 607.4,                last time consumption/overall running time: 83.5107s / 19286.2816 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2781
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2760
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 601.5,                last time consumption/overall running time: 82.5190s / 19368.8006 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2749
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2659
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 596.3,                last time consumption/overall running time: 82.1452s / 19450.9458 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2848
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2795
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 525.4,                last time consumption/overall running time: 73.9263s / 19524.8721 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2434
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2452
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 578.45,                last time consumption/overall running time: 80.9462s / 19605.8183 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2732
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2703
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 569.65,                last time consumption/overall running time: 79.0034s / 19684.8217 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2912
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2820
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 604.65,                last time consumption/overall running time: 83.0400s / 19767.8617 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2721
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2649
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 598.15,                last time consumption/overall running time: 82.3195s / 19850.1812 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2705
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2702
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 553.6,                last time consumption/overall running time: 78.4840s / 19928.6652 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2657
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2611
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 558.85,                last time consumption/overall running time: 78.4246s / 20007.0899 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2653
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2708
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 531.5,                last time consumption/overall running time: 74.3370s / 20081.4269 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2456
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2349
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 518.5,                last time consumption/overall running time: 72.7486s / 20154.1755 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2862
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2792
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 580.85,                last time consumption/overall running time: 79.5662s / 20233.7417 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2746
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2679
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 541.2,                last time consumption/overall running time: 76.1220s / 20309.8637 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2723
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2798
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 591.7,                last time consumption/overall running time: 81.8871s / 20391.7509 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2834
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2908
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 581.0,                last time consumption/overall running time: 81.5327s / 20473.2835 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2660
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2675
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 539.85,                last time consumption/overall running time: 76.2345s / 20549.5181 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2759
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2750
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 587.95,                last time consumption/overall running time: 81.1566s / 20630.6746 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2654
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2678
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 536.7,                last time consumption/overall running time: 75.8920s / 20706.5666 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2743
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2754
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 574.75,                last time consumption/overall running time: 78.7825s / 20785.3491 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2761
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2789
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 546.35,                last time consumption/overall running time: 76.8047s / 20862.1539 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2735
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2762
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 583.75,                last time consumption/overall running time: 81.9544s / 20944.1083 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2909
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2888
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 564.15,                last time consumption/overall running time: 78.1109s / 21022.2191 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2926
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2939
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 551.55,                last time consumption/overall running time: 78.1575s / 21100.3766 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2907
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2827
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 598.4,                last time consumption/overall running time: 82.7727s / 21183.1493 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2760
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2689
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 570.9,                last time consumption/overall running time: 79.2159s / 21262.3651 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3000
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2961
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 531.1,                last time consumption/overall running time: 76.1448s / 21338.5099 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.2701
env0_second_0:                 episode reward: -1.3000,                 loss: 0.2705
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 581.5,                last time consumption/overall running time: 81.0794s / 21419.5893 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2784
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2758
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 611.85,                last time consumption/overall running time: 83.9519s / 21503.5412 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2658
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2566
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 558.05,                last time consumption/overall running time: 78.7912s / 21582.3324 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2628
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2704
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 552.25,                last time consumption/overall running time: 77.4827s / 21659.8152 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2508
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2529
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 522.75,                last time consumption/overall running time: 74.4493s / 21734.2645 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2664
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2707
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 545.55,                last time consumption/overall running time: 77.0214s / 21811.2859 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2591
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2538
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 550.95,                last time consumption/overall running time: 78.0147s / 21889.3006 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2670
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2720
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 518.5,                last time consumption/overall running time: 74.3076s / 21963.6081 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2454
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2448
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 567.25,                last time consumption/overall running time: 79.4891s / 22043.0972 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2797
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2728
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 576.3,                last time consumption/overall running time: 80.7128s / 22123.8100 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2637
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2697
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 566.1,                last time consumption/overall running time: 79.6604s / 22203.4703 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.2696
env0_second_0:                 episode reward: -1.3000,                 loss: 0.2720
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 562.9,                last time consumption/overall running time: 78.7917s / 22282.2620 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2606
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2629
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 590.5,                last time consumption/overall running time: 80.5199s / 22362.7819 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2621
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2550
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 603.1,                last time consumption/overall running time: 83.4373s / 22446.2192 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2732
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2814
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 571.9,                last time consumption/overall running time: 80.0760s / 22526.2951 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2507
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2560
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 566.4,                last time consumption/overall running time: 79.5078s / 22605.8029 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2738
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2736
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 572.15,                last time consumption/overall running time: 79.4941s / 22685.2971 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2692
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2694
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 543.6,                last time consumption/overall running time: 75.9433s / 22761.2404 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2608
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2541
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 584.75,                last time consumption/overall running time: 80.8167s / 22842.0571 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2723
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2721
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 598.1,                last time consumption/overall running time: 82.6580s / 22924.7151 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2555
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2644
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 573.9,                last time consumption/overall running time: 79.7223s / 23004.4374 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2752
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2847
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 592.9,                last time consumption/overall running time: 82.4351s / 23086.8725 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2658
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2610
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 555.45,                last time consumption/overall running time: 78.2052s / 23165.0777 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2788
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2787
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 587.85,                last time consumption/overall running time: 81.7993s / 23246.8770 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2707
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2743
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 530.5,                last time consumption/overall running time: 75.9465s / 23322.8235 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2716
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2708
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 601.35,                last time consumption/overall running time: 83.1492s / 23405.9727 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2733
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2756
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 561.15,                last time consumption/overall running time: 78.3335s / 23484.3061 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2600
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2584
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 600.15,                last time consumption/overall running time: 80.5162s / 23564.8224 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2638
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2733
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 596.8,                last time consumption/overall running time: 83.2032s / 23648.0256 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2642
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2618
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 539.35,                last time consumption/overall running time: 75.9318s / 23723.9573 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2621
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2629
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 533.65,                last time consumption/overall running time: 76.5055s / 23800.4628 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2758
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2817
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 530.95,                last time consumption/overall running time: 73.9101s / 23874.3730 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2709
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2741
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 579.4,                last time consumption/overall running time: 81.2309s / 23955.6038 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2855
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2812
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 525.85,                last time consumption/overall running time: 75.4747s / 24031.0785 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2622
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2641
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 583.45,                last time consumption/overall running time: 81.9593s / 24113.0377 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2542
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2579
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 583.2,                last time consumption/overall running time: 80.8577s / 24193.8954 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2739
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2703
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 529.3,                last time consumption/overall running time: 74.0773s / 24267.9727 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2772
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2743
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 549.25,                last time consumption/overall running time: 77.6267s / 24345.5994 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2766
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2830
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 582.05,                last time consumption/overall running time: 81.5142s / 24427.1136 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2574
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2574
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 547.65,                last time consumption/overall running time: 76.9149s / 24504.0285 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2558
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2575
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 583.25,                last time consumption/overall running time: 81.1227s / 24585.1512 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2785
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2946
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 547.4,                last time consumption/overall running time: 77.8233s / 24662.9745 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2729
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2886
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 572.75,                last time consumption/overall running time: 80.6465s / 24743.6210 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2554
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2644
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 559.4,                last time consumption/overall running time: 78.5042s / 24822.1252 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2758
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2791
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 535.8,                last time consumption/overall running time: 75.3788s / 24897.5040 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2663
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2602
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 533.7,                last time consumption/overall running time: 75.8599s / 24973.3639 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2618
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2591
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 576.85,                last time consumption/overall running time: 80.7309s / 25054.0948 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2926
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2971
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 546.0,                last time consumption/overall running time: 76.4918s / 25130.5867 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2598
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2510
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 564.6,                last time consumption/overall running time: 79.4113s / 25209.9980 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2664
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2720
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 596.6,                last time consumption/overall running time: 82.2770s / 25292.2749 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2617
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2690
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 592.15,                last time consumption/overall running time: 80.6669s / 25372.9418 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2748
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2736
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 580.5,                last time consumption/overall running time: 81.2718s / 25454.2136 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2559
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2582
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 560.9,                last time consumption/overall running time: 78.9940s / 25533.2076 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2756
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2754
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 563.35,                last time consumption/overall running time: 78.3801s / 25611.5877 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2814
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2880
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 575.1,                last time consumption/overall running time: 79.1280s / 25690.7158 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2487
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2473
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 552.1,                last time consumption/overall running time: 76.7323s / 25767.4481 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2684
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2704
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 566.5,                last time consumption/overall running time: 78.5767s / 25846.0248 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.2543
env0_second_0:                 episode reward: 1.6500,                 loss: 0.2491
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 583.3,                last time consumption/overall running time: 82.2419s / 25928.2667 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2769
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2827
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 567.95,                last time consumption/overall running time: 79.0809s / 26007.3477 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2595
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2636
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 549.5,                last time consumption/overall running time: 76.6897s / 26084.0374 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2646
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2708
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 544.5,                last time consumption/overall running time: 76.1608s / 26160.1982 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2713
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2705
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 573.1,                last time consumption/overall running time: 80.0669s / 26240.2651 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2633
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2594
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 555.9,                last time consumption/overall running time: 78.2976s / 26318.5627 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2762
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2740
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 568.15,                last time consumption/overall running time: 80.5389s / 26399.1016 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2678
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2608
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 578.55,                last time consumption/overall running time: 81.4762s / 26480.5778 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2729
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2745
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 568.8,                last time consumption/overall running time: 79.6277s / 26560.2055 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2653
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2737
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 562.65,                last time consumption/overall running time: 78.4842s / 26638.6898 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2692
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2654
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 567.75,                last time consumption/overall running time: 79.9031s / 26718.5928 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2646
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2634
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 559.25,                last time consumption/overall running time: 78.4857s / 26797.0786 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2670
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2831
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 587.5,                last time consumption/overall running time: 81.5161s / 26878.5947 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2841
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2789
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 570.85,                last time consumption/overall running time: 79.2682s / 26957.8628 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2705
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2777
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 539.85,                last time consumption/overall running time: 76.5186s / 27034.3815 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2688
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2705
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 576.6,                last time consumption/overall running time: 79.8934s / 27114.2749 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2868
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2829
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 568.2,                last time consumption/overall running time: 80.0315s / 27194.3064 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2666
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2573
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 541.7,                last time consumption/overall running time: 76.7096s / 27271.0160 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2423
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2359
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 579.9,                last time consumption/overall running time: 80.7748s / 27351.7907 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2860
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2919
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 581.15,                last time consumption/overall running time: 81.4396s / 27433.2303 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2606
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2682
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 554.5,                last time consumption/overall running time: 78.9053s / 27512.1356 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2676
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2767
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 609.65,                last time consumption/overall running time: 84.1171s / 27596.2527 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2715
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2807
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 546.9,                last time consumption/overall running time: 76.7253s / 27672.9780 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2707
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2748
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 578.95,                last time consumption/overall running time: 81.4687s / 27754.4466 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2528
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2563
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 542.35,                last time consumption/overall running time: 77.6420s / 27832.0887 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2717
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2738
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 564.15,                last time consumption/overall running time: 79.4486s / 27911.5373 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2947
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2923
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 546.25,                last time consumption/overall running time: 75.8691s / 27987.4063 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2562
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2540
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 609.3,                last time consumption/overall running time: 83.6866s / 28071.0929 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2845
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2848
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 594.3,                last time consumption/overall running time: 82.5704s / 28153.6634 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2678
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2655
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 572.2,                last time consumption/overall running time: 79.4484s / 28233.1118 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2853
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2826
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 581.15,                last time consumption/overall running time: 80.5501s / 28313.6618 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2638
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2609
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 558.15,                last time consumption/overall running time: 78.6480s / 28392.3098 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2810
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2929
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 583.95,                last time consumption/overall running time: 81.6732s / 28473.9830 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2717
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2718
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 600.9,                last time consumption/overall running time: 83.5829s / 28557.5659 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2623
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2679
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 586.95,                last time consumption/overall running time: 82.4695s / 28640.0354 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2543
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2518
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 559.6,                last time consumption/overall running time: 78.9206s / 28718.9561 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2499
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2499
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 600.1,                last time consumption/overall running time: 81.5826s / 28800.5386 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2801
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2732
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 604.7,                last time consumption/overall running time: 83.6942s / 28884.2328 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2601
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2575
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 530.6,                last time consumption/overall running time: 74.4505s / 28958.6833 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2586
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2603
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 594.4,                last time consumption/overall running time: 82.7491s / 29041.4323 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2735
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2796
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 547.6,                last time consumption/overall running time: 76.4542s / 29117.8866 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2642
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2586
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 561.4,                last time consumption/overall running time: 78.3677s / 29196.2542 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2943
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2947
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 568.6,                last time consumption/overall running time: 79.9204s / 29276.1746 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2864
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2881
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 565.3,                last time consumption/overall running time: 79.3302s / 29355.5048 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2684
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2729
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 557.3,                last time consumption/overall running time: 78.0687s / 29433.5736 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2943
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2980
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 579.75,                last time consumption/overall running time: 82.0301s / 29515.6037 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2651
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2681
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 532.3,                last time consumption/overall running time: 75.5287s / 29591.1323 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2729
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2752
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 528.0,                last time consumption/overall running time: 75.1287s / 29666.2611 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2582
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2586
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 544.3,                last time consumption/overall running time: 77.3173s / 29743.5784 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2674
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2654
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 582.45,                last time consumption/overall running time: 80.3394s / 29823.9178 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2705
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2707
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 545.85,                last time consumption/overall running time: 78.1162s / 29902.0340 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2836
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2824
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 576.45,                last time consumption/overall running time: 80.7637s / 29982.7977 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2589
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2510
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 565.3,                last time consumption/overall running time: 78.8942s / 30061.6919 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2787
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2841
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 556.85,                last time consumption/overall running time: 77.8345s / 30139.5263 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2793
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2857
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 553.65,                last time consumption/overall running time: 78.9921s / 30218.5184 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2687
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2809
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 544.2,                last time consumption/overall running time: 77.0111s / 30295.5296 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2900
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2971
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 558.25,                last time consumption/overall running time: 78.4018s / 30373.9314 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2778
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2773
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 585.65,                last time consumption/overall running time: 82.1544s / 30456.0858 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2944
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2978
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 577.4,                last time consumption/overall running time: 80.6594s / 30536.7451 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2757
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2715
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 540.55,                last time consumption/overall running time: 76.1491s / 30612.8942 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2915
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2963
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 601.95,                last time consumption/overall running time: 84.1907s / 30697.0849 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2794
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2820
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 589.35,                last time consumption/overall running time: 80.1810s / 30777.2659 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2771
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2755
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 543.7,                last time consumption/overall running time: 76.0205s / 30853.2864 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2797
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2894
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 558.25,                last time consumption/overall running time: 78.8797s / 30932.1661 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2940
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2981
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 576.95,                last time consumption/overall running time: 80.3912s / 31012.5573 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2721
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2783
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 584.25,                last time consumption/overall running time: 82.2877s / 31094.8450 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2569
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2594
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 573.3,                last time consumption/overall running time: 80.4652s / 31175.3102 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2810
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2903
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 541.05,                last time consumption/overall running time: 75.6338s / 31250.9441 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2568
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2547
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 561.9,                last time consumption/overall running time: 76.8787s / 31327.8227 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2785
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2818
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 568.2,                last time consumption/overall running time: 78.8342s / 31406.6569 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2647
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2602
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 546.15,                last time consumption/overall running time: 77.2249s / 31483.8818 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2798
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2873
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 589.15,                last time consumption/overall running time: 80.7654s / 31564.6473 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2703
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2677
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 607.05,                last time consumption/overall running time: 84.0875s / 31648.7347 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2740
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2785
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 557.65,                last time consumption/overall running time: 78.6986s / 31727.4333 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2897
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2929
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 548.3,                last time consumption/overall running time: 77.3965s / 31804.8298 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2421
env0_second_0:                 episode reward: 1.4500,                 loss: 0.2483
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 582.4,                last time consumption/overall running time: 81.0821s / 31885.9119 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2422
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2446
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 603.05,                last time consumption/overall running time: 82.8648s / 31968.7767 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2539
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2551
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 544.65,                last time consumption/overall running time: 76.3957s / 32045.1724 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2804
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2781
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 538.25,                last time consumption/overall running time: 76.2604s / 32121.4328 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2937
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2963
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 576.6,                last time consumption/overall running time: 80.0835s / 32201.5163 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2674
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2728
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 570.2,                last time consumption/overall running time: 79.8600s / 32281.3763 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2794
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2804
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 597.25,                last time consumption/overall running time: 82.6428s / 32364.0192 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2891
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2954
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 544.25,                last time consumption/overall running time: 76.6426s / 32440.6617 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2621
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2615
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 588.05,                last time consumption/overall running time: 82.0499s / 32522.7116 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2766
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2657
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 586.6,                last time consumption/overall running time: 80.3745s / 32603.0861 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2678
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2712
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 546.2,                last time consumption/overall running time: 77.5245s / 32680.6106 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2590
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2681
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 541.45,                last time consumption/overall running time: 76.5254s / 32757.1359 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2463
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2545
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 556.55,                last time consumption/overall running time: 78.3363s / 32835.4723 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2685
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2686
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 579.3,                last time consumption/overall running time: 79.2056s / 32914.6779 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2625
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2605
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 570.7,                last time consumption/overall running time: 80.0567s / 32994.7346 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2599
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2650
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 597.25,                last time consumption/overall running time: 83.4313s / 33078.1659 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2617
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2603
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 580.55,                last time consumption/overall running time: 79.9443s / 33158.1102 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2822
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2843
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 546.55,                last time consumption/overall running time: 75.7808s / 33233.8910 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2552
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2565
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 585.85,                last time consumption/overall running time: 81.7111s / 33315.6021 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2465
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2503
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 573.15,                last time consumption/overall running time: 81.0688s / 33396.6709 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2487
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2465
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 620.2,                last time consumption/overall running time: 85.9077s / 33482.5786 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2475
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2441
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 551.45,                last time consumption/overall running time: 77.1750s / 33559.7536 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2866
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2949
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 597.4,                last time consumption/overall running time: 82.1339s / 33641.8875 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2534
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2566
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 532.15,                last time consumption/overall running time: 75.2805s / 33717.1680 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2519
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2607
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 585.9,                last time consumption/overall running time: 80.9867s / 33798.1547 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2680
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2696
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 547.35,                last time consumption/overall running time: 78.5384s / 33876.6930 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2732
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2679
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 574.7,                last time consumption/overall running time: 78.3963s / 33955.0894 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2528
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2492
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 568.05,                last time consumption/overall running time: 78.4756s / 34033.5649 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2544
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2550
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 629.6,                last time consumption/overall running time: 87.5024s / 34121.0673 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2503
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2503
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 629.25,                last time consumption/overall running time: 86.8377s / 34207.9050 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2279
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2184
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 634.95,                last time consumption/overall running time: 86.4520s / 34294.3570 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2421
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2251
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 628.25,                last time consumption/overall running time: 84.3242s / 34378.6813 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2240
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2297
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 604.0,                last time consumption/overall running time: 82.9136s / 34461.5948 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2350
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2402
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 554.6,                last time consumption/overall running time: 78.4306s / 34540.0254 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2745
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2745
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 578.45,                last time consumption/overall running time: 80.5717s / 34620.5971 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2662
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2699
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 595.9,                last time consumption/overall running time: 83.2635s / 34703.8606 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2321
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2346
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 648.1,                last time consumption/overall running time: 88.4971s / 34792.3576 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.2486
env0_second_0:                 episode reward: -1.6500,                 loss: 0.2553
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 566.7,                last time consumption/overall running time: 79.1959s / 34871.5536 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2363
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2382
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 586.0,                last time consumption/overall running time: 81.2052s / 34952.7588 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2525
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2503
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 650.9,                last time consumption/overall running time: 88.3512s / 35041.1100 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2275
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2251
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 602.35,                last time consumption/overall running time: 83.6103s / 35124.7203 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2241
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2085
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 620.2,                last time consumption/overall running time: 84.9890s / 35209.7093 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2391
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2421
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 610.55,                last time consumption/overall running time: 83.0287s / 35292.7380 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.1958
env0_second_0:                 episode reward: 1.5000,                 loss: 0.1860
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 636.25,                last time consumption/overall running time: 87.0669s / 35379.8049 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2014
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2041
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 612.55,                last time consumption/overall running time: 83.6608s / 35463.4657 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2063
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2058
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 674.15,                last time consumption/overall running time: 89.4820s / 35552.9477 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.1884
env0_second_0:                 episode reward: 1.8000,                 loss: 0.1940
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 661.65,                last time consumption/overall running time: 89.5154s / 35642.4631 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2135
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2163
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 646.4,                last time consumption/overall running time: 88.2315s / 35730.6947 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2251
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2216
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 634.05,                last time consumption/overall running time: 86.4173s / 35817.1120 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.1982
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2114
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 687.2,                last time consumption/overall running time: 92.3903s / 35909.5024 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1993
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2062
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 638.85,                last time consumption/overall running time: 87.1503s / 35996.6526 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2197
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2229
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 627.0,                last time consumption/overall running time: 85.8967s / 36082.5493 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.1900
env0_second_0:                 episode reward: 2.4000,                 loss: 0.1933
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 596.4,                last time consumption/overall running time: 83.7846s / 36166.3339 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.1994
env0_second_0:                 episode reward: 2.1000,                 loss: 0.2000
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 674.85,                last time consumption/overall running time: 90.9200s / 36257.2540 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1987
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2109
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 687.15,                last time consumption/overall running time: 92.8915s / 36350.1454 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.1804
env0_second_0:                 episode reward: 1.4000,                 loss: 0.1894
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 594.95,                last time consumption/overall running time: 82.9927s / 36433.1381 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2525
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2524
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 634.45,                last time consumption/overall running time: 86.3175s / 36519.4557 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.1947
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2079
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 675.3,                last time consumption/overall running time: 91.5722s / 36611.0279 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.1934
env0_second_0:                 episode reward: 1.1000,                 loss: 0.1920
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 649.85,                last time consumption/overall running time: 88.5586s / 36699.5864 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.1903
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1970
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 585.85,                last time consumption/overall running time: 81.4896s / 36781.0760 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2101
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2089
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 627.6,                last time consumption/overall running time: 84.4476s / 36865.5236 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.1911
env0_second_0:                 episode reward: 1.8500,                 loss: 0.1901
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 660.45,                last time consumption/overall running time: 89.0339s / 36954.5575 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.1577
env0_second_0:                 episode reward: 1.8500,                 loss: 0.1718
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 625.3,                last time consumption/overall running time: 86.4698s / 37041.0273 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.1878
env0_second_0:                 episode reward: 2.4500,                 loss: 0.1978
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 637.95,                last time consumption/overall running time: 86.6522s / 37127.6795 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.1853
env0_second_0:                 episode reward: 2.2500,                 loss: 0.1907
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 624.35,                last time consumption/overall running time: 85.3956s / 37213.0750 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.1978
env0_second_0:                 episode reward: 2.0000,                 loss: 0.2143
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 735.2,                last time consumption/overall running time: 97.0228s / 37310.0978 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.1487
env0_second_0:                 episode reward: 1.4000,                 loss: 0.1584
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 645.75,                last time consumption/overall running time: 88.5658s / 37398.6636 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.1419
env0_second_0:                 episode reward: 2.3500,                 loss: 0.1547
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 633.9,                last time consumption/overall running time: 86.1672s / 37484.8308 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.1437
env0_second_0:                 episode reward: 2.8500,                 loss: 0.1416
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 660.3,                last time consumption/overall running time: 89.1850s / 37574.0158 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.1657
env0_second_0:                 episode reward: 2.2000,                 loss: 0.1788
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 600.95,                last time consumption/overall running time: 82.5940s / 37656.6098 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.1472
env0_second_0:                 episode reward: 2.6500,                 loss: 0.1510
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 665.95,                last time consumption/overall running time: 88.4368s / 37745.0466 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.1613
env0_second_0:                 episode reward: 2.1000,                 loss: 0.1667
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 635.65,                last time consumption/overall running time: 86.6236s / 37831.6702 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.1173
env0_second_0:                 episode reward: 2.2500,                 loss: 0.1210
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 643.15,                last time consumption/overall running time: 86.6785s / 37918.3487 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.1490
env0_second_0:                 episode reward: 2.5500,                 loss: 0.1665
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 633.8,                last time consumption/overall running time: 86.8133s / 38005.1620 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.1693
env0_second_0:                 episode reward: 2.8500,                 loss: 0.1755
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 684.1,                last time consumption/overall running time: 91.4594s / 38096.6214 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.1189
env0_second_0:                 episode reward: 2.3500,                 loss: 0.1182
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 699.15,                last time consumption/overall running time: 93.4896s / 38190.1110 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.1291
env0_second_0:                 episode reward: 2.3500,                 loss: 0.1404
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 691.65,                last time consumption/overall running time: 91.9552s / 38282.0662 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0892
env0_second_0:                 episode reward: 3.1500,                 loss: 0.1005
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 611.65,                last time consumption/overall running time: 83.8374s / 38365.9036 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1176
env0_second_0:                 episode reward: 3.2000,                 loss: 0.1175
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 627.25,                last time consumption/overall running time: 85.9292s / 38451.8328 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.1143
env0_second_0:                 episode reward: 2.9000,                 loss: 0.1224
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 664.25,                last time consumption/overall running time: 89.8081s / 38541.6409 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0965
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0944
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 595.1,                last time consumption/overall running time: 83.1849s / 38624.8259 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0968
env0_second_0:                 episode reward: 3.1500,                 loss: 0.1083
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 629.8,                last time consumption/overall running time: 84.0316s / 38708.8575 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.1254
env0_second_0:                 episode reward: 2.6500,                 loss: 0.1309
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 633.95,                last time consumption/overall running time: 86.5937s / 38795.4512 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1311
env0_second_0:                 episode reward: 3.3500,                 loss: 0.1501
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 703.65,                last time consumption/overall running time: 95.0461s / 38890.4973 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0943
env0_second_0:                 episode reward: 2.7500,                 loss: 0.1038
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 657.75,                last time consumption/overall running time: 89.1547s / 38979.6519 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1023
env0_second_0:                 episode reward: 3.2000,                 loss: 0.1162
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 620.05,                last time consumption/overall running time: 85.7608s / 39065.4127 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.1226
env0_second_0:                 episode reward: 2.5000,                 loss: 0.1351
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 573.45,                last time consumption/overall running time: 80.4411s / 39145.8538 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.1050
env0_second_0:                 episode reward: 2.4000,                 loss: 0.1089
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 639.6,                last time consumption/overall running time: 86.6029s / 39232.4567 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.1124
env0_second_0:                 episode reward: 2.5500,                 loss: 0.1311
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 668.7,                last time consumption/overall running time: 91.1502s / 39323.6069 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.1313
env0_second_0:                 episode reward: 2.4000,                 loss: 0.1445
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 666.6,                last time consumption/overall running time: 90.3877s / 39413.9947 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0893
env0_second_0:                 episode reward: 2.6000,                 loss: 0.1025
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 676.3,                last time consumption/overall running time: 90.9988s / 39504.9935 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1150
env0_second_0:                 episode reward: 3.1000,                 loss: 0.1356
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 657.35,                last time consumption/overall running time: 89.0207s / 39594.0141 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0879
env0_second_0:                 episode reward: 3.0500,                 loss: 0.1085
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 665.95,                last time consumption/overall running time: 90.4971s / 39684.5113 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0748
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0865
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 606.55,                last time consumption/overall running time: 83.0986s / 39767.6098 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.1081
env0_second_0:                 episode reward: 2.9500,                 loss: 0.1295/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 699.7,                last time consumption/overall running time: 94.4110s / 39862.0209 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0543
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0691
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 738.55,                last time consumption/overall running time: 96.9098s / 39958.9306 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0407
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0586
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 702.15,                last time consumption/overall running time: 84.2181s / 40043.1488 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0653
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0966
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 690.0,                last time consumption/overall running time: 80.8119s / 40123.9607 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0650
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0840
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
