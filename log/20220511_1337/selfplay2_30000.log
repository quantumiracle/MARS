2022-05-11 13:59:43.911806: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 13:59:43.911876: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 13:59:43.911882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f150d6a4470>
3 3 3
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220511131205/mdp_arbitrary_mdp_selfplay2/30000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 8000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220511131205/mdp_arbitrary_mdp_selfplay2/30000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220511131205_exploit_30000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220511131205_exploit_30000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7964s / 0.7964 s
agent0:                 episode reward: 2.1687,                 loss: nan
agent1:                 episode reward: -2.1687,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0224s / 0.8188 s
agent0:                 episode reward: 0.7460,                 loss: nan
agent1:                 episode reward: -0.7460,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0230s / 0.8418 s
agent0:                 episode reward: 0.0913,                 loss: nan
agent1:                 episode reward: -0.0913,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0232s / 0.8650 s
agent0:                 episode reward: -0.1517,                 loss: nan
agent1:                 episode reward: 0.1517,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0254s / 0.8904 s
agent0:                 episode reward: -0.0617,                 loss: nan
agent1:                 episode reward: 0.0617,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0283s / 0.9187 s
agent0:                 episode reward: 0.0969,                 loss: nan
agent1:                 episode reward: -0.0969,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0230s / 0.9417 s
agent0:                 episode reward: 0.1263,                 loss: nan
agent1:                 episode reward: -0.1263,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0235s / 0.9653 s
agent0:                 episode reward: 0.4948,                 loss: nan
agent1:                 episode reward: -0.4948,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0257s / 0.9910 s
agent0:                 episode reward: -0.0542,                 loss: nan
agent1:                 episode reward: 0.0542,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0293s / 1.0203 s
agent0:                 episode reward: 0.0095,                 loss: nan
agent1:                 episode reward: -0.0095,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0248s / 1.0451 s
agent0:                 episode reward: 0.4139,                 loss: nan
agent1:                 episode reward: -0.4139,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0987s / 1.1438 s
agent0:                 episode reward: 0.6016,                 loss: nan
agent1:                 episode reward: -0.6016,                 loss: 0.4388
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2148s / 1.3586 s
agent0:                 episode reward: 0.0858,                 loss: nan
agent1:                 episode reward: -0.0858,                 loss: 0.3981
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2178s / 1.5764 s
agent0:                 episode reward: 0.3232,                 loss: nan
agent1:                 episode reward: -0.3232,                 loss: 0.3790
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2162s / 1.7926 s
agent0:                 episode reward: 0.2154,                 loss: nan
agent1:                 episode reward: -0.2154,                 loss: 0.3582
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2130s / 2.0056 s
agent0:                 episode reward: 0.3748,                 loss: nan
agent1:                 episode reward: -0.3748,                 loss: 0.3462
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2200s / 2.2256 s
agent0:                 episode reward: 0.0588,                 loss: nan
agent1:                 episode reward: -0.0588,                 loss: 0.3482
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2144s / 2.4400 s
agent0:                 episode reward: -0.0769,                 loss: nan
agent1:                 episode reward: 0.0769,                 loss: 0.3446
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2268s / 2.6668 s
agent0:                 episode reward: 0.1110,                 loss: nan
agent1:                 episode reward: -0.1110,                 loss: 0.3482
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2177s / 2.8845 s
agent0:                 episode reward: -0.3716,                 loss: nan
agent1:                 episode reward: 0.3716,                 loss: 0.3450
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2211s / 3.1056 s
agent0:                 episode reward: -0.0594,                 loss: nan
agent1:                 episode reward: 0.0594,                 loss: 0.3431
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2167s / 3.3223 s
agent0:                 episode reward: 0.2255,                 loss: nan
agent1:                 episode reward: -0.2255,                 loss: 0.3532
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2149s / 3.5371 s
agent0:                 episode reward: -0.1499,                 loss: nan
agent1:                 episode reward: 0.1499,                 loss: 0.3502
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2213s / 3.7584 s
agent0:                 episode reward: 0.1524,                 loss: nan
agent1:                 episode reward: -0.1524,                 loss: 0.3466
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2226s / 3.9810 s
agent0:                 episode reward: 0.2627,                 loss: nan
agent1:                 episode reward: -0.2627,                 loss: 0.3494
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2217s / 4.2026 s
agent0:                 episode reward: -0.1294,                 loss: nan
agent1:                 episode reward: 0.1294,                 loss: 0.3508
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2224s / 4.4250 s
agent0:                 episode reward: -0.2284,                 loss: nan
agent1:                 episode reward: 0.2284,                 loss: 0.3513
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2282s / 4.6532 s
agent0:                 episode reward: 0.0014,                 loss: nan
agent1:                 episode reward: -0.0014,                 loss: 0.3513
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2372s / 4.8905 s
agent0:                 episode reward: 0.2690,                 loss: nan
agent1:                 episode reward: -0.2690,                 loss: 0.3313
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2290s / 5.1194 s
agent0:                 episode reward: 0.0040,                 loss: nan
agent1:                 episode reward: -0.0040,                 loss: 0.3060
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2247s / 5.3441 s
agent0:                 episode reward: 0.0813,                 loss: nan
agent1:                 episode reward: -0.0813,                 loss: 0.2946
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2216s / 5.5657 s
agent0:                 episode reward: 0.0369,                 loss: nan
agent1:                 episode reward: -0.0369,                 loss: 0.2941
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2303s / 5.7960 s
agent0:                 episode reward: 0.4432,                 loss: nan
agent1:                 episode reward: -0.4432,                 loss: 0.2872
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2181s / 6.0141 s
agent0:                 episode reward: -0.3795,                 loss: nan
agent1:                 episode reward: 0.3795,                 loss: 0.2810
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2180s / 6.2321 s
agent0:                 episode reward: 0.2007,                 loss: nan
agent1:                 episode reward: -0.2007,                 loss: 0.2806
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2223s / 6.4544 s
agent0:                 episode reward: 0.2853,                 loss: nan
agent1:                 episode reward: -0.2853,                 loss: 0.2787
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2249s / 6.6793 s
agent0:                 episode reward: -0.3002,                 loss: nan
agent1:                 episode reward: 0.3002,                 loss: 0.2762
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2236s / 6.9029 s
agent0:                 episode reward: -0.0312,                 loss: nan
agent1:                 episode reward: 0.0312,                 loss: 0.2763
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 7.2162 s
agent0:                 episode reward: -0.1896,                 loss: nan
agent1:                 episode reward: 0.1896,                 loss: 0.2757
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2209s / 7.4371 s
agent0:                 episode reward: 0.5296,                 loss: nan
agent1:                 episode reward: -0.5296,                 loss: 0.2730
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 7.6932 s
agent0:                 episode reward: -0.2733,                 loss: nan
agent1:                 episode reward: 0.2733,                 loss: 0.2728
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2287s / 7.9219 s
agent0:                 episode reward: -0.3993,                 loss: nan
agent1:                 episode reward: 0.3993,                 loss: 0.2703
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2346s / 8.1564 s
agent0:                 episode reward: -0.1650,                 loss: nan
agent1:                 episode reward: 0.1650,                 loss: 0.2685
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2279s / 8.3843 s
agent0:                 episode reward: -0.1839,                 loss: nan
agent1:                 episode reward: 0.1839,                 loss: 0.2667
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2316s / 8.6159 s
agent0:                 episode reward: -0.1366,                 loss: nan
agent1:                 episode reward: 0.1366,                 loss: 0.2693
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2378s / 8.8537 s
agent0:                 episode reward: -0.0275,                 loss: nan
agent1:                 episode reward: 0.0275,                 loss: 0.2735
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2312s / 9.0849 s
agent0:                 episode reward: 0.2378,                 loss: nan
agent1:                 episode reward: -0.2378,                 loss: 0.2544
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2280s / 9.3129 s
agent0:                 episode reward: -0.1911,                 loss: nan
agent1:                 episode reward: 0.1911,                 loss: 0.2510
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2312s / 9.5440 s
agent0:                 episode reward: -0.1743,                 loss: nan
agent1:                 episode reward: 0.1743,                 loss: 0.2553
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2400s / 9.7841 s
agent0:                 episode reward: -0.5109,                 loss: nan
agent1:                 episode reward: 0.5109,                 loss: 0.2531
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2404s / 10.0244 s
agent0:                 episode reward: -0.2100,                 loss: nan
agent1:                 episode reward: 0.2100,                 loss: 0.2485
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2389s / 10.2634 s
agent0:                 episode reward: -0.1875,                 loss: nan
agent1:                 episode reward: 0.1875,                 loss: 0.2499
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2278s / 10.4911 s
agent0:                 episode reward: 0.0053,                 loss: nan
agent1:                 episode reward: -0.0053,                 loss: 0.2461
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2268s / 10.7180 s
agent0:                 episode reward: 0.2911,                 loss: nan
agent1:                 episode reward: -0.2911,                 loss: 0.2451
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2327s / 10.9507 s
agent0:                 episode reward: 0.0003,                 loss: nan
agent1:                 episode reward: -0.0003,                 loss: 0.2440
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2337s / 11.1843 s
agent0:                 episode reward: 0.0069,                 loss: nan
agent1:                 episode reward: -0.0069,                 loss: 0.2477
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2279s / 11.4122 s
agent0:                 episode reward: -0.2292,                 loss: nan
agent1:                 episode reward: 0.2292,                 loss: 0.2475
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2431s / 11.6553 s
agent0:                 episode reward: -0.2051,                 loss: nan
agent1:                 episode reward: 0.2051,                 loss: 0.2452
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2379s / 11.8932 s
agent0:                 episode reward: 0.0869,                 loss: nan
agent1:                 episode reward: -0.0869,                 loss: 0.2456
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 12.1280 s
agent0:                 episode reward: -0.2113,                 loss: nan
agent1:                 episode reward: 0.2113,                 loss: 0.2512
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2350s / 12.3629 s
agent0:                 episode reward: -0.2953,                 loss: nan
agent1:                 episode reward: 0.2953,                 loss: 0.2481
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2364s / 12.5994 s
agent0:                 episode reward: -0.1735,                 loss: nan
agent1:                 episode reward: 0.1735,                 loss: 0.2821
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2365s / 12.8359 s
agent0:                 episode reward: 0.0459,                 loss: nan
agent1:                 episode reward: -0.0459,                 loss: 0.3209
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2679s / 13.1038 s
agent0:                 episode reward: -0.4038,                 loss: nan
agent1:                 episode reward: 0.4038,                 loss: 0.3155
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2292s / 13.3330 s
agent0:                 episode reward: -0.3379,                 loss: nan
agent1:                 episode reward: 0.3379,                 loss: 0.3143
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2419s / 13.5749 s
agent0:                 episode reward: -0.4424,                 loss: nan
agent1:                 episode reward: 0.4424,                 loss: 0.3149
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2396s / 13.8145 s
agent0:                 episode reward: 0.0638,                 loss: nan
agent1:                 episode reward: -0.0638,                 loss: 0.3148
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2379s / 14.0524 s
agent0:                 episode reward: -0.1419,                 loss: nan
agent1:                 episode reward: 0.1419,                 loss: 0.3163
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2425s / 14.2950 s
agent0:                 episode reward: -0.1970,                 loss: nan
agent1:                 episode reward: 0.1970,                 loss: 0.3131
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2383s / 14.5332 s
agent0:                 episode reward: -0.2418,                 loss: nan
agent1:                 episode reward: 0.2418,                 loss: 0.3158
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2628s / 14.7960 s
agent0:                 episode reward: -0.2579,                 loss: nan
agent1:                 episode reward: 0.2579,                 loss: 0.3163
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2408s / 15.0368 s
agent0:                 episode reward: -0.4226,                 loss: nan
agent1:                 episode reward: 0.4226,                 loss: 0.3113
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2364s / 15.2732 s
agent0:                 episode reward: -0.3462,                 loss: nan
agent1:                 episode reward: 0.3462,                 loss: 0.3127
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2366s / 15.5097 s
agent0:                 episode reward: -0.3359,                 loss: nan
agent1:                 episode reward: 0.3359,                 loss: 0.3139
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2365s / 15.7463 s
agent0:                 episode reward: -0.0803,                 loss: nan
agent1:                 episode reward: 0.0803,                 loss: 0.3143
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2392s / 15.9855 s
agent0:                 episode reward: -0.2812,                 loss: nan
agent1:                 episode reward: 0.2812,                 loss: 0.3128
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2431s / 16.2286 s
agent0:                 episode reward: -0.6282,                 loss: nan
agent1:                 episode reward: 0.6282,                 loss: 0.3091
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2421s / 16.4707 s
agent0:                 episode reward: -0.2169,                 loss: nan
agent1:                 episode reward: 0.2169,                 loss: 0.3124
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2416s / 16.7123 s
agent0:                 episode reward: -0.4613,                 loss: nan
agent1:                 episode reward: 0.4613,                 loss: 0.2874
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2382s / 16.9505 s
agent0:                 episode reward: -0.3543,                 loss: nan
agent1:                 episode reward: 0.3543,                 loss: 0.2747
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2446s / 17.1951 s
agent0:                 episode reward: -0.0494,                 loss: nan
agent1:                 episode reward: 0.0494,                 loss: 0.2751
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3630s / 17.5581 s
agent0:                 episode reward: 0.1193,                 loss: nan
agent1:                 episode reward: -0.1193,                 loss: 0.2761
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2494s / 17.8075 s
agent0:                 episode reward: -0.0892,                 loss: nan
agent1:                 episode reward: 0.0892,                 loss: 0.2758
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2406s / 18.0481 s
agent0:                 episode reward: -0.5420,                 loss: nan
agent1:                 episode reward: 0.5420,                 loss: 0.2741
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2421s / 18.2902 s
agent0:                 episode reward: -0.1472,                 loss: nan
agent1:                 episode reward: 0.1472,                 loss: 0.2725
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2426s / 18.5327 s
agent0:                 episode reward: -0.1413,                 loss: nan
agent1:                 episode reward: 0.1413,                 loss: 0.2686
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2418s / 18.7745 s
agent0:                 episode reward: -0.4620,                 loss: nan
agent1:                 episode reward: 0.4620,                 loss: 0.2724
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2437s / 19.0182 s
agent0:                 episode reward: -0.4354,                 loss: nan
agent1:                 episode reward: 0.4354,                 loss: 0.2702
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2420s / 19.2601 s
agent0:                 episode reward: -0.5943,                 loss: nan
agent1:                 episode reward: 0.5943,                 loss: 0.2700
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2511s / 19.5113 s
agent0:                 episode reward: -0.0665,                 loss: nan
agent1:                 episode reward: 0.0665,                 loss: 0.2717
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2484s / 19.7597 s
agent0:                 episode reward: -0.1784,                 loss: nan
agent1:                 episode reward: 0.1784,                 loss: 0.2713
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2455s / 20.0052 s
agent0:                 episode reward: -0.1965,                 loss: nan
agent1:                 episode reward: 0.1965,                 loss: 0.2710
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2460s / 20.2512 s
agent0:                 episode reward: -0.4842,                 loss: nan
agent1:                 episode reward: 0.4842,                 loss: 0.2705
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2488s / 20.5000 s
agent0:                 episode reward: -0.3387,                 loss: nan
agent1:                 episode reward: 0.3387,                 loss: 0.2723
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2552s / 20.7552 s
agent0:                 episode reward: -0.1701,                 loss: nan
agent1:                 episode reward: 0.1701,                 loss: 0.2696
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2483s / 21.0036 s
agent0:                 episode reward: -0.1628,                 loss: nan
agent1:                 episode reward: 0.1628,                 loss: 0.2625
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2526s / 21.2562 s
agent0:                 episode reward: -0.1151,                 loss: nan
agent1:                 episode reward: 0.1151,                 loss: 0.2528
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2686s / 21.5248 s
agent0:                 episode reward: -0.3173,                 loss: nan
agent1:                 episode reward: 0.3173,                 loss: 0.2523
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2437s / 21.7685 s
agent0:                 episode reward: -0.2463,                 loss: nan
agent1:                 episode reward: 0.2463,                 loss: 0.2537
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 22.0158 s
agent0:                 episode reward: -0.2597,                 loss: nan
agent1:                 episode reward: 0.2597,                 loss: 0.2556
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 22.2631 s
agent0:                 episode reward: -0.2117,                 loss: nan
agent1:                 episode reward: 0.2117,                 loss: 0.2535
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2482s / 22.5113 s
agent0:                 episode reward: -0.2645,                 loss: nan
agent1:                 episode reward: 0.2645,                 loss: 0.2493
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2443s / 22.7555 s
agent0:                 episode reward: -0.7678,                 loss: nan
agent1:                 episode reward: 0.7678,                 loss: 0.2547
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2466s / 23.0022 s
agent0:                 episode reward: -0.4893,                 loss: nan
agent1:                 episode reward: 0.4893,                 loss: 0.2521
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2501s / 23.2523 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.2545
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2466s / 23.4988 s
agent0:                 episode reward: 0.0452,                 loss: nan
agent1:                 episode reward: -0.0452,                 loss: 0.2525
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 23.7558 s
agent0:                 episode reward: -0.0923,                 loss: nan
agent1:                 episode reward: 0.0923,                 loss: 0.2526
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2494s / 24.0052 s
agent0:                 episode reward: -0.3926,                 loss: nan
agent1:                 episode reward: 0.3926,                 loss: 0.2499
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2521s / 24.2573 s
agent0:                 episode reward: -0.1617,                 loss: nan
agent1:                 episode reward: 0.1617,                 loss: 0.2524
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2482s / 24.5055 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.2499
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2524s / 24.7579 s
agent0:                 episode reward: -0.1743,                 loss: nan
agent1:                 episode reward: 0.1743,                 loss: 0.2495
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 25.0052 s
agent0:                 episode reward: -0.3653,                 loss: nan
agent1:                 episode reward: 0.3653,                 loss: 0.2722
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2726s / 25.2779 s
agent0:                 episode reward: -0.3567,                 loss: nan
agent1:                 episode reward: 0.3567,                 loss: 0.2987
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2512s / 25.5290 s
agent0:                 episode reward: -0.3938,                 loss: nan
agent1:                 episode reward: 0.3938,                 loss: 0.2990
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2527s / 25.7817 s
agent0:                 episode reward: -0.1149,                 loss: nan
agent1:                 episode reward: 0.1149,                 loss: 0.2986
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2498s / 26.0315 s
agent0:                 episode reward: 0.1275,                 loss: nan
agent1:                 episode reward: -0.1275,                 loss: 0.2980
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2547s / 26.2862 s
agent0:                 episode reward: -0.5349,                 loss: nan
agent1:                 episode reward: 0.5349,                 loss: 0.2986
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2538s / 26.5401 s
agent0:                 episode reward: -0.2747,                 loss: nan
agent1:                 episode reward: 0.2747,                 loss: 0.2975
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2699s / 26.8100 s
agent0:                 episode reward: -0.1162,                 loss: nan
agent1:                 episode reward: 0.1162,                 loss: 0.3012
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2551s / 27.0651 s
agent0:                 episode reward: -0.2261,                 loss: nan
agent1:                 episode reward: 0.2261,                 loss: 0.3000
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2645s / 27.3295 s
agent0:                 episode reward: -0.2885,                 loss: nan
agent1:                 episode reward: 0.2885,                 loss: 0.2974
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3345s / 27.6640 s
agent0:                 episode reward: -0.5601,                 loss: nan
agent1:                 episode reward: 0.5601,                 loss: 0.2976
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2600s / 27.9240 s
agent0:                 episode reward: -0.5801,                 loss: nan
agent1:                 episode reward: 0.5801,                 loss: 0.2965
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2574s / 28.1813 s
agent0:                 episode reward: -0.5541,                 loss: nan
agent1:                 episode reward: 0.5541,                 loss: 0.2970
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2502s / 28.4316 s
agent0:                 episode reward: -0.4384,                 loss: nan
agent1:                 episode reward: 0.4384,                 loss: 0.2966
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2545s / 28.6860 s
agent0:                 episode reward: -0.2561,                 loss: nan
agent1:                 episode reward: 0.2561,                 loss: 0.2968
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2596s / 28.9456 s
agent0:                 episode reward: -0.3598,                 loss: nan
agent1:                 episode reward: 0.3598,                 loss: 0.2965
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2588s / 29.2044 s
agent0:                 episode reward: -0.6105,                 loss: nan
agent1:                 episode reward: 0.6105,                 loss: 0.2985
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2567s / 29.4611 s
agent0:                 episode reward: 0.0264,                 loss: nan
agent1:                 episode reward: -0.0264,                 loss: 0.2769
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2946s / 29.7557 s
agent0:                 episode reward: -0.3767,                 loss: nan
agent1:                 episode reward: 0.3767,                 loss: 0.2677
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 30.0156 s
agent0:                 episode reward: -0.2738,                 loss: nan
agent1:                 episode reward: 0.2738,                 loss: 0.2645
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 30.2702 s
agent0:                 episode reward: -0.3298,                 loss: nan
agent1:                 episode reward: 0.3298,                 loss: 0.2630
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2539s / 30.5241 s
agent0:                 episode reward: -0.6183,                 loss: nan
agent1:                 episode reward: 0.6183,                 loss: 0.2660
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2565s / 30.7806 s
agent0:                 episode reward: -0.5326,                 loss: nan
agent1:                 episode reward: 0.5326,                 loss: 0.2621
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2583s / 31.0389 s
agent0:                 episode reward: -0.4414,                 loss: nan
agent1:                 episode reward: 0.4414,                 loss: 0.2655
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 31.2968 s
agent0:                 episode reward: -0.1439,                 loss: nan
agent1:                 episode reward: 0.1439,                 loss: 0.2621
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2583s / 31.5552 s
agent0:                 episode reward: -0.6688,                 loss: nan
agent1:                 episode reward: 0.6688,                 loss: 0.2673
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2591s / 31.8143 s
agent0:                 episode reward: -0.6581,                 loss: nan
agent1:                 episode reward: 0.6581,                 loss: 0.2621
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2560s / 32.0703 s
agent0:                 episode reward: -0.4513,                 loss: nan
agent1:                 episode reward: 0.4513,                 loss: 0.2630
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 32.3282 s
agent0:                 episode reward: -0.5581,                 loss: nan
agent1:                 episode reward: 0.5581,                 loss: 0.2620
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2645s / 32.5927 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.2638
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2864s / 32.8791 s
agent0:                 episode reward: -0.5874,                 loss: nan
agent1:                 episode reward: 0.5874,                 loss: 0.2588
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2635s / 33.1426 s
agent0:                 episode reward: -0.5158,                 loss: nan
agent1:                 episode reward: 0.5158,                 loss: 0.2584
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2615s / 33.4041 s
agent0:                 episode reward: -0.6419,                 loss: nan
agent1:                 episode reward: 0.6419,                 loss: 0.2610
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2622s / 33.6663 s
agent0:                 episode reward: -0.6036,                 loss: nan
agent1:                 episode reward: 0.6036,                 loss: 0.2587
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2566s / 33.9229 s
agent0:                 episode reward: -0.5158,                 loss: nan
agent1:                 episode reward: 0.5158,                 loss: 0.2532
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2594s / 34.1823 s
agent0:                 episode reward: -0.3627,                 loss: nan
agent1:                 episode reward: 0.3627,                 loss: 0.2499
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2619s / 34.4442 s
agent0:                 episode reward: -0.4222,                 loss: nan
agent1:                 episode reward: 0.4222,                 loss: 0.2508
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2625s / 34.7068 s
agent0:                 episode reward: 0.1867,                 loss: nan
agent1:                 episode reward: -0.1867,                 loss: 0.2490
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 34.9667 s
agent0:                 episode reward: -0.2015,                 loss: nan
agent1:                 episode reward: 0.2015,                 loss: 0.2500
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2600s / 35.2266 s
agent0:                 episode reward: -0.5390,                 loss: nan
agent1:                 episode reward: 0.5390,                 loss: 0.2454
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 35.4878 s
agent0:                 episode reward: -0.4401,                 loss: nan
agent1:                 episode reward: 0.4401,                 loss: 0.2485
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2711s / 35.7589 s
agent0:                 episode reward: -0.5346,                 loss: nan
agent1:                 episode reward: 0.5346,                 loss: 0.2469
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2704s / 36.0293 s
agent0:                 episode reward: -0.2153,                 loss: nan
agent1:                 episode reward: 0.2153,                 loss: 0.2467
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2652s / 36.2945 s
agent0:                 episode reward: -0.5146,                 loss: nan
agent1:                 episode reward: 0.5146,                 loss: 0.2507
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2625s / 36.5570 s
agent0:                 episode reward: -0.7771,                 loss: nan
agent1:                 episode reward: 0.7771,                 loss: 0.2476
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2653s / 36.8223 s
agent0:                 episode reward: -0.4511,                 loss: nan
agent1:                 episode reward: 0.4511,                 loss: 0.2459
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2689s / 37.0912 s
agent0:                 episode reward: -0.3349,                 loss: nan
agent1:                 episode reward: 0.3349,                 loss: 0.2494
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2644s / 37.3556 s
agent0:                 episode reward: -0.3815,                 loss: nan
agent1:                 episode reward: 0.3815,                 loss: 0.2474
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2797s / 37.6353 s
agent0:                 episode reward: -0.3003,                 loss: nan
agent1:                 episode reward: 0.3003,                 loss: 0.2455
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3893s / 38.0247 s
agent0:                 episode reward: -0.3755,                 loss: nan
agent1:                 episode reward: 0.3755,                 loss: 0.2501
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2664s / 38.2911 s
agent0:                 episode reward: -0.4931,                 loss: nan
agent1:                 episode reward: 0.4931,                 loss: 0.2678
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2667s / 38.5578 s
agent0:                 episode reward: -0.6898,                 loss: nan
agent1:                 episode reward: 0.6898,                 loss: 0.2899
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2718s / 38.8296 s
agent0:                 episode reward: -0.7184,                 loss: nan
agent1:                 episode reward: 0.7184,                 loss: 0.2909
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 39.1040 s
agent0:                 episode reward: -0.8283,                 loss: nan
agent1:                 episode reward: 0.8283,                 loss: 0.2932
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2627s / 39.3668 s
agent0:                 episode reward: -0.7498,                 loss: nan
agent1:                 episode reward: 0.7498,                 loss: 0.2919
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2658s / 39.6326 s
agent0:                 episode reward: -0.5784,                 loss: nan
agent1:                 episode reward: 0.5784,                 loss: 0.2909
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2680s / 39.9006 s
agent0:                 episode reward: -0.4737,                 loss: nan
agent1:                 episode reward: 0.4737,                 loss: 0.2917
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2740s / 40.1746 s
agent0:                 episode reward: -0.3038,                 loss: nan
agent1:                 episode reward: 0.3038,                 loss: 0.2905
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2687s / 40.4432 s
agent0:                 episode reward: -0.5530,                 loss: nan
agent1:                 episode reward: 0.5530,                 loss: 0.2900
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2733s / 40.7165 s
agent0:                 episode reward: -0.8940,                 loss: nan
agent1:                 episode reward: 0.8940,                 loss: 0.2911
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 40.9931 s
agent0:                 episode reward: -0.2646,                 loss: nan
agent1:                 episode reward: 0.2646,                 loss: 0.2916
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2947s / 41.2878 s
agent0:                 episode reward: -0.7774,                 loss: nan
agent1:                 episode reward: 0.7774,                 loss: 0.2930
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2736s / 41.5614 s
agent0:                 episode reward: -0.6229,                 loss: nan
agent1:                 episode reward: 0.6229,                 loss: 0.2934
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3132s / 41.8746 s
agent0:                 episode reward: -0.6101,                 loss: nan
agent1:                 episode reward: 0.6101,                 loss: 0.2915
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2730s / 42.1476 s
agent0:                 episode reward: -0.1477,                 loss: nan
agent1:                 episode reward: 0.1477,                 loss: 0.2943
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2711s / 42.4188 s
agent0:                 episode reward: -0.2230,                 loss: nan
agent1:                 episode reward: 0.2230,                 loss: 0.2931
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2730s / 42.6918 s
agent0:                 episode reward: -0.5814,                 loss: nan
agent1:                 episode reward: 0.5814,                 loss: 0.2931
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2712s / 42.9630 s
agent0:                 episode reward: -0.5492,                 loss: nan
agent1:                 episode reward: 0.5492,                 loss: 0.2784
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2716s / 43.2347 s
agent0:                 episode reward: -0.1717,                 loss: nan
agent1:                 episode reward: 0.1717,                 loss: 0.2753
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2710s / 43.5056 s
agent0:                 episode reward: -0.5221,                 loss: nan
agent1:                 episode reward: 0.5221,                 loss: 0.2753
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2728s / 43.7784 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.2712
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2724s / 44.0508 s
agent0:                 episode reward: -0.8117,                 loss: nan
agent1:                 episode reward: 0.8117,                 loss: 0.2770
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2780s / 44.3288 s
agent0:                 episode reward: -0.3909,                 loss: nan
agent1:                 episode reward: 0.3909,                 loss: 0.2734
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2753s / 44.6041 s
agent0:                 episode reward: -0.1616,                 loss: nan
agent1:                 episode reward: 0.1616,                 loss: 0.2717
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2862s / 44.8903 s
agent0:                 episode reward: -0.1157,                 loss: nan
agent1:                 episode reward: 0.1157,                 loss: 0.2700
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 45.1669 s
agent0:                 episode reward: -0.4758,                 loss: nan
agent1:                 episode reward: 0.4758,                 loss: 0.2727
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2957s / 45.4627 s
agent0:                 episode reward: -0.2966,                 loss: nan
agent1:                 episode reward: 0.2966,                 loss: 0.2722
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2771s / 45.7398 s
agent0:                 episode reward: -0.6629,                 loss: nan
agent1:                 episode reward: 0.6629,                 loss: 0.2721
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2752s / 46.0150 s
agent0:                 episode reward: -0.2945,                 loss: nan
agent1:                 episode reward: 0.2945,                 loss: 0.2729
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2969s / 46.3118 s
agent0:                 episode reward: -1.0112,                 loss: nan
agent1:                 episode reward: 1.0112,                 loss: 0.2727
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2777s / 46.5896 s
agent0:                 episode reward: -0.7511,                 loss: nan
agent1:                 episode reward: 0.7511,                 loss: 0.2714
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2731s / 46.8626 s
agent0:                 episode reward: -0.4404,                 loss: nan
agent1:                 episode reward: 0.4404,                 loss: 0.2715
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2760s / 47.1387 s
agent0:                 episode reward: -0.4458,                 loss: nan
agent1:                 episode reward: 0.4458,                 loss: 0.2735
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2759s / 47.4146 s
agent0:                 episode reward: -0.7416,                 loss: nan
agent1:                 episode reward: 0.7416,                 loss: 0.2728
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2898s / 47.7044 s
agent0:                 episode reward: -0.6160,                 loss: nan
agent1:                 episode reward: 0.6160,                 loss: 0.2618
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2891s / 47.9936 s
agent0:                 episode reward: -0.6287,                 loss: nan
agent1:                 episode reward: 0.6287,                 loss: 0.2637
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3526s / 48.3462 s
agent0:                 episode reward: -0.4399,                 loss: nan
agent1:                 episode reward: 0.4399,                 loss: 0.2636
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2785s / 48.6247 s
agent0:                 episode reward: -0.3813,                 loss: nan
agent1:                 episode reward: 0.3813,                 loss: 0.2607
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2804s / 48.9050 s
agent0:                 episode reward: -0.5849,                 loss: nan
agent1:                 episode reward: 0.5849,                 loss: 0.2616
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2807s / 49.1857 s
agent0:                 episode reward: -0.4556,                 loss: nan
agent1:                 episode reward: 0.4556,                 loss: 0.2633
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2996s / 49.4853 s
agent0:                 episode reward: -0.7312,                 loss: nan
agent1:                 episode reward: 0.7312,                 loss: 0.2598
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3007s / 49.7860 s
agent0:                 episode reward: -0.5413,                 loss: nan
agent1:                 episode reward: 0.5413,                 loss: 0.2614
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2753s / 50.0613 s
agent0:                 episode reward: -0.5825,                 loss: nan
agent1:                 episode reward: 0.5825,                 loss: 0.2643
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3025s / 50.3638 s
agent0:                 episode reward: -0.3327,                 loss: nan
agent1:                 episode reward: 0.3327,                 loss: 0.2589
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2789s / 50.6428 s
agent0:                 episode reward: -0.8564,                 loss: nan
agent1:                 episode reward: 0.8564,                 loss: 0.2593
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2815s / 50.9242 s
agent0:                 episode reward: -0.5935,                 loss: nan
agent1:                 episode reward: 0.5935,                 loss: 0.2576
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2833s / 51.2075 s
agent0:                 episode reward: -0.6299,                 loss: nan
agent1:                 episode reward: 0.6299,                 loss: 0.2608
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2802s / 51.4876 s
agent0:                 episode reward: -0.5381,                 loss: nan
agent1:                 episode reward: 0.5381,                 loss: 0.2635
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2809s / 51.7685 s
agent0:                 episode reward: -0.4191,                 loss: nan
agent1:                 episode reward: 0.4191,                 loss: 0.2637
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2813s / 52.0498 s
agent0:                 episode reward: 0.1300,                 loss: nan
agent1:                 episode reward: -0.1300,                 loss: 0.2628
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2840s / 52.3338 s
agent0:                 episode reward: -0.2967,                 loss: nan
agent1:                 episode reward: 0.2967,                 loss: 0.2733
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2878s / 52.6216 s
agent0:                 episode reward: -0.6936,                 loss: nan
agent1:                 episode reward: 0.6936,                 loss: 0.2884
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2859s / 52.9075 s
agent0:                 episode reward: -0.2537,                 loss: nan
agent1:                 episode reward: 0.2537,                 loss: 0.2909
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2845s / 53.1921 s
agent0:                 episode reward: -0.3422,                 loss: nan
agent1:                 episode reward: 0.3422,                 loss: 0.2870
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2848s / 53.4769 s
agent0:                 episode reward: -0.4170,                 loss: nan
agent1:                 episode reward: 0.4170,                 loss: 0.2900
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3040s / 53.7809 s
agent0:                 episode reward: -1.1467,                 loss: nan
agent1:                 episode reward: 1.1467,                 loss: 0.2899
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2949s / 54.0758 s
agent0:                 episode reward: -0.6983,                 loss: nan
agent1:                 episode reward: 0.6983,                 loss: 0.2885
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2885s / 54.3643 s
agent0:                 episode reward: -0.7310,                 loss: nan
agent1:                 episode reward: 0.7310,                 loss: 0.2905
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3092s / 54.6735 s
agent0:                 episode reward: -0.1242,                 loss: nan
agent1:                 episode reward: 0.1242,                 loss: 0.2904
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2930s / 54.9665 s
agent0:                 episode reward: -0.1571,                 loss: nan
agent1:                 episode reward: 0.1571,                 loss: 0.2886
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2892s / 55.2557 s
agent0:                 episode reward: -0.7447,                 loss: nan
agent1:                 episode reward: 0.7447,                 loss: 0.2911
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2873s / 55.5430 s
agent0:                 episode reward: -0.4625,                 loss: nan
agent1:                 episode reward: 0.4625,                 loss: 0.2912
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2951s / 55.8381 s
agent0:                 episode reward: -0.4274,                 loss: nan
agent1:                 episode reward: 0.4274,                 loss: 0.2899
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2889s / 56.1270 s
agent0:                 episode reward: -0.6808,                 loss: nan
agent1:                 episode reward: 0.6808,                 loss: 0.2863
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2867s / 56.4137 s
agent0:                 episode reward: -0.4185,                 loss: nan
agent1:                 episode reward: 0.4185,                 loss: 0.2908
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2924s / 56.7061 s
agent0:                 episode reward: -0.5671,                 loss: nan
agent1:                 episode reward: 0.5671,                 loss: 0.2887
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2957s / 57.0018 s
agent0:                 episode reward: -0.7451,                 loss: nan
agent1:                 episode reward: 0.7451,                 loss: 0.2871
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2892s / 57.2910 s
agent0:                 episode reward: -0.7967,                 loss: nan
agent1:                 episode reward: 0.7967,                 loss: 0.2799
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2886s / 57.5796 s
agent0:                 episode reward: -0.8875,                 loss: nan
agent1:                 episode reward: 0.8875,                 loss: 0.2735
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3037s / 57.8833 s
agent0:                 episode reward: -0.5116,                 loss: nan
agent1:                 episode reward: 0.5116,                 loss: 0.2697
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2904s / 58.1737 s
agent0:                 episode reward: -0.7322,                 loss: nan
agent1:                 episode reward: 0.7322,                 loss: 0.2726
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3435s / 58.5171 s
agent0:                 episode reward: -0.6048,                 loss: nan
agent1:                 episode reward: 0.6048,                 loss: 0.2744
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2921s / 58.8092 s
agent0:                 episode reward: -0.4602,                 loss: nan
agent1:                 episode reward: 0.4602,                 loss: 0.2728
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2894s / 59.0986 s
agent0:                 episode reward: -0.1981,                 loss: nan
agent1:                 episode reward: 0.1981,                 loss: 0.2773
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2861s / 59.3846 s
agent0:                 episode reward: -0.4351,                 loss: nan
agent1:                 episode reward: 0.4351,                 loss: 0.2754
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2866s / 59.6712 s
agent0:                 episode reward: -0.3506,                 loss: nan
agent1:                 episode reward: 0.3506,                 loss: 0.2715
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2950s / 59.9662 s
agent0:                 episode reward: -0.5023,                 loss: nan
agent1:                 episode reward: 0.5023,                 loss: 0.2741
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2851s / 60.2513 s
agent0:                 episode reward: -0.5489,                 loss: nan
agent1:                 episode reward: 0.5489,                 loss: 0.2761
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2846s / 60.5359 s
agent0:                 episode reward: -0.8262,                 loss: nan
agent1:                 episode reward: 0.8262,                 loss: 0.2737
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2847s / 60.8207 s
agent0:                 episode reward: -0.7391,                 loss: nan
agent1:                 episode reward: 0.7391,                 loss: 0.2734
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2936s / 61.1143 s
agent0:                 episode reward: -0.5448,                 loss: nan
agent1:                 episode reward: 0.5448,                 loss: 0.2745
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2891s / 61.4035 s
agent0:                 episode reward: -0.6900,                 loss: nan
agent1:                 episode reward: 0.6900,                 loss: 0.2720
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2958s / 61.6992 s
agent0:                 episode reward: -0.4441,                 loss: nan
agent1:                 episode reward: 0.4441,                 loss: 0.2726
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2932s / 61.9924 s
agent0:                 episode reward: -0.8198,                 loss: nan
agent1:                 episode reward: 0.8198,                 loss: 0.2717
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 62.2864 s
agent0:                 episode reward: -0.3364,                 loss: nan
agent1:                 episode reward: 0.3364,                 loss: 0.2816
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2950s / 62.5814 s
agent0:                 episode reward: -0.9351,                 loss: nan
agent1:                 episode reward: 0.9351,                 loss: 0.2790
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3214s / 62.9028 s
agent0:                 episode reward: -0.6233,                 loss: nan
agent1:                 episode reward: 0.6233,                 loss: 0.2820
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2970s / 63.1998 s
agent0:                 episode reward: -0.7273,                 loss: nan
agent1:                 episode reward: 0.7273,                 loss: 0.2772
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2938s / 63.4936 s
agent0:                 episode reward: -0.5394,                 loss: nan
agent1:                 episode reward: 0.5394,                 loss: 0.2785
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 63.7877 s
agent0:                 episode reward: -0.8588,                 loss: nan
agent1:                 episode reward: 0.8588,                 loss: 0.2820
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2984s / 64.0860 s
agent0:                 episode reward: -0.5203,                 loss: nan
agent1:                 episode reward: 0.5203,                 loss: 0.2814
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2952s / 64.3813 s
agent0:                 episode reward: -0.4714,                 loss: nan
agent1:                 episode reward: 0.4714,                 loss: 0.2770
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2982s / 64.6795 s
agent0:                 episode reward: -0.6498,                 loss: nan
agent1:                 episode reward: 0.6498,                 loss: 0.2805
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2897s / 64.9691 s
agent0:                 episode reward: -0.4587,                 loss: nan
agent1:                 episode reward: 0.4587,                 loss: 0.2788
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2931s / 65.2622 s
agent0:                 episode reward: -0.5671,                 loss: nan
agent1:                 episode reward: 0.5671,                 loss: 0.2822
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2984s / 65.5606 s
agent0:                 episode reward: -0.7084,                 loss: nan
agent1:                 episode reward: 0.7084,                 loss: 0.2783
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3006s / 65.8612 s
agent0:                 episode reward: -0.8681,                 loss: nan
agent1:                 episode reward: 0.8681,                 loss: 0.2791
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2978s / 66.1590 s
agent0:                 episode reward: -0.7003,                 loss: nan
agent1:                 episode reward: 0.7003,                 loss: 0.2809
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2927s / 66.4517 s
agent0:                 episode reward: -0.6346,                 loss: nan
agent1:                 episode reward: 0.6346,                 loss: 0.2814
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2955s / 66.7472 s
agent0:                 episode reward: -0.7838,                 loss: nan
agent1:                 episode reward: 0.7838,                 loss: 0.2811
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2977s / 67.0449 s
agent0:                 episode reward: -0.0205,                 loss: nan
agent1:                 episode reward: 0.0205,                 loss: 0.2824
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2974s / 67.3423 s
agent0:                 episode reward: -0.7682,                 loss: nan
agent1:                 episode reward: 0.7682,                 loss: 0.2862
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2975s / 67.6398 s
agent0:                 episode reward: -0.3560,                 loss: nan
agent1:                 episode reward: 0.3560,                 loss: 0.2883
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3027s / 67.9425 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.2827
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2974s / 68.2399 s
agent0:                 episode reward: -0.7178,                 loss: nan
agent1:                 episode reward: 0.7178,                 loss: 0.2868
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2972s / 68.5371 s
agent0:                 episode reward: -0.8445,                 loss: nan
agent1:                 episode reward: 0.8445,                 loss: 0.2862
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3620s / 68.8991 s
agent0:                 episode reward: -0.5268,                 loss: nan
agent1:                 episode reward: 0.5268,                 loss: 0.2829
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3009s / 69.2000 s
agent0:                 episode reward: -0.3984,                 loss: nan
agent1:                 episode reward: 0.3984,                 loss: 0.2822
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2977s / 69.4977 s
agent0:                 episode reward: -0.4471,                 loss: nan
agent1:                 episode reward: 0.4471,                 loss: 0.2847
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2987s / 69.7965 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.2868
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2998s / 70.0962 s
agent0:                 episode reward: -0.6926,                 loss: nan
agent1:                 episode reward: 0.6926,                 loss: 0.2845
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2992s / 70.3954 s
agent0:                 episode reward: -0.8313,                 loss: nan
agent1:                 episode reward: 0.8313,                 loss: 0.2813
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3012s / 70.6967 s
agent0:                 episode reward: -0.9344,                 loss: nan
agent1:                 episode reward: 0.9344,                 loss: 0.2818
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3000s / 70.9966 s
agent0:                 episode reward: -0.6486,                 loss: nan
agent1:                 episode reward: 0.6486,                 loss: 0.2855
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3778s / 71.3745 s
agent0:                 episode reward: -0.8347,                 loss: nan
agent1:                 episode reward: 0.8347,                 loss: 0.2869
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3041s / 71.6786 s
agent0:                 episode reward: -0.8990,                 loss: nan
agent1:                 episode reward: 0.8990,                 loss: 0.2845
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3289s / 72.0075 s
agent0:                 episode reward: -0.7523,                 loss: nan
agent1:                 episode reward: 0.7523,                 loss: 0.2829
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3060s / 72.3134 s
agent0:                 episode reward: -0.6480,                 loss: nan
agent1:                 episode reward: 0.6480,                 loss: 0.2881
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3062s / 72.6197 s
agent0:                 episode reward: -0.7762,                 loss: nan
agent1:                 episode reward: 0.7762,                 loss: 0.2853
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2987s / 72.9183 s
agent0:                 episode reward: -0.4071,                 loss: nan
agent1:                 episode reward: 0.4071,                 loss: 0.2821
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3018s / 73.2201 s
agent0:                 episode reward: -0.8688,                 loss: nan
agent1:                 episode reward: 0.8688,                 loss: 0.2824
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3028s / 73.5229 s
agent0:                 episode reward: -0.7564,                 loss: nan
agent1:                 episode reward: 0.7564,                 loss: 0.2833
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2979s / 73.8208 s
agent0:                 episode reward: -0.4135,                 loss: nan
agent1:                 episode reward: 0.4135,                 loss: 0.2790
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2976s / 74.1184 s
agent0:                 episode reward: -0.4228,                 loss: nan
agent1:                 episode reward: 0.4228,                 loss: 0.2846
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2996s / 74.4180 s
agent0:                 episode reward: -0.5762,                 loss: nan
agent1:                 episode reward: 0.5762,                 loss: 0.2828
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3033s / 74.7213 s
agent0:                 episode reward: -0.7022,                 loss: nan
agent1:                 episode reward: 0.7022,                 loss: 0.2800
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 75.0319 s
agent0:                 episode reward: -0.9837,                 loss: nan
agent1:                 episode reward: 0.9837,                 loss: 0.2809
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3104s / 75.3424 s
agent0:                 episode reward: -0.7446,                 loss: nan
agent1:                 episode reward: 0.7446,                 loss: 0.2811
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3079s / 75.6503 s
agent0:                 episode reward: -0.4298,                 loss: nan
agent1:                 episode reward: 0.4298,                 loss: 0.2833
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3037s / 75.9540 s
agent0:                 episode reward: -0.8146,                 loss: nan
agent1:                 episode reward: 0.8146,                 loss: 0.2803
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3066s / 76.2606 s
agent0:                 episode reward: -0.2948,                 loss: nan
agent1:                 episode reward: 0.2948,                 loss: 0.2845
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3072s / 76.5678 s
agent0:                 episode reward: -0.2273,                 loss: nan
agent1:                 episode reward: 0.2273,                 loss: 0.2835
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3008s / 76.8686 s
agent0:                 episode reward: -0.8542,                 loss: nan
agent1:                 episode reward: 0.8542,                 loss: 0.2835
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3068s / 77.1753 s
agent0:                 episode reward: -0.5969,                 loss: nan
agent1:                 episode reward: 0.5969,                 loss: 0.2851
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3054s / 77.4807 s
agent0:                 episode reward: -0.8878,                 loss: nan
agent1:                 episode reward: 0.8878,                 loss: 0.2748
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3100s / 77.7907 s
agent0:                 episode reward: -0.8317,                 loss: nan
agent1:                 episode reward: 0.8317,                 loss: 0.2720
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3296s / 78.1204 s
agent0:                 episode reward: -0.7358,                 loss: nan
agent1:                 episode reward: 0.7358,                 loss: 0.2754
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3011s / 78.4214 s
agent0:                 episode reward: -0.6484,                 loss: nan
agent1:                 episode reward: 0.6484,                 loss: 0.2733
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3063s / 78.7278 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.2755
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4039s / 79.1317 s
agent0:                 episode reward: -0.5187,                 loss: nan
agent1:                 episode reward: 0.5187,                 loss: 0.2756
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 79.4582 s
agent0:                 episode reward: -0.4212,                 loss: nan
agent1:                 episode reward: 0.4212,                 loss: 0.2744
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 79.7719 s
agent0:                 episode reward: -0.6570,                 loss: nan
agent1:                 episode reward: 0.6570,                 loss: 0.2716
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3100s / 80.0820 s
agent0:                 episode reward: -0.6179,                 loss: nan
agent1:                 episode reward: 0.6179,                 loss: 0.2743
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3102s / 80.3922 s
agent0:                 episode reward: -0.4521,                 loss: nan
agent1:                 episode reward: 0.4521,                 loss: 0.2737
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3108s / 80.7030 s
agent0:                 episode reward: -0.7294,                 loss: nan
agent1:                 episode reward: 0.7294,                 loss: 0.2734
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3175s / 81.0205 s
agent0:                 episode reward: -0.4698,                 loss: nan
agent1:                 episode reward: 0.4698,                 loss: 0.2736
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3116s / 81.3321 s
agent0:                 episode reward: -0.9432,                 loss: nan
agent1:                 episode reward: 0.9432,                 loss: 0.2756
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3057s / 81.6378 s
agent0:                 episode reward: -0.7888,                 loss: nan
agent1:                 episode reward: 0.7888,                 loss: 0.2754
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3093s / 81.9471 s
agent0:                 episode reward: -0.6694,                 loss: nan
agent1:                 episode reward: 0.6694,                 loss: 0.2786
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3093s / 82.2564 s
agent0:                 episode reward: -0.5651,                 loss: nan
agent1:                 episode reward: 0.5651,                 loss: 0.2756
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3101s / 82.5665 s
agent0:                 episode reward: -0.4689,                 loss: nan
agent1:                 episode reward: 0.4689,                 loss: 0.2792
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3106s / 82.8771 s
agent0:                 episode reward: -0.6138,                 loss: nan
agent1:                 episode reward: 0.6138,                 loss: 0.2798
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3155s / 83.1926 s
agent0:                 episode reward: -0.9941,                 loss: nan
agent1:                 episode reward: 0.9941,                 loss: 0.2819
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3085s / 83.5011 s
agent0:                 episode reward: -0.8403,                 loss: nan
agent1:                 episode reward: 0.8403,                 loss: 0.2833
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3109s / 83.8120 s
agent0:                 episode reward: -0.3619,                 loss: nan
agent1:                 episode reward: 0.3619,                 loss: 0.2809
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3230s / 84.1349 s
agent0:                 episode reward: -0.7591,                 loss: nan
agent1:                 episode reward: 0.7591,                 loss: 0.2784
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3071s / 84.4421 s
agent0:                 episode reward: -0.3580,                 loss: nan
agent1:                 episode reward: 0.3580,                 loss: 0.2847
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3098s / 84.7519 s
agent0:                 episode reward: -0.7908,                 loss: nan
agent1:                 episode reward: 0.7908,                 loss: 0.2833
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3136s / 85.0655 s
agent0:                 episode reward: -0.7492,                 loss: nan
agent1:                 episode reward: 0.7492,                 loss: 0.2868
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3091s / 85.3745 s
agent0:                 episode reward: -0.1988,                 loss: nan
agent1:                 episode reward: 0.1988,                 loss: 0.2852
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3123s / 85.6869 s
agent0:                 episode reward: -0.4885,                 loss: nan
agent1:                 episode reward: 0.4885,                 loss: 0.2840
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3643s / 86.0512 s
agent0:                 episode reward: -0.5513,                 loss: nan
agent1:                 episode reward: 0.5513,                 loss: 0.2827
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3162s / 86.3674 s
agent0:                 episode reward: -0.7838,                 loss: nan
agent1:                 episode reward: 0.7838,                 loss: 0.2802
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3122s / 86.6796 s
agent0:                 episode reward: -0.5852,                 loss: nan
agent1:                 episode reward: 0.5852,                 loss: 0.2793
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3248s / 87.0044 s
agent0:                 episode reward: -0.5165,                 loss: nan
agent1:                 episode reward: 0.5165,                 loss: 0.2818
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3191s / 87.3235 s
agent0:                 episode reward: -0.6291,                 loss: nan
agent1:                 episode reward: 0.6291,                 loss: 0.2824
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3179s / 87.6414 s
agent0:                 episode reward: -0.8333,                 loss: nan
agent1:                 episode reward: 0.8333,                 loss: 0.2831
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3314s / 87.9728 s
agent0:                 episode reward: -0.9885,                 loss: nan
agent1:                 episode reward: 0.9885,                 loss: 0.2909
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3249s / 88.2977 s
agent0:                 episode reward: -0.7277,                 loss: nan
agent1:                 episode reward: 0.7277,                 loss: 0.2925
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3168s / 88.6145 s
agent0:                 episode reward: -0.6028,                 loss: nan
agent1:                 episode reward: 0.6028,                 loss: 0.2882
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3153s / 88.9298 s
agent0:                 episode reward: -0.6918,                 loss: nan
agent1:                 episode reward: 0.6918,                 loss: 0.2913
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3809s / 89.3107 s
agent0:                 episode reward: -0.6442,                 loss: nan
agent1:                 episode reward: 0.6442,                 loss: 0.2915
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 89.6285 s
agent0:                 episode reward: -0.7156,                 loss: nan
agent1:                 episode reward: 0.7156,                 loss: 0.2928
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3377s / 89.9662 s
agent0:                 episode reward: -0.7123,                 loss: nan
agent1:                 episode reward: 0.7123,                 loss: 0.2891
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3294s / 90.2956 s
agent0:                 episode reward: -0.8600,                 loss: nan
agent1:                 episode reward: 0.8600,                 loss: 0.2893
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3207s / 90.6163 s
agent0:                 episode reward: -0.6955,                 loss: nan
agent1:                 episode reward: 0.6955,                 loss: 0.2896
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3195s / 90.9358 s
agent0:                 episode reward: -0.7328,                 loss: nan
agent1:                 episode reward: 0.7328,                 loss: 0.2899
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3260s / 91.2619 s
agent0:                 episode reward: -0.6538,                 loss: nan
agent1:                 episode reward: 0.6538,                 loss: 0.2891
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3180s / 91.5799 s
agent0:                 episode reward: -0.7180,                 loss: nan
agent1:                 episode reward: 0.7180,                 loss: 0.2902
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3166s / 91.8965 s
agent0:                 episode reward: -0.5148,                 loss: nan
agent1:                 episode reward: 0.5148,                 loss: 0.2934
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 92.2199 s
agent0:                 episode reward: -1.0959,                 loss: nan
agent1:                 episode reward: 1.0959,                 loss: 0.2913
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 92.5444 s
agent0:                 episode reward: -0.6743,                 loss: nan
agent1:                 episode reward: 0.6743,                 loss: 0.2909
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3232s / 92.8676 s
agent0:                 episode reward: -0.7916,                 loss: nan
agent1:                 episode reward: 0.7916,                 loss: 0.2913
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3325s / 93.2001 s
agent0:                 episode reward: -0.8592,                 loss: nan
agent1:                 episode reward: 0.8592,                 loss: 0.2899
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3198s / 93.5200 s
agent0:                 episode reward: -0.9175,                 loss: nan
agent1:                 episode reward: 0.9175,                 loss: 0.2729
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3217s / 93.8417 s
agent0:                 episode reward: -0.3357,                 loss: nan
agent1:                 episode reward: 0.3357,                 loss: 0.2707
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3206s / 94.1622 s
agent0:                 episode reward: -0.8567,                 loss: nan
agent1:                 episode reward: 0.8567,                 loss: 0.2721
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3254s / 94.4876 s
agent0:                 episode reward: -0.6835,                 loss: nan
agent1:                 episode reward: 0.6835,                 loss: 0.2683
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 94.8107 s
agent0:                 episode reward: -0.6490,                 loss: nan
agent1:                 episode reward: 0.6490,                 loss: 0.2694
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3214s / 95.1322 s
agent0:                 episode reward: -0.3015,                 loss: nan
agent1:                 episode reward: 0.3015,                 loss: 0.2712
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3206s / 95.4527 s
agent0:                 episode reward: -0.8944,                 loss: nan
agent1:                 episode reward: 0.8944,                 loss: 0.2725
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3202s / 95.7729 s
agent0:                 episode reward: -0.7423,                 loss: nan
agent1:                 episode reward: 0.7423,                 loss: 0.2725
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3571s / 96.1300 s
agent0:                 episode reward: -0.3898,                 loss: nan
agent1:                 episode reward: 0.3898,                 loss: 0.2704
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3203s / 96.4503 s
agent0:                 episode reward: -0.7808,                 loss: nan
agent1:                 episode reward: 0.7808,                 loss: 0.2707
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 96.7738 s
agent0:                 episode reward: -0.6770,                 loss: nan
agent1:                 episode reward: 0.6770,                 loss: 0.2709
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3249s / 97.0987 s
agent0:                 episode reward: -0.5296,                 loss: nan
agent1:                 episode reward: 0.5296,                 loss: 0.2775
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3286s / 97.4273 s
agent0:                 episode reward: -0.7183,                 loss: nan
agent1:                 episode reward: 0.7183,                 loss: 0.2734
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3324s / 97.7597 s
agent0:                 episode reward: -0.7809,                 loss: nan
agent1:                 episode reward: 0.7809,                 loss: 0.2735
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3315s / 98.0912 s
agent0:                 episode reward: -0.8190,                 loss: nan
agent1:                 episode reward: 0.8190,                 loss: 0.2733
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3415s / 98.4327 s
agent0:                 episode reward: -0.9859,                 loss: nan
agent1:                 episode reward: 0.9859,                 loss: 0.2759
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 98.7644 s
agent0:                 episode reward: -1.1613,                 loss: nan
agent1:                 episode reward: 1.1613,                 loss: 0.2812
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3356s / 99.1000 s
agent0:                 episode reward: -0.5272,                 loss: nan
agent1:                 episode reward: 0.5272,                 loss: 0.2826
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3763s / 99.4763 s
agent0:                 episode reward: -0.8979,                 loss: nan
agent1:                 episode reward: 0.8979,                 loss: 0.2828
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3352s / 99.8115 s
agent0:                 episode reward: -1.1047,                 loss: nan
agent1:                 episode reward: 1.1047,                 loss: 0.2824
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3288s / 100.1403 s
agent0:                 episode reward: -0.7613,                 loss: nan
agent1:                 episode reward: 0.7613,                 loss: 0.2876
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3289s / 100.4692 s
agent0:                 episode reward: -0.5981,                 loss: nan
agent1:                 episode reward: 0.5981,                 loss: 0.2817
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3269s / 100.7961 s
agent0:                 episode reward: -1.0862,                 loss: nan
agent1:                 episode reward: 1.0862,                 loss: 0.2831
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3258s / 101.1219 s
agent0:                 episode reward: -0.8387,                 loss: nan
agent1:                 episode reward: 0.8387,                 loss: 0.2828
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3252s / 101.4472 s
agent0:                 episode reward: -0.5141,                 loss: nan
agent1:                 episode reward: 0.5141,                 loss: 0.2802
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3251s / 101.7723 s
agent0:                 episode reward: -0.8152,                 loss: nan
agent1:                 episode reward: 0.8152,                 loss: 0.2793
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3405s / 102.1128 s
agent0:                 episode reward: -0.3482,                 loss: nan
agent1:                 episode reward: 0.3482,                 loss: 0.2826
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3233s / 102.4361 s
agent0:                 episode reward: -0.9469,                 loss: nan
agent1:                 episode reward: 0.9469,                 loss: 0.2794
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 102.7596 s
agent0:                 episode reward: -0.7626,                 loss: nan
agent1:                 episode reward: 0.7626,                 loss: 0.2786
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3304s / 103.0900 s
agent0:                 episode reward: -0.7509,                 loss: nan
agent1:                 episode reward: 0.7509,                 loss: 0.2806
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3233s / 103.4133 s
agent0:                 episode reward: -0.4728,                 loss: nan
agent1:                 episode reward: 0.4728,                 loss: 0.2822
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3289s / 103.7422 s
agent0:                 episode reward: -1.0556,                 loss: nan
agent1:                 episode reward: 1.0556,                 loss: 0.2830
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3303s / 104.0725 s
agent0:                 episode reward: -0.3925,                 loss: nan
agent1:                 episode reward: 0.3925,                 loss: 0.2805
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3466s / 104.4191 s
agent0:                 episode reward: -0.4247,                 loss: nan
agent1:                 episode reward: 0.4247,                 loss: 0.2873
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3346s / 104.7537 s
agent0:                 episode reward: -0.8702,                 loss: nan
agent1:                 episode reward: 0.8702,                 loss: 0.2881
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3380s / 105.0916 s
agent0:                 episode reward: -1.0004,                 loss: nan
agent1:                 episode reward: 1.0004,                 loss: 0.2890
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3312s / 105.4228 s
agent0:                 episode reward: -1.2248,                 loss: nan
agent1:                 episode reward: 1.2248,                 loss: 0.2887
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3368s / 105.7596 s
agent0:                 episode reward: -0.8250,                 loss: nan
agent1:                 episode reward: 0.8250,                 loss: 0.2844
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3261s / 106.0857 s
agent0:                 episode reward: -0.9968,                 loss: nan
agent1:                 episode reward: 0.9968,                 loss: 0.2860
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 106.4122 s
agent0:                 episode reward: -0.9021,                 loss: nan
agent1:                 episode reward: 0.9021,                 loss: 0.2868
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3320s / 106.7442 s
agent0:                 episode reward: -0.7441,                 loss: nan
agent1:                 episode reward: 0.7441,                 loss: 0.2874
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3284s / 107.0726 s
agent0:                 episode reward: -0.9484,                 loss: nan
agent1:                 episode reward: 0.9484,                 loss: 0.2886
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3314s / 107.4039 s
agent0:                 episode reward: -0.8881,                 loss: nan
agent1:                 episode reward: 0.8881,                 loss: 0.2911
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3330s / 107.7369 s
agent0:                 episode reward: -0.6610,                 loss: nan
agent1:                 episode reward: 0.6610,                 loss: 0.2866
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3475s / 108.0844 s
agent0:                 episode reward: -0.5095,                 loss: nan
agent1:                 episode reward: 0.5095,                 loss: 0.2888
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3460s / 108.4304 s
agent0:                 episode reward: -1.0351,                 loss: nan
agent1:                 episode reward: 1.0351,                 loss: 0.2911
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3420s / 108.7724 s
agent0:                 episode reward: -0.5984,                 loss: nan
agent1:                 episode reward: 0.5984,                 loss: 0.2886
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3341s / 109.1065 s
agent0:                 episode reward: -0.6562,                 loss: nan
agent1:                 episode reward: 0.6562,                 loss: 0.2869
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3332s / 109.4398 s
agent0:                 episode reward: -0.6840,                 loss: nan
agent1:                 episode reward: 0.6840,                 loss: 0.2879
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3787s / 109.8185 s
agent0:                 episode reward: -0.8169,                 loss: nan
agent1:                 episode reward: 0.8169,                 loss: 0.2868
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3612s / 110.1797 s
agent0:                 episode reward: -0.5981,                 loss: nan
agent1:                 episode reward: 0.5981,                 loss: 0.2809
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3319s / 110.5115 s
agent0:                 episode reward: -0.6683,                 loss: nan
agent1:                 episode reward: 0.6683,                 loss: 0.2784
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3329s / 110.8445 s
agent0:                 episode reward: -0.7224,                 loss: nan
agent1:                 episode reward: 0.7224,                 loss: 0.2786
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3493s / 111.1937 s
agent0:                 episode reward: -0.6779,                 loss: nan
agent1:                 episode reward: 0.6779,                 loss: 0.2761
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3341s / 111.5278 s
agent0:                 episode reward: -0.6738,                 loss: nan
agent1:                 episode reward: 0.6738,                 loss: 0.2774
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3352s / 111.8630 s
agent0:                 episode reward: -0.5836,                 loss: nan
agent1:                 episode reward: 0.5836,                 loss: 0.2798
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3420s / 112.2050 s
agent0:                 episode reward: -0.8087,                 loss: nan
agent1:                 episode reward: 0.8087,                 loss: 0.2806
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3348s / 112.5398 s
agent0:                 episode reward: -0.4416,                 loss: nan
agent1:                 episode reward: 0.4416,                 loss: 0.2771
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3493s / 112.8891 s
agent0:                 episode reward: -1.0058,                 loss: nan
agent1:                 episode reward: 1.0058,                 loss: 0.2753
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 113.2207 s
agent0:                 episode reward: -0.8393,                 loss: nan
agent1:                 episode reward: 0.8393,                 loss: 0.2788
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3361s / 113.5568 s
agent0:                 episode reward: -1.0985,                 loss: nan
agent1:                 episode reward: 1.0985,                 loss: 0.2775
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3324s / 113.8892 s
agent0:                 episode reward: -0.7008,                 loss: nan
agent1:                 episode reward: 0.7008,                 loss: 0.2748
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3405s / 114.2297 s
agent0:                 episode reward: -0.7285,                 loss: nan
agent1:                 episode reward: 0.7285,                 loss: 0.2810
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3358s / 114.5656 s
agent0:                 episode reward: -0.9554,                 loss: nan
agent1:                 episode reward: 0.9554,                 loss: 0.2788
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3332s / 114.8987 s
agent0:                 episode reward: -0.2857,                 loss: nan
agent1:                 episode reward: 0.2857,                 loss: 0.2746
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3349s / 115.2337 s
agent0:                 episode reward: -0.8204,                 loss: nan
agent1:                 episode reward: 0.8204,                 loss: 0.2804
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3342s / 115.5679 s
agent0:                 episode reward: -0.6892,                 loss: nan
agent1:                 episode reward: 0.6892,                 loss: 0.2835
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3342s / 115.9021 s
agent0:                 episode reward: -0.4084,                 loss: nan
agent1:                 episode reward: 0.4084,                 loss: 0.2889
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3348s / 116.2369 s
agent0:                 episode reward: -0.9277,                 loss: nan
agent1:                 episode reward: 0.9277,                 loss: 0.2876
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3342s / 116.5711 s
agent0:                 episode reward: -1.3390,                 loss: nan
agent1:                 episode reward: 1.3390,                 loss: 0.2906
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3365s / 116.9075 s
agent0:                 episode reward: -1.0441,                 loss: nan
agent1:                 episode reward: 1.0441,                 loss: 0.2887
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3561s / 117.2636 s
agent0:                 episode reward: -0.6174,                 loss: nan
agent1:                 episode reward: 0.6174,                 loss: 0.2852
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3423s / 117.6059 s
agent0:                 episode reward: -1.0329,                 loss: nan
agent1:                 episode reward: 1.0329,                 loss: 0.2882
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3391s / 117.9449 s
agent0:                 episode reward: -0.7902,                 loss: nan
agent1:                 episode reward: 0.7902,                 loss: 0.2861
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3357s / 118.2806 s
agent0:                 episode reward: -0.8313,                 loss: nan
agent1:                 episode reward: 0.8313,                 loss: 0.2881
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3511s / 118.6317 s
agent0:                 episode reward: -1.0458,                 loss: nan
agent1:                 episode reward: 1.0458,                 loss: 0.2877
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3377s / 118.9694 s
agent0:                 episode reward: -0.8504,                 loss: nan
agent1:                 episode reward: 0.8504,                 loss: 0.2862
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3397s / 119.3091 s
agent0:                 episode reward: -0.7535,                 loss: nan
agent1:                 episode reward: 0.7535,                 loss: 0.2863
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3408s / 119.6499 s
agent0:                 episode reward: -0.9636,                 loss: nan
agent1:                 episode reward: 0.9636,                 loss: 0.2869
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3945s / 120.0444 s
agent0:                 episode reward: -0.4302,                 loss: nan
agent1:                 episode reward: 0.4302,                 loss: 0.2861
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3525s / 120.3968 s
agent0:                 episode reward: -0.7671,                 loss: nan
agent1:                 episode reward: 0.7671,                 loss: 0.2877
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3439s / 120.7407 s
agent0:                 episode reward: -0.8732,                 loss: nan
agent1:                 episode reward: 0.8732,                 loss: 0.2880
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3668s / 121.1075 s
agent0:                 episode reward: -0.5988,                 loss: nan
agent1:                 episode reward: 0.5988,                 loss: 0.2867
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3646s / 121.4721 s
agent0:                 episode reward: -0.6504,                 loss: nan
agent1:                 episode reward: 0.6504,                 loss: 0.2802
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3404s / 121.8125 s
agent0:                 episode reward: -0.9431,                 loss: nan
agent1:                 episode reward: 0.9431,                 loss: 0.2757
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3465s / 122.1590 s
agent0:                 episode reward: -0.4224,                 loss: nan
agent1:                 episode reward: 0.4224,                 loss: 0.2733
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3531s / 122.5121 s
agent0:                 episode reward: -0.9005,                 loss: nan
agent1:                 episode reward: 0.9005,                 loss: 0.2705
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3429s / 122.8550 s
agent0:                 episode reward: -0.6440,                 loss: nan
agent1:                 episode reward: 0.6440,                 loss: 0.2769
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3562s / 123.2112 s
agent0:                 episode reward: -1.0606,                 loss: nan
agent1:                 episode reward: 1.0606,                 loss: 0.2746
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3442s / 123.5553 s
agent0:                 episode reward: -0.5655,                 loss: nan
agent1:                 episode reward: 0.5655,                 loss: 0.2767
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3415s / 123.8968 s
agent0:                 episode reward: -0.7822,                 loss: nan
agent1:                 episode reward: 0.7822,                 loss: 0.2780
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3476s / 124.2444 s
agent0:                 episode reward: -0.5748,                 loss: nan
agent1:                 episode reward: 0.5748,                 loss: 0.2735
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3483s / 124.5927 s
agent0:                 episode reward: -0.6111,                 loss: nan
agent1:                 episode reward: 0.6111,                 loss: 0.2760
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3457s / 124.9384 s
agent0:                 episode reward: -0.6534,                 loss: nan
agent1:                 episode reward: 0.6534,                 loss: 0.2762
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3493s / 125.2877 s
agent0:                 episode reward: -0.8815,                 loss: nan
agent1:                 episode reward: 0.8815,                 loss: 0.2740
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3519s / 125.6396 s
agent0:                 episode reward: -0.7779,                 loss: nan
agent1:                 episode reward: 0.7779,                 loss: 0.2738
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3508s / 125.9904 s
agent0:                 episode reward: -0.8154,                 loss: nan
agent1:                 episode reward: 0.8154,                 loss: 0.2722
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3734s / 126.3638 s
agent0:                 episode reward: -0.8712,                 loss: nan
agent1:                 episode reward: 0.8712,                 loss: 0.2733
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3510s / 126.7148 s
agent0:                 episode reward: -0.7151,                 loss: nan
agent1:                 episode reward: 0.7151,                 loss: 0.2730
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3511s / 127.0658 s
agent0:                 episode reward: -0.8092,                 loss: nan
agent1:                 episode reward: 0.8092,                 loss: 0.2748
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3482s / 127.4141 s
agent0:                 episode reward: -0.6410,                 loss: nan
agent1:                 episode reward: 0.6410,                 loss: 0.2854
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3491s / 127.7631 s
agent0:                 episode reward: -1.1559,                 loss: nan
agent1:                 episode reward: 1.1559,                 loss: 0.2874
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3453s / 128.1085 s
agent0:                 episode reward: -0.7781,                 loss: nan
agent1:                 episode reward: 0.7781,                 loss: 0.2860
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3467s / 128.4552 s
agent0:                 episode reward: -1.0497,                 loss: nan
agent1:                 episode reward: 1.0497,                 loss: 0.2873
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3625s / 128.8177 s
agent0:                 episode reward: -0.6536,                 loss: nan
agent1:                 episode reward: 0.6536,                 loss: 0.2870
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3638s / 129.1815 s
agent0:                 episode reward: -0.6121,                 loss: nan
agent1:                 episode reward: 0.6121,                 loss: 0.2909
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3523s / 129.5338 s
agent0:                 episode reward: -0.7476,                 loss: nan
agent1:                 episode reward: 0.7476,                 loss: 0.2892
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3497s / 129.8835 s
agent0:                 episode reward: -0.5363,                 loss: nan
agent1:                 episode reward: 0.5363,                 loss: 0.2903
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4051s / 130.2886 s
agent0:                 episode reward: -0.5921,                 loss: nan
agent1:                 episode reward: 0.5921,                 loss: 0.2886
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3518s / 130.6404 s
agent0:                 episode reward: -0.8218,                 loss: nan
agent1:                 episode reward: 0.8218,                 loss: 0.2898
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3538s / 130.9943 s
agent0:                 episode reward: -0.8834,                 loss: nan
agent1:                 episode reward: 0.8834,                 loss: 0.2888
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3517s / 131.3460 s
agent0:                 episode reward: -0.5460,                 loss: nan
agent1:                 episode reward: 0.5460,                 loss: 0.2865
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3490s / 131.6949 s
agent0:                 episode reward: -0.7074,                 loss: nan
agent1:                 episode reward: 0.7074,                 loss: 0.2899
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3515s / 132.0465 s
agent0:                 episode reward: -0.7237,                 loss: nan
agent1:                 episode reward: 0.7237,                 loss: 0.2924
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3511s / 132.3976 s
agent0:                 episode reward: -0.4099,                 loss: nan
agent1:                 episode reward: 0.4099,                 loss: 0.2848
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3507s / 132.7482 s
agent0:                 episode reward: -0.3787,                 loss: nan
agent1:                 episode reward: 0.3787,                 loss: 0.2869
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3520s / 133.1002 s
agent0:                 episode reward: -1.0494,                 loss: nan
agent1:                 episode reward: 1.0494,                 loss: 0.2866
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3548s / 133.4550 s
agent0:                 episode reward: -0.4990,                 loss: nan
agent1:                 episode reward: 0.4990,                 loss: 0.2818
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3759s / 133.8309 s
agent0:                 episode reward: -0.7344,                 loss: nan
agent1:                 episode reward: 0.7344,                 loss: 0.2853
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3473s / 134.1783 s
agent0:                 episode reward: -0.5542,                 loss: nan
agent1:                 episode reward: 0.5542,                 loss: 0.2830
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3544s / 134.5327 s
agent0:                 episode reward: -0.5985,                 loss: nan
agent1:                 episode reward: 0.5985,                 loss: 0.2831
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3565s / 134.8892 s
agent0:                 episode reward: -0.7597,                 loss: nan
agent1:                 episode reward: 0.7597,                 loss: 0.2833
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3605s / 135.2497 s
agent0:                 episode reward: -0.5051,                 loss: nan
agent1:                 episode reward: 0.5051,                 loss: 0.2855
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3601s / 135.6098 s
agent0:                 episode reward: -1.1240,                 loss: nan
agent1:                 episode reward: 1.1240,                 loss: 0.2841
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3535s / 135.9633 s
agent0:                 episode reward: -0.4943,                 loss: nan
agent1:                 episode reward: 0.4943,                 loss: 0.2831
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3496s / 136.3129 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.2828
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3586s / 136.6715 s
agent0:                 episode reward: -1.2111,                 loss: nan
agent1:                 episode reward: 1.2111,                 loss: 0.2856
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3504s / 137.0219 s
agent0:                 episode reward: -1.1272,                 loss: nan
agent1:                 episode reward: 1.1272,                 loss: 0.2824
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3522s / 137.3741 s
agent0:                 episode reward: -0.5032,                 loss: nan
agent1:                 episode reward: 0.5032,                 loss: 0.2812
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3781s / 137.7522 s
agent0:                 episode reward: -1.1194,                 loss: nan
agent1:                 episode reward: 1.1194,                 loss: 0.2872
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3577s / 138.1099 s
agent0:                 episode reward: -0.7977,                 loss: nan
agent1:                 episode reward: 0.7977,                 loss: 0.2857
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3494s / 138.4594 s
agent0:                 episode reward: -0.7310,                 loss: nan
agent1:                 episode reward: 0.7310,                 loss: 0.2856
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3563s / 138.8156 s
agent0:                 episode reward: -0.7734,                 loss: nan
agent1:                 episode reward: 0.7734,                 loss: 0.2822
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3678s / 139.1834 s
agent0:                 episode reward: -0.4727,                 loss: nan
agent1:                 episode reward: 0.4727,                 loss: 0.2838
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3549s / 139.5384 s
agent0:                 episode reward: -0.9113,                 loss: nan
agent1:                 episode reward: 0.9113,                 loss: 0.2827
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3507s / 139.8890 s
agent0:                 episode reward: -1.1257,                 loss: nan
agent1:                 episode reward: 1.1257,                 loss: 0.2835
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3509s / 140.2399 s
agent0:                 episode reward: -0.6958,                 loss: nan
agent1:                 episode reward: 0.6958,                 loss: 0.2812
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4072s / 140.6471 s
agent0:                 episode reward: -0.7887,                 loss: nan
agent1:                 episode reward: 0.7887,                 loss: 0.2839
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3610s / 141.0081 s
agent0:                 episode reward: -0.7921,                 loss: nan
agent1:                 episode reward: 0.7921,                 loss: 0.2824
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3638s / 141.3719 s
agent0:                 episode reward: -0.8216,                 loss: nan
agent1:                 episode reward: 0.8216,                 loss: 0.2816
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3568s / 141.7287 s
agent0:                 episode reward: -0.8366,                 loss: nan
agent1:                 episode reward: 0.8366,                 loss: 0.2823
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3570s / 142.0857 s
agent0:                 episode reward: -0.9395,                 loss: nan
agent1:                 episode reward: 0.9395,                 loss: 0.2806
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3856s / 142.4713 s
agent0:                 episode reward: -0.3797,                 loss: nan
agent1:                 episode reward: 0.3797,                 loss: 0.2841
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3645s / 142.8358 s
agent0:                 episode reward: -0.6873,                 loss: nan
agent1:                 episode reward: 0.6873,                 loss: 0.2845
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3597s / 143.1955 s
agent0:                 episode reward: -0.5749,                 loss: nan
agent1:                 episode reward: 0.5749,                 loss: 0.2825
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3519s / 143.5474 s
agent0:                 episode reward: -0.9198,                 loss: nan
agent1:                 episode reward: 0.9198,                 loss: 0.2808
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3546s / 143.9020 s
agent0:                 episode reward: -0.8963,                 loss: nan
agent1:                 episode reward: 0.8963,                 loss: 0.2854
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3570s / 144.2589 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.2830
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3551s / 144.6140 s
agent0:                 episode reward: -0.3414,                 loss: nan
agent1:                 episode reward: 0.3414,                 loss: 0.2808
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3597s / 144.9737 s
agent0:                 episode reward: -0.4950,                 loss: nan
agent1:                 episode reward: 0.4950,                 loss: 0.2852
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3582s / 145.3319 s
agent0:                 episode reward: -1.1305,                 loss: nan
agent1:                 episode reward: 1.1305,                 loss: 0.2906
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3572s / 145.6892 s
agent0:                 episode reward: -0.6391,                 loss: nan
agent1:                 episode reward: 0.6391,                 loss: 0.2920
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3824s / 146.0716 s
agent0:                 episode reward: -0.7621,                 loss: nan
agent1:                 episode reward: 0.7621,                 loss: 0.2903
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3574s / 146.4290 s
agent0:                 episode reward: -0.8655,                 loss: nan
agent1:                 episode reward: 0.8655,                 loss: 0.2925
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3678s / 146.7968 s
agent0:                 episode reward: -0.7849,                 loss: nan
agent1:                 episode reward: 0.7849,                 loss: 0.2913
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3854s / 147.1822 s
agent0:                 episode reward: -0.7705,                 loss: nan
agent1:                 episode reward: 0.7705,                 loss: 0.2892
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3618s / 147.5440 s
agent0:                 episode reward: -0.8808,                 loss: nan
agent1:                 episode reward: 0.8808,                 loss: 0.2915
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3620s / 147.9060 s
agent0:                 episode reward: -1.0941,                 loss: nan
agent1:                 episode reward: 1.0941,                 loss: 0.2928
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3650s / 148.2710 s
agent0:                 episode reward: -0.9084,                 loss: nan
agent1:                 episode reward: 0.9084,                 loss: 0.2879
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3693s / 148.6404 s
agent0:                 episode reward: -0.5228,                 loss: nan
agent1:                 episode reward: 0.5228,                 loss: 0.2919
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3690s / 149.0094 s
agent0:                 episode reward: -0.9866,                 loss: nan
agent1:                 episode reward: 0.9866,                 loss: 0.2905
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3624s / 149.3718 s
agent0:                 episode reward: -0.8250,                 loss: nan
agent1:                 episode reward: 0.8250,                 loss: 0.2866
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3640s / 149.7358 s
agent0:                 episode reward: -0.8428,                 loss: nan
agent1:                 episode reward: 0.8428,                 loss: 0.2897
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3840s / 150.1198 s
agent0:                 episode reward: -1.0082,                 loss: nan
agent1:                 episode reward: 1.0082,                 loss: 0.2925
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3703s / 150.4902 s
agent0:                 episode reward: -0.9047,                 loss: nan
agent1:                 episode reward: 0.9047,                 loss: 0.2901
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4135s / 150.9037 s
agent0:                 episode reward: -0.8305,                 loss: nan
agent1:                 episode reward: 0.8305,                 loss: 0.2901
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3653s / 151.2690 s
agent0:                 episode reward: -0.9473,                 loss: nan
agent1:                 episode reward: 0.9473,                 loss: 0.2863
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3724s / 151.6415 s
agent0:                 episode reward: -1.0519,                 loss: nan
agent1:                 episode reward: 1.0519,                 loss: 0.2736
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3634s / 152.0049 s
agent0:                 episode reward: -0.9264,                 loss: nan
agent1:                 episode reward: 0.9264,                 loss: 0.2721
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3659s / 152.3708 s
agent0:                 episode reward: -0.8839,                 loss: nan
agent1:                 episode reward: 0.8839,                 loss: 0.2693
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3640s / 152.7348 s
agent0:                 episode reward: -1.0950,                 loss: nan
agent1:                 episode reward: 1.0950,                 loss: 0.2738
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3784s / 153.1132 s
agent0:                 episode reward: -0.9353,                 loss: nan
agent1:                 episode reward: 0.9353,                 loss: 0.2698
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3743s / 153.4875 s
agent0:                 episode reward: -0.6935,                 loss: nan
agent1:                 episode reward: 0.6935,                 loss: 0.2740
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3842s / 153.8717 s
agent0:                 episode reward: -0.6971,                 loss: nan
agent1:                 episode reward: 0.6971,                 loss: 0.2700
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3798s / 154.2515 s
agent0:                 episode reward: -0.7085,                 loss: nan
agent1:                 episode reward: 0.7085,                 loss: 0.2719
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3625s / 154.6140 s
agent0:                 episode reward: -0.7700,                 loss: nan
agent1:                 episode reward: 0.7700,                 loss: 0.2721
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3601s / 154.9741 s
agent0:                 episode reward: -0.4993,                 loss: nan
agent1:                 episode reward: 0.4993,                 loss: 0.2701
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3943s / 155.3684 s
agent0:                 episode reward: -1.0758,                 loss: nan
agent1:                 episode reward: 1.0758,                 loss: 0.2718
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3622s / 155.7306 s
agent0:                 episode reward: -0.5992,                 loss: nan
agent1:                 episode reward: 0.5992,                 loss: 0.2715
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3733s / 156.1039 s
agent0:                 episode reward: -0.2937,                 loss: nan
agent1:                 episode reward: 0.2937,                 loss: 0.2711
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3604s / 156.4642 s
agent0:                 episode reward: -1.0013,                 loss: nan
agent1:                 episode reward: 1.0013,                 loss: 0.2712
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3682s / 156.8325 s
agent0:                 episode reward: -0.4190,                 loss: nan
agent1:                 episode reward: 0.4190,                 loss: 0.2705
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3620s / 157.1945 s
agent0:                 episode reward: -0.7426,                 loss: nan
agent1:                 episode reward: 0.7426,                 loss: 0.2726
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3611s / 157.5556 s
agent0:                 episode reward: -0.4209,                 loss: nan
agent1:                 episode reward: 0.4209,                 loss: 0.2917
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3631s / 157.9187 s
agent0:                 episode reward: -0.6941,                 loss: nan
agent1:                 episode reward: 0.6941,                 loss: 0.2944
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3662s / 158.2849 s
agent0:                 episode reward: -0.9205,                 loss: nan
agent1:                 episode reward: 0.9205,                 loss: 0.2932
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3669s / 158.6518 s
agent0:                 episode reward: -1.1062,                 loss: nan
agent1:                 episode reward: 1.1062,                 loss: 0.2942
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3637s / 159.0155 s
agent0:                 episode reward: -0.8477,                 loss: nan
agent1:                 episode reward: 0.8477,                 loss: 0.2946
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3794s / 159.3949 s
agent0:                 episode reward: -0.9353,                 loss: nan
agent1:                 episode reward: 0.9353,                 loss: 0.2950
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3627s / 159.7576 s
agent0:                 episode reward: -0.9940,                 loss: nan
agent1:                 episode reward: 0.9940,                 loss: 0.2923
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3642s / 160.1218 s
agent0:                 episode reward: -0.7355,                 loss: nan
agent1:                 episode reward: 0.7355,                 loss: 0.2960
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3608s / 160.4826 s
agent0:                 episode reward: -0.6065,                 loss: nan
agent1:                 episode reward: 0.6065,                 loss: 0.2953
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3633s / 160.8460 s
agent0:                 episode reward: -0.6418,                 loss: nan
agent1:                 episode reward: 0.6418,                 loss: 0.2913
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4316s / 161.2775 s
agent0:                 episode reward: -1.0691,                 loss: nan
agent1:                 episode reward: 1.0691,                 loss: 0.2940
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3655s / 161.6431 s
agent0:                 episode reward: -0.9943,                 loss: nan
agent1:                 episode reward: 0.9943,                 loss: 0.2942
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3720s / 162.0151 s
agent0:                 episode reward: -0.9498,                 loss: nan
agent1:                 episode reward: 0.9498,                 loss: 0.2928
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3891s / 162.4042 s
agent0:                 episode reward: -0.3902,                 loss: nan
agent1:                 episode reward: 0.3902,                 loss: 0.2929
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3685s / 162.7727 s
agent0:                 episode reward: -0.7223,                 loss: nan
agent1:                 episode reward: 0.7223,                 loss: 0.2905
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3688s / 163.1414 s
agent0:                 episode reward: -0.6779,                 loss: nan
agent1:                 episode reward: 0.6779,                 loss: 0.2939
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3646s / 163.5061 s
agent0:                 episode reward: -0.8221,                 loss: nan
agent1:                 episode reward: 0.8221,                 loss: 0.2944
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3675s / 163.8736 s
agent0:                 episode reward: -0.8539,                 loss: nan
agent1:                 episode reward: 0.8539,                 loss: 0.2851
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3937s / 164.2673 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.2857
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3725s / 164.6398 s
agent0:                 episode reward: -0.8333,                 loss: nan
agent1:                 episode reward: 0.8333,                 loss: 0.2822
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3688s / 165.0085 s
agent0:                 episode reward: -0.9601,                 loss: nan
agent1:                 episode reward: 0.9601,                 loss: 0.2791
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3849s / 165.3934 s
agent0:                 episode reward: -0.6083,                 loss: nan
agent1:                 episode reward: 0.6083,                 loss: 0.2816
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3773s / 165.7707 s
agent0:                 episode reward: -0.6110,                 loss: nan
agent1:                 episode reward: 0.6110,                 loss: 0.2855
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3716s / 166.1423 s
agent0:                 episode reward: -0.6196,                 loss: nan
agent1:                 episode reward: 0.6196,                 loss: 0.2821
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3672s / 166.5095 s
agent0:                 episode reward: -0.6216,                 loss: nan
agent1:                 episode reward: 0.6216,                 loss: 0.2805
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3724s / 166.8819 s
agent0:                 episode reward: -0.8578,                 loss: nan
agent1:                 episode reward: 0.8578,                 loss: 0.2804
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3725s / 167.2544 s
agent0:                 episode reward: -0.3216,                 loss: nan
agent1:                 episode reward: 0.3216,                 loss: 0.2837
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3756s / 167.6300 s
agent0:                 episode reward: -1.0193,                 loss: nan
agent1:                 episode reward: 1.0193,                 loss: 0.2830
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3711s / 168.0011 s
agent0:                 episode reward: -0.8963,                 loss: nan
agent1:                 episode reward: 0.8963,                 loss: 0.2838
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3724s / 168.3735 s
agent0:                 episode reward: -0.7388,                 loss: nan
agent1:                 episode reward: 0.7388,                 loss: 0.2845
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3735s / 168.7470 s
agent0:                 episode reward: -0.6784,                 loss: nan
agent1:                 episode reward: 0.6784,                 loss: 0.2857
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3720s / 169.1190 s
agent0:                 episode reward: -0.6348,                 loss: nan
agent1:                 episode reward: 0.6348,                 loss: 0.2823
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3805s / 169.4995 s
agent0:                 episode reward: -1.0903,                 loss: nan
agent1:                 episode reward: 1.0903,                 loss: 0.2828
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3792s / 169.8787 s
agent0:                 episode reward: -0.4947,                 loss: nan
agent1:                 episode reward: 0.4947,                 loss: 0.2792
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3801s / 170.2588 s
agent0:                 episode reward: -0.8344,                 loss: nan
agent1:                 episode reward: 0.8344,                 loss: 0.2734
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3917s / 170.6506 s
agent0:                 episode reward: -0.7785,                 loss: nan
agent1:                 episode reward: 0.7785,                 loss: 0.2693
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3982s / 171.0488 s
agent0:                 episode reward: -0.6337,                 loss: nan
agent1:                 episode reward: 0.6337,                 loss: 0.2679
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4285s / 171.4773 s
agent0:                 episode reward: -0.8375,                 loss: nan
agent1:                 episode reward: 0.8375,                 loss: 0.2672
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3980s / 171.8752 s
agent0:                 episode reward: -1.0275,                 loss: nan
agent1:                 episode reward: 1.0275,                 loss: 0.2725
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3784s / 172.2536 s
agent0:                 episode reward: -0.7454,                 loss: nan
agent1:                 episode reward: 0.7454,                 loss: 0.2717
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3747s / 172.6283 s
agent0:                 episode reward: -0.7723,                 loss: nan
agent1:                 episode reward: 0.7723,                 loss: 0.2706
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3823s / 173.0106 s
agent0:                 episode reward: -0.7578,                 loss: nan
agent1:                 episode reward: 0.7578,                 loss: 0.2717
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3771s / 173.3877 s
agent0:                 episode reward: -0.8090,                 loss: nan
agent1:                 episode reward: 0.8090,                 loss: 0.2718
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3812s / 173.7689 s
agent0:                 episode reward: -0.7746,                 loss: nan
agent1:                 episode reward: 0.7746,                 loss: 0.2724
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3831s / 174.1520 s
agent0:                 episode reward: -0.5913,                 loss: nan
agent1:                 episode reward: 0.5913,                 loss: 0.2684
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3806s / 174.5326 s
agent0:                 episode reward: -0.6158,                 loss: nan
agent1:                 episode reward: 0.6158,                 loss: 0.2690
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3756s / 174.9082 s
agent0:                 episode reward: -0.7002,                 loss: nan
agent1:                 episode reward: 0.7002,                 loss: 0.2718
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3821s / 175.2902 s
agent0:                 episode reward: -0.7692,                 loss: nan
agent1:                 episode reward: 0.7692,                 loss: 0.2700
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3747s / 175.6650 s
agent0:                 episode reward: -0.6430,                 loss: nan
agent1:                 episode reward: 0.6430,                 loss: 0.2693
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3838s / 176.0488 s
agent0:                 episode reward: -0.9496,                 loss: nan
agent1:                 episode reward: 0.9496,                 loss: 0.2693
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4078s / 176.4566 s
agent0:                 episode reward: -0.7630,                 loss: nan
agent1:                 episode reward: 0.7630,                 loss: 0.2879
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3827s / 176.8393 s
agent0:                 episode reward: -0.6488,                 loss: nan
agent1:                 episode reward: 0.6488,                 loss: 0.2939
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3889s / 177.2282 s
agent0:                 episode reward: -0.8317,                 loss: nan
agent1:                 episode reward: 0.8317,                 loss: 0.2968
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3879s / 177.6161 s
agent0:                 episode reward: -0.8100,                 loss: nan
agent1:                 episode reward: 0.8100,                 loss: 0.3009
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3806s / 177.9967 s
agent0:                 episode reward: -0.8622,                 loss: nan
agent1:                 episode reward: 0.8622,                 loss: 0.2969
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3778s / 178.3745 s
agent0:                 episode reward: -0.8900,                 loss: nan
agent1:                 episode reward: 0.8900,                 loss: 0.2994
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3836s / 178.7581 s
agent0:                 episode reward: -0.8761,                 loss: nan
agent1:                 episode reward: 0.8761,                 loss: 0.2971
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3984s / 179.1565 s
agent0:                 episode reward: -0.9409,                 loss: nan
agent1:                 episode reward: 0.9409,                 loss: 0.2984
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3895s / 179.5460 s
agent0:                 episode reward: -0.6233,                 loss: nan
agent1:                 episode reward: 0.6233,                 loss: 0.2982
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3819s / 179.9279 s
agent0:                 episode reward: -0.8546,                 loss: nan
agent1:                 episode reward: 0.8546,                 loss: 0.2976
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4105s / 180.3384 s
agent0:                 episode reward: -0.7822,                 loss: nan
agent1:                 episode reward: 0.7822,                 loss: 0.2955
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3845s / 180.7229 s
agent0:                 episode reward: -0.8739,                 loss: nan
agent1:                 episode reward: 0.8739,                 loss: 0.2958
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3878s / 181.1107 s
agent0:                 episode reward: -0.7933,                 loss: nan
agent1:                 episode reward: 0.7933,                 loss: 0.2994
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4315s / 181.5421 s
agent0:                 episode reward: -0.9879,                 loss: nan
agent1:                 episode reward: 0.9879,                 loss: 0.2979
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3853s / 181.9274 s
agent0:                 episode reward: -0.7058,                 loss: nan
agent1:                 episode reward: 0.7058,                 loss: 0.3000
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3890s / 182.3165 s
agent0:                 episode reward: -1.1817,                 loss: nan
agent1:                 episode reward: 1.1817,                 loss: 0.2940
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3816s / 182.6980 s
agent0:                 episode reward: -0.9846,                 loss: nan
agent1:                 episode reward: 0.9846,                 loss: 0.2969
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3952s / 183.0932 s
agent0:                 episode reward: -0.8181,                 loss: nan
agent1:                 episode reward: 0.8181,                 loss: 0.2819
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3840s / 183.4772 s
agent0:                 episode reward: -0.6811,                 loss: nan
agent1:                 episode reward: 0.6811,                 loss: 0.2843
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3964s / 183.8736 s
agent0:                 episode reward: -0.7746,                 loss: nan
agent1:                 episode reward: 0.7746,                 loss: 0.2836
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3864s / 184.2600 s
agent0:                 episode reward: -1.1774,                 loss: nan
agent1:                 episode reward: 1.1774,                 loss: 0.2821
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3925s / 184.6525 s
agent0:                 episode reward: -0.8641,                 loss: nan
agent1:                 episode reward: 0.8641,                 loss: 0.2831
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3845s / 185.0370 s
agent0:                 episode reward: -0.9191,                 loss: nan
agent1:                 episode reward: 0.9191,                 loss: 0.2824
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3902s / 185.4272 s
agent0:                 episode reward: -0.6688,                 loss: nan
agent1:                 episode reward: 0.6688,                 loss: 0.2810
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3831s / 185.8103 s
agent0:                 episode reward: -0.4611,                 loss: nan
agent1:                 episode reward: 0.4611,                 loss: 0.2814
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3970s / 186.2073 s
agent0:                 episode reward: -0.9702,                 loss: nan
agent1:                 episode reward: 0.9702,                 loss: 0.2813
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4030s / 186.6104 s
agent0:                 episode reward: -0.6015,                 loss: nan
agent1:                 episode reward: 0.6015,                 loss: 0.2814
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3910s / 187.0014 s
agent0:                 episode reward: -1.0596,                 loss: nan
agent1:                 episode reward: 1.0596,                 loss: 0.2844
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4036s / 187.4050 s
agent0:                 episode reward: -0.2147,                 loss: nan
agent1:                 episode reward: 0.2147,                 loss: 0.2812
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3941s / 187.7991 s
agent0:                 episode reward: -0.7128,                 loss: nan
agent1:                 episode reward: 0.7128,                 loss: 0.2820
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3893s / 188.1883 s
agent0:                 episode reward: -0.5993,                 loss: nan
agent1:                 episode reward: 0.5993,                 loss: 0.2848
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3929s / 188.5813 s
agent0:                 episode reward: -0.5894,                 loss: nan
agent1:                 episode reward: 0.5894,                 loss: 0.2826
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3902s / 188.9714 s
agent0:                 episode reward: -1.0725,                 loss: nan
agent1:                 episode reward: 1.0725,                 loss: 0.2823
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4159s / 189.3874 s
agent0:                 episode reward: -0.6807,                 loss: nan
agent1:                 episode reward: 0.6807,                 loss: 0.2821
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3975s / 189.7848 s
agent0:                 episode reward: -0.6001,                 loss: nan
agent1:                 episode reward: 0.6001,                 loss: 0.2727
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3939s / 190.1787 s
agent0:                 episode reward: -1.0492,                 loss: nan
agent1:                 episode reward: 1.0492,                 loss: 0.2736
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3907s / 190.5694 s
agent0:                 episode reward: -0.4034,                 loss: nan
agent1:                 episode reward: 0.4034,                 loss: 0.2739
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3901s / 190.9596 s
agent0:                 episode reward: -0.4661,                 loss: nan
agent1:                 episode reward: 0.4661,                 loss: 0.2754
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3941s / 191.3537 s
agent0:                 episode reward: -0.9001,                 loss: nan
agent1:                 episode reward: 0.9001,                 loss: 0.2707
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4302s / 191.7838 s
agent0:                 episode reward: -0.6934,                 loss: nan
agent1:                 episode reward: 0.6934,                 loss: 0.2761
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4035s / 192.1873 s
agent0:                 episode reward: -0.8163,                 loss: nan
agent1:                 episode reward: 0.8163,                 loss: 0.2726
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3983s / 192.5856 s
agent0:                 episode reward: -0.7784,                 loss: nan
agent1:                 episode reward: 0.7784,                 loss: 0.2709
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4003s / 192.9859 s
agent0:                 episode reward: -0.8469,                 loss: nan
agent1:                 episode reward: 0.8469,                 loss: 0.2742
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3899s / 193.3758 s
agent0:                 episode reward: -0.7131,                 loss: nan
agent1:                 episode reward: 0.7131,                 loss: 0.2736
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3992s / 193.7750 s
agent0:                 episode reward: -0.9606,                 loss: nan
agent1:                 episode reward: 0.9606,                 loss: 0.2726
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3903s / 194.1653 s
agent0:                 episode reward: -0.6969,                 loss: nan
agent1:                 episode reward: 0.6969,                 loss: 0.2744
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3961s / 194.5614 s
agent0:                 episode reward: -0.8507,                 loss: nan
agent1:                 episode reward: 0.8507,                 loss: 0.2740
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3936s / 194.9550 s
agent0:                 episode reward: -1.1662,                 loss: nan
agent1:                 episode reward: 1.1662,                 loss: 0.2715
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4063s / 195.3613 s
agent0:                 episode reward: -0.5612,                 loss: nan
agent1:                 episode reward: 0.5612,                 loss: 0.2723
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4100s / 195.7713 s
agent0:                 episode reward: -0.0678,                 loss: nan
agent1:                 episode reward: 0.0678,                 loss: 0.2709
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3970s / 196.1682 s
agent0:                 episode reward: -0.5632,                 loss: nan
agent1:                 episode reward: 0.5632,                 loss: 0.2901
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3924s / 196.5607 s
agent0:                 episode reward: -0.8609,                 loss: nan
agent1:                 episode reward: 0.8609,                 loss: 0.2967
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3932s / 196.9539 s
agent0:                 episode reward: -0.3604,                 loss: nan
agent1:                 episode reward: 0.3604,                 loss: 0.2939
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3911s / 197.3450 s
agent0:                 episode reward: -1.2407,                 loss: nan
agent1:                 episode reward: 1.2407,                 loss: 0.2957
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3930s / 197.7380 s
agent0:                 episode reward: -0.7785,                 loss: nan
agent1:                 episode reward: 0.7785,                 loss: 0.2959
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4323s / 198.1703 s
agent0:                 episode reward: -1.0476,                 loss: nan
agent1:                 episode reward: 1.0476,                 loss: 0.2959
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3947s / 198.5650 s
agent0:                 episode reward: -0.4830,                 loss: nan
agent1:                 episode reward: 0.4830,                 loss: 0.2950
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3983s / 198.9633 s
agent0:                 episode reward: -0.8684,                 loss: nan
agent1:                 episode reward: 0.8684,                 loss: 0.2963
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3989s / 199.3622 s
agent0:                 episode reward: -0.5578,                 loss: nan
agent1:                 episode reward: 0.5578,                 loss: 0.2956
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4048s / 199.7670 s
agent0:                 episode reward: -0.8197,                 loss: nan
agent1:                 episode reward: 0.8197,                 loss: 0.2979
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3992s / 200.1662 s
agent0:                 episode reward: -0.9990,                 loss: nan
agent1:                 episode reward: 0.9990,                 loss: 0.2976
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3910s / 200.5572 s
agent0:                 episode reward: -0.9045,                 loss: nan
agent1:                 episode reward: 0.9045,                 loss: 0.2916
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3969s / 200.9541 s
agent0:                 episode reward: -0.8970,                 loss: nan
agent1:                 episode reward: 0.8970,                 loss: 0.2940
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4047s / 201.3588 s
agent0:                 episode reward: -0.8204,                 loss: nan
agent1:                 episode reward: 0.8204,                 loss: 0.2970
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3970s / 201.7557 s
agent0:                 episode reward: -0.6601,                 loss: nan
agent1:                 episode reward: 0.6601,                 loss: 0.3011
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4408s / 202.1965 s
agent0:                 episode reward: -0.9481,                 loss: nan
agent1:                 episode reward: 0.9481,                 loss: 0.2949
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4009s / 202.5974 s
agent0:                 episode reward: -0.9661,                 loss: nan
agent1:                 episode reward: 0.9661,                 loss: 0.2945
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4000s / 202.9974 s
agent0:                 episode reward: -0.6778,                 loss: nan
agent1:                 episode reward: 0.6778,                 loss: 0.2854
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4002s / 203.3976 s
agent0:                 episode reward: -0.6580,                 loss: nan
agent1:                 episode reward: 0.6580,                 loss: 0.2869
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4116s / 203.8092 s
agent0:                 episode reward: -0.3212,                 loss: nan
agent1:                 episode reward: 0.3212,                 loss: 0.2848
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4153s / 204.2245 s
agent0:                 episode reward: -0.7806,                 loss: nan
agent1:                 episode reward: 0.7806,                 loss: 0.2840
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4014s / 204.6259 s
agent0:                 episode reward: -0.4126,                 loss: nan
agent1:                 episode reward: 0.4126,                 loss: 0.2843
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4079s / 205.0338 s
agent0:                 episode reward: -0.7383,                 loss: nan
agent1:                 episode reward: 0.7383,                 loss: 0.2796
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4030s / 205.4368 s
agent0:                 episode reward: -0.9180,                 loss: nan
agent1:                 episode reward: 0.9180,                 loss: 0.2820
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4164s / 205.8533 s
agent0:                 episode reward: -0.6242,                 loss: nan
agent1:                 episode reward: 0.6242,                 loss: 0.2856
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4156s / 206.2689 s
agent0:                 episode reward: -0.7022,                 loss: nan
agent1:                 episode reward: 0.7022,                 loss: 0.2814
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3957s / 206.6647 s
agent0:                 episode reward: -0.8607,                 loss: nan
agent1:                 episode reward: 0.8607,                 loss: 0.2840
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4177s / 207.0824 s
agent0:                 episode reward: -0.7045,                 loss: nan
agent1:                 episode reward: 0.7045,                 loss: 0.2796
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3991s / 207.4814 s
agent0:                 episode reward: -0.7783,                 loss: nan
agent1:                 episode reward: 0.7783,                 loss: 0.2866
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4013s / 207.8828 s
agent0:                 episode reward: -0.8204,                 loss: nan
agent1:                 episode reward: 0.8204,                 loss: 0.2864
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3963s / 208.2791 s
agent0:                 episode reward: -0.7059,                 loss: nan
agent1:                 episode reward: 0.7059,                 loss: 0.2867
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4381s / 208.7172 s
agent0:                 episode reward: -0.4906,                 loss: nan
agent1:                 episode reward: 0.4906,                 loss: 0.2835
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4085s / 209.1257 s
agent0:                 episode reward: -0.9507,                 loss: nan
agent1:                 episode reward: 0.9507,                 loss: 0.2853
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4006s / 209.5263 s
agent0:                 episode reward: -0.8034,                 loss: nan
agent1:                 episode reward: 0.8034,                 loss: 0.2829
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4077s / 209.9340 s
agent0:                 episode reward: -1.2377,                 loss: nan
agent1:                 episode reward: 1.2377,                 loss: 0.2764
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4374s / 210.3713 s
agent0:                 episode reward: -0.6124,                 loss: nan
agent1:                 episode reward: 0.6124,                 loss: 0.2764
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4035s / 210.7748 s
agent0:                 episode reward: -0.8414,                 loss: nan
agent1:                 episode reward: 0.8414,                 loss: 0.2770
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3993s / 211.1741 s
agent0:                 episode reward: -0.8629,                 loss: nan
agent1:                 episode reward: 0.8629,                 loss: 0.2761
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4023s / 211.5764 s
agent0:                 episode reward: -0.6772,                 loss: nan
agent1:                 episode reward: 0.6772,                 loss: 0.2741
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3989s / 211.9752 s
agent0:                 episode reward: -0.6237,                 loss: nan
agent1:                 episode reward: 0.6237,                 loss: 0.2760
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4898s / 212.4650 s
agent0:                 episode reward: -0.8484,                 loss: nan
agent1:                 episode reward: 0.8484,                 loss: 0.2781
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4044s / 212.8694 s
agent0:                 episode reward: -1.0209,                 loss: nan
agent1:                 episode reward: 1.0209,                 loss: 0.2782
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4066s / 213.2760 s
agent0:                 episode reward: -0.6598,                 loss: nan
agent1:                 episode reward: 0.6598,                 loss: 0.2781
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4054s / 213.6814 s
agent0:                 episode reward: -0.9154,                 loss: nan
agent1:                 episode reward: 0.9154,                 loss: 0.2771
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4426s / 214.1239 s
agent0:                 episode reward: -0.5121,                 loss: nan
agent1:                 episode reward: 0.5121,                 loss: 0.2756
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4022s / 214.5261 s
agent0:                 episode reward: -0.2661,                 loss: nan
agent1:                 episode reward: 0.2661,                 loss: 0.2776
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4059s / 214.9321 s
agent0:                 episode reward: -0.8004,                 loss: nan
agent1:                 episode reward: 0.8004,                 loss: 0.2796
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4128s / 215.3449 s
agent0:                 episode reward: -0.9332,                 loss: nan
agent1:                 episode reward: 0.9332,                 loss: 0.2760
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4082s / 215.7531 s
agent0:                 episode reward: -0.8116,                 loss: nan
agent1:                 episode reward: 0.8116,                 loss: 0.2749
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4172s / 216.1703 s
agent0:                 episode reward: -0.4973,                 loss: nan
agent1:                 episode reward: 0.4973,                 loss: 0.2783
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4102s / 216.5804 s
agent0:                 episode reward: -0.7519,                 loss: nan
agent1:                 episode reward: 0.7519,                 loss: 0.2888
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4105s / 216.9909 s
agent0:                 episode reward: -0.8865,                 loss: nan
agent1:                 episode reward: 0.8865,                 loss: 0.2947
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4088s / 217.3998 s
agent0:                 episode reward: -0.4658,                 loss: nan
agent1:                 episode reward: 0.4658,                 loss: 0.2968
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4083s / 217.8081 s
agent0:                 episode reward: -0.5029,                 loss: nan
agent1:                 episode reward: 0.5029,                 loss: 0.2973
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4144s / 218.2226 s
agent0:                 episode reward: -0.7901,                 loss: nan
agent1:                 episode reward: 0.7901,                 loss: 0.2952
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4101s / 218.6326 s
agent0:                 episode reward: -1.0324,                 loss: nan
agent1:                 episode reward: 1.0324,                 loss: 0.2944
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4116s / 219.0442 s
agent0:                 episode reward: -1.1437,                 loss: nan
agent1:                 episode reward: 1.1437,                 loss: 0.2992
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4127s / 219.4569 s
agent0:                 episode reward: -0.9733,                 loss: nan
agent1:                 episode reward: 0.9733,                 loss: 0.2949
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4172s / 219.8741 s
agent0:                 episode reward: -0.1957,                 loss: nan
agent1:                 episode reward: 0.1957,                 loss: 0.2937
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4177s / 220.2918 s
agent0:                 episode reward: -0.5870,                 loss: nan
agent1:                 episode reward: 0.5870,                 loss: 0.2939
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4395s / 220.7313 s
agent0:                 episode reward: -0.8249,                 loss: nan
agent1:                 episode reward: 0.8249,                 loss: 0.2920
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4336s / 221.1649 s
agent0:                 episode reward: -1.1858,                 loss: nan
agent1:                 episode reward: 1.1858,                 loss: 0.2935
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4051s / 221.5700 s
agent0:                 episode reward: -0.9728,                 loss: nan
agent1:                 episode reward: 0.9728,                 loss: 0.2931
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4191s / 221.9891 s
agent0:                 episode reward: -0.9398,                 loss: nan
agent1:                 episode reward: 0.9398,                 loss: 0.2937
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4165s / 222.4055 s
agent0:                 episode reward: -0.5772,                 loss: nan
agent1:                 episode reward: 0.5772,                 loss: 0.2979
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4666s / 222.8721 s
agent0:                 episode reward: -0.7796,                 loss: nan
agent1:                 episode reward: 0.7796,                 loss: 0.2939
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4093s / 223.2814 s
agent0:                 episode reward: -0.5965,                 loss: nan
agent1:                 episode reward: 0.5965,                 loss: 0.2942
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4116s / 223.6931 s
agent0:                 episode reward: -1.0450,                 loss: nan
agent1:                 episode reward: 1.0450,                 loss: 0.2972
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4082s / 224.1013 s
agent0:                 episode reward: -0.8427,                 loss: nan
agent1:                 episode reward: 0.8427,                 loss: 0.2978
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4088s / 224.5101 s
agent0:                 episode reward: -0.5915,                 loss: nan
agent1:                 episode reward: 0.5915,                 loss: 0.2967
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4153s / 224.9254 s
agent0:                 episode reward: -1.0984,                 loss: nan
agent1:                 episode reward: 1.0984,                 loss: 0.2969
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4078s / 225.3332 s
agent0:                 episode reward: -0.7939,                 loss: nan
agent1:                 episode reward: 0.7939,                 loss: 0.2946
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4337s / 225.7669 s
agent0:                 episode reward: -0.8724,                 loss: nan
agent1:                 episode reward: 0.8724,                 loss: 0.2917
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4130s / 226.1799 s
agent0:                 episode reward: -0.6362,                 loss: nan
agent1:                 episode reward: 0.6362,                 loss: 0.2924
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4111s / 226.5910 s
agent0:                 episode reward: -1.0228,                 loss: nan
agent1:                 episode reward: 1.0228,                 loss: 0.2970
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4381s / 227.0291 s
agent0:                 episode reward: -0.4678,                 loss: nan
agent1:                 episode reward: 0.4678,                 loss: 0.2961
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4225s / 227.4516 s
agent0:                 episode reward: -0.5320,                 loss: nan
agent1:                 episode reward: 0.5320,                 loss: 0.2928
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4135s / 227.8651 s
agent0:                 episode reward: -0.6760,                 loss: nan
agent1:                 episode reward: 0.6760,                 loss: 0.2927
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4203s / 228.2853 s
agent0:                 episode reward: -0.7840,                 loss: nan
agent1:                 episode reward: 0.7840,                 loss: 0.2919
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4348s / 228.7201 s
agent0:                 episode reward: -0.8516,                 loss: nan
agent1:                 episode reward: 0.8516,                 loss: 0.2926
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4164s / 229.1365 s
agent0:                 episode reward: -0.9152,                 loss: nan
agent1:                 episode reward: 0.9152,                 loss: 0.2980
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4472s / 229.5837 s
agent0:                 episode reward: -0.6958,                 loss: nan
agent1:                 episode reward: 0.6958,                 loss: 0.2932
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4210s / 230.0048 s
agent0:                 episode reward: -0.6611,                 loss: nan
agent1:                 episode reward: 0.6611,                 loss: 0.2944
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4218s / 230.4266 s
agent0:                 episode reward: -0.9053,                 loss: nan
agent1:                 episode reward: 0.9053,                 loss: 0.2976
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4220s / 230.8486 s
agent0:                 episode reward: -0.5433,                 loss: nan
agent1:                 episode reward: 0.5433,                 loss: 0.2864
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4462s / 231.2948 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.2854
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4212s / 231.7160 s
agent0:                 episode reward: -0.6582,                 loss: nan
agent1:                 episode reward: 0.6582,                 loss: 0.2868
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4158s / 232.1318 s
agent0:                 episode reward: -0.4012,                 loss: nan
agent1:                 episode reward: 0.4012,                 loss: 0.2863
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4127s / 232.5446 s
agent0:                 episode reward: -1.0883,                 loss: nan
agent1:                 episode reward: 1.0883,                 loss: 0.2837
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4562s / 233.0008 s
agent0:                 episode reward: -0.9436,                 loss: nan
agent1:                 episode reward: 0.9436,                 loss: 0.2881
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4182s / 233.4190 s
agent0:                 episode reward: -0.7378,                 loss: nan
agent1:                 episode reward: 0.7378,                 loss: 0.2852
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4147s / 233.8337 s
agent0:                 episode reward: -0.5595,                 loss: nan
agent1:                 episode reward: 0.5595,                 loss: 0.2859
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4368s / 234.2705 s
agent0:                 episode reward: -0.5696,                 loss: nan
agent1:                 episode reward: 0.5696,                 loss: 0.2870
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4181s / 234.6886 s
agent0:                 episode reward: -1.2371,                 loss: nan
agent1:                 episode reward: 1.2371,                 loss: 0.2842
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4198s / 235.1085 s
agent0:                 episode reward: -0.7392,                 loss: nan
agent1:                 episode reward: 0.7392,                 loss: 0.2845
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4204s / 235.5289 s
agent0:                 episode reward: -0.1869,                 loss: nan
agent1:                 episode reward: 0.1869,                 loss: 0.2888
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4175s / 235.9463 s
agent0:                 episode reward: -0.9987,                 loss: nan
agent1:                 episode reward: 0.9987,                 loss: 0.2873
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4184s / 236.3647 s
agent0:                 episode reward: -0.9747,                 loss: nan
agent1:                 episode reward: 0.9747,                 loss: 0.2884
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4173s / 236.7820 s
agent0:                 episode reward: -1.0083,                 loss: nan
agent1:                 episode reward: 1.0083,                 loss: 0.2888
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4603s / 237.2423 s
agent0:                 episode reward: -0.3675,                 loss: nan
agent1:                 episode reward: 0.3675,                 loss: 0.2882
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4216s / 237.6639 s
agent0:                 episode reward: -0.5372,                 loss: nan
agent1:                 episode reward: 0.5372,                 loss: 0.2843
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4174s / 238.0813 s
agent0:                 episode reward: -0.8123,                 loss: nan
agent1:                 episode reward: 0.8123,                 loss: 0.2843
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4145s / 238.4958 s
agent0:                 episode reward: -0.7736,                 loss: nan
agent1:                 episode reward: 0.7736,                 loss: 0.2870
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4228s / 238.9187 s
agent0:                 episode reward: -0.7397,                 loss: nan
agent1:                 episode reward: 0.7397,                 loss: 0.2894
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4164s / 239.3351 s
agent0:                 episode reward: -0.5404,                 loss: nan
agent1:                 episode reward: 0.5404,                 loss: 0.2846
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4235s / 239.7586 s
agent0:                 episode reward: -0.9224,                 loss: nan
agent1:                 episode reward: 0.9224,                 loss: 0.2854
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4374s / 240.1960 s
agent0:                 episode reward: -0.8370,                 loss: nan
agent1:                 episode reward: 0.8370,                 loss: 0.2882
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4224s / 240.6184 s
agent0:                 episode reward: -0.6485,                 loss: nan
agent1:                 episode reward: 0.6485,                 loss: 0.2881
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4263s / 241.0448 s
agent0:                 episode reward: -0.6902,                 loss: nan
agent1:                 episode reward: 0.6902,                 loss: 0.2861
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4228s / 241.4675 s
agent0:                 episode reward: -0.8402,                 loss: nan
agent1:                 episode reward: 0.8402,                 loss: 0.2887
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4243s / 241.8918 s
agent0:                 episode reward: -0.5180,                 loss: nan
agent1:                 episode reward: 0.5180,                 loss: 0.2854
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4243s / 242.3161 s
agent0:                 episode reward: -0.5605,                 loss: nan
agent1:                 episode reward: 0.5605,                 loss: 0.2893
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4242s / 242.7403 s
agent0:                 episode reward: -0.4050,                 loss: nan
agent1:                 episode reward: 0.4050,                 loss: 0.2889
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4887s / 243.2290 s
agent0:                 episode reward: -0.8506,                 loss: nan
agent1:                 episode reward: 0.8506,                 loss: 0.2894
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4255s / 243.6545 s
agent0:                 episode reward: -0.6674,                 loss: nan
agent1:                 episode reward: 0.6674,                 loss: 0.2877
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4243s / 244.0788 s
agent0:                 episode reward: -0.6589,                 loss: nan
agent1:                 episode reward: 0.6589,                 loss: 0.2855
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4232s / 244.5021 s
agent0:                 episode reward: -0.8874,                 loss: nan
agent1:                 episode reward: 0.8874,                 loss: 0.2896
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4272s / 244.9293 s
agent0:                 episode reward: -0.5980,                 loss: nan
agent1:                 episode reward: 0.5980,                 loss: 0.2941
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4528s / 245.3821 s
agent0:                 episode reward: -0.7508,                 loss: nan
agent1:                 episode reward: 0.7508,                 loss: 0.2934
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4271s / 245.8092 s
agent0:                 episode reward: -0.7070,                 loss: nan
agent1:                 episode reward: 0.7070,                 loss: 0.2945
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4367s / 246.2459 s
agent0:                 episode reward: -0.5894,                 loss: nan
agent1:                 episode reward: 0.5894,                 loss: 0.2955
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4284s / 246.6743 s
agent0:                 episode reward: -0.9339,                 loss: nan
agent1:                 episode reward: 0.9339,                 loss: 0.2970
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4237s / 247.0980 s
agent0:                 episode reward: -0.5609,                 loss: nan
agent1:                 episode reward: 0.5609,                 loss: 0.2982
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4279s / 247.5259 s
agent0:                 episode reward: -0.4268,                 loss: nan
agent1:                 episode reward: 0.4268,                 loss: 0.2962
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4276s / 247.9536 s
agent0:                 episode reward: -0.9833,                 loss: nan
agent1:                 episode reward: 0.9833,                 loss: 0.2958
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4251s / 248.3786 s
agent0:                 episode reward: -1.1614,                 loss: nan
agent1:                 episode reward: 1.1614,                 loss: 0.2968
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4314s / 248.8101 s
agent0:                 episode reward: -1.0033,                 loss: nan
agent1:                 episode reward: 1.0033,                 loss: 0.2985
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4607s / 249.2708 s
agent0:                 episode reward: -1.1641,                 loss: nan
agent1:                 episode reward: 1.1641,                 loss: 0.2921
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4282s / 249.6990 s
agent0:                 episode reward: -0.9328,                 loss: nan
agent1:                 episode reward: 0.9328,                 loss: 0.2972
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4299s / 250.1289 s
agent0:                 episode reward: -0.7840,                 loss: nan
agent1:                 episode reward: 0.7840,                 loss: 0.2951
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4371s / 250.5660 s
agent0:                 episode reward: -0.6558,                 loss: nan
agent1:                 episode reward: 0.6558,                 loss: 0.2940
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4273s / 250.9933 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.2979
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4247s / 251.4180 s
agent0:                 episode reward: -1.0954,                 loss: nan
agent1:                 episode reward: 1.0954,                 loss: 0.2936
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4291s / 251.8471 s
agent0:                 episode reward: -0.6984,                 loss: nan
agent1:                 episode reward: 0.6984,                 loss: 0.2913
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4358s / 252.2829 s
agent0:                 episode reward: -0.9890,                 loss: nan
agent1:                 episode reward: 0.9890,                 loss: 0.2861
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4268s / 252.7097 s
agent0:                 episode reward: -0.7226,                 loss: nan
agent1:                 episode reward: 0.7226,                 loss: 0.2857
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4457s / 253.1554 s
agent0:                 episode reward: -0.9861,                 loss: nan
agent1:                 episode reward: 0.9861,                 loss: 0.2896
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4880s / 253.6434 s
agent0:                 episode reward: -0.8273,                 loss: nan
agent1:                 episode reward: 0.8273,                 loss: 0.2881
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4315s / 254.0750 s
agent0:                 episode reward: -1.0749,                 loss: nan
agent1:                 episode reward: 1.0749,                 loss: 0.2846
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4691s / 254.5441 s
agent0:                 episode reward: -1.0868,                 loss: nan
agent1:                 episode reward: 1.0868,                 loss: 0.2843
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4311s / 254.9752 s
agent0:                 episode reward: -0.6587,                 loss: nan
agent1:                 episode reward: 0.6587,                 loss: 0.2852
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4368s / 255.4120 s
agent0:                 episode reward: -0.7318,                 loss: nan
agent1:                 episode reward: 0.7318,                 loss: 0.2861
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4331s / 255.8452 s
agent0:                 episode reward: -1.0081,                 loss: nan
agent1:                 episode reward: 1.0081,                 loss: 0.2825
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4359s / 256.2811 s
agent0:                 episode reward: -0.6957,                 loss: nan
agent1:                 episode reward: 0.6957,                 loss: 0.2845
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4515s / 256.7326 s
agent0:                 episode reward: -0.8274,                 loss: nan
agent1:                 episode reward: 0.8274,                 loss: 0.2865
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4311s / 257.1636 s
agent0:                 episode reward: -0.7066,                 loss: nan
agent1:                 episode reward: 0.7066,                 loss: 0.2887
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4337s / 257.5973 s
agent0:                 episode reward: -0.6078,                 loss: nan
agent1:                 episode reward: 0.6078,                 loss: 0.2839
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4275s / 258.0248 s
agent0:                 episode reward: -0.8733,                 loss: nan
agent1:                 episode reward: 0.8733,                 loss: 0.2887
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4356s / 258.4604 s
agent0:                 episode reward: -0.5810,                 loss: nan
agent1:                 episode reward: 0.5810,                 loss: 0.2894
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4366s / 258.8970 s
agent0:                 episode reward: -0.8735,                 loss: nan
agent1:                 episode reward: 0.8735,                 loss: 0.2880
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4312s / 259.3282 s
agent0:                 episode reward: -0.8909,                 loss: nan
agent1:                 episode reward: 0.8909,                 loss: 0.2927
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4337s / 259.7619 s
agent0:                 episode reward: -1.0007,                 loss: nan
agent1:                 episode reward: 1.0007,                 loss: 0.2947
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4318s / 260.1937 s
agent0:                 episode reward: -0.5229,                 loss: nan
agent1:                 episode reward: 0.5229,                 loss: 0.2962
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4371s / 260.6308 s
agent0:                 episode reward: -0.8148,                 loss: nan
agent1:                 episode reward: 0.8148,                 loss: 0.2945
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4379s / 261.0687 s
agent0:                 episode reward: -0.9577,                 loss: nan
agent1:                 episode reward: 0.9577,                 loss: 0.2928
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4411s / 261.5098 s
agent0:                 episode reward: -1.0496,                 loss: nan
agent1:                 episode reward: 1.0496,                 loss: 0.2937
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4528s / 261.9627 s
agent0:                 episode reward: -0.8081,                 loss: nan
agent1:                 episode reward: 0.8081,                 loss: 0.2947
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4341s / 262.3968 s
agent0:                 episode reward: -1.0285,                 loss: nan
agent1:                 episode reward: 1.0285,                 loss: 0.2900
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4372s / 262.8340 s
agent0:                 episode reward: -0.8988,                 loss: nan
agent1:                 episode reward: 0.8988,                 loss: 0.2928
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4333s / 263.2674 s
agent0:                 episode reward: -0.9236,                 loss: nan
agent1:                 episode reward: 0.9236,                 loss: 0.2937
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4841s / 263.7515 s
agent0:                 episode reward: -0.5915,                 loss: nan
agent1:                 episode reward: 0.5915,                 loss: 0.2940
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4458s / 264.1973 s
agent0:                 episode reward: -0.8092,                 loss: nan
agent1:                 episode reward: 0.8092,                 loss: 0.2944
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4366s / 264.6339 s
agent0:                 episode reward: -0.3624,                 loss: nan
agent1:                 episode reward: 0.3624,                 loss: 0.2953
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4388s / 265.0727 s
agent0:                 episode reward: -0.9245,                 loss: nan
agent1:                 episode reward: 0.9245,                 loss: 0.2939
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4337s / 265.5064 s
agent0:                 episode reward: -0.3795,                 loss: nan
agent1:                 episode reward: 0.3795,                 loss: 0.2925
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4389s / 265.9453 s
agent0:                 episode reward: -0.7115,                 loss: nan
agent1:                 episode reward: 0.7115,                 loss: 0.2942
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4341s / 266.3794 s
agent0:                 episode reward: -1.1295,                 loss: nan
agent1:                 episode reward: 1.1295,                 loss: 0.2940
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4338s / 266.8132 s
agent0:                 episode reward: -0.8195,                 loss: nan
agent1:                 episode reward: 0.8195,                 loss: 0.2911
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4666s / 267.2797 s
agent0:                 episode reward: -0.7945,                 loss: nan
agent1:                 episode reward: 0.7945,                 loss: 0.2924
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4448s / 267.7246 s
agent0:                 episode reward: -0.9473,                 loss: nan
agent1:                 episode reward: 0.9473,                 loss: 0.2947
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4437s / 268.1682 s
agent0:                 episode reward: -0.7993,                 loss: nan
agent1:                 episode reward: 0.7993,                 loss: 0.2951
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4404s / 268.6086 s
agent0:                 episode reward: -0.6553,                 loss: nan
agent1:                 episode reward: 0.6553,                 loss: 0.2923
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4476s / 269.0562 s
agent0:                 episode reward: -0.7641,                 loss: nan
agent1:                 episode reward: 0.7641,                 loss: 0.2950
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4415s / 269.4977 s
agent0:                 episode reward: -0.8963,                 loss: nan
agent1:                 episode reward: 0.8963,                 loss: 0.2909
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4409s / 269.9386 s
agent0:                 episode reward: -1.0616,                 loss: nan
agent1:                 episode reward: 1.0616,                 loss: 0.2925
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4722s / 270.4108 s
agent0:                 episode reward: -1.1194,                 loss: nan
agent1:                 episode reward: 1.1194,                 loss: 0.2881
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4615s / 270.8723 s
agent0:                 episode reward: -0.3400,                 loss: nan
agent1:                 episode reward: 0.3400,                 loss: 0.2936
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4312s / 271.3035 s
agent0:                 episode reward: -0.6380,                 loss: nan
agent1:                 episode reward: 0.6380,                 loss: 0.2899
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4431s / 271.7466 s
agent0:                 episode reward: -0.7904,                 loss: nan
agent1:                 episode reward: 0.7904,                 loss: 0.2920
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4410s / 272.1877 s
agent0:                 episode reward: -0.6625,                 loss: nan
agent1:                 episode reward: 0.6625,                 loss: 0.2943
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4386s / 272.6263 s
agent0:                 episode reward: -0.7579,                 loss: nan
agent1:                 episode reward: 0.7579,                 loss: 0.2924
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4393s / 273.0656 s
agent0:                 episode reward: -0.4624,                 loss: nan
agent1:                 episode reward: 0.4624,                 loss: 0.2897
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4534s / 273.5190 s
agent0:                 episode reward: -1.0716,                 loss: nan
agent1:                 episode reward: 1.0716,                 loss: 0.2948
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4908s / 274.0098 s
agent0:                 episode reward: -0.6961,                 loss: nan
agent1:                 episode reward: 0.6961,                 loss: 0.2884
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4421s / 274.4519 s
agent0:                 episode reward: -0.7827,                 loss: nan
agent1:                 episode reward: 0.7827,                 loss: 0.2899
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4427s / 274.8946 s
agent0:                 episode reward: -0.8268,                 loss: nan
agent1:                 episode reward: 0.8268,                 loss: 0.2926
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4390s / 275.3335 s
agent0:                 episode reward: -0.5189,                 loss: nan
agent1:                 episode reward: 0.5189,                 loss: 0.2921
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4398s / 275.7733 s
agent0:                 episode reward: -1.1340,                 loss: nan
agent1:                 episode reward: 1.1340,                 loss: 0.2913
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4490s / 276.2223 s
agent0:                 episode reward: -0.6594,                 loss: nan
agent1:                 episode reward: 0.6594,                 loss: 0.2901
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4440s / 276.6663 s
agent0:                 episode reward: -0.7838,                 loss: nan
agent1:                 episode reward: 0.7838,                 loss: 0.2924
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4511s / 277.1174 s
agent0:                 episode reward: -0.7377,                 loss: nan
agent1:                 episode reward: 0.7377,                 loss: 0.2888
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4558s / 277.5732 s
agent0:                 episode reward: -0.5822,                 loss: nan
agent1:                 episode reward: 0.5822,                 loss: 0.2901
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4505s / 278.0237 s
agent0:                 episode reward: -0.8446,                 loss: nan
agent1:                 episode reward: 0.8446,                 loss: 0.2901
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4663s / 278.4901 s
agent0:                 episode reward: -0.6116,                 loss: nan
agent1:                 episode reward: 0.6116,                 loss: 0.2904
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4449s / 278.9350 s
agent0:                 episode reward: -0.7823,                 loss: nan
agent1:                 episode reward: 0.7823,                 loss: 0.2890
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4420s / 279.3770 s
agent0:                 episode reward: -0.5745,                 loss: nan
agent1:                 episode reward: 0.5745,                 loss: 0.2865
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4430s / 279.8199 s
agent0:                 episode reward: -0.5541,                 loss: nan
agent1:                 episode reward: 0.5541,                 loss: 0.2925
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4476s / 280.2676 s
agent0:                 episode reward: -0.8902,                 loss: nan
agent1:                 episode reward: 0.8902,                 loss: 0.2943
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4538s / 280.7213 s
agent0:                 episode reward: -0.5061,                 loss: nan
agent1:                 episode reward: 0.5061,                 loss: 0.2946
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4543s / 281.1756 s
agent0:                 episode reward: -0.4697,                 loss: nan
agent1:                 episode reward: 0.4697,                 loss: 0.2891
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4566s / 281.6322 s
agent0:                 episode reward: -0.8152,                 loss: nan
agent1:                 episode reward: 0.8152,                 loss: 0.2957
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4562s / 282.0884 s
agent0:                 episode reward: -0.9755,                 loss: nan
agent1:                 episode reward: 0.9755,                 loss: 0.2951
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4459s / 282.5344 s
agent0:                 episode reward: -0.7124,                 loss: nan
agent1:                 episode reward: 0.7124,                 loss: 0.2974
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4491s / 282.9834 s
agent0:                 episode reward: -0.5800,                 loss: nan
agent1:                 episode reward: 0.5800,                 loss: 0.2971
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4540s / 283.4374 s
agent0:                 episode reward: -0.7296,                 loss: nan
agent1:                 episode reward: 0.7296,                 loss: 0.2963
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4477s / 283.8851 s
agent0:                 episode reward: -0.8233,                 loss: nan
agent1:                 episode reward: 0.8233,                 loss: 0.2966
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5104s / 284.3955 s
agent0:                 episode reward: -0.9114,                 loss: nan
agent1:                 episode reward: 0.9114,                 loss: 0.2975
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4505s / 284.8461 s
agent0:                 episode reward: -0.5910,                 loss: nan
agent1:                 episode reward: 0.5910,                 loss: 0.3007
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4626s / 285.3087 s
agent0:                 episode reward: -0.6403,                 loss: nan
agent1:                 episode reward: 0.6403,                 loss: 0.2974
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4522s / 285.7609 s
agent0:                 episode reward: -1.0341,                 loss: nan
agent1:                 episode reward: 1.0341,                 loss: 0.2961
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4547s / 286.2156 s
agent0:                 episode reward: -0.7115,                 loss: nan
agent1:                 episode reward: 0.7115,                 loss: 0.2984
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4582s / 286.6738 s
agent0:                 episode reward: -0.7543,                 loss: nan
agent1:                 episode reward: 0.7543,                 loss: 0.2975
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4716s / 287.1453 s
agent0:                 episode reward: -0.4917,                 loss: nan
agent1:                 episode reward: 0.4917,                 loss: 0.2960
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4604s / 287.6057 s
agent0:                 episode reward: -0.7216,                 loss: nan
agent1:                 episode reward: 0.7216,                 loss: 0.2996
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4557s / 288.0614 s
agent0:                 episode reward: -0.6603,                 loss: nan
agent1:                 episode reward: 0.6603,                 loss: 0.2992
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4682s / 288.5296 s
agent0:                 episode reward: -1.0204,                 loss: nan
agent1:                 episode reward: 1.0204,                 loss: 0.2998
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4510s / 288.9806 s
agent0:                 episode reward: -0.7513,                 loss: nan
agent1:                 episode reward: 0.7513,                 loss: 0.2980
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4547s / 289.4353 s
agent0:                 episode reward: -1.1205,                 loss: nan
agent1:                 episode reward: 1.1205,                 loss: 0.2974
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4553s / 289.8906 s
agent0:                 episode reward: -0.4464,                 loss: nan
agent1:                 episode reward: 0.4464,                 loss: 0.2949
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4544s / 290.3450 s
agent0:                 episode reward: -0.9226,                 loss: nan
agent1:                 episode reward: 0.9226,                 loss: 0.2965
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4616s / 290.8067 s
agent0:                 episode reward: -0.6066,                 loss: nan
agent1:                 episode reward: 0.6066,                 loss: 0.2976
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4745s / 291.2812 s
agent0:                 episode reward: -1.0275,                 loss: nan
agent1:                 episode reward: 1.0275,                 loss: 0.2947
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4651s / 291.7463 s
agent0:                 episode reward: -0.9078,                 loss: nan
agent1:                 episode reward: 0.9078,                 loss: 0.2942
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4610s / 292.2073 s
agent0:                 episode reward: -0.8069,                 loss: nan
agent1:                 episode reward: 0.8069,                 loss: 0.2972
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4579s / 292.6652 s
agent0:                 episode reward: -0.7182,                 loss: nan
agent1:                 episode reward: 0.7182,                 loss: 0.2971
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4651s / 293.1304 s
agent0:                 episode reward: -0.7643,                 loss: nan
agent1:                 episode reward: 0.7643,                 loss: 0.2954
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4673s / 293.5976 s
agent0:                 episode reward: -0.8320,                 loss: nan
agent1:                 episode reward: 0.8320,                 loss: 0.2958
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4575s / 294.0551 s
agent0:                 episode reward: -0.7655,                 loss: nan
agent1:                 episode reward: 0.7655,                 loss: 0.2990
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5123s / 294.5675 s
agent0:                 episode reward: -0.7281,                 loss: nan
agent1:                 episode reward: 0.7281,                 loss: 0.2917
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4830s / 295.0505 s
agent0:                 episode reward: -0.6176,                 loss: nan
agent1:                 episode reward: 0.6176,                 loss: 0.2949
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4644s / 295.5149 s
agent0:                 episode reward: -0.7611,                 loss: nan
agent1:                 episode reward: 0.7611,                 loss: 0.2941
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4585s / 295.9734 s
agent0:                 episode reward: -1.3791,                 loss: nan
agent1:                 episode reward: 1.3791,                 loss: 0.2944
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4609s / 296.4343 s
agent0:                 episode reward: -0.9393,                 loss: nan
agent1:                 episode reward: 0.9393,                 loss: 0.2968
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4686s / 296.9029 s
agent0:                 episode reward: -0.7528,                 loss: nan
agent1:                 episode reward: 0.7528,                 loss: 0.2949
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4713s / 297.3743 s
agent0:                 episode reward: -1.0434,                 loss: nan
agent1:                 episode reward: 1.0434,                 loss: 0.2860
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4643s / 297.8385 s
agent0:                 episode reward: -0.7242,                 loss: nan
agent1:                 episode reward: 0.7242,                 loss: 0.2873
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4648s / 298.3033 s
agent0:                 episode reward: -1.0659,                 loss: nan
agent1:                 episode reward: 1.0659,                 loss: 0.2823
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4659s / 298.7692 s
agent0:                 episode reward: -0.8798,                 loss: nan
agent1:                 episode reward: 0.8798,                 loss: 0.2855
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4642s / 299.2335 s
agent0:                 episode reward: -0.7013,                 loss: nan
agent1:                 episode reward: 0.7013,                 loss: 0.2899
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4633s / 299.6968 s
agent0:                 episode reward: -1.1006,                 loss: nan
agent1:                 episode reward: 1.1006,                 loss: 0.2844
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4675s / 300.1643 s
agent0:                 episode reward: -0.7346,                 loss: nan
agent1:                 episode reward: 0.7346,                 loss: 0.2853
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4869s / 300.6512 s
agent0:                 episode reward: -0.9531,                 loss: nan
agent1:                 episode reward: 0.9531,                 loss: 0.2866
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4707s / 301.1219 s
agent0:                 episode reward: -0.5477,                 loss: nan
agent1:                 episode reward: 0.5477,                 loss: 0.2867
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4629s / 301.5848 s
agent0:                 episode reward: -0.7273,                 loss: nan
agent1:                 episode reward: 0.7273,                 loss: 0.2880
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4713s / 302.0561 s
agent0:                 episode reward: -0.5946,                 loss: nan
agent1:                 episode reward: 0.5946,                 loss: 0.2851
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4618s / 302.5179 s
agent0:                 episode reward: -0.9760,                 loss: nan
agent1:                 episode reward: 0.9760,                 loss: 0.2839
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4599s / 302.9778 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.2879
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4878s / 303.4656 s
agent0:                 episode reward: -0.7626,                 loss: nan
agent1:                 episode reward: 0.7626,                 loss: 0.2871
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4655s / 303.9311 s
agent0:                 episode reward: -0.8510,                 loss: nan
agent1:                 episode reward: 0.8510,                 loss: 0.2864
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4951s / 304.4263 s
agent0:                 episode reward: -0.8108,                 loss: nan
agent1:                 episode reward: 0.8108,                 loss: 0.2912
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5245s / 304.9508 s
agent0:                 episode reward: -0.8211,                 loss: nan
agent1:                 episode reward: 0.8211,                 loss: 0.2868
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4684s / 305.4192 s
agent0:                 episode reward: -0.6595,                 loss: nan
agent1:                 episode reward: 0.6595,                 loss: 0.2914
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4675s / 305.8867 s
agent0:                 episode reward: -0.6471,                 loss: nan
agent1:                 episode reward: 0.6471,                 loss: 0.2959
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4943s / 306.3810 s
agent0:                 episode reward: -0.7016,                 loss: nan
agent1:                 episode reward: 0.7016,                 loss: 0.2901
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4762s / 306.8572 s
agent0:                 episode reward: -1.0226,                 loss: nan
agent1:                 episode reward: 1.0226,                 loss: 0.2884
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4760s / 307.3332 s
agent0:                 episode reward: -0.9727,                 loss: nan
agent1:                 episode reward: 0.9727,                 loss: 0.2887
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4797s / 307.8129 s
agent0:                 episode reward: -0.7217,                 loss: nan
agent1:                 episode reward: 0.7217,                 loss: 0.2910
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4601s / 308.2730 s
agent0:                 episode reward: -1.0879,                 loss: nan
agent1:                 episode reward: 1.0879,                 loss: 0.2884
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4630s / 308.7360 s
agent0:                 episode reward: -0.7881,                 loss: nan
agent1:                 episode reward: 0.7881,                 loss: 0.2929
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4747s / 309.2107 s
agent0:                 episode reward: -0.5966,                 loss: nan
agent1:                 episode reward: 0.5966,                 loss: 0.2898
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4901s / 309.7008 s
agent0:                 episode reward: -0.8154,                 loss: nan
agent1:                 episode reward: 0.8154,                 loss: 0.2890
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4673s / 310.1681 s
agent0:                 episode reward: -0.8203,                 loss: nan
agent1:                 episode reward: 0.8203,                 loss: 0.2886
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4668s / 310.6349 s
agent0:                 episode reward: -1.0508,                 loss: nan
agent1:                 episode reward: 1.0508,                 loss: 0.2932
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4753s / 311.1102 s
agent0:                 episode reward: -0.7729,                 loss: nan
agent1:                 episode reward: 0.7729,                 loss: 0.2889
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5011s / 311.6113 s
agent0:                 episode reward: -0.8173,                 loss: nan
agent1:                 episode reward: 0.8173,                 loss: 0.2893
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4643s / 312.0755 s
agent0:                 episode reward: -0.8367,                 loss: nan
agent1:                 episode reward: 0.8367,                 loss: 0.2915
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4752s / 312.5507 s
agent0:                 episode reward: -0.4657,                 loss: nan
agent1:                 episode reward: 0.4657,                 loss: 0.2945
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4675s / 313.0181 s
agent0:                 episode reward: -0.7748,                 loss: nan
agent1:                 episode reward: 0.7748,                 loss: 0.2989
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4705s / 313.4886 s
agent0:                 episode reward: -0.6881,                 loss: nan
agent1:                 episode reward: 0.6881,                 loss: 0.2953
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4741s / 313.9628 s
agent0:                 episode reward: -0.8020,                 loss: nan
agent1:                 episode reward: 0.8020,                 loss: 0.2982
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4856s / 314.4483 s
agent0:                 episode reward: -1.2894,                 loss: nan
agent1:                 episode reward: 1.2894,                 loss: 0.2980
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5260s / 314.9743 s
agent0:                 episode reward: -0.5920,                 loss: nan
agent1:                 episode reward: 0.5920,                 loss: 0.2990
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4797s / 315.4540 s
agent0:                 episode reward: -0.8032,                 loss: nan
agent1:                 episode reward: 0.8032,                 loss: 0.2974
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4701s / 315.9241 s
agent0:                 episode reward: -0.5164,                 loss: nan
agent1:                 episode reward: 0.5164,                 loss: 0.2999
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4673s / 316.3914 s
agent0:                 episode reward: -0.7808,                 loss: nan
agent1:                 episode reward: 0.7808,                 loss: 0.3000
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4709s / 316.8623 s
agent0:                 episode reward: -0.8916,                 loss: nan
agent1:                 episode reward: 0.8916,                 loss: 0.2980
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4810s / 317.3433 s
agent0:                 episode reward: -0.4811,                 loss: nan
agent1:                 episode reward: 0.4811,                 loss: 0.3017
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4769s / 317.8203 s
agent0:                 episode reward: -0.4696,                 loss: nan
agent1:                 episode reward: 0.4696,                 loss: 0.3013
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4784s / 318.2987 s
agent0:                 episode reward: -0.8716,                 loss: nan
agent1:                 episode reward: 0.8716,                 loss: 0.2980
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4664s / 318.7651 s
agent0:                 episode reward: -0.5492,                 loss: nan
agent1:                 episode reward: 0.5492,                 loss: 0.3002
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4719s / 319.2370 s
agent0:                 episode reward: -0.6010,                 loss: nan
agent1:                 episode reward: 0.6010,                 loss: 0.3015
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4817s / 319.7188 s
agent0:                 episode reward: -0.9148,                 loss: nan
agent1:                 episode reward: 0.9148,                 loss: 0.2994
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4926s / 320.2113 s
agent0:                 episode reward: -0.5708,                 loss: nan
agent1:                 episode reward: 0.5708,                 loss: 0.2973
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4912s / 320.7025 s
agent0:                 episode reward: -1.0303,                 loss: nan
agent1:                 episode reward: 1.0303,                 loss: 0.2951
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4764s / 321.1789 s
agent0:                 episode reward: -0.9218,                 loss: nan
agent1:                 episode reward: 0.9218,                 loss: 0.2900
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5688s / 321.7477 s
agent0:                 episode reward: -0.7899,                 loss: nan
agent1:                 episode reward: 0.7899,                 loss: 0.2889
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4748s / 322.2225 s
agent0:                 episode reward: -0.6992,                 loss: nan
agent1:                 episode reward: 0.6992,                 loss: 0.2912
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4715s / 322.6941 s
agent0:                 episode reward: -1.0836,                 loss: nan
agent1:                 episode reward: 1.0836,                 loss: 0.2920
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4754s / 323.1695 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.2892
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4761s / 323.6455 s
agent0:                 episode reward: -0.8954,                 loss: nan
agent1:                 episode reward: 0.8954,                 loss: 0.2895
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5010s / 324.1465 s
agent0:                 episode reward: -1.0275,                 loss: nan
agent1:                 episode reward: 1.0275,                 loss: 0.2869
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4958s / 324.6423 s
agent0:                 episode reward: -0.6751,                 loss: nan
agent1:                 episode reward: 0.6751,                 loss: 0.2918
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5644s / 325.2067 s
agent0:                 episode reward: -0.7725,                 loss: nan
agent1:                 episode reward: 0.7725,                 loss: 0.2918
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4812s / 325.6879 s
agent0:                 episode reward: -0.5582,                 loss: nan
agent1:                 episode reward: 0.5582,                 loss: 0.2889
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4746s / 326.1625 s
agent0:                 episode reward: -0.6111,                 loss: nan
agent1:                 episode reward: 0.6111,                 loss: 0.2914
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4718s / 326.6343 s
agent0:                 episode reward: -0.4811,                 loss: nan
agent1:                 episode reward: 0.4811,                 loss: 0.2898
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4719s / 327.1062 s
agent0:                 episode reward: -0.7404,                 loss: nan
agent1:                 episode reward: 0.7404,                 loss: 0.2920
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4868s / 327.5931 s
agent0:                 episode reward: -0.8351,                 loss: nan
agent1:                 episode reward: 0.8351,                 loss: 0.2887
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5073s / 328.1004 s
agent0:                 episode reward: -0.4529,                 loss: nan
agent1:                 episode reward: 0.4529,                 loss: 0.2910
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5002s / 328.6005 s
agent0:                 episode reward: -0.7664,                 loss: nan
agent1:                 episode reward: 0.7664,                 loss: 0.2931
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4918s / 329.0923 s
agent0:                 episode reward: -0.8581,                 loss: nan
agent1:                 episode reward: 0.8581,                 loss: 0.2912
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5088s / 329.6011 s
agent0:                 episode reward: -0.6265,                 loss: nan
agent1:                 episode reward: 0.6265,                 loss: 0.2878
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4889s / 330.0900 s
agent0:                 episode reward: -0.4110,                 loss: nan
agent1:                 episode reward: 0.4110,                 loss: 0.2924
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4796s / 330.5696 s
agent0:                 episode reward: -0.4157,                 loss: nan
agent1:                 episode reward: 0.4157,                 loss: 0.2889
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4802s / 331.0497 s
agent0:                 episode reward: -0.5923,                 loss: nan
agent1:                 episode reward: 0.5923,                 loss: 0.2913
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4875s / 331.5372 s
agent0:                 episode reward: -0.7527,                 loss: nan
agent1:                 episode reward: 0.7527,                 loss: 0.2920
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4837s / 332.0209 s
agent0:                 episode reward: -0.7131,                 loss: nan
agent1:                 episode reward: 0.7131,                 loss: 0.2903
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4831s / 332.5040 s
agent0:                 episode reward: -1.0852,                 loss: nan
agent1:                 episode reward: 1.0852,                 loss: 0.2919
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4824s / 332.9864 s
agent0:                 episode reward: -0.9652,                 loss: nan
agent1:                 episode reward: 0.9652,                 loss: 0.2883
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4942s / 333.4807 s
agent0:                 episode reward: -0.9199,                 loss: nan
agent1:                 episode reward: 0.9199,                 loss: 0.2877
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4886s / 333.9693 s
agent0:                 episode reward: -0.3994,                 loss: nan
agent1:                 episode reward: 0.3994,                 loss: 0.2887
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4828s / 334.4521 s
agent0:                 episode reward: -0.8412,                 loss: nan
agent1:                 episode reward: 0.8412,                 loss: 0.2862
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4800s / 334.9321 s
agent0:                 episode reward: -0.8299,                 loss: nan
agent1:                 episode reward: 0.8299,                 loss: 0.2893
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5267s / 335.4587 s
agent0:                 episode reward: -0.7693,                 loss: nan
agent1:                 episode reward: 0.7693,                 loss: 0.2907
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4913s / 335.9501 s
agent0:                 episode reward: -0.8928,                 loss: nan
agent1:                 episode reward: 0.8928,                 loss: 0.2900
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5088s / 336.4589 s
agent0:                 episode reward: -0.7326,                 loss: nan
agent1:                 episode reward: 0.7326,                 loss: 0.2906
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4862s / 336.9450 s
agent0:                 episode reward: -0.6751,                 loss: nan
agent1:                 episode reward: 0.6751,                 loss: 0.2908
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4773s / 337.4223 s
agent0:                 episode reward: -0.8953,                 loss: nan
agent1:                 episode reward: 0.8953,                 loss: 0.3028
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4760s / 337.8983 s
agent0:                 episode reward: -0.9379,                 loss: nan
agent1:                 episode reward: 0.9379,                 loss: 0.2988
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4772s / 338.3755 s
agent0:                 episode reward: -1.0171,                 loss: nan
agent1:                 episode reward: 1.0171,                 loss: 0.2978
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4830s / 338.8585 s
agent0:                 episode reward: -0.7058,                 loss: nan
agent1:                 episode reward: 0.7058,                 loss: 0.2970
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5099s / 339.3684 s
agent0:                 episode reward: -0.6061,                 loss: nan
agent1:                 episode reward: 0.6061,                 loss: 0.2974
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4873s / 339.8557 s
agent0:                 episode reward: -0.9161,                 loss: nan
agent1:                 episode reward: 0.9161,                 loss: 0.2968
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4878s / 340.3435 s
agent0:                 episode reward: -0.9532,                 loss: nan
agent1:                 episode reward: 0.9532,                 loss: 0.2982
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4757s / 340.8192 s
agent0:                 episode reward: -1.0378,                 loss: nan
agent1:                 episode reward: 1.0378,                 loss: 0.2988
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4764s / 341.2955 s
agent0:                 episode reward: -1.0213,                 loss: nan
agent1:                 episode reward: 1.0213,                 loss: 0.2984
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4844s / 341.7799 s
agent0:                 episode reward: -0.8796,                 loss: nan
agent1:                 episode reward: 0.8796,                 loss: 0.2999
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4836s / 342.2635 s
agent0:                 episode reward: -0.8450,                 loss: nan
agent1:                 episode reward: 0.8450,                 loss: 0.3001
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5084s / 342.7719 s
agent0:                 episode reward: -0.7534,                 loss: nan
agent1:                 episode reward: 0.7534,                 loss: 0.2957
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4849s / 343.2567 s
agent0:                 episode reward: -0.7185,                 loss: nan
agent1:                 episode reward: 0.7185,                 loss: 0.2999
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4792s / 343.7360 s
agent0:                 episode reward: -0.7223,                 loss: nan
agent1:                 episode reward: 0.7223,                 loss: 0.2989
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5250s / 344.2609 s
agent0:                 episode reward: -0.7083,                 loss: nan
agent1:                 episode reward: 0.7083,                 loss: 0.3010
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5001s / 344.7611 s
agent0:                 episode reward: -0.6937,                 loss: nan
agent1:                 episode reward: 0.6937,                 loss: 0.3004
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4810s / 345.2421 s
agent0:                 episode reward: -0.7043,                 loss: nan
agent1:                 episode reward: 0.7043,                 loss: 0.2932
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5404s / 345.7825 s
agent0:                 episode reward: -0.8221,                 loss: nan
agent1:                 episode reward: 0.8221,                 loss: 0.2808
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5157s / 346.2982 s
agent0:                 episode reward: -0.9564,                 loss: nan
agent1:                 episode reward: 0.9564,                 loss: 0.2847
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4924s / 346.7906 s
agent0:                 episode reward: -0.9564,                 loss: nan
agent1:                 episode reward: 0.9564,                 loss: 0.2783
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4935s / 347.2840 s
agent0:                 episode reward: -0.6385,                 loss: nan
agent1:                 episode reward: 0.6385,                 loss: 0.2809
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4849s / 347.7689 s
agent0:                 episode reward: -0.8106,                 loss: nan
agent1:                 episode reward: 0.8106,                 loss: 0.2833
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4844s / 348.2533 s
agent0:                 episode reward: -0.5286,                 loss: nan
agent1:                 episode reward: 0.5286,                 loss: 0.2788
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4991s / 348.7524 s
agent0:                 episode reward: -0.7135,                 loss: nan
agent1:                 episode reward: 0.7135,                 loss: 0.2849
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4851s / 349.2376 s
agent0:                 episode reward: -0.8279,                 loss: nan
agent1:                 episode reward: 0.8279,                 loss: 0.2779
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5115s / 349.7490 s
agent0:                 episode reward: -0.7678,                 loss: nan
agent1:                 episode reward: 0.7678,                 loss: 0.2789
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4886s / 350.2376 s
agent0:                 episode reward: -0.9473,                 loss: nan
agent1:                 episode reward: 0.9473,                 loss: 0.2809
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4920s / 350.7296 s
agent0:                 episode reward: -0.7776,                 loss: nan
agent1:                 episode reward: 0.7776,                 loss: 0.2790
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4866s / 351.2162 s
agent0:                 episode reward: -0.7015,                 loss: nan
agent1:                 episode reward: 0.7015,                 loss: 0.2804
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5192s / 351.7354 s
agent0:                 episode reward: -0.7493,                 loss: nan
agent1:                 episode reward: 0.7493,                 loss: 0.2763
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4847s / 352.2201 s
agent0:                 episode reward: -0.6423,                 loss: nan
agent1:                 episode reward: 0.6423,                 loss: 0.2804
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4875s / 352.7076 s
agent0:                 episode reward: -0.7868,                 loss: nan
agent1:                 episode reward: 0.7868,                 loss: 0.2794
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5042s / 353.2118 s
agent0:                 episode reward: -0.3039,                 loss: nan
agent1:                 episode reward: 0.3039,                 loss: 0.2831
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4917s / 353.7035 s
agent0:                 episode reward: -0.6487,                 loss: nan
agent1:                 episode reward: 0.6487,                 loss: 0.2853
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4901s / 354.1936 s
agent0:                 episode reward: -0.6036,                 loss: nan
agent1:                 episode reward: 0.6036,                 loss: 0.2776
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4968s / 354.6904 s
agent0:                 episode reward: -0.5677,                 loss: nan
agent1:                 episode reward: 0.5677,                 loss: 0.2820
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5148s / 355.2052 s
agent0:                 episode reward: -0.8564,                 loss: nan
agent1:                 episode reward: 0.8564,                 loss: 0.2841
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4866s / 355.6918 s
agent0:                 episode reward: -0.7935,                 loss: nan
agent1:                 episode reward: 0.7935,                 loss: 0.2790
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5517s / 356.2435 s
agent0:                 episode reward: -0.9843,                 loss: nan
agent1:                 episode reward: 0.9843,                 loss: 0.2825
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4873s / 356.7308 s
agent0:                 episode reward: -0.6879,                 loss: nan
agent1:                 episode reward: 0.6879,                 loss: 0.2813
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4897s / 357.2206 s
agent0:                 episode reward: -0.7726,                 loss: nan
agent1:                 episode reward: 0.7726,                 loss: 0.2830
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5235s / 357.7441 s
agent0:                 episode reward: -0.6921,                 loss: nan
agent1:                 episode reward: 0.6921,                 loss: 0.2825
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4934s / 358.2375 s
agent0:                 episode reward: -0.8418,                 loss: nan
agent1:                 episode reward: 0.8418,                 loss: 0.2809
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5236s / 358.7611 s
agent0:                 episode reward: -0.6646,                 loss: nan
agent1:                 episode reward: 0.6646,                 loss: 0.2803
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5163s / 359.2774 s
agent0:                 episode reward: -0.9154,                 loss: nan
agent1:                 episode reward: 0.9154,                 loss: 0.2834
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4878s / 359.7653 s
agent0:                 episode reward: -0.7693,                 loss: nan
agent1:                 episode reward: 0.7693,                 loss: 0.2818
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4960s / 360.2612 s
agent0:                 episode reward: -0.7050,                 loss: nan
agent1:                 episode reward: 0.7050,                 loss: 0.2803
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5205s / 360.7817 s
agent0:                 episode reward: -0.6782,                 loss: nan
agent1:                 episode reward: 0.6782,                 loss: 0.2771
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5127s / 361.2943 s
agent0:                 episode reward: -0.7953,                 loss: nan
agent1:                 episode reward: 0.7953,                 loss: 0.2833
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5217s / 361.8161 s
agent0:                 episode reward: -0.6946,                 loss: nan
agent1:                 episode reward: 0.6946,                 loss: 0.2857
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5026s / 362.3186 s
agent0:                 episode reward: -0.7058,                 loss: nan
agent1:                 episode reward: 0.7058,                 loss: 0.3077
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4914s / 362.8101 s
agent0:                 episode reward: -0.9740,                 loss: nan
agent1:                 episode reward: 0.9740,                 loss: 0.2997
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4934s / 363.3035 s
agent0:                 episode reward: -0.6797,                 loss: nan
agent1:                 episode reward: 0.6797,                 loss: 0.2998
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5022s / 363.8057 s
agent0:                 episode reward: -0.7344,                 loss: nan
agent1:                 episode reward: 0.7344,                 loss: 0.3008
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4997s / 364.3054 s
agent0:                 episode reward: -0.2839,                 loss: nan
agent1:                 episode reward: 0.2839,                 loss: 0.2999
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5483s / 364.8537 s
agent0:                 episode reward: -0.7947,                 loss: nan
agent1:                 episode reward: 0.7947,                 loss: 0.2988
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4920s / 365.3457 s
agent0:                 episode reward: -0.4121,                 loss: nan
agent1:                 episode reward: 0.4121,                 loss: 0.2970
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4932s / 365.8389 s
agent0:                 episode reward: -0.8032,                 loss: nan
agent1:                 episode reward: 0.8032,                 loss: 0.2975
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5365s / 366.3754 s
agent0:                 episode reward: -0.6976,                 loss: nan
agent1:                 episode reward: 0.6976,                 loss: 0.3010
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5054s / 366.8808 s
agent0:                 episode reward: -0.6904,                 loss: nan
agent1:                 episode reward: 0.6904,                 loss: 0.2988
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4935s / 367.3743 s
agent0:                 episode reward: -0.5672,                 loss: nan
agent1:                 episode reward: 0.5672,                 loss: 0.2991
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4938s / 367.8681 s
agent0:                 episode reward: -0.8743,                 loss: nan
agent1:                 episode reward: 0.8743,                 loss: 0.2961
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4950s / 368.3631 s
agent0:                 episode reward: -0.8362,                 loss: nan
agent1:                 episode reward: 0.8362,                 loss: 0.3008
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4935s / 368.8566 s
agent0:                 episode reward: -0.7703,                 loss: nan
agent1:                 episode reward: 0.7703,                 loss: 0.2971
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4997s / 369.3563 s
agent0:                 episode reward: -0.5552,                 loss: nan
agent1:                 episode reward: 0.5552,                 loss: 0.3004
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5295s / 369.8858 s
agent0:                 episode reward: -0.3732,                 loss: nan
agent1:                 episode reward: 0.3732,                 loss: 0.3003
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5131s / 370.3990 s
agent0:                 episode reward: -0.7273,                 loss: nan
agent1:                 episode reward: 0.7273,                 loss: 0.2932
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5040s / 370.9030 s
agent0:                 episode reward: -0.4874,                 loss: nan
agent1:                 episode reward: 0.4874,                 loss: 0.2676
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5023s / 371.4052 s
agent0:                 episode reward: -0.9672,                 loss: nan
agent1:                 episode reward: 0.9672,                 loss: 0.2690
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5055s / 371.9107 s
agent0:                 episode reward: -0.5618,                 loss: nan
agent1:                 episode reward: 0.5618,                 loss: 0.2652
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5086s / 372.4193 s
agent0:                 episode reward: -0.7318,                 loss: nan
agent1:                 episode reward: 0.7318,                 loss: 0.2638
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5146s / 372.9339 s
agent0:                 episode reward: -0.6147,                 loss: nan
agent1:                 episode reward: 0.6147,                 loss: 0.2663
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5243s / 373.4582 s
agent0:                 episode reward: -1.0167,                 loss: nan
agent1:                 episode reward: 1.0167,                 loss: 0.2687
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5023s / 373.9605 s
agent0:                 episode reward: -0.8702,                 loss: nan
agent1:                 episode reward: 0.8702,                 loss: 0.2662
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5244s / 374.4850 s
agent0:                 episode reward: -0.7590,                 loss: nan
agent1:                 episode reward: 0.7590,                 loss: 0.2690
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4966s / 374.9815 s
agent0:                 episode reward: -0.7768,                 loss: nan
agent1:                 episode reward: 0.7768,                 loss: 0.2691
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4993s / 375.4808 s
agent0:                 episode reward: -0.4886,                 loss: nan
agent1:                 episode reward: 0.4886,                 loss: 0.2662
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5046s / 375.9854 s
agent0:                 episode reward: -0.7031,                 loss: nan
agent1:                 episode reward: 0.7031,                 loss: 0.2668
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5742s / 376.5596 s
agent0:                 episode reward: -0.6345,                 loss: nan
agent1:                 episode reward: 0.6345,                 loss: 0.2671
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5025s / 377.0621 s
agent0:                 episode reward: -0.4610,                 loss: nan
agent1:                 episode reward: 0.4610,                 loss: 0.2682
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4986s / 377.5607 s
agent0:                 episode reward: -0.8284,                 loss: nan
agent1:                 episode reward: 0.8284,                 loss: 0.2661
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5158s / 378.0765 s
agent0:                 episode reward: -0.9742,                 loss: nan
agent1:                 episode reward: 0.9742,                 loss: 0.2673
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4988s / 378.5753 s
agent0:                 episode reward: -0.6051,                 loss: nan
agent1:                 episode reward: 0.6051,                 loss: 0.2674
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5161s / 379.0914 s
agent0:                 episode reward: -0.9255,                 loss: nan
agent1:                 episode reward: 0.9255,                 loss: 0.2894
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5054s / 379.5968 s
agent0:                 episode reward: -0.7828,                 loss: nan
agent1:                 episode reward: 0.7828,                 loss: 0.2938
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5048s / 380.1017 s
agent0:                 episode reward: -0.8631,                 loss: nan
agent1:                 episode reward: 0.8631,                 loss: 0.2876
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5032s / 380.6049 s
agent0:                 episode reward: -0.5868,                 loss: nan
agent1:                 episode reward: 0.5868,                 loss: 0.2895
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5062s / 381.1111 s
agent0:                 episode reward: -1.0604,                 loss: nan
agent1:                 episode reward: 1.0604,                 loss: 0.2927
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5113s / 381.6224 s
agent0:                 episode reward: -0.5715,                 loss: nan
agent1:                 episode reward: 0.5715,                 loss: 0.2942
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5121s / 382.1345 s
agent0:                 episode reward: -0.6995,                 loss: nan
agent1:                 episode reward: 0.6995,                 loss: 0.2952
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5131s / 382.6476 s
agent0:                 episode reward: -0.9349,                 loss: nan
agent1:                 episode reward: 0.9349,                 loss: 0.2921
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5092s / 383.1568 s
agent0:                 episode reward: -0.9876,                 loss: nan
agent1:                 episode reward: 0.9876,                 loss: 0.2936
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5084s / 383.6652 s
agent0:                 episode reward: -0.4144,                 loss: nan
agent1:                 episode reward: 0.4144,                 loss: 0.2895
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5377s / 384.2029 s
agent0:                 episode reward: -1.1332,                 loss: nan
agent1:                 episode reward: 1.1332,                 loss: 0.2950
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5129s / 384.7158 s
agent0:                 episode reward: -0.8376,                 loss: nan
agent1:                 episode reward: 0.8376,                 loss: 0.2950
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5069s / 385.2228 s
agent0:                 episode reward: -0.8491,                 loss: nan
agent1:                 episode reward: 0.8491,                 loss: 0.2917
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5069s / 385.7296 s
agent0:                 episode reward: -0.6175,                 loss: nan
agent1:                 episode reward: 0.6175,                 loss: 0.2904
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5218s / 386.2514 s
agent0:                 episode reward: -0.9151,                 loss: nan
agent1:                 episode reward: 0.9151,                 loss: 0.2926
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5471s / 386.7985 s
agent0:                 episode reward: -0.5802,                 loss: nan
agent1:                 episode reward: 0.5802,                 loss: 0.2936
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5107s / 387.3092 s
agent0:                 episode reward: -0.5621,                 loss: nan
agent1:                 episode reward: 0.5621,                 loss: 0.2953
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5212s / 387.8304 s
agent0:                 episode reward: -1.0661,                 loss: nan
agent1:                 episode reward: 1.0661,                 loss: 0.2952
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5118s / 388.3422 s
agent0:                 episode reward: -0.4864,                 loss: nan
agent1:                 episode reward: 0.4864,                 loss: 0.2901
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5117s / 388.8539 s
agent0:                 episode reward: -0.7723,                 loss: nan
agent1:                 episode reward: 0.7723,                 loss: 0.2906
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5096s / 389.3635 s
agent0:                 episode reward: -1.0421,                 loss: nan
agent1:                 episode reward: 1.0421,                 loss: 0.2920
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5104s / 389.8738 s
agent0:                 episode reward: -0.6665,                 loss: nan
agent1:                 episode reward: 0.6665,                 loss: 0.2918
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5144s / 390.3883 s
agent0:                 episode reward: -0.9221,                 loss: nan
agent1:                 episode reward: 0.9221,                 loss: 0.2905
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5239s / 390.9121 s
agent0:                 episode reward: -0.5097,                 loss: nan
agent1:                 episode reward: 0.5097,                 loss: 0.2901
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5153s / 391.4274 s
agent0:                 episode reward: -0.6123,                 loss: nan
agent1:                 episode reward: 0.6123,                 loss: 0.2872
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5111s / 391.9385 s
agent0:                 episode reward: -0.6690,                 loss: nan
agent1:                 episode reward: 0.6690,                 loss: 0.2889
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5158s / 392.4543 s
agent0:                 episode reward: -0.8061,                 loss: nan
agent1:                 episode reward: 0.8061,                 loss: 0.2872
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5065s / 392.9607 s
agent0:                 episode reward: -0.8302,                 loss: nan
agent1:                 episode reward: 0.8302,                 loss: 0.2902
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5097s / 393.4704 s
agent0:                 episode reward: -0.8516,                 loss: nan
agent1:                 episode reward: 0.8516,                 loss: 0.2909
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5181s / 393.9885 s
agent0:                 episode reward: -0.6035,                 loss: nan
agent1:                 episode reward: 0.6035,                 loss: 0.2897
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5190s / 394.5075 s
agent0:                 episode reward: -1.0430,                 loss: nan
agent1:                 episode reward: 1.0430,                 loss: 0.2916
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5075s / 395.0150 s
agent0:                 episode reward: -1.0306,                 loss: nan
agent1:                 episode reward: 1.0306,                 loss: 0.2904
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5118s / 395.5269 s
agent0:                 episode reward: -0.6372,                 loss: nan
agent1:                 episode reward: 0.6372,                 loss: 0.2912
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5069s / 396.0338 s
agent0:                 episode reward: -0.6867,                 loss: nan
agent1:                 episode reward: 0.6867,                 loss: 0.2973
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5102s / 396.5440 s
agent0:                 episode reward: -1.2717,                 loss: nan
agent1:                 episode reward: 1.2717,                 loss: 0.2669
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5584s / 397.1024 s
agent0:                 episode reward: -1.0071,                 loss: nan
agent1:                 episode reward: 1.0071,                 loss: 0.2708
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5168s / 397.6192 s
agent0:                 episode reward: -0.6338,                 loss: nan
agent1:                 episode reward: 0.6338,                 loss: 0.2704
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5075s / 398.1267 s
agent0:                 episode reward: -0.1612,                 loss: nan
agent1:                 episode reward: 0.1612,                 loss: 0.2708
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5126s / 398.6393 s
agent0:                 episode reward: -0.9405,                 loss: nan
agent1:                 episode reward: 0.9405,                 loss: 0.2704
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5076s / 399.1469 s
agent0:                 episode reward: -1.0043,                 loss: nan
agent1:                 episode reward: 1.0043,                 loss: 0.2683
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5281s / 399.6750 s
agent0:                 episode reward: -0.7010,                 loss: nan
agent1:                 episode reward: 0.7010,                 loss: 0.2711
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5177s / 400.1927 s
agent0:                 episode reward: -0.5974,                 loss: nan
agent1:                 episode reward: 0.5974,                 loss: 0.2705
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5105s / 400.7032 s
agent0:                 episode reward: -0.6299,                 loss: nan
agent1:                 episode reward: 0.6299,                 loss: 0.2668
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5110s / 401.2141 s
agent0:                 episode reward: -0.5207,                 loss: nan
agent1:                 episode reward: 0.5207,                 loss: 0.2680
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5138s / 401.7279 s
agent0:                 episode reward: -0.7050,                 loss: nan
agent1:                 episode reward: 0.7050,                 loss: 0.2692
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5360s / 402.2639 s
agent0:                 episode reward: -0.7173,                 loss: nan
agent1:                 episode reward: 0.7173,                 loss: 0.2673
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5334s / 402.7973 s
agent0:                 episode reward: -0.8830,                 loss: nan
agent1:                 episode reward: 0.8830,                 loss: 0.2628
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5209s / 403.3182 s
agent0:                 episode reward: -0.5795,                 loss: nan
agent1:                 episode reward: 0.5795,                 loss: 0.2714
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5190s / 403.8372 s
agent0:                 episode reward: -1.0175,                 loss: nan
agent1:                 episode reward: 1.0175,                 loss: 0.2711
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5103s / 404.3475 s
agent0:                 episode reward: -0.7818,                 loss: nan
agent1:                 episode reward: 0.7818,                 loss: 0.2686
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5133s / 404.8608 s
agent0:                 episode reward: -0.6481,                 loss: nan
agent1:                 episode reward: 0.6481,                 loss: 0.2901
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5160s / 405.3768 s
agent0:                 episode reward: -0.6918,                 loss: nan
agent1:                 episode reward: 0.6918,                 loss: 0.2918
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5244s / 405.9012 s
agent0:                 episode reward: -1.0301,                 loss: nan
agent1:                 episode reward: 1.0301,                 loss: 0.2903
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5145s / 406.4157 s
agent0:                 episode reward: -0.8699,                 loss: nan
agent1:                 episode reward: 0.8699,                 loss: 0.2937
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5283s / 406.9440 s
agent0:                 episode reward: -0.6631,                 loss: nan
agent1:                 episode reward: 0.6631,                 loss: 0.2917
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5743s / 407.5184 s
agent0:                 episode reward: -0.5235,                 loss: nan
agent1:                 episode reward: 0.5235,                 loss: 0.2936
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5140s / 408.0323 s
agent0:                 episode reward: -0.6785,                 loss: nan
agent1:                 episode reward: 0.6785,                 loss: 0.2935
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5216s / 408.5540 s
agent0:                 episode reward: -0.8955,                 loss: nan
agent1:                 episode reward: 0.8955,                 loss: 0.2955
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5219s / 409.0758 s
agent0:                 episode reward: -0.8915,                 loss: nan
agent1:                 episode reward: 0.8915,                 loss: 0.2929
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5527s / 409.6285 s
agent0:                 episode reward: -0.7389,                 loss: nan
agent1:                 episode reward: 0.7389,                 loss: 0.2908
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5292s / 410.1576 s
agent0:                 episode reward: -0.8713,                 loss: nan
agent1:                 episode reward: 0.8713,                 loss: 0.2905
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5165s / 410.6742 s
agent0:                 episode reward: -0.6573,                 loss: nan
agent1:                 episode reward: 0.6573,                 loss: 0.2906
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5403s / 411.2145 s
agent0:                 episode reward: -1.0256,                 loss: nan
agent1:                 episode reward: 1.0256,                 loss: 0.2946
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5317s / 411.7462 s
agent0:                 episode reward: -0.6822,                 loss: nan
agent1:                 episode reward: 0.6822,                 loss: 0.2900
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5293s / 412.2754 s
agent0:                 episode reward: -0.9924,                 loss: nan
agent1:                 episode reward: 0.9924,                 loss: 0.2917
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5376s / 412.8130 s
agent0:                 episode reward: -0.7418,                 loss: nan
agent1:                 episode reward: 0.7418,                 loss: 0.2934
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5284s / 413.3414 s
agent0:                 episode reward: -0.8190,                 loss: nan
agent1:                 episode reward: 0.8190,                 loss: 0.3003
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5310s / 413.8724 s
agent0:                 episode reward: -0.4834,                 loss: nan
agent1:                 episode reward: 0.4834,                 loss: 0.2928
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5262s / 414.3986 s
agent0:                 episode reward: -0.5045,                 loss: nan
agent1:                 episode reward: 0.5045,                 loss: 0.2859
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5387s / 414.9373 s
agent0:                 episode reward: -0.7128,                 loss: nan
agent1:                 episode reward: 0.7128,                 loss: 0.2803
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5340s / 415.4713 s
agent0:                 episode reward: -0.5741,                 loss: nan
agent1:                 episode reward: 0.5741,                 loss: 0.2803
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5295s / 416.0008 s
agent0:                 episode reward: -1.0576,                 loss: nan
agent1:                 episode reward: 1.0576,                 loss: 0.2867
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5267s / 416.5275 s
agent0:                 episode reward: -0.3371,                 loss: nan
agent1:                 episode reward: 0.3371,                 loss: 0.2839
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5313s / 417.0588 s
agent0:                 episode reward: -0.5282,                 loss: nan
agent1:                 episode reward: 0.5282,                 loss: 0.2837
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 417.6453 s
agent0:                 episode reward: -0.5421,                 loss: nan
agent1:                 episode reward: 0.5421,                 loss: 0.2862
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5347s / 418.1799 s
agent0:                 episode reward: -0.7579,                 loss: nan
agent1:                 episode reward: 0.7579,                 loss: 0.2855
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5299s / 418.7098 s
agent0:                 episode reward: -0.6438,                 loss: nan
agent1:                 episode reward: 0.6438,                 loss: 0.2833
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5437s / 419.2535 s
agent0:                 episode reward: -1.0379,                 loss: nan
agent1:                 episode reward: 1.0379,                 loss: 0.2840
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5303s / 419.7837 s
agent0:                 episode reward: -0.6492,                 loss: nan
agent1:                 episode reward: 0.6492,                 loss: 0.2819
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5262s / 420.3099 s
agent0:                 episode reward: -0.6729,                 loss: nan
agent1:                 episode reward: 0.6729,                 loss: 0.2835
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5463s / 420.8562 s
agent0:                 episode reward: -0.9347,                 loss: nan
agent1:                 episode reward: 0.9347,                 loss: 0.2840
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5233s / 421.3795 s
agent0:                 episode reward: -0.6501,                 loss: nan
agent1:                 episode reward: 0.6501,                 loss: 0.2853
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5255s / 421.9051 s
agent0:                 episode reward: -0.9093,                 loss: nan
agent1:                 episode reward: 0.9093,                 loss: 0.2840
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5224s / 422.4274 s
agent0:                 episode reward: -0.7902,                 loss: nan
agent1:                 episode reward: 0.7902,                 loss: 0.2910
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5379s / 422.9653 s
agent0:                 episode reward: -0.8885,                 loss: nan
agent1:                 episode reward: 0.8885,                 loss: 0.2704
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5280s / 423.4933 s
agent0:                 episode reward: -0.7897,                 loss: nan
agent1:                 episode reward: 0.7897,                 loss: 0.2663
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5364s / 424.0297 s
agent0:                 episode reward: -0.8514,                 loss: nan
agent1:                 episode reward: 0.8514,                 loss: 0.2641
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5254s / 424.5551 s
agent0:                 episode reward: -1.0025,                 loss: nan
agent1:                 episode reward: 1.0025,                 loss: 0.2645
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5341s / 425.0892 s
agent0:                 episode reward: -0.9537,                 loss: nan
agent1:                 episode reward: 0.9537,                 loss: 0.2625
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5372s / 425.6264 s
agent0:                 episode reward: -1.1393,                 loss: nan
agent1:                 episode reward: 1.1393,                 loss: 0.2630
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5321s / 426.1585 s
agent0:                 episode reward: -1.0067,                 loss: nan
agent1:                 episode reward: 1.0067,                 loss: 0.2655
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5394s / 426.6979 s
agent0:                 episode reward: -0.9164,                 loss: nan
agent1:                 episode reward: 0.9164,                 loss: 0.2638
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5353s / 427.2333 s
agent0:                 episode reward: -0.8880,                 loss: nan
agent1:                 episode reward: 0.8880,                 loss: 0.2643
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 427.8258 s
agent0:                 episode reward: -0.6702,                 loss: nan
agent1:                 episode reward: 0.6702,                 loss: 0.2631
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5347s / 428.3605 s
agent0:                 episode reward: -0.7510,                 loss: nan
agent1:                 episode reward: 0.7510,                 loss: 0.2647
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5310s / 428.8914 s
agent0:                 episode reward: -0.7405,                 loss: nan
agent1:                 episode reward: 0.7405,                 loss: 0.2630
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 429.4727 s
agent0:                 episode reward: -0.9071,                 loss: nan
agent1:                 episode reward: 0.9071,                 loss: 0.2646
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5427s / 430.0154 s
agent0:                 episode reward: -0.4541,                 loss: nan
agent1:                 episode reward: 0.4541,                 loss: 0.2609
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5330s / 430.5484 s
agent0:                 episode reward: -0.9935,                 loss: nan
agent1:                 episode reward: 0.9935,                 loss: 0.2609
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5341s / 431.0825 s
agent0:                 episode reward: -0.6099,                 loss: nan
agent1:                 episode reward: 0.6099,                 loss: 0.2622
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5328s / 431.6153 s
agent0:                 episode reward: -0.8302,                 loss: nan
agent1:                 episode reward: 0.8302,                 loss: 0.2987
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5332s / 432.1485 s
agent0:                 episode reward: -0.7692,                 loss: nan
agent1:                 episode reward: 0.7692,                 loss: 0.3010
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5447s / 432.6932 s
agent0:                 episode reward: -0.8667,                 loss: nan
agent1:                 episode reward: 0.8667,                 loss: 0.2978
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5433s / 433.2366 s
agent0:                 episode reward: -0.7494,                 loss: nan
agent1:                 episode reward: 0.7494,                 loss: 0.3046
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5384s / 433.7750 s
agent0:                 episode reward: -0.7434,                 loss: nan
agent1:                 episode reward: 0.7434,                 loss: 0.3033
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5352s / 434.3101 s
agent0:                 episode reward: -0.6372,                 loss: nan
agent1:                 episode reward: 0.6372,                 loss: 0.2997
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5352s / 434.8454 s
agent0:                 episode reward: -1.1254,                 loss: nan
agent1:                 episode reward: 1.1254,                 loss: 0.3017
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5354s / 435.3807 s
agent0:                 episode reward: -0.3328,                 loss: nan
agent1:                 episode reward: 0.3328,                 loss: 0.3036
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5601s / 435.9408 s
agent0:                 episode reward: -0.6276,                 loss: nan
agent1:                 episode reward: 0.6276,                 loss: 0.2998
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5395s / 436.4803 s
agent0:                 episode reward: -0.7046,                 loss: nan
agent1:                 episode reward: 0.7046,                 loss: 0.3019
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5391s / 437.0194 s
agent0:                 episode reward: -0.4867,                 loss: nan
agent1:                 episode reward: 0.4867,                 loss: 0.2986
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5413s / 437.5607 s
agent0:                 episode reward: -0.9857,                 loss: nan
agent1:                 episode reward: 0.9857,                 loss: 0.2990
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 438.1467 s
agent0:                 episode reward: -1.2489,                 loss: nan
agent1:                 episode reward: 1.2489,                 loss: 0.2994
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5576s / 438.7043 s
agent0:                 episode reward: -0.6631,                 loss: nan
agent1:                 episode reward: 0.6631,                 loss: 0.3019
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5464s / 439.2507 s
agent0:                 episode reward: -0.5275,                 loss: nan
agent1:                 episode reward: 0.5275,                 loss: 0.3001
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5432s / 439.7939 s
agent0:                 episode reward: -1.0086,                 loss: nan
agent1:                 episode reward: 1.0086,                 loss: 0.2992
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5440s / 440.3379 s
agent0:                 episode reward: -0.5351,                 loss: nan
agent1:                 episode reward: 0.5351,                 loss: 0.2982
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5387s / 440.8767 s
agent0:                 episode reward: -0.8706,                 loss: nan
agent1:                 episode reward: 0.8706,                 loss: 0.2920
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5382s / 441.4149 s
agent0:                 episode reward: -0.7486,                 loss: nan
agent1:                 episode reward: 0.7486,                 loss: 0.2864
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5477s / 441.9626 s
agent0:                 episode reward: -0.9766,                 loss: nan
agent1:                 episode reward: 0.9766,                 loss: 0.2857
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5387s / 442.5013 s
agent0:                 episode reward: -0.8328,                 loss: nan
agent1:                 episode reward: 0.8328,                 loss: 0.2904
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5764s / 443.0776 s
agent0:                 episode reward: -0.7229,                 loss: nan
agent1:                 episode reward: 0.7229,                 loss: 0.2887
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5381s / 443.6157 s
agent0:                 episode reward: -0.9694,                 loss: nan
agent1:                 episode reward: 0.9694,                 loss: 0.2880
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5558s / 444.1715 s
agent0:                 episode reward: -0.9080,                 loss: nan
agent1:                 episode reward: 0.9080,                 loss: 0.2873
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5533s / 444.7248 s
agent0:                 episode reward: -0.3452,                 loss: nan
agent1:                 episode reward: 0.3452,                 loss: 0.2851
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5483s / 445.2731 s
agent0:                 episode reward: -1.2008,                 loss: nan
agent1:                 episode reward: 1.2008,                 loss: 0.2871
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5409s / 445.8140 s
agent0:                 episode reward: -0.5164,                 loss: nan
agent1:                 episode reward: 0.5164,                 loss: 0.2872
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5388s / 446.3528 s
agent0:                 episode reward: -0.8611,                 loss: nan
agent1:                 episode reward: 0.8611,                 loss: 0.2870
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5382s / 446.8911 s
agent0:                 episode reward: -0.6593,                 loss: nan
agent1:                 episode reward: 0.6593,                 loss: 0.2864
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5494s / 447.4404 s
agent0:                 episode reward: -0.6250,                 loss: nan
agent1:                 episode reward: 0.6250,                 loss: 0.2860
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5692s / 448.0097 s
agent0:                 episode reward: -0.7114,                 loss: nan
agent1:                 episode reward: 0.7114,                 loss: 0.2891
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 448.5932 s
agent0:                 episode reward: -0.9336,                 loss: nan
agent1:                 episode reward: 0.9336,                 loss: 0.2861
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5483s / 449.1415 s
agent0:                 episode reward: -0.9654,                 loss: nan
agent1:                 episode reward: 0.9654,                 loss: 0.2885
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5404s / 449.6819 s
agent0:                 episode reward: -0.7359,                 loss: nan
agent1:                 episode reward: 0.7359,                 loss: 0.2960
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5382s / 450.2201 s
agent0:                 episode reward: -0.3669,                 loss: nan
agent1:                 episode reward: 0.3669,                 loss: 0.2654
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5448s / 450.7649 s
agent0:                 episode reward: -0.5891,                 loss: nan
agent1:                 episode reward: 0.5891,                 loss: 0.2629
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5389s / 451.3038 s
agent0:                 episode reward: -0.6753,                 loss: nan
agent1:                 episode reward: 0.6753,                 loss: 0.2606
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5375s / 451.8413 s
agent0:                 episode reward: -0.8430,                 loss: nan
agent1:                 episode reward: 0.8430,                 loss: 0.2648
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5542s / 452.3955 s
agent0:                 episode reward: -0.8195,                 loss: nan
agent1:                 episode reward: 0.8195,                 loss: 0.2606
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5436s / 452.9391 s
agent0:                 episode reward: -0.3823,                 loss: nan
agent1:                 episode reward: 0.3823,                 loss: 0.2620
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5640s / 453.5031 s
agent0:                 episode reward: -0.7386,                 loss: nan
agent1:                 episode reward: 0.7386,                 loss: 0.2653
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5491s / 454.0523 s
agent0:                 episode reward: -1.0964,                 loss: nan
agent1:                 episode reward: 1.0964,                 loss: 0.2598
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5528s / 454.6050 s
agent0:                 episode reward: -0.9266,                 loss: nan
agent1:                 episode reward: 0.9266,                 loss: 0.2608
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5470s / 455.1520 s
agent0:                 episode reward: -0.9495,                 loss: nan
agent1:                 episode reward: 0.9495,                 loss: 0.2632
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5409s / 455.6929 s
agent0:                 episode reward: -0.7515,                 loss: nan
agent1:                 episode reward: 0.7515,                 loss: 0.2638
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5490s / 456.2419 s
agent0:                 episode reward: -0.5000,                 loss: nan
agent1:                 episode reward: 0.5000,                 loss: 0.2611
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5620s / 456.8039 s
agent0:                 episode reward: -0.9181,                 loss: nan
agent1:                 episode reward: 0.9181,                 loss: 0.2640
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5503s / 457.3542 s
agent0:                 episode reward: -1.0537,                 loss: nan
agent1:                 episode reward: 1.0537,                 loss: 0.2622
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5483s / 457.9025 s
agent0:                 episode reward: -0.6303,                 loss: nan
agent1:                 episode reward: 0.6303,                 loss: 0.2619
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 458.4905 s
agent0:                 episode reward: -0.7532,                 loss: nan
agent1:                 episode reward: 0.7532,                 loss: 0.2590
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5498s / 459.0402 s
agent0:                 episode reward: -0.9330,                 loss: nan
agent1:                 episode reward: 0.9330,                 loss: 0.2985
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5526s / 459.5928 s
agent0:                 episode reward: -0.8742,                 loss: nan
agent1:                 episode reward: 0.8742,                 loss: 0.3050
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5496s / 460.1424 s
agent0:                 episode reward: -0.7306,                 loss: nan
agent1:                 episode reward: 0.7306,                 loss: 0.3026
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5607s / 460.7031 s
agent0:                 episode reward: -0.6592,                 loss: nan
agent1:                 episode reward: 0.6592,                 loss: 0.3063
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5577s / 461.2608 s
agent0:                 episode reward: -0.5442,                 loss: nan
agent1:                 episode reward: 0.5442,                 loss: 0.3045
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5563s / 461.8171 s
agent0:                 episode reward: -0.4488,                 loss: nan
agent1:                 episode reward: 0.4488,                 loss: 0.3044
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5536s / 462.3707 s
agent0:                 episode reward: -0.9203,                 loss: nan
agent1:                 episode reward: 0.9203,                 loss: 0.3059
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5835s / 462.9542 s
agent0:                 episode reward: -0.8452,                 loss: nan
agent1:                 episode reward: 0.8452,                 loss: 0.3035
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5666s / 463.5208 s
agent0:                 episode reward: -0.3803,                 loss: nan
agent1:                 episode reward: 0.3803,                 loss: 0.3043
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5458s / 464.0666 s
agent0:                 episode reward: -0.6047,                 loss: nan
agent1:                 episode reward: 0.6047,                 loss: 0.3055
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5478s / 464.6145 s
agent0:                 episode reward: -0.5808,                 loss: nan
agent1:                 episode reward: 0.5808,                 loss: 0.3059
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5710s / 465.1855 s
agent0:                 episode reward: -0.7582,                 loss: nan
agent1:                 episode reward: 0.7582,                 loss: 0.3061
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5567s / 465.7422 s
agent0:                 episode reward: -0.6664,                 loss: nan
agent1:                 episode reward: 0.6664,                 loss: 0.3039
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5571s / 466.2993 s
agent0:                 episode reward: -0.6439,                 loss: nan
agent1:                 episode reward: 0.6439,                 loss: 0.3045
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5553s / 466.8546 s
agent0:                 episode reward: -1.0058,                 loss: nan
agent1:                 episode reward: 1.0058,                 loss: 0.3030
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5558s / 467.4104 s
agent0:                 episode reward: -1.1501,                 loss: nan
agent1:                 episode reward: 1.1501,                 loss: 0.3023
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5574s / 467.9679 s
agent0:                 episode reward: -0.2268,                 loss: nan
agent1:                 episode reward: 0.2268,                 loss: 0.3033
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6185s / 468.5864 s
agent0:                 episode reward: -0.9586,                 loss: nan
agent1:                 episode reward: 0.9586,                 loss: 0.2908
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5760s / 469.1624 s
agent0:                 episode reward: -0.5873,                 loss: nan
agent1:                 episode reward: 0.5873,                 loss: 0.2889
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5559s / 469.7183 s
agent0:                 episode reward: -1.1019,                 loss: nan
agent1:                 episode reward: 1.1019,                 loss: 0.2855
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5564s / 470.2747 s
agent0:                 episode reward: -0.7246,                 loss: nan
agent1:                 episode reward: 0.7246,                 loss: 0.2877
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5581s / 470.8329 s
agent0:                 episode reward: -0.9008,                 loss: nan
agent1:                 episode reward: 0.9008,                 loss: 0.2854
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5591s / 471.3919 s
agent0:                 episode reward: -0.9676,                 loss: nan
agent1:                 episode reward: 0.9676,                 loss: 0.2840
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5632s / 471.9552 s
agent0:                 episode reward: -0.8585,                 loss: nan
agent1:                 episode reward: 0.8585,                 loss: 0.2867
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5564s / 472.5116 s
agent0:                 episode reward: -0.7911,                 loss: nan
agent1:                 episode reward: 0.7911,                 loss: 0.2877
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5576s / 473.0692 s
agent0:                 episode reward: -0.8193,                 loss: nan
agent1:                 episode reward: 0.8193,                 loss: 0.2844
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5677s / 473.6369 s
agent0:                 episode reward: -0.7974,                 loss: nan
agent1:                 episode reward: 0.7974,                 loss: 0.2881
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5562s / 474.1931 s
agent0:                 episode reward: -0.9400,                 loss: nan
agent1:                 episode reward: 0.9400,                 loss: 0.2873
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5673s / 474.7604 s
agent0:                 episode reward: -0.9639,                 loss: nan
agent1:                 episode reward: 0.9639,                 loss: 0.2858
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5572s / 475.3176 s
agent0:                 episode reward: -0.5256,                 loss: nan
agent1:                 episode reward: 0.5256,                 loss: 0.2824
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5597s / 475.8773 s
agent0:                 episode reward: -1.1200,                 loss: nan
agent1:                 episode reward: 1.1200,                 loss: 0.2845
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5618s / 476.4391 s
agent0:                 episode reward: -0.6688,                 loss: nan
agent1:                 episode reward: 0.6688,                 loss: 0.2873
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5559s / 476.9950 s
agent0:                 episode reward: -0.9843,                 loss: nan
agent1:                 episode reward: 0.9843,                 loss: 0.2914
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5804s / 477.5754 s
agent0:                 episode reward: -0.8656,                 loss: nan
agent1:                 episode reward: 0.8656,                 loss: 0.2910
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5585s / 478.1339 s
agent0:                 episode reward: -0.6561,                 loss: nan
agent1:                 episode reward: 0.6561,                 loss: 0.2730
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5655s / 478.6994 s
agent0:                 episode reward: -0.8100,                 loss: nan
agent1:                 episode reward: 0.8100,                 loss: 0.2717
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6099s / 479.3092 s
agent0:                 episode reward: -0.5387,                 loss: nan
agent1:                 episode reward: 0.5387,                 loss: 0.2686
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5665s / 479.8757 s
agent0:                 episode reward: -1.0462,                 loss: nan
agent1:                 episode reward: 1.0462,                 loss: 0.2682
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5724s / 480.4482 s
agent0:                 episode reward: -0.8548,                 loss: nan
agent1:                 episode reward: 0.8548,                 loss: 0.2705
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 481.0393 s
agent0:                 episode reward: -0.7070,                 loss: nan
agent1:                 episode reward: 0.7070,                 loss: 0.2699
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5677s / 481.6069 s
agent0:                 episode reward: -0.7710,                 loss: nan
agent1:                 episode reward: 0.7710,                 loss: 0.2719
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5676s / 482.1745 s
agent0:                 episode reward: -0.7063,                 loss: nan
agent1:                 episode reward: 0.7063,                 loss: 0.2709
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5687s / 482.7432 s
agent0:                 episode reward: -1.1468,                 loss: nan
agent1:                 episode reward: 1.1468,                 loss: 0.2676
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5687s / 483.3119 s
agent0:                 episode reward: -0.8982,                 loss: nan
agent1:                 episode reward: 0.8982,                 loss: 0.2702
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5810s / 483.8929 s
agent0:                 episode reward: -0.5318,                 loss: nan
agent1:                 episode reward: 0.5318,                 loss: 0.2698
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5610s / 484.4539 s
agent0:                 episode reward: -0.7784,                 loss: nan
agent1:                 episode reward: 0.7784,                 loss: 0.2708
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5678s / 485.0217 s
agent0:                 episode reward: -0.7492,                 loss: nan
agent1:                 episode reward: 0.7492,                 loss: 0.2697
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 485.6058 s
agent0:                 episode reward: -0.8020,                 loss: nan
agent1:                 episode reward: 0.8020,                 loss: 0.2729
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5656s / 486.1714 s
agent0:                 episode reward: -0.6064,                 loss: nan
agent1:                 episode reward: 0.6064,                 loss: 0.2662
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5810s / 486.7524 s
agent0:                 episode reward: -0.7488,                 loss: nan
agent1:                 episode reward: 0.7488,                 loss: 0.2680
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5632s / 487.3156 s
agent0:                 episode reward: -0.6457,                 loss: nan
agent1:                 episode reward: 0.6457,                 loss: 0.3057
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5716s / 487.8872 s
agent0:                 episode reward: -0.6401,                 loss: nan
agent1:                 episode reward: 0.6401,                 loss: 0.3045
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5640s / 488.4512 s
agent0:                 episode reward: -0.6350,                 loss: nan
agent1:                 episode reward: 0.6350,                 loss: 0.3072
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6071s / 489.0583 s
agent0:                 episode reward: -0.6506,                 loss: nan
agent1:                 episode reward: 0.6506,                 loss: 0.3034
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5993s / 489.6576 s
agent0:                 episode reward: -0.7501,                 loss: nan
agent1:                 episode reward: 0.7501,                 loss: 0.3080
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5607s / 490.2183 s
agent0:                 episode reward: -1.0634,                 loss: nan
agent1:                 episode reward: 1.0634,                 loss: 0.3077
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5601s / 490.7784 s
agent0:                 episode reward: -0.7098,                 loss: nan
agent1:                 episode reward: 0.7098,                 loss: 0.3091
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6239s / 491.4023 s
agent0:                 episode reward: -0.6162,                 loss: nan
agent1:                 episode reward: 0.6162,                 loss: 0.3048
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5639s / 491.9662 s
agent0:                 episode reward: -0.5782,                 loss: nan
agent1:                 episode reward: 0.5782,                 loss: 0.3059
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5630s / 492.5292 s
agent0:                 episode reward: -1.0870,                 loss: nan
agent1:                 episode reward: 1.0870,                 loss: 0.3049
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5814s / 493.1105 s
agent0:                 episode reward: -0.8464,                 loss: nan
agent1:                 episode reward: 0.8464,                 loss: 0.3054
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5692s / 493.6797 s
agent0:                 episode reward: -1.0479,                 loss: nan
agent1:                 episode reward: 1.0479,                 loss: 0.3130
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 494.2597 s
agent0:                 episode reward: -0.7405,                 loss: nan
agent1:                 episode reward: 0.7405,                 loss: 0.3068
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5692s / 494.8289 s
agent0:                 episode reward: -0.8164,                 loss: nan
agent1:                 episode reward: 0.8164,                 loss: 0.3073
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5757s / 495.4046 s
agent0:                 episode reward: -0.7289,                 loss: nan
agent1:                 episode reward: 0.7289,                 loss: 0.3078
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5762s / 495.9808 s
agent0:                 episode reward: -0.6091,                 loss: nan
agent1:                 episode reward: 0.6091,                 loss: 0.3043
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5739s / 496.5546 s
agent0:                 episode reward: -0.8328,                 loss: nan
agent1:                 episode reward: 0.8328,                 loss: 0.3080
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5595s / 497.1141 s
agent0:                 episode reward: -0.8948,                 loss: nan
agent1:                 episode reward: 0.8948,                 loss: 0.2873
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5727s / 497.6868 s
agent0:                 episode reward: -0.1989,                 loss: nan
agent1:                 episode reward: 0.1989,                 loss: 0.2839
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5717s / 498.2585 s
agent0:                 episode reward: -0.6526,                 loss: nan
agent1:                 episode reward: 0.6526,                 loss: 0.2817
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 498.8564 s
agent0:                 episode reward: -0.7315,                 loss: nan
agent1:                 episode reward: 0.7315,                 loss: 0.2853
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6197s / 499.4761 s
agent0:                 episode reward: -0.9755,                 loss: nan
agent1:                 episode reward: 0.9755,                 loss: 0.2856
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5684s / 500.0445 s
agent0:                 episode reward: -0.7601,                 loss: nan
agent1:                 episode reward: 0.7601,                 loss: 0.2847
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5613s / 500.6058 s
agent0:                 episode reward: -0.8941,                 loss: nan
agent1:                 episode reward: 0.8941,                 loss: 0.2845
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5679s / 501.1737 s
agent0:                 episode reward: -0.4054,                 loss: nan
agent1:                 episode reward: 0.4054,                 loss: 0.2844
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 501.7619 s
agent0:                 episode reward: -0.9183,                 loss: nan
agent1:                 episode reward: 0.9183,                 loss: 0.2867
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 502.3520 s
agent0:                 episode reward: -1.0455,                 loss: nan
agent1:                 episode reward: 1.0455,                 loss: 0.2840
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5680s / 502.9200 s
agent0:                 episode reward: -0.5493,                 loss: nan
agent1:                 episode reward: 0.5493,                 loss: 0.2838
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5727s / 503.4927 s
agent0:                 episode reward: -0.9031,                 loss: nan
agent1:                 episode reward: 0.9031,                 loss: 0.2829
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5791s / 504.0718 s
agent0:                 episode reward: -0.4550,                 loss: nan
agent1:                 episode reward: 0.4550,                 loss: 0.2866
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6119s / 504.6837 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.2820
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5692s / 505.2529 s
agent0:                 episode reward: -0.9563,                 loss: nan
agent1:                 episode reward: 0.9563,                 loss: 0.2859
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 505.8357 s
agent0:                 episode reward: -0.6678,                 loss: nan
agent1:                 episode reward: 0.6678,                 loss: 0.2834
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6177s / 506.4535 s
agent0:                 episode reward: -0.6207,                 loss: nan
agent1:                 episode reward: 0.6207,                 loss: 0.2910
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5676s / 507.0211 s
agent0:                 episode reward: -1.1152,                 loss: nan
agent1:                 episode reward: 1.1152,                 loss: 0.2696
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 507.6210 s
agent0:                 episode reward: -0.5605,                 loss: nan
agent1:                 episode reward: 0.5605,                 loss: 0.2677
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5716s / 508.1926 s
agent0:                 episode reward: -0.9609,                 loss: nan
agent1:                 episode reward: 0.9609,                 loss: 0.2703
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5720s / 508.7646 s
agent0:                 episode reward: -1.2422,                 loss: nan
agent1:                 episode reward: 1.2422,                 loss: 0.2706
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5686s / 509.3333 s
agent0:                 episode reward: -0.5945,                 loss: nan
agent1:                 episode reward: 0.5945,                 loss: 0.2674
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6332s / 509.9665 s
agent0:                 episode reward: -0.9938,                 loss: nan
agent1:                 episode reward: 0.9938,                 loss: 0.2679
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 510.5637 s
agent0:                 episode reward: -0.8294,                 loss: nan
agent1:                 episode reward: 0.8294,                 loss: 0.2657
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 511.1490 s
agent0:                 episode reward: -1.0899,                 loss: nan
agent1:                 episode reward: 1.0899,                 loss: 0.2655
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5734s / 511.7224 s
agent0:                 episode reward: -0.7506,                 loss: nan
agent1:                 episode reward: 0.7506,                 loss: 0.2673
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 512.3253 s
agent0:                 episode reward: -0.8782,                 loss: nan
agent1:                 episode reward: 0.8782,                 loss: 0.2691
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 512.9065 s
agent0:                 episode reward: -0.7960,                 loss: nan
agent1:                 episode reward: 0.7960,                 loss: 0.2646
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5769s / 513.4834 s
agent0:                 episode reward: -0.7678,                 loss: nan
agent1:                 episode reward: 0.7678,                 loss: 0.2663
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 514.0859 s
agent0:                 episode reward: -0.6409,                 loss: nan
agent1:                 episode reward: 0.6409,                 loss: 0.2662
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6233s / 514.7092 s
agent0:                 episode reward: -1.1685,                 loss: nan
agent1:                 episode reward: 1.1685,                 loss: 0.2656
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5743s / 515.2835 s
agent0:                 episode reward: -0.7873,                 loss: nan
agent1:                 episode reward: 0.7873,                 loss: 0.2676
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5720s / 515.8555 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.2688
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5793s / 516.4348 s
agent0:                 episode reward: -0.8476,                 loss: nan
agent1:                 episode reward: 0.8476,                 loss: 0.3077
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 517.0226 s
agent0:                 episode reward: -0.6165,                 loss: nan
agent1:                 episode reward: 0.6165,                 loss: 0.3046
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 517.6083 s
agent0:                 episode reward: -0.6920,                 loss: nan
agent1:                 episode reward: 0.6920,                 loss: 0.3022
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 518.1940 s
agent0:                 episode reward: -1.0601,                 loss: nan
agent1:                 episode reward: 1.0601,                 loss: 0.3054
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 518.7862 s
agent0:                 episode reward: -0.8092,                 loss: nan
agent1:                 episode reward: 0.8092,                 loss: 0.3005
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5791s / 519.3652 s
agent0:                 episode reward: -0.8645,                 loss: nan
agent1:                 episode reward: 0.8645,                 loss: 0.3036
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6482s / 520.0134 s
agent0:                 episode reward: -0.6239,                 loss: nan
agent1:                 episode reward: 0.6239,                 loss: 0.2990
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5788s / 520.5922 s
agent0:                 episode reward: -0.7125,                 loss: nan
agent1:                 episode reward: 0.7125,                 loss: 0.3000
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 521.1758 s
agent0:                 episode reward: -0.9661,                 loss: nan
agent1:                 episode reward: 0.9661,                 loss: 0.3024
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 521.7623 s
agent0:                 episode reward: -0.7813,                 loss: nan
agent1:                 episode reward: 0.7813,                 loss: 0.3044
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5801s / 522.3425 s
agent0:                 episode reward: -0.5504,                 loss: nan
agent1:                 episode reward: 0.5504,                 loss: 0.3018
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 522.9299 s
agent0:                 episode reward: -0.4577,                 loss: nan
agent1:                 episode reward: 0.4577,                 loss: 0.3023
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5816s / 523.5115 s
agent0:                 episode reward: -1.0088,                 loss: nan
agent1:                 episode reward: 1.0088,                 loss: 0.3016
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 524.1010 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.3003
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 524.6879 s
agent0:                 episode reward: -1.0266,                 loss: nan
agent1:                 episode reward: 1.0266,                 loss: 0.3012
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6424s / 525.3303 s
agent0:                 episode reward: -0.9933,                 loss: nan
agent1:                 episode reward: 0.9933,                 loss: 0.3002
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 525.9213 s
agent0:                 episode reward: -0.8485,                 loss: nan
agent1:                 episode reward: 0.8485,                 loss: 0.3004
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 526.5106 s
agent0:                 episode reward: -1.0024,                 loss: nan
agent1:                 episode reward: 1.0024,                 loss: 0.2887
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 527.1102 s
agent0:                 episode reward: -0.6566,                 loss: nan
agent1:                 episode reward: 0.6566,                 loss: 0.2785
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5933s / 527.7035 s
agent0:                 episode reward: -0.8228,                 loss: nan
agent1:                 episode reward: 0.8228,                 loss: 0.2774
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 528.2920 s
agent0:                 episode reward: -0.7544,                 loss: nan
agent1:                 episode reward: 0.7544,                 loss: 0.2806
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5933s / 528.8853 s
agent0:                 episode reward: -0.6363,                 loss: nan
agent1:                 episode reward: 0.6363,                 loss: 0.2804
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 529.4768 s
agent0:                 episode reward: -0.7756,                 loss: nan
agent1:                 episode reward: 0.7756,                 loss: 0.2838
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6409s / 530.1176 s
agent0:                 episode reward: -0.6037,                 loss: nan
agent1:                 episode reward: 0.6037,                 loss: 0.2798
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 530.7059 s
agent0:                 episode reward: -0.9091,                 loss: nan
agent1:                 episode reward: 0.9091,                 loss: 0.2815
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 531.2913 s
agent0:                 episode reward: -0.6067,                 loss: nan
agent1:                 episode reward: 0.6067,                 loss: 0.2813
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6178s / 531.9092 s
agent0:                 episode reward: -0.7897,                 loss: nan
agent1:                 episode reward: 0.7897,                 loss: 0.2793
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 532.5036 s
agent0:                 episode reward: -0.7036,                 loss: nan
agent1:                 episode reward: 0.7036,                 loss: 0.2784
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 533.0959 s
agent0:                 episode reward: -0.4361,                 loss: nan
agent1:                 episode reward: 0.4361,                 loss: 0.2817
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 533.6874 s
agent0:                 episode reward: -0.7100,                 loss: nan
agent1:                 episode reward: 0.7100,                 loss: 0.2815
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 534.2842 s
agent0:                 episode reward: -0.6036,                 loss: nan
agent1:                 episode reward: 0.6036,                 loss: 0.2786
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 534.8803 s
agent0:                 episode reward: -0.7655,                 loss: nan
agent1:                 episode reward: 0.7655,                 loss: 0.2836
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 535.4779 s
agent0:                 episode reward: -0.9350,                 loss: nan
agent1:                 episode reward: 0.9350,                 loss: 0.2809
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6106s / 536.0886 s
agent0:                 episode reward: -0.6919,                 loss: nan
agent1:                 episode reward: 0.6919,                 loss: 0.2846
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 536.6823 s
agent0:                 episode reward: -0.8641,                 loss: nan
agent1:                 episode reward: 0.8641,                 loss: 0.2784
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6270s / 537.3092 s
agent0:                 episode reward: -0.5307,                 loss: nan
agent1:                 episode reward: 0.5307,                 loss: 0.2779
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6196s / 537.9288 s
agent0:                 episode reward: -0.9255,                 loss: nan
agent1:                 episode reward: 0.9255,                 loss: 0.2762
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 538.5134 s
agent0:                 episode reward: -0.9101,                 loss: nan
agent1:                 episode reward: 0.9101,                 loss: 0.2774
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 539.1041 s
agent0:                 episode reward: -0.8459,                 loss: nan
agent1:                 episode reward: 0.8459,                 loss: 0.2752
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 539.6919 s
agent0:                 episode reward: -0.9161,                 loss: nan
agent1:                 episode reward: 0.9161,                 loss: 0.2748
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6489s / 540.3408 s
agent0:                 episode reward: -0.9593,                 loss: nan
agent1:                 episode reward: 0.9593,                 loss: 0.2735
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 540.9452 s
agent0:                 episode reward: -0.3845,                 loss: nan
agent1:                 episode reward: 0.3845,                 loss: 0.2775
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 541.5446 s
agent0:                 episode reward: -1.0755,                 loss: nan
agent1:                 episode reward: 1.0755,                 loss: 0.2727
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 542.1451 s
agent0:                 episode reward: -0.7968,                 loss: nan
agent1:                 episode reward: 0.7968,                 loss: 0.2731
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 542.7428 s
agent0:                 episode reward: -0.8684,                 loss: nan
agent1:                 episode reward: 0.8684,                 loss: 0.2771
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 543.3556 s
agent0:                 episode reward: -0.9109,                 loss: nan
agent1:                 episode reward: 0.9109,                 loss: 0.2761
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 543.9603 s
agent0:                 episode reward: -1.2089,                 loss: nan
agent1:                 episode reward: 1.2089,                 loss: 0.2760
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6210s / 544.5813 s
agent0:                 episode reward: -1.0021,                 loss: nan
agent1:                 episode reward: 1.0021,                 loss: 0.2707
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 545.1812 s
agent0:                 episode reward: -0.5765,                 loss: nan
agent1:                 episode reward: 0.5765,                 loss: 0.2751
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 545.7763 s
agent0:                 episode reward: -0.7747,                 loss: nan
agent1:                 episode reward: 0.7747,                 loss: 0.2769
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 546.3697 s
agent0:                 episode reward: -0.7446,                 loss: nan
agent1:                 episode reward: 0.7446,                 loss: 0.3085
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6217s / 546.9913 s
agent0:                 episode reward: -0.7856,                 loss: nan
agent1:                 episode reward: 0.7856,                 loss: 0.3085
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 547.5866 s
agent0:                 episode reward: -0.8114,                 loss: nan
agent1:                 episode reward: 0.8114,                 loss: 0.3059
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 548.1837 s
agent0:                 episode reward: -0.7313,                 loss: nan
agent1:                 episode reward: 0.7313,                 loss: 0.3052
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 548.7826 s
agent0:                 episode reward: -0.8505,                 loss: nan
agent1:                 episode reward: 0.8505,                 loss: 0.3053
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 549.3792 s
agent0:                 episode reward: -0.7849,                 loss: nan
agent1:                 episode reward: 0.7849,                 loss: 0.3073
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 549.9879 s
agent0:                 episode reward: -0.7784,                 loss: nan
agent1:                 episode reward: 0.7784,                 loss: 0.3071
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6647s / 550.6526 s
agent0:                 episode reward: -0.7313,                 loss: nan
agent1:                 episode reward: 0.7313,                 loss: 0.3073
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6099s / 551.2625 s
agent0:                 episode reward: -0.5257,                 loss: nan
agent1:                 episode reward: 0.5257,                 loss: 0.3056
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6162s / 551.8787 s
agent0:                 episode reward: -0.4654,                 loss: nan
agent1:                 episode reward: 0.4654,                 loss: 0.3051
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6119s / 552.4906 s
agent0:                 episode reward: -1.0847,                 loss: nan
agent1:                 episode reward: 1.0847,                 loss: 0.3071
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6212s / 553.1118 s
agent0:                 episode reward: -0.8567,                 loss: nan
agent1:                 episode reward: 0.8567,                 loss: 0.3060
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 553.7213 s
agent0:                 episode reward: -0.7402,                 loss: nan
agent1:                 episode reward: 0.7402,                 loss: 0.3053
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 554.3211 s
agent0:                 episode reward: -1.0255,                 loss: nan
agent1:                 episode reward: 1.0255,                 loss: 0.3069
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6094s / 554.9305 s
agent0:                 episode reward: -0.6595,                 loss: nan
agent1:                 episode reward: 0.6595,                 loss: 0.3071
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6078s / 555.5383 s
agent0:                 episode reward: -0.9241,                 loss: nan
agent1:                 episode reward: 0.9241,                 loss: 0.3062
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 556.1415 s
agent0:                 episode reward: -0.7699,                 loss: nan
agent1:                 episode reward: 0.7699,                 loss: 0.3065
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6126s / 556.7541 s
agent0:                 episode reward: -0.7985,                 loss: nan
agent1:                 episode reward: 0.7985,                 loss: 0.2836
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6060s / 557.3601 s
agent0:                 episode reward: -0.9551,                 loss: nan
agent1:                 episode reward: 0.9551,                 loss: 0.2806
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 557.9634 s
agent0:                 episode reward: -1.0105,                 loss: nan
agent1:                 episode reward: 1.0105,                 loss: 0.2798
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6175s / 558.5809 s
agent0:                 episode reward: -0.7871,                 loss: nan
agent1:                 episode reward: 0.7871,                 loss: 0.2819
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6398s / 559.2207 s
agent0:                 episode reward: -0.7669,                 loss: nan
agent1:                 episode reward: 0.7669,                 loss: 0.2816
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6045s / 559.8252 s
agent0:                 episode reward: -0.7222,                 loss: nan
agent1:                 episode reward: 0.7222,                 loss: 0.2827
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6176s / 560.4428 s
agent0:                 episode reward: -0.7983,                 loss: nan
agent1:                 episode reward: 0.7983,                 loss: 0.2866
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6636s / 561.1064 s
agent0:                 episode reward: -0.5490,                 loss: nan
agent1:                 episode reward: 0.5490,                 loss: 0.2841
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 561.7192 s
agent0:                 episode reward: -0.5449,                 loss: nan
agent1:                 episode reward: 0.5449,                 loss: 0.2852
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6077s / 562.3269 s
agent0:                 episode reward: -0.6324,                 loss: nan
agent1:                 episode reward: 0.6324,                 loss: 0.2837
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 562.9268 s
agent0:                 episode reward: -0.6481,                 loss: nan
agent1:                 episode reward: 0.6481,                 loss: 0.2846
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 563.5270 s
agent0:                 episode reward: -0.8690,                 loss: nan
agent1:                 episode reward: 0.8690,                 loss: 0.2840
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 564.1290 s
agent0:                 episode reward: -0.9931,                 loss: nan
agent1:                 episode reward: 0.9931,                 loss: 0.2817
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6166s / 564.7457 s
agent0:                 episode reward: -0.8486,                 loss: nan
agent1:                 episode reward: 0.8486,                 loss: 0.2830
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6056s / 565.3513 s
agent0:                 episode reward: -0.9108,                 loss: nan
agent1:                 episode reward: 0.9108,                 loss: 0.2833
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 565.9557 s
agent0:                 episode reward: -0.5431,                 loss: nan
agent1:                 episode reward: 0.5431,                 loss: 0.2834
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6094s / 566.5651 s
agent0:                 episode reward: -0.8381,                 loss: nan
agent1:                 episode reward: 0.8381,                 loss: 0.2910
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6071s / 567.1722 s
agent0:                 episode reward: -0.8065,                 loss: nan
agent1:                 episode reward: 0.8065,                 loss: 0.2760
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6296s / 567.8019 s
agent0:                 episode reward: -0.6252,                 loss: nan
agent1:                 episode reward: 0.6252,                 loss: 0.2802
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6243s / 568.4262 s
agent0:                 episode reward: -1.2091,                 loss: nan
agent1:                 episode reward: 1.2091,                 loss: 0.2800
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 569.0327 s
agent0:                 episode reward: -1.0875,                 loss: nan
agent1:                 episode reward: 1.0875,                 loss: 0.2767
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6071s / 569.6398 s
agent0:                 episode reward: -0.7042,                 loss: nan
agent1:                 episode reward: 0.7042,                 loss: 0.2794
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6189s / 570.2587 s
agent0:                 episode reward: -0.8117,                 loss: nan
agent1:                 episode reward: 0.8117,                 loss: 0.2811
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6429s / 570.9016 s
agent0:                 episode reward: -0.7522,                 loss: nan
agent1:                 episode reward: 0.7522,                 loss: 0.2760
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6863s / 571.5879 s
agent0:                 episode reward: -1.1795,                 loss: nan
agent1:                 episode reward: 1.1795,                 loss: 0.2812
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 572.2015 s
agent0:                 episode reward: -0.6431,                 loss: nan
agent1:                 episode reward: 0.6431,                 loss: 0.2776
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6187s / 572.8202 s
agent0:                 episode reward: -0.9287,                 loss: nan
agent1:                 episode reward: 0.9287,                 loss: 0.2766
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6106s / 573.4308 s
agent0:                 episode reward: -0.7277,                 loss: nan
agent1:                 episode reward: 0.7277,                 loss: 0.2790
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6167s / 574.0474 s
agent0:                 episode reward: -0.9083,                 loss: nan
agent1:                 episode reward: 0.9083,                 loss: 0.2778
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6164s / 574.6639 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.2768
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6134s / 575.2772 s
agent0:                 episode reward: -0.9525,                 loss: nan
agent1:                 episode reward: 0.9525,                 loss: 0.2772
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 575.8908 s
agent0:                 episode reward: -0.9128,                 loss: nan
agent1:                 episode reward: 0.9128,                 loss: 0.2787
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6302s / 576.5210 s
agent0:                 episode reward: -0.7080,                 loss: nan
agent1:                 episode reward: 0.7080,                 loss: 0.2750
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6438s / 577.1648 s
agent0:                 episode reward: -0.5670,                 loss: nan
agent1:                 episode reward: 0.5670,                 loss: 0.3104
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6125s / 577.7773 s
agent0:                 episode reward: -0.6914,                 loss: nan
agent1:                 episode reward: 0.6914,                 loss: 0.3063
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 578.3850 s
agent0:                 episode reward: -0.9025,                 loss: nan
agent1:                 episode reward: 0.9025,                 loss: 0.3068
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6115s / 578.9964 s
agent0:                 episode reward: -0.7439,                 loss: nan
agent1:                 episode reward: 0.7439,                 loss: 0.3020
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6135s / 579.6099 s
agent0:                 episode reward: -1.4102,                 loss: nan
agent1:                 episode reward: 1.4102,                 loss: 0.3032
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6471s / 580.2570 s
agent0:                 episode reward: -0.9585,                 loss: nan
agent1:                 episode reward: 0.9585,                 loss: 0.3059
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6152s / 580.8723 s
agent0:                 episode reward: -1.0041,                 loss: nan
agent1:                 episode reward: 1.0041,                 loss: 0.3037
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6649s / 581.5372 s
agent0:                 episode reward: -0.8277,                 loss: nan
agent1:                 episode reward: 0.8277,                 loss: 0.3010
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6202s / 582.1574 s
agent0:                 episode reward: -1.0731,                 loss: nan
agent1:                 episode reward: 1.0731,                 loss: 0.3055
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6108s / 582.7682 s
agent0:                 episode reward: -0.5070,                 loss: nan
agent1:                 episode reward: 0.5070,                 loss: 0.3042
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6133s / 583.3815 s
agent0:                 episode reward: -0.7297,                 loss: nan
agent1:                 episode reward: 0.7297,                 loss: 0.3012
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6162s / 583.9977 s
agent0:                 episode reward: -1.1571,                 loss: nan
agent1:                 episode reward: 1.1571,                 loss: 0.3030
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6181s / 584.6158 s
agent0:                 episode reward: -0.6036,                 loss: nan
agent1:                 episode reward: 0.6036,                 loss: 0.3070
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6366s / 585.2524 s
agent0:                 episode reward: -0.5478,                 loss: nan
agent1:                 episode reward: 0.5478,                 loss: 0.3028
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6155s / 585.8679 s
agent0:                 episode reward: -0.7792,                 loss: nan
agent1:                 episode reward: 0.7792,                 loss: 0.3045
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6233s / 586.4912 s
agent0:                 episode reward: -1.1444,                 loss: nan
agent1:                 episode reward: 1.1444,                 loss: 0.3060
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 587.1049 s
agent0:                 episode reward: -1.0723,                 loss: nan
agent1:                 episode reward: 1.0723,                 loss: 0.3057
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6216s / 587.7265 s
agent0:                 episode reward: -0.5770,                 loss: nan
agent1:                 episode reward: 0.5770,                 loss: 0.2852
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6194s / 588.3459 s
agent0:                 episode reward: -0.7182,                 loss: nan
agent1:                 episode reward: 0.7182,                 loss: 0.2847
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6260s / 588.9720 s
agent0:                 episode reward: -0.4091,                 loss: nan
agent1:                 episode reward: 0.4091,                 loss: 0.2838
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6176s / 589.5896 s
agent0:                 episode reward: -0.8656,                 loss: nan
agent1:                 episode reward: 0.8656,                 loss: 0.2828
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6172s / 590.2068 s
agent0:                 episode reward: -0.6734,                 loss: nan
agent1:                 episode reward: 0.6734,                 loss: 0.2869
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 590.8252 s
agent0:                 episode reward: -0.5140,                 loss: nan
agent1:                 episode reward: 0.5140,                 loss: 0.2828
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6240s / 591.4493 s
agent0:                 episode reward: -0.7161,                 loss: nan
agent1:                 episode reward: 0.7161,                 loss: 0.2826
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6938s / 592.1430 s
agent0:                 episode reward: -0.8937,                 loss: nan
agent1:                 episode reward: 0.8937,                 loss: 0.2822
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6203s / 592.7634 s
agent0:                 episode reward: -0.9588,                 loss: nan
agent1:                 episode reward: 0.9588,                 loss: 0.2802
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6408s / 593.4041 s
agent0:                 episode reward: -0.8550,                 loss: nan
agent1:                 episode reward: 0.8550,                 loss: 0.2848
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6196s / 594.0237 s
agent0:                 episode reward: -1.1004,                 loss: nan
agent1:                 episode reward: 1.1004,                 loss: 0.2844
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6207s / 594.6445 s
agent0:                 episode reward: -0.6433,                 loss: nan
agent1:                 episode reward: 0.6433,                 loss: 0.2841
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6343s / 595.2788 s
agent0:                 episode reward: -0.7880,                 loss: nan
agent1:                 episode reward: 0.7880,                 loss: 0.2837
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6240s / 595.9028 s
agent0:                 episode reward: -0.8646,                 loss: nan
agent1:                 episode reward: 0.8646,                 loss: 0.2835
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6208s / 596.5236 s
agent0:                 episode reward: -0.9006,                 loss: nan
agent1:                 episode reward: 0.9006,                 loss: 0.2824
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6420s / 597.1655 s
agent0:                 episode reward: -0.6221,                 loss: nan
agent1:                 episode reward: 0.6221,                 loss: 0.2844
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6217s / 597.7873 s
agent0:                 episode reward: -0.5589,                 loss: nan
agent1:                 episode reward: 0.5589,                 loss: 0.2885
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6330s / 598.4202 s
agent0:                 episode reward: -1.1428,                 loss: nan
agent1:                 episode reward: 1.1428,                 loss: 0.2857
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6303s / 599.0505 s
agent0:                 episode reward: -0.6462,                 loss: nan
agent1:                 episode reward: 0.6462,                 loss: 0.2872
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6182s / 599.6687 s
agent0:                 episode reward: -0.8304,                 loss: nan
agent1:                 episode reward: 0.8304,                 loss: 0.2905
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6250s / 600.2937 s
agent0:                 episode reward: -0.9321,                 loss: nan
agent1:                 episode reward: 0.9321,                 loss: 0.2876
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6281s / 600.9218 s
agent0:                 episode reward: -0.6370,                 loss: nan
agent1:                 episode reward: 0.6370,                 loss: 0.2885
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6408s / 601.5627 s
agent0:                 episode reward: -0.5105,                 loss: nan
agent1:                 episode reward: 0.5105,                 loss: 0.2863
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6756s / 602.2382 s
agent0:                 episode reward: -0.7721,                 loss: nan
agent1:                 episode reward: 0.7721,                 loss: 0.2881
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6313s / 602.8696 s
agent0:                 episode reward: -0.7254,                 loss: nan
agent1:                 episode reward: 0.7254,                 loss: 0.2878
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6166s / 603.4862 s
agent0:                 episode reward: -0.6981,                 loss: nan
agent1:                 episode reward: 0.6981,                 loss: 0.2881
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6373s / 604.1234 s
agent0:                 episode reward: -0.5898,                 loss: nan
agent1:                 episode reward: 0.5898,                 loss: 0.2890
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6180s / 604.7415 s
agent0:                 episode reward: -1.0037,                 loss: nan
agent1:                 episode reward: 1.0037,                 loss: 0.2866
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6320s / 605.3735 s
agent0:                 episode reward: -0.3334,                 loss: nan
agent1:                 episode reward: 0.3334,                 loss: 0.2866
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6223s / 605.9958 s
agent0:                 episode reward: -0.4233,                 loss: nan
agent1:                 episode reward: 0.4233,                 loss: 0.2912
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6204s / 606.6162 s
agent0:                 episode reward: -0.6141,                 loss: nan
agent1:                 episode reward: 0.6141,                 loss: 0.2881
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6325s / 607.2487 s
agent0:                 episode reward: -0.8003,                 loss: nan
agent1:                 episode reward: 0.8003,                 loss: 0.2864
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6345s / 607.8832 s
agent0:                 episode reward: -0.5914,                 loss: nan
agent1:                 episode reward: 0.5914,                 loss: 0.2865
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6297s / 608.5129 s
agent0:                 episode reward: -0.8637,                 loss: nan
agent1:                 episode reward: 0.8637,                 loss: 0.3121
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6572s / 609.1701 s
agent0:                 episode reward: -0.9430,                 loss: nan
agent1:                 episode reward: 0.9430,                 loss: 0.2971
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6403s / 609.8105 s
agent0:                 episode reward: -0.9146,                 loss: nan
agent1:                 episode reward: 0.9146,                 loss: 0.2968
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6326s / 610.4431 s
agent0:                 episode reward: -0.4899,                 loss: nan
agent1:                 episode reward: 0.4899,                 loss: 0.2969
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6263s / 611.0694 s
agent0:                 episode reward: -0.3974,                 loss: nan
agent1:                 episode reward: 0.3974,                 loss: 0.2975
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6235s / 611.6928 s
agent0:                 episode reward: -0.5904,                 loss: nan
agent1:                 episode reward: 0.5904,                 loss: 0.2954
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7063s / 612.3992 s
agent0:                 episode reward: -0.9436,                 loss: nan
agent1:                 episode reward: 0.9436,                 loss: 0.2954
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6267s / 613.0259 s
agent0:                 episode reward: -0.8433,                 loss: nan
agent1:                 episode reward: 0.8433,                 loss: 0.2994
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6312s / 613.6571 s
agent0:                 episode reward: -0.7824,                 loss: nan
agent1:                 episode reward: 0.7824,                 loss: 0.2939
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6289s / 614.2860 s
agent0:                 episode reward: -0.9563,                 loss: nan
agent1:                 episode reward: 0.9563,                 loss: 0.2988
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6390s / 614.9250 s
agent0:                 episode reward: -0.9903,                 loss: nan
agent1:                 episode reward: 0.9903,                 loss: 0.2948
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6429s / 615.5679 s
agent0:                 episode reward: -0.5469,                 loss: nan
agent1:                 episode reward: 0.5469,                 loss: 0.2982
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6426s / 616.2105 s
agent0:                 episode reward: -0.9670,                 loss: nan
agent1:                 episode reward: 0.9670,                 loss: 0.2970
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6419s / 616.8524 s
agent0:                 episode reward: -0.9866,                 loss: nan
agent1:                 episode reward: 0.9866,                 loss: 0.2953
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6379s / 617.4903 s
agent0:                 episode reward: -0.6174,                 loss: nan
agent1:                 episode reward: 0.6174,                 loss: 0.2991
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6482s / 618.1384 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.2984
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6350s / 618.7734 s
agent0:                 episode reward: -1.0008,                 loss: nan
agent1:                 episode reward: 1.0008,                 loss: 0.2983
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6520s / 619.4253 s
agent0:                 episode reward: -0.4251,                 loss: nan
agent1:                 episode reward: 0.4251,                 loss: 0.2824
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6370s / 620.0624 s
agent0:                 episode reward: -1.0472,                 loss: nan
agent1:                 episode reward: 1.0472,                 loss: 0.2789
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6310s / 620.6934 s
agent0:                 episode reward: -0.5000,                 loss: nan
agent1:                 episode reward: 0.5000,                 loss: 0.2773
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6366s / 621.3299 s
agent0:                 episode reward: -1.0582,                 loss: nan
agent1:                 episode reward: 1.0582,                 loss: 0.2755
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6444s / 621.9743 s
agent0:                 episode reward: -0.8316,                 loss: nan
agent1:                 episode reward: 0.8316,                 loss: 0.2749
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6889s / 622.6632 s
agent0:                 episode reward: -0.8729,                 loss: nan
agent1:                 episode reward: 0.8729,                 loss: 0.2760
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6399s / 623.3031 s
agent0:                 episode reward: -0.7769,                 loss: nan
agent1:                 episode reward: 0.7769,                 loss: 0.2751
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6360s / 623.9390 s
agent0:                 episode reward: -0.8663,                 loss: nan
agent1:                 episode reward: 0.8663,                 loss: 0.2740
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6325s / 624.5715 s
agent0:                 episode reward: -0.4419,                 loss: nan
agent1:                 episode reward: 0.4419,                 loss: 0.2765
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6508s / 625.2223 s
agent0:                 episode reward: -0.8667,                 loss: nan
agent1:                 episode reward: 0.8667,                 loss: 0.2734
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6427s / 625.8650 s
agent0:                 episode reward: -0.7100,                 loss: nan
agent1:                 episode reward: 0.7100,                 loss: 0.2761
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6568s / 626.5218 s
agent0:                 episode reward: -1.1263,                 loss: nan
agent1:                 episode reward: 1.1263,                 loss: 0.2759
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6396s / 627.1614 s
agent0:                 episode reward: -0.5259,                 loss: nan
agent1:                 episode reward: 0.5259,                 loss: 0.2736
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6418s / 627.8032 s
agent0:                 episode reward: -0.8636,                 loss: nan
agent1:                 episode reward: 0.8636,                 loss: 0.2713
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6459s / 628.4490 s
agent0:                 episode reward: -0.7970,                 loss: nan
agent1:                 episode reward: 0.7970,                 loss: 0.2771
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6334s / 629.0825 s
agent0:                 episode reward: -0.6979,                 loss: nan
agent1:                 episode reward: 0.6979,                 loss: 0.2758
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6376s / 629.7200 s
agent0:                 episode reward: -0.7515,                 loss: nan
agent1:                 episode reward: 0.7515,                 loss: 0.2853
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6412s / 630.3612 s
agent0:                 episode reward: -0.8817,                 loss: nan
agent1:                 episode reward: 0.8817,                 loss: 0.2958
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6875s / 631.0487 s
agent0:                 episode reward: -0.7742,                 loss: nan
agent1:                 episode reward: 0.7742,                 loss: 0.2949
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6401s / 631.6888 s
agent0:                 episode reward: -0.7439,                 loss: nan
agent1:                 episode reward: 0.7439,                 loss: 0.2985
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6398s / 632.3286 s
agent0:                 episode reward: -0.8066,                 loss: nan
agent1:                 episode reward: 0.8066,                 loss: 0.2965
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7002s / 633.0288 s
agent0:                 episode reward: -0.6097,                 loss: nan
agent1:                 episode reward: 0.6097,                 loss: 0.2930
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6490s / 633.6779 s
agent0:                 episode reward: -0.8883,                 loss: nan
agent1:                 episode reward: 0.8883,                 loss: 0.2968
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6612s / 634.3391 s
agent0:                 episode reward: -0.7488,                 loss: nan
agent1:                 episode reward: 0.7488,                 loss: 0.2952
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6713s / 635.0104 s
agent0:                 episode reward: -0.9878,                 loss: nan
agent1:                 episode reward: 0.9878,                 loss: 0.2942
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6580s / 635.6684 s
agent0:                 episode reward: -0.7320,                 loss: nan
agent1:                 episode reward: 0.7320,                 loss: 0.2963
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6477s / 636.3162 s
agent0:                 episode reward: -0.9894,                 loss: nan
agent1:                 episode reward: 0.9894,                 loss: 0.2944
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6497s / 636.9658 s
agent0:                 episode reward: -0.5500,                 loss: nan
agent1:                 episode reward: 0.5500,                 loss: 0.2945
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6523s / 637.6182 s
agent0:                 episode reward: -0.8391,                 loss: nan
agent1:                 episode reward: 0.8391,                 loss: 0.2940
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6542s / 638.2723 s
agent0:                 episode reward: -0.5826,                 loss: nan
agent1:                 episode reward: 0.5826,                 loss: 0.2921
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6354s / 638.9077 s
agent0:                 episode reward: -0.6855,                 loss: nan
agent1:                 episode reward: 0.6855,                 loss: 0.2961
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6476s / 639.5553 s
agent0:                 episode reward: -0.6703,                 loss: nan
agent1:                 episode reward: 0.6703,                 loss: 0.2943
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6799s / 640.2353 s
agent0:                 episode reward: -0.4608,                 loss: nan
agent1:                 episode reward: 0.4608,                 loss: 0.2963
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6441s / 640.8793 s
agent0:                 episode reward: -0.5027,                 loss: nan
agent1:                 episode reward: 0.5027,                 loss: 0.3043
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6504s / 641.5297 s
agent0:                 episode reward: -1.2182,                 loss: nan
agent1:                 episode reward: 1.2182,                 loss: 0.2966
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6456s / 642.1754 s
agent0:                 episode reward: -0.9707,                 loss: nan
agent1:                 episode reward: 0.9707,                 loss: 0.2981
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6985s / 642.8738 s
agent0:                 episode reward: -0.5204,                 loss: nan
agent1:                 episode reward: 0.5204,                 loss: 0.2966
Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6628s / 643.5366 s
agent0:                 episode reward: -0.9816,                 loss: nan
agent1:                 episode reward: 0.9816,                 loss: 0.2982
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6493s / 644.1859 s/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

agent0:                 episode reward: -0.5405,                 loss: nan
agent1:                 episode reward: 0.5405,                 loss: 0.2926
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6559s / 644.8418 s
agent0:                 episode reward: -0.6703,                 loss: nan
agent1:                 episode reward: 0.6703,                 loss: 0.2989
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6777s / 645.5196 s
agent0:                 episode reward: -0.6360,                 loss: nan
agent1:                 episode reward: 0.6360,                 loss: 0.2962
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6850s / 646.2046 s
agent0:                 episode reward: -0.9233,                 loss: nan
agent1:                 episode reward: 0.9233,                 loss: 0.2956
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6545s / 646.8591 s
agent0:                 episode reward: -1.0282,                 loss: nan
agent1:                 episode reward: 1.0282,                 loss: 0.2964
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6481s / 647.5071 s
agent0:                 episode reward: -0.5223,                 loss: nan
agent1:                 episode reward: 0.5223,                 loss: 0.2942
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6913s / 648.1984 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.2982
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6614s / 648.8599 s
agent0:                 episode reward: -0.5574,                 loss: nan
agent1:                 episode reward: 0.5574,                 loss: 0.2946
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6636s / 649.5235 s
agent0:                 episode reward: -0.6498,                 loss: nan
agent1:                 episode reward: 0.6498,                 loss: 0.2954
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6580s / 650.1814 s
agent0:                 episode reward: -0.6748,                 loss: nan
agent1:                 episode reward: 0.6748,                 loss: 0.2969
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6727s / 650.8541 s
agent0:                 episode reward: -0.6243,                 loss: nan
agent1:                 episode reward: 0.6243,                 loss: 0.2974
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6691s / 651.5232 s
agent0:                 episode reward: -0.8659,                 loss: nan
agent1:                 episode reward: 0.8659,                 loss: 0.2977
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6621s / 652.1853 s
agent0:                 episode reward: -0.8597,                 loss: nan
agent1:                 episode reward: 0.8597,                 loss: 0.2840
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6573s / 652.8426 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.2824
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6930s / 653.5356 s
agent0:                 episode reward: -0.5942,                 loss: nan
agent1:                 episode reward: 0.5942,                 loss: 0.2783
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7169s / 654.2525 s
agent0:                 episode reward: -0.6052,                 loss: nan
agent1:                 episode reward: 0.6052,                 loss: 0.2771
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6621s / 654.9146 s
agent0:                 episode reward: -0.7640,                 loss: nan
agent1:                 episode reward: 0.7640,                 loss: 0.2822
