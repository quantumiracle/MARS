pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f3b6646cba8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/0_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/0_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_0/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_0/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5693s / 0.5693 s
agent0:                 episode reward: 1.0880,                 loss: nan
agent1:                 episode reward: -1.0880,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1073s / 0.6766 s
agent0:                 episode reward: -0.3215,                 loss: nan
agent1:                 episode reward: 0.3215,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0913s / 0.7679 s
agent0:                 episode reward: 0.2688,                 loss: nan
agent1:                 episode reward: -0.2688,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0745s / 0.8424 s
agent0:                 episode reward: -0.3051,                 loss: nan
agent1:                 episode reward: 0.3051,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0712s / 0.9137 s
agent0:                 episode reward: -0.3375,                 loss: nan
agent1:                 episode reward: 0.3375,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0776s / 0.9913 s
agent0:                 episode reward: 0.0383,                 loss: nan
agent1:                 episode reward: -0.0383,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0765s / 1.0678 s
agent0:                 episode reward: -0.0484,                 loss: nan
agent1:                 episode reward: 0.0484,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0846s / 1.1524 s
agent0:                 episode reward: -0.2189,                 loss: nan
agent1:                 episode reward: 0.2189,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1079s / 1.2603 s
agent0:                 episode reward: -0.2680,                 loss: nan
agent1:                 episode reward: 0.2680,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1888s / 1.4492 s
agent0:                 episode reward: -0.1436,                 loss: nan
agent1:                 episode reward: 0.1436,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 1.6483 s
agent0:                 episode reward: -0.4629,                 loss: nan
agent1:                 episode reward: 0.4629,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 1.8507 s
agent0:                 episode reward: 0.1646,                 loss: nan
agent1:                 episode reward: -0.1646,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 2.0473 s
agent0:                 episode reward: -0.2424,                 loss: nan
agent1:                 episode reward: 0.2424,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 2.2415 s
agent0:                 episode reward: -0.1647,                 loss: nan
agent1:                 episode reward: 0.1647,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 2.4445 s
agent0:                 episode reward: -0.1605,                 loss: nan
agent1:                 episode reward: 0.1605,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 2.6429 s
agent0:                 episode reward: -0.3125,                 loss: nan
agent1:                 episode reward: 0.3125,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 2.8390 s
agent0:                 episode reward: -0.4449,                 loss: nan
agent1:                 episode reward: 0.4449,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 3.0331 s
agent0:                 episode reward: -0.2442,                 loss: nan
agent1:                 episode reward: 0.2442,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 3.2315 s
agent0:                 episode reward: -0.2283,                 loss: nan
agent1:                 episode reward: 0.2283,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 3.4302 s
agent0:                 episode reward: -0.1126,                 loss: nan
agent1:                 episode reward: 0.1126,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 3.6317 s
agent0:                 episode reward: -0.1513,                 loss: nan
agent1:                 episode reward: 0.1513,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 3.8303 s
agent0:                 episode reward: 0.0813,                 loss: nan
agent1:                 episode reward: -0.0813,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 4.0311 s
agent0:                 episode reward: -0.1618,                 loss: nan
agent1:                 episode reward: 0.1618,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 4.2299 s
agent0:                 episode reward: -0.2619,                 loss: nan
agent1:                 episode reward: 0.2619,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 4.4300 s
agent0:                 episode reward: 0.0584,                 loss: nan
agent1:                 episode reward: -0.0584,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 4.6274 s
agent0:                 episode reward: -0.7402,                 loss: nan
agent1:                 episode reward: 0.7402,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 4.8271 s
agent0:                 episode reward: 0.0670,                 loss: nan
agent1:                 episode reward: -0.0670,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 5.0247 s
agent0:                 episode reward: -0.1162,                 loss: nan
agent1:                 episode reward: 0.1162,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 5.2253 s
agent0:                 episode reward: -0.6474,                 loss: nan
agent1:                 episode reward: 0.6474,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 5.4234 s
agent0:                 episode reward: -0.5694,                 loss: nan
agent1:                 episode reward: 0.5694,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 5.6175 s
agent0:                 episode reward: 0.0566,                 loss: nan
agent1:                 episode reward: -0.0566,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 5.8156 s
agent0:                 episode reward: -0.4215,                 loss: nan
agent1:                 episode reward: 0.4215,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 6.0129 s
agent0:                 episode reward: 0.0824,                 loss: nan
agent1:                 episode reward: -0.0824,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 6.2088 s
agent0:                 episode reward: 0.0324,                 loss: nan
agent1:                 episode reward: -0.0324,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 6.4054 s
agent0:                 episode reward: -0.6397,                 loss: nan
agent1:                 episode reward: 0.6397,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 6.6027 s
agent0:                 episode reward: -0.2526,                 loss: nan
agent1:                 episode reward: 0.2526,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 6.7970 s
agent0:                 episode reward: -0.1353,                 loss: nan
agent1:                 episode reward: 0.1353,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 6.9923 s
agent0:                 episode reward: 0.2528,                 loss: nan
agent1:                 episode reward: -0.2528,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 7.1953 s
agent0:                 episode reward: -0.3303,                 loss: nan
agent1:                 episode reward: 0.3303,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 7.3983 s
agent0:                 episode reward: -0.1769,                 loss: nan
agent1:                 episode reward: 0.1769,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 7.5943 s
agent0:                 episode reward: -0.1667,                 loss: nan
agent1:                 episode reward: 0.1667,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 7.7962 s
agent0:                 episode reward: -0.4586,                 loss: nan
agent1:                 episode reward: 0.4586,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 7.9996 s
agent0:                 episode reward: -0.2435,                 loss: nan
agent1:                 episode reward: 0.2435,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 8.1965 s
agent0:                 episode reward: -0.4839,                 loss: nan
agent1:                 episode reward: 0.4839,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 8.3955 s
agent0:                 episode reward: -0.2915,                 loss: nan
agent1:                 episode reward: 0.2915,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 8.5947 s
agent0:                 episode reward: -0.0826,                 loss: nan
agent1:                 episode reward: 0.0826,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 8.7923 s
agent0:                 episode reward: -0.3183,                 loss: nan
agent1:                 episode reward: 0.3183,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 8.9905 s
agent0:                 episode reward: -0.2929,                 loss: nan
agent1:                 episode reward: 0.2929,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2100s / 9.2006 s
agent0:                 episode reward: -0.3077,                 loss: nan
agent1:                 episode reward: 0.3077,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 9.3988 s
agent0:                 episode reward: -0.3023,                 loss: nan
agent1:                 episode reward: 0.3023,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 9.5935 s
agent0:                 episode reward: -0.1683,                 loss: nan
agent1:                 episode reward: 0.1683,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 9.7880 s
agent0:                 episode reward: -0.2368,                 loss: nan
agent1:                 episode reward: 0.2368,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 9.9906 s
agent0:                 episode reward: 0.1027,                 loss: nan
agent1:                 episode reward: -0.1027,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 10.1894 s
agent0:                 episode reward: -0.1221,                 loss: nan
agent1:                 episode reward: 0.1221,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 10.3851 s
agent0:                 episode reward: -0.0371,                 loss: nan
agent1:                 episode reward: 0.0371,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 10.5883 s
agent0:                 episode reward: -0.1866,                 loss: nan
agent1:                 episode reward: 0.1866,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 10.7882 s
agent0:                 episode reward: -0.2517,                 loss: nan
agent1:                 episode reward: 0.2517,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 10.9891 s
agent0:                 episode reward: -0.2327,                 loss: nan
agent1:                 episode reward: 0.2327,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 11.1863 s
agent0:                 episode reward: 0.0521,                 loss: nan
agent1:                 episode reward: -0.0521,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 11.3841 s
agent0:                 episode reward: -0.2325,                 loss: nan
agent1:                 episode reward: 0.2325,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 11.5836 s
agent0:                 episode reward: -0.3749,                 loss: nan
agent1:                 episode reward: 0.3749,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 11.7822 s
agent0:                 episode reward: -0.0630,                 loss: nan
agent1:                 episode reward: 0.0630,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1891s / 11.9713 s
agent0:                 episode reward: -0.0060,                 loss: nan
agent1:                 episode reward: 0.0060,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1904s / 12.1616 s
agent0:                 episode reward: -0.3667,                 loss: nan
agent1:                 episode reward: 0.3667,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 12.3602 s
agent0:                 episode reward: -0.6813,                 loss: nan
agent1:                 episode reward: 0.6813,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 12.5587 s
agent0:                 episode reward: -0.5257,                 loss: nan
agent1:                 episode reward: 0.5257,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 12.7599 s
agent0:                 episode reward: -0.6797,                 loss: nan
agent1:                 episode reward: 0.6797,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 12.9618 s
agent0:                 episode reward: 0.0817,                 loss: nan
agent1:                 episode reward: -0.0817,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 13.1566 s
agent0:                 episode reward: -0.7385,                 loss: nan
agent1:                 episode reward: 0.7385,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 13.3546 s
agent0:                 episode reward: 0.0172,                 loss: nan
agent1:                 episode reward: -0.0172,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 13.5528 s
agent0:                 episode reward: -0.1351,                 loss: nan
agent1:                 episode reward: 0.1351,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 13.7503 s
agent0:                 episode reward: -0.4127,                 loss: nan
agent1:                 episode reward: 0.4127,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 13.9472 s
agent0:                 episode reward: 0.1195,                 loss: nan
agent1:                 episode reward: -0.1195,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 14.1455 s
agent0:                 episode reward: -0.2737,                 loss: nan
agent1:                 episode reward: 0.2737,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 14.3419 s
agent0:                 episode reward: -0.1220,                 loss: nan
agent1:                 episode reward: 0.1220,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 14.5421 s
agent0:                 episode reward: -0.2332,                 loss: nan
agent1:                 episode reward: 0.2332,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 14.7361 s
agent0:                 episode reward: 0.1185,                 loss: nan
agent1:                 episode reward: -0.1185,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 14.9341 s
agent0:                 episode reward: -0.5270,                 loss: nan
agent1:                 episode reward: 0.5270,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 15.1270 s
agent0:                 episode reward: -0.2882,                 loss: nan
agent1:                 episode reward: 0.2882,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1899s / 15.3169 s
agent0:                 episode reward: -0.2597,                 loss: nan
agent1:                 episode reward: 0.2597,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 15.5135 s
agent0:                 episode reward: -0.2316,                 loss: nan
agent1:                 episode reward: 0.2316,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 15.7119 s
agent0:                 episode reward: -0.0473,                 loss: nan
agent1:                 episode reward: 0.0473,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 15.9125 s
agent0:                 episode reward: -0.0877,                 loss: nan
agent1:                 episode reward: 0.0877,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 16.1133 s
agent0:                 episode reward: 0.3602,                 loss: nan
agent1:                 episode reward: -0.3602,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 16.3141 s
agent0:                 episode reward: 0.1241,                 loss: nan
agent1:                 episode reward: -0.1241,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 16.5155 s
agent0:                 episode reward: -0.1611,                 loss: nan
agent1:                 episode reward: 0.1611,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 16.7108 s
agent0:                 episode reward: -0.5096,                 loss: nan
agent1:                 episode reward: 0.5096,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 16.9112 s
agent0:                 episode reward: -0.0331,                 loss: nan
agent1:                 episode reward: 0.0331,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 17.1109 s
agent0:                 episode reward: -0.0561,                 loss: nan
agent1:                 episode reward: 0.0561,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1890s / 17.3000 s
agent0:                 episode reward: 0.0004,                 loss: nan
agent1:                 episode reward: -0.0004,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 17.5032 s
agent0:                 episode reward: -0.2908,                 loss: nan
agent1:                 episode reward: 0.2908,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 17.7063 s
agent0:                 episode reward: 0.1441,                 loss: nan
agent1:                 episode reward: -0.1441,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 17.9019 s
agent0:                 episode reward: -0.3217,                 loss: nan
agent1:                 episode reward: 0.3217,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 18.1037 s
agent0:                 episode reward: 0.1908,                 loss: nan
agent1:                 episode reward: -0.1908,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 18.3036 s
agent0:                 episode reward: -0.4360,                 loss: nan
agent1:                 episode reward: 0.4360,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 18.5061 s
agent0:                 episode reward: -0.3251,                 loss: nan
agent1:                 episode reward: 0.3251,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 18.7076 s
agent0:                 episode reward: -0.5464,                 loss: nan
agent1:                 episode reward: 0.5464,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 18.9072 s
agent0:                 episode reward: 0.0546,                 loss: nan
agent1:                 episode reward: -0.0546,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 19.1105 s
agent0:                 episode reward: -0.4143,                 loss: nan
agent1:                 episode reward: 0.4143,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 19.3105 s
agent0:                 episode reward: 0.0701,                 loss: nan
agent1:                 episode reward: -0.0701,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 19.5060 s
agent0:                 episode reward: 0.3217,                 loss: nan
agent1:                 episode reward: -0.3217,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 19.7029 s
agent0:                 episode reward: -0.1324,                 loss: nan
agent1:                 episode reward: 0.1324,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 19.9026 s
agent0:                 episode reward: -0.3774,                 loss: nan
agent1:                 episode reward: 0.3774,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 20.1034 s
agent0:                 episode reward: -0.0437,                 loss: nan
agent1:                 episode reward: 0.0437,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 20.3014 s
agent0:                 episode reward: -0.0361,                 loss: nan
agent1:                 episode reward: 0.0361,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 20.5025 s
agent0:                 episode reward: -0.5839,                 loss: nan
agent1:                 episode reward: 0.5839,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 20.7013 s
agent0:                 episode reward: -0.2962,                 loss: nan
agent1:                 episode reward: 0.2962,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 20.9019 s
agent0:                 episode reward: -0.0265,                 loss: nan
agent1:                 episode reward: 0.0265,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 21.0992 s
agent0:                 episode reward: -0.0530,                 loss: nan
agent1:                 episode reward: 0.0530,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 21.2976 s
agent0:                 episode reward: -0.2439,                 loss: nan
agent1:                 episode reward: 0.2439,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 21.4924 s
agent0:                 episode reward: -0.4176,                 loss: nan
agent1:                 episode reward: 0.4176,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 21.6888 s
agent0:                 episode reward: 0.1271,                 loss: nan
agent1:                 episode reward: -0.1271,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 21.8851 s
agent0:                 episode reward: -0.1125,                 loss: nan
agent1:                 episode reward: 0.1125,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 22.0865 s
agent0:                 episode reward: -0.0312,                 loss: nan
agent1:                 episode reward: 0.0312,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 22.2852 s
agent0:                 episode reward: -0.1384,                 loss: nan
agent1:                 episode reward: 0.1384,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 22.4833 s
agent0:                 episode reward: -0.1555,                 loss: nan
agent1:                 episode reward: 0.1555,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 22.6822 s
agent0:                 episode reward: -0.1216,                 loss: nan
agent1:                 episode reward: 0.1216,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 22.8793 s
agent0:                 episode reward: 0.0809,                 loss: nan
agent1:                 episode reward: -0.0809,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 23.0771 s
agent0:                 episode reward: 0.0405,                 loss: nan
agent1:                 episode reward: -0.0405,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1925s / 23.2696 s
agent0:                 episode reward: -0.4907,                 loss: nan
agent1:                 episode reward: 0.4907,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 23.4717 s
agent0:                 episode reward: -0.2694,                 loss: nan
agent1:                 episode reward: 0.2694,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 23.6694 s
agent0:                 episode reward: 0.0745,                 loss: nan
agent1:                 episode reward: -0.0745,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 23.8634 s
agent0:                 episode reward: -0.4410,                 loss: nan
agent1:                 episode reward: 0.4410,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 24.0591 s
agent0:                 episode reward: -0.0505,                 loss: nan
agent1:                 episode reward: 0.0505,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 24.2532 s
agent0:                 episode reward: -0.7721,                 loss: nan
agent1:                 episode reward: 0.7721,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 24.4567 s
agent0:                 episode reward: -0.6218,                 loss: nan
agent1:                 episode reward: 0.6218,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 24.6560 s
agent0:                 episode reward: -0.4405,                 loss: nan
agent1:                 episode reward: 0.4405,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 24.8557 s
agent0:                 episode reward: 0.0140,                 loss: nan
agent1:                 episode reward: -0.0140,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 25.0544 s
agent0:                 episode reward: -0.1524,                 loss: nan
agent1:                 episode reward: 0.1524,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 25.2514 s
agent0:                 episode reward: -0.0707,                 loss: nan
agent1:                 episode reward: 0.0707,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 25.4551 s
agent0:                 episode reward: -0.2643,                 loss: nan
agent1:                 episode reward: 0.2643,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 25.6541 s
agent0:                 episode reward: 0.1592,                 loss: nan
agent1:                 episode reward: -0.1592,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 25.8549 s
agent0:                 episode reward: -0.0849,                 loss: nan
agent1:                 episode reward: 0.0849,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 26.0583 s
agent0:                 episode reward: -0.4278,                 loss: nan
agent1:                 episode reward: 0.4278,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 26.2586 s
agent0:                 episode reward: -0.0597,                 loss: nan
agent1:                 episode reward: 0.0597,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 26.4578 s
agent0:                 episode reward: -0.2486,                 loss: nan
agent1:                 episode reward: 0.2486,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 26.6567 s
agent0:                 episode reward: 0.2803,                 loss: nan
agent1:                 episode reward: -0.2803,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 26.8574 s
agent0:                 episode reward: -0.5030,                 loss: nan
agent1:                 episode reward: 0.5030,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2521s / 27.1096 s
agent0:                 episode reward: -0.2258,                 loss: nan
agent1:                 episode reward: 0.2258,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 27.3087 s
agent0:                 episode reward: -0.4091,                 loss: nan
agent1:                 episode reward: 0.4091,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 27.5112 s
agent0:                 episode reward: 0.0064,                 loss: nan
agent1:                 episode reward: -0.0064,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 27.7136 s
agent0:                 episode reward: -0.2432,                 loss: nan
agent1:                 episode reward: 0.2432,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 27.9134 s
agent0:                 episode reward: -0.9092,                 loss: nan
agent1:                 episode reward: 0.9092,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 28.1134 s
agent0:                 episode reward: -0.1293,                 loss: nan
agent1:                 episode reward: 0.1293,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1881s / 28.3015 s
agent0:                 episode reward: -0.1235,                 loss: nan
agent1:                 episode reward: 0.1235,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1742s / 28.4756 s
agent0:                 episode reward: -0.0470,                 loss: nan
agent1:                 episode reward: 0.0470,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1916s / 28.6672 s
agent0:                 episode reward: -0.1430,                 loss: nan
agent1:                 episode reward: 0.1430,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 28.8647 s
agent0:                 episode reward: -0.2277,                 loss: nan
agent1:                 episode reward: 0.2277,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 29.0656 s
agent0:                 episode reward: -0.2255,                 loss: nan
agent1:                 episode reward: 0.2255,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 29.2654 s
agent0:                 episode reward: 0.4694,                 loss: nan
agent1:                 episode reward: -0.4694,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 29.4665 s
agent0:                 episode reward: -0.2710,                 loss: nan
agent1:                 episode reward: 0.2710,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1918s / 29.6583 s
agent0:                 episode reward: -0.3467,                 loss: nan
agent1:                 episode reward: 0.3467,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 29.8569 s
agent0:                 episode reward: -0.1566,                 loss: nan
agent1:                 episode reward: 0.1566,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2034s / 30.0603 s
agent0:                 episode reward: -0.5355,                 loss: nan
agent1:                 episode reward: 0.5355,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 30.2625 s
agent0:                 episode reward: -0.1656,                 loss: nan
agent1:                 episode reward: 0.1656,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 30.4610 s
agent0:                 episode reward: -0.2050,                 loss: nan
agent1:                 episode reward: 0.2050,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2035s / 30.6645 s
agent0:                 episode reward: -0.3613,                 loss: nan
agent1:                 episode reward: 0.3613,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 30.8662 s
agent0:                 episode reward: -0.4065,                 loss: nan
agent1:                 episode reward: 0.4065,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 31.0640 s
agent0:                 episode reward: -0.1409,                 loss: nan
agent1:                 episode reward: 0.1409,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 31.2627 s
agent0:                 episode reward: 0.0779,                 loss: nan
agent1:                 episode reward: -0.0779,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 31.4642 s
agent0:                 episode reward: -0.2291,                 loss: nan
agent1:                 episode reward: 0.2291,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 31.6635 s
agent0:                 episode reward: -0.0053,                 loss: nan
agent1:                 episode reward: 0.0053,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 31.8625 s
agent0:                 episode reward: -0.2919,                 loss: nan
agent1:                 episode reward: 0.2919,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 32.0648 s
agent0:                 episode reward: -0.0883,                 loss: nan
agent1:                 episode reward: 0.0883,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 32.2636 s
agent0:                 episode reward: -0.1293,                 loss: nan
agent1:                 episode reward: 0.1293,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 32.4622 s
agent0:                 episode reward: 0.0115,                 loss: nan
agent1:                 episode reward: -0.0115,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 32.6615 s
agent0:                 episode reward: -0.0253,                 loss: nan
agent1:                 episode reward: 0.0253,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3643s / 33.0258 s
agent0:                 episode reward: -0.1983,                 loss: nan
agent1:                 episode reward: 0.1983,                 loss: 0.4534
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6175s / 33.6433 s
agent0:                 episode reward: -0.1440,                 loss: nan
agent1:                 episode reward: 0.1440,                 loss: 0.4318
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6144s / 34.2577 s
agent0:                 episode reward: -0.5822,                 loss: nan
agent1:                 episode reward: 0.5822,                 loss: 0.4208
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5788s / 34.8364 s
agent0:                 episode reward: -0.8546,                 loss: nan
agent1:                 episode reward: 0.8546,                 loss: 0.4156
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5795s / 35.4159 s
agent0:                 episode reward: -0.7046,                 loss: nan
agent1:                 episode reward: 0.7046,                 loss: 0.4151
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 36.0052 s
agent0:                 episode reward: -0.8045,                 loss: nan
agent1:                 episode reward: 0.8045,                 loss: 0.4136
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 36.5928 s
agent0:                 episode reward: -0.3657,                 loss: nan
agent1:                 episode reward: 0.3657,                 loss: 0.4102
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5802s / 37.1730 s
agent0:                 episode reward: -1.0007,                 loss: nan
agent1:                 episode reward: 1.0007,                 loss: 0.4100
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5736s / 37.7466 s
agent0:                 episode reward: -1.0808,                 loss: nan
agent1:                 episode reward: 1.0808,                 loss: 0.4072
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 38.3279 s
agent0:                 episode reward: -0.6793,                 loss: nan
agent1:                 episode reward: 0.6793,                 loss: 0.4071
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5728s / 38.9007 s
agent0:                 episode reward: -0.6327,                 loss: nan
agent1:                 episode reward: 0.6327,                 loss: 0.4070
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5814s / 39.4821 s
agent0:                 episode reward: -0.6719,                 loss: nan
agent1:                 episode reward: 0.6719,                 loss: 0.4033
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5779s / 40.0600 s
agent0:                 episode reward: -0.8370,                 loss: nan
agent1:                 episode reward: 0.8370,                 loss: 0.4034
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 40.6518 s
agent0:                 episode reward: -0.6266,                 loss: nan
agent1:                 episode reward: 0.6266,                 loss: 0.4027
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 41.2351 s
agent0:                 episode reward: -0.8166,                 loss: nan
agent1:                 episode reward: 0.8166,                 loss: 0.4017
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5774s / 41.8125 s
agent0:                 episode reward: -0.7533,                 loss: nan
agent1:                 episode reward: 0.7533,                 loss: 0.4011
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 42.3968 s
agent0:                 episode reward: -0.7066,                 loss: nan
agent1:                 episode reward: 0.7066,                 loss: 0.4006
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 42.9810 s
agent0:                 episode reward: -0.6765,                 loss: nan
agent1:                 episode reward: 0.6765,                 loss: 0.3767
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 43.5656 s
agent0:                 episode reward: -0.6120,                 loss: nan
agent1:                 episode reward: 0.6120,                 loss: 0.3615
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 44.1455 s
agent0:                 episode reward: -0.8109,                 loss: nan
agent1:                 episode reward: 0.8109,                 loss: 0.3600
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 44.7286 s
agent0:                 episode reward: -0.5965,                 loss: nan
agent1:                 episode reward: 0.5965,                 loss: 0.3593
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 45.3156 s
agent0:                 episode reward: -0.8367,                 loss: nan
agent1:                 episode reward: 0.8367,                 loss: 0.3629
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 45.8984 s
agent0:                 episode reward: -0.8201,                 loss: nan
agent1:                 episode reward: 0.8201,                 loss: 0.3574
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 46.4848 s
agent0:                 episode reward: -0.8331,                 loss: nan
agent1:                 episode reward: 0.8331,                 loss: 0.3596
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 47.0719 s
agent0:                 episode reward: -0.6295,                 loss: nan
agent1:                 episode reward: 0.6295,                 loss: 0.3598
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5779s / 47.6498 s
agent0:                 episode reward: -0.5377,                 loss: nan
agent1:                 episode reward: 0.5377,                 loss: 0.3588
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 48.2381 s
agent0:                 episode reward: -0.6365,                 loss: nan
agent1:                 episode reward: 0.6365,                 loss: 0.3587
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 48.8370 s
agent0:                 episode reward: -0.4214,                 loss: nan
agent1:                 episode reward: 0.4214,                 loss: 0.3563
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5826s / 49.4196 s
agent0:                 episode reward: -0.6498,                 loss: nan
agent1:                 episode reward: 0.6498,                 loss: 0.3590
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5834s / 50.0031 s
agent0:                 episode reward: -0.8005,                 loss: nan
agent1:                 episode reward: 0.8005,                 loss: 0.3545
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5814s / 50.5845 s
agent0:                 episode reward: -0.6492,                 loss: nan
agent1:                 episode reward: 0.6492,                 loss: 0.3554
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 51.1656 s
agent0:                 episode reward: -0.8225,                 loss: nan
agent1:                 episode reward: 0.8225,                 loss: 0.3546
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 51.7528 s
agent0:                 episode reward: -0.5544,                 loss: nan
agent1:                 episode reward: 0.5544,                 loss: 0.3562
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5821s / 52.3349 s
agent0:                 episode reward: -0.4436,                 loss: nan
agent1:                 episode reward: 0.4436,                 loss: 0.3610
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5933s / 52.9283 s
agent0:                 episode reward: -0.8239,                 loss: nan
agent1:                 episode reward: 0.8239,                 loss: 0.3341
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 53.5208 s
agent0:                 episode reward: -0.5044,                 loss: nan
agent1:                 episode reward: 0.5044,                 loss: 0.3188
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 54.1040 s
agent0:                 episode reward: -0.3714,                 loss: nan
agent1:                 episode reward: 0.3714,                 loss: 0.3126
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 54.6942 s
agent0:                 episode reward: -0.8811,                 loss: nan
agent1:                 episode reward: 0.8811,                 loss: 0.3105
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 55.2801 s
agent0:                 episode reward: -0.9697,                 loss: nan
agent1:                 episode reward: 0.9697,                 loss: 0.3069
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5805s / 55.8606 s
agent0:                 episode reward: -0.4860,                 loss: nan
agent1:                 episode reward: 0.4860,                 loss: 0.3056
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5786s / 56.4392 s
agent0:                 episode reward: -0.6309,                 loss: nan
agent1:                 episode reward: 0.6309,                 loss: 0.3038
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 57.0314 s
agent0:                 episode reward: -1.0332,                 loss: nan
agent1:                 episode reward: 1.0332,                 loss: 0.3006
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 57.6166 s
agent0:                 episode reward: -1.0911,                 loss: nan
agent1:                 episode reward: 1.0911,                 loss: 0.3004
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 58.2029 s
agent0:                 episode reward: -1.0292,                 loss: nan
agent1:                 episode reward: 1.0292,                 loss: 0.2970
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5773s / 58.7801 s
agent0:                 episode reward: -0.3866,                 loss: nan
agent1:                 episode reward: 0.3866,                 loss: 0.2987
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5815s / 59.3617 s
agent0:                 episode reward: -0.4418,                 loss: nan
agent1:                 episode reward: 0.4418,                 loss: 0.2984
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5805s / 59.9422 s
agent0:                 episode reward: -0.6556,                 loss: nan
agent1:                 episode reward: 0.6556,                 loss: 0.2958
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 60.5317 s
agent0:                 episode reward: -1.1089,                 loss: nan
agent1:                 episode reward: 1.1089,                 loss: 0.2977
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5834s / 61.1151 s
agent0:                 episode reward: -0.6166,                 loss: nan
agent1:                 episode reward: 0.6166,                 loss: 0.2995
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5785s / 61.6935 s
agent0:                 episode reward: -0.8021,                 loss: nan
agent1:                 episode reward: 0.8021,                 loss: 0.2986
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 62.2870 s
agent0:                 episode reward: -1.0439,                 loss: nan
agent1:                 episode reward: 1.0439,                 loss: 0.3404
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 62.8693 s
agent0:                 episode reward: -0.9205,                 loss: nan
agent1:                 episode reward: 0.9205,                 loss: 0.3875
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5803s / 63.4496 s
agent0:                 episode reward: -1.1956,                 loss: nan
agent1:                 episode reward: 1.1956,                 loss: 0.3791
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 64.0333 s
agent0:                 episode reward: -0.5135,                 loss: nan
agent1:                 episode reward: 0.5135,                 loss: 0.3795
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 64.6249 s
agent0:                 episode reward: -0.1862,                 loss: nan
agent1:                 episode reward: 0.1862,                 loss: 0.3783
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5834s / 65.2084 s
agent0:                 episode reward: -0.6642,                 loss: nan
agent1:                 episode reward: 0.6642,                 loss: 0.3812
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 65.7972 s
agent0:                 episode reward: -0.1531,                 loss: nan
agent1:                 episode reward: 0.1531,                 loss: 0.3791
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 66.3851 s
agent0:                 episode reward: -0.1803,                 loss: nan
agent1:                 episode reward: 0.1803,                 loss: 0.3802
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 66.9730 s
agent0:                 episode reward: -0.2920,                 loss: nan
agent1:                 episode reward: 0.2920,                 loss: 0.3786
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 67.5623 s
agent0:                 episode reward: -0.9281,                 loss: nan
agent1:                 episode reward: 0.9281,                 loss: 0.3814
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 68.1496 s
agent0:                 episode reward: -1.0515,                 loss: nan
agent1:                 episode reward: 1.0515,                 loss: 0.3808
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 68.7451 s
agent0:                 episode reward: -0.9223,                 loss: nan
agent1:                 episode reward: 0.9223,                 loss: 0.3769
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 69.3303 s
agent0:                 episode reward: -0.7944,                 loss: nan
agent1:                 episode reward: 0.7944,                 loss: 0.3812
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5873s / 69.9176 s
agent0:                 episode reward: -0.5955,                 loss: nan
agent1:                 episode reward: 0.5955,                 loss: 0.3772
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 70.5056 s
agent0:                 episode reward: -0.3764,                 loss: nan
agent1:                 episode reward: 0.3764,                 loss: 0.3783
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5841s / 71.0897 s
agent0:                 episode reward: -0.5703,                 loss: nan
agent1:                 episode reward: 0.5703,                 loss: 0.3764
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6157s / 71.7053 s
agent0:                 episode reward: -0.9854,                 loss: nan
agent1:                 episode reward: 0.9854,                 loss: 0.3767
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 72.2954 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.3509
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 72.8859 s
agent0:                 episode reward: -0.7936,                 loss: nan
agent1:                 episode reward: 0.7936,                 loss: 0.3297
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 73.4750 s
agent0:                 episode reward: -1.1027,                 loss: nan
agent1:                 episode reward: 1.1027,                 loss: 0.3306
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 74.0614 s
agent0:                 episode reward: -0.4523,                 loss: nan
agent1:                 episode reward: 0.4523,                 loss: 0.3287
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 74.6465 s
agent0:                 episode reward: -0.4464,                 loss: nan
agent1:                 episode reward: 0.4464,                 loss: 0.3308
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 75.2361 s
agent0:                 episode reward: -0.6286,                 loss: nan
agent1:                 episode reward: 0.6286,                 loss: 0.3319
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 75.8296 s
agent0:                 episode reward: -0.7168,                 loss: nan
agent1:                 episode reward: 0.7168,                 loss: 0.3302
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 76.4223 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.3295
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 77.0086 s
agent0:                 episode reward: -0.6498,                 loss: nan
agent1:                 episode reward: 0.6498,                 loss: 0.3295
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 77.5987 s
agent0:                 episode reward: -0.7069,                 loss: nan
agent1:                 episode reward: 0.7069,                 loss: 0.3297
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 78.1897 s
agent0:                 episode reward: -0.6374,                 loss: nan
agent1:                 episode reward: 0.6374,                 loss: 0.3305
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 78.7777 s
agent0:                 episode reward: -0.1567,                 loss: nan
agent1:                 episode reward: 0.1567,                 loss: 0.3306
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 79.3725 s
agent0:                 episode reward: -0.4085,                 loss: nan
agent1:                 episode reward: 0.4085,                 loss: 0.3309
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 79.9672 s
agent0:                 episode reward: -0.9029,                 loss: nan
agent1:                 episode reward: 0.9029,                 loss: 0.3307
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 80.5653 s
agent0:                 episode reward: -0.6818,                 loss: nan
agent1:                 episode reward: 0.6818,                 loss: 0.3279
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 81.1621 s
agent0:                 episode reward: -1.0922,                 loss: nan
agent1:                 episode reward: 1.0922,                 loss: 0.3306
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 81.7488 s
agent0:                 episode reward: -0.6484,                 loss: nan
agent1:                 episode reward: 0.6484,                 loss: 0.3317
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 82.3365 s
agent0:                 episode reward: -0.3148,                 loss: nan
agent1:                 episode reward: 0.3148,                 loss: 0.3355
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6109s / 82.9474 s
agent0:                 episode reward: -0.7459,                 loss: nan
agent1:                 episode reward: 0.7459,                 loss: 0.3306
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 83.5435 s
agent0:                 episode reward: -0.7586,                 loss: nan
agent1:                 episode reward: 0.7586,                 loss: 0.3270
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 84.1347 s
agent0:                 episode reward: -0.6196,                 loss: nan
agent1:                 episode reward: 0.6196,                 loss: 0.3320
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 84.7236 s
agent0:                 episode reward: -0.5260,                 loss: nan
agent1:                 episode reward: 0.5260,                 loss: 0.3348
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 85.3150 s
agent0:                 episode reward: -0.6591,                 loss: nan
agent1:                 episode reward: 0.6591,                 loss: 0.3285
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 85.9061 s
agent0:                 episode reward: -0.8968,                 loss: nan
agent1:                 episode reward: 0.8968,                 loss: 0.3317
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 86.4966 s
agent0:                 episode reward: -0.8494,                 loss: nan
agent1:                 episode reward: 0.8494,                 loss: 0.3321
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 87.0891 s
agent0:                 episode reward: -0.7916,                 loss: nan
agent1:                 episode reward: 0.7916,                 loss: 0.3329
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 87.6800 s
agent0:                 episode reward: -0.7750,                 loss: nan
agent1:                 episode reward: 0.7750,                 loss: 0.3337
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 88.2762 s
agent0:                 episode reward: -0.9113,                 loss: nan
agent1:                 episode reward: 0.9113,                 loss: 0.3315
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 88.8686 s
agent0:                 episode reward: -0.6705,                 loss: nan
agent1:                 episode reward: 0.6705,                 loss: 0.3318
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6030s / 89.4716 s
agent0:                 episode reward: -0.5389,                 loss: nan
agent1:                 episode reward: 0.5389,                 loss: 0.3335
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 90.0714 s
agent0:                 episode reward: -0.7178,                 loss: nan
agent1:                 episode reward: 0.7178,                 loss: 0.3338
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 90.6566 s
agent0:                 episode reward: -0.3441,                 loss: nan
agent1:                 episode reward: 0.3441,                 loss: 0.3316
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 91.2503 s
agent0:                 episode reward: -0.7143,                 loss: nan
agent1:                 episode reward: 0.7143,                 loss: 0.3302
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 91.8533 s
agent0:                 episode reward: -0.7432,                 loss: nan
agent1:                 episode reward: 0.7432,                 loss: 0.3562
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 92.4430 s
agent0:                 episode reward: -0.6263,                 loss: nan
agent1:                 episode reward: 0.6263,                 loss: 0.3810
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 93.0375 s
agent0:                 episode reward: -0.5421,                 loss: nan
agent1:                 episode reward: 0.5421,                 loss: 0.3819
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 93.6274 s
agent0:                 episode reward: -0.6387,                 loss: nan
agent1:                 episode reward: 0.6387,                 loss: 0.3796
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 94.2308 s
agent0:                 episode reward: -0.5311,                 loss: nan
agent1:                 episode reward: 0.5311,                 loss: 0.3785
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6001s / 94.8309 s
agent0:                 episode reward: -0.5912,                 loss: nan
agent1:                 episode reward: 0.5912,                 loss: 0.3780
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 95.4235 s
agent0:                 episode reward: -0.9953,                 loss: nan
agent1:                 episode reward: 0.9953,                 loss: 0.3764
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 96.0240 s
agent0:                 episode reward: -0.7183,                 loss: nan
agent1:                 episode reward: 0.7183,                 loss: 0.3787
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 96.6181 s
agent0:                 episode reward: -0.5489,                 loss: nan
agent1:                 episode reward: 0.5489,                 loss: 0.3769
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 97.2067 s
agent0:                 episode reward: -0.5150,                 loss: nan
agent1:                 episode reward: 0.5150,                 loss: 0.3774
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7045s / 97.9112 s
agent0:                 episode reward: -0.2390,                 loss: nan
agent1:                 episode reward: 0.2390,                 loss: 0.3771
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6296s / 98.5408 s
agent0:                 episode reward: -0.8900,                 loss: nan
agent1:                 episode reward: 0.8900,                 loss: 0.3751
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 99.1373 s
agent0:                 episode reward: -0.7682,                 loss: nan
agent1:                 episode reward: 0.7682,                 loss: 0.3765
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 99.7417 s
agent0:                 episode reward: -0.7708,                 loss: nan
agent1:                 episode reward: 0.7708,                 loss: 0.3741
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 100.3385 s
agent0:                 episode reward: -0.5500,                 loss: nan
agent1:                 episode reward: 0.5500,                 loss: 0.3766
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 100.9320 s
agent0:                 episode reward: -0.6877,                 loss: nan
agent1:                 episode reward: 0.6877,                 loss: 0.3766
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 101.5300 s
agent0:                 episode reward: -0.9105,                 loss: nan
agent1:                 episode reward: 0.9105,                 loss: 0.3745
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 102.1265 s
agent0:                 episode reward: -0.4856,                 loss: nan
agent1:                 episode reward: 0.4856,                 loss: 0.3424
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 102.7151 s
agent0:                 episode reward: -0.4109,                 loss: nan
agent1:                 episode reward: 0.4109,                 loss: 0.3235
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 103.3063 s
agent0:                 episode reward: -1.0231,                 loss: nan
agent1:                 episode reward: 1.0231,                 loss: 0.3225
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 103.9033 s
agent0:                 episode reward: -0.1645,                 loss: nan
agent1:                 episode reward: 0.1645,                 loss: 0.3188
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 104.5024 s
agent0:                 episode reward: -0.9939,                 loss: nan
agent1:                 episode reward: 0.9939,                 loss: 0.3239
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 105.1039 s
agent0:                 episode reward: -0.4329,                 loss: nan
agent1:                 episode reward: 0.4329,                 loss: 0.3194
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 105.6991 s
agent0:                 episode reward: -0.6212,                 loss: nan
agent1:                 episode reward: 0.6212,                 loss: 0.3192
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 106.2891 s
agent0:                 episode reward: -0.5067,                 loss: nan
agent1:                 episode reward: 0.5067,                 loss: 0.3205
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 106.8840 s
agent0:                 episode reward: -0.5568,                 loss: nan
agent1:                 episode reward: 0.5568,                 loss: 0.3213
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 107.4767 s
agent0:                 episode reward: -0.3310,                 loss: nan
agent1:                 episode reward: 0.3310,                 loss: 0.3240
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 108.0653 s
agent0:                 episode reward: -0.5542,                 loss: nan
agent1:                 episode reward: 0.5542,                 loss: 0.3214
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 108.6551 s
agent0:                 episode reward: -0.6660,                 loss: nan
agent1:                 episode reward: 0.6660,                 loss: 0.3207
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 109.2465 s
agent0:                 episode reward: -0.5118,                 loss: nan
agent1:                 episode reward: 0.5118,                 loss: 0.3226
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 109.8381 s
agent0:                 episode reward: -0.7921,                 loss: nan
agent1:                 episode reward: 0.7921,                 loss: 0.3194
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 110.4273 s
agent0:                 episode reward: -0.3328,                 loss: nan
agent1:                 episode reward: 0.3328,                 loss: 0.3222
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7011s / 111.1284 s
agent0:                 episode reward: -0.4765,                 loss: nan
agent1:                 episode reward: 0.4765,                 loss: 0.3261
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6236s / 111.7520 s
agent0:                 episode reward: -0.7731,                 loss: nan
agent1:                 episode reward: 0.7731,                 loss: 0.3247
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 112.3556 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.3523
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6020s / 112.9575 s
agent0:                 episode reward: -0.9384,                 loss: nan
agent1:                 episode reward: 0.9384,                 loss: 0.3554
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6248s / 113.5823 s
agent0:                 episode reward: -0.5177,                 loss: nan
agent1:                 episode reward: 0.5177,                 loss: 0.3548
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6121s / 114.1944 s
agent0:                 episode reward: -1.2083,                 loss: nan
agent1:                 episode reward: 1.2083,                 loss: 0.3535
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5950s / 114.7894 s
agent0:                 episode reward: -0.9963,                 loss: nan
agent1:                 episode reward: 0.9963,                 loss: 0.3569
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 115.3833 s
agent0:                 episode reward: -0.7834,                 loss: nan
agent1:                 episode reward: 0.7834,                 loss: 0.3563
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5933s / 115.9765 s
agent0:                 episode reward: -0.4655,                 loss: nan
agent1:                 episode reward: 0.4655,                 loss: 0.3526
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6055s / 116.5820 s
agent0:                 episode reward: -1.0687,                 loss: nan
agent1:                 episode reward: 1.0687,                 loss: 0.3532
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 117.1739 s
agent0:                 episode reward: -0.4193,                 loss: nan
agent1:                 episode reward: 0.4193,                 loss: 0.3569
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 117.7643 s
agent0:                 episode reward: -0.9699,                 loss: nan
agent1:                 episode reward: 0.9699,                 loss: 0.3534
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 118.3548 s
agent0:                 episode reward: -0.7297,                 loss: nan
agent1:                 episode reward: 0.7297,                 loss: 0.3542
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 118.9527 s
agent0:                 episode reward: -0.9697,                 loss: nan
agent1:                 episode reward: 0.9697,                 loss: 0.3553
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 119.5494 s
agent0:                 episode reward: -0.8620,                 loss: nan
agent1:                 episode reward: 0.8620,                 loss: 0.3532
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 120.1455 s
agent0:                 episode reward: -0.8269,                 loss: nan
agent1:                 episode reward: 0.8269,                 loss: 0.3524
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 120.7416 s
agent0:                 episode reward: -1.0420,                 loss: nan
agent1:                 episode reward: 1.0420,                 loss: 0.3503
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 121.3377 s
agent0:                 episode reward: -0.4506,                 loss: nan
agent1:                 episode reward: 0.4506,                 loss: 0.3526
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 121.9349 s
agent0:                 episode reward: -0.1255,                 loss: nan
agent1:                 episode reward: 0.1255,                 loss: 0.3580
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 122.5309 s
agent0:                 episode reward: -1.0410,                 loss: nan
agent1:                 episode reward: 1.0410,                 loss: 0.3584
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 123.1209 s
agent0:                 episode reward: -0.5312,                 loss: nan
agent1:                 episode reward: 0.5312,                 loss: 0.3638
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5983s / 123.7192 s
agent0:                 episode reward: -0.3049,                 loss: nan
agent1:                 episode reward: 0.3049,                 loss: 0.3620
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 124.3248 s
agent0:                 episode reward: -0.6432,                 loss: nan
agent1:                 episode reward: 0.6432,                 loss: 0.3621
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 124.9231 s
agent0:                 episode reward: -1.1852,                 loss: nan
agent1:                 episode reward: 1.1852,                 loss: 0.3602
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 125.5138 s
agent0:                 episode reward: -0.9321,                 loss: nan
agent1:                 episode reward: 0.9321,                 loss: 0.3615
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 126.1136 s
agent0:                 episode reward: -0.4066,                 loss: nan
agent1:                 episode reward: 0.4066,                 loss: 0.3613
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 126.6999 s
agent0:                 episode reward: -0.4316,                 loss: nan
agent1:                 episode reward: 0.4316,                 loss: 0.3617
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 127.2925 s
agent0:                 episode reward: -0.6156,                 loss: nan
agent1:                 episode reward: 0.6156,                 loss: 0.3596
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 127.8870 s
agent0:                 episode reward: -0.4909,                 loss: nan
agent1:                 episode reward: 0.4909,                 loss: 0.3626
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 128.4801 s
agent0:                 episode reward: -0.5740,                 loss: nan
agent1:                 episode reward: 0.5740,                 loss: 0.3593
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 129.0740 s
agent0:                 episode reward: -0.7113,                 loss: nan
agent1:                 episode reward: 0.7113,                 loss: 0.3599
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 129.6692 s
agent0:                 episode reward: -0.7268,                 loss: nan
agent1:                 episode reward: 0.7268,                 loss: 0.3604
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 130.2645 s
agent0:                 episode reward: -1.0634,                 loss: nan
agent1:                 episode reward: 1.0634,                 loss: 0.3583
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 130.8611 s
agent0:                 episode reward: -0.8353,                 loss: nan
agent1:                 episode reward: 0.8353,                 loss: 0.3582
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 131.4585 s
agent0:                 episode reward: -0.9224,                 loss: nan
agent1:                 episode reward: 0.9224,                 loss: 0.3594
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 132.0541 s
agent0:                 episode reward: -0.5230,                 loss: nan
agent1:                 episode reward: 0.5230,                 loss: 0.3616
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 132.6526 s
agent0:                 episode reward: -0.5813,                 loss: nan
agent1:                 episode reward: 0.5813,                 loss: 0.3572
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 133.2515 s
agent0:                 episode reward: -0.7633,                 loss: nan
agent1:                 episode reward: 0.7633,                 loss: 0.3569
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 133.8438 s
agent0:                 episode reward: -0.5370,                 loss: nan
agent1:                 episode reward: 0.5370,                 loss: 0.3589
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 134.4362 s
agent0:                 episode reward: -0.5279,                 loss: nan
agent1:                 episode reward: 0.5279,                 loss: 0.3582
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 135.0330 s
agent0:                 episode reward: -0.8760,                 loss: nan
agent1:                 episode reward: 0.8760,                 loss: 0.3576
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 135.6286 s
agent0:                 episode reward: -0.6508,                 loss: nan
agent1:                 episode reward: 0.6508,                 loss: 0.3568
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 136.2237 s
agent0:                 episode reward: -0.6407,                 loss: nan
agent1:                 episode reward: 0.6407,                 loss: 0.3595
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 136.8198 s
agent0:                 episode reward: -0.7598,                 loss: nan
agent1:                 episode reward: 0.7598,                 loss: 0.3551
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 137.4237 s
agent0:                 episode reward: -0.5908,                 loss: nan
agent1:                 episode reward: 0.5908,                 loss: 0.3562
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 138.0133 s
agent0:                 episode reward: -0.4866,                 loss: nan
agent1:                 episode reward: 0.4866,                 loss: 0.3574
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 138.6124 s
agent0:                 episode reward: -0.8515,                 loss: nan
agent1:                 episode reward: 0.8515,                 loss: 0.3575
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 139.2038 s
agent0:                 episode reward: -0.7434,                 loss: nan
agent1:                 episode reward: 0.7434,                 loss: 0.3570
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 139.7918 s
agent0:                 episode reward: -0.8837,                 loss: nan
agent1:                 episode reward: 0.8837,                 loss: 0.3552
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 140.3902 s
agent0:                 episode reward: -0.7546,                 loss: nan
agent1:                 episode reward: 0.7546,                 loss: 0.3595
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 140.9800 s
agent0:                 episode reward: -0.3404,                 loss: nan
agent1:                 episode reward: 0.3404,                 loss: 0.3578
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 141.5701 s
agent0:                 episode reward: -0.9336,                 loss: nan
agent1:                 episode reward: 0.9336,                 loss: 0.3580
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 142.1622 s
agent0:                 episode reward: -0.6451,                 loss: nan
agent1:                 episode reward: 0.6451,                 loss: 0.3472
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6023s / 142.7645 s
agent0:                 episode reward: -0.9506,                 loss: nan
agent1:                 episode reward: 0.9506,                 loss: 0.3485
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 143.3604 s
agent0:                 episode reward: -0.6800,                 loss: nan
agent1:                 episode reward: 0.6800,                 loss: 0.3465
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 143.9500 s
agent0:                 episode reward: -0.6662,                 loss: nan
agent1:                 episode reward: 0.6662,                 loss: 0.3493
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 144.5593 s
agent0:                 episode reward: -0.8386,                 loss: nan
agent1:                 episode reward: 0.8386,                 loss: 0.3448
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 145.1489 s
agent0:                 episode reward: -0.4083,                 loss: nan
agent1:                 episode reward: 0.4083,                 loss: 0.3428
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 145.7539 s
agent0:                 episode reward: -0.6345,                 loss: nan
agent1:                 episode reward: 0.6345,                 loss: 0.3441
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 146.3582 s
agent0:                 episode reward: -0.7921,                 loss: nan
agent1:                 episode reward: 0.7921,                 loss: 0.3453
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 146.9591 s
agent0:                 episode reward: -0.5726,                 loss: nan
agent1:                 episode reward: 0.5726,                 loss: 0.3474
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 147.5547 s
agent0:                 episode reward: -0.7741,                 loss: nan
agent1:                 episode reward: 0.7741,                 loss: 0.3443
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 148.1511 s
agent0:                 episode reward: -1.1351,                 loss: nan
agent1:                 episode reward: 1.1351,                 loss: 0.3446
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 148.7541 s
agent0:                 episode reward: -0.8772,                 loss: nan
agent1:                 episode reward: 0.8772,                 loss: 0.3446
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 149.3557 s
agent0:                 episode reward: -0.8148,                 loss: nan
agent1:                 episode reward: 0.8148,                 loss: 0.3441
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6059s / 149.9615 s
agent0:                 episode reward: -0.8117,                 loss: nan
agent1:                 episode reward: 0.8117,                 loss: 0.3464
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 150.5628 s
agent0:                 episode reward: -0.7698,                 loss: nan
agent1:                 episode reward: 0.7698,                 loss: 0.3439
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 151.1756 s
agent0:                 episode reward: -0.6806,                 loss: nan
agent1:                 episode reward: 0.6806,                 loss: 0.3461
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 151.7757 s
agent0:                 episode reward: -0.5870,                 loss: nan
agent1:                 episode reward: 0.5870,                 loss: 0.3511
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 152.3716 s
agent0:                 episode reward: -0.9658,                 loss: nan
agent1:                 episode reward: 0.9658,                 loss: 0.3552
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 152.9617 s
agent0:                 episode reward: -1.1283,                 loss: nan
agent1:                 episode reward: 1.1283,                 loss: 0.3574
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 153.5693 s
agent0:                 episode reward: -0.8546,                 loss: nan
agent1:                 episode reward: 0.8546,                 loss: 0.3560
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 154.1703 s
agent0:                 episode reward: -0.5352,                 loss: nan
agent1:                 episode reward: 0.5352,                 loss: 0.3549
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 154.7658 s
agent0:                 episode reward: -0.4514,                 loss: nan
agent1:                 episode reward: 0.4514,                 loss: 0.3571
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 155.3639 s
agent0:                 episode reward: -0.6830,                 loss: nan
agent1:                 episode reward: 0.6830,                 loss: 0.3564
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 155.9656 s
agent0:                 episode reward: -0.7016,                 loss: nan
agent1:                 episode reward: 0.7016,                 loss: 0.3570
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 156.5578 s
agent0:                 episode reward: -0.5665,                 loss: nan
agent1:                 episode reward: 0.5665,                 loss: 0.3581
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 157.1541 s
agent0:                 episode reward: -1.1254,                 loss: nan
agent1:                 episode reward: 1.1254,                 loss: 0.3569
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 157.7574 s
agent0:                 episode reward: -0.7562,                 loss: nan
agent1:                 episode reward: 0.7562,                 loss: 0.3569
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 158.3505 s
agent0:                 episode reward: -0.6418,                 loss: nan
agent1:                 episode reward: 0.6418,                 loss: 0.3590
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 158.9397 s
agent0:                 episode reward: -0.7980,                 loss: nan
agent1:                 episode reward: 0.7980,                 loss: 0.3579
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6030s / 159.5427 s
agent0:                 episode reward: -0.7431,                 loss: nan
agent1:                 episode reward: 0.7431,                 loss: 0.3562
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 160.1411 s
agent0:                 episode reward: -0.5264,                 loss: nan
agent1:                 episode reward: 0.5264,                 loss: 0.3560
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 160.7342 s
agent0:                 episode reward: -0.8980,                 loss: nan
agent1:                 episode reward: 0.8980,                 loss: 0.3572
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 161.3324 s
agent0:                 episode reward: -0.7889,                 loss: nan
agent1:                 episode reward: 0.7889,                 loss: 0.3586
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6103s / 161.9427 s
agent0:                 episode reward: -0.5676,                 loss: nan
agent1:                 episode reward: 0.5676,                 loss: 0.3552
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6014s / 162.5440 s
agent0:                 episode reward: -1.0114,                 loss: nan
agent1:                 episode reward: 1.0114,                 loss: 0.3592
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5983s / 163.1423 s
agent0:                 episode reward: -0.6678,                 loss: nan
agent1:                 episode reward: 0.6678,                 loss: 0.3570
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 163.7450 s
agent0:                 episode reward: -0.4095,                 loss: nan
agent1:                 episode reward: 0.4095,                 loss: 0.3580
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 164.3412 s
agent0:                 episode reward: -1.0227,                 loss: nan
agent1:                 episode reward: 1.0227,                 loss: 0.3600
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 164.9369 s
agent0:                 episode reward: -0.9265,                 loss: nan
agent1:                 episode reward: 0.9265,                 loss: 0.3557
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 165.5409 s
agent0:                 episode reward: -0.5262,                 loss: nan
agent1:                 episode reward: 0.5262,                 loss: 0.3592
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 166.1395 s
agent0:                 episode reward: -0.8623,                 loss: nan
agent1:                 episode reward: 0.8623,                 loss: 0.3575
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 166.7415 s
agent0:                 episode reward: -0.5055,                 loss: nan
agent1:                 episode reward: 0.5055,                 loss: 0.3571
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 167.3409 s
agent0:                 episode reward: -0.7605,                 loss: nan
agent1:                 episode reward: 0.7605,                 loss: 0.3575
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 167.9448 s
agent0:                 episode reward: -0.6470,                 loss: nan
agent1:                 episode reward: 0.6470,                 loss: 0.3588
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 168.5409 s
agent0:                 episode reward: -0.6276,                 loss: nan
agent1:                 episode reward: 0.6276,                 loss: 0.3570
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6078s / 169.1488 s
agent0:                 episode reward: -0.7615,                 loss: nan
agent1:                 episode reward: 0.7615,                 loss: 0.3581
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 169.7483 s
agent0:                 episode reward: -0.5419,                 loss: nan
agent1:                 episode reward: 0.5419,                 loss: 0.3589
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 170.3571 s
agent0:                 episode reward: -0.2673,                 loss: nan
agent1:                 episode reward: 0.2673,                 loss: 0.3568
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 170.9619 s
agent0:                 episode reward: -0.5393,                 loss: nan
agent1:                 episode reward: 0.5393,                 loss: 0.3585
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 171.5624 s
agent0:                 episode reward: -0.4801,                 loss: nan
agent1:                 episode reward: 0.4801,                 loss: 0.3571
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6106s / 172.1729 s
agent0:                 episode reward: -0.5905,                 loss: nan
agent1:                 episode reward: 0.5905,                 loss: 0.3470
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 172.7705 s
agent0:                 episode reward: -0.7657,                 loss: nan
agent1:                 episode reward: 0.7657,                 loss: 0.3441
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 173.3608 s
agent0:                 episode reward: -0.7065,                 loss: nan
agent1:                 episode reward: 0.7065,                 loss: 0.3469
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 173.9633 s
agent0:                 episode reward: -0.8365,                 loss: nan
agent1:                 episode reward: 0.8365,                 loss: 0.3471
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 174.5715 s
agent0:                 episode reward: -0.7070,                 loss: nan
agent1:                 episode reward: 0.7070,                 loss: 0.3493
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 175.1694 s
agent0:                 episode reward: -0.5692,                 loss: nan
agent1:                 episode reward: 0.5692,                 loss: 0.3489
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6089s / 175.7783 s
agent0:                 episode reward: -0.4715,                 loss: nan
agent1:                 episode reward: 0.4715,                 loss: 0.3502
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 176.3822 s
agent0:                 episode reward: -0.8852,                 loss: nan
agent1:                 episode reward: 0.8852,                 loss: 0.3472
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 176.9837 s
agent0:                 episode reward: -0.3259,                 loss: nan
agent1:                 episode reward: 0.3259,                 loss: 0.3469
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6074s / 177.5912 s
agent0:                 episode reward: -0.7381,                 loss: nan
agent1:                 episode reward: 0.7381,                 loss: 0.3464
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 178.1879 s
agent0:                 episode reward: -0.8080,                 loss: nan
agent1:                 episode reward: 0.8080,                 loss: 0.3468
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6116s / 178.7995 s
agent0:                 episode reward: -0.5755,                 loss: nan
agent1:                 episode reward: 0.5755,                 loss: 0.3457
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6116s / 179.4111 s
agent0:                 episode reward: -0.2945,                 loss: nan
agent1:                 episode reward: 0.2945,                 loss: 0.3479
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 180.0138 s
agent0:                 episode reward: -0.5451,                 loss: nan
agent1:                 episode reward: 0.5451,                 loss: 0.3431
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6086s / 180.6224 s
agent0:                 episode reward: -0.8562,                 loss: nan
agent1:                 episode reward: 0.8562,                 loss: 0.3467
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6100s / 181.2324 s
agent0:                 episode reward: -0.4674,                 loss: nan
agent1:                 episode reward: 0.4674,                 loss: 0.3463
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6100s / 181.8424 s
agent0:                 episode reward: -0.8101,                 loss: nan
agent1:                 episode reward: 0.8101,                 loss: 0.3508
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 182.4435 s
agent0:                 episode reward: -0.7478,                 loss: nan
agent1:                 episode reward: 0.7478,                 loss: 0.3570
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 183.0517 s
agent0:                 episode reward: -1.2632,                 loss: nan
agent1:                 episode reward: 1.2632,                 loss: 0.3554
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6023s / 183.6540 s
agent0:                 episode reward: -0.4569,                 loss: nan
agent1:                 episode reward: 0.4569,                 loss: 0.3517
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6176s / 184.2716 s
agent0:                 episode reward: -0.7108,                 loss: nan
agent1:                 episode reward: 0.7108,                 loss: 0.3563
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 184.8750 s
agent0:                 episode reward: -0.4131,                 loss: nan
agent1:                 episode reward: 0.4131,                 loss: 0.3594
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 185.4724 s
agent0:                 episode reward: -0.8618,                 loss: nan
agent1:                 episode reward: 0.8618,                 loss: 0.3603
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 186.0831 s
agent0:                 episode reward: -0.7889,                 loss: nan
agent1:                 episode reward: 0.7889,                 loss: 0.3571
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6157s / 186.6988 s
agent0:                 episode reward: -0.7484,                 loss: nan
agent1:                 episode reward: 0.7484,                 loss: 0.3566
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6118s / 187.3106 s
agent0:                 episode reward: -0.6366,                 loss: nan
agent1:                 episode reward: 0.6366,                 loss: 0.3534
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 187.9202 s
agent0:                 episode reward: -0.8976,                 loss: nan
agent1:                 episode reward: 0.8976,                 loss: 0.3562
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6145s / 188.5347 s
agent0:                 episode reward: -0.2149,                 loss: nan
agent1:                 episode reward: 0.2149,                 loss: 0.3581
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 189.1483 s
agent0:                 episode reward: -0.5347,                 loss: nan
agent1:                 episode reward: 0.5347,                 loss: 0.3532
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 189.7472 s
agent0:                 episode reward: -0.3482,                 loss: nan
agent1:                 episode reward: 0.3482,                 loss: 0.3564
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 190.3453 s
agent0:                 episode reward: -0.6081,                 loss: nan
agent1:                 episode reward: 0.6081,                 loss: 0.3573
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6193s / 190.9646 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.3586
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6103s / 191.5749 s
agent0:                 episode reward: -0.6294,                 loss: nan
agent1:                 episode reward: 0.6294,                 loss: 0.3577
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6145s / 192.1894 s
agent0:                 episode reward: -0.9955,                 loss: nan
agent1:                 episode reward: 0.9955,                 loss: 0.3565
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6125s / 192.8019 s
agent0:                 episode reward: -1.0354,                 loss: nan
agent1:                 episode reward: 1.0354,                 loss: 0.3542
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 193.4043 s
agent0:                 episode reward: -0.4058,                 loss: nan
agent1:                 episode reward: 0.4058,                 loss: 0.3566