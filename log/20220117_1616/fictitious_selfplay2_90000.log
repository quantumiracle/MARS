pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f43e6585a50>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.006 0.006 0.006 ... 0.006 0.006 0.006]
 [0.006 0.006 0.006 ... 0.006 0.006 0.006]]
Load checkpoints (policy family):  [['50' '5253' '7615' ... '88510' '88868' '89256']
 ['193' '5289' '7712' ... '88692' '89048' '89466']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_90000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220117153310_exploit_90000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220117153310_exploit_90000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 5.4215s / 5.4215 s
agent0:                 episode reward: -1.0566,                 loss: nan
agent1:                 episode reward: 1.0566,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.5594s / 11.9809 s
agent0:                 episode reward: 0.1942,                 loss: nan
agent1:                 episode reward: -0.1942,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 5.1665s / 17.1474 s
agent0:                 episode reward: -0.0865,                 loss: nan
agent1:                 episode reward: 0.0865,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.4722s / 23.6196 s
agent0:                 episode reward: -0.0049,                 loss: nan
agent1:                 episode reward: 0.0049,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.6974s / 30.3170 s
agent0:                 episode reward: -0.1130,                 loss: nan
agent1:                 episode reward: 0.1130,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.0704s / 37.3874 s
agent0:                 episode reward: -0.1077,                 loss: nan
agent1:                 episode reward: 0.1077,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 7.0480s / 44.4355 s
agent0:                 episode reward: 0.0400,                 loss: nan
agent1:                 episode reward: -0.0400,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.8249s / 51.2604 s
agent0:                 episode reward: 0.1838,                 loss: nan
agent1:                 episode reward: -0.1838,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.7430s / 59.0033 s
agent0:                 episode reward: -0.3373,                 loss: nan
agent1:                 episode reward: 0.3373,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 7.1557s / 66.1590 s
agent0:                 episode reward: 0.3859,                 loss: nan
agent1:                 episode reward: -0.3859,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.2126s / 73.3716 s
agent0:                 episode reward: -0.0992,                 loss: nan
agent1:                 episode reward: 0.0992,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.9031s / 172.2747 s
agent0:                 episode reward: 0.0927,                 loss: nan
agent1:                 episode reward: -0.0927,                 loss: 0.2262
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.5221s / 409.7968 s
agent0:                 episode reward: 0.0615,                 loss: nan
agent1:                 episode reward: -0.0615,                 loss: 0.1836
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2490s / 652.0458 s
agent0:                 episode reward: -0.1045,                 loss: nan
agent1:                 episode reward: 0.1045,                 loss: 0.1695
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4162s / 894.4620 s
agent0:                 episode reward: -0.0114,                 loss: nan
agent1:                 episode reward: 0.0114,                 loss: 0.1650
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3358s / 1136.7978 s
agent0:                 episode reward: -0.0071,                 loss: nan
agent1:                 episode reward: 0.0071,                 loss: 0.1643
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6995s / 1381.4973 s
agent0:                 episode reward: 0.3457,                 loss: nan
agent1:                 episode reward: -0.3457,                 loss: 0.1635
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8729s / 1628.3701 s
agent0:                 episode reward: 0.3214,                 loss: nan
agent1:                 episode reward: -0.3214,                 loss: 0.1611
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.9168s / 1864.2870 s
agent0:                 episode reward: 0.0171,                 loss: nan
agent1:                 episode reward: -0.0171,                 loss: 0.1592
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9386s / 2107.2255 s
agent0:                 episode reward: 0.0190,                 loss: nan
agent1:                 episode reward: -0.0190,                 loss: 0.1589
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9264s / 2352.1519 s
agent0:                 episode reward: 0.1797,                 loss: nan
agent1:                 episode reward: -0.1797,                 loss: 0.1559
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6354s / 2602.7873 s
agent0:                 episode reward: -0.4352,                 loss: nan
agent1:                 episode reward: 0.4352,                 loss: 0.1542
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8723s / 2846.6596 s
agent0:                 episode reward: -0.0663,                 loss: nan
agent1:                 episode reward: 0.0663,                 loss: 0.1525
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7985s / 3093.4581 s
agent0:                 episode reward: 0.0553,                 loss: nan
agent1:                 episode reward: -0.0553,                 loss: 0.1534
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5256s / 3336.9837 s
agent0:                 episode reward: -0.3926,                 loss: nan
agent1:                 episode reward: 0.3926,                 loss: 0.1515
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7708s / 3583.7545 s
agent0:                 episode reward: 0.1652,                 loss: nan
agent1:                 episode reward: -0.1652,                 loss: 0.1516
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5678s / 3829.3223 s
agent0:                 episode reward: 0.1497,                 loss: nan
agent1:                 episode reward: -0.1497,                 loss: 0.1524
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0065s / 4082.3288 s
agent0:                 episode reward: -0.1719,                 loss: nan
agent1:                 episode reward: 0.1719,                 loss: 0.1519
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9970s / 4334.3259 s
agent0:                 episode reward: -0.3123,                 loss: nan
agent1:                 episode reward: 0.3123,                 loss: 0.1616
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 233.7539s / 4568.0798 s
agent0:                 episode reward: -0.0809,                 loss: nan
agent1:                 episode reward: 0.0809,                 loss: 0.1592
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9584s / 4818.0381 s
agent0:                 episode reward: -0.3220,                 loss: nan
agent1:                 episode reward: 0.3220,                 loss: 0.1567
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6524s / 5067.6905 s
agent0:                 episode reward: 0.2843,                 loss: nan
agent1:                 episode reward: -0.2843,                 loss: 0.1557
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5297s / 5321.2202 s
agent0:                 episode reward: -0.2118,                 loss: nan
agent1:                 episode reward: 0.2118,                 loss: 0.1549
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2829s / 5565.5031 s
agent0:                 episode reward: 0.1916,                 loss: nan
agent1:                 episode reward: -0.1916,                 loss: 0.1560
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6288s / 5814.1319 s
agent0:                 episode reward: -0.3440,                 loss: nan
agent1:                 episode reward: 0.3440,                 loss: 0.1562
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5479s / 6056.6798 s
agent0:                 episode reward: 0.3293,                 loss: nan
agent1:                 episode reward: -0.3293,                 loss: 0.1532
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2947s / 6308.9746 s
agent0:                 episode reward: 0.3372,                 loss: nan
agent1:                 episode reward: -0.3372,                 loss: 0.1543
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1160s / 6557.0906 s
agent0:                 episode reward: 0.0131,                 loss: nan
agent1:                 episode reward: -0.0131,                 loss: 0.1536
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3613s / 6799.4519 s
agent0:                 episode reward: 0.0433,                 loss: nan
agent1:                 episode reward: -0.0433,                 loss: 0.1518
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6722s / 7040.1240 s
agent0:                 episode reward: -0.0139,                 loss: nan
agent1:                 episode reward: 0.0139,                 loss: 0.1499
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.9046s / 7281.0286 s
agent0:                 episode reward: -0.3731,                 loss: nan
agent1:                 episode reward: 0.3731,                 loss: 0.1507
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8897s / 7521.9183 s
agent0:                 episode reward: -0.2952,                 loss: nan
agent1:                 episode reward: 0.2952,                 loss: 0.1492
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7154s / 7770.6337 s
agent0:                 episode reward: -0.0177,                 loss: nan
agent1:                 episode reward: 0.0177,                 loss: 0.1481
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1223s / 8010.7560 s
agent0:                 episode reward: 0.0371,                 loss: nan
agent1:                 episode reward: -0.0371,                 loss: 0.1484
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4365s / 8252.1925 s
agent0:                 episode reward: -0.1080,                 loss: nan
agent1:                 episode reward: 0.1080,                 loss: 0.1460
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9142s / 8497.1067 s
agent0:                 episode reward: -0.1142,                 loss: nan
agent1:                 episode reward: 0.1142,                 loss: 0.1457
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2668s / 8747.3735 s
agent0:                 episode reward: -0.0079,                 loss: nan
agent1:                 episode reward: 0.0079,                 loss: 0.1467
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9232s / 8994.2967 s
agent0:                 episode reward: -0.1507,                 loss: nan
agent1:                 episode reward: 0.1507,                 loss: 0.1451
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6176s / 9237.9143 s
agent0:                 episode reward: 0.3042,                 loss: nan
agent1:                 episode reward: -0.3042,                 loss: 0.1442
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3158s / 9480.2301 s
agent0:                 episode reward: -0.1489,                 loss: nan
agent1:                 episode reward: 0.1489,                 loss: 0.1448
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5387s / 9721.7688 s
agent0:                 episode reward: -0.1772,                 loss: nan
agent1:                 episode reward: 0.1772,                 loss: 0.1435
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4347s / 9963.2035 s
agent0:                 episode reward: 0.3600,                 loss: nan
agent1:                 episode reward: -0.3600,                 loss: 0.1445
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5464s / 10208.7499 s
agent0:                 episode reward: -0.0662,                 loss: nan
agent1:                 episode reward: 0.0662,                 loss: 0.1440
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1762s / 10453.9260 s
agent0:                 episode reward: -0.0007,                 loss: nan
agent1:                 episode reward: 0.0007,                 loss: 0.1444
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.4142s / 10692.3402 s
agent0:                 episode reward: 0.1154,                 loss: nan
agent1:                 episode reward: -0.1154,                 loss: 0.1437
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7209s / 10936.0611 s
agent0:                 episode reward: -0.2231,                 loss: nan
agent1:                 episode reward: 0.2231,                 loss: 0.1455
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2043s / 11186.2654 s
agent0:                 episode reward: -0.4228,                 loss: nan
agent1:                 episode reward: 0.4228,                 loss: 0.1431
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1373s / 11437.4027 s
agent0:                 episode reward: 0.1361,                 loss: nan
agent1:                 episode reward: -0.1361,                 loss: 0.1439
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8710s / 11690.2737 s
agent0:                 episode reward: -0.0762,                 loss: nan
agent1:                 episode reward: 0.0762,                 loss: 0.1433
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3284s / 11935.6021 s
agent0:                 episode reward: -0.4680,                 loss: nan
agent1:                 episode reward: 0.4680,                 loss: 0.1429
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6249s / 12185.2270 s
agent0:                 episode reward: -0.1059,                 loss: nan
agent1:                 episode reward: 0.1059,                 loss: 0.1424
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.0347s / 12429.2617 s
agent0:                 episode reward: -0.1747,                 loss: nan
agent1:                 episode reward: 0.1747,                 loss: 0.1436
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8940s / 12676.1557 s
agent0:                 episode reward: -0.2228,                 loss: nan
agent1:                 episode reward: 0.2228,                 loss: 0.1441
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 234.7850s / 12910.9407 s
agent0:                 episode reward: -0.2785,                 loss: nan
agent1:                 episode reward: 0.2785,                 loss: 0.1431
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 235.2003s / 13146.1410 s
agent0:                 episode reward: -0.2369,                 loss: nan
agent1:                 episode reward: 0.2369,                 loss: 0.1436
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0768s / 13394.2179 s
agent0:                 episode reward: -0.2952,                 loss: nan
agent1:                 episode reward: 0.2952,                 loss: 0.1422
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.7946s / 13633.0125 s
agent0:                 episode reward: 0.0216,                 loss: nan
agent1:                 episode reward: -0.0216,                 loss: 0.1419
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4019s / 13876.4144 s
agent0:                 episode reward: 0.0753,                 loss: nan
agent1:                 episode reward: -0.0753,                 loss: 0.1442
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8269s / 14129.2413 s
agent0:                 episode reward: 0.1433,                 loss: nan
agent1:                 episode reward: -0.1433,                 loss: 0.1427
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7775s / 14378.0188 s
agent0:                 episode reward: 0.2016,                 loss: nan
agent1:                 episode reward: -0.2016,                 loss: 0.1437
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3564s / 14623.3752 s
agent0:                 episode reward: -0.3488,                 loss: nan
agent1:                 episode reward: 0.3488,                 loss: 0.1426
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.1235s / 14860.4987 s
agent0:                 episode reward: -0.1379,                 loss: nan
agent1:                 episode reward: 0.1379,                 loss: 0.1415
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7760s / 15109.2747 s
agent0:                 episode reward: -0.0972,                 loss: nan
agent1:                 episode reward: 0.0972,                 loss: 0.1411
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0979s / 15356.3725 s
agent0:                 episode reward: -0.2666,                 loss: nan
agent1:                 episode reward: 0.2666,                 loss: 0.1418
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0531s / 15599.4257 s
agent0:                 episode reward: -0.2075,                 loss: nan
agent1:                 episode reward: 0.2075,                 loss: 0.1416
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.1558s / 15856.5815 s
agent0:                 episode reward: -0.0600,                 loss: nan
agent1:                 episode reward: 0.0600,                 loss: 0.1421
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8639s / 16098.4453 s
agent0:                 episode reward: -0.2734,                 loss: nan
agent1:                 episode reward: 0.2734,                 loss: 0.1409
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9288s / 16346.3742 s
agent0:                 episode reward: -0.0363,                 loss: nan
agent1:                 episode reward: 0.0363,                 loss: 0.1398
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8637s / 16596.2379 s
agent0:                 episode reward: -0.4361,                 loss: nan
agent1:                 episode reward: 0.4361,                 loss: 0.1408
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7445s / 16844.9824 s
agent0:                 episode reward: -0.3884,                 loss: nan
agent1:                 episode reward: 0.3884,                 loss: 0.1417
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7437s / 17088.7261 s
agent0:                 episode reward: -0.0620,                 loss: nan
agent1:                 episode reward: 0.0620,                 loss: 0.1414
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9386s / 17340.6647 s
agent0:                 episode reward: -0.1130,                 loss: nan
agent1:                 episode reward: 0.1130,                 loss: 0.1407
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0220s / 17586.6867 s
agent0:                 episode reward: -0.2390,                 loss: nan
agent1:                 episode reward: 0.2390,                 loss: 0.1404
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.2840s / 17826.9707 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: 0.1406
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5120s / 18070.4828 s
agent0:                 episode reward: -0.3153,                 loss: nan
agent1:                 episode reward: 0.3153,                 loss: 0.1401
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1436s / 18314.6263 s
agent0:                 episode reward: -0.6238,                 loss: nan
agent1:                 episode reward: 0.6238,                 loss: 0.1399
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2272s / 18565.8535 s
agent0:                 episode reward: -0.1965,                 loss: nan
agent1:                 episode reward: 0.1965,                 loss: 0.1393
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.5118s / 18803.3653 s
agent0:                 episode reward: -0.1581,                 loss: nan
agent1:                 episode reward: 0.1581,                 loss: 0.1381
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4397s / 19049.8050 s
agent0:                 episode reward: 0.0180,                 loss: nan
agent1:                 episode reward: -0.0180,                 loss: 0.1392
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3170s / 19297.1220 s
agent0:                 episode reward: 0.1452,                 loss: nan
agent1:                 episode reward: -0.1452,                 loss: 0.1394
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3647s / 19537.4868 s
agent0:                 episode reward: -0.2537,                 loss: nan
agent1:                 episode reward: 0.2537,                 loss: 0.1398
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8863s / 19786.3730 s
agent0:                 episode reward: 0.0564,                 loss: nan
agent1:                 episode reward: -0.0564,                 loss: 0.1391
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4859s / 20037.8589 s
agent0:                 episode reward: 0.3462,                 loss: nan
agent1:                 episode reward: -0.3462,                 loss: 0.1385
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4207s / 20284.2796 s
agent0:                 episode reward: -0.0109,                 loss: nan
agent1:                 episode reward: 0.0109,                 loss: 0.1393
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6359s / 20527.9155 s
agent0:                 episode reward: 0.2721,                 loss: nan
agent1:                 episode reward: -0.2721,                 loss: 0.1404
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3663s / 20779.2817 s
agent0:                 episode reward: -0.1563,                 loss: nan
agent1:                 episode reward: 0.1563,                 loss: 0.1416
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2967s / 21026.5784 s
agent0:                 episode reward: 0.0485,                 loss: nan
agent1:                 episode reward: -0.0485,                 loss: 0.1435
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6738s / 21276.2522 s
agent0:                 episode reward: -0.2495,                 loss: nan
agent1:                 episode reward: 0.2495,                 loss: 0.1430
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3147s / 21517.5669 s
agent0:                 episode reward: -0.2098,                 loss: nan
agent1:                 episode reward: 0.2098,                 loss: 0.1413
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7379s / 21769.3047 s
agent0:                 episode reward: -0.1686,                 loss: nan
agent1:                 episode reward: 0.1686,                 loss: 0.1422
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9495s / 22018.2542 s
agent0:                 episode reward: 0.2896,                 loss: nan
agent1:                 episode reward: -0.2896,                 loss: 0.1403
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3162s / 22262.5704 s
agent0:                 episode reward: -0.1109,                 loss: nan
agent1:                 episode reward: 0.1109,                 loss: 0.1425
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7777s / 22514.3481 s
agent0:                 episode reward: -0.2816,                 loss: nan
agent1:                 episode reward: 0.2816,                 loss: 0.1425
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4227s / 22757.7708 s
agent0:                 episode reward: 0.1758,                 loss: nan
agent1:                 episode reward: -0.1758,                 loss: 0.1430
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6914s / 23007.4622 s
agent0:                 episode reward: -0.0963,                 loss: nan
agent1:                 episode reward: 0.0963,                 loss: 0.1427
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1492s / 23254.6114 s
agent0:                 episode reward: -0.2440,                 loss: nan
agent1:                 episode reward: 0.2440,                 loss: 0.1426
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4543s / 23502.0657 s
agent0:                 episode reward: -0.0968,                 loss: nan
agent1:                 episode reward: 0.0968,                 loss: 0.1421
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7367s / 23748.8024 s
agent0:                 episode reward: 0.0137,                 loss: nan
agent1:                 episode reward: -0.0137,                 loss: 0.1418
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4976s / 23999.2999 s
agent0:                 episode reward: 0.1349,                 loss: nan
agent1:                 episode reward: -0.1349,                 loss: 0.1422
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7268s / 24254.0267 s
agent0:                 episode reward: -0.3261,                 loss: nan
agent1:                 episode reward: 0.3261,                 loss: 0.1418
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9859s / 24502.0126 s
agent0:                 episode reward: -0.4958,                 loss: nan
agent1:                 episode reward: 0.4958,                 loss: 0.1413
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5722s / 24748.5848 s
agent0:                 episode reward: -0.3577,                 loss: nan
agent1:                 episode reward: 0.3577,                 loss: 0.1410
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7959s / 25000.3807 s
agent0:                 episode reward: 0.1900,                 loss: nan
agent1:                 episode reward: -0.1900,                 loss: 0.1416
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6469s / 25241.0276 s
agent0:                 episode reward: 0.0092,                 loss: nan
agent1:                 episode reward: -0.0092,                 loss: 0.1413
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0492s / 25484.0767 s
agent0:                 episode reward: -0.3395,                 loss: nan
agent1:                 episode reward: 0.3395,                 loss: 0.1400
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2408s / 25732.3176 s
agent0:                 episode reward: -0.1400,                 loss: nan
agent1:                 episode reward: 0.1400,                 loss: 0.1409
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.7596s / 25968.0772 s
agent0:                 episode reward: 0.0297,                 loss: nan
agent1:                 episode reward: -0.0297,                 loss: 0.1410
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1710s / 26211.2482 s
agent0:                 episode reward: -0.0663,                 loss: nan
agent1:                 episode reward: 0.0663,                 loss: 0.1400
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1343s / 26464.3825 s
agent0:                 episode reward: -0.3761,                 loss: nan
agent1:                 episode reward: 0.3761,                 loss: 0.1402
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3683s / 26712.7507 s
agent0:                 episode reward: -0.1766,                 loss: nan
agent1:                 episode reward: 0.1766,                 loss: 0.1421
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4420s / 26962.1927 s
agent0:                 episode reward: 0.0244,                 loss: nan
agent1:                 episode reward: -0.0244,                 loss: 0.1410
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3522s / 27213.5450 s
agent0:                 episode reward: -0.0619,                 loss: nan
agent1:                 episode reward: 0.0619,                 loss: 0.1401
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6217s / 27467.1666 s
agent0:                 episode reward: -0.4165,                 loss: nan
agent1:                 episode reward: 0.4165,                 loss: 0.1401
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.0825s / 27706.2492 s
agent0:                 episode reward: 0.2988,                 loss: nan
agent1:                 episode reward: -0.2988,                 loss: 0.1389
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5169s / 27953.7660 s
agent0:                 episode reward: 0.0366,                 loss: nan
agent1:                 episode reward: -0.0366,                 loss: 0.1407
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4081s / 28200.1742 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1413
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.3287s / 28457.5029 s
agent0:                 episode reward: -0.0814,                 loss: nan
agent1:                 episode reward: 0.0814,                 loss: 0.1412
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7110s / 28703.2139 s
agent0:                 episode reward: -0.2676,                 loss: nan
agent1:                 episode reward: 0.2676,                 loss: 0.1411
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8233s / 28953.0372 s
agent0:                 episode reward: -0.3675,                 loss: nan
agent1:                 episode reward: 0.3675,                 loss: 0.1436
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2889s / 29202.3261 s
agent0:                 episode reward: 0.1606,                 loss: nan
agent1:                 episode reward: -0.1606,                 loss: 0.1428
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9906s / 29449.3168 s
agent0:                 episode reward: -0.2957,                 loss: nan
agent1:                 episode reward: 0.2957,                 loss: 0.1454
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3863s / 29693.7031 s
agent0:                 episode reward: -0.4900,                 loss: nan
agent1:                 episode reward: 0.4900,                 loss: 0.1443
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9751s / 29938.6781 s
agent0:                 episode reward: 0.0141,                 loss: nan
agent1:                 episode reward: -0.0141,                 loss: 0.1434
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 261.1659s / 30199.8440 s
agent0:                 episode reward: 0.0245,                 loss: nan
agent1:                 episode reward: -0.0245,                 loss: 0.1431
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6171s / 30453.4611 s
agent0:                 episode reward: -0.1565,                 loss: nan
agent1:                 episode reward: 0.1565,                 loss: 0.1436
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3233s / 30699.7844 s
agent0:                 episode reward: -0.0156,                 loss: nan
agent1:                 episode reward: 0.0156,                 loss: 0.1434
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0483s / 30949.8327 s
agent0:                 episode reward: -0.6467,                 loss: nan
agent1:                 episode reward: 0.6467,                 loss: 0.1446
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1008s / 31196.9335 s
agent0:                 episode reward: -0.2645,                 loss: nan
agent1:                 episode reward: 0.2645,                 loss: 0.1421
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.4030s / 31435.3364 s
agent0:                 episode reward: -0.0108,                 loss: nan
agent1:                 episode reward: 0.0108,                 loss: 0.1424
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2667s / 31684.6031 s
agent0:                 episode reward: -0.0194,                 loss: nan
agent1:                 episode reward: 0.0194,                 loss: 0.1446
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0035s / 31931.6065 s
agent0:                 episode reward: 0.3940,                 loss: nan
agent1:                 episode reward: -0.3940,                 loss: 0.1443
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.6571s / 32185.2637 s
agent0:                 episode reward: 0.1114,                 loss: nan
agent1:                 episode reward: -0.1114,                 loss: 0.1442
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4365s / 32429.7002 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.1441
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0735s / 32672.7737 s
agent0:                 episode reward: -0.4081,                 loss: nan
agent1:                 episode reward: 0.4081,                 loss: 0.1441
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7711s / 32916.5448 s
agent0:                 episode reward: 0.0636,                 loss: nan
agent1:                 episode reward: -0.0636,                 loss: 0.1436
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7546s / 33163.2994 s
agent0:                 episode reward: 0.3961,                 loss: nan
agent1:                 episode reward: -0.3961,                 loss: 0.1424
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4550s / 33416.7543 s
agent0:                 episode reward: -0.1774,                 loss: nan
agent1:                 episode reward: 0.1774,                 loss: 0.1430
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0957s / 33666.8501 s
agent0:                 episode reward: -0.2875,                 loss: nan
agent1:                 episode reward: 0.2875,                 loss: 0.1437
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9047s / 33913.7548 s
agent0:                 episode reward: -0.2884,                 loss: nan
agent1:                 episode reward: 0.2884,                 loss: 0.1422
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.2864s / 34171.0411 s
agent0:                 episode reward: -0.2644,                 loss: nan
agent1:                 episode reward: 0.2644,                 loss: 0.1412
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6733s / 34420.7144 s
agent0:                 episode reward: 0.0513,                 loss: nan
agent1:                 episode reward: -0.0513,                 loss: 0.1429
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1270s / 34663.8414 s
agent0:                 episode reward: -0.5976,                 loss: nan
agent1:                 episode reward: 0.5976,                 loss: 0.1424
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4145s / 34904.2560 s
agent0:                 episode reward: 0.1471,                 loss: nan
agent1:                 episode reward: -0.1471,                 loss: 0.1430
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8111s / 35145.0671 s
agent0:                 episode reward: -0.0510,                 loss: nan
agent1:                 episode reward: 0.0510,                 loss: 0.1417
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1276s / 35395.1946 s
agent0:                 episode reward: -0.3995,                 loss: nan
agent1:                 episode reward: 0.3995,                 loss: 0.1416
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.2004s / 35634.3951 s
agent0:                 episode reward: 0.0543,                 loss: nan
agent1:                 episode reward: -0.0543,                 loss: 0.1409
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.1790s / 35890.5740 s
agent0:                 episode reward: -0.4043,                 loss: nan
agent1:                 episode reward: 0.4043,                 loss: 0.1414
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7704s / 36137.3445 s
agent0:                 episode reward: -0.3549,                 loss: nan
agent1:                 episode reward: 0.3549,                 loss: 0.1426
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1498s / 36386.4943 s
agent0:                 episode reward: -0.3572,                 loss: nan
agent1:                 episode reward: 0.3572,                 loss: 0.1414
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.2853s / 36637.7796 s
agent0:                 episode reward: -0.1055,                 loss: nan
agent1:                 episode reward: 0.1055,                 loss: 0.1434
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6708s / 36884.4504 s
agent0:                 episode reward: -0.1216,                 loss: nan
agent1:                 episode reward: 0.1216,                 loss: 0.1425
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7442s / 37132.1947 s
agent0:                 episode reward: 0.0122,                 loss: nan
agent1:                 episode reward: -0.0122,                 loss: 0.1411
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7760s / 37377.9707 s
agent0:                 episode reward: 0.0818,                 loss: nan
agent1:                 episode reward: -0.0818,                 loss: 0.1426
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8537s / 37625.8244 s
agent0:                 episode reward: 0.1132,                 loss: nan
agent1:                 episode reward: -0.1132,                 loss: 0.1413
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9343s / 37880.7587 s
agent0:                 episode reward: -0.1349,                 loss: nan
agent1:                 episode reward: 0.1349,                 loss: 0.1430
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6592s / 38131.4179 s
agent0:                 episode reward: -0.1267,                 loss: nan
agent1:                 episode reward: 0.1267,                 loss: 0.1417
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3962s / 38377.8141 s
agent0:                 episode reward: -0.2689,                 loss: nan
agent1:                 episode reward: 0.2689,                 loss: 0.1428
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4341s / 38629.2481 s
agent0:                 episode reward: -0.0456,                 loss: nan
agent1:                 episode reward: 0.0456,                 loss: 0.1426
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6092s / 38871.8573 s
agent0:                 episode reward: -0.0767,                 loss: nan
agent1:                 episode reward: 0.0767,                 loss: 0.1405
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6045s / 39116.4619 s
agent0:                 episode reward: -0.2546,                 loss: nan
agent1:                 episode reward: 0.2546,                 loss: 0.1416
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2110s / 39369.6729 s
agent0:                 episode reward: 0.0045,                 loss: nan
agent1:                 episode reward: -0.0045,                 loss: 0.1440
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3088s / 39616.9816 s
agent0:                 episode reward: -0.2661,                 loss: nan
agent1:                 episode reward: 0.2661,                 loss: 0.1398
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1112s / 39865.0929 s
agent0:                 episode reward: -0.2029,                 loss: nan
agent1:                 episode reward: 0.2029,                 loss: 0.1404
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3502s / 40110.4431 s
agent0:                 episode reward: -0.6142,                 loss: nan
agent1:                 episode reward: 0.6142,                 loss: 0.1404
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7926s / 40359.2357 s
agent0:                 episode reward: -0.4518,                 loss: nan
agent1:                 episode reward: 0.4518,                 loss: 0.1404
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 261.6520s / 40620.8877 s
agent0:                 episode reward: -0.1023,                 loss: nan
agent1:                 episode reward: 0.1023,                 loss: 0.1411
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 256.3261s / 40877.2138 s
agent0:                 episode reward: -0.1027,                 loss: nan
agent1:                 episode reward: 0.1027,                 loss: 0.1410
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0126s / 41129.2264 s
agent0:                 episode reward: 0.2670,                 loss: nan
agent1:                 episode reward: -0.2670,                 loss: 0.1422
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4656s / 41373.6919 s
agent0:                 episode reward: -0.3533,                 loss: nan
agent1:                 episode reward: 0.3533,                 loss: 0.1404
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1002s / 41627.7921 s
agent0:                 episode reward: -0.2602,                 loss: nan
agent1:                 episode reward: 0.2602,                 loss: 0.1405
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5828s / 41873.3749 s
agent0:                 episode reward: 0.0850,                 loss: nan
agent1:                 episode reward: -0.0850,                 loss: 0.1395
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.5052s / 42130.8802 s
agent0:                 episode reward: -0.3343,                 loss: nan
agent1:                 episode reward: 0.3343,                 loss: 0.1392
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3816s / 42377.2618 s
agent0:                 episode reward: 0.2121,                 loss: nan
agent1:                 episode reward: -0.2121,                 loss: 0.1381
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8882s / 42624.1500 s
agent0:                 episode reward: -0.3810,                 loss: nan
agent1:                 episode reward: 0.3810,                 loss: 0.1380
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4972s / 42863.6472 s
agent0:                 episode reward: -0.3074,                 loss: nan
agent1:                 episode reward: 0.3074,                 loss: 0.1396
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.2905s / 43117.9377 s
agent0:                 episode reward: -0.4315,                 loss: nan
agent1:                 episode reward: 0.4315,                 loss: 0.1388
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7178s / 43367.6556 s
agent0:                 episode reward: -0.2129,                 loss: nan
agent1:                 episode reward: 0.2129,                 loss: 0.1376
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.8636s / 43617.5191 s
agent0:                 episode reward: -0.2158,                 loss: nan
agent1:                 episode reward: 0.2158,                 loss: 0.1401
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0078s / 43864.5270 s
agent0:                 episode reward: -0.1874,                 loss: nan
agent1:                 episode reward: 0.1874,                 loss: 0.1392
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.4217s / 44101.9487 s
agent0:                 episode reward: -0.6210,                 loss: nan
agent1:                 episode reward: 0.6210,                 loss: 0.1398
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4745s / 44354.4232 s
agent0:                 episode reward: -0.2823,                 loss: nan
agent1:                 episode reward: 0.2823,                 loss: 0.1398
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1899s / 44604.6131 s
agent0:                 episode reward: -0.0424,                 loss: nan
agent1:                 episode reward: 0.0424,                 loss: 0.1386
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9149s / 44851.5280 s
agent0:                 episode reward: -0.5679,                 loss: nan
agent1:                 episode reward: 0.5679,                 loss: 0.1388
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 234.0633s / 45085.5913 s
agent0:                 episode reward: -0.2290,                 loss: nan
agent1:                 episode reward: 0.2290,                 loss: 0.1390
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7915s / 45337.3829 s
agent0:                 episode reward: -0.2695,                 loss: nan
agent1:                 episode reward: 0.2695,                 loss: 0.1389
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4326s / 45576.8154 s
agent0:                 episode reward: -0.2249,                 loss: nan
agent1:                 episode reward: 0.2249,                 loss: 0.1405
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0849s / 45826.9004 s
agent0:                 episode reward: 0.1682,                 loss: nan
agent1:                 episode reward: -0.1682,                 loss: 0.1391
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5518s / 46077.4522 s
agent0:                 episode reward: -0.0554,                 loss: nan
agent1:                 episode reward: 0.0554,                 loss: 0.1412
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1657s / 46322.6179 s
agent0:                 episode reward: 0.1130,                 loss: nan
agent1:                 episode reward: -0.1130,                 loss: 0.1401
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1599s / 46576.7778 s
agent0:                 episode reward: -0.8340,                 loss: nan
agent1:                 episode reward: 0.8340,                 loss: 0.1393
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0432s / 46817.8210 s
agent0:                 episode reward: -0.1776,                 loss: nan
agent1:                 episode reward: 0.1776,                 loss: 0.1398
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4529s / 47059.2739 s
agent0:                 episode reward: 0.3062,                 loss: nan
agent1:                 episode reward: -0.3062,                 loss: 0.1404
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9519s / 47306.2259 s
agent0:                 episode reward: -0.1915,                 loss: nan
agent1:                 episode reward: 0.1915,                 loss: 0.1405
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3596s / 47552.5855 s
agent0:                 episode reward: -0.3528,                 loss: nan
agent1:                 episode reward: 0.3528,                 loss: 0.1397
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 258.2795s / 47810.8650 s
agent0:                 episode reward: -0.5845,                 loss: nan
agent1:                 episode reward: 0.5845,                 loss: 0.1394
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6458s / 48055.5108 s
agent0:                 episode reward: -0.2890,                 loss: nan
agent1:                 episode reward: 0.2890,                 loss: 0.1399
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2301s / 48296.7409 s
agent0:                 episode reward: 0.0782,                 loss: nan
agent1:                 episode reward: -0.0782,                 loss: 0.1408
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4771s / 48545.2180 s
agent0:                 episode reward: 0.0705,                 loss: nan
agent1:                 episode reward: -0.0705,                 loss: 0.1397
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.3598s / 48787.5777 s
agent0:                 episode reward: -0.4549,                 loss: nan
agent1:                 episode reward: 0.4549,                 loss: 0.1398
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1237s / 49034.7015 s
agent0:                 episode reward: -0.0039,                 loss: nan
agent1:                 episode reward: 0.0039,                 loss: 0.1380
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5383s / 49278.2398 s
agent0:                 episode reward: 0.1894,                 loss: nan
agent1:                 episode reward: -0.1894,                 loss: 0.1401
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5188s / 49520.7586 s
agent0:                 episode reward: -0.3713,                 loss: nan
agent1:                 episode reward: 0.3713,                 loss: 0.1397
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3263s / 49768.0849 s
agent0:                 episode reward: -0.4160,                 loss: nan
agent1:                 episode reward: 0.4160,                 loss: 0.1384
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3396s / 50020.4245 s
agent0:                 episode reward: -0.0557,                 loss: nan
agent1:                 episode reward: 0.0557,                 loss: 0.1371
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2600s / 50265.6845 s
agent0:                 episode reward: -0.1429,                 loss: nan
agent1:                 episode reward: 0.1429,                 loss: 0.1386
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.5127s / 50508.1972 s
agent0:                 episode reward: -0.0716,                 loss: nan
agent1:                 episode reward: 0.0716,                 loss: 0.1384
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6752s / 50752.8724 s
agent0:                 episode reward: -0.3798,                 loss: nan
agent1:                 episode reward: 0.3798,                 loss: 0.1392
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6999s / 51001.5723 s
agent0:                 episode reward: -0.3419,                 loss: nan
agent1:                 episode reward: 0.3419,                 loss: 0.1381
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9227s / 51249.4950 s
agent0:                 episode reward: -0.1689,                 loss: nan
agent1:                 episode reward: 0.1689,                 loss: 0.1385
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9870s / 51502.4820 s
agent0:                 episode reward: -0.5110,                 loss: nan
agent1:                 episode reward: 0.5110,                 loss: 0.1386
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9920s / 51750.4741 s
agent0:                 episode reward: -0.6083,                 loss: nan
agent1:                 episode reward: 0.6083,                 loss: 0.1370
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2294s / 51999.7035 s
agent0:                 episode reward: 0.0031,                 loss: nan
agent1:                 episode reward: -0.0031,                 loss: 0.1386
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7589s / 52250.4624 s
agent0:                 episode reward: -0.0550,                 loss: nan
agent1:                 episode reward: 0.0550,                 loss: 0.1377
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.4371s / 52504.8995 s
agent0:                 episode reward: -0.0055,                 loss: nan
agent1:                 episode reward: 0.0055,                 loss: 0.1384
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0793s / 52756.9788 s
agent0:                 episode reward: -0.3554,                 loss: nan
agent1:                 episode reward: 0.3554,                 loss: 0.1371
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5857s / 53007.5644 s
agent0:                 episode reward: 0.1156,                 loss: nan
agent1:                 episode reward: -0.1156,                 loss: 0.1374
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7046s / 53258.2691 s
agent0:                 episode reward: -0.2094,                 loss: nan
agent1:                 episode reward: 0.2094,                 loss: 0.1384
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6481s / 53501.9171 s
agent0:                 episode reward: -0.1831,                 loss: nan
agent1:                 episode reward: 0.1831,                 loss: 0.1384
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0675s / 53743.9847 s
agent0:                 episode reward: -0.2619,                 loss: nan
agent1:                 episode reward: 0.2619,                 loss: 0.1402
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0270s / 53987.0117 s
agent0:                 episode reward: 0.3287,                 loss: nan
agent1:                 episode reward: -0.3287,                 loss: 0.1408
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3059s / 54238.3176 s
agent0:                 episode reward: -0.2748,                 loss: nan
agent1:                 episode reward: 0.2748,                 loss: 0.1417
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8759s / 54485.1935 s
agent0:                 episode reward: -0.2020,                 loss: nan
agent1:                 episode reward: 0.2020,                 loss: 0.1413
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8127s / 54738.0062 s
agent0:                 episode reward: -0.4621,                 loss: nan
agent1:                 episode reward: 0.4621,                 loss: 0.1412
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3216s / 54984.3278 s
agent0:                 episode reward: -0.2092,                 loss: nan
agent1:                 episode reward: 0.2092,                 loss: 0.1390
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4562s / 55231.7841 s
agent0:                 episode reward: 0.1320,                 loss: nan
agent1:                 episode reward: -0.1320,                 loss: 0.1395
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7953s / 55482.5794 s
agent0:                 episode reward: -0.0035,                 loss: nan
agent1:                 episode reward: 0.0035,                 loss: 0.1396
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0629s / 55731.6423 s
agent0:                 episode reward: -0.3649,                 loss: nan
agent1:                 episode reward: 0.3649,                 loss: 0.1409
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1475s / 55981.7898 s
agent0:                 episode reward: 0.0982,                 loss: nan
agent1:                 episode reward: -0.0982,                 loss: 0.1406
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4237s / 56229.2135 s
agent0:                 episode reward: -0.0160,                 loss: nan
agent1:                 episode reward: 0.0160,                 loss: 0.1413
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3013s / 56481.5148 s
agent0:                 episode reward: -0.2884,                 loss: nan
agent1:                 episode reward: 0.2884,                 loss: 0.1388
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9447s / 56724.4596 s
agent0:                 episode reward: -0.0282,                 loss: nan
agent1:                 episode reward: 0.0282,                 loss: 0.1416
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3611s / 56969.8207 s
agent0:                 episode reward: 0.0092,                 loss: nan
agent1:                 episode reward: -0.0092,                 loss: 0.1397
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8756s / 57223.6963 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.1405
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2041s / 57473.9004 s
agent0:                 episode reward: -0.2911,                 loss: nan
agent1:                 episode reward: 0.2911,                 loss: 0.1397
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5409s / 57718.4413 s
agent0:                 episode reward: -0.3579,                 loss: nan
agent1:                 episode reward: 0.3579,                 loss: 0.1392
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2623s / 57966.7036 s
agent0:                 episode reward: -0.3195,                 loss: nan
agent1:                 episode reward: 0.3195,                 loss: 0.1382
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7240s / 58212.4276 s
agent0:                 episode reward: -0.3474,                 loss: nan
agent1:                 episode reward: 0.3474,                 loss: 0.1384
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1500s / 58453.5776 s
agent0:                 episode reward: -0.3622,                 loss: nan
agent1:                 episode reward: 0.3622,                 loss: 0.1376
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6239s / 58699.2015 s
agent0:                 episode reward: 0.1604,                 loss: nan
agent1:                 episode reward: -0.1604,                 loss: 0.1382
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 239.3560s / 58938.5575 s
agent0:                 episode reward: -0.4096,                 loss: nan
agent1:                 episode reward: 0.4096,                 loss: 0.1377
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9898s / 59188.5473 s
agent0:                 episode reward: -0.2544,                 loss: nan
agent1:                 episode reward: 0.2544,                 loss: 0.1379
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6792s / 59441.2265 s
agent0:                 episode reward: 0.0507,                 loss: nan
agent1:                 episode reward: -0.0507,                 loss: 0.1386
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2243s / 59684.4507 s
agent0:                 episode reward: -0.5467,                 loss: nan
agent1:                 episode reward: 0.5467,                 loss: 0.1379
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2473s / 59932.6980 s
agent0:                 episode reward: -0.4027,                 loss: nan
agent1:                 episode reward: 0.4027,                 loss: 0.1365
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4333s / 60184.1314 s
agent0:                 episode reward: 0.0164,                 loss: nan
agent1:                 episode reward: -0.0164,                 loss: 0.1358
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.3788s / 60434.5102 s
agent0:                 episode reward: -0.1538,                 loss: nan
agent1:                 episode reward: 0.1538,                 loss: 0.1383
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1192s / 60686.6294 s
agent0:                 episode reward: -0.3184,                 loss: nan
agent1:                 episode reward: 0.3184,                 loss: 0.1377
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4135s / 60931.0429 s
agent0:                 episode reward: -0.1264,                 loss: nan
agent1:                 episode reward: 0.1264,                 loss: 0.1385
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7366s / 61175.7794 s
agent0:                 episode reward: -0.5064,                 loss: nan
agent1:                 episode reward: 0.5064,                 loss: 0.1377
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0825s / 61425.8619 s
agent0:                 episode reward: -0.2700,                 loss: nan
agent1:                 episode reward: 0.2700,                 loss: 0.1382
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6444s / 61668.5063 s
agent0:                 episode reward: -0.1532,                 loss: nan
agent1:                 episode reward: 0.1532,                 loss: 0.1370
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2377s / 61917.7441 s
agent0:                 episode reward: -0.2518,                 loss: nan
agent1:                 episode reward: 0.2518,                 loss: 0.1409
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 237.5748s / 62155.3188 s
agent0:                 episode reward: -0.2245,                 loss: nan
agent1:                 episode reward: 0.2245,                 loss: 0.1418
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.4565s / 62398.7753 s
agent0:                 episode reward: -0.2082,                 loss: nan
agent1:                 episode reward: 0.2082,                 loss: 0.1418
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0808s / 62648.8561 s
agent0:                 episode reward: -0.2919,                 loss: nan
agent1:                 episode reward: 0.2919,                 loss: 0.1421
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4332s / 62898.2893 s
agent0:                 episode reward: -0.4506,                 loss: nan
agent1:                 episode reward: 0.4506,                 loss: 0.1428
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5179s / 63145.8072 s
agent0:                 episode reward: -0.4513,                 loss: nan
agent1:                 episode reward: 0.4513,                 loss: 0.1424
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9597s / 63393.7669 s
agent0:                 episode reward: -0.3307,                 loss: nan
agent1:                 episode reward: 0.3307,                 loss: 0.1422
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.4605s / 63634.2274 s
agent0:                 episode reward: -0.5686,                 loss: nan
agent1:                 episode reward: 0.5686,                 loss: 0.1412
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.1430s / 63892.3704 s
agent0:                 episode reward: -0.3628,                 loss: nan
agent1:                 episode reward: 0.3628,                 loss: 0.1413
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3655s / 64135.7359 s
agent0:                 episode reward: -0.2983,                 loss: nan
agent1:                 episode reward: 0.2983,                 loss: 0.1410
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6659s / 64385.4018 s
agent0:                 episode reward: -0.5588,                 loss: nan
agent1:                 episode reward: 0.5588,                 loss: 0.1414
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6994s / 64631.1011 s
agent0:                 episode reward: -0.1398,                 loss: nan
agent1:                 episode reward: 0.1398,                 loss: 0.1428
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9838s / 64877.0849 s
agent0:                 episode reward: -0.5615,                 loss: nan
agent1:                 episode reward: 0.5615,                 loss: 0.1425
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7846s / 65127.8695 s
agent0:                 episode reward: -0.2639,                 loss: nan
agent1:                 episode reward: 0.2639,                 loss: 0.1414
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8674s / 65371.7369 s
agent0:                 episode reward: -0.5836,                 loss: nan
agent1:                 episode reward: 0.5836,                 loss: 0.1442
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5508s / 65622.2878 s
agent0:                 episode reward: -0.4005,                 loss: nan
agent1:                 episode reward: 0.4005,                 loss: 0.1423
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.4613s / 65877.7491 s
agent0:                 episode reward: -0.6291,                 loss: nan
agent1:                 episode reward: 0.6291,                 loss: 0.1425
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5784s / 66125.3275 s
agent0:                 episode reward: -0.5775,                 loss: nan
agent1:                 episode reward: 0.5775,                 loss: 0.1396
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5117s / 66375.8392 s
agent0:                 episode reward: -0.3890,                 loss: nan
agent1:                 episode reward: 0.3890,                 loss: 0.1384
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0300s / 66623.8692 s
agent0:                 episode reward: -0.3435,                 loss: nan
agent1:                 episode reward: 0.3435,                 loss: 0.1394
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4383s / 66875.3076 s
agent0:                 episode reward: -0.3233,                 loss: nan
agent1:                 episode reward: 0.3233,                 loss: 0.1397
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6142s / 67126.9217 s
agent0:                 episode reward: -0.3453,                 loss: nan
agent1:                 episode reward: 0.3453,                 loss: 0.1387
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2486s / 67377.1704 s
agent0:                 episode reward: -0.1358,                 loss: nan
agent1:                 episode reward: 0.1358,                 loss: 0.1386
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9396s / 67621.1099 s
agent0:                 episode reward: -0.4119,                 loss: nan
agent1:                 episode reward: 0.4119,                 loss: 0.1390
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.9368s / 67877.0467 s
agent0:                 episode reward: -0.3946,                 loss: nan
agent1:                 episode reward: 0.3946,                 loss: 0.1398
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2972s / 68124.3439 s
agent0:                 episode reward: -0.0169,                 loss: nan
agent1:                 episode reward: 0.0169,                 loss: 0.1404
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4857s / 68374.8296 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: 0.1397
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9620s / 68626.7916 s
agent0:                 episode reward: -0.3196,                 loss: nan
agent1:                 episode reward: 0.3196,                 loss: 0.1399
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8344s / 68879.6261 s
agent0:                 episode reward: -0.0829,                 loss: nan
agent1:                 episode reward: 0.0829,                 loss: 0.1394
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4373s / 69126.0633 s
agent0:                 episode reward: -0.3236,                 loss: nan
agent1:                 episode reward: 0.3236,                 loss: 0.1385
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6701s / 69373.7334 s
agent0:                 episode reward: -0.2358,                 loss: nan
agent1:                 episode reward: 0.2358,                 loss: 0.1384
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5780s / 69622.3114 s
agent0:                 episode reward: -0.1237,                 loss: nan
agent1:                 episode reward: 0.1237,                 loss: 0.1400
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0787s / 69871.3901 s
agent0:                 episode reward: 0.0810,                 loss: nan
agent1:                 episode reward: -0.0810,                 loss: 0.1395
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5156s / 70119.9056 s
agent0:                 episode reward: -0.6718,                 loss: nan
agent1:                 episode reward: 0.6718,                 loss: 0.1396
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.8366s / 70376.7423 s
agent0:                 episode reward: -0.3494,                 loss: nan
agent1:                 episode reward: 0.3494,                 loss: 0.1408
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0306s / 70624.7729 s
agent0:                 episode reward: -0.3252,                 loss: nan
agent1:                 episode reward: 0.3252,                 loss: 0.1412
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 258.3734s / 70883.1462 s
agent0:                 episode reward: -0.3240,                 loss: nan
agent1:                 episode reward: 0.3240,                 loss: 0.1417
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9045s / 71132.0507 s
agent0:                 episode reward: -0.5593,                 loss: nan
agent1:                 episode reward: 0.5593,                 loss: 0.1403
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7158s / 71386.7665 s
agent0:                 episode reward: -0.5974,                 loss: nan
agent1:                 episode reward: 0.5974,                 loss: 0.1408
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6506s / 71636.4171 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: 0.1401
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.5170s / 71879.9341 s
agent0:                 episode reward: -0.2750,                 loss: nan
agent1:                 episode reward: 0.2750,                 loss: 0.1401
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7668s / 72135.7009 s
agent0:                 episode reward: -0.4717,                 loss: nan
agent1:                 episode reward: 0.4717,                 loss: 0.1410
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 259.0455s / 72394.7464 s
agent0:                 episode reward: -0.5289,                 loss: nan
agent1:                 episode reward: 0.5289,                 loss: 0.1410
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.2838s / 72648.0302 s
agent0:                 episode reward: -0.4903,                 loss: nan
agent1:                 episode reward: 0.4903,                 loss: 0.1412
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0465s / 72899.0767 s
agent0:                 episode reward: -0.2595,                 loss: nan
agent1:                 episode reward: 0.2595,                 loss: 0.1394
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 257.1191s / 73156.1958 s
agent0:                 episode reward: -0.4636,                 loss: nan
agent1:                 episode reward: 0.4636,                 loss: 0.1408
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5959s / 73407.7917 s
agent0:                 episode reward: -0.5602,                 loss: nan
agent1:                 episode reward: 0.5602,                 loss: 0.1424
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3038s / 73661.0955 s
agent0:                 episode reward: -0.3740,                 loss: nan
agent1:                 episode reward: 0.3740,                 loss: 0.1415
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.3669s / 73917.4624 s
agent0:                 episode reward: -0.6497,                 loss: nan
agent1:                 episode reward: 0.6497,                 loss: 0.1407
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2365s / 74166.6989 s
agent0:                 episode reward: -0.2015,                 loss: nan
agent1:                 episode reward: 0.2015,                 loss: 0.1400
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1152s / 74413.8141 s
agent0:                 episode reward: -0.2398,                 loss: nan
agent1:                 episode reward: 0.2398,                 loss: 0.1398
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.6262s / 74670.4402 s
agent0:                 episode reward: -0.1645,                 loss: nan
agent1:                 episode reward: 0.1645,                 loss: 0.1406
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 261.5955s / 74932.0358 s
agent0:                 episode reward: -0.1505,                 loss: nan
agent1:                 episode reward: 0.1505,                 loss: 0.1408
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4247s / 75185.4605 s
agent0:                 episode reward: 0.1278,                 loss: nan
agent1:                 episode reward: -0.1278,                 loss: 0.1380
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.5918s / 75441.0523 s
agent0:                 episode reward: -0.1118,                 loss: nan
agent1:                 episode reward: 0.1118,                 loss: 0.1396
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1863s / 75681.2386 s
agent0:                 episode reward: -0.4269,                 loss: nan
agent1:                 episode reward: 0.4269,                 loss: 0.1380
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 235.0121s / 75916.2507 s
agent0:                 episode reward: -0.4428,                 loss: nan
agent1:                 episode reward: 0.4428,                 loss: 0.1392
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.0359s / 76172.2866 s
agent0:                 episode reward: -0.5688,                 loss: nan
agent1:                 episode reward: 0.5688,                 loss: 0.1388
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4203s / 76420.7069 s
agent0:                 episode reward: 0.0981,                 loss: nan
agent1:                 episode reward: -0.0981,                 loss: 0.1395
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.0234s / 76678.7303 s
agent0:                 episode reward: -0.4293,                 loss: nan
agent1:                 episode reward: 0.4293,                 loss: 0.1387
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6771s / 76927.4074 s
agent0:                 episode reward: -0.2699,                 loss: nan
agent1:                 episode reward: 0.2699,                 loss: 0.1406
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7457s / 77179.1531 s
agent0:                 episode reward: -0.6002,                 loss: nan
agent1:                 episode reward: 0.6002,                 loss: 0.1398
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5982s / 77432.7513 s
agent0:                 episode reward: -0.1263,                 loss: nan
agent1:                 episode reward: 0.1263,                 loss: 0.1393
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6658s / 77674.4172 s
agent0:                 episode reward: -0.8476,                 loss: nan
agent1:                 episode reward: 0.8476,                 loss: 0.1381
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3399s / 77923.7571 s
agent0:                 episode reward: -0.1285,                 loss: nan
agent1:                 episode reward: 0.1285,                 loss: 0.1402
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.4256s / 78162.1827 s
agent0:                 episode reward: -0.2664,                 loss: nan
agent1:                 episode reward: 0.2664,                 loss: 0.1397
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.0710s / 78418.2537 s
agent0:                 episode reward: -0.1056,                 loss: nan
agent1:                 episode reward: 0.1056,                 loss: 0.1403
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9435s / 78667.1971 s
agent0:                 episode reward: -0.0488,                 loss: nan
agent1:                 episode reward: 0.0488,                 loss: 0.1405
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.2398s / 78905.4370 s
agent0:                 episode reward: -0.6374,                 loss: nan
agent1:                 episode reward: 0.6374,                 loss: 0.1412
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9219s / 79158.3589 s
agent0:                 episode reward: -0.2688,                 loss: nan
agent1:                 episode reward: 0.2688,                 loss: 0.1406
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9320s / 79405.2910 s
agent0:                 episode reward: -0.6530,                 loss: nan
agent1:                 episode reward: 0.6530,                 loss: 0.1395
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9632s / 79657.2542 s
agent0:                 episode reward: -0.1381,                 loss: nan
agent1:                 episode reward: 0.1381,                 loss: 0.1415
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0112s / 79902.2654 s
agent0:                 episode reward: -0.1431,                 loss: nan
agent1:                 episode reward: 0.1431,                 loss: 0.1411
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5959s / 80152.8612 s
agent0:                 episode reward: -0.4837,                 loss: nan
agent1:                 episode reward: 0.4837,                 loss: 0.1411
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6101s / 80407.4714 s
agent0:                 episode reward: -0.4415,                 loss: nan
agent1:                 episode reward: 0.4415,                 loss: 0.1409
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9836s / 80652.4550 s
agent0:                 episode reward: -0.0454,                 loss: nan
agent1:                 episode reward: 0.0454,                 loss: 0.1399
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2720s / 80904.7269 s
agent0:                 episode reward: -0.1392,                 loss: nan
agent1:                 episode reward: 0.1392,                 loss: 0.1406
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0527s / 81157.7796 s
agent0:                 episode reward: -0.3605,                 loss: nan
agent1:                 episode reward: 0.3605,                 loss: 0.1408
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.3659s / 81413.1456 s
agent0:                 episode reward: 0.1940,                 loss: nan
agent1:                 episode reward: -0.1940,                 loss: 0.1395
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0408s / 81658.1863 s
agent0:                 episode reward: -0.3342,                 loss: nan
agent1:                 episode reward: 0.3342,                 loss: 0.1408
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6877s / 81909.8740 s
agent0:                 episode reward: -0.4947,                 loss: nan
agent1:                 episode reward: 0.4947,                 loss: 0.1407
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.8563s / 82165.7303 s
agent0:                 episode reward: -0.4957,                 loss: nan
agent1:                 episode reward: 0.4957,                 loss: 0.1400
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6007s / 82411.3310 s
agent0:                 episode reward: -0.2518,                 loss: nan
agent1:                 episode reward: 0.2518,                 loss: 0.1405
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3149s / 82658.6459 s
agent0:                 episode reward: -0.2406,                 loss: nan
agent1:                 episode reward: 0.2406,                 loss: 0.1403
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4115s / 82910.0574 s
agent0:                 episode reward: 0.0589,                 loss: nan
agent1:                 episode reward: -0.0589,                 loss: 0.1408
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8202s / 83149.8777 s
agent0:                 episode reward: -0.3878,                 loss: nan
agent1:                 episode reward: 0.3878,                 loss: 0.1410
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 258.2080s / 83408.0857 s
agent0:                 episode reward: 0.0701,                 loss: nan
agent1:                 episode reward: -0.0701,                 loss: 0.1403
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4134s / 83655.4991 s
agent0:                 episode reward: -0.4102,                 loss: nan
agent1:                 episode reward: 0.4102,                 loss: 0.1406
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5421s / 83908.0413 s
agent0:                 episode reward: -0.1453,                 loss: nan
agent1:                 episode reward: 0.1453,                 loss: 0.1419
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1585s / 84162.1998 s
agent0:                 episode reward: -0.5468,                 loss: nan
agent1:                 episode reward: 0.5468,                 loss: 0.1405
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7655s / 84402.9653 s
agent0:                 episode reward: -0.0606,                 loss: nan
agent1:                 episode reward: 0.0606,                 loss: 0.1392
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6449s / 84645.6103 s
agent0:                 episode reward: -0.3098,                 loss: nan
agent1:                 episode reward: 0.3098,                 loss: 0.1409
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5407s / 84899.1510 s
agent0:                 episode reward: -0.2921,                 loss: nan
agent1:                 episode reward: 0.2921,                 loss: 0.1398
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7046s / 85142.8555 s
agent0:                 episode reward: -0.0429,                 loss: nan
agent1:                 episode reward: 0.0429,                 loss: 0.1406
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.1113s / 85392.9668 s
agent0:                 episode reward: -0.2242,                 loss: nan
agent1:                 episode reward: 0.2242,                 loss: 0.1391
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.9983s / 85641.9651 s
agent0:                 episode reward: -0.1856,                 loss: nan
agent1:                 episode reward: 0.1856,                 loss: 0.1398
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5724s / 85889.5374 s
agent0:                 episode reward: -0.6118,                 loss: nan
agent1:                 episode reward: 0.6118,                 loss: 0.1388
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9193s / 86133.4567 s
agent0:                 episode reward: -0.3539,                 loss: nan
agent1:                 episode reward: 0.3539,                 loss: 0.1398
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8244s / 86379.2811 s
agent0:                 episode reward: -0.1980,                 loss: nan
agent1:                 episode reward: 0.1980,                 loss: 0.1405
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3439s / 86626.6250 s
agent0:                 episode reward: -0.1949,                 loss: nan
agent1:                 episode reward: 0.1949,                 loss: 0.1409
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6635s / 86878.2886 s
agent0:                 episode reward: -0.6945,                 loss: nan
agent1:                 episode reward: 0.6945,                 loss: 0.1380
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7913s / 87125.0799 s
agent0:                 episode reward: -0.6524,                 loss: nan
agent1:                 episode reward: 0.6524,                 loss: 0.1364
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7911s / 87378.8710 s
agent0:                 episode reward: -0.1202,                 loss: nan
agent1:                 episode reward: 0.1202,                 loss: 0.1356
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7948s / 87633.6659 s
agent0:                 episode reward: -0.2638,                 loss: nan
agent1:                 episode reward: 0.2638,                 loss: 0.1373
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.6534s / 87874.3192 s
agent0:                 episode reward: -0.2051,                 loss: nan
agent1:                 episode reward: 0.2051,                 loss: 0.1366
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0990s / 88126.4182 s
agent0:                 episode reward: -0.1501,                 loss: nan
agent1:                 episode reward: 0.1501,                 loss: 0.1368
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9880s / 88376.4062 s
agent0:                 episode reward: -0.1285,                 loss: nan
agent1:                 episode reward: 0.1285,                 loss: 0.1364
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.0265s / 88630.4328 s
agent0:                 episode reward: -0.3317,                 loss: nan
agent1:                 episode reward: 0.3317,                 loss: 0.1359
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3870s / 88882.8198 s
agent0:                 episode reward: -0.2575,                 loss: nan
agent1:                 episode reward: 0.2575,                 loss: 0.1365
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.0313s / 89135.8510 s
agent0:                 episode reward: -0.3632,                 loss: nan
agent1:                 episode reward: 0.3632,                 loss: 0.1388
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5013s / 89389.3523 s
agent0:                 episode reward: -0.1217,                 loss: nan
agent1:                 episode reward: 0.1217,                 loss: 0.1368
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6948s / 89636.0470 s
agent0:                 episode reward: -0.5053,                 loss: nan
agent1:                 episode reward: 0.5053,                 loss: 0.1353
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6060s / 89890.6530 s
agent0:                 episode reward: -0.6518,                 loss: nan
agent1:                 episode reward: 0.6518,                 loss: 0.1355
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6598s / 90142.3128 s