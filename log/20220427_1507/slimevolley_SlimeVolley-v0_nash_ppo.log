pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [499, 150, 109, 988, 26]
<SubprocVectorEnv instance>
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 5, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'feature': {'hidden_dim_list': [128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'policy': {'hidden_dim_list': [128], 'hidden_activation': False, 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220427_1507/slimevolley_SlimeVolley-v0_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220427_1507/slimevolley_SlimeVolley-v0_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 8.6170s / 8.6170 s
env0_first_0:                 episode reward: 3.0000,                 loss: -0.1462
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 1.0000,                 loss: nan
env3_second_0:                 episode reward: -1.0000,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 51.8730s / 60.4900 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0266
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 61.5678s / 122.0578 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3365
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: -1.2000,                 loss: nan
env3_second_0:                 episode reward: 1.2000,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 60.7882s / 182.8460 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3207
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 58.1428s / 240.9888 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3743
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 57.6082s / 298.5970 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.4736
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 57.1766s / 355.7737 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.5412
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.9637s / 411.7373 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.4969
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5622s / 467.2996 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.5130
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8751s / 522.1746 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.5238
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.1647s / 576.3393 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.5924
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4147s / 630.7539 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.5362
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 58.1835s / 688.9375 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.5194
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 58.2340s / 747.1715 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.6457
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 58.1887s / 805.3602 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.6683
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 57.6355s / 862.9957 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.7054
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 57.9589s / 920.9547 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.6914
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 57.4426s / 978.3973 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.6915
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 57.5064s / 1035.9037 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.6487
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 57.7511s / 1093.6548 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.6430
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.7581s / 1149.4129 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.6275
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.4679s / 1205.8808 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.6664
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.9974s / 1261.8782 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.6842
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.0449s / 1317.9231 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.6837
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.8560s / 1373.7791 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.6792
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.8976s / 1429.6767 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.6895
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.3383s / 1486.0150 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.6718
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.3242s / 1542.3392 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.5658
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0410s / 1597.3802 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.6219
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2106s / 1652.5907 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.7499
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0604s / 1707.6511 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.6727
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0962s / 1762.7473 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.6880
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1877s / 1817.9350 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.6911
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1181s / 1873.0531 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.6892
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6022s / 1928.6553 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.7551
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1485s / 1983.8038 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.7339
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7727s / 2038.5765 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.6599
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8541s / 2093.4306 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.6388
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.9794s / 2147.4100 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.6245
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3379s / 2201.7479 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.5818
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0850s / 2256.8329 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.6159
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3412s / 2311.1741 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.6282
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9514s / 2366.1255 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.6845
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0975s / 2421.2229 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.6897
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7858s / 2476.0087 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.6611
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4619s / 2530.4706 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.6437
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4359s / 2585.9065 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.5944
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8849s / 2640.7913 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.6581
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1089s / 2695.9002 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.6897
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4094s / 2750.3096 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.7576
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.7925s / 2804.1021 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.6960
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5415s / 2858.6436 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.6330
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8015s / 2913.4451 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.6408
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3751s / 2967.8202 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.6287
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5607s / 3022.3810 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.6650
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4107s / 3076.7917 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.6190
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.0430s / 3130.8346 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.6632
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8235s / 3185.6581 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.5783
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 1.0000,                 loss: nan
env4_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.0006s / 3239.6588 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.6304
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3709s / 3294.0296 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.5969
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5100s / 3349.5396 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.5947
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.7425s / 3406.2821 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.6038
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.9320s / 3463.2141 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.5396
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.7865s / 3520.0006 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.5031
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6582s / 3575.6588 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.5217
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5238s / 3631.1826 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.5108
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3639s / 3686.5465 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.5412
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.7701s / 3742.3166 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.5632
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 58.2541s / 3800.5707 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.5722
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.9990s / 3857.5696 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.6404
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 57.2158s / 3914.7854 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.5406
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.4045s / 3971.1899 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.5514
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.9706s / 4027.1604 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.5796
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 57.1388s / 4084.2993 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.5466
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6091s / 4139.9084 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.5208
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2656s / 4194.1740 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.5961
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6996s / 4248.8736 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.5076
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6739s / 4304.5475 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.5893
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1099s / 4359.6574 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.6333
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4692s / 4414.1266 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.6776
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3428s / 4469.4694 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.5615
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6096s / 4525.0790 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.6499
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9044s / 4579.9834 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.6215
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0674s / 4635.0508 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.6191
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0311s / 4690.0819 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.6208
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.8284s / 4743.9103 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.5925
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3460s / 4798.2564 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.6306
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4849s / 4852.7413 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.6141
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.8817s / 4906.6230 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.5597
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8474s / 4961.4705 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.5213
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3309s / 5015.8014 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.5483
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0915s / 5070.8929 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.5577
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4836s / 5126.3765 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.5077
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6422s / 5181.0187 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.6038
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.1929s / 5235.2116 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.5561
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2055s / 5290.4171 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.5920
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4733s / 5345.8904 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.6098
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7501s / 5400.6406 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.5857
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.8119s / 5456.4525 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.6104
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5584s / 5512.0109 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.5854
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1401s / 5567.1510 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.5136
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6761s / 5621.8271 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.5329
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4060s / 5677.2332 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.5810
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4530s / 5731.6862 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.5623
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.9609s / 5787.6471 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.5647
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.6639s / 5844.3110 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.5312
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.7506s / 5901.0616 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.5289
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 57.7590s / 5958.8207 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.5461
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.7827s / 6015.6034 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.5374
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.0056s / 6071.6090 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.5451
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5404s / 6127.1494 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.5202
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.7399s / 6182.8892 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.5089
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1551s / 6238.0443 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.5372
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3126s / 6293.3569 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.5051
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.3975s / 6349.7544 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.4871
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 1.0000,                 loss: nan
env3_second_0:                 episode reward: -1.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5750s / 6405.3294 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.5413
env0_second_0:                 episode reward: -0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2330s / 6460.5624 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.5100
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2235s / 6515.7859 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.4792
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2169s / 6571.0028 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.4883
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6894s / 6626.6923 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.5154
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1322s / 6681.8244 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.5656
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1513s / 6736.9758 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.5605
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.7208s / 6792.6966 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.5618
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6953s / 6847.3919 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.5701
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8753s / 6902.2671 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.5605
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9815s / 6957.2487 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.6059
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5489s / 7011.7976 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.5328
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9411s / 7066.7387 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.6033
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1271s / 7121.8658 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.5996
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0499s / 7176.9157 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.5631
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6175s / 7231.5332 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.5372
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5889s / 7287.1220 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.5453
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6222s / 7341.7442 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.4628
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7965s / 7396.5408 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.5566
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9454s / 7451.4862 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.5153
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.1368s / 7505.6230 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.4754
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8062s / 7560.4292 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.5928
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.1449s / 7614.5741 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.5197
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9034s / 7669.4776 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.5588
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.1830s / 7723.6606 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.5662
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9931s / 7778.6537 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.4882
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3634s / 7834.0171 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3846
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4331s / 7888.4502 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.4515
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2620s / 7942.7122 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.4246
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.7619s / 7996.4741 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3399
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2209s / 8050.6950 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3074
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6504s / 8105.3454 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2884
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6644s / 8160.0098 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2345
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5776s / 8214.5873 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2583
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.1861s / 8267.7734 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2703
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.0330s / 8321.8065 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2478
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2085s / 8377.0150 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2045
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1050s / 8432.1199 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0696
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6728s / 8486.7927 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0337
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5398s / 8541.3326 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0095
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3700s / 8595.7026 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.1569
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9659s / 8650.6685 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0082
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9797s / 8705.6481 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0812
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6493s / 8760.2974 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.1441
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3707s / 8814.6681 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2260
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.8825s / 8868.5506 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2071
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9865s / 8923.5371 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0361
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5937s / 8978.1308 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0728
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5776s / 9032.7084 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0783
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9581s / 9087.6665 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0895
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8352s / 9142.5017 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1765
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6109s / 9197.1126 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.1624
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.1457s / 9251.2582 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.1299
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3079s / 9305.5661 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2589
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5487s / 9360.1148 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.1277
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6506s / 9414.7654 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.1590
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6657s / 9469.4311 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2060
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0111s / 9524.4422 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2147
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6860s / 9579.1282 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.1741
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.8781s / 9633.0064 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2748
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2041s / 9687.2105 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1282
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7070s / 9741.9175 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1784
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7951s / 9796.7126 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2200
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7489s / 9851.4615 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2018
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6141s / 9906.0755 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.1673
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2901s / 9961.3657 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2162
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4904s / 10015.8560 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0303
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.9762s / 10069.8323 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.0349
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3105s / 10124.1428 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0179
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1352s / 10179.2779 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.1202
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3073s / 10233.5852 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1767
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3170s / 10287.9022 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.0171
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.8435s / 10343.7457 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0099
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5864s / 10398.3322 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0078
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8280s / 10453.1601 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0177
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.9791s / 10507.1392 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1094
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3761s / 10561.5153 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2549
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0189s / 10616.5342 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.0501
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.1785s / 10670.7128 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0301
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2654s / 10725.9782 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0262
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9832s / 10780.9614 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0968
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1014s / 10836.0629 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.0897
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7452s / 10890.8080 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.1409
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5567s / 10945.3648 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.0564
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4113s / 11000.7761 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0051
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5964s / 11055.3725 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0702
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4043s / 11110.7768 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0834
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8288s / 11165.6056 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.1652
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7279s / 11220.3334 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.1515
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4251s / 11275.7585 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0379
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3385s / 11330.0970 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1387
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8050s / 11384.9020 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0632
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7718s / 11439.6738 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0742
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3659s / 11494.0397 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0918
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.0816s / 11548.1213 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.1846
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7899s / 11602.9112 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2570
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3621s / 11658.2733 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.1009
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5849s / 11712.8582 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.1338
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7101s / 11767.5683 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.2397
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6883s / 11823.2566 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0697
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7541s / 11878.0107 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.1191
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8973s / 11932.9081 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.1753
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2639s / 11987.1719 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.1663
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6084s / 12041.7803 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0786
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3447s / 12096.1249 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.1997
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9936s / 12151.1185 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2273
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5188s / 12205.6373 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0745
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2434s / 12260.8806 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0439
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6873s / 12315.5679 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0020
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9669s / 12370.5348 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.1160
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5884s / 12425.1232 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0883
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2291s / 12480.3523 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0139
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5244s / 12534.8767 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.0929
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5758s / 12589.4525 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.1048
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8657s / 12644.3182 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.0703
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9455s / 12699.2637 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0424
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8111s / 12754.0748 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0382
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2706s / 12809.3454 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0052
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9270s / 12864.2723 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0502
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0004s / 12919.2727 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0123
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2835s / 12973.5563 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.1176
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3020s / 13027.8583 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2544
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0826s / 13082.9409 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0969
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8310s / 13137.7720 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.1290
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4430s / 13192.2150 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.1621
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9418s / 13247.1568 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.1716
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9976s / 13302.1544 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.1953
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.8559s / 13358.0103 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2415
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.9068s / 13411.9171 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.2625
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4619s / 13467.3790 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.2393
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6066s / 13522.9856 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0941
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.8416s / 13576.8272 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.0781
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8960s / 13631.7231 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.1336
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8922s / 13686.6154 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.1021
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5651s / 13741.1805 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.1739
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8905s / 13796.0709 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.0987
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0447s / 13851.1156 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.1447
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3159s / 13906.4315 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.1892
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7194s / 13961.1509 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.1665
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7809s / 14015.9319 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0418
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9668s / 14070.8986 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.1498
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.1203s / 14125.0189 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2224
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5305s / 14179.5495 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0818
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.9000,                 loss: nan
env3_second_0:                 episode reward: -0.9000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1743s / 14234.7238 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0040
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4948s / 14290.2186 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0004
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8914s / 14345.1100 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.1953
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.0313s / 14399.1413 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2575
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4094s / 14454.5507 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2014
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6593s / 14509.2100 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.1402
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3226s / 14563.5325 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2012
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7423s / 14618.2748 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.1691
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4234s / 14672.6982 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.2129
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5723s / 14727.2705 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2650
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7864s / 14782.0568 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.1890
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3854s / 14837.4423 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.1200
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6093s / 14892.0515 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2681
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6196s / 14946.6711 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.1775
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4369s / 15001.1080 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.1180
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5752s / 15055.6832 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0644
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6856s / 15111.3689 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2490
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7679s / 15166.1367 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.1467
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0296s / 15221.1664 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2342
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2889s / 15276.4553 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2586
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7598s / 15331.2151 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1490
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2890s / 15385.5041 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.2589
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8106s / 15440.3147 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.3139
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7449s / 15495.0595 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.3505
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8363s / 15549.8959 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.1753
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8850s / 15604.7808 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.3216
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0814s / 15659.8622 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4014
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2416s / 15715.1038 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.3772
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6472s / 15769.7510 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.1101
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1971s / 15824.9482 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.1486
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.0994s / 15879.0476 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.1964
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9284s / 15933.9759 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.1700
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2447s / 15988.2206 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.1925
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3271s / 16042.5477 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.1168
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3933s / 16097.9410 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.2021
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6360s / 16152.5770 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0279
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1013s / 16207.6783 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.0083
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9457s / 16262.6240 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.1366
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3419s / 16317.9659 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.1629
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8240s / 16372.7899 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1569
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7288s / 16427.5187 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.2552
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5451s / 16482.0638 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2008
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.7138s / 16537.7775 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.2289
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5123s / 16592.2898 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.3962
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7982s / 16647.0880 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.0273
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0698s / 16702.1578 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2051
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9587s / 16757.1165 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.3260
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4751s / 16811.5916 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.2755
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9771s / 16866.5688 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2583
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4621s / 16922.0309 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3177
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2250s / 16977.2559 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.3902
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2841s / 17032.5400 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4164
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4087s / 17086.9487 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.3599
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9789s / 17141.9277 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.3768
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6079s / 17196.5355 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.3317
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0863s / 17251.6218 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.3128
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8299s / 17306.4517 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.3551
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3277s / 17360.7794 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.3433
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.8979s / 17414.6773 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4031
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5312s / 17469.2084 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.3605
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8480s / 17524.0564 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2212
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5128s / 17579.5692 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2393
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1189s / 17634.6881 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2641
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7100s / 17689.3980 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.3250
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4127s / 17743.8107 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4052
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3191s / 17798.1299 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3337
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7977s / 17852.9275 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0417
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8246s / 17907.7522 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0076
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5152s / 17962.2674 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0881
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1815s / 18017.4489 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.0938
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.7770s / 18073.2259 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2751
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8543s / 18128.0802 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.1724
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1974s / 18183.2777 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.1992
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7064s / 18237.9841 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2382
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8687s / 18292.8527 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.1138
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8693s / 18347.7221 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1906
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7780s / 18402.5001 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.2650
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8815s / 18457.3816 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.3235
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8643s / 18512.2459 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2737
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.8542s / 18568.1001 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.3359
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8669s / 18622.9670 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.1078
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9316s / 18677.8985 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.2434
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2443s / 18732.1428 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.3177
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8777s / 18787.0205 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.3191
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6144s / 18841.6348 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3474
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9481s / 18896.5829 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.3988
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0442s / 18951.6272 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.2920
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5529s / 19007.1800 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.3163
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1620s / 19062.3420 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2936
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5501s / 19116.8922 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.3684
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4938s / 19171.3860 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.3629
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1988s / 19226.5848 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.3792
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.9604s / 19280.5452 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.1506
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.7445s / 19336.2897 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.2583
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1967s / 19391.4864 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4212
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7532s / 19446.2396 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.3143
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8501s / 19501.0897 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4305
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1572s / 19556.2469 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.2186
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7908s / 19611.0377 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3997
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1854s / 19666.2231 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4618
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2215s / 19721.4446 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.2222
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3233s / 19776.7680 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.3524
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6801s / 19831.4480 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4099
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7314s / 19886.1794 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2533
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9976s / 19941.1770 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.0715
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7913s / 19995.9683 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.1684
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1223s / 20051.0906 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.0624
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4401s / 20106.5307 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.1413
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1464s / 20161.6771 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0761
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9395s / 20216.6166 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2479
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4815s / 20271.0982 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.0438
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9828s / 20326.0810 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0623
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.8521s / 20381.9330 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.1371
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1036s / 20437.0366 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.1830
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6309s / 20491.6675 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0519
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2293s / 20545.8968 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.0824
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6117s / 20600.5085 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0214
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7051s / 20655.2135 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0153
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -1.2000,                 loss: nan
env3_second_0:                 episode reward: 1.2000,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2082s / 20709.4217 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.3206
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.1511s / 20765.5729 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2409
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7007s / 20820.2735 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.2468
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7269s / 20875.0004 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.1554
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4269s / 20929.4272 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.2071
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2752s / 20984.7024 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0701
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5464s / 21039.2488 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2957
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1072s / 21094.3560 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.1377
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8106s / 21149.1666 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0892
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0720s / 21204.2387 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.3083
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7626s / 21259.0012 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.2042
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3580s / 21313.3592 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2326
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9189s / 21368.2781 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.1616
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6925s / 21423.9706 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.2594
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5970s / 21478.5677 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4014
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3102s / 21533.8779 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4614
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.6123s / 21589.4902 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4592
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4063s / 21644.8964 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4233
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0437s / 21699.9401 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4088
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8244s / 21754.7646 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4078
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2097s / 21808.9743 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.3671
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1688s / 21864.1430 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4167
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.8246s / 21917.9676 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.3993
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7818s / 21972.7494 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.3358
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4914s / 22028.2407 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.4249
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4557s / 22082.6965 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.3958
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6922s / 22137.3886 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.2424
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8730s / 22192.2616 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1600
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8830s / 22247.1447 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.2587
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.7263s / 22302.8710 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.3500
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6185s / 22357.4896 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4204
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3630s / 22411.8525 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4324
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1043s / 22466.9568 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4394
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9490s / 22521.9058 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4289
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6245s / 22576.5303 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4746
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7932s / 22631.3236 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.3905
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7858s / 22686.1094 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4303
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4820s / 22740.5913 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.2073
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7299s / 22795.3212 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.2196
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8698s / 22850.1910 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2780
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0586s / 22905.2496 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.4319
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5195s / 22959.7691 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4516
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6844s / 23014.4535 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4147
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2280s / 23069.6815 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.3341
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7967s / 23124.4782 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.3213
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8396s / 23179.3177 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.3749
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9475s / 23234.2653 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4019
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9054s / 23289.1707 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.3788
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2518s / 23344.4225 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.1418
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1326s / 23399.5551 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.1211
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8737s / 23454.4288 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.2786
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7527s / 23509.1815 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.3965
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4293s / 23563.6107 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3992
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9716s / 23618.5823 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2762
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5263s / 23673.1086 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.2695
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2478s / 23728.3564 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3701
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7671s / 23783.1234 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.3450
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7940s / 23837.9175 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2306
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3031s / 23892.2206 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2804
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2451s / 23947.4657 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.0215
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5396s / 24002.0052 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.1906
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2621s / 24056.2673 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.0154
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0974s / 24111.3647 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.1162
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2431s / 24166.6079 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.2338
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8180s / 24221.4259 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.1590
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8769s / 24276.3028 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2022
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5551s / 24330.8579 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.2803
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7841s / 24385.6420 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.1775
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2248s / 24440.8668 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.2664
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6188s / 24495.4857 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.3243
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9547s / 24550.4403 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.1768
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4642s / 24604.9046 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.2003
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4354s / 24660.3400 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3153
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 56.0323s / 24716.3723 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.3974
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1205s / 24771.4928 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.3852
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1697s / 24826.6625 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.1145
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.8661s / 24882.5286 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.2065
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2991s / 24937.8277 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.1373
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6475s / 24992.4752 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.1015
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7010s / 25047.1763 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.3625
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0595s / 25102.2357 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2972
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2736s / 25157.5094 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4025
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6210s / 25212.1303 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2959
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6856s / 25266.8160 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.3163
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7426s / 25321.5585 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.3561
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1414s / 25376.6999 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.3542
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.2555s / 25430.9555 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.3772
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5624s / 25486.5179 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.3622
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 53.6888s / 25540.2067 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.3199
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6283s / 25594.8350 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.3491
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3640s / 25650.1990 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.2547
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5226s / 25705.7216 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.2590
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2023s / 25760.9240 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.3042
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.1469s / 25815.0708 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2789
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0188s / 25870.0896 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.2363
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.9213s / 25926.0109 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.3868
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7260s / 25980.7369 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2797
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.5293s / 26036.2662 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.2654
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.4633s / 26090.7295 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0634
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8788s / 26145.6083 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.2149
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2828s / 26200.8911 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0982
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7093s / 26255.6004 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.1479
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6703s / 26310.2708 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2809
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5241s / 26364.7949 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.0149
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3639s / 26420.1588 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.1270
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1391s / 26475.2979 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.0436
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3174s / 26530.6153 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0410
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1549s / 26585.7702 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0680
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9945s / 26640.7647 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0216
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9542s / 26695.7189 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.0854
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7679s / 26750.4868 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0996
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.3977s / 26804.8845 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.3085
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.7282s / 26859.6126 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.3416
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9352s / 26914.5478 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3677
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.0756s / 26969.6234 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.3914
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.1673s / 27024.7907 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.3269
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.6429s / 27079.4336 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.3424
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.4791s / 27134.9127 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.3640
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.8306s / 27189.7433 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.3440
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.5050s / 27244.2482 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.2314
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.3119s / 27299.5601 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1030
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 55.2098s / 27354.7699 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0868
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.1000s / 27408.8700 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.2681
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 54.9997s / 27463.8697 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.1600
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
