2022-05-10 13:22:14.411588: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 13:22:14.411657: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 13:22:14.411663: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fdccf5afba8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510123946/mdp_arbitrary_mdp_selfplay2/6000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510123946/mdp_arbitrary_mdp_selfplay2/6000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510123946_exploit_6000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510123946_exploit_6000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8155s / 0.8155 s
agent0:                 episode reward: -0.0083,                 loss: nan
agent1:                 episode reward: 0.0083,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0769s / 0.8924 s
agent0:                 episode reward: 1.0925,                 loss: nan
agent1:                 episode reward: -1.0925,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0773s / 0.9697 s
agent0:                 episode reward: 0.5952,                 loss: nan
agent1:                 episode reward: -0.5952,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0861s / 1.0557 s
agent0:                 episode reward: -0.1303,                 loss: nan
agent1:                 episode reward: 0.1303,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6180s / 1.6738 s
agent0:                 episode reward: 0.5611,                 loss: nan
agent1:                 episode reward: -0.5611,                 loss: 0.4414
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7597s / 2.4334 s
agent0:                 episode reward: 0.1375,                 loss: nan
agent1:                 episode reward: -0.1375,                 loss: 0.4351
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7294s / 3.1628 s
agent0:                 episode reward: 0.2327,                 loss: nan
agent1:                 episode reward: -0.2327,                 loss: 0.4337
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7207s / 3.8835 s
agent0:                 episode reward: 0.0183,                 loss: nan
agent1:                 episode reward: -0.0183,                 loss: 0.4311
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7289s / 4.6124 s
agent0:                 episode reward: 0.3173,                 loss: nan
agent1:                 episode reward: -0.3173,                 loss: 0.4282
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7318s / 5.3442 s
agent0:                 episode reward: 0.4148,                 loss: nan
agent1:                 episode reward: -0.4148,                 loss: 0.4350
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7409s / 6.0851 s
agent0:                 episode reward: 1.3518,                 loss: nan
agent1:                 episode reward: -1.3518,                 loss: 0.4350
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7582s / 6.8434 s
agent0:                 episode reward: 0.5436,                 loss: nan
agent1:                 episode reward: -0.5436,                 loss: 0.4327
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7534s / 7.5968 s
agent0:                 episode reward: 1.1740,                 loss: nan
agent1:                 episode reward: -1.1740,                 loss: 0.4315
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7573s / 8.3541 s
agent0:                 episode reward: 0.0516,                 loss: nan
agent1:                 episode reward: -0.0516,                 loss: 0.4297
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7539s / 9.1080 s
agent0:                 episode reward: 0.0587,                 loss: nan
agent1:                 episode reward: -0.0587,                 loss: 0.4205
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7439s / 9.8519 s
agent0:                 episode reward: 0.3826,                 loss: nan
agent1:                 episode reward: -0.3826,                 loss: 0.4149
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7572s / 10.6090 s
agent0:                 episode reward: 0.0079,                 loss: nan
agent1:                 episode reward: -0.0079,                 loss: 0.4108
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7517s / 11.3608 s
agent0:                 episode reward: 0.9094,                 loss: nan
agent1:                 episode reward: -0.9094,                 loss: 0.4090
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7759s / 12.1367 s
agent0:                 episode reward: -0.4227,                 loss: nan
agent1:                 episode reward: 0.4227,                 loss: 0.4081
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8201s / 12.9568 s
agent0:                 episode reward: 0.0918,                 loss: nan
agent1:                 episode reward: -0.0918,                 loss: 0.4020
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7691s / 13.7258 s
agent0:                 episode reward: 0.4490,                 loss: nan
agent1:                 episode reward: -0.4490,                 loss: 0.3989
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7678s / 14.4936 s
agent0:                 episode reward: 0.9047,                 loss: nan
agent1:                 episode reward: -0.9047,                 loss: 0.3973
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7793s / 15.2729 s
agent0:                 episode reward: 0.2922,                 loss: nan
agent1:                 episode reward: -0.2922,                 loss: 0.3957
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7881s / 16.0610 s
agent0:                 episode reward: -0.1269,                 loss: nan
agent1:                 episode reward: 0.1269,                 loss: 0.3935
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7855s / 16.8465 s
agent0:                 episode reward: 0.8963,                 loss: nan
agent1:                 episode reward: -0.8963,                 loss: 0.3848
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7803s / 17.6268 s
agent0:                 episode reward: 0.0441,                 loss: nan
agent1:                 episode reward: -0.0441,                 loss: 0.3836
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8369s / 18.4637 s
agent0:                 episode reward: 0.0866,                 loss: nan
agent1:                 episode reward: -0.0866,                 loss: 0.3814
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7938s / 19.2576 s
agent0:                 episode reward: 0.1788,                 loss: nan
agent1:                 episode reward: -0.1788,                 loss: 0.3821
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7894s / 20.0469 s
agent0:                 episode reward: 0.8021,                 loss: nan
agent1:                 episode reward: -0.8021,                 loss: 0.3802
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8007s / 20.8476 s
agent0:                 episode reward: -0.0521,                 loss: nan
agent1:                 episode reward: 0.0521,                 loss: 0.3729
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8020s / 21.6496 s
agent0:                 episode reward: -0.0327,                 loss: nan
agent1:                 episode reward: 0.0327,                 loss: 0.3727
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8255s / 22.4751 s
agent0:                 episode reward: 0.9113,                 loss: nan
agent1:                 episode reward: -0.9113,                 loss: 0.3732
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8230s / 23.2982 s
agent0:                 episode reward: 0.8900,                 loss: nan
agent1:                 episode reward: -0.8900,                 loss: 0.3715
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8249s / 24.1231 s
agent0:                 episode reward: 0.1795,                 loss: nan
agent1:                 episode reward: -0.1795,                 loss: 0.3701
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8060s / 24.9291 s
agent0:                 episode reward: 0.5912,                 loss: nan
agent1:                 episode reward: -0.5912,                 loss: 0.3617
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8227s / 25.7518 s
agent0:                 episode reward: 0.2262,                 loss: nan
agent1:                 episode reward: -0.2262,                 loss: 0.3602
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8125s / 26.5643 s
agent0:                 episode reward: 0.4956,                 loss: nan
agent1:                 episode reward: -0.4956,                 loss: 0.3582
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8297s / 27.3940 s
agent0:                 episode reward: -0.4011,                 loss: nan
agent1:                 episode reward: 0.4011,                 loss: 0.3601
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8176s / 28.2116 s
agent0:                 episode reward: -0.0607,                 loss: nan
agent1:                 episode reward: 0.0607,                 loss: 0.3593
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8256s / 29.0372 s
agent0:                 episode reward: 0.4166,                 loss: nan
agent1:                 episode reward: -0.4166,                 loss: 0.3539
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8516s / 29.8888 s
agent0:                 episode reward: 0.0153,                 loss: nan
agent1:                 episode reward: -0.0153,                 loss: 0.3510
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8620s / 30.7507 s
agent0:                 episode reward: 0.6632,                 loss: nan
agent1:                 episode reward: -0.6632,                 loss: 0.3514
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8488s / 31.5995 s
agent0:                 episode reward: 0.5640,                 loss: nan
agent1:                 episode reward: -0.5640,                 loss: 0.3517
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8634s / 32.4630 s
agent0:                 episode reward: 0.9054,                 loss: nan
agent1:                 episode reward: -0.9054,                 loss: 0.3503
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9207s / 33.3837 s
agent0:                 episode reward: 0.4052,                 loss: nan
agent1:                 episode reward: -0.4052,                 loss: 0.3528
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8572s / 34.2409 s
agent0:                 episode reward: 0.6980,                 loss: nan
agent1:                 episode reward: -0.6980,                 loss: 0.3529
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8582s / 35.0991 s
agent0:                 episode reward: 0.0159,                 loss: nan
agent1:                 episode reward: -0.0159,                 loss: 0.3507
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8598s / 35.9589 s
agent0:                 episode reward: 0.2765,                 loss: nan
agent1:                 episode reward: -0.2765,                 loss: 0.3505
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8582s / 36.8171 s
agent0:                 episode reward: 0.1044,                 loss: nan
agent1:                 episode reward: -0.1044,                 loss: 0.3501
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8586s / 37.6757 s
agent0:                 episode reward: 0.3249,                 loss: nan
agent1:                 episode reward: -0.3249,                 loss: 0.3451
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8730s / 38.5487 s
agent0:                 episode reward: 0.4873,                 loss: nan
agent1:                 episode reward: -0.4873,                 loss: 0.3434
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9099s / 39.4586 s
agent0:                 episode reward: 0.5552,                 loss: nan
agent1:                 episode reward: -0.5552,                 loss: 0.3422
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9050s / 40.3635 s
agent0:                 episode reward: 0.3904,                 loss: nan
agent1:                 episode reward: -0.3904,                 loss: 0.3402
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9007s / 41.2642 s
agent0:                 episode reward: -0.0881,                 loss: nan
agent1:                 episode reward: 0.0881,                 loss: 0.3422
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8777s / 42.1419 s
agent0:                 episode reward: 0.7707,                 loss: nan
agent1:                 episode reward: -0.7707,                 loss: 0.3363
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9315s / 43.0734 s
agent0:                 episode reward: 0.3357,                 loss: nan
agent1:                 episode reward: -0.3357,                 loss: 0.3353
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8851s / 43.9584 s
agent0:                 episode reward: 1.0647,                 loss: nan
agent1:                 episode reward: -1.0647,                 loss: 0.3362
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8721s / 44.8305 s
agent0:                 episode reward: 0.5161,                 loss: nan
agent1:                 episode reward: -0.5161,                 loss: 0.3359
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8949s / 45.7254 s
agent0:                 episode reward: -0.5482,                 loss: nan
agent1:                 episode reward: 0.5482,                 loss: 0.3348
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8815s / 46.6070 s
agent0:                 episode reward: 0.4219,                 loss: nan
agent1:                 episode reward: -0.4219,                 loss: 0.3349
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8938s / 47.5008 s
agent0:                 episode reward: 0.3300,                 loss: nan
agent1:                 episode reward: -0.3300,                 loss: 0.3325
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8911s / 48.3918 s
agent0:                 episode reward: 0.7109,                 loss: nan
agent1:                 episode reward: -0.7109,                 loss: 0.3334
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9164s / 49.3082 s
agent0:                 episode reward: 0.2127,                 loss: nan
agent1:                 episode reward: -0.2127,                 loss: 0.3328
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9083s / 50.2165 s
agent0:                 episode reward: 0.4804,                 loss: nan
agent1:                 episode reward: -0.4804,                 loss: 0.3336
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9102s / 51.1267 s
agent0:                 episode reward: 1.1398,                 loss: nan
agent1:                 episode reward: -1.1398,                 loss: 0.3378
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8925s / 52.0192 s
agent0:                 episode reward: 0.1280,                 loss: nan
agent1:                 episode reward: -0.1280,                 loss: 0.3393
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8983s / 52.9175 s
agent0:                 episode reward: 0.5729,                 loss: nan
agent1:                 episode reward: -0.5729,                 loss: 0.3378
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9458s / 53.8633 s
agent0:                 episode reward: 0.3904,                 loss: nan
agent1:                 episode reward: -0.3904,                 loss: 0.3378
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9311s / 54.7944 s
agent0:                 episode reward: 0.8242,                 loss: nan
agent1:                 episode reward: -0.8242,                 loss: 0.3393
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9057s / 55.7002 s
agent0:                 episode reward: -0.1375,                 loss: nan
agent1:                 episode reward: 0.1375,                 loss: 0.3390
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9229s / 56.6231 s
agent0:                 episode reward: 0.4899,                 loss: nan
agent1:                 episode reward: -0.4899,                 loss: 0.3386
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9679s / 57.5909 s
agent0:                 episode reward: -0.1097,                 loss: nan
agent1:                 episode reward: 0.1097,                 loss: 0.3384
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9073s / 58.4983 s
agent0:                 episode reward: 0.7579,                 loss: nan
agent1:                 episode reward: -0.7579,                 loss: 0.3393
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9172s / 59.4155 s
agent0:                 episode reward: -0.3159,                 loss: nan
agent1:                 episode reward: 0.3159,                 loss: 0.3391
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9315s / 60.3470 s
agent0:                 episode reward: 0.0362,                 loss: nan
agent1:                 episode reward: -0.0362,                 loss: 0.3454
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9322s / 61.2792 s
agent0:                 episode reward: -0.0824,                 loss: nan
agent1:                 episode reward: 0.0824,                 loss: 0.3470
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9169s / 62.1961 s
agent0:                 episode reward: 0.1102,                 loss: nan
agent1:                 episode reward: -0.1102,                 loss: 0.3484
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9358s / 63.1319 s
agent0:                 episode reward: 0.3402,                 loss: nan
agent1:                 episode reward: -0.3402,                 loss: 0.3478
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0028s / 64.1347 s
agent0:                 episode reward: -0.1849,                 loss: nan
agent1:                 episode reward: 0.1849,                 loss: 0.3473
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9334s / 65.0681 s
agent0:                 episode reward: 0.3383,                 loss: nan
agent1:                 episode reward: -0.3383,                 loss: 0.3525
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9572s / 66.0253 s
agent0:                 episode reward: 0.2225,                 loss: nan
agent1:                 episode reward: -0.2225,                 loss: 0.3558
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9460s / 66.9713 s
agent0:                 episode reward: 0.3222,                 loss: nan
agent1:                 episode reward: -0.3222,                 loss: 0.3545
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9453s / 67.9166 s
agent0:                 episode reward: -0.0264,                 loss: nan
agent1:                 episode reward: 0.0264,                 loss: 0.3533
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9420s / 68.8586 s
agent0:                 episode reward: 0.4243,                 loss: nan
agent1:                 episode reward: -0.4243,                 loss: 0.3543
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9520s / 69.8106 s
agent0:                 episode reward: 0.4292,                 loss: nan
agent1:                 episode reward: -0.4292,                 loss: 0.3558
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9582s / 70.7688 s
agent0:                 episode reward: 0.3655,                 loss: nan
agent1:                 episode reward: -0.3655,                 loss: 0.3581
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9526s / 71.7214 s
agent0:                 episode reward: -0.1116,                 loss: nan
agent1:                 episode reward: 0.1116,                 loss: 0.3571
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9563s / 72.6777 s
agent0:                 episode reward: 0.4408,                 loss: nan
agent1:                 episode reward: -0.4408,                 loss: 0.3557
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9876s / 73.6653 s
agent0:                 episode reward: -0.5745,                 loss: nan
agent1:                 episode reward: 0.5745,                 loss: 0.3564
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9773s / 74.6426 s
agent0:                 episode reward: -0.3768,                 loss: nan
agent1:                 episode reward: 0.3768,                 loss: 0.3547
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9721s / 75.6148 s
agent0:                 episode reward: 0.7040,                 loss: nan
agent1:                 episode reward: -0.7040,                 loss: 0.3556
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9768s / 76.5915 s
agent0:                 episode reward: 0.2575,                 loss: nan
agent1:                 episode reward: -0.2575,                 loss: 0.3545
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9706s / 77.5621 s
agent0:                 episode reward: 0.1826,                 loss: nan
agent1:                 episode reward: -0.1826,                 loss: 0.3533
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9801s / 78.5422 s
agent0:                 episode reward: 0.2534,                 loss: nan
agent1:                 episode reward: -0.2534,                 loss: 0.3531
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9820s / 79.5242 s
agent0:                 episode reward: -0.5540,                 loss: nan
agent1:                 episode reward: 0.5540,                 loss: 0.3485
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9823s / 80.5064 s
agent0:                 episode reward: 0.5343,                 loss: nan
agent1:                 episode reward: -0.5343,                 loss: 0.3454
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0183s / 81.5247 s
agent0:                 episode reward: -0.2145,                 loss: nan
agent1:                 episode reward: 0.2145,                 loss: 0.3460
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0222s / 82.5470 s
agent0:                 episode reward: 0.7829,                 loss: nan
agent1:                 episode reward: -0.7829,                 loss: 0.3451
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9912s / 83.5381 s
agent0:                 episode reward: -0.2869,                 loss: nan
agent1:                 episode reward: 0.2869,                 loss: 0.3442
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0549s / 84.5931 s
agent0:                 episode reward: 0.7718,                 loss: nan
agent1:                 episode reward: -0.7718,                 loss: 0.3348
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0023s / 85.5954 s
agent0:                 episode reward: 0.5377,                 loss: nan
agent1:                 episode reward: -0.5377,                 loss: 0.3340
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0012s / 86.5966 s
agent0:                 episode reward: -0.0756,                 loss: nan
agent1:                 episode reward: 0.0756,                 loss: 0.3337
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9997s / 87.5963 s
agent0:                 episode reward: 0.5448,                 loss: nan
agent1:                 episode reward: -0.5448,                 loss: 0.3318
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9875s / 88.5838 s
agent0:                 episode reward: 1.0927,                 loss: nan
agent1:                 episode reward: -1.0927,                 loss: 0.3329
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0787s / 89.6625 s
agent0:                 episode reward: 0.2168,                 loss: nan
agent1:                 episode reward: -0.2168,                 loss: 0.3250
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0509s / 90.7134 s
agent0:                 episode reward: -0.1163,                 loss: nan
agent1:                 episode reward: 0.1163,                 loss: 0.3236
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0357s / 91.7491 s
agent0:                 episode reward: 0.4319,                 loss: nan
agent1:                 episode reward: -0.4319,                 loss: 0.3220
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0171s / 92.7662 s
agent0:                 episode reward: 0.8546,                 loss: nan
agent1:                 episode reward: -0.8546,                 loss: 0.3220
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0243s / 93.7905 s
agent0:                 episode reward: 0.5340,                 loss: nan
agent1:                 episode reward: -0.5340,                 loss: 0.3221
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1039s / 94.8944 s
agent0:                 episode reward: 0.3637,                 loss: nan
agent1:                 episode reward: -0.3637,                 loss: 0.3235
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0235s / 95.9179 s
agent0:                 episode reward: -0.4640,                 loss: nan
agent1:                 episode reward: 0.4640,                 loss: 0.3251
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0762s / 96.9941 s
agent0:                 episode reward: 0.6568,                 loss: nan
agent1:                 episode reward: -0.6568,                 loss: 0.3240
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0167s / 98.0108 s
agent0:                 episode reward: 1.2056,                 loss: nan
agent1:                 episode reward: -1.2056,                 loss: 0.3228
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0783s / 99.0891 s
agent0:                 episode reward: -0.1739,                 loss: nan
agent1:                 episode reward: 0.1739,                 loss: 0.3216
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0307s / 100.1198 s
agent0:                 episode reward: 0.5083,                 loss: nan
agent1:                 episode reward: -0.5083,                 loss: 0.3245
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0639s / 101.1837 s
agent0:                 episode reward: -0.8629,                 loss: nan
agent1:                 episode reward: 0.8629,                 loss: 0.3227
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0296s / 102.2133 s
agent0:                 episode reward: 0.1404,                 loss: nan
agent1:                 episode reward: -0.1404,                 loss: 0.3230
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0158s / 103.2291 s
agent0:                 episode reward: 1.0365,                 loss: nan
agent1:                 episode reward: -1.0365,                 loss: 0.3217
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0154s / 104.2446 s
agent0:                 episode reward: -1.0578,                 loss: nan
agent1:                 episode reward: 1.0578,                 loss: 0.3212
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0811s / 105.3257 s
agent0:                 episode reward: 0.0168,                 loss: nan
agent1:                 episode reward: -0.0168,                 loss: 0.3301
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0059s / 106.3315 s
agent0:                 episode reward: 0.2584,                 loss: nan
agent1:                 episode reward: -0.2584,                 loss: 0.3311
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0665s / 107.3981 s
agent0:                 episode reward: 0.9616,                 loss: nan
agent1:                 episode reward: -0.9616,                 loss: 0.3297
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0194s / 108.4175 s
agent0:                 episode reward: -0.2954,                 loss: nan
agent1:                 episode reward: 0.2954,                 loss: 0.3314
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0201s / 109.4376 s
agent0:                 episode reward: -0.0951,                 loss: nan
agent1:                 episode reward: 0.0951,                 loss: 0.3282
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0237s / 110.4613 s
agent0:                 episode reward: 0.5276,                 loss: nan
agent1:                 episode reward: -0.5276,                 loss: 0.3356
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0395s / 111.5008 s
agent0:                 episode reward: 1.2363,                 loss: nan
agent1:                 episode reward: -1.2363,                 loss: 0.3350
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0204s / 112.5212 s
agent0:                 episode reward: 0.4111,                 loss: nan
agent1:                 episode reward: -0.4111,                 loss: 0.3340
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0073s / 113.5285 s
agent0:                 episode reward: -0.0003,                 loss: nan
agent1:                 episode reward: 0.0003,                 loss: 0.3320
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0495s / 114.5780 s
agent0:                 episode reward: -0.5037,                 loss: nan
agent1:                 episode reward: 0.5037,                 loss: 0.3338
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0716s / 115.6496 s
agent0:                 episode reward: 0.3934,                 loss: nan
agent1:                 episode reward: -0.3934,                 loss: 0.3453
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0763s / 116.7259 s
agent0:                 episode reward: 0.7122,                 loss: nan
agent1:                 episode reward: -0.7122,                 loss: 0.3454
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0536s / 117.7795 s
agent0:                 episode reward: -0.3998,                 loss: nan
agent1:                 episode reward: 0.3998,                 loss: 0.3451
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0392s / 118.8187 s
agent0:                 episode reward: -0.5111,                 loss: nan
agent1:                 episode reward: 0.5111,                 loss: 0.3467
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0926s / 119.9113 s
agent0:                 episode reward: 0.8003,                 loss: nan
agent1:                 episode reward: -0.8003,                 loss: 0.3440
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0600s / 120.9713 s
agent0:                 episode reward: 0.4966,                 loss: nan
agent1:                 episode reward: -0.4966,                 loss: 0.3567
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0538s / 122.0251 s
agent0:                 episode reward: 0.3070,                 loss: nan
agent1:                 episode reward: -0.3070,                 loss: 0.3600
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0559s / 123.0811 s
agent0:                 episode reward: 0.1042,                 loss: nan
agent1:                 episode reward: -0.1042,                 loss: 0.3588
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0709s / 124.1520 s
agent0:                 episode reward: 0.6856,                 loss: nan
agent1:                 episode reward: -0.6856,                 loss: 0.3593
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1006s / 125.2526 s
agent0:                 episode reward: -0.4798,                 loss: nan
agent1:                 episode reward: 0.4798,                 loss: 0.3581
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0644s / 126.3170 s
agent0:                 episode reward: 0.3341,                 loss: nan
agent1:                 episode reward: -0.3341,                 loss: 0.3615
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0640s / 127.3810 s
agent0:                 episode reward: 0.0351,                 loss: nan
agent1:                 episode reward: -0.0351,                 loss: 0.3621
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0548s / 128.4358 s
agent0:                 episode reward: 0.5579,                 loss: nan
agent1:                 episode reward: -0.5579,                 loss: 0.3605
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0732s / 129.5090 s
agent0:                 episode reward: 0.3230,                 loss: nan
agent1:                 episode reward: -0.3230,                 loss: 0.3612
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0727s / 130.5817 s
agent0:                 episode reward: 0.3733,                 loss: nan
agent1:                 episode reward: -0.3733,                 loss: 0.3604
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0972s / 131.6789 s
agent0:                 episode reward: 0.2025,                 loss: nan
agent1:                 episode reward: -0.2025,                 loss: 0.3614
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0796s / 132.7585 s
agent0:                 episode reward: 0.1960,                 loss: nan
agent1:                 episode reward: -0.1960,                 loss: 0.3603
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0952s / 133.8537 s
agent0:                 episode reward: -0.0121,                 loss: nan
agent1:                 episode reward: 0.0121,                 loss: 0.3597
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1201s / 134.9739 s
agent0:                 episode reward: -0.1491,                 loss: nan
agent1:                 episode reward: 0.1491,                 loss: 0.3606
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1495s / 136.1233 s
agent0:                 episode reward: 0.5203,                 loss: nan
agent1:                 episode reward: -0.5203,                 loss: 0.3599
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1008s / 137.2241 s
agent0:                 episode reward: -0.1020,                 loss: nan
agent1:                 episode reward: 0.1020,                 loss: 0.3559
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1236s / 138.3477 s
agent0:                 episode reward: 0.1625,                 loss: nan
agent1:                 episode reward: -0.1625,                 loss: 0.3557
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1021s / 139.4497 s
agent0:                 episode reward: 0.7444,                 loss: nan
agent1:                 episode reward: -0.7444,                 loss: 0.3534
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1146s / 140.5644 s
agent0:                 episode reward: 0.5067,                 loss: nan
agent1:                 episode reward: -0.5067,                 loss: 0.3527
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1245s / 141.6889 s
agent0:                 episode reward: 0.5860,                 loss: nan
agent1:                 episode reward: -0.5860,                 loss: 0.3515
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1089s / 142.7977 s
agent0:                 episode reward: 0.6509,                 loss: nan
agent1:                 episode reward: -0.6509,                 loss: 0.3417
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1092s / 143.9069 s
agent0:                 episode reward: 0.0003,                 loss: nan
agent1:                 episode reward: -0.0003,                 loss: 0.3401
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1082s / 145.0151 s
agent0:                 episode reward: -0.0492,                 loss: nan
agent1:                 episode reward: 0.0492,                 loss: 0.3379
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1795s / 146.1946 s
agent0:                 episode reward: 0.9649,                 loss: nan
agent1:                 episode reward: -0.9649,                 loss: 0.3377
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1312s / 147.3259 s
agent0:                 episode reward: -0.9292,                 loss: nan
agent1:                 episode reward: 0.9292,                 loss: 0.3389
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1430s / 148.4689 s
agent0:                 episode reward: 0.3860,                 loss: nan
agent1:                 episode reward: -0.3860,                 loss: 0.3246
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1410s / 149.6099 s
agent0:                 episode reward: -0.0437,                 loss: nan
agent1:                 episode reward: 0.0437,                 loss: 0.3207
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1345s / 150.7444 s
agent0:                 episode reward: 0.6298,                 loss: nan
agent1:                 episode reward: -0.6298,                 loss: 0.3203
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1564s / 151.9008 s
agent0:                 episode reward: 0.6986,                 loss: nan
agent1:                 episode reward: -0.6986,                 loss: 0.3206
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1401s / 153.0409 s
agent0:                 episode reward: -0.1330,                 loss: nan
agent1:                 episode reward: 0.1330,                 loss: 0.3192
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1933s / 154.2342 s
agent0:                 episode reward: -0.2997,                 loss: nan
agent1:                 episode reward: 0.2997,                 loss: 0.3109
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1446s / 155.3788 s
agent0:                 episode reward: -0.1002,                 loss: nan
agent1:                 episode reward: 0.1002,                 loss: 0.3093
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2237s / 156.6025 s
agent0:                 episode reward: 0.4426,                 loss: nan
agent1:                 episode reward: -0.4426,                 loss: 0.3083
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1437s / 157.7462 s
agent0:                 episode reward: 0.4832,                 loss: nan
agent1:                 episode reward: -0.4832,                 loss: 0.3090
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1413s / 158.8874 s
agent0:                 episode reward: 0.5963,                 loss: nan
agent1:                 episode reward: -0.5963,                 loss: 0.3070
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1423s / 160.0297 s
agent0:                 episode reward: 0.5009,                 loss: nan
agent1:                 episode reward: -0.5009,                 loss: 0.3033
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1531s / 161.1828 s
agent0:                 episode reward: 0.4165,                 loss: nan
agent1:                 episode reward: -0.4165,                 loss: 0.3028
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1693s / 162.3520 s
agent0:                 episode reward: 0.6387,                 loss: nan
agent1:                 episode reward: -0.6387,                 loss: 0.3024
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1513s / 163.5034 s
agent0:                 episode reward: -0.3441,                 loss: nan
agent1:                 episode reward: 0.3441,                 loss: 0.3001
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1795s / 164.6828 s
agent0:                 episode reward: 0.2255,                 loss: nan
agent1:                 episode reward: -0.2255,                 loss: 0.3011
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2159s / 165.8987 s
agent0:                 episode reward: -0.2212,                 loss: nan
agent1:                 episode reward: 0.2212,                 loss: 0.3000
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1774s / 167.0762 s
agent0:                 episode reward: 0.0347,                 loss: nan
agent1:                 episode reward: -0.0347,                 loss: 0.2979
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2006s / 168.2768 s
agent0:                 episode reward: -0.3335,                 loss: nan
agent1:                 episode reward: 0.3335,                 loss: 0.2965
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1793s / 169.4561 s
agent0:                 episode reward: -0.3566,                 loss: nan
agent1:                 episode reward: 0.3566,                 loss: 0.2968
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1750s / 170.6311 s
agent0:                 episode reward: 0.0838,                 loss: nan
agent1:                 episode reward: -0.0838,                 loss: 0.2966
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1803s / 171.8114 s
agent0:                 episode reward: 0.5152,                 loss: nan
agent1:                 episode reward: -0.5152,                 loss: 0.3067
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1790s / 172.9904 s
agent0:                 episode reward: -0.0627,                 loss: nan
agent1:                 episode reward: 0.0627,                 loss: 0.3076
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2021s / 174.1925 s
agent0:                 episode reward: 0.4234,                 loss: nan
agent1:                 episode reward: -0.4234,                 loss: 0.3074
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1907s / 175.3832 s
agent0:                 episode reward: 0.4114,                 loss: nan
agent1:                 episode reward: -0.4114,                 loss: 0.3076
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2284s / 176.6117 s
agent0:                 episode reward: -0.4033,                 loss: nan
agent1:                 episode reward: 0.4033,                 loss: 0.3076
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1893s / 177.8010 s
agent0:                 episode reward: -0.4741,                 loss: nan
agent1:                 episode reward: 0.4741,                 loss: 0.3281
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1768s / 178.9778 s
agent0:                 episode reward: 0.8882,                 loss: nan
agent1:                 episode reward: -0.8882,                 loss: 0.3304
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2020s / 180.1798 s
agent0:                 episode reward: -0.0658,                 loss: nan
agent1:                 episode reward: 0.0658,                 loss: 0.3274
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1969s / 181.3767 s
agent0:                 episode reward: 0.0817,                 loss: nan
agent1:                 episode reward: -0.0817,                 loss: 0.3279
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2269s / 182.6037 s
agent0:                 episode reward: 0.1708,                 loss: nan
agent1:                 episode reward: -0.1708,                 loss: 0.3268
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2121s / 183.8158 s
agent0:                 episode reward: 0.1494,                 loss: nan
agent1:                 episode reward: -0.1494,                 loss: 0.3508
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2120s / 185.0278 s
agent0:                 episode reward: -0.1286,                 loss: nan
agent1:                 episode reward: 0.1286,                 loss: 0.3547
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2428s / 186.2705 s
agent0:                 episode reward: 0.0227,                 loss: nan
agent1:                 episode reward: -0.0227,                 loss: 0.3535
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2112s / 187.4817 s
agent0:                 episode reward: 0.1192,                 loss: nan
agent1:                 episode reward: -0.1192,                 loss: 0.3534
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2172s / 188.6989 s
agent0:                 episode reward: -0.2392,                 loss: nan
agent1:                 episode reward: 0.2392,                 loss: 0.3551
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2232s / 189.9222 s
agent0:                 episode reward: -0.2252,                 loss: nan
agent1:                 episode reward: 0.2252,                 loss: 0.3689
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2223s / 191.1445 s
agent0:                 episode reward: 0.6482,                 loss: nan
agent1:                 episode reward: -0.6482,                 loss: 0.3666
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2365s / 192.3810 s
agent0:                 episode reward: 0.1704,                 loss: nan
agent1:                 episode reward: -0.1704,                 loss: 0.3646
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2301s / 193.6111 s
agent0:                 episode reward: 0.4907,                 loss: nan
agent1:                 episode reward: -0.4907,                 loss: 0.3620
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2286s / 194.8397 s
agent0:                 episode reward: 0.2663,                 loss: nan
agent1:                 episode reward: -0.2663,                 loss: 0.3615
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2178s / 196.0575 s
agent0:                 episode reward: -0.1184,                 loss: nan
agent1:                 episode reward: 0.1184,                 loss: 0.3351
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2749s / 197.3324 s
agent0:                 episode reward: 0.5951,                 loss: nan
agent1:                 episode reward: -0.5951,                 loss: 0.3221
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2593s / 198.5917 s
agent0:                 episode reward: 0.7564,                 loss: nan
agent1:                 episode reward: -0.7564,                 loss: 0.3243
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2340s / 199.8257 s
agent0:                 episode reward: -0.1093,                 loss: nan
agent1:                 episode reward: 0.1093,                 loss: 0.3233
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2514s / 201.0771 s
agent0:                 episode reward: -0.0462,                 loss: nan
agent1:                 episode reward: 0.0462,                 loss: 0.3227
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2629s / 202.3400 s
agent0:                 episode reward: -0.6987,                 loss: nan
agent1:                 episode reward: 0.6987,                 loss: 0.2873
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2573s / 203.5972 s
agent0:                 episode reward: 0.4027,                 loss: nan
agent1:                 episode reward: -0.4027,                 loss: 0.2750
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2487s / 204.8459 s
agent0:                 episode reward: -0.1582,                 loss: nan
agent1:                 episode reward: 0.1582,                 loss: 0.2743
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2372s / 206.0831 s
agent0:                 episode reward: 0.6791,                 loss: nan
agent1:                 episode reward: -0.6791,                 loss: 0.2731
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3136s / 207.3967 s
agent0:                 episode reward: -0.3671,                 loss: nan
agent1:                 episode reward: 0.3671,                 loss: 0.2745
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2604s / 208.6571 s
agent0:                 episode reward: 0.0363,                 loss: nan
agent1:                 episode reward: -0.0363,                 loss: 0.2588
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2656s / 209.9227 s
agent0:                 episode reward: 0.6402,                 loss: nan
agent1:                 episode reward: -0.6402,                 loss: 0.2510
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2605s / 211.1832 s
agent0:                 episode reward: -0.1663,                 loss: nan
agent1:                 episode reward: 0.1663,                 loss: 0.2429
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2685s / 212.4517 s
agent0:                 episode reward: 0.0244,                 loss: nan
agent1:                 episode reward: -0.0244,                 loss: 0.2376
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2718s / 213.7235 s
agent0:                 episode reward: -0.5181,                 loss: nan
agent1:                 episode reward: 0.5181,                 loss: 0.2378
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2839s / 215.0073 s
agent0:                 episode reward: 0.2241,                 loss: nan
agent1:                 episode reward: -0.2241,                 loss: 0.2380
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2743s / 216.2817 s
agent0:                 episode reward: -0.1123,                 loss: nan
agent1:                 episode reward: 0.1123,                 loss: 0.2300
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3474s / 217.6291 s
agent0:                 episode reward: -0.8832,                 loss: nan
agent1:                 episode reward: 0.8832,                 loss: 0.2302
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2783s / 218.9074 s
agent0:                 episode reward: 0.3424,                 loss: nan
agent1:                 episode reward: -0.3424,                 loss: 0.2276
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2818s / 220.1891 s
agent0:                 episode reward: -0.6016,                 loss: nan
agent1:                 episode reward: 0.6016,                 loss: 0.2287
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2847s / 221.4738 s
agent0:                 episode reward: 0.0916,                 loss: nan
agent1:                 episode reward: -0.0916,                 loss: 0.2413
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2876s / 222.7614 s
agent0:                 episode reward: 0.4268,                 loss: nan
agent1:                 episode reward: -0.4268,                 loss: 0.2359
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3207s / 224.0821 s
agent0:                 episode reward: -0.5318,                 loss: nan
agent1:                 episode reward: 0.5318,                 loss: 0.2363
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2884s / 225.3706 s
agent0:                 episode reward: 0.0096,                 loss: nan
agent1:                 episode reward: -0.0096,                 loss: 0.2337
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2891s / 226.6597 s
agent0:                 episode reward: 0.0996,                 loss: nan
agent1:                 episode reward: -0.0996,                 loss: 0.2350
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3500s / 228.0097 s
agent0:                 episode reward: 0.6121,                 loss: nan
agent1:                 episode reward: -0.6121,                 loss: 0.2516
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3043s / 229.3141 s
agent0:                 episode reward: -0.1011,                 loss: nan
agent1:                 episode reward: 0.1011,                 loss: 0.2525
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3000s / 230.6141 s
agent0:                 episode reward: -0.1019,                 loss: nan
agent1:                 episode reward: 0.1019,                 loss: 0.2499
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3150s / 231.9291 s
agent0:                 episode reward: 0.1406,                 loss: nan
agent1:                 episode reward: -0.1406,                 loss: 0.2504
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3095s / 233.2386 s
agent0:                 episode reward: -0.2418,                 loss: nan
agent1:                 episode reward: 0.2418,                 loss: 0.2493
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3095s / 234.5481 s
agent0:                 episode reward: 0.1164,                 loss: nan
agent1:                 episode reward: -0.1164,                 loss: 0.2755
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3083s / 235.8564 s
agent0:                 episode reward: -0.1926,                 loss: nan
agent1:                 episode reward: 0.1926,                 loss: 0.2752
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3181s / 237.1744 s
agent0:                 episode reward: -0.3414,                 loss: nan
agent1:                 episode reward: 0.3414,                 loss: 0.2751
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3574s / 238.5319 s
agent0:                 episode reward: -0.2146,                 loss: nan
agent1:                 episode reward: 0.2146,                 loss: 0.2743
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3615s / 239.8933 s
agent0:                 episode reward: -0.0901,                 loss: nan
agent1:                 episode reward: 0.0901,                 loss: 0.2750
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3196s / 241.2129 s
agent0:                 episode reward: -0.0639,                 loss: nan
agent1:                 episode reward: 0.0639,                 loss: 0.3180
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3705s / 242.5835 s
agent0:                 episode reward: -0.5122,                 loss: nan
agent1:                 episode reward: 0.5122,                 loss: 0.3264
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3382s / 243.9217 s
agent0:                 episode reward: -0.0192,                 loss: nan
agent1:                 episode reward: 0.0192,                 loss: 0.3267
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3473s / 245.2690 s
agent0:                 episode reward: 0.3271,                 loss: nan
agent1:                 episode reward: -0.3271,                 loss: 0.3241
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3455s / 246.6145 s
agent0:                 episode reward: -0.4593,                 loss: nan
agent1:                 episode reward: 0.4593,                 loss: 0.3261
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3905s / 248.0050 s
agent0:                 episode reward: -0.0421,                 loss: nan
agent1:                 episode reward: 0.0421,                 loss: 0.3559
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3629s / 249.3679 s
agent0:                 episode reward: -0.1949,                 loss: nan
agent1:                 episode reward: 0.1949,                 loss: 0.3590
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3415s / 250.7093 s
agent0:                 episode reward: 0.7951,                 loss: nan
agent1:                 episode reward: -0.7951,                 loss: 0.3588
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3553s / 252.0646 s
agent0:                 episode reward: 0.1579,                 loss: nan
agent1:                 episode reward: -0.1579,                 loss: 0.3587
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3541s / 253.4187 s
agent0:                 episode reward: -0.5005,                 loss: nan
agent1:                 episode reward: 0.5005,                 loss: 0.3579
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3508s / 254.7695 s
agent0:                 episode reward: 0.3493,                 loss: nan
agent1:                 episode reward: -0.3493,                 loss: 0.3572
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3637s / 256.1332 s
agent0:                 episode reward: -0.7260,                 loss: nan
agent1:                 episode reward: 0.7260,                 loss: 0.3535
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3578s / 257.4911 s
agent0:                 episode reward: 0.1645,                 loss: nan
agent1:                 episode reward: -0.1645,                 loss: 0.3523
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3868s / 258.8779 s
agent0:                 episode reward: -0.1525,                 loss: nan
agent1:                 episode reward: 0.1525,                 loss: 0.3521
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3541s / 260.2319 s
agent0:                 episode reward: -0.6791,                 loss: nan
agent1:                 episode reward: 0.6791,                 loss: 0.3524
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3615s / 261.5934 s
agent0:                 episode reward: -0.4089,                 loss: nan
agent1:                 episode reward: 0.4089,                 loss: 0.3048
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3609s / 262.9543 s
agent0:                 episode reward: -1.0086,                 loss: nan
agent1:                 episode reward: 1.0086,                 loss: 0.2922
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3991s / 264.3534 s
agent0:                 episode reward: -0.4085,                 loss: nan
agent1:                 episode reward: 0.4085,                 loss: 0.2922
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3691s / 265.7225 s
agent0:                 episode reward: -0.3995,                 loss: nan
agent1:                 episode reward: 0.3995,                 loss: 0.2939
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3782s / 267.1006 s
agent0:                 episode reward: 0.1097,                 loss: nan
agent1:                 episode reward: -0.1097,                 loss: 0.2915
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4195s / 268.5201 s
agent0:                 episode reward: -0.6642,                 loss: nan
agent1:                 episode reward: 0.6642,                 loss: 0.2660
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3820s / 269.9021 s
agent0:                 episode reward: 0.3208,                 loss: nan
agent1:                 episode reward: -0.3208,                 loss: 0.2592
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3847s / 271.2868 s
agent0:                 episode reward: -0.4423,                 loss: nan
agent1:                 episode reward: 0.4423,                 loss: 0.2595
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4020s / 272.6888 s
agent0:                 episode reward: -0.3109,                 loss: nan
agent1:                 episode reward: 0.3109,                 loss: 0.2575
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3885s / 274.0773 s
agent0:                 episode reward: -1.1003,                 loss: nan
agent1:                 episode reward: 1.1003,                 loss: 0.2585
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3884s / 275.4657 s
agent0:                 episode reward: 0.0533,                 loss: nan
agent1:                 episode reward: -0.0533,                 loss: 0.2519
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4215s / 276.8871 s
agent0:                 episode reward: 0.4680,                 loss: nan
agent1:                 episode reward: -0.4680,                 loss: 0.2471
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3922s / 278.2793 s
agent0:                 episode reward: -0.0580,                 loss: nan
agent1:                 episode reward: 0.0580,                 loss: 0.2456
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4426s / 279.7219 s
agent0:                 episode reward: -0.4878,                 loss: nan
agent1:                 episode reward: 0.4878,                 loss: 0.2433
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4097s / 281.1316 s
agent0:                 episode reward: 0.2798,                 loss: nan
agent1:                 episode reward: -0.2798,                 loss: 0.2453
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4065s / 282.5381 s
agent0:                 episode reward: -0.3071,                 loss: nan
agent1:                 episode reward: 0.3071,                 loss: 0.2500
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4139s / 283.9520 s
agent0:                 episode reward: -0.4015,                 loss: nan
agent1:                 episode reward: 0.4015,                 loss: 0.2425
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4010s / 285.3530 s
agent0:                 episode reward: -0.3393,                 loss: nan
agent1:                 episode reward: 0.3393,                 loss: 0.2427
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4195s / 286.7725 s
agent0:                 episode reward: 0.2451,                 loss: nan
agent1:                 episode reward: -0.2451,                 loss: 0.2420
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4422s / 288.2147 s
agent0:                 episode reward: -0.2235,                 loss: nan
agent1:                 episode reward: 0.2235,                 loss: 0.2417
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4927s / 289.7074 s
agent0:                 episode reward: -0.6290,                 loss: nan
agent1:                 episode reward: 0.6290,                 loss: 0.2459
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4070s / 291.1143 s
agent0:                 episode reward: -0.3981,                 loss: nan
agent1:                 episode reward: 0.3981,                 loss: 0.2411
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4053s / 292.5196 s
agent0:                 episode reward: -0.6075,                 loss: nan
agent1:                 episode reward: 0.6075,                 loss: 0.2407
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4406s / 293.9602 s
agent0:                 episode reward: -0.9432,                 loss: nan
agent1:                 episode reward: 0.9432,                 loss: 0.2405
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4184s / 295.3786 s
agent0:                 episode reward: 0.4756,                 loss: nan
agent1:                 episode reward: -0.4756,                 loss: 0.2395
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4666s / 296.8452 s
agent0:                 episode reward: -0.1188,                 loss: nan
agent1:                 episode reward: 0.1188,                 loss: 0.2431
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4543s / 298.2995 s
agent0:                 episode reward: -0.9028,                 loss: nan
agent1:                 episode reward: 0.9028,                 loss: 0.2370
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4524s / 299.7519 s
agent0:                 episode reward: 0.3007,                 loss: nan
agent1:                 episode reward: -0.3007,                 loss: 0.2365
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4241s / 301.1760 s
agent0:                 episode reward: 0.3243,                 loss: nan
agent1:                 episode reward: -0.3243,                 loss: 0.2381
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4646s / 302.6406 s
agent0:                 episode reward: -0.5158,                 loss: nan
agent1:                 episode reward: 0.5158,                 loss: 0.2354
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4437s / 304.0843 s
agent0:                 episode reward: 0.0053,                 loss: nan
agent1:                 episode reward: -0.0053,                 loss: 0.2677
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4344s / 305.5186 s
agent0:                 episode reward: 0.4537,                 loss: nan
agent1:                 episode reward: -0.4537,                 loss: 0.2679
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4608s / 306.9794 s
agent0:                 episode reward: 0.0979,                 loss: nan
agent1:                 episode reward: -0.0979,                 loss: 0.2676
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4434s / 308.4228 s
agent0:                 episode reward: 0.0624,                 loss: nan
agent1:                 episode reward: -0.0624,                 loss: 0.2668
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4839s / 309.9068 s
agent0:                 episode reward: 0.3559,                 loss: nan
agent1:                 episode reward: -0.3559,                 loss: 0.2671
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4267s / 311.3335 s
agent0:                 episode reward: 0.3314,                 loss: nan
agent1:                 episode reward: -0.3314,                 loss: 0.3118
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4520s / 312.7855 s
agent0:                 episode reward: -1.0029,                 loss: nan
agent1:                 episode reward: 1.0029,                 loss: 0.3155
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4676s / 314.2530 s
agent0:                 episode reward: 0.3426,                 loss: nan
agent1:                 episode reward: -0.3426,                 loss: 0.3158
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4480s / 315.7011 s
agent0:                 episode reward: -0.1364,                 loss: nan
agent1:                 episode reward: 0.1364,                 loss: 0.3130
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4415s / 317.1426 s
agent0:                 episode reward: -0.1979,                 loss: nan
agent1:                 episode reward: 0.1979,                 loss: 0.3151
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4454s / 318.5880 s
agent0:                 episode reward: 0.2705,                 loss: nan
agent1:                 episode reward: -0.2705,                 loss: 0.3498
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4798s / 320.0678 s
agent0:                 episode reward: -0.2230,                 loss: nan
agent1:                 episode reward: 0.2230,                 loss: 0.3489
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4635s / 321.5313 s
agent0:                 episode reward: -0.3112,                 loss: nan
agent1:                 episode reward: 0.3112,                 loss: 0.3499
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4615s / 322.9928 s
agent0:                 episode reward: 0.7516,                 loss: nan
agent1:                 episode reward: -0.7516,                 loss: 0.3481
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4642s / 324.4570 s
agent0:                 episode reward: -0.5805,                 loss: nan
agent1:                 episode reward: 0.5805,                 loss: 0.3474
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4824s / 325.9395 s
agent0:                 episode reward: -1.1174,                 loss: nan
agent1:                 episode reward: 1.1174,                 loss: 0.3160
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4713s / 327.4108 s
agent0:                 episode reward: -0.5268,                 loss: nan
agent1:                 episode reward: 0.5268,                 loss: 0.3001
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4652s / 328.8760 s
agent0:                 episode reward: -0.2193,                 loss: nan
agent1:                 episode reward: 0.2193,                 loss: 0.2994
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5280s / 330.4040 s
agent0:                 episode reward: -0.8353,                 loss: nan
agent1:                 episode reward: 0.8353,                 loss: 0.2991
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4959s / 331.8999 s
agent0:                 episode reward: 0.6230,                 loss: nan
agent1:                 episode reward: -0.6230,                 loss: 0.2971
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5043s / 333.4042 s
agent0:                 episode reward: -0.0758,                 loss: nan
agent1:                 episode reward: 0.0758,                 loss: 0.2506
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4889s / 334.8931 s
agent0:                 episode reward: -0.7674,                 loss: nan
agent1:                 episode reward: 0.7674,                 loss: 0.2325
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4782s / 336.3713 s
agent0:                 episode reward: 0.5240,                 loss: nan
agent1:                 episode reward: -0.5240,                 loss: 0.2313
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4815s / 337.8528 s
agent0:                 episode reward: 0.2814,                 loss: nan
agent1:                 episode reward: -0.2814,                 loss: 0.2283
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4911s / 339.3438 s
agent0:                 episode reward: -0.5079,                 loss: nan
agent1:                 episode reward: 0.5079,                 loss: 0.2260
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5196s / 340.8634 s
agent0:                 episode reward: -0.0591,                 loss: nan
agent1:                 episode reward: 0.0591,                 loss: 0.2319
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4902s / 342.3536 s
agent0:                 episode reward: -0.1068,                 loss: nan
agent1:                 episode reward: 0.1068,                 loss: 0.2251
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4986s / 343.8522 s
agent0:                 episode reward: 0.1131,                 loss: nan
agent1:                 episode reward: -0.1131,                 loss: 0.2215
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5065s / 345.3588 s
agent0:                 episode reward: -0.2421,                 loss: nan
agent1:                 episode reward: 0.2421,                 loss: 0.2204
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5106s / 346.8693 s
agent0:                 episode reward: -0.2787,                 loss: nan
agent1:                 episode reward: 0.2787,                 loss: 0.2187
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5320s / 348.4013 s
agent0:                 episode reward: 0.3238,                 loss: nan
agent1:                 episode reward: -0.3238,                 loss: 0.2227
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5249s / 349.9262 s
agent0:                 episode reward: -0.3507,                 loss: nan
agent1:                 episode reward: 0.3507,                 loss: 0.2179
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5454s / 351.4716 s
agent0:                 episode reward: -1.1189,                 loss: nan
agent1:                 episode reward: 1.1189,                 loss: 0.2173
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5237s / 352.9953 s
agent0:                 episode reward: -0.1866,                 loss: nan
agent1:                 episode reward: 0.1866,                 loss: 0.2158
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5446s / 354.5399 s
agent0:                 episode reward: -0.4307,                 loss: nan
agent1:                 episode reward: 0.4307,                 loss: 0.2144
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5663s / 356.1062 s
agent0:                 episode reward: -0.4237,                 loss: nan
agent1:                 episode reward: 0.4237,                 loss: 0.2329
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5894s / 357.6956 s
agent0:                 episode reward: -0.0109,                 loss: nan
agent1:                 episode reward: 0.0109,                 loss: 0.2272
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5482s / 359.2438 s
agent0:                 episode reward: -0.0680,                 loss: nan
agent1:                 episode reward: 0.0680,                 loss: 0.2214
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5936s / 360.8375 s
agent0:                 episode reward: -0.3008,                 loss: nan
agent1:                 episode reward: 0.3008,                 loss: 0.2223
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5294s / 362.3669 s
agent0:                 episode reward: -0.3413,                 loss: nan
agent1:                 episode reward: 0.3413,                 loss: 0.2214
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5739s / 363.9408 s
agent0:                 episode reward: -0.5072,                 loss: nan
agent1:                 episode reward: 0.5072,                 loss: 0.2250
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5422s / 365.4830 s
agent0:                 episode reward: -0.2148,                 loss: nan
agent1:                 episode reward: 0.2148,                 loss: 0.2223
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5567s / 367.0396 s
agent0:                 episode reward: -0.4129,                 loss: nan
agent1:                 episode reward: 0.4129,                 loss: 0.2222
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5571s / 368.5967 s
agent0:                 episode reward: -0.5291,                 loss: nan
agent1:                 episode reward: 0.5291,                 loss: 0.2205
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5555s / 370.1522 s
agent0:                 episode reward: 0.1897,                 loss: nan
agent1:                 episode reward: -0.1897,                 loss: 0.2215
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6060s / 371.7582 s
agent0:                 episode reward: -0.0346,                 loss: nan
agent1:                 episode reward: 0.0346,                 loss: 0.2144
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5832s / 373.3414 s
agent0:                 episode reward: 0.4121,                 loss: nan
agent1:                 episode reward: -0.4121,                 loss: 0.2101
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5807s / 374.9222 s
agent0:                 episode reward: -0.9407,                 loss: nan
agent1:                 episode reward: 0.9407,                 loss: 0.2097
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5788s / 376.5009 s
agent0:                 episode reward: -0.1740,                 loss: nan
agent1:                 episode reward: 0.1740,                 loss: 0.2089
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5776s / 378.0785 s
agent0:                 episode reward: 0.8640,                 loss: nan
agent1:                 episode reward: -0.8640,                 loss: 0.2081
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5817s / 379.6602 s
agent0:                 episode reward: -0.3658,                 loss: nan
agent1:                 episode reward: 0.3658,                 loss: 0.2449
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6564s / 381.3166 s
agent0:                 episode reward: -0.1604,                 loss: nan
agent1:                 episode reward: 0.1604,                 loss: 0.2442
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5756s / 382.8922 s
agent0:                 episode reward: -0.8353,                 loss: nan
agent1:                 episode reward: 0.8353,                 loss: 0.2436
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6080s / 384.5001 s
agent0:                 episode reward: -0.7972,                 loss: nan
agent1:                 episode reward: 0.7972,                 loss: 0.2453
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5818s / 386.0819 s
agent0:                 episode reward: 0.1244,                 loss: nan
agent1:                 episode reward: -0.1244,                 loss: 0.2451
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5964s / 387.6784 s
agent0:                 episode reward: -0.2472,                 loss: nan
agent1:                 episode reward: 0.2472,                 loss: 0.2837
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6124s / 389.2908 s
agent0:                 episode reward: -0.7501,                 loss: nan
agent1:                 episode reward: 0.7501,                 loss: 0.2840
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6347s / 390.9255 s
agent0:                 episode reward: 0.3659,                 loss: nan
agent1:                 episode reward: -0.3659,                 loss: 0.2828
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6141s / 392.5396 s
agent0:                 episode reward: 0.6293,                 loss: nan
agent1:                 episode reward: -0.6293,                 loss: 0.2826
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6391s / 394.1787 s
agent0:                 episode reward: -0.4505,                 loss: nan
agent1:                 episode reward: 0.4505,                 loss: 0.2804
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6329s / 395.8116 s
agent0:                 episode reward: -0.0643,                 loss: nan
agent1:                 episode reward: 0.0643,                 loss: 0.3042
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6246s / 397.4362 s
agent0:                 episode reward: -0.3278,                 loss: nan
agent1:                 episode reward: 0.3278,                 loss: 0.2947
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6022s / 399.0384 s
agent0:                 episode reward: -0.4215,                 loss: nan
agent1:                 episode reward: 0.4215,                 loss: 0.2935
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6157s / 400.6541 s
agent0:                 episode reward: -0.9286,                 loss: nan
agent1:                 episode reward: 0.9286,                 loss: 0.2932
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6515s / 402.3055 s
agent0:                 episode reward: -0.4647,                 loss: nan
agent1:                 episode reward: 0.4647,                 loss: 0.2928
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6235s / 403.9291 s
agent0:                 episode reward: -1.0200,                 loss: nan
agent1:                 episode reward: 1.0200,                 loss: 0.2258
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6518s / 405.5808 s
agent0:                 episode reward: -0.0724,                 loss: nan
agent1:                 episode reward: 0.0724,                 loss: 0.1997
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6394s / 407.2202 s
agent0:                 episode reward: -1.6704,                 loss: nan
agent1:                 episode reward: 1.6704,                 loss: 0.1999
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6435s / 408.8637 s
agent0:                 episode reward: -0.4002,                 loss: nan
agent1:                 episode reward: 0.4002,                 loss: 0.1969
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6315s / 410.4952 s
agent0:                 episode reward: -1.0227,                 loss: nan
agent1:                 episode reward: 1.0227,                 loss: 0.1978
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6900s / 412.1852 s
agent0:                 episode reward: -1.1036,                 loss: nan
agent1:                 episode reward: 1.1036,                 loss: 0.1671
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6445s / 413.8297 s
agent0:                 episode reward: -0.0918,                 loss: nan
agent1:                 episode reward: 0.0918,                 loss: 0.1552
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6384s / 415.4681 s
agent0:                 episode reward: -0.4893,                 loss: nan
agent1:                 episode reward: 0.4893,                 loss: 0.1555
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6575s / 417.1256 s
agent0:                 episode reward: 0.1376,                 loss: nan
agent1:                 episode reward: -0.1376,                 loss: 0.1556
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6334s / 418.7590 s
agent0:                 episode reward: -0.6024,                 loss: nan
agent1:                 episode reward: 0.6024,                 loss: 0.1555
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6576s / 420.4166 s
agent0:                 episode reward: -0.5973,                 loss: nan
agent1:                 episode reward: 0.5973,                 loss: 0.1706
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6979s / 422.1145 s
agent0:                 episode reward: -0.2705,                 loss: nan
agent1:                 episode reward: 0.2705,                 loss: 0.1710
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6467s / 423.7612 s
agent0:                 episode reward: -0.2385,                 loss: nan
agent1:                 episode reward: 0.2385,                 loss: 0.1712
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6600s / 425.4212 s
agent0:                 episode reward: -1.5798,                 loss: nan
agent1:                 episode reward: 1.5798,                 loss: 0.1708
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6773s / 427.0986 s
agent0:                 episode reward: 0.3557,                 loss: nan
agent1:                 episode reward: -0.3557,                 loss: 0.1690
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6648s / 428.7633 s
agent0:                 episode reward: -0.2264,                 loss: nan
agent1:                 episode reward: 0.2264,                 loss: 0.2060
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6844s / 430.4478 s
agent0:                 episode reward: 0.3550,                 loss: nan
agent1:                 episode reward: -0.3550,                 loss: 0.2081
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7143s / 432.1621 s
agent0:                 episode reward: -1.0178,                 loss: nan
agent1:                 episode reward: 1.0178,                 loss: 0.2075
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6827s / 433.8448 s
agent0:                 episode reward: -0.8550,                 loss: nan
agent1:                 episode reward: 0.8550,                 loss: 0.2064
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7075s / 435.5523 s
agent0:                 episode reward: -0.4946,                 loss: nan
agent1:                 episode reward: 0.4946,                 loss: 0.2065
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6957s / 437.2480 s
agent0:                 episode reward: -0.2100,                 loss: nan
agent1:                 episode reward: 0.2100,                 loss: 0.2415
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7311s / 438.9791 s
agent0:                 episode reward: -0.2093,                 loss: nan
agent1:                 episode reward: 0.2093,                 loss: 0.2425
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6978s / 440.6769 s
agent0:                 episode reward: 0.0528,                 loss: nan
agent1:                 episode reward: -0.0528,                 loss: 0.2407
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7551s / 442.4320 s
agent0:                 episode reward: -0.6037,                 loss: nan
agent1:                 episode reward: 0.6037,                 loss: 0.2409
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7152s / 444.1472 s
agent0:                 episode reward: 0.2231,                 loss: nan
agent1:                 episode reward: -0.2231,                 loss: 0.2410
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7343s / 445.8815 s
agent0:                 episode reward: 0.1109,                 loss: nan
agent1:                 episode reward: -0.1109,                 loss: 0.2607
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7252s / 447.6067 s
agent0:                 episode reward: -0.7782,                 loss: nan
agent1:                 episode reward: 0.7782,                 loss: 0.2599
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7122s / 449.3189 s
agent0:                 episode reward: -0.4914,                 loss: nan
agent1:                 episode reward: 0.4914,                 loss: 0.2592
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7485s / 451.0675 s
agent0:                 episode reward: -0.7707,                 loss: nan
agent1:                 episode reward: 0.7707,                 loss: 0.2576
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7602s / 452.8277 s
agent0:                 episode reward: -0.0190,                 loss: nan
agent1:                 episode reward: 0.0190,                 loss: 0.2570
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7513s / 454.5789 s
agent0:                 episode reward: -0.9713,                 loss: nan
agent1:                 episode reward: 0.9713,                 loss: 0.2614
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7633s / 456.3422 s
agent0:                 episode reward: -0.7829,                 loss: nan
agent1:                 episode reward: 0.7829,                 loss: 0.2604
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7452s / 458.0874 s
agent0:                 episode reward: 0.4181,                 loss: nan
agent1:                 episode reward: -0.4181,                 loss: 0.2582
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7493s / 459.8367 s
agent0:                 episode reward: -0.0258,                 loss: nan
agent1:                 episode reward: 0.0258,                 loss: 0.2574
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7600s / 461.5967 s
agent0:                 episode reward: -1.2466,                 loss: nan
agent1:                 episode reward: 1.2466,                 loss: 0.2563
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8166s / 463.4133 s
agent0:                 episode reward: -0.0040,                 loss: nan
agent1:                 episode reward: 0.0040,                 loss: 0.2857
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7559s / 465.1692 s
agent0:                 episode reward: -0.4607,                 loss: nan
agent1:                 episode reward: 0.4607,                 loss: 0.2866
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7528s / 466.9220 s
agent0:                 episode reward: 0.2835,                 loss: nan
agent1:                 episode reward: -0.2835,                 loss: 0.2838
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7680s / 468.6900 s
agent0:                 episode reward: -0.0937,                 loss: nan
agent1:                 episode reward: 0.0937,                 loss: 0.2809
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7591s / 470.4491 s
agent0:                 episode reward: -0.5569,                 loss: nan
agent1:                 episode reward: 0.5569,                 loss: 0.2822
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7656s / 472.2147 s
agent0:                 episode reward: -0.7161,                 loss: nan
agent1:                 episode reward: 0.7161,                 loss: 0.3185
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8256s / 474.0403 s
agent0:                 episode reward: -0.5880,                 loss: nan
agent1:                 episode reward: 0.5880,                 loss: 0.3228
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8012s / 475.8415 s
agent0:                 episode reward: -0.9093,                 loss: nan
agent1:                 episode reward: 0.9093,                 loss: 0.3222
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7694s / 477.6109 s
agent0:                 episode reward: -0.1939,                 loss: nan
agent1:                 episode reward: 0.1939,                 loss: 0.3189
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7597s / 479.3706 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.3202
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7873s / 481.1579 s
agent0:                 episode reward: -0.3707,                 loss: nan
agent1:                 episode reward: 0.3707,                 loss: 0.3438
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7770s / 482.9349 s
agent0:                 episode reward: -0.4994,                 loss: nan
agent1:                 episode reward: 0.4994,                 loss: 0.3426
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8336s / 484.7685 s
agent0:                 episode reward: -0.7089,                 loss: nan
agent1:                 episode reward: 0.7089,                 loss: 0.3414
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7932s / 486.5617 s
agent0:                 episode reward: 0.4625,                 loss: nan
agent1:                 episode reward: -0.4625,                 loss: 0.3421
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7962s / 488.3579 s
agent0:                 episode reward: -0.5642,                 loss: nan
agent1:                 episode reward: 0.5642,                 loss: 0.3434
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8221s / 490.1800 s
agent0:                 episode reward: -0.2874,                 loss: nan
agent1:                 episode reward: 0.2874,                 loss: 0.3166
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7822s / 491.9622 s
agent0:                 episode reward: -0.2109,                 loss: nan
agent1:                 episode reward: 0.2109,                 loss: 0.3041
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8538s / 493.8161 s
agent0:                 episode reward: -0.8817,                 loss: nan
agent1:                 episode reward: 0.8817,                 loss: 0.3044
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8081s / 495.6242 s
agent0:                 episode reward: -0.3654,                 loss: nan
agent1:                 episode reward: 0.3654,                 loss: 0.3035
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8313s / 497.4555 s
agent0:                 episode reward: -0.5562,                 loss: nan
agent1:                 episode reward: 0.5562,                 loss: 0.3022
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8233s / 499.2788 s
agent0:                 episode reward: -0.1020,                 loss: nan
agent1:                 episode reward: 0.1020,                 loss: 0.2442
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8248s / 501.1036 s
agent0:                 episode reward: -0.5368,                 loss: nan
agent1:                 episode reward: 0.5368,                 loss: 0.2268
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8285s / 502.9321 s
agent0:                 episode reward: 0.4029,                 loss: nan
agent1:                 episode reward: -0.4029,                 loss: 0.2227
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8996s / 504.8317 s
agent0:                 episode reward: -0.5269,                 loss: nan
agent1:                 episode reward: 0.5269,                 loss: 0.2235
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8424s / 506.6741 s
agent0:                 episode reward: -1.0789,                 loss: nan
agent1:                 episode reward: 1.0789,                 loss: 0.2218
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8577s / 508.5319 s
agent0:                 episode reward: -0.9393,                 loss: nan
agent1:                 episode reward: 0.9393,                 loss: 0.2109
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8354s / 510.3673 s
agent0:                 episode reward: -0.9465,                 loss: nan
agent1:                 episode reward: 0.9465,                 loss: 0.2044
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8759s / 512.2432 s
agent0:                 episode reward: -0.5486,                 loss: nan
agent1:                 episode reward: 0.5486,                 loss: 0.2044
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9019s / 514.1451 s
agent0:                 episode reward: -1.0196,                 loss: nan
agent1:                 episode reward: 1.0196,                 loss: 0.2042
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8602s / 516.0052 s
agent0:                 episode reward: -0.5982,                 loss: nan
agent1:                 episode reward: 0.5982,                 loss: 0.2029
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8469s / 517.8522 s
agent0:                 episode reward: 0.0125,                 loss: nan
agent1:                 episode reward: -0.0125,                 loss: 0.2226
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8820s / 519.7342 s
agent0:                 episode reward: -0.2499,                 loss: nan
agent1:                 episode reward: 0.2499,                 loss: 0.2220
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8966s / 521.6308 s
agent0:                 episode reward: -0.1682,                 loss: nan
agent1:                 episode reward: 0.1682,                 loss: 0.2228
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8621s / 523.4929 s
agent0:                 episode reward: -0.3333,                 loss: nan
agent1:                 episode reward: 0.3333,                 loss: 0.2218
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9467s / 525.4396 s
agent0:                 episode reward: -0.8701,                 loss: nan
agent1:                 episode reward: 0.8701,                 loss: 0.2219
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9062s / 527.3458 s
agent0:                 episode reward: -0.7120,                 loss: nan
agent1:                 episode reward: 0.7120,                 loss: 0.2456
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8636s / 529.2094 s
agent0:                 episode reward: -0.3992,                 loss: nan
agent1:                 episode reward: 0.3992,                 loss: 0.2451
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8944s / 531.1038 s
agent0:                 episode reward: -0.3906,                 loss: nan
agent1:                 episode reward: 0.3906,                 loss: 0.2428
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8846s / 532.9884 s
agent0:                 episode reward: -0.2837,                 loss: nan
agent1:                 episode reward: 0.2837,                 loss: 0.2417
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9329s / 534.9213 s
agent0:                 episode reward: -0.5771,                 loss: nan
agent1:                 episode reward: 0.5771,                 loss: 0.2433
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9033s / 536.8247 s
agent0:                 episode reward: -0.5503,                 loss: nan
agent1:                 episode reward: 0.5503,                 loss: 0.2585
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9063s / 538.7310 s
agent0:                 episode reward: -0.3299,                 loss: nan
agent1:                 episode reward: 0.3299,                 loss: 0.2566
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8986s / 540.6295 s
agent0:                 episode reward: -0.4578,                 loss: nan
agent1:                 episode reward: 0.4578,                 loss: 0.2562
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8855s / 542.5150 s
agent0:                 episode reward: -1.0183,                 loss: nan
agent1:                 episode reward: 1.0183,                 loss: 0.2565
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9111s / 544.4262 s
agent0:                 episode reward: -0.3048,                 loss: nan
agent1:                 episode reward: 0.3048,                 loss: 0.2520
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9957s / 546.4219 s
agent0:                 episode reward: -1.3941,                 loss: nan
agent1:                 episode reward: 1.3941,                 loss: 0.2628
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9108s / 548.3327 s
agent0:                 episode reward: -0.9395,                 loss: nan
agent1:                 episode reward: 0.9395,                 loss: 0.2599
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9373s / 550.2700 s
agent0:                 episode reward: -0.5053,                 loss: nan
agent1:                 episode reward: 0.5053,                 loss: 0.2614
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9128s / 552.1828 s
agent0:                 episode reward: -0.5935,                 loss: nan
agent1:                 episode reward: 0.5935,                 loss: 0.2612
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9163s / 554.0990 s
agent0:                 episode reward: -1.1426,                 loss: nan
agent1:                 episode reward: 1.1426,                 loss: 0.2624
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0287s / 556.1277 s
agent0:                 episode reward: -0.5849,                 loss: nan
agent1:                 episode reward: 0.5849,                 loss: 0.2771
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9407s / 558.0684 s
agent0:                 episode reward: -0.2351,                 loss: nan
agent1:                 episode reward: 0.2351,                 loss: 0.2765
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9381s / 560.0065 s
agent0:                 episode reward: -1.0919,                 loss: nan
agent1:                 episode reward: 1.0919,                 loss: 0.2737
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9418s / 561.9483 s
agent0:                 episode reward: -0.7243,                 loss: nan
agent1:                 episode reward: 0.7243,                 loss: 0.2729
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9373s / 563.8856 s
agent0:                 episode reward: -0.5022,                 loss: nan
agent1:                 episode reward: 0.5022,                 loss: 0.2723
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9955s / 565.8811 s
agent0:                 episode reward: -0.5954,                 loss: nan
agent1:                 episode reward: 0.5954,                 loss: 0.3082
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9616s / 567.8427 s
agent0:                 episode reward: -0.1558,                 loss: nan
agent1:                 episode reward: 0.1558,                 loss: 0.3090
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9384s / 569.7811 s
agent0:                 episode reward: -1.2279,                 loss: nan
agent1:                 episode reward: 1.2279,                 loss: 0.3062
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9654s / 571.7464 s
agent0:                 episode reward: -0.7768,                 loss: nan
agent1:                 episode reward: 0.7768,                 loss: 0.3052
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9556s / 573.7020 s
agent0:                 episode reward: -1.1937,                 loss: nan
agent1:                 episode reward: 1.1937,                 loss: 0.3039
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0044s / 575.7064 s
agent0:                 episode reward: -1.0344,                 loss: nan
agent1:                 episode reward: 1.0344,                 loss: 0.3084
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9799s / 577.6863 s
agent0:                 episode reward: -1.5606,                 loss: nan
agent1:                 episode reward: 1.5606,                 loss: 0.2983
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9830s / 579.6693 s
agent0:                 episode reward: -0.2236,                 loss: nan
agent1:                 episode reward: 0.2236,                 loss: 0.2986
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9717s / 581.6410 s
agent0:                 episode reward: -0.0801,                 loss: nan
agent1:                 episode reward: 0.0801,                 loss: 0.2987
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9788s / 583.6197 s
agent0:                 episode reward: -0.5403,                 loss: nan
agent1:                 episode reward: 0.5403,                 loss: 0.2987
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0327s / 585.6525 s
agent0:                 episode reward: -0.4146,                 loss: nan
agent1:                 episode reward: 0.4146,                 loss: 0.2468
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9973s / 587.6497 s
agent0:                 episode reward: -0.3462,                 loss: nan
agent1:                 episode reward: 0.3462,                 loss: 0.2242
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0054s / 589.6551 s
agent0:                 episode reward: -0.3316,                 loss: nan
agent1:                 episode reward: 0.3316,                 loss: 0.2215
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0055s / 591.6606 s
agent0:                 episode reward: -1.2838,                 loss: nan
agent1:                 episode reward: 1.2838,                 loss: 0.2206
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9774s / 593.6380 s
agent0:                 episode reward: -0.5879,                 loss: nan
agent1:                 episode reward: 0.5879,                 loss: 0.2214
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9905s / 595.6284 s
agent0:                 episode reward: 0.1938,                 loss: nan
agent1:                 episode reward: -0.1938,                 loss: 0.1902
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0784s / 597.7068 s
agent0:                 episode reward: -0.3709,                 loss: nan
agent1:                 episode reward: 0.3709,                 loss: 0.1777
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0074s / 599.7142 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.1744
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0331s / 601.7474 s
agent0:                 episode reward: -0.7023,                 loss: nan
agent1:                 episode reward: 0.7023,                 loss: 0.1745
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9995s / 603.7469 s
agent0:                 episode reward: -0.4232,                 loss: nan
agent1:                 episode reward: 0.4232,                 loss: 0.1742
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9876s / 605.7345 s
agent0:                 episode reward: -0.4751,                 loss: nan
agent1:                 episode reward: 0.4751,                 loss: 0.1875
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0731s / 607.8075 s
agent0:                 episode reward: -0.6369,                 loss: nan
agent1:                 episode reward: 0.6369,                 loss: 0.1847
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0164s / 609.8239 s
agent0:                 episode reward: 0.0760,                 loss: nan
agent1:                 episode reward: -0.0760,                 loss: 0.1838
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0196s / 611.8435 s
agent0:                 episode reward: -0.2449,                 loss: nan
agent1:                 episode reward: 0.2449,                 loss: 0.1825
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0657s / 613.9092 s
agent0:                 episode reward: -1.1427,                 loss: nan
agent1:                 episode reward: 1.1427,                 loss: 0.1839
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0341s / 615.9433 s
agent0:                 episode reward: -0.6390,                 loss: nan
agent1:                 episode reward: 0.6390,                 loss: 0.2146
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0938s / 618.0371 s
agent0:                 episode reward: -0.5679,                 loss: nan
agent1:                 episode reward: 0.5679,                 loss: 0.2157
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0777s / 620.1147 s
agent0:                 episode reward: -0.9845,                 loss: nan
agent1:                 episode reward: 0.9845,                 loss: 0.2154
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0534s / 622.1681 s
agent0:                 episode reward: 0.0760,                 loss: nan
agent1:                 episode reward: -0.0760,                 loss: 0.2164
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0459s / 624.2141 s
agent0:                 episode reward: -0.9028,                 loss: nan
agent1:                 episode reward: 0.9028,                 loss: 0.2161
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0783s / 626.2924 s
agent0:                 episode reward: -0.4988,                 loss: nan
agent1:                 episode reward: 0.4988,                 loss: 0.2439
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1514s / 628.4438 s
agent0:                 episode reward: -1.1243,                 loss: nan
agent1:                 episode reward: 1.1243,                 loss: 0.2454
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0694s / 630.5132 s
agent0:                 episode reward: -0.4373,                 loss: nan
agent1:                 episode reward: 0.4373,                 loss: 0.2432
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0796s / 632.5928 s
agent0:                 episode reward: -0.4461,                 loss: nan
agent1:                 episode reward: 0.4461,                 loss: 0.2429
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1135s / 634.7062 s
agent0:                 episode reward: -0.2959,                 loss: nan
agent1:                 episode reward: 0.2959,                 loss: 0.2444
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0777s / 636.7840 s
agent0:                 episode reward: -0.1808,                 loss: nan
agent1:                 episode reward: 0.1808,                 loss: 0.2569
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1390s / 638.9230 s
agent0:                 episode reward: -0.7149,                 loss: nan
agent1:                 episode reward: 0.7149,                 loss: 0.2561
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0899s / 641.0128 s
agent0:                 episode reward: -0.5378,                 loss: nan
agent1:                 episode reward: 0.5378,                 loss: 0.2547
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1140s / 643.1268 s
agent0:                 episode reward: -0.3140,                 loss: nan
agent1:                 episode reward: 0.3140,                 loss: 0.2554
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1190s / 645.2458 s
agent0:                 episode reward: -0.7204,                 loss: nan
agent1:                 episode reward: 0.7204,                 loss: 0.2534
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1659s / 647.4117 s
agent0:                 episode reward: -0.9697,                 loss: nan
agent1:                 episode reward: 0.9697,                 loss: 0.2627
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1000s / 649.5117 s
agent0:                 episode reward: -1.3060,                 loss: nan
agent1:                 episode reward: 1.3060,                 loss: 0.2629
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1260s / 651.6377 s
agent0:                 episode reward: -0.4210,                 loss: nan
agent1:                 episode reward: 0.4210,                 loss: 0.2616
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1385s / 653.7762 s
agent0:                 episode reward: -0.6239,                 loss: nan
agent1:                 episode reward: 0.6239,                 loss: 0.2630
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0870s / 655.8632 s
agent0:                 episode reward: -0.8960,                 loss: nan
agent1:                 episode reward: 0.8960,                 loss: 0.2609
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1450s / 658.0082 s
agent0:                 episode reward: -0.7872,                 loss: nan
agent1:                 episode reward: 0.7872,                 loss: 0.2785
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0608s / 660.0690 s
agent0:                 episode reward: -0.9542,                 loss: nan
agent1:                 episode reward: 0.9542,                 loss: 0.2762
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0799s / 662.1489 s
agent0:                 episode reward: -0.5579,                 loss: nan
agent1:                 episode reward: 0.5579,                 loss: 0.2757
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1062s / 664.2551 s
agent0:                 episode reward: -0.9893,                 loss: nan
agent1:                 episode reward: 0.9893,                 loss: 0.2767
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0773s / 666.3324 s
agent0:                 episode reward: -0.8956,                 loss: nan
agent1:                 episode reward: 0.8956,                 loss: 0.2747
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1696s / 668.5020 s
agent0:                 episode reward: -0.7465,                 loss: nan
agent1:                 episode reward: 0.7465,                 loss: 0.3112
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1357s / 670.6378 s
agent0:                 episode reward: -0.5772,                 loss: nan
agent1:                 episode reward: 0.5772,                 loss: 0.3125
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1189s / 672.7567 s
agent0:                 episode reward: -0.6950,                 loss: nan
agent1:                 episode reward: 0.6950,                 loss: 0.3095
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1061s / 674.8628 s
agent0:                 episode reward: -0.7514,                 loss: nan
agent1:                 episode reward: 0.7514,                 loss: 0.3099
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1327s / 676.9955 s
agent0:                 episode reward: -1.5267,                 loss: nan
agent1:                 episode reward: 1.5267,                 loss: 0.3089/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2144s / 679.2099 s
agent0:                 episode reward: -0.5222,                 loss: nan
agent1:                 episode reward: 0.5222,                 loss: 0.3155
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1497s / 681.3596 s
agent0:                 episode reward: -1.2705,                 loss: nan
agent1:                 episode reward: 1.2705,                 loss: 0.3050
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1603s / 683.5199 s
agent0:                 episode reward: -0.9915,                 loss: nan
agent1:                 episode reward: 0.9915,                 loss: 0.3066
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1207s / 685.6406 s
agent0:                 episode reward: -1.0404,                 loss: nan
agent1:                 episode reward: 1.0404,                 loss: 0.3058
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1774s / 687.8181 s
agent0:                 episode reward: -1.3083,                 loss: nan
agent1:                 episode reward: 1.3083,                 loss: 0.3055
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2224s / 690.0405 s
agent0:                 episode reward: -0.9186,                 loss: nan
agent1:                 episode reward: 0.9186,                 loss: 0.2540
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1436s / 692.1841 s
agent0:                 episode reward: -0.8281,                 loss: nan
agent1:                 episode reward: 0.8281,                 loss: 0.2367
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1649s / 694.3490 s
agent0:                 episode reward: -1.0774,                 loss: nan
agent1:                 episode reward: 1.0774,                 loss: 0.2347
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2204s / 696.5694 s
agent0:                 episode reward: -1.3371,                 loss: nan
agent1:                 episode reward: 1.3371,                 loss: 0.2352
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.2372s / 698.8066 s
agent0:                 episode reward: -1.2498,                 loss: nan
agent1:                 episode reward: 1.2498,                 loss: 0.2360
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.1768s / 700.9834 s
agent0:                 episode reward: -0.5393,                 loss: nan
agent1:                 episode reward: 0.5393,                 loss: 0.1928
