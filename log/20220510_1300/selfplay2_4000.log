2022-05-10 13:11:13.956388: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 13:11:13.956459: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 13:11:13.956464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fbf6808d518>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510123946/mdp_arbitrary_mdp_selfplay2/4000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510123946/mdp_arbitrary_mdp_selfplay2/4000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510123946_exploit_4000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510123946_exploit_4000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8235s / 0.8235 s
agent0:                 episode reward: -1.6843,                 loss: nan
agent1:                 episode reward: 1.6843,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0780s / 0.9015 s
agent0:                 episode reward: 0.4394,                 loss: nan
agent1:                 episode reward: -0.4394,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0766s / 0.9781 s
agent0:                 episode reward: 0.8712,                 loss: nan
agent1:                 episode reward: -0.8712,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0696s / 1.0477 s
agent0:                 episode reward: 0.6813,                 loss: nan
agent1:                 episode reward: -0.6813,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6306s / 1.6783 s
agent0:                 episode reward: 0.5604,                 loss: nan
agent1:                 episode reward: -0.5604,                 loss: 0.4368
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7262s / 2.4044 s
agent0:                 episode reward: -0.1993,                 loss: nan
agent1:                 episode reward: 0.1993,                 loss: 0.4063
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7554s / 3.1598 s
agent0:                 episode reward: 0.3169,                 loss: nan
agent1:                 episode reward: -0.3169,                 loss: 0.3955
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7711s / 3.9310 s
agent0:                 episode reward: 0.7081,                 loss: nan
agent1:                 episode reward: -0.7081,                 loss: 0.3826
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7618s / 4.6927 s
agent0:                 episode reward: -0.0996,                 loss: nan
agent1:                 episode reward: 0.0996,                 loss: 0.3770
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7683s / 5.4610 s
agent0:                 episode reward: 0.5790,                 loss: nan
agent1:                 episode reward: -0.5790,                 loss: 0.4058
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7421s / 6.2031 s
agent0:                 episode reward: 0.7408,                 loss: nan
agent1:                 episode reward: -0.7408,                 loss: 0.4075
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7343s / 6.9374 s
agent0:                 episode reward: 0.7984,                 loss: nan
agent1:                 episode reward: -0.7984,                 loss: 0.4070
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8072s / 7.7446 s
agent0:                 episode reward: 0.3386,                 loss: nan
agent1:                 episode reward: -0.3386,                 loss: 0.4069
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7584s / 8.5030 s
agent0:                 episode reward: 0.2792,                 loss: nan
agent1:                 episode reward: -0.2792,                 loss: 0.4070
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7728s / 9.2758 s
agent0:                 episode reward: 0.3833,                 loss: nan
agent1:                 episode reward: -0.3833,                 loss: 0.4274
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7516s / 10.0274 s
agent0:                 episode reward: 0.0866,                 loss: nan
agent1:                 episode reward: -0.0866,                 loss: 0.4267
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7543s / 10.7818 s
agent0:                 episode reward: 0.3408,                 loss: nan
agent1:                 episode reward: -0.3408,                 loss: 0.4234
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7717s / 11.5534 s
agent0:                 episode reward: 0.3937,                 loss: nan
agent1:                 episode reward: -0.3937,                 loss: 0.4220
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7702s / 12.3236 s
agent0:                 episode reward: -0.1372,                 loss: nan
agent1:                 episode reward: 0.1372,                 loss: 0.4218
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7864s / 13.1100 s
agent0:                 episode reward: -0.1933,                 loss: nan
agent1:                 episode reward: 0.1933,                 loss: 0.4270
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7646s / 13.8746 s
agent0:                 episode reward: 0.7192,                 loss: nan
agent1:                 episode reward: -0.7192,                 loss: 0.4240
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7747s / 14.6492 s
agent0:                 episode reward: 1.0485,                 loss: nan
agent1:                 episode reward: -1.0485,                 loss: 0.4202
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7759s / 15.4251 s
agent0:                 episode reward: 0.7281,                 loss: nan
agent1:                 episode reward: -0.7281,                 loss: 0.4178
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7708s / 16.1960 s
agent0:                 episode reward: 0.2080,                 loss: nan
agent1:                 episode reward: -0.2080,                 loss: 0.4149
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7812s / 16.9772 s
agent0:                 episode reward: 0.8076,                 loss: nan
agent1:                 episode reward: -0.8076,                 loss: 0.4127
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8403s / 17.8175 s
agent0:                 episode reward: 0.4879,                 loss: nan
agent1:                 episode reward: -0.4879,                 loss: 0.4104
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7880s / 18.6055 s
agent0:                 episode reward: 0.4373,                 loss: nan
agent1:                 episode reward: -0.4373,                 loss: 0.4076
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7915s / 19.3970 s
agent0:                 episode reward: 0.1945,                 loss: nan
agent1:                 episode reward: -0.1945,                 loss: 0.4058
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7920s / 20.1890 s
agent0:                 episode reward: 0.5832,                 loss: nan
agent1:                 episode reward: -0.5832,                 loss: 0.4023
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8281s / 21.0171 s
agent0:                 episode reward: 0.6625,                 loss: nan
agent1:                 episode reward: -0.6625,                 loss: 0.3978
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8054s / 21.8226 s
agent0:                 episode reward: -0.1347,                 loss: nan
agent1:                 episode reward: 0.1347,                 loss: 0.3941
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8034s / 22.6260 s
agent0:                 episode reward: 0.0427,                 loss: nan
agent1:                 episode reward: -0.0427,                 loss: 0.3913
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8185s / 23.4445 s
agent0:                 episode reward: 0.9217,                 loss: nan
agent1:                 episode reward: -0.9217,                 loss: 0.3897
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8358s / 24.2803 s
agent0:                 episode reward: 0.4361,                 loss: nan
agent1:                 episode reward: -0.4361,                 loss: 0.3879
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8050s / 25.0853 s
agent0:                 episode reward: 0.5609,                 loss: nan
agent1:                 episode reward: -0.5609,                 loss: 0.3808
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8145s / 25.8998 s
agent0:                 episode reward: 0.8507,                 loss: nan
agent1:                 episode reward: -0.8507,                 loss: 0.3775
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8273s / 26.7272 s
agent0:                 episode reward: -0.0034,                 loss: nan
agent1:                 episode reward: 0.0034,                 loss: 0.3754
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8023s / 27.5294 s
agent0:                 episode reward: -0.1558,                 loss: nan
agent1:                 episode reward: 0.1558,                 loss: 0.3763
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8602s / 28.3897 s
agent0:                 episode reward: 0.4550,                 loss: nan
agent1:                 episode reward: -0.4550,                 loss: 0.3767
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8365s / 29.2262 s
agent0:                 episode reward: 0.2795,                 loss: nan
agent1:                 episode reward: -0.2795,                 loss: 0.3678
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8308s / 30.0570 s
agent0:                 episode reward: 0.3505,                 loss: nan
agent1:                 episode reward: -0.3505,                 loss: 0.3655
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8430s / 30.9000 s
agent0:                 episode reward: -0.4700,                 loss: nan
agent1:                 episode reward: 0.4700,                 loss: 0.3658
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8308s / 31.7308 s
agent0:                 episode reward: 0.4105,                 loss: nan
agent1:                 episode reward: -0.4105,                 loss: 0.3634
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8242s / 32.5550 s
agent0:                 episode reward: -0.2171,                 loss: nan
agent1:                 episode reward: 0.2171,                 loss: 0.3613
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8382s / 33.3932 s
agent0:                 episode reward: -0.5844,                 loss: nan
agent1:                 episode reward: 0.5844,                 loss: 0.3517
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8441s / 34.2373 s
agent0:                 episode reward: 0.5443,                 loss: nan
agent1:                 episode reward: -0.5443,                 loss: 0.3471
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8601s / 35.0974 s
agent0:                 episode reward: 0.2261,                 loss: nan
agent1:                 episode reward: -0.2261,                 loss: 0.3461
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8500s / 35.9474 s
agent0:                 episode reward: -0.4269,                 loss: nan
agent1:                 episode reward: 0.4269,                 loss: 0.3437
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8528s / 36.8002 s
agent0:                 episode reward: 0.2325,                 loss: nan
agent1:                 episode reward: -0.2325,                 loss: 0.3447
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8806s / 37.6808 s
agent0:                 episode reward: 0.3939,                 loss: nan
agent1:                 episode reward: -0.3939,                 loss: 0.3337
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9151s / 38.5959 s
agent0:                 episode reward: 1.0773,                 loss: nan
agent1:                 episode reward: -1.0773,                 loss: 0.3306
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8361s / 39.4320 s
agent0:                 episode reward: 0.5543,                 loss: nan
agent1:                 episode reward: -0.5543,                 loss: 0.3274
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8572s / 40.2892 s
agent0:                 episode reward: 0.5806,                 loss: nan
agent1:                 episode reward: -0.5806,                 loss: 0.3264
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8427s / 41.1320 s
agent0:                 episode reward: -0.1995,                 loss: nan
agent1:                 episode reward: 0.1995,                 loss: 0.3276
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8461s / 41.9781 s
agent0:                 episode reward: -0.0492,                 loss: nan
agent1:                 episode reward: 0.0492,                 loss: 0.3221
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8413s / 42.8194 s
agent0:                 episode reward: 0.4440,                 loss: nan
agent1:                 episode reward: -0.4440,                 loss: 0.3199
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8357s / 43.6550 s
agent0:                 episode reward: -0.4383,                 loss: nan
agent1:                 episode reward: 0.4383,                 loss: 0.3196
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8466s / 44.5016 s
agent0:                 episode reward: 0.4093,                 loss: nan
agent1:                 episode reward: -0.4093,                 loss: 0.3179
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8466s / 45.3482 s
agent0:                 episode reward: 0.1196,                 loss: nan
agent1:                 episode reward: -0.1196,                 loss: 0.3171
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8697s / 46.2179 s
agent0:                 episode reward: -0.0802,                 loss: nan
agent1:                 episode reward: 0.0802,                 loss: 0.3063
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8658s / 47.0837 s
agent0:                 episode reward: 0.0545,                 loss: nan
agent1:                 episode reward: -0.0545,                 loss: 0.3020
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8972s / 47.9809 s
agent0:                 episode reward: 0.3386,                 loss: nan
agent1:                 episode reward: -0.3386,                 loss: 0.3008
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9691s / 48.9500 s
agent0:                 episode reward: 0.1021,                 loss: nan
agent1:                 episode reward: -0.1021,                 loss: 0.2995
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8861s / 49.8362 s
agent0:                 episode reward: 0.4609,                 loss: nan
agent1:                 episode reward: -0.4609,                 loss: 0.3008
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9017s / 50.7379 s
agent0:                 episode reward: 0.7996,                 loss: nan
agent1:                 episode reward: -0.7996,                 loss: 0.2987
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9015s / 51.6394 s
agent0:                 episode reward: -0.1511,                 loss: nan
agent1:                 episode reward: 0.1511,                 loss: 0.2982
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8949s / 52.5343 s
agent0:                 episode reward: 0.3692,                 loss: nan
agent1:                 episode reward: -0.3692,                 loss: 0.2938
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9001s / 53.4344 s
agent0:                 episode reward: 0.3784,                 loss: nan
agent1:                 episode reward: -0.3784,                 loss: 0.2925
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9360s / 54.3705 s
agent0:                 episode reward: 0.2086,                 loss: nan
agent1:                 episode reward: -0.2086,                 loss: 0.2918
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8933s / 55.2638 s
agent0:                 episode reward: 0.5192,                 loss: nan
agent1:                 episode reward: -0.5192,                 loss: 0.2904
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9038s / 56.1676 s
agent0:                 episode reward: 0.0060,                 loss: nan
agent1:                 episode reward: -0.0060,                 loss: 0.2868
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9036s / 57.0712 s
agent0:                 episode reward: 0.9927,                 loss: nan
agent1:                 episode reward: -0.9927,                 loss: 0.2858
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8993s / 57.9705 s
agent0:                 episode reward: 0.9699,                 loss: nan
agent1:                 episode reward: -0.9699,                 loss: 0.2833
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9683s / 58.9387 s
agent0:                 episode reward: -0.9429,                 loss: nan
agent1:                 episode reward: 0.9429,                 loss: 0.2831
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9377s / 59.8765 s
agent0:                 episode reward: 0.5415,                 loss: nan
agent1:                 episode reward: -0.5415,                 loss: 0.2882
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9239s / 60.8003 s
agent0:                 episode reward: 0.3954,                 loss: nan
agent1:                 episode reward: -0.3954,                 loss: 0.2869
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9446s / 61.7449 s
agent0:                 episode reward: 0.3765,                 loss: nan
agent1:                 episode reward: -0.3765,                 loss: 0.2856
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9346s / 62.6796 s
agent0:                 episode reward: -0.0315,                 loss: nan
agent1:                 episode reward: 0.0315,                 loss: 0.2831
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9108s / 63.5904 s
agent0:                 episode reward: -0.2266,                 loss: nan
agent1:                 episode reward: 0.2266,                 loss: 0.2821
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9263s / 64.5167 s
agent0:                 episode reward: -0.3036,                 loss: nan
agent1:                 episode reward: 0.3036,                 loss: 0.3010
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9371s / 65.4538 s
agent0:                 episode reward: 0.3567,                 loss: nan
agent1:                 episode reward: -0.3567,                 loss: 0.3012
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9183s / 66.3720 s
agent0:                 episode reward: -0.1080,                 loss: nan
agent1:                 episode reward: 0.1080,                 loss: 0.3005
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9191s / 67.2911 s
agent0:                 episode reward: 0.5890,                 loss: nan
agent1:                 episode reward: -0.5890,                 loss: 0.2997
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9342s / 68.2253 s
agent0:                 episode reward: 0.1829,                 loss: nan
agent1:                 episode reward: -0.1829,                 loss: 0.2971
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9961s / 69.2214 s
agent0:                 episode reward: 0.3196,                 loss: nan
agent1:                 episode reward: -0.3196,                 loss: 0.3204
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9328s / 70.1541 s
agent0:                 episode reward: 0.0288,                 loss: nan
agent1:                 episode reward: -0.0288,                 loss: 0.3233
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9545s / 71.1086 s
agent0:                 episode reward: 0.4148,                 loss: nan
agent1:                 episode reward: -0.4148,                 loss: 0.3215
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9460s / 72.0546 s
agent0:                 episode reward: 0.0974,                 loss: nan
agent1:                 episode reward: -0.0974,                 loss: 0.3215
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9348s / 72.9894 s
agent0:                 episode reward: -0.6188,                 loss: nan
agent1:                 episode reward: 0.6188,                 loss: 0.3193
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9387s / 73.9281 s
agent0:                 episode reward: -0.3744,                 loss: nan
agent1:                 episode reward: 0.3744,                 loss: 0.3402
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9540s / 74.8821 s
agent0:                 episode reward: 0.1162,                 loss: nan
agent1:                 episode reward: -0.1162,                 loss: 0.3419
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9503s / 75.8325 s
agent0:                 episode reward: -0.0232,                 loss: nan
agent1:                 episode reward: 0.0232,                 loss: 0.3421
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9477s / 76.7802 s
agent0:                 episode reward: -0.4314,                 loss: nan
agent1:                 episode reward: 0.4314,                 loss: 0.3391
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9483s / 77.7285 s
agent0:                 episode reward: 0.9250,                 loss: nan
agent1:                 episode reward: -0.9250,                 loss: 0.3397
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9561s / 78.6847 s
agent0:                 episode reward: 0.0325,                 loss: nan
agent1:                 episode reward: -0.0325,                 loss: 0.3584
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0383s / 79.7229 s
agent0:                 episode reward: 0.6354,                 loss: nan
agent1:                 episode reward: -0.6354,                 loss: 0.3621
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0012s / 80.7241 s
agent0:                 episode reward: 0.1755,                 loss: nan
agent1:                 episode reward: -0.1755,                 loss: 0.3626
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9753s / 81.6994 s
agent0:                 episode reward: 0.9725,                 loss: nan
agent1:                 episode reward: -0.9725,                 loss: 0.3623
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9695s / 82.6689 s
agent0:                 episode reward: 0.5951,                 loss: nan
agent1:                 episode reward: -0.5951,                 loss: 0.3614
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9769s / 83.6457 s
agent0:                 episode reward: 0.5326,                 loss: nan
agent1:                 episode reward: -0.5326,                 loss: 0.3730
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9887s / 84.6344 s
agent0:                 episode reward: -0.2613,                 loss: nan
agent1:                 episode reward: 0.2613,                 loss: 0.3724
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9812s / 85.6156 s
agent0:                 episode reward: 0.2174,                 loss: nan
agent1:                 episode reward: -0.2174,                 loss: 0.3712
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9620s / 86.5775 s
agent0:                 episode reward: -0.2595,                 loss: nan
agent1:                 episode reward: 0.2595,                 loss: 0.3728
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0195s / 87.5970 s
agent0:                 episode reward: 0.2481,                 loss: nan
agent1:                 episode reward: -0.2481,                 loss: 0.3711
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9765s / 88.5736 s
agent0:                 episode reward: 0.3451,                 loss: nan
agent1:                 episode reward: -0.3451,                 loss: 0.3697
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0342s / 89.6077 s
agent0:                 episode reward: 0.2414,                 loss: nan
agent1:                 episode reward: -0.2414,                 loss: 0.3650
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9818s / 90.5895 s
agent0:                 episode reward: -0.2204,                 loss: nan
agent1:                 episode reward: 0.2204,                 loss: 0.3659
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9930s / 91.5825 s
agent0:                 episode reward: -0.1951,                 loss: nan
agent1:                 episode reward: 0.1951,                 loss: 0.3631
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9886s / 92.5711 s
agent0:                 episode reward: 0.4691,                 loss: nan
agent1:                 episode reward: -0.4691,                 loss: 0.3644
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9978s / 93.5689 s
agent0:                 episode reward: 0.2731,                 loss: nan
agent1:                 episode reward: -0.2731,                 loss: 0.3447
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9879s / 94.5569 s
agent0:                 episode reward: -0.9392,                 loss: nan
agent1:                 episode reward: 0.9392,                 loss: 0.3382
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0533s / 95.6102 s
agent0:                 episode reward: -0.8434,                 loss: nan
agent1:                 episode reward: 0.8434,                 loss: 0.3380
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0060s / 96.6161 s
agent0:                 episode reward: 0.2978,                 loss: nan
agent1:                 episode reward: -0.2978,                 loss: 0.3362
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9965s / 97.6127 s
agent0:                 episode reward: -0.1965,                 loss: nan
agent1:                 episode reward: 0.1965,                 loss: 0.3367
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0206s / 98.6333 s
agent0:                 episode reward: 0.2812,                 loss: nan
agent1:                 episode reward: -0.2812,                 loss: 0.3121
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0503s / 99.6835 s
agent0:                 episode reward: -0.2332,                 loss: nan
agent1:                 episode reward: 0.2332,                 loss: 0.3059
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9995s / 100.6831 s
agent0:                 episode reward: 0.2014,                 loss: nan
agent1:                 episode reward: -0.2014,                 loss: 0.3052
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0006s / 101.6837 s
agent0:                 episode reward: 0.1171,                 loss: nan
agent1:                 episode reward: -0.1171,                 loss: 0.3036
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0271s / 102.7108 s
agent0:                 episode reward: 0.2747,                 loss: nan
agent1:                 episode reward: -0.2747,                 loss: 0.3036
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0042s / 103.7150 s
agent0:                 episode reward: -0.0639,                 loss: nan
agent1:                 episode reward: 0.0639,                 loss: 0.2868
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0333s / 104.7483 s
agent0:                 episode reward: 0.7927,                 loss: nan
agent1:                 episode reward: -0.7927,                 loss: 0.2821
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0206s / 105.7689 s
agent0:                 episode reward: 0.2055,                 loss: nan
agent1:                 episode reward: -0.2055,                 loss: 0.2804
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0224s / 106.7913 s
agent0:                 episode reward: -0.1831,                 loss: nan
agent1:                 episode reward: 0.1831,                 loss: 0.2803
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0158s / 107.8071 s
agent0:                 episode reward: -0.2708,                 loss: nan
agent1:                 episode reward: 0.2708,                 loss: 0.2794
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0291s / 108.8363 s
agent0:                 episode reward: 0.3144,                 loss: nan
agent1:                 episode reward: -0.3144,                 loss: 0.2765
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0587s / 109.8950 s
agent0:                 episode reward: -0.0437,                 loss: nan
agent1:                 episode reward: 0.0437,                 loss: 0.2736
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0465s / 110.9414 s
agent0:                 episode reward: -0.0040,                 loss: nan
agent1:                 episode reward: 0.0040,                 loss: 0.2726
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0245s / 111.9660 s
agent0:                 episode reward: -0.5030,                 loss: nan
agent1:                 episode reward: 0.5030,                 loss: 0.2708
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0636s / 113.0296 s
agent0:                 episode reward: 0.1355,                 loss: nan
agent1:                 episode reward: -0.1355,                 loss: 0.2692
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0192s / 114.0488 s
agent0:                 episode reward: 0.0520,                 loss: nan
agent1:                 episode reward: -0.0520,                 loss: 0.2709
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0154s / 115.0642 s
agent0:                 episode reward: 0.2765,                 loss: nan
agent1:                 episode reward: -0.2765,                 loss: 0.2629
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0176s / 116.0818 s
agent0:                 episode reward: 0.1403,                 loss: nan
agent1:                 episode reward: -0.1403,                 loss: 0.2636
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0193s / 117.1010 s
agent0:                 episode reward: 0.0321,                 loss: nan
agent1:                 episode reward: -0.0321,                 loss: 0.2629
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9943s / 118.0954 s
agent0:                 episode reward: 0.2447,                 loss: nan
agent1:                 episode reward: -0.2447,                 loss: 0.2628
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9951s / 119.0905 s
agent0:                 episode reward: 0.2497,                 loss: nan
agent1:                 episode reward: -0.2497,                 loss: 0.2642
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0904s / 120.1809 s
agent0:                 episode reward: 0.3348,                 loss: nan
agent1:                 episode reward: -0.3348,                 loss: 0.2604
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0366s / 121.2175 s
agent0:                 episode reward: 0.0697,                 loss: nan
agent1:                 episode reward: -0.0697,                 loss: 0.2582
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0244s / 122.2419 s
agent0:                 episode reward: 0.5814,                 loss: nan
agent1:                 episode reward: -0.5814,                 loss: 0.2584
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0051s / 123.2469 s
agent0:                 episode reward: 0.4429,                 loss: nan
agent1:                 episode reward: -0.4429,                 loss: 0.2562
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0096s / 124.2565 s
agent0:                 episode reward: 0.2462,                 loss: nan
agent1:                 episode reward: -0.2462,                 loss: 0.2769
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0030s / 125.2595 s
agent0:                 episode reward: -0.0894,                 loss: nan
agent1:                 episode reward: 0.0894,                 loss: 0.2747
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0198s / 126.2793 s
agent0:                 episode reward: -0.7867,                 loss: nan
agent1:                 episode reward: 0.7867,                 loss: 0.2736
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0297s / 127.3090 s
agent0:                 episode reward: 0.0415,                 loss: nan
agent1:                 episode reward: -0.0415,                 loss: 0.2749
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0274s / 128.3364 s
agent0:                 episode reward: 0.1677,                 loss: nan
agent1:                 episode reward: -0.1677,                 loss: 0.2725
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0477s / 129.3841 s
agent0:                 episode reward: 0.1674,                 loss: nan
agent1:                 episode reward: -0.1674,                 loss: 0.3204
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0652s / 130.4493 s
agent0:                 episode reward: -0.3615,                 loss: nan
agent1:                 episode reward: 0.3615,                 loss: 0.3243
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0248s / 131.4741 s
agent0:                 episode reward: -0.2183,                 loss: nan
agent1:                 episode reward: 0.2183,                 loss: 0.3234
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0556s / 132.5297 s
agent0:                 episode reward: 0.1654,                 loss: nan
agent1:                 episode reward: -0.1654,                 loss: 0.3201
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0376s / 133.5672 s
agent0:                 episode reward: 0.1777,                 loss: nan
agent1:                 episode reward: -0.1777,                 loss: 0.3205
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0389s / 134.6062 s
agent0:                 episode reward: -0.0234,                 loss: nan
agent1:                 episode reward: 0.0234,                 loss: 0.3496
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0455s / 135.6517 s
agent0:                 episode reward: -0.2097,                 loss: nan
agent1:                 episode reward: 0.2097,                 loss: 0.3446
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0342s / 136.6859 s
agent0:                 episode reward: -0.1541,                 loss: nan
agent1:                 episode reward: 0.1541,                 loss: 0.3429
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0724s / 137.7582 s
agent0:                 episode reward: 0.3420,                 loss: nan
agent1:                 episode reward: -0.3420,                 loss: 0.3427
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0566s / 138.8148 s
agent0:                 episode reward: -0.0467,                 loss: nan
agent1:                 episode reward: 0.0467,                 loss: 0.3381
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0426s / 139.8574 s
agent0:                 episode reward: 0.2503,                 loss: nan
agent1:                 episode reward: -0.2503,                 loss: 0.2799
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1187s / 140.9761 s
agent0:                 episode reward: -0.5228,                 loss: nan
agent1:                 episode reward: 0.5228,                 loss: 0.2567
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0419s / 142.0180 s
agent0:                 episode reward: -0.4671,                 loss: nan
agent1:                 episode reward: 0.4671,                 loss: 0.2572
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0711s / 143.0891 s
agent0:                 episode reward: 1.0337,                 loss: nan
agent1:                 episode reward: -1.0337,                 loss: 0.2553
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0677s / 144.1568 s
agent0:                 episode reward: -0.3131,                 loss: nan
agent1:                 episode reward: 0.3131,                 loss: 0.2571
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0785s / 145.2352 s
agent0:                 episode reward: 0.2878,                 loss: nan
agent1:                 episode reward: -0.2878,                 loss: 0.2132
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0744s / 146.3096 s
agent0:                 episode reward: 0.1374,                 loss: nan
agent1:                 episode reward: -0.1374,                 loss: 0.2029
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0898s / 147.3994 s
agent0:                 episode reward: 0.0750,                 loss: nan
agent1:                 episode reward: -0.0750,                 loss: 0.1991
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0717s / 148.4711 s
agent0:                 episode reward: 0.1545,                 loss: nan
agent1:                 episode reward: -0.1545,                 loss: 0.2017
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0833s / 149.5543 s
agent0:                 episode reward: -0.0468,                 loss: nan
agent1:                 episode reward: 0.0468,                 loss: 0.2007
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1256s / 150.6800 s
agent0:                 episode reward: 0.1791,                 loss: nan
agent1:                 episode reward: -0.1791,                 loss: 0.2159
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0924s / 151.7724 s
agent0:                 episode reward: -0.2067,                 loss: nan
agent1:                 episode reward: 0.2067,                 loss: 0.2092
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1113s / 152.8837 s
agent0:                 episode reward: -0.0783,                 loss: nan
agent1:                 episode reward: 0.0783,                 loss: 0.2098
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1130s / 153.9967 s
agent0:                 episode reward: 0.1909,                 loss: nan
agent1:                 episode reward: -0.1909,                 loss: 0.2083
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0995s / 155.0962 s
agent0:                 episode reward: 0.1827,                 loss: nan
agent1:                 episode reward: -0.1827,                 loss: 0.2089
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1060s / 156.2022 s
agent0:                 episode reward: 0.1286,                 loss: nan
agent1:                 episode reward: -0.1286,                 loss: 0.2264
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1058s / 157.3080 s
agent0:                 episode reward: -0.3646,                 loss: nan
agent1:                 episode reward: 0.3646,                 loss: 0.2270
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1126s / 158.4206 s
agent0:                 episode reward: 0.4007,                 loss: nan
agent1:                 episode reward: -0.4007,                 loss: 0.2261
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1013s / 159.5219 s
agent0:                 episode reward: -0.1003,                 loss: nan
agent1:                 episode reward: 0.1003,                 loss: 0.2236
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1012s / 160.6231 s
agent0:                 episode reward: -0.2392,                 loss: nan
agent1:                 episode reward: 0.2392,                 loss: 0.2222
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1706s / 161.7937 s
agent0:                 episode reward: -0.1233,                 loss: nan
agent1:                 episode reward: 0.1233,                 loss: 0.2468
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1243s / 162.9180 s
agent0:                 episode reward: -0.0805,                 loss: nan
agent1:                 episode reward: 0.0805,                 loss: 0.2465
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1095s / 164.0275 s
agent0:                 episode reward: -0.1671,                 loss: nan
agent1:                 episode reward: 0.1671,                 loss: 0.2438
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1222s / 165.1496 s
agent0:                 episode reward: -0.1635,                 loss: nan
agent1:                 episode reward: 0.1635,                 loss: 0.2428
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1157s / 166.2653 s
agent0:                 episode reward: -0.0479,                 loss: nan
agent1:                 episode reward: 0.0479,                 loss: 0.2419
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1237s / 167.3891 s
agent0:                 episode reward: 0.1327,                 loss: nan
agent1:                 episode reward: -0.1327,                 loss: 0.2530
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1319s / 168.5210 s
agent0:                 episode reward: 0.4512,                 loss: nan
agent1:                 episode reward: -0.4512,                 loss: 0.2464
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1217s / 169.6427 s
agent0:                 episode reward: 0.4067,                 loss: nan
agent1:                 episode reward: -0.4067,                 loss: 0.2463
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1484s / 170.7911 s
agent0:                 episode reward: -0.0702,                 loss: nan
agent1:                 episode reward: 0.0702,                 loss: 0.2443
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1764s / 171.9676 s
agent0:                 episode reward: -0.1999,                 loss: nan
agent1:                 episode reward: 0.1999,                 loss: 0.2446
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1498s / 173.1174 s
agent0:                 episode reward: 0.0676,                 loss: nan
agent1:                 episode reward: -0.0676,                 loss: 0.2509
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1402s / 174.2576 s
agent0:                 episode reward: 0.4227,                 loss: nan
agent1:                 episode reward: -0.4227,                 loss: 0.2462
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1362s / 175.3939 s
agent0:                 episode reward: -0.4458,                 loss: nan
agent1:                 episode reward: 0.4458,                 loss: 0.2456
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1431s / 176.5369 s
agent0:                 episode reward: -0.1565,                 loss: nan
agent1:                 episode reward: 0.1565,                 loss: 0.2458
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1424s / 177.6793 s
agent0:                 episode reward: 0.4115,                 loss: nan
agent1:                 episode reward: -0.4115,                 loss: 0.2442
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1690s / 178.8483 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: 0.2766
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1729s / 180.0212 s
agent0:                 episode reward: -0.9548,                 loss: nan
agent1:                 episode reward: 0.9548,                 loss: 0.2760
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2112s / 181.2325 s
agent0:                 episode reward: 0.2938,                 loss: nan
agent1:                 episode reward: -0.2938,                 loss: 0.2747
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1811s / 182.4135 s
agent0:                 episode reward: -0.2126,                 loss: nan
agent1:                 episode reward: 0.2126,                 loss: 0.2740
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1742s / 183.5878 s
agent0:                 episode reward: -0.6757,                 loss: nan
agent1:                 episode reward: 0.6757,                 loss: 0.2746
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1633s / 184.7511 s
agent0:                 episode reward: -0.0737,                 loss: nan
agent1:                 episode reward: 0.0737,                 loss: 0.3292
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1739s / 185.9249 s
agent0:                 episode reward: -0.3531,                 loss: nan
agent1:                 episode reward: 0.3531,                 loss: 0.3343
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1900s / 187.1150 s
agent0:                 episode reward: 0.0237,                 loss: nan
agent1:                 episode reward: -0.0237,                 loss: 0.3308
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1718s / 188.2867 s
agent0:                 episode reward: 0.2517,                 loss: nan
agent1:                 episode reward: -0.2517,                 loss: 0.3316
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1616s / 189.4484 s
agent0:                 episode reward: -0.3414,                 loss: nan
agent1:                 episode reward: 0.3414,                 loss: 0.3292
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1816s / 190.6299 s
agent0:                 episode reward: 0.2392,                 loss: nan
agent1:                 episode reward: -0.2392,                 loss: 0.3409
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2350s / 191.8649 s
agent0:                 episode reward: 0.4995,                 loss: nan
agent1:                 episode reward: -0.4995,                 loss: 0.3346
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1856s / 193.0505 s
agent0:                 episode reward: -0.0085,                 loss: nan
agent1:                 episode reward: 0.0085,                 loss: 0.3345
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1777s / 194.2283 s
agent0:                 episode reward: -0.0990,                 loss: nan
agent1:                 episode reward: 0.0990,                 loss: 0.3327
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1895s / 195.4178 s
agent0:                 episode reward: -0.1294,                 loss: nan
agent1:                 episode reward: 0.1294,                 loss: 0.3334
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1766s / 196.5944 s
agent0:                 episode reward: -0.3213,                 loss: nan
agent1:                 episode reward: 0.3213,                 loss: 0.2706
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1670s / 197.7614 s
agent0:                 episode reward: -0.8290,                 loss: nan
agent1:                 episode reward: 0.8290,                 loss: 0.2497
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1795s / 198.9409 s
agent0:                 episode reward: -0.2370,                 loss: nan
agent1:                 episode reward: 0.2370,                 loss: 0.2494
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1703s / 200.1112 s
agent0:                 episode reward: -0.2886,                 loss: nan
agent1:                 episode reward: 0.2886,                 loss: 0.2470
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1789s / 201.2900 s
agent0:                 episode reward: -0.9770,                 loss: nan
agent1:                 episode reward: 0.9770,                 loss: 0.2465
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2168s / 202.5068 s
agent0:                 episode reward: -0.7842,                 loss: nan
agent1:                 episode reward: 0.7842,                 loss: 0.2111
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2062s / 203.7129 s
agent0:                 episode reward: 0.0201,                 loss: nan
agent1:                 episode reward: -0.0201,                 loss: 0.2003
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2141s / 204.9271 s
agent0:                 episode reward: -0.6540,                 loss: nan
agent1:                 episode reward: 0.6540,                 loss: 0.1981
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1989s / 206.1260 s
agent0:                 episode reward: 0.0695,                 loss: nan
agent1:                 episode reward: -0.0695,                 loss: 0.1969
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2266s / 207.3526 s
agent0:                 episode reward: -0.0358,                 loss: nan
agent1:                 episode reward: 0.0358,                 loss: 0.1979
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2146s / 208.5672 s
agent0:                 episode reward: 0.1439,                 loss: nan
agent1:                 episode reward: -0.1439,                 loss: 0.2058
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2177s / 209.7849 s
agent0:                 episode reward: -0.5687,                 loss: nan
agent1:                 episode reward: 0.5687,                 loss: 0.2008
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2208s / 211.0057 s
agent0:                 episode reward: 0.1213,                 loss: nan
agent1:                 episode reward: -0.1213,                 loss: 0.2016
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2817s / 212.2875 s
agent0:                 episode reward: 0.1975,                 loss: nan
agent1:                 episode reward: -0.1975,                 loss: 0.2008
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2266s / 213.5140 s
agent0:                 episode reward: -0.3999,                 loss: nan
agent1:                 episode reward: 0.3999,                 loss: 0.2004
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2192s / 214.7332 s
agent0:                 episode reward: -0.8388,                 loss: nan
agent1:                 episode reward: 0.8388,                 loss: 0.2205
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2240s / 215.9572 s
agent0:                 episode reward: 0.0244,                 loss: nan
agent1:                 episode reward: -0.0244,                 loss: 0.2232
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2137s / 217.1709 s
agent0:                 episode reward: -0.2514,                 loss: nan
agent1:                 episode reward: 0.2514,                 loss: 0.2213
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2116s / 218.3826 s
agent0:                 episode reward: -0.5842,                 loss: nan
agent1:                 episode reward: 0.5842,                 loss: 0.2212
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2325s / 219.6151 s
agent0:                 episode reward: -0.4810,                 loss: nan
agent1:                 episode reward: 0.4810,                 loss: 0.2234
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2407s / 220.8558 s
agent0:                 episode reward: -1.3979,                 loss: nan
agent1:                 episode reward: 1.3979,                 loss: 0.2318
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2556s / 222.1114 s
agent0:                 episode reward: 0.1174,                 loss: nan
agent1:                 episode reward: -0.1174,                 loss: 0.2292
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2672s / 223.3786 s
agent0:                 episode reward: 0.6754,                 loss: nan
agent1:                 episode reward: -0.6754,                 loss: 0.2282
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2302s / 224.6088 s
agent0:                 episode reward: -0.2394,                 loss: nan
agent1:                 episode reward: 0.2394,                 loss: 0.2272
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2363s / 225.8451 s
agent0:                 episode reward: -0.1085,                 loss: nan
agent1:                 episode reward: 0.1085,                 loss: 0.2260
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2416s / 227.0867 s
agent0:                 episode reward: 0.0077,                 loss: nan
agent1:                 episode reward: -0.0077,                 loss: 0.2285
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2766s / 228.3633 s
agent0:                 episode reward: -0.7584,                 loss: nan
agent1:                 episode reward: 0.7584,                 loss: 0.2252
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2316s / 229.5949 s
agent0:                 episode reward: 0.4157,                 loss: nan
agent1:                 episode reward: -0.4157,                 loss: 0.2223
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2728s / 230.8677 s
agent0:                 episode reward: -0.1664,                 loss: nan
agent1:                 episode reward: 0.1664,                 loss: 0.2232
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2438s / 232.1115 s
agent0:                 episode reward: -0.3117,                 loss: nan
agent1:                 episode reward: 0.3117,                 loss: 0.2218
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2780s / 233.3895 s
agent0:                 episode reward: -0.5848,                 loss: nan
agent1:                 episode reward: 0.5848,                 loss: 0.2353
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2565s / 234.6461 s
agent0:                 episode reward: -0.3280,                 loss: nan
agent1:                 episode reward: 0.3280,                 loss: 0.2312
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2492s / 235.8953 s
agent0:                 episode reward: -0.4957,                 loss: nan
agent1:                 episode reward: 0.4957,                 loss: 0.2314
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2746s / 237.1699 s
agent0:                 episode reward: 0.3315,                 loss: nan
agent1:                 episode reward: -0.3315,                 loss: 0.2289
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2457s / 238.4156 s
agent0:                 episode reward: -0.2552,                 loss: nan
agent1:                 episode reward: 0.2552,                 loss: 0.2281
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2474s / 239.6630 s
agent0:                 episode reward: -0.0923,                 loss: nan
agent1:                 episode reward: 0.0923,                 loss: 0.2621
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2649s / 240.9278 s
agent0:                 episode reward: -0.8829,                 loss: nan
agent1:                 episode reward: 0.8829,                 loss: 0.2622
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2599s / 242.1878 s
agent0:                 episode reward: 0.1728,                 loss: nan
agent1:                 episode reward: -0.1728,                 loss: 0.2616
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3125s / 243.5003 s
agent0:                 episode reward: -0.5314,                 loss: nan
agent1:                 episode reward: 0.5314,                 loss: 0.2601
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2827s / 244.7830 s
agent0:                 episode reward: 0.0310,                 loss: nan
agent1:                 episode reward: -0.0310,                 loss: 0.2595
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2665s / 246.0496 s
agent0:                 episode reward: -0.2311,                 loss: nan
agent1:                 episode reward: 0.2311,                 loss: 0.3104
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2746s / 247.3242 s
agent0:                 episode reward: -0.3525,                 loss: nan
agent1:                 episode reward: 0.3525,                 loss: 0.3148
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2717s / 248.5959 s
agent0:                 episode reward: -0.7772,                 loss: nan
agent1:                 episode reward: 0.7772,                 loss: 0.3122
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2763s / 249.8721 s
agent0:                 episode reward: -0.4528,                 loss: nan
agent1:                 episode reward: 0.4528,                 loss: 0.3138
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2827s / 251.1549 s
agent0:                 episode reward: -0.2146,                 loss: nan
agent1:                 episode reward: 0.2146,                 loss: 0.3116
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2756s / 252.4305 s
agent0:                 episode reward: -0.0910,                 loss: nan
agent1:                 episode reward: 0.0910,                 loss: 0.3209
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3343s / 253.7647 s
agent0:                 episode reward: -0.7444,                 loss: nan
agent1:                 episode reward: 0.7444,                 loss: 0.3137
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2962s / 255.0609 s
agent0:                 episode reward: -0.9184,                 loss: nan
agent1:                 episode reward: 0.9184,                 loss: 0.3126
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2764s / 256.3373 s
agent0:                 episode reward: -1.2735,                 loss: nan
agent1:                 episode reward: 1.2735,                 loss: 0.3123
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2778s / 257.6151 s
agent0:                 episode reward: -0.6537,                 loss: nan
agent1:                 episode reward: 0.6537,                 loss: 0.3108
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3201s / 258.9352 s
agent0:                 episode reward: 0.1263,                 loss: nan
agent1:                 episode reward: -0.1263,                 loss: 0.2356
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2819s / 260.2172 s
agent0:                 episode reward: -0.2832,                 loss: nan
agent1:                 episode reward: 0.2832,                 loss: 0.2107
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3119s / 261.5291 s
agent0:                 episode reward: -0.7760,                 loss: nan
agent1:                 episode reward: 0.7760,                 loss: 0.2084
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2857s / 262.8149 s
agent0:                 episode reward: -0.1738,                 loss: nan
agent1:                 episode reward: 0.1738,                 loss: 0.2079
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3861s / 264.2010 s
agent0:                 episode reward: -1.5025,                 loss: nan
agent1:                 episode reward: 1.5025,                 loss: 0.2074
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3010s / 265.5020 s
agent0:                 episode reward: -0.4017,                 loss: nan
agent1:                 episode reward: 0.4017,                 loss: 0.1733
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2976s / 266.7996 s
agent0:                 episode reward: -0.7818,                 loss: nan
agent1:                 episode reward: 0.7818,                 loss: 0.1627
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2998s / 268.0994 s
agent0:                 episode reward: -0.9104,                 loss: nan
agent1:                 episode reward: 0.9104,                 loss: 0.1619
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2995s / 269.3989 s
agent0:                 episode reward: -0.3523,                 loss: nan
agent1:                 episode reward: 0.3523,                 loss: 0.1594
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3187s / 270.7176 s
agent0:                 episode reward: -0.5256,                 loss: nan
agent1:                 episode reward: 0.5256,                 loss: 0.1590
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3012s / 272.0188 s
agent0:                 episode reward: -1.1323,                 loss: nan
agent1:                 episode reward: 1.1323,                 loss: 0.1763
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3344s / 273.3532 s
agent0:                 episode reward: -0.5299,                 loss: nan
agent1:                 episode reward: 0.5299,                 loss: 0.1724
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3780s / 274.7311 s
agent0:                 episode reward: -0.2575,                 loss: nan
agent1:                 episode reward: 0.2575,                 loss: 0.1737
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3050s / 276.0361 s
agent0:                 episode reward: -0.9365,                 loss: nan
agent1:                 episode reward: 0.9365,                 loss: 0.1714
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3064s / 277.3426 s
agent0:                 episode reward: -0.4634,                 loss: nan
agent1:                 episode reward: 0.4634,                 loss: 0.1703
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3257s / 278.6683 s
agent0:                 episode reward: -0.6189,                 loss: nan
agent1:                 episode reward: 0.6189,                 loss: 0.1920
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3314s / 279.9997 s
agent0:                 episode reward: -1.0731,                 loss: nan
agent1:                 episode reward: 1.0731,                 loss: 0.1929
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3129s / 281.3125 s
agent0:                 episode reward: -0.3392,                 loss: nan
agent1:                 episode reward: 0.3392,                 loss: 0.1914
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3268s / 282.6394 s
agent0:                 episode reward: -0.6240,                 loss: nan
agent1:                 episode reward: 0.6240,                 loss: 0.1923
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3634s / 284.0028 s
agent0:                 episode reward: -0.2249,                 loss: nan
agent1:                 episode reward: 0.2249,                 loss: 0.1895
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3383s / 285.3411 s
agent0:                 episode reward: -0.3301,                 loss: nan
agent1:                 episode reward: 0.3301,                 loss: 0.2176
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3486s / 286.6896 s
agent0:                 episode reward: -0.3425,                 loss: nan
agent1:                 episode reward: 0.3425,                 loss: 0.2162
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3407s / 288.0303 s
agent0:                 episode reward: -0.8312,                 loss: nan
agent1:                 episode reward: 0.8312,                 loss: 0.2172
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3367s / 289.3671 s
agent0:                 episode reward: -0.1221,                 loss: nan
agent1:                 episode reward: 0.1221,                 loss: 0.2172
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3448s / 290.7119 s
agent0:                 episode reward: -0.0703,                 loss: nan
agent1:                 episode reward: 0.0703,                 loss: 0.2177
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3453s / 292.0572 s
agent0:                 episode reward: 0.0421,                 loss: nan
agent1:                 episode reward: -0.0421,                 loss: 0.2270
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3539s / 293.4111 s
agent0:                 episode reward: -0.5711,                 loss: nan
agent1:                 episode reward: 0.5711,                 loss: 0.2233
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4117s / 294.8228 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.2233
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3487s / 296.1715 s
agent0:                 episode reward: -0.5283,                 loss: nan
agent1:                 episode reward: 0.5283,                 loss: 0.2226
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3764s / 297.5479 s
agent0:                 episode reward: 0.0543,                 loss: nan
agent1:                 episode reward: -0.0543,                 loss: 0.2230
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3460s / 298.8939 s
agent0:                 episode reward: -0.3364,                 loss: nan
agent1:                 episode reward: 0.3364,                 loss: 0.2260
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3744s / 300.2684 s
agent0:                 episode reward: -0.4925,                 loss: nan
agent1:                 episode reward: 0.4925,                 loss: 0.2228
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3670s / 301.6354 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.2228
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3765s / 303.0120 s
agent0:                 episode reward: -0.2951,                 loss: nan
agent1:                 episode reward: 0.2951,                 loss: 0.2220
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3953s / 304.4072 s
agent0:                 episode reward: -0.5383,                 loss: nan
agent1:                 episode reward: 0.5383,                 loss: 0.2213
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3694s / 305.7767 s
agent0:                 episode reward: -0.2926,                 loss: nan
agent1:                 episode reward: 0.2926,                 loss: 0.2460
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3622s / 307.1389 s
agent0:                 episode reward: -0.1646,                 loss: nan
agent1:                 episode reward: 0.1646,                 loss: 0.2446
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3864s / 308.5253 s
agent0:                 episode reward: -0.6718,                 loss: nan
agent1:                 episode reward: 0.6718,                 loss: 0.2443
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3709s / 309.8961 s
agent0:                 episode reward: -0.2650,                 loss: nan
agent1:                 episode reward: 0.2650,                 loss: 0.2435
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3736s / 311.2697 s
agent0:                 episode reward: -0.4890,                 loss: nan
agent1:                 episode reward: 0.4890,                 loss: 0.2440
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3789s / 312.6486 s
agent0:                 episode reward: -0.4478,                 loss: nan
agent1:                 episode reward: 0.4478,                 loss: 0.2764
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4143s / 314.0629 s
agent0:                 episode reward: 0.4997,                 loss: nan
agent1:                 episode reward: -0.4997,                 loss: 0.2791
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4452s / 315.5081 s
agent0:                 episode reward: 0.0600,                 loss: nan
agent1:                 episode reward: -0.0600,                 loss: 0.2775
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3820s / 316.8901 s
agent0:                 episode reward: -0.1172,                 loss: nan
agent1:                 episode reward: 0.1172,                 loss: 0.2776
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3928s / 318.2829 s
agent0:                 episode reward: -0.6027,                 loss: nan
agent1:                 episode reward: 0.6027,                 loss: 0.2761
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3967s / 319.6796 s
agent0:                 episode reward: 0.1657,                 loss: nan
agent1:                 episode reward: -0.1657,                 loss: 0.3293
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3934s / 321.0730 s
agent0:                 episode reward: -0.3054,                 loss: nan
agent1:                 episode reward: 0.3054,                 loss: 0.3354
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3900s / 322.4629 s
agent0:                 episode reward: -0.7268,                 loss: nan
agent1:                 episode reward: 0.7268,                 loss: 0.3329
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3799s / 323.8428 s
agent0:                 episode reward: 0.0308,                 loss: nan
agent1:                 episode reward: -0.0308,                 loss: 0.3331
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4447s / 325.2875 s
agent0:                 episode reward: -0.4095,                 loss: nan
agent1:                 episode reward: 0.4095,                 loss: 0.3324
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4126s / 326.7000 s
agent0:                 episode reward: 0.2900,                 loss: nan
agent1:                 episode reward: -0.2900,                 loss: 0.3131
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4035s / 328.1036 s
agent0:                 episode reward: -0.4561,                 loss: nan
agent1:                 episode reward: 0.4561,                 loss: 0.3029
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4106s / 329.5142 s
agent0:                 episode reward: -0.1579,                 loss: nan
agent1:                 episode reward: 0.1579,                 loss: 0.3028
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4161s / 330.9303 s
agent0:                 episode reward: -0.5388,                 loss: nan
agent1:                 episode reward: 0.5388,                 loss: 0.3020
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4047s / 332.3350 s
agent0:                 episode reward: 0.0323,                 loss: nan
agent1:                 episode reward: -0.0323,                 loss: 0.3012
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4062s / 333.7412 s
agent0:                 episode reward: -0.1364,                 loss: nan
agent1:                 episode reward: 0.1364,                 loss: 0.2376
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4444s / 335.1856 s
agent0:                 episode reward: -0.4286,                 loss: nan
agent1:                 episode reward: 0.4286,                 loss: 0.2226
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4333s / 336.6189 s
agent0:                 episode reward: -0.9513,                 loss: nan
agent1:                 episode reward: 0.9513,                 loss: 0.2221
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4023s / 338.0212 s
agent0:                 episode reward: 0.1630,                 loss: nan
agent1:                 episode reward: -0.1630,                 loss: 0.2224
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4178s / 339.4390 s
agent0:                 episode reward: -0.6775,                 loss: nan
agent1:                 episode reward: 0.6775,                 loss: 0.2239
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4199s / 340.8589 s
agent0:                 episode reward: -0.2663,                 loss: nan
agent1:                 episode reward: 0.2663,                 loss: 0.1967
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4851s / 342.3440 s
agent0:                 episode reward: -0.7336,                 loss: nan
agent1:                 episode reward: 0.7336,                 loss: 0.1903
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4212s / 343.7652 s
agent0:                 episode reward: -0.3639,                 loss: nan
agent1:                 episode reward: 0.3639,                 loss: 0.1883
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4859s / 345.2512 s
agent0:                 episode reward: -1.1550,                 loss: nan
agent1:                 episode reward: 1.1550,                 loss: 0.1879
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4266s / 346.6778 s
agent0:                 episode reward: -0.5975,                 loss: nan
agent1:                 episode reward: 0.5975,                 loss: 0.1876
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4240s / 348.1018 s
agent0:                 episode reward: -0.6818,                 loss: nan
agent1:                 episode reward: 0.6818,                 loss: 0.1934
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4096s / 349.5114 s
agent0:                 episode reward: -0.2899,                 loss: nan
agent1:                 episode reward: 0.2899,                 loss: 0.1913
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4114s / 350.9228 s
agent0:                 episode reward: -0.0976,                 loss: nan
agent1:                 episode reward: 0.0976,                 loss: 0.1894
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4360s / 352.3588 s
agent0:                 episode reward: 0.0492,                 loss: nan
agent1:                 episode reward: -0.0492,                 loss: 0.1890
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4439s / 353.8027 s
agent0:                 episode reward: -0.1225,                 loss: nan
agent1:                 episode reward: 0.1225,                 loss: 0.1880
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4682s / 355.2709 s
agent0:                 episode reward: -0.6769,                 loss: nan
agent1:                 episode reward: 0.6769,                 loss: 0.2093
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5176s / 356.7885 s
agent0:                 episode reward: -0.8595,                 loss: nan
agent1:                 episode reward: 0.8595,                 loss: 0.2082
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4396s / 358.2280 s
agent0:                 episode reward: -1.4908,                 loss: nan
agent1:                 episode reward: 1.4908,                 loss: 0.2052
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4499s / 359.6780 s
agent0:                 episode reward: -0.4072,                 loss: nan
agent1:                 episode reward: 0.4072,                 loss: 0.2038
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4699s / 361.1478 s
agent0:                 episode reward: 0.1170,                 loss: nan
agent1:                 episode reward: -0.1170,                 loss: 0.2004
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4479s / 362.5957 s
agent0:                 episode reward: -0.1307,                 loss: nan
agent1:                 episode reward: 0.1307,                 loss: 0.2212
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5678s / 364.1635 s
agent0:                 episode reward: -0.6664,                 loss: nan
agent1:                 episode reward: 0.6664,                 loss: 0.2222
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5132s / 365.6766 s
agent0:                 episode reward: -0.7949,                 loss: nan
agent1:                 episode reward: 0.7949,                 loss: 0.2213
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4608s / 367.1374 s
agent0:                 episode reward: -1.0995,                 loss: nan
agent1:                 episode reward: 1.0995,                 loss: 0.2231
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4476s / 368.5850 s
agent0:                 episode reward: -0.2464,                 loss: nan
agent1:                 episode reward: 0.2464,                 loss: 0.2213
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4849s / 370.0699 s
agent0:                 episode reward: -0.8505,                 loss: nan
agent1:                 episode reward: 0.8505,                 loss: 0.2382
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4626s / 371.5325 s
agent0:                 episode reward: -0.2424,                 loss: nan
agent1:                 episode reward: 0.2424,                 loss: 0.2382
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4767s / 373.0092 s
agent0:                 episode reward: -0.6934,                 loss: nan
agent1:                 episode reward: 0.6934,                 loss: 0.2381
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4592s / 374.4685 s
agent0:                 episode reward: -0.0520,                 loss: nan
agent1:                 episode reward: 0.0520,                 loss: 0.2370
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5614s / 376.0299 s
agent0:                 episode reward: -0.5613,                 loss: nan
agent1:                 episode reward: 0.5613,                 loss: 0.2378
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4922s / 377.5221 s
agent0:                 episode reward: -0.6476,                 loss: nan
agent1:                 episode reward: 0.6476,                 loss: 0.2567
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4757s / 378.9977 s
agent0:                 episode reward: -0.6772,                 loss: nan
agent1:                 episode reward: 0.6772,                 loss: 0.2553
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4826s / 380.4804 s
agent0:                 episode reward: -0.3896,                 loss: nan
agent1:                 episode reward: 0.3896,                 loss: 0.2550
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5065s / 381.9869 s
agent0:                 episode reward: -0.5519,                 loss: nan
agent1:                 episode reward: 0.5519,                 loss: 0.2567
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4912s / 383.4781 s
agent0:                 episode reward: -1.1533,                 loss: nan
agent1:                 episode reward: 1.1533,                 loss: 0.2553
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5024s / 384.9805 s
agent0:                 episode reward: -0.7516,                 loss: nan
agent1:                 episode reward: 0.7516,                 loss: 0.2911
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5676s / 386.5481 s
agent0:                 episode reward: -0.2276,                 loss: nan
agent1:                 episode reward: 0.2276,                 loss: 0.2913
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5147s / 388.0628 s
agent0:                 episode reward: -0.5467,                 loss: nan
agent1:                 episode reward: 0.5467,                 loss: 0.2920
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5100s / 389.5727 s
agent0:                 episode reward: -0.6532,                 loss: nan
agent1:                 episode reward: 0.6532,                 loss: 0.2920
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5040s / 391.0768 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.2913
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5101s / 392.5869 s
agent0:                 episode reward: -0.7729,                 loss: nan
agent1:                 episode reward: 0.7729,                 loss: 0.3348
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5345s / 394.1213 s
agent0:                 episode reward: 0.0931,                 loss: nan
agent1:                 episode reward: -0.0931,                 loss: 0.3367
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5148s / 395.6361 s
agent0:                 episode reward: -0.3214,                 loss: nan
agent1:                 episode reward: 0.3214,                 loss: 0.3359
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5755s / 397.2117 s
agent0:                 episode reward: -0.9968,                 loss: nan
agent1:                 episode reward: 0.9968,                 loss: 0.3348
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5132s / 398.7248 s
agent0:                 episode reward: -1.0916,                 loss: nan
agent1:                 episode reward: 1.0916,                 loss: 0.3338
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5257s / 400.2505 s
agent0:                 episode reward: 0.0315,                 loss: nan
agent1:                 episode reward: -0.0315,                 loss: 0.3180
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5169s / 401.7674 s
agent0:                 episode reward: -0.2206,                 loss: nan
agent1:                 episode reward: 0.2206,                 loss: 0.3113
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5348s / 403.3022 s
agent0:                 episode reward: -0.2531,                 loss: nan
agent1:                 episode reward: 0.2531,                 loss: 0.3112
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5289s / 404.8311 s
agent0:                 episode reward: -0.6018,                 loss: nan
agent1:                 episode reward: 0.6018,                 loss: 0.3104
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5520s / 406.3831 s
agent0:                 episode reward: -1.0637,                 loss: nan
agent1:                 episode reward: 1.0637,                 loss: 0.3088
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5844s / 407.9675 s
agent0:                 episode reward: -0.8366,                 loss: nan
agent1:                 episode reward: 0.8366,                 loss: 0.2664
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5394s / 409.5069 s
agent0:                 episode reward: -0.1599,                 loss: nan
agent1:                 episode reward: 0.1599,                 loss: 0.2542
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5591s / 411.0660 s
agent0:                 episode reward: -0.4339,                 loss: nan
agent1:                 episode reward: 0.4339,                 loss: 0.2565
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5328s / 412.5987 s
agent0:                 episode reward: -0.4893,                 loss: nan
agent1:                 episode reward: 0.4893,                 loss: 0.2561
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5529s / 414.1516 s
agent0:                 episode reward: -0.5635,                 loss: nan
agent1:                 episode reward: 0.5635,                 loss: 0.2557
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5489s / 415.7005 s
agent0:                 episode reward: -0.3094,                 loss: nan
agent1:                 episode reward: 0.3094,                 loss: 0.2229
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5968s / 417.2973 s
agent0:                 episode reward: 0.3998,                 loss: nan
agent1:                 episode reward: -0.3998,                 loss: 0.2160
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5686s / 418.8659 s
agent0:                 episode reward: -0.3558,                 loss: nan
agent1:                 episode reward: 0.3558,                 loss: 0.2146
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5599s / 420.4258 s
agent0:                 episode reward: -1.1294,                 loss: nan
agent1:                 episode reward: 1.1294,                 loss: 0.2162
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5545s / 421.9803 s
agent0:                 episode reward: -0.5501,                 loss: nan
agent1:                 episode reward: 0.5501,                 loss: 0.2153
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5740s / 423.5543 s
agent0:                 episode reward: -0.2047,                 loss: nan
agent1:                 episode reward: 0.2047,                 loss: 0.2054
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5566s / 425.1109 s
agent0:                 episode reward: -0.0982,                 loss: nan
agent1:                 episode reward: 0.0982,                 loss: 0.2016
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5765s / 426.6874 s
agent0:                 episode reward: -0.4681,                 loss: nan
agent1:                 episode reward: 0.4681,                 loss: 0.2005
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6503s / 428.3377 s
agent0:                 episode reward: -0.7846,                 loss: nan
agent1:                 episode reward: 0.7846,                 loss: 0.2016
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5760s / 429.9137 s
agent0:                 episode reward: -0.8134,                 loss: nan
agent1:                 episode reward: 0.8134,                 loss: 0.1996
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5830s / 431.4967 s
agent0:                 episode reward: -0.5134,                 loss: nan
agent1:                 episode reward: 0.5134,                 loss: 0.2085
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5838s / 433.0805 s
agent0:                 episode reward: -0.7420,                 loss: nan
agent1:                 episode reward: 0.7420,                 loss: 0.2110
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5829s / 434.6634 s
agent0:                 episode reward: 0.0382,                 loss: nan
agent1:                 episode reward: -0.0382,                 loss: 0.2106
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6072s / 436.2706 s
agent0:                 episode reward: -0.7954,                 loss: nan
agent1:                 episode reward: 0.7954,                 loss: 0.2091
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6305s / 437.9011 s
agent0:                 episode reward: -1.0652,                 loss: nan
agent1:                 episode reward: 1.0652,                 loss: 0.2097
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5905s / 439.4916 s
agent0:                 episode reward: 0.3635,                 loss: nan
agent1:                 episode reward: -0.3635,                 loss: 0.2160
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5886s / 441.0803 s
agent0:                 episode reward: -0.0740,                 loss: nan
agent1:                 episode reward: 0.0740,                 loss: 0.2158
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5924s / 442.6727 s
agent0:                 episode reward: -0.1841,                 loss: nan
agent1:                 episode reward: 0.1841,                 loss: 0.2157
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6515s / 444.3242 s
agent0:                 episode reward: -0.6555,                 loss: nan
agent1:                 episode reward: 0.6555,                 loss: 0.2158
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5894s / 445.9136 s
agent0:                 episode reward: -0.1898,                 loss: nan
agent1:                 episode reward: 0.1898,                 loss: 0.2167
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6511s / 447.5647 s
agent0:                 episode reward: -0.4203,                 loss: nan
agent1:                 episode reward: 0.4203,                 loss: 0.2327
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6302s / 449.1949 s
agent0:                 episode reward: -0.7672,                 loss: nan
agent1:                 episode reward: 0.7672,                 loss: 0.2366
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6102s / 450.8051 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.2347
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6419s / 452.4470 s
agent0:                 episode reward: -1.1813,                 loss: nan
agent1:                 episode reward: 1.1813,                 loss: 0.2328
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6224s / 454.0694 s
agent0:                 episode reward: -0.6872,                 loss: nan
agent1:                 episode reward: 0.6872,                 loss: 0.2361
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6082s / 455.6776 s
agent0:                 episode reward: -0.6264,                 loss: nan
agent1:                 episode reward: 0.6264,                 loss: 0.2517
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6247s / 457.3023 s
agent0:                 episode reward: -0.7165,                 loss: nan
agent1:                 episode reward: 0.7165,                 loss: 0.2513
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6659s / 458.9682 s
agent0:                 episode reward: -0.8045,                 loss: nan
agent1:                 episode reward: 0.8045,                 loss: 0.2505
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6366s / 460.6048 s
agent0:                 episode reward: 0.5900,                 loss: nan
agent1:                 episode reward: -0.5900,                 loss: 0.2534
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6545s / 462.2593 s
agent0:                 episode reward: -0.2345,                 loss: nan
agent1:                 episode reward: 0.2345,                 loss: 0.2531
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6337s / 463.8930 s
agent0:                 episode reward: -0.6406,                 loss: nan
agent1:                 episode reward: 0.6406,                 loss: 0.2848
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6257s / 465.5188 s
agent0:                 episode reward: -0.1082,                 loss: nan
agent1:                 episode reward: 0.1082,                 loss: 0.2846
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6373s / 467.1560 s
agent0:                 episode reward: -1.1965,                 loss: nan
agent1:                 episode reward: 1.1965,                 loss: 0.2853
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7075s / 468.8636 s
agent0:                 episode reward: -0.2882,                 loss: nan
agent1:                 episode reward: 0.2882,                 loss: 0.2835
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6577s / 470.5213 s
agent0:                 episode reward: 0.3762,                 loss: nan
agent1:                 episode reward: -0.3762,                 loss: 0.2839
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6568s / 472.1781 s
agent0:                 episode reward: -0.7983,                 loss: nan
agent1:                 episode reward: 0.7983,                 loss: 0.3176
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6308s / 473.8088 s
agent0:                 episode reward: -0.9116,                 loss: nan
agent1:                 episode reward: 0.9116,                 loss: 0.3175
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6543s / 475.4631 s
agent0:                 episode reward: -0.7696,                 loss: nan
agent1:                 episode reward: 0.7696,                 loss: 0.3162
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7014s / 477.1646 s
agent0:                 episode reward: -0.1121,                 loss: nan
agent1:                 episode reward: 0.1121,                 loss: 0.3167
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7068s / 478.8714 s
agent0:                 episode reward: -0.8388,                 loss: nan
agent1:                 episode reward: 0.8388,                 loss: 0.3175
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6607s / 480.5321 s
agent0:                 episode reward: -1.4421,                 loss: nan
agent1:                 episode reward: 1.4421,                 loss: 0.3185
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6668s / 482.1989 s
agent0:                 episode reward: -1.3664,                 loss: nan
agent1:                 episode reward: 1.3664,                 loss: 0.3147
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7093s / 483.9082 s
agent0:                 episode reward: -0.4040,                 loss: nan
agent1:                 episode reward: 0.4040,                 loss: 0.3139
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6841s / 485.5923 s
agent0:                 episode reward: -0.9846,                 loss: nan
agent1:                 episode reward: 0.9846,                 loss: 0.3132
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7087s / 487.3009 s
agent0:                 episode reward: -0.7469,                 loss: nan
agent1:                 episode reward: 0.7469,                 loss: 0.3130
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7584s / 489.0594 s
agent0:                 episode reward: -0.1846,                 loss: nan
agent1:                 episode reward: 0.1846,                 loss: 0.2552
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6756s / 490.7350 s
agent0:                 episode reward: -0.4526,                 loss: nan
agent1:                 episode reward: 0.4526,                 loss: 0.2383
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6738s / 492.4088 s
agent0:                 episode reward: -0.2421,                 loss: nan
agent1:                 episode reward: 0.2421,                 loss: 0.2402
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7018s / 494.1106 s
agent0:                 episode reward: -0.2033,                 loss: nan
agent1:                 episode reward: 0.2033,                 loss: 0.2387
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6841s / 495.7946 s
agent0:                 episode reward: -0.2164,                 loss: nan
agent1:                 episode reward: 0.2164,                 loss: 0.2369
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6891s / 497.4838 s
agent0:                 episode reward: -0.3737,                 loss: nan
agent1:                 episode reward: 0.3737,                 loss: 0.1925
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7426s / 499.2264 s
agent0:                 episode reward: -1.1574,                 loss: nan
agent1:                 episode reward: 1.1574,                 loss: 0.1801
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6910s / 500.9173 s
agent0:                 episode reward: -0.9900,                 loss: nan
agent1:                 episode reward: 0.9900,                 loss: 0.1794
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7275s / 502.6448 s
agent0:                 episode reward: -0.4382,                 loss: nan
agent1:                 episode reward: 0.4382,                 loss: 0.1784
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7174s / 504.3622 s
agent0:                 episode reward: -0.6164,                 loss: nan
agent1:                 episode reward: 0.6164,                 loss: 0.1780
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6921s / 506.0543 s
agent0:                 episode reward: -0.3362,                 loss: nan
agent1:                 episode reward: 0.3362,                 loss: 0.1762
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7986s / 507.8529 s
agent0:                 episode reward: -0.3060,                 loss: nan
agent1:                 episode reward: 0.3060,                 loss: 0.1748
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8448s / 509.6978 s
agent0:                 episode reward: 0.0022,                 loss: nan
agent1:                 episode reward: -0.0022,                 loss: 0.1739
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7324s / 511.4302 s
agent0:                 episode reward: -0.7265,                 loss: nan
agent1:                 episode reward: 0.7265,                 loss: 0.1725
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7157s / 513.1459 s
agent0:                 episode reward: -0.5903,                 loss: nan
agent1:                 episode reward: 0.5903,                 loss: 0.1720
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7292s / 514.8751 s
agent0:                 episode reward: -0.6339,                 loss: nan
agent1:                 episode reward: 0.6339,                 loss: 0.2038
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7316s / 516.6067 s
agent0:                 episode reward: -0.6832,                 loss: nan
agent1:                 episode reward: 0.6832,                 loss: 0.2062
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7334s / 518.3401 s
agent0:                 episode reward: -0.8754,                 loss: nan
agent1:                 episode reward: 0.8754,                 loss: 0.2045
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7957s / 520.1358 s
agent0:                 episode reward: -0.9533,                 loss: nan
agent1:                 episode reward: 0.9533,                 loss: 0.2051
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7395s / 521.8753 s
agent0:                 episode reward: -0.6837,                 loss: nan
agent1:                 episode reward: 0.6837,                 loss: 0.2007
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7368s / 523.6121 s
agent0:                 episode reward: -0.9384,                 loss: nan
agent1:                 episode reward: 0.9384,                 loss: 0.2271
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7311s / 525.3432 s
agent0:                 episode reward: -0.7983,                 loss: nan
agent1:                 episode reward: 0.7983,                 loss: 0.2300
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7420s / 527.0852 s
agent0:                 episode reward: -0.4393,                 loss: nan
agent1:                 episode reward: 0.4393,                 loss: 0.2282
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7606s / 528.8458 s
agent0:                 episode reward: -1.0313,                 loss: nan
agent1:                 episode reward: 1.0313,                 loss: 0.2285
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7791s / 530.6248 s
agent0:                 episode reward: -0.2074,                 loss: nan
agent1:                 episode reward: 0.2074,                 loss: 0.2285
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7389s / 532.3637 s
agent0:                 episode reward: -1.2422,                 loss: nan
agent1:                 episode reward: 1.2422,                 loss: 0.2358
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7488s / 534.1125 s
agent0:                 episode reward: -0.2637,                 loss: nan
agent1:                 episode reward: 0.2637,                 loss: 0.2358
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7634s / 535.8759 s
agent0:                 episode reward: -0.8939,                 loss: nan
agent1:                 episode reward: 0.8939,                 loss: 0.2357
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7597s / 537.6356 s
agent0:                 episode reward: -0.5656,                 loss: nan
agent1:                 episode reward: 0.5656,                 loss: 0.2368
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7738s / 539.4094 s
agent0:                 episode reward: -0.7340,                 loss: nan
agent1:                 episode reward: 0.7340,                 loss: 0.2347
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8278s / 541.2372 s
agent0:                 episode reward: -0.7276,                 loss: nan
agent1:                 episode reward: 0.7276,                 loss: 0.2519
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7851s / 543.0222 s
agent0:                 episode reward: -0.8378,                 loss: nan
agent1:                 episode reward: 0.8378,                 loss: 0.2544
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8073s / 544.8296 s
agent0:                 episode reward: -0.9126,                 loss: nan
agent1:                 episode reward: 0.9126,                 loss: 0.2548
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7945s / 546.6241 s
agent0:                 episode reward: -0.1866,                 loss: nan
agent1:                 episode reward: 0.1866,                 loss: 0.2512
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7756s / 548.3997 s
agent0:                 episode reward: -0.3069,                 loss: nan
agent1:                 episode reward: 0.3069,                 loss: 0.2541
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8210s / 550.2207 s
agent0:                 episode reward: -0.4051,                 loss: nan
agent1:                 episode reward: 0.4051,                 loss: 0.2777
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7835s / 552.0042 s
agent0:                 episode reward: -0.9429,                 loss: nan
agent1:                 episode reward: 0.9429,                 loss: 0.2811
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7911s / 553.7953 s
agent0:                 episode reward: -0.0708,                 loss: nan
agent1:                 episode reward: 0.0708,                 loss: 0.2812
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7997s / 555.5950 s
agent0:                 episode reward: -0.7447,                 loss: nan
agent1:                 episode reward: 0.7447,                 loss: 0.2811
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7992s / 557.3943 s
agent0:                 episode reward: -0.7892,                 loss: nan
agent1:                 episode reward: 0.7892,                 loss: 0.2788
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8032s / 559.1974 s
agent0:                 episode reward: -0.4081,                 loss: nan
agent1:                 episode reward: 0.4081,                 loss: 0.3034
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8727s / 561.0701 s
agent0:                 episode reward: -0.5980,                 loss: nan
agent1:                 episode reward: 0.5980,                 loss: 0.3087
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8086s / 562.8787 s
agent0:                 episode reward: -1.1512,                 loss: nan
agent1:                 episode reward: 1.1512,                 loss: 0.3076
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8085s / 564.6872 s
agent0:                 episode reward: -1.0493,                 loss: nan
agent1:                 episode reward: 1.0493,                 loss: 0.3071
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8281s / 566.5153 s
agent0:                 episode reward: -0.8178,                 loss: nan
agent1:                 episode reward: 0.8178,                 loss: 0.3090
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9015s / 568.4168 s
agent0:                 episode reward: -0.7353,                 loss: nan
agent1:                 episode reward: 0.7353,                 loss: 0.3259
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8611s / 570.2779 s
agent0:                 episode reward: -0.7021,                 loss: nan
agent1:                 episode reward: 0.7021,                 loss: 0.3278
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8357s / 572.1136 s
agent0:                 episode reward: -0.3547,                 loss: nan
agent1:                 episode reward: 0.3547,                 loss: 0.3268
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8214s / 573.9350 s
agent0:                 episode reward: -0.3012,                 loss: nan
agent1:                 episode reward: 0.3012,                 loss: 0.3252
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8518s / 575.7868 s
agent0:                 episode reward: -0.5288,                 loss: nan
agent1:                 episode reward: 0.5288,                 loss: 0.3276
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8646s / 577.6514 s
agent0:                 episode reward: -0.5802,                 loss: nan
agent1:                 episode reward: 0.5802,                 loss: 0.3158
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8602s / 579.5116 s
agent0:                 episode reward: -0.2396,                 loss: nan
agent1:                 episode reward: 0.2396,                 loss: 0.3115
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8975s / 581.4090 s
agent0:                 episode reward: -1.2768,                 loss: nan
agent1:                 episode reward: 1.2768,                 loss: 0.3113
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8598s / 583.2688 s
agent0:                 episode reward: -0.6044,                 loss: nan
agent1:                 episode reward: 0.6044,                 loss: 0.3127
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8641s / 585.1329 s
agent0:                 episode reward: -0.8497,                 loss: nan
agent1:                 episode reward: 0.8497,                 loss: 0.3120
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8550s / 586.9879 s
agent0:                 episode reward: -0.2908,                 loss: nan
agent1:                 episode reward: 0.2908,                 loss: 0.2560
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8581s / 588.8461 s
agent0:                 episode reward: -0.6200,                 loss: nan
agent1:                 episode reward: 0.6200,                 loss: 0.2427
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8486s / 590.6947 s
agent0:                 episode reward: -0.2876,                 loss: nan
agent1:                 episode reward: 0.2876,                 loss: 0.2421
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9172s / 592.6118 s
agent0:                 episode reward: -0.8986,                 loss: nan
agent1:                 episode reward: 0.8986,                 loss: 0.2415
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8870s / 594.4989 s
agent0:                 episode reward: -0.6931,                 loss: nan
agent1:                 episode reward: 0.6931,                 loss: 0.2412
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8844s / 596.3833 s
agent0:                 episode reward: -1.1439,                 loss: nan
agent1:                 episode reward: 1.1439,                 loss: 0.2098
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8958s / 598.2791 s
agent0:                 episode reward: -1.2098,                 loss: nan
agent1:                 episode reward: 1.2098,                 loss: 0.2043
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8871s / 600.1661 s
agent0:                 episode reward: -1.2572,                 loss: nan
agent1:                 episode reward: 1.2572,                 loss: 0.2059
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9511s / 602.1172 s
agent0:                 episode reward: -0.8358,                 loss: nan
agent1:                 episode reward: 0.8358,                 loss: 0.2042
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9113s / 604.0285 s
agent0:                 episode reward: -0.6157,                 loss: nan
agent1:                 episode reward: 0.6157,                 loss: 0.2049
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8716s / 605.9001 s
agent0:                 episode reward: -0.9776,                 loss: nan
agent1:                 episode reward: 0.9776,                 loss: 0.1990
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9050s / 607.8051 s
agent0:                 episode reward: -0.5925,                 loss: nan
agent1:                 episode reward: 0.5925,                 loss: 0.1950
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9173s / 609.7224 s
agent0:                 episode reward: -0.9047,                 loss: nan
agent1:                 episode reward: 0.9047,                 loss: 0.1972
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9475s / 611.6700 s
agent0:                 episode reward: -0.8595,                 loss: nan
agent1:                 episode reward: 0.8595,                 loss: 0.1949
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8860s / 613.5560 s
agent0:                 episode reward: -0.0942,                 loss: nan
agent1:                 episode reward: 0.0942,                 loss: 0.1955
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9176s / 615.4736 s
agent0:                 episode reward: -0.2853,                 loss: nan
agent1:                 episode reward: 0.2853,                 loss: 0.2097
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9107s / 617.3843 s
agent0:                 episode reward: -0.8587,                 loss: nan
agent1:                 episode reward: 0.8587,                 loss: 0.2094
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9483s / 619.3326 s
agent0:                 episode reward: -0.4462,                 loss: nan
agent1:                 episode reward: 0.4462,                 loss: 0.2090
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9234s / 621.2560 s
agent0:                 episode reward: -0.2706,                 loss: nan
agent1:                 episode reward: 0.2706,                 loss: 0.2108
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9511s / 623.2071 s
agent0:                 episode reward: -0.0590,                 loss: nan
agent1:                 episode reward: 0.0590,                 loss: 0.2078
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9188s / 625.1259 s
agent0:                 episode reward: -0.7763,                 loss: nan
agent1:                 episode reward: 0.7763,                 loss: 0.2225
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9298s / 627.0557 s
agent0:                 episode reward: -0.5361,                 loss: nan
agent1:                 episode reward: 0.5361,                 loss: 0.2192
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9338s / 628.9894 s
agent0:                 episode reward: -0.7603,                 loss: nan
agent1:                 episode reward: 0.7603,                 loss: 0.2204
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9446s / 630.9341 s
agent0:                 episode reward: -0.6831,                 loss: nan
agent1:                 episode reward: 0.6831,                 loss: 0.2193
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0067s / 632.9407 s
agent0:                 episode reward: -0.3299,                 loss: nan
agent1:                 episode reward: 0.3299,                 loss: 0.2199/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9760s / 634.9168 s
agent0:                 episode reward: -0.2869,                 loss: nan
agent1:                 episode reward: 0.2869,                 loss: 0.2393
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9990s / 636.9158 s
agent0:                 episode reward: -1.4433,                 loss: nan
agent1:                 episode reward: 1.4433,                 loss: 0.2419
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9857s / 638.9014 s
agent0:                 episode reward: -0.0881,                 loss: nan
agent1:                 episode reward: 0.0881,                 loss: 0.2382
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9624s / 640.8638 s
agent0:                 episode reward: -0.5846,                 loss: nan
agent1:                 episode reward: 0.5846,                 loss: 0.2391
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9942s / 642.8580 s
agent0:                 episode reward: -1.0387,                 loss: nan
agent1:                 episode reward: 1.0387,                 loss: 0.2389
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9772s / 644.8353 s
agent0:                 episode reward: -0.5320,                 loss: nan
agent1:                 episode reward: 0.5320,                 loss: 0.2633
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9688s / 646.8040 s
agent0:                 episode reward: 0.0406,                 loss: nan
agent1:                 episode reward: -0.0406,                 loss: 0.2656
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9769s / 648.7809 s
agent0:                 episode reward: -0.6296,                 loss: nan
agent1:                 episode reward: 0.6296,                 loss: 0.2646
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9797s / 650.7606 s
agent0:                 episode reward: -0.8464,                 loss: nan
agent1:                 episode reward: 0.8464,                 loss: 0.2635
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0442s / 652.8048 s
agent0:                 episode reward: -0.5338,                 loss: nan
agent1:                 episode reward: 0.5338,                 loss: 0.2638
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9882s / 654.7930 s
agent0:                 episode reward: -1.1020,                 loss: nan
agent1:                 episode reward: 1.1020,                 loss: 0.2899
