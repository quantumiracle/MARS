pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [23, 24]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=18, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 100000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220411_2111/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220411_2111/pettingzoo_boxing_v1_nash_dqn.
Episode: 1/100000 (0.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 19.5491s / 19.5491 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0075
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/100000 (0.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 664.2355s / 683.7846 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0057
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 41/100000 (0.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 668.9388s / 1352.7234 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0055
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 61/100000 (0.0610%),                 avg. length: 299.0,                last time consumption/overall running time: 666.2164s / 2018.9398 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0053
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 81/100000 (0.0810%),                 avg. length: 299.0,                last time consumption/overall running time: 668.2162s / 2687.1559 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0051
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 101/100000 (0.1010%),                 avg. length: 299.0,                last time consumption/overall running time: 671.1365s / 3358.2925 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0049
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 121/100000 (0.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 673.2477s / 4031.5402 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0056
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 141/100000 (0.1410%),                 avg. length: 299.0,                last time consumption/overall running time: 673.1387s / 4704.6788 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0051
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 161/100000 (0.1610%),                 avg. length: 299.0,                last time consumption/overall running time: 675.8291s / 5380.5079 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0047
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 181/100000 (0.1810%),                 avg. length: 299.0,                last time consumption/overall running time: 677.6502s / 6058.1581 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0045
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 201/100000 (0.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 682.5734s / 6740.7315 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0043
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 221/100000 (0.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 681.2989s / 7422.0304 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 241/100000 (0.2410%),                 avg. length: 299.0,                last time consumption/overall running time: 683.2412s / 8105.2716 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0046
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 261/100000 (0.2610%),                 avg. length: 299.0,                last time consumption/overall running time: 686.7988s / 8792.0704 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0040
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 281/100000 (0.2810%),                 avg. length: 299.0,                last time consumption/overall running time: 687.8127s / 9479.8831 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0043
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 301/100000 (0.3010%),                 avg. length: 299.0,                last time consumption/overall running time: 689.8788s / 10169.7619 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0040
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 321/100000 (0.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 692.5312s / 10862.2931 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0041
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 341/100000 (0.3410%),                 avg. length: 299.0,                last time consumption/overall running time: 693.9103s / 11556.2034 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0039
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 361/100000 (0.3610%),                 avg. length: 299.0,                last time consumption/overall running time: 697.8578s / 12254.0612 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0038
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 381/100000 (0.3810%),                 avg. length: 299.0,                last time consumption/overall running time: 699.5941s / 12953.6552 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0038
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 401/100000 (0.4010%),                 avg. length: 299.0,                last time consumption/overall running time: 699.8019s / 13653.4571 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0037
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 421/100000 (0.4210%),                 avg. length: 299.0,                last time consumption/overall running time: 696.3536s / 14349.8107 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0041
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 441/100000 (0.4410%),                 avg. length: 299.0,                last time consumption/overall running time: 696.1461s / 15045.9568 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0043
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 461/100000 (0.4610%),                 avg. length: 299.0,                last time consumption/overall running time: 694.9717s / 15740.9285 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0045
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 481/100000 (0.4810%),                 avg. length: 299.0,                last time consumption/overall running time: 697.0671s / 16437.9956 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0045
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 501/100000 (0.5010%),                 avg. length: 299.0,                last time consumption/overall running time: 695.4407s / 17133.4363 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0047
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 521/100000 (0.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 696.5337s / 17829.9700 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0045
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 541/100000 (0.5410%),                 avg. length: 299.0,                last time consumption/overall running time: 714.8529s / 18544.8229 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0045
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 561/100000 (0.5610%),                 avg. length: 299.0,                last time consumption/overall running time: 698.1284s / 19242.9513 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0047
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 581/100000 (0.5810%),                 avg. length: 299.0,                last time consumption/overall running time: 696.1163s / 19939.0676 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0048
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 601/100000 (0.6010%),                 avg. length: 299.0,                last time consumption/overall running time: 698.4276s / 20637.4952 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0046
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 621/100000 (0.6210%),                 avg. length: 299.0,                last time consumption/overall running time: 699.2305s / 21336.7257 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0047
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 641/100000 (0.6410%),                 avg. length: 299.0,                last time consumption/overall running time: 702.6499s / 22039.3756 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0049
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 661/100000 (0.6610%),                 avg. length: 299.0,                last time consumption/overall running time: 699.8647s / 22739.2402 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0052
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 681/100000 (0.6810%),                 avg. length: 299.0,                last time consumption/overall running time: 697.8328s / 23437.0731 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0056
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 701/100000 (0.7010%),                 avg. length: 299.0,                last time consumption/overall running time: 699.4274s / 24136.5005 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 721/100000 (0.7210%),                 avg. length: 299.0,                last time consumption/overall running time: 699.5434s / 24836.0438 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0057
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 741/100000 (0.7410%),                 avg. length: 299.0,                last time consumption/overall running time: 696.5922s / 25532.6360 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0062
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 761/100000 (0.7610%),                 avg. length: 299.0,                last time consumption/overall running time: 696.1098s / 26228.7458 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0065
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 781/100000 (0.7810%),                 avg. length: 299.0,                last time consumption/overall running time: 694.1297s / 26922.8754 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0081
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 801/100000 (0.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 693.8324s / 27616.7079 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0084
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 821/100000 (0.8210%),                 avg. length: 299.0,                last time consumption/overall running time: 691.2126s / 28307.9205 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0089
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 841/100000 (0.8410%),                 avg. length: 299.0,                last time consumption/overall running time: 688.3198s / 28996.2402 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0091
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 861/100000 (0.8610%),                 avg. length: 299.0,                last time consumption/overall running time: 687.7439s / 29683.9841 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 881/100000 (0.8810%),                 avg. length: 299.0,                last time consumption/overall running time: 687.7280s / 30371.7122 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0101
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 901/100000 (0.9010%),                 avg. length: 299.0,                last time consumption/overall running time: 682.3066s / 31054.0188 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0097
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 921/100000 (0.9210%),                 avg. length: 299.0,                last time consumption/overall running time: 685.8487s / 31739.8675 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0114
env0_second_0:                 episode reward: 3.2000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 941/100000 (0.9410%),                 avg. length: 299.0,                last time consumption/overall running time: 684.5558s / 32424.4233 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0125
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 961/100000 (0.9610%),                 avg. length: 299.0,                last time consumption/overall running time: 681.9032s / 33106.3265 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 981/100000 (0.9810%),                 avg. length: 299.0,                last time consumption/overall running time: 681.0539s / 33787.3805 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0126
env0_second_0:                 episode reward: 2.1000,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1001/100000 (1.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 681.3923s / 34468.7728 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0139
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 1021/100000 (1.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 682.9087s / 35151.6815 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0153
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1041/100000 (1.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 683.2740s / 35834.9555 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0178
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1061/100000 (1.0610%),                 avg. length: 299.0,                last time consumption/overall running time: 680.4343s / 36515.3898 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0180
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1081/100000 (1.0810%),                 avg. length: 299.0,                last time consumption/overall running time: 682.1625s / 37197.5522 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0178
env0_second_0:                 episode reward: 2.7000,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 1101/100000 (1.1010%),                 avg. length: 299.0,                last time consumption/overall running time: 678.9066s / 37876.4588 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0218
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1121/100000 (1.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 677.8870s / 38554.3458 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0210
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1141/100000 (1.1410%),                 avg. length: 299.0,                last time consumption/overall running time: 678.0190s / 39232.3648 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0231
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 1161/100000 (1.1610%),                 avg. length: 299.0,                last time consumption/overall running time: 677.3238s / 39909.6886 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0250
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1181/100000 (1.1810%),                 avg. length: 299.0,                last time consumption/overall running time: 677.1001s / 40586.7887 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0232
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1201/100000 (1.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 678.6645s / 41265.4532 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0237
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1221/100000 (1.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 679.4741s / 41944.9273 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0278
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1241/100000 (1.2410%),                 avg. length: 299.0,                last time consumption/overall running time: 677.0388s / 42621.9661 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0275
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 1261/100000 (1.2610%),                 avg. length: 299.0,                last time consumption/overall running time: 678.3770s / 43300.3431 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0265
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 1281/100000 (1.2810%),                 avg. length: 299.0,                last time consumption/overall running time: 681.9331s / 43982.2762 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0247
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1301/100000 (1.3010%),                 avg. length: 299.0,                last time consumption/overall running time: 679.4388s / 44661.7150 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0307
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 1321/100000 (1.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 673.6735s / 45335.3884 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0356
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1341/100000 (1.3410%),                 avg. length: 299.0,                last time consumption/overall running time: 679.8260s / 46015.2144 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0299
env0_second_0:                 episode reward: 3.1000,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1361/100000 (1.3610%),                 avg. length: 299.0,                last time consumption/overall running time: 676.2269s / 46691.4413 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0343
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1381/100000 (1.3810%),                 avg. length: 299.0,                last time consumption/overall running time: 673.3968s / 47364.8381 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0391
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1401/100000 (1.4010%),                 avg. length: 299.0,                last time consumption/overall running time: 675.9460s / 48040.7840 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0359
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 1421/100000 (1.4210%),                 avg. length: 299.0,                last time consumption/overall running time: 674.3285s / 48715.1126 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0414
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1441/100000 (1.4410%),                 avg. length: 299.0,                last time consumption/overall running time: 675.3829s / 49390.4955 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0420
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1461/100000 (1.4610%),                 avg. length: 299.0,                last time consumption/overall running time: 673.4917s / 50063.9872 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0445
env0_second_0:                 episode reward: 2.8500,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 1481/100000 (1.4810%),                 avg. length: 299.0,                last time consumption/overall running time: 671.6285s / 50735.6156 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0499
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1501/100000 (1.5010%),                 avg. length: 299.0,                last time consumption/overall running time: 670.0056s / 51405.6213 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0504
env0_second_0:                 episode reward: 1.6000,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 1521/100000 (1.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 672.2063s / 52077.8276 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0518
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 1541/100000 (1.5410%),                 avg. length: 299.0,                last time consumption/overall running time: 672.4571s / 52750.2847 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.0532
env0_second_0:                 episode reward: 5.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1561/100000 (1.5610%),                 avg. length: 299.0,                last time consumption/overall running time: 672.6415s / 53422.9262 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0516
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 1581/100000 (1.5810%),                 avg. length: 299.0,                last time consumption/overall running time: 670.7987s / 54093.7249 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0555
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 1601/100000 (1.6010%),                 avg. length: 299.0,                last time consumption/overall running time: 669.5958s / 54763.3206 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0596
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 1621/100000 (1.6210%),                 avg. length: 299.0,                last time consumption/overall running time: 669.1553s / 55432.4759 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0572
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1641/100000 (1.6410%),                 avg. length: 299.0,                last time consumption/overall running time: 672.2682s / 56104.7441 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0552
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1661/100000 (1.6610%),                 avg. length: 299.0,                last time consumption/overall running time: 669.6773s / 56774.4215 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0626
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 1681/100000 (1.6810%),                 avg. length: 299.0,                last time consumption/overall running time: 670.3733s / 57444.7948 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0658
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1701/100000 (1.7010%),                 avg. length: 299.0,                last time consumption/overall running time: 671.6862s / 58116.4810 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0625
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 1721/100000 (1.7210%),                 avg. length: 299.0,                last time consumption/overall running time: 675.0577s / 58791.5386 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0644
env0_second_0:                 episode reward: 2.2000,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 1741/100000 (1.7410%),                 avg. length: 299.0,                last time consumption/overall running time: 666.7153s / 59458.2540 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0755
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1761/100000 (1.7610%),                 avg. length: 299.0,                last time consumption/overall running time: 665.4814s / 60123.7353 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0778
env0_second_0:                 episode reward: 4.0000,                 loss: nan
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 1781/100000 (1.7810%),                 avg. length: 299.0,                last time consumption/overall running time: 668.9350s / 60792.6703 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0749
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1801/100000 (1.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 665.4969s / 61458.1672 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0834
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 1821/100000 (1.8210%),                 avg. length: 299.0,                last time consumption/overall running time: 665.9020s / 62124.0692 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0914
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 1841/100000 (1.8410%),                 avg. length: 299.0,                last time consumption/overall running time: 665.6133s / 62789.6825 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0948
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 1861/100000 (1.8610%),                 avg. length: 299.0,                last time consumption/overall running time: 669.2458s / 63458.9283 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0931
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 1881/100000 (1.8810%),                 avg. length: 299.0,                last time consumption/overall running time: 666.9719s / 64125.9002 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0945
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1901/100000 (1.9010%),                 avg. length: 299.0,                last time consumption/overall running time: 667.6629s / 64793.5632 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0992
env0_second_0:                 episode reward: 5.3000,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 1921/100000 (1.9210%),                 avg. length: 299.0,                last time consumption/overall running time: 668.5033s / 65462.0665 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0888
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 1941/100000 (1.9410%),                 avg. length: 299.0,                last time consumption/overall running time: 664.1730s / 66126.2395 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0984
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1961/100000 (1.9610%),                 avg. length: 299.0,                last time consumption/overall running time: 665.3827s / 66791.6222 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.1005
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1981/100000 (1.9810%),                 avg. length: 299.0,                last time consumption/overall running time: 669.2183s / 67460.8405 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0963
env0_second_0:                 episode reward: 4.9500,                 loss: nan
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 2001/100000 (2.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 665.7382s / 68126.5787 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0991
env0_second_0:                 episode reward: 2.4000,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 2021/100000 (2.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 668.1762s / 68794.7550 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.1074
env0_second_0:                 episode reward: 1.8500,                 loss: nan
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 2041/100000 (2.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 667.7306s / 69462.4856 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0997
env0_second_0:                 episode reward: 4.5500,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 2061/100000 (2.0610%),                 avg. length: 299.0,                last time consumption/overall running time: 667.5048s / 70129.9904 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0897
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2081/100000 (2.0810%),                 avg. length: 299.0,                last time consumption/overall running time: 668.5378s / 70798.5282 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0935
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2101/100000 (2.1010%),                 avg. length: 299.0,                last time consumption/overall running time: 704.1090s / 71502.6372 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0982
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 2121/100000 (2.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 800.8544s / 72303.4917 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1026
env0_second_0:                 episode reward: 3.7000,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2141/100000 (2.1410%),                 avg. length: 299.0,                last time consumption/overall running time: 799.1975s / 73102.6892 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.1064
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 2161/100000 (2.1610%),                 avg. length: 299.0,                last time consumption/overall running time: 798.4671s / 73901.1563 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1131
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 2181/100000 (2.1810%),                 avg. length: 299.0,                last time consumption/overall running time: 801.6281s / 74702.7844 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.1215
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 2201/100000 (2.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 800.6541s / 75503.4385 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1170
env0_second_0:                 episode reward: 3.6000,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 2221/100000 (2.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 796.9521s / 76300.3906 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.1316
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 2241/100000 (2.2410%),                 avg. length: 299.0,                last time consumption/overall running time: 799.2523s / 77099.6429 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.1331
env0_second_0:                 episode reward: 4.6000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2261/100000 (2.2610%),                 avg. length: 299.0,                last time consumption/overall running time: 794.0730s / 77893.7159 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.1413
env0_second_0:                 episode reward: 2.2500,                 loss: nan
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 2281/100000 (2.2810%),                 avg. length: 299.0,                last time consumption/overall running time: 794.7573s / 78688.4732 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.1506
env0_second_0:                 episode reward: 3.0000,                 loss: nan
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 2301/100000 (2.3010%),                 avg. length: 299.0,                last time consumption/overall running time: 790.4728s / 79478.9460 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.1482
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 2321/100000 (2.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 793.9300s / 80272.8760 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.1389
env0_second_0:                 episode reward: 2.6500,                 loss: nan
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 2341/100000 (2.3410%),                 avg. length: 299.0,                last time consumption/overall running time: 793.9601s / 81066.8361 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1387
env0_second_0:                 episode reward: 4.2500,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 2361/100000 (2.3610%),                 avg. length: 299.0,                last time consumption/overall running time: 788.5058s / 81855.3419 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.1505
env0_second_0:                 episode reward: 2.1500,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 2381/100000 (2.3810%),                 avg. length: 299.0,                last time consumption/overall running time: 791.3727s / 82646.7146 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.1467
env0_second_0:                 episode reward: 1.3000,                 loss: nan
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 2401/100000 (2.4010%),                 avg. length: 299.0,                last time consumption/overall running time: 788.3198s / 83435.0344 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1558
env0_second_0:                 episode reward: 4.1500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2421/100000 (2.4210%),                 avg. length: 299.0,                last time consumption/overall running time: 789.0962s / 84224.1305 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.1597
env0_second_0:                 episode reward: 3.1500,                 loss: nan
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 2441/100000 (2.4410%),                 avg. length: 299.0,                last time consumption/overall running time: 789.3926s / 85013.5231 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1688
env0_second_0:                 episode reward: 3.5000,                 loss: nan
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 2461/100000 (2.4610%),                 avg. length: 299.0,                last time consumption/overall running time: 786.8208s / 85800.3440 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1770
env0_second_0:                 episode reward: 3.8500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2481/100000 (2.4810%),                 avg. length: 299.0,                last time consumption/overall running time: 787.3988s / 86587.7428 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.1865
env0_second_0:                 episode reward: 5.7500,                 loss: nan
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 2501/100000 (2.5010%),                 avg. length: 299.0,                last time consumption/overall running time: 789.3431s / 87377.0859 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.1714
env0_second_0:                 episode reward: 4.5500,                 loss: nan
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 2521/100000 (2.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 786.2820s / 88163.3679 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1805
env0_second_0:                 episode reward: 3.5500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2541/100000 (2.5410%),                 avg. length: 299.0,                last time consumption/overall running time: 786.5807s / 88949.9486 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.1882
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 2561/100000 (2.5610%),                 avg. length: 299.0,                last time consumption/overall running time: 786.1874s / 89736.1361 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.1910
env0_second_0:                 episode reward: 8.6500,                 loss: nan
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 2581/100000 (2.5810%),                 avg. length: 299.0,                last time consumption/overall running time: 786.4242s / 90522.5603 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.2087
env0_second_0:                 episode reward: 6.7500,                 loss: nan
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 2601/100000 (2.6010%),                 avg. length: 299.0,                last time consumption/overall running time: 783.2056s / 91305.7658 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.2412
env0_second_0:                 episode reward: 5.5500,                 loss: nan
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 2621/100000 (2.6210%),                 avg. length: 299.0,                last time consumption/overall running time: 790.2523s / 92096.0181 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2419
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 2641/100000 (2.6410%),                 avg. length: 299.0,                last time consumption/overall running time: 788.5490s / 92884.5671 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.2499
env0_second_0:                 episode reward: 9.0000,                 loss: nan
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 2661/100000 (2.6610%),                 avg. length: 299.0,                last time consumption/overall running time: 785.1628s / 93669.7299 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.2390
env0_second_0:                 episode reward: 3.9000,                 loss: nan
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 2681/100000 (2.6810%),                 avg. length: 299.0,                last time consumption/overall running time: 787.5350s / 94457.2649 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.2342
env0_second_0:                 episode reward: 3.4500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2701/100000 (2.7010%),                 avg. length: 299.0,                last time consumption/overall running time: 784.4744s / 95241.7394 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.2447
env0_second_0:                 episode reward: 7.6000,                 loss: nan
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 2721/100000 (2.7210%),                 avg. length: 299.0,                last time consumption/overall running time: 782.9561s / 96024.6955 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.2532
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 2741/100000 (2.7410%),                 avg. length: 299.0,                last time consumption/overall running time: 783.4734s / 96808.1688 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.2585
env0_second_0:                 episode reward: 6.5500,                 loss: nan
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 2761/100000 (2.7610%),                 avg. length: 299.0,                last time consumption/overall running time: 786.6424s / 97594.8112 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.2557
env0_second_0:                 episode reward: 3.4500,                 loss: nan
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 2781/100000 (2.7810%),                 avg. length: 299.0,                last time consumption/overall running time: 786.0422s / 98380.8534 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.2717
env0_second_0:                 episode reward: 5.0000,                 loss: nan
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 2801/100000 (2.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 787.0850s / 99167.9384 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.2685
env0_second_0:                 episode reward: 5.1500,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 2821/100000 (2.8210%),                 avg. length: 299.0,                last time consumption/overall running time: 785.5905s / 99953.5289 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2820
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 2841/100000 (2.8410%),                 avg. length: 299.0,                last time consumption/overall running time: 788.3619s / 100741.8908 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.2802
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2861/100000 (2.8610%),                 avg. length: 299.0,                last time consumption/overall running time: 784.9486s / 101526.8393 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.2953
env0_second_0:                 episode reward: 4.3500,                 loss: nan
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 2881/100000 (2.8810%),                 avg. length: 299.0,                last time consumption/overall running time: 783.4323s / 102310.2716 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.3220
env0_second_0:                 episode reward: 7.4500,                 loss: nan
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 2901/100000 (2.9010%),                 avg. length: 299.0,                last time consumption/overall running time: 785.0184s / 103095.2900 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.3299
env0_second_0:                 episode reward: 5.2000,                 loss: nan
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 2921/100000 (2.9210%),                 avg. length: 299.0,                last time consumption/overall running time: 783.6138s / 103878.9038 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3149
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 2941/100000 (2.9410%),                 avg. length: 299.0,                last time consumption/overall running time: 787.5805s / 104666.4843 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.3251
env0_second_0:                 episode reward: 6.4000,                 loss: nan
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 2961/100000 (2.9610%),                 avg. length: 299.0,                last time consumption/overall running time: 784.3030s / 105450.7873 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3597
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 2981/100000 (2.9810%),                 avg. length: 299.0,                last time consumption/overall running time: 783.5241s / 106234.3114 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.3806
env0_second_0:                 episode reward: 3.3500,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 3001/100000 (3.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 785.7431s / 107020.0545 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.3918
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 3021/100000 (3.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 783.8112s / 107803.8657 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.4234
env0_second_0:                 episode reward: 7.9500,                 loss: nan
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 3041/100000 (3.0410%),                 avg. length: 299.0,                last time consumption/overall running time: 781.0122s / 108584.8779 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.4348
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 3061/100000 (3.0610%),                 avg. length: 299.0,                last time consumption/overall running time: 784.5711s / 109369.4490 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.4423
env0_second_0:                 episode reward: 9.1500,                 loss: nan
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 3081/100000 (3.0810%),                 avg. length: 299.0,                last time consumption/overall running time: 781.7268s / 110151.1758 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.4984
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 3101/100000 (3.1010%),                 avg. length: 299.0,                last time consumption/overall running time: 787.9659s / 110939.1417 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.5012
env0_second_0:                 episode reward: 3.3500,                 loss: nan
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 3121/100000 (3.1210%),                 avg. length: 299.0,                last time consumption/overall running time: 784.6032s / 111723.7449 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.5286
env0_second_0:                 episode reward: 6.9500,                 loss: nan
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 3141/100000 (3.1410%),                 avg. length: 299.0,                last time consumption/overall running time: 787.3032s / 112511.0481 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.5269
env0_second_0:                 episode reward: 5.0500,                 loss: nan
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 3161/100000 (3.1610%),                 avg. length: 299.0,                last time consumption/overall running time: 783.9076s / 113294.9557 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.5589
env0_second_0:                 episode reward: 7.4000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 3181/100000 (3.1810%),                 avg. length: 299.0,                last time consumption/overall running time: 783.6343s / 114078.5900 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.5748
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 3201/100000 (3.2010%),                 avg. length: 299.0,                last time consumption/overall running time: 786.3278s / 114864.9178 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.5735
env0_second_0:                 episode reward: 6.7000,                 loss: nan
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 3221/100000 (3.2210%),                 avg. length: 299.0,                last time consumption/overall running time: 784.0666s / 115648.9844 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.6061
env0_second_0:                 episode reward: 6.0000,                 loss: nan
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 3241/100000 (3.2410%),                 avg. length: 299.0,                last time consumption/overall running time: 782.6363s / 116431.6207 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.6072
env0_second_0:                 episode reward: 9.6500,                 loss: nan
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 3261/100000 (3.2610%),                 avg. length: 299.0,                last time consumption/overall running time: 783.8640s / 117215.4847 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.6737
env0_second_0:                 episode reward: 10.8500,                 loss: nan
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 3281/100000 (3.2810%),                 avg. length: 299.0,                last time consumption/overall running time: 781.6251s / 117997.1098 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.7348
env0_second_0:                 episode reward: 8.2000,                 loss: nan
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 3301/100000 (3.3010%),                 avg. length: 299.0,                last time consumption/overall running time: 782.3293s / 118779.4391 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.7468
env0_second_0:                 episode reward: 11.7000,                 loss: nan
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 3321/100000 (3.3210%),                 avg. length: 299.0,                last time consumption/overall running time: 781.5024s / 119560.9414 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.7770
env0_second_0:                 episode reward: 10.2500,                 loss: nan
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 3341/100000 (3.3410%),                 avg. length: 299.0,                last time consumption/overall running time: 775.4719s / 120336.4134 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.8102
env0_second_0:                 episode reward: 5.1500,                 loss: nan
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 3361/100000 (3.3610%),                 avg. length: 299.0,                last time consumption/overall running time: 777.2520s / 121113.6654 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.8589
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 3381/100000 (3.3810%),                 avg. length: 299.0,                last time consumption/overall running time: 767.0782s / 121880.7435 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.9196
env0_second_0:                 episode reward: 6.1500,                 loss: nan
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 3401/100000 (3.4010%),                 avg. length: 299.0,                last time consumption/overall running time: 765.9312s / 122646.6747 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.9686
env0_second_0:                 episode reward: 7.1000,                 loss: nan
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 3421/100000 (3.4210%),                 avg. length: 299.0,                last time consumption/overall running time: 765.9081s / 123412.5828 s
env0_first_0:                 episode reward: -5.5000,                 loss: 1.0063
env0_second_0:                 episode reward: 5.5000,                 loss: nan
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 3441/100000 (3.4410%),                 avg. length: 299.0,                last time consumption/overall running time: 770.3686s / 124182.9514 s
env0_first_0:                 episode reward: -8.3000,                 loss: 1.0007
env0_second_0:                 episode reward: 8.3000,                 loss: nan
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 3461/100000 (3.4610%),                 avg. length: 299.0,                last time consumption/overall running time: 769.9002s / 124952.8516 s
env0_first_0:                 episode reward: -5.7000,                 loss: 1.0527
env0_second_0:                 episode reward: 5.7000,                 loss: nan
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 3481/100000 (3.4810%),                 avg. length: 299.0,                last time consumption/overall running time: 765.6006s / 125718.4521 s
env0_first_0:                 episode reward: -7.1000,                 loss: 1.0952
env0_second_0:                 episode reward: 7.1000,                 loss: nan
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 3501/100000 (3.5010%),                 avg. length: 299.0,                last time consumption/overall running time: 765.7001s / 126484.1523 s
env0_first_0:                 episode reward: -2.3000,                 loss: 1.2487
env0_second_0:                 episode reward: 2.3000,                 loss: nan
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 3521/100000 (3.5210%),                 avg. length: 299.0,                last time consumption/overall running time: 763.4012s / 127247.5534 s
env0_first_0:                 episode reward: -10.1500,                 loss: 1.3060
env0_second_0:                 episode reward: 10.1500,                 loss: nan
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 3541/100000 (3.5410%),                 avg. length: 299.0,                last time consumption/overall running time: 763.7316s / 128011.2850 s
env0_first_0:                 episode reward: -7.9000,                 loss: 1.2280
env0_second_0:                 episode reward: 7.9000,                 loss: nan
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 3561/100000 (3.5610%),                 avg. length: 299.0,                last time consumption/overall running time: 761.7536s / 128773.0387 s
env0_first_0:                 episode reward: -7.1000,                 loss: 1.3028
env0_second_0:                 episode reward: 7.1000,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 3581/100000 (3.5810%),                 avg. length: 299.0,                last time consumption/overall running time: 757.4409s / 129530.4796 s
env0_first_0:                 episode reward: -13.9000,                 loss: 1.3219
env0_second_0:                 episode reward: 13.9000,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 3601/100000 (3.6010%),                 avg. length: 299.0,                last time consumption/overall running time: 761.4593s / 130291.9389 s
env0_first_0:                 episode reward: -8.4500,                 loss: 1.3568
env0_second_0:                 episode reward: 8.4500,                 loss: nan
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 3621/100000 (3.6210%),                 avg. length: 299.0,                last time consumption/overall running time: 763.8220s / 131055.7608 s
env0_first_0:                 episode reward: -10.2000,                 loss: 1.4162
env0_second_0:                 episode reward: 10.2000,                 loss: nan
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 3641/100000 (3.6410%),                 avg. length: 299.0,                last time consumption/overall running time: 762.0807s / 131817.8415 s
env0_first_0:                 episode reward: -3.1000,                 loss: 1.4003
env0_second_0:                 episode reward: 3.1000,                 loss: nan
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 3661/100000 (3.6610%),                 avg. length: 299.0,                last time consumption/overall running time: 760.0675s / 132577.9090 s
env0_first_0:                 episode reward: -12.0500,                 loss: 1.4502
env0_second_0:                 episode reward: 12.0500,                 loss: nan
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 3681/100000 (3.6810%),                 avg. length: 299.0,                last time consumption/overall running time: 763.4863s / 133341.3953 s
env0_first_0:                 episode reward: -7.3500,                 loss: 1.4113
env0_second_0:                 episode reward: 7.3500,                 loss: nan
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 3701/100000 (3.7010%),                 avg. length: 299.0,                last time consumption/overall running time: 764.4656s / 134105.8609 s
env0_first_0:                 episode reward: -6.0000,                 loss: 1.3520
env0_second_0:                 episode reward: 6.0000,                 loss: nan
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 3721/100000 (3.7210%),                 avg. length: 299.0,                last time consumption/overall running time: 760.7378s / 134866.5987 s
env0_first_0:                 episode reward: -6.4000,                 loss: 1.3828
env0_second_0:                 episode reward: 6.4000,                 loss: nan
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 3741/100000 (3.7410%),                 avg. length: 299.0,                last time consumption/overall running time: 755.9583s / 135622.5570 s
env0_first_0:                 episode reward: -11.8500,                 loss: 1.4295
env0_second_0:                 episode reward: 11.8500,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 3761/100000 (3.7610%),                 avg. length: 299.0,                last time consumption/overall running time: 760.5286s / 136383.0856 s
env0_first_0:                 episode reward: -7.7000,                 loss: 1.5066
env0_second_0:                 episode reward: 7.7000,                 loss: nan
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 3781/100000 (3.7810%),                 avg. length: 299.0,                last time consumption/overall running time: 762.2448s / 137145.3304 s
env0_first_0:                 episode reward: -4.2500,                 loss: 1.6531
env0_second_0:                 episode reward: 4.2500,                 loss: nan
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 3801/100000 (3.8010%),                 avg. length: 299.0,                last time consumption/overall running time: 763.0091s / 137908.3394 s
env0_first_0:                 episode reward: -2.9500,                 loss: 1.5891
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 3821/100000 (3.8210%),                 avg. length: 299.0,                last time consumption/overall running time: 762.5213s / 138670.8607 s
env0_first_0:                 episode reward: -2.3000,                 loss: 1.5029
env0_second_0:                 episode reward: 2.3000,                 loss: nan
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 3841/100000 (3.8410%),                 avg. length: 299.0,                last time consumption/overall running time: 761.0216s / 139431.8823 s
env0_first_0:                 episode reward: -7.2000,                 loss: 1.4750
env0_second_0:                 episode reward: 7.2000,                 loss: nan
env1_first_0:                 episode reward: -16.8500,                 loss: nan
env1_second_0:                 episode reward: 16.8500,                 loss: nan
Episode: 3861/100000 (3.8610%),                 avg. length: 299.0,                last time consumption/overall running time: 762.9203s / 140194.8026 s
env0_first_0:                 episode reward: -15.5500,                 loss: 1.4661
env0_second_0:                 episode reward: 15.5500,                 loss: nan
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 3881/100000 (3.8810%),                 avg. length: 299.0,                last time consumption/overall running time: 765.3834s / 140960.1860 s
env0_first_0:                 episode reward: -6.9500,                 loss: 1.5227
env0_second_0:                 episode reward: 6.9500,                 loss: nan
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 3901/100000 (3.9010%),                 avg. length: 299.0,                last time consumption/overall running time: 762.8567s / 141723.0427 s
env0_first_0:                 episode reward: -16.4500,                 loss: 1.5948
env0_second_0:                 episode reward: 16.4500,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 3921/100000 (3.9210%),                 avg. length: 299.0,                last time consumption/overall running time: 762.0198s / 142485.0625 s
env0_first_0:                 episode reward: -4.7500,                 loss: 1.5731
env0_second_0:                 episode reward: 4.7500,                 loss: nan
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 3941/100000 (3.9410%),                 avg. length: 299.0,                last time consumption/overall running time: 764.9148s / 143249.9774 s
env0_first_0:                 episode reward: -12.8500,                 loss: 1.6027
env0_second_0:                 episode reward: 12.8500,                 loss: nan
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 3961/100000 (3.9610%),                 avg. length: 299.0,                last time consumption/overall running time: 762.0342s / 144012.0115 s
env0_first_0:                 episode reward: -13.7500,                 loss: 1.7205
env0_second_0:                 episode reward: 13.7500,                 loss: nan
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 3981/100000 (3.9810%),                 avg. length: 299.0,                last time consumption/overall running time: 764.0801s / 144776.0916 s
env0_first_0:                 episode reward: -12.2500,                 loss: 1.7091
env0_second_0:                 episode reward: 12.2500,                 loss: nan
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 4001/100000 (4.0010%),                 avg. length: 299.0,                last time consumption/overall running time: 759.2600s / 145535.3517 s
env0_first_0:                 episode reward: -11.5000,                 loss: 1.6300
env0_second_0:                 episode reward: 11.5000,                 loss: nan
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 4021/100000 (4.0210%),                 avg. length: 299.0,                last time consumption/overall running time: 758.7134s / 146294.0650 s
env0_first_0:                 episode reward: -7.5000,                 loss: 1.6786
env0_second_0:                 episode reward: 7.5000,                 loss: nan
env1_first_0:                 episode reward: -5.0000,                 loss: nan