2022-05-10 16:54:35.581230: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 16:54:35.581326: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 16:54:35.581333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f646297b630>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/2000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/2000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510161908_exploit_2000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510161908_exploit_2000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0067s / 1.0067 s
agent0:                 episode reward: 0.6395,                 loss: nan
agent1:                 episode reward: -0.6395,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1734s / 1.1800 s
agent0:                 episode reward: 1.1736,                 loss: nan
agent1:                 episode reward: -1.1736,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1469s / 1.3269 s
agent0:                 episode reward: 1.2510,                 loss: nan
agent1:                 episode reward: -1.2510,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1581s / 1.4850 s
agent0:                 episode reward: 0.7126,                 loss: nan
agent1:                 episode reward: -0.7126,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8467s / 2.3317 s
agent0:                 episode reward: 0.7447,                 loss: nan
agent1:                 episode reward: -0.7447,                 loss: 0.4805
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0588s / 3.3904 s
agent0:                 episode reward: 0.8203,                 loss: nan
agent1:                 episode reward: -0.8203,                 loss: 0.4401
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7647s / 4.1552 s
agent0:                 episode reward: 1.0277,                 loss: nan
agent1:                 episode reward: -1.0277,                 loss: 0.4373
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8649s / 5.0201 s
agent0:                 episode reward: 0.6156,                 loss: nan
agent1:                 episode reward: -0.6156,                 loss: 0.4363
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9905s / 6.0105 s
agent0:                 episode reward: 0.7081,                 loss: nan
agent1:                 episode reward: -0.7081,                 loss: 0.4340
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8058s / 6.8163 s
agent0:                 episode reward: 0.3313,                 loss: nan
agent1:                 episode reward: -0.3313,                 loss: 0.4504
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8013s / 7.6176 s
agent0:                 episode reward: 0.9223,                 loss: nan
agent1:                 episode reward: -0.9223,                 loss: 0.4487
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7936s / 8.4112 s
agent0:                 episode reward: 0.7214,                 loss: nan
agent1:                 episode reward: -0.7214,                 loss: 0.4476
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7906s / 9.2017 s
agent0:                 episode reward: 1.1175,                 loss: nan
agent1:                 episode reward: -1.1175,                 loss: 0.4462
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8038s / 10.0055 s
agent0:                 episode reward: -0.1417,                 loss: nan
agent1:                 episode reward: 0.1417,                 loss: 0.4460
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9518s / 10.9573 s
agent0:                 episode reward: 0.8573,                 loss: nan
agent1:                 episode reward: -0.8573,                 loss: 0.4414
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8577s / 11.8150 s
agent0:                 episode reward: 0.8955,                 loss: nan
agent1:                 episode reward: -0.8955,                 loss: 0.4381
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8634s / 12.6784 s
agent0:                 episode reward: -0.4857,                 loss: nan
agent1:                 episode reward: 0.4857,                 loss: 0.4366
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8218s / 13.5002 s
agent0:                 episode reward: 0.9571,                 loss: nan
agent1:                 episode reward: -0.9571,                 loss: 0.4351
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8599s / 14.3601 s
agent0:                 episode reward: 0.3829,                 loss: nan
agent1:                 episode reward: -0.3829,                 loss: 0.4341
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9330s / 15.2932 s
agent0:                 episode reward: 0.9475,                 loss: nan
agent1:                 episode reward: -0.9475,                 loss: 0.4268
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8441s / 16.1372 s
agent0:                 episode reward: 0.4582,                 loss: nan
agent1:                 episode reward: -0.4582,                 loss: 0.4231
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9108s / 17.0481 s
agent0:                 episode reward: 1.3408,                 loss: nan
agent1:                 episode reward: -1.3408,                 loss: 0.4229
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8227s / 17.8707 s
agent0:                 episode reward: 0.8010,                 loss: nan
agent1:                 episode reward: -0.8010,                 loss: 0.4221
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7942s / 18.6649 s
agent0:                 episode reward: 1.0440,                 loss: nan
agent1:                 episode reward: -1.0440,                 loss: 0.4197
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8165s / 19.4814 s
agent0:                 episode reward: 0.3448,                 loss: nan
agent1:                 episode reward: -0.3448,                 loss: 0.4033
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8418s / 20.3232 s
agent0:                 episode reward: 0.6282,                 loss: nan
agent1:                 episode reward: -0.6282,                 loss: 0.3972
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9166s / 21.2398 s
agent0:                 episode reward: 0.3367,                 loss: nan
agent1:                 episode reward: -0.3367,                 loss: 0.3946
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8395s / 22.0793 s
agent0:                 episode reward: 0.9970,                 loss: nan
agent1:                 episode reward: -0.9970,                 loss: 0.3925
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8308s / 22.9101 s
agent0:                 episode reward: -0.1892,                 loss: nan
agent1:                 episode reward: 0.1892,                 loss: 0.3909
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8752s / 23.7852 s
agent0:                 episode reward: 0.7425,                 loss: nan
agent1:                 episode reward: -0.7425,                 loss: 0.3738
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8390s / 24.6243 s
agent0:                 episode reward: -0.0281,                 loss: nan
agent1:                 episode reward: 0.0281,                 loss: 0.3687
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8442s / 25.4685 s
agent0:                 episode reward: 0.5436,                 loss: nan
agent1:                 episode reward: -0.5436,                 loss: 0.3674
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8658s / 26.3342 s
agent0:                 episode reward: 0.9074,                 loss: nan
agent1:                 episode reward: -0.9074,                 loss: 0.3653
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8779s / 27.2122 s
agent0:                 episode reward: 1.0121,                 loss: nan
agent1:                 episode reward: -1.0121,                 loss: 0.3645
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8583s / 28.0705 s
agent0:                 episode reward: 0.6235,                 loss: nan
agent1:                 episode reward: -0.6235,                 loss: 0.3537
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8648s / 28.9353 s
agent0:                 episode reward: 1.4051,                 loss: nan
agent1:                 episode reward: -1.4051,                 loss: 0.3522
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8816s / 29.8169 s
agent0:                 episode reward: 0.8939,                 loss: nan
agent1:                 episode reward: -0.8939,                 loss: 0.3513
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8667s / 30.6836 s
agent0:                 episode reward: 0.2838,                 loss: nan
agent1:                 episode reward: -0.2838,                 loss: 0.3511
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9363s / 31.6198 s
agent0:                 episode reward: 0.7640,                 loss: nan
agent1:                 episode reward: -0.7640,                 loss: 0.3517
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9518s / 32.5716 s
agent0:                 episode reward: 0.6710,                 loss: nan
agent1:                 episode reward: -0.6710,                 loss: 0.3508
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8693s / 33.4409 s
agent0:                 episode reward: 0.2828,                 loss: nan
agent1:                 episode reward: -0.2828,                 loss: 0.3473
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8799s / 34.3208 s
agent0:                 episode reward: 0.4093,                 loss: nan
agent1:                 episode reward: -0.4093,                 loss: 0.3458
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8936s / 35.2144 s
agent0:                 episode reward: 0.6373,                 loss: nan
agent1:                 episode reward: -0.6373,                 loss: 0.3455
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8694s / 36.0838 s
agent0:                 episode reward: 1.6340,                 loss: nan
agent1:                 episode reward: -1.6340,                 loss: 0.3455
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9089s / 36.9926 s
agent0:                 episode reward: 0.5265,                 loss: nan
agent1:                 episode reward: -0.5265,                 loss: 0.3384
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8898s / 37.8824 s
agent0:                 episode reward: 0.2234,                 loss: nan
agent1:                 episode reward: -0.2234,                 loss: 0.3361
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8987s / 38.7811 s
agent0:                 episode reward: 0.9263,                 loss: nan
agent1:                 episode reward: -0.9263,                 loss: 0.3333
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8830s / 39.6641 s
agent0:                 episode reward: 1.0186,                 loss: nan
agent1:                 episode reward: -1.0186,                 loss: 0.3327
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9155s / 40.5796 s
agent0:                 episode reward: 0.4409,                 loss: nan
agent1:                 episode reward: -0.4409,                 loss: 0.3314
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9111s / 41.4907 s
agent0:                 episode reward: 0.3251,                 loss: nan
agent1:                 episode reward: -0.3251,                 loss: 0.3176
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9584s / 42.4491 s
agent0:                 episode reward: 0.5744,                 loss: nan
agent1:                 episode reward: -0.5744,                 loss: 0.3168
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8963s / 43.3454 s
agent0:                 episode reward: 0.2826,                 loss: nan
agent1:                 episode reward: -0.2826,                 loss: 0.3143
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9310s / 44.2763 s
agent0:                 episode reward: 0.4641,                 loss: nan
agent1:                 episode reward: -0.4641,                 loss: 0.3134
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8889s / 45.1652 s
agent0:                 episode reward: 0.4467,                 loss: nan
agent1:                 episode reward: -0.4467,                 loss: 0.3127
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9265s / 46.0917 s
agent0:                 episode reward: 1.0408,                 loss: nan
agent1:                 episode reward: -1.0408,                 loss: 0.3090
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9402s / 47.0319 s
agent0:                 episode reward: 1.1348,                 loss: nan
agent1:                 episode reward: -1.1348,                 loss: 0.3072
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9133s / 47.9452 s
agent0:                 episode reward: 0.7719,                 loss: nan
agent1:                 episode reward: -0.7719,                 loss: 0.3056
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9405s / 48.8857 s
agent0:                 episode reward: 0.1361,                 loss: nan
agent1:                 episode reward: -0.1361,                 loss: 0.3046
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9174s / 49.8031 s
agent0:                 episode reward: 0.3138,                 loss: nan
agent1:                 episode reward: -0.3138,                 loss: 0.3034
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9355s / 50.7386 s
agent0:                 episode reward: 0.9241,                 loss: nan
agent1:                 episode reward: -0.9241,                 loss: 0.3119
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9297s / 51.6683 s
agent0:                 episode reward: 0.7050,                 loss: nan
agent1:                 episode reward: -0.7050,                 loss: 0.3121
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0170s / 52.6853 s
agent0:                 episode reward: 1.0583,                 loss: nan
agent1:                 episode reward: -1.0583,                 loss: 0.3101
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9452s / 53.6306 s
agent0:                 episode reward: 0.0708,                 loss: nan
agent1:                 episode reward: -0.0708,                 loss: 0.3089
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9242s / 54.5548 s
agent0:                 episode reward: 0.5257,                 loss: nan
agent1:                 episode reward: -0.5257,                 loss: 0.3092
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9369s / 55.4917 s
agent0:                 episode reward: -0.0863,                 loss: nan
agent1:                 episode reward: 0.0863,                 loss: 0.3223
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9350s / 56.4266 s
agent0:                 episode reward: -0.3440,                 loss: nan
agent1:                 episode reward: 0.3440,                 loss: 0.3228
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9836s / 57.4103 s
agent0:                 episode reward: 0.5702,                 loss: nan
agent1:                 episode reward: -0.5702,                 loss: 0.3224
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9435s / 58.3538 s
agent0:                 episode reward: 0.2142,                 loss: nan
agent1:                 episode reward: -0.2142,                 loss: 0.3215
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9577s / 59.3115 s
agent0:                 episode reward: 0.5347,                 loss: nan
agent1:                 episode reward: -0.5347,                 loss: 0.3197
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9521s / 60.2635 s
agent0:                 episode reward: 0.4703,                 loss: nan
agent1:                 episode reward: -0.4703,                 loss: 0.3488
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9385s / 61.2020 s
agent0:                 episode reward: 0.0880,                 loss: nan
agent1:                 episode reward: -0.0880,                 loss: 0.3512
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9657s / 62.1677 s
agent0:                 episode reward: 1.2451,                 loss: nan
agent1:                 episode reward: -1.2451,                 loss: 0.3497
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0067s / 63.1744 s
agent0:                 episode reward: 1.2083,                 loss: nan
agent1:                 episode reward: -1.2083,                 loss: 0.3485
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9454s / 64.1197 s
agent0:                 episode reward: 0.5325,                 loss: nan
agent1:                 episode reward: -0.5325,                 loss: 0.3480
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0336s / 65.1533 s
agent0:                 episode reward: 0.7822,                 loss: nan
agent1:                 episode reward: -0.7822,                 loss: 0.3810
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9595s / 66.1128 s
agent0:                 episode reward: 0.9721,                 loss: nan
agent1:                 episode reward: -0.9721,                 loss: 0.3821
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9721s / 67.0849 s
agent0:                 episode reward: 0.4313,                 loss: nan
agent1:                 episode reward: -0.4313,                 loss: 0.3803
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9655s / 68.0504 s
agent0:                 episode reward: 0.3114,                 loss: nan
agent1:                 episode reward: -0.3114,                 loss: 0.3778
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9700s / 69.0204 s
agent0:                 episode reward: 0.0987,                 loss: nan
agent1:                 episode reward: -0.0987,                 loss: 0.3779
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9923s / 70.0127 s
agent0:                 episode reward: 0.1799,                 loss: nan
agent1:                 episode reward: -0.1799,                 loss: 0.3966
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9631s / 70.9758 s
agent0:                 episode reward: 0.6885,                 loss: nan
agent1:                 episode reward: -0.6885,                 loss: 0.3929
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9906s / 71.9663 s
agent0:                 episode reward: 0.9610,                 loss: nan
agent1:                 episode reward: -0.9610,                 loss: 0.3933
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0276s / 72.9939 s
agent0:                 episode reward: 0.4736,                 loss: nan
agent1:                 episode reward: -0.4736,                 loss: 0.3906
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0102s / 74.0042 s
agent0:                 episode reward: 1.0574,                 loss: nan
agent1:                 episode reward: -1.0574,                 loss: 0.3908
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9858s / 74.9900 s
agent0:                 episode reward: 0.2337,                 loss: nan
agent1:                 episode reward: -0.2337,                 loss: 0.3597
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9816s / 75.9715 s
agent0:                 episode reward: 0.7256,                 loss: nan
agent1:                 episode reward: -0.7256,                 loss: 0.3451
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9845s / 76.9560 s
agent0:                 episode reward: 1.3523,                 loss: nan
agent1:                 episode reward: -1.3523,                 loss: 0.3440
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9997s / 77.9557 s
agent0:                 episode reward: 1.0465,                 loss: nan
agent1:                 episode reward: -1.0465,                 loss: 0.3414
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9873s / 78.9430 s
agent0:                 episode reward: -0.1294,                 loss: nan
agent1:                 episode reward: 0.1294,                 loss: 0.3397
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9769s / 79.9200 s
agent0:                 episode reward: 0.5681,                 loss: nan
agent1:                 episode reward: -0.5681,                 loss: 0.2760
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0087s / 80.9287 s
agent0:                 episode reward: 0.1370,                 loss: nan
agent1:                 episode reward: -0.1370,                 loss: 0.2588
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0166s / 81.9453 s
agent0:                 episode reward: 0.9610,                 loss: nan
agent1:                 episode reward: -0.9610,                 loss: 0.2587
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0768s / 83.0221 s
agent0:                 episode reward: 0.8158,                 loss: nan
agent1:                 episode reward: -0.8158,                 loss: 0.2549
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0241s / 84.0462 s
agent0:                 episode reward: 0.6879,                 loss: nan
agent1:                 episode reward: -0.6879,                 loss: 0.2577
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0064s / 85.0527 s
agent0:                 episode reward: 0.4701,                 loss: nan
agent1:                 episode reward: -0.4701,                 loss: 0.2427
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0157s / 86.0684 s
agent0:                 episode reward: 0.5844,                 loss: nan
agent1:                 episode reward: -0.5844,                 loss: 0.2351
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0214s / 87.0898 s
agent0:                 episode reward: 0.6158,                 loss: nan
agent1:                 episode reward: -0.6158,                 loss: 0.2345
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0312s / 88.1210 s
agent0:                 episode reward: 0.6927,                 loss: nan
agent1:                 episode reward: -0.6927,                 loss: 0.2336
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0106s / 89.1317 s
agent0:                 episode reward: 0.5909,                 loss: nan
agent1:                 episode reward: -0.5909,                 loss: 0.2308
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0647s / 90.1964 s
agent0:                 episode reward: 0.9391,                 loss: nan
agent1:                 episode reward: -0.9391,                 loss: 0.2687
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0051s / 91.2015 s
agent0:                 episode reward: 1.2160,                 loss: nan
agent1:                 episode reward: -1.2160,                 loss: 0.2703
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0228s / 92.2243 s
agent0:                 episode reward: 0.0945,                 loss: nan
agent1:                 episode reward: -0.0945,                 loss: 0.2694
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1208s / 93.3451 s
agent0:                 episode reward: 0.2462,                 loss: nan
agent1:                 episode reward: -0.2462,                 loss: 0.2700
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0317s / 94.3768 s
agent0:                 episode reward: 0.4972,                 loss: nan
agent1:                 episode reward: -0.4972,                 loss: 0.2680
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0498s / 95.4266 s
agent0:                 episode reward: 0.9371,                 loss: nan
agent1:                 episode reward: -0.9371,                 loss: 0.2785
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0248s / 96.4514 s
agent0:                 episode reward: 0.3467,                 loss: nan
agent1:                 episode reward: -0.3467,                 loss: 0.2772
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0713s / 97.5227 s
agent0:                 episode reward: 0.5107,                 loss: nan
agent1:                 episode reward: -0.5107,                 loss: 0.2772
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0786s / 98.6014 s
agent0:                 episode reward: 1.1960,                 loss: nan
agent1:                 episode reward: -1.1960,                 loss: 0.2751
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0412s / 99.6426 s
agent0:                 episode reward: 0.8730,                 loss: nan
agent1:                 episode reward: -0.8730,                 loss: 0.2737
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0461s / 100.6887 s
agent0:                 episode reward: 0.3528,                 loss: nan
agent1:                 episode reward: -0.3528,                 loss: 0.2822
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0656s / 101.7543 s
agent0:                 episode reward: 0.2075,                 loss: nan
agent1:                 episode reward: -0.2075,                 loss: 0.2804
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1154s / 102.8696 s
agent0:                 episode reward: 0.2216,                 loss: nan
agent1:                 episode reward: -0.2216,                 loss: 0.2791
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1156s / 103.9853 s
agent0:                 episode reward: 1.3031,                 loss: nan
agent1:                 episode reward: -1.3031,                 loss: 0.2782
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0620s / 105.0472 s
agent0:                 episode reward: -0.0310,                 loss: nan
agent1:                 episode reward: 0.0310,                 loss: 0.2780
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0655s / 106.1127 s
agent0:                 episode reward: -0.7542,                 loss: nan
agent1:                 episode reward: 0.7542,                 loss: 0.2840
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0922s / 107.2050 s
agent0:                 episode reward: -0.2452,                 loss: nan
agent1:                 episode reward: 0.2452,                 loss: 0.2803
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0854s / 108.2904 s
agent0:                 episode reward: 0.9833,                 loss: nan
agent1:                 episode reward: -0.9833,                 loss: 0.2786
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0874s / 109.3778 s
agent0:                 episode reward: 0.5472,                 loss: nan
agent1:                 episode reward: -0.5472,                 loss: 0.2775
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0627s / 110.4405 s
agent0:                 episode reward: 0.0701,                 loss: nan
agent1:                 episode reward: -0.0701,                 loss: 0.2779
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0976s / 111.5382 s
agent0:                 episode reward: 0.2770,                 loss: nan
agent1:                 episode reward: -0.2770,                 loss: 0.2849
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0618s / 112.6000 s
agent0:                 episode reward: 0.6166,                 loss: nan
agent1:                 episode reward: -0.6166,                 loss: 0.2864
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1406s / 113.7406 s
agent0:                 episode reward: 0.5930,                 loss: nan
agent1:                 episode reward: -0.5930,                 loss: 0.2840
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0634s / 114.8040 s
agent0:                 episode reward: 0.5286,                 loss: nan
agent1:                 episode reward: -0.5286,                 loss: 0.2828
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1242s / 115.9281 s
agent0:                 episode reward: 0.6384,                 loss: nan
agent1:                 episode reward: -0.6384,                 loss: 0.2824
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0842s / 117.0124 s
agent0:                 episode reward: 0.5209,                 loss: nan
agent1:                 episode reward: -0.5209,                 loss: 0.3022
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0854s / 118.0978 s
agent0:                 episode reward: 1.1430,                 loss: nan
agent1:                 episode reward: -1.1430,                 loss: 0.3028
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0482s / 119.1460 s
agent0:                 episode reward: 0.3114,                 loss: nan
agent1:                 episode reward: -0.3114,                 loss: 0.3029
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0820s / 120.2280 s
agent0:                 episode reward: 0.3320,                 loss: nan
agent1:                 episode reward: -0.3320,                 loss: 0.3027
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0509s / 121.2789 s
agent0:                 episode reward: 0.3620,                 loss: nan
agent1:                 episode reward: -0.3620,                 loss: 0.3011
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0576s / 122.3365 s
agent0:                 episode reward: -0.5065,                 loss: nan
agent1:                 episode reward: 0.5065,                 loss: 0.3375
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0852s / 123.4218 s
agent0:                 episode reward: -0.1419,                 loss: nan
agent1:                 episode reward: 0.1419,                 loss: 0.3401
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1346s / 124.5564 s
agent0:                 episode reward: 0.0299,                 loss: nan
agent1:                 episode reward: -0.0299,                 loss: 0.3392
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0786s / 125.6349 s
agent0:                 episode reward: 0.1106,                 loss: nan
agent1:                 episode reward: -0.1106,                 loss: 0.3380
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0792s / 126.7142 s
agent0:                 episode reward: 0.3028,                 loss: nan
agent1:                 episode reward: -0.3028,                 loss: 0.3380
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0863s / 127.8005 s
agent0:                 episode reward: 0.6250,                 loss: nan
agent1:                 episode reward: -0.6250,                 loss: 0.3734
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0940s / 128.8945 s
agent0:                 episode reward: 0.6844,                 loss: nan
agent1:                 episode reward: -0.6844,                 loss: 0.3762
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0578s / 129.9522 s
agent0:                 episode reward: 0.5097,                 loss: nan
agent1:                 episode reward: -0.5097,                 loss: 0.3743
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0567s / 131.0089 s
agent0:                 episode reward: 0.3564,                 loss: nan
agent1:                 episode reward: -0.3564,                 loss: 0.3737
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1111s / 132.1200 s
agent0:                 episode reward: 0.2160,                 loss: nan
agent1:                 episode reward: -0.2160,                 loss: 0.3736
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0574s / 133.1773 s
agent0:                 episode reward: -0.7137,                 loss: nan
agent1:                 episode reward: 0.7137,                 loss: 0.3630
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1387s / 134.3161 s
agent0:                 episode reward: 0.5630,                 loss: nan
agent1:                 episode reward: -0.5630,                 loss: 0.3545
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0836s / 135.3997 s
agent0:                 episode reward: 0.1888,                 loss: nan
agent1:                 episode reward: -0.1888,                 loss: 0.3512
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0978s / 136.4975 s
agent0:                 episode reward: 0.5992,                 loss: nan
agent1:                 episode reward: -0.5992,                 loss: 0.3503
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0733s / 137.5708 s
agent0:                 episode reward: 0.3176,                 loss: nan
agent1:                 episode reward: -0.3176,                 loss: 0.3489
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1157s / 138.6865 s
agent0:                 episode reward: 0.4204,                 loss: nan
agent1:                 episode reward: -0.4204,                 loss: 0.2788
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1057s / 139.7922 s
agent0:                 episode reward: 0.3249,                 loss: nan
agent1:                 episode reward: -0.3249,                 loss: 0.2612
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1091s / 140.9013 s
agent0:                 episode reward: 0.1627,                 loss: nan
agent1:                 episode reward: -0.1627,                 loss: 0.2591
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0939s / 141.9952 s
agent0:                 episode reward: 0.2184,                 loss: nan
agent1:                 episode reward: -0.2184,                 loss: 0.2582
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1059s / 143.1011 s
agent0:                 episode reward: 0.2994,                 loss: nan
agent1:                 episode reward: -0.2994,                 loss: 0.2571
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1206s / 144.2217 s
agent0:                 episode reward: 0.6276,                 loss: nan
agent1:                 episode reward: -0.6276,                 loss: 0.2355
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1739s / 145.3957 s
agent0:                 episode reward: 0.8306,                 loss: nan
agent1:                 episode reward: -0.8306,                 loss: 0.2257
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1058s / 146.5015 s
agent0:                 episode reward: 0.8518,                 loss: nan
agent1:                 episode reward: -0.8518,                 loss: 0.2266
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1228s / 147.6242 s
agent0:                 episode reward: 0.4501,                 loss: nan
agent1:                 episode reward: -0.4501,                 loss: 0.2263
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1482s / 148.7725 s
agent0:                 episode reward: 1.0156,                 loss: nan
agent1:                 episode reward: -1.0156,                 loss: 0.2239
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1332s / 149.9057 s
agent0:                 episode reward: 0.6122,                 loss: nan
agent1:                 episode reward: -0.6122,                 loss: 0.2417
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1081s / 151.0138 s
agent0:                 episode reward: -0.0273,                 loss: nan
agent1:                 episode reward: 0.0273,                 loss: 0.2414
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1275s / 152.1414 s
agent0:                 episode reward: 0.0736,                 loss: nan
agent1:                 episode reward: -0.0736,                 loss: 0.2407
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1427s / 153.2841 s
agent0:                 episode reward: 0.4762,                 loss: nan
agent1:                 episode reward: -0.4762,                 loss: 0.2412
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1291s / 154.4132 s
agent0:                 episode reward: 0.2074,                 loss: nan
agent1:                 episode reward: -0.2074,                 loss: 0.2398
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1974s / 155.6106 s
agent0:                 episode reward: 0.1839,                 loss: nan
agent1:                 episode reward: -0.1839,                 loss: 0.2656
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1653s / 156.7759 s
agent0:                 episode reward: 0.4446,                 loss: nan
agent1:                 episode reward: -0.4446,                 loss: 0.2684
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1205s / 157.8964 s
agent0:                 episode reward: -0.0147,                 loss: nan
agent1:                 episode reward: 0.0147,                 loss: 0.2661
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1722s / 159.0686 s
agent0:                 episode reward: 0.5874,                 loss: nan
agent1:                 episode reward: -0.5874,                 loss: 0.2660
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1270s / 160.1956 s
agent0:                 episode reward: 0.0486,                 loss: nan
agent1:                 episode reward: -0.0486,                 loss: 0.2666
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1444s / 161.3400 s
agent0:                 episode reward: 0.1336,                 loss: nan
agent1:                 episode reward: -0.1336,                 loss: 0.2867
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1617s / 162.5017 s
agent0:                 episode reward: -0.3519,                 loss: nan
agent1:                 episode reward: 0.3519,                 loss: 0.2860
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1549s / 163.6566 s
agent0:                 episode reward: 0.0249,                 loss: nan
agent1:                 episode reward: -0.0249,                 loss: 0.2873
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1630s / 164.8197 s
agent0:                 episode reward: 1.1656,                 loss: nan
agent1:                 episode reward: -1.1656,                 loss: 0.2843
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2288s / 166.0485 s
agent0:                 episode reward: 0.4516,                 loss: nan
agent1:                 episode reward: -0.4516,                 loss: 0.2841
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1502s / 167.1987 s
agent0:                 episode reward: 0.3728,                 loss: nan
agent1:                 episode reward: -0.3728,                 loss: 0.2989
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1723s / 168.3711 s
agent0:                 episode reward: 0.0402,                 loss: nan
agent1:                 episode reward: -0.0402,                 loss: 0.2978
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1665s / 169.5376 s
agent0:                 episode reward: 1.0642,                 loss: nan
agent1:                 episode reward: -1.0642,                 loss: 0.2958
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1606s / 170.6982 s
agent0:                 episode reward: 0.4289,                 loss: nan
agent1:                 episode reward: -0.4289,                 loss: 0.2960
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1627s / 171.8609 s
agent0:                 episode reward: -0.1760,                 loss: nan
agent1:                 episode reward: 0.1760,                 loss: 0.2955
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1960s / 173.0569 s
agent0:                 episode reward: 0.4139,                 loss: nan
agent1:                 episode reward: -0.4139,                 loss: 0.3049
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1690s / 174.2259 s
agent0:                 episode reward: 0.1987,                 loss: nan
agent1:                 episode reward: -0.1987,                 loss: 0.3001
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2294s / 175.4553 s
agent0:                 episode reward: 0.4023,                 loss: nan
agent1:                 episode reward: -0.4023,                 loss: 0.2982
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1666s / 176.6219 s
agent0:                 episode reward: 0.1222,                 loss: nan
agent1:                 episode reward: -0.1222,                 loss: 0.2990
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1943s / 177.8162 s
agent0:                 episode reward: -0.0637,                 loss: nan
agent1:                 episode reward: 0.0637,                 loss: 0.2980
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1838s / 179.0000 s
agent0:                 episode reward: 0.2609,                 loss: nan
agent1:                 episode reward: -0.2609,                 loss: 0.3218
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1825s / 180.1825 s
agent0:                 episode reward: 0.6915,                 loss: nan
agent1:                 episode reward: -0.6915,                 loss: 0.3226
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2150s / 181.3975 s
agent0:                 episode reward: 0.0021,                 loss: nan
agent1:                 episode reward: -0.0021,                 loss: 0.3209
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1836s / 182.5811 s
agent0:                 episode reward: 0.1223,                 loss: nan
agent1:                 episode reward: -0.1223,                 loss: 0.3185
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2058s / 183.7869 s
agent0:                 episode reward: 0.2332,                 loss: nan
agent1:                 episode reward: -0.2332,                 loss: 0.3186
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1820s / 184.9689 s
agent0:                 episode reward: 0.1050,                 loss: nan
agent1:                 episode reward: -0.1050,                 loss: 0.3540
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2795s / 186.2484 s
agent0:                 episode reward: 1.1766,                 loss: nan
agent1:                 episode reward: -1.1766,                 loss: 0.3568
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2119s / 187.4602 s
agent0:                 episode reward: 0.6561,                 loss: nan
agent1:                 episode reward: -0.6561,                 loss: 0.3550
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2101s / 188.6703 s
agent0:                 episode reward: -0.0295,                 loss: nan
agent1:                 episode reward: 0.0295,                 loss: 0.3560
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2713s / 189.9416 s
agent0:                 episode reward: -0.2176,                 loss: nan
agent1:                 episode reward: 0.2176,                 loss: 0.3552
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2040s / 191.1456 s
agent0:                 episode reward: -0.4091,                 loss: nan
agent1:                 episode reward: 0.4091,                 loss: 0.3693
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2044s / 192.3500 s
agent0:                 episode reward: 0.4162,                 loss: nan
agent1:                 episode reward: -0.4162,                 loss: 0.3693
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2099s / 193.5599 s
agent0:                 episode reward: 0.6630,                 loss: nan
agent1:                 episode reward: -0.6630,                 loss: 0.3682
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2052s / 194.7651 s
agent0:                 episode reward: -0.3003,                 loss: nan
agent1:                 episode reward: 0.3003,                 loss: 0.3682
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2983s / 196.0634 s
agent0:                 episode reward: 0.0012,                 loss: nan
agent1:                 episode reward: -0.0012,                 loss: 0.3681
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2073s / 197.2707 s
agent0:                 episode reward: 0.7458,                 loss: nan
agent1:                 episode reward: -0.7458,                 loss: 0.3305
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2624s / 198.5331 s
agent0:                 episode reward: 0.0440,                 loss: nan
agent1:                 episode reward: -0.0440,                 loss: 0.3180
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2298s / 199.7630 s
agent0:                 episode reward: 0.5126,                 loss: nan
agent1:                 episode reward: -0.5126,                 loss: 0.3161
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2216s / 200.9846 s
agent0:                 episode reward: 0.1370,                 loss: nan
agent1:                 episode reward: -0.1370,                 loss: 0.3158
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2282s / 202.2128 s
agent0:                 episode reward: 0.0937,                 loss: nan
agent1:                 episode reward: -0.0937,                 loss: 0.3153
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2142s / 203.4270 s
agent0:                 episode reward: 0.7139,                 loss: nan
agent1:                 episode reward: -0.7139,                 loss: 0.2605
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2320s / 204.6590 s
agent0:                 episode reward: 1.2418,                 loss: nan
agent1:                 episode reward: -1.2418,                 loss: 0.2446
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2300s / 205.8889 s
agent0:                 episode reward: 0.1742,                 loss: nan
agent1:                 episode reward: -0.1742,                 loss: 0.2462
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3376s / 207.2265 s
agent0:                 episode reward: 0.2903,                 loss: nan
agent1:                 episode reward: -0.2903,                 loss: 0.2440
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2379s / 208.4644 s
agent0:                 episode reward: 0.6652,                 loss: nan
agent1:                 episode reward: -0.6652,                 loss: 0.2423
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2493s / 209.7137 s
agent0:                 episode reward: -0.0115,                 loss: nan
agent1:                 episode reward: 0.0115,                 loss: 0.2359
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2436s / 210.9573 s
agent0:                 episode reward: 0.4327,                 loss: nan
agent1:                 episode reward: -0.4327,                 loss: 0.2326
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2343s / 212.1916 s
agent0:                 episode reward: 0.4709,                 loss: nan
agent1:                 episode reward: -0.4709,                 loss: 0.2329
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2761s / 213.4676 s
agent0:                 episode reward: 0.5009,                 loss: nan
agent1:                 episode reward: -0.5009,                 loss: 0.2290
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3209s / 214.7885 s
agent0:                 episode reward: 0.2672,                 loss: nan
agent1:                 episode reward: -0.2672,                 loss: 0.2306
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2533s / 216.0419 s
agent0:                 episode reward: 0.6336,                 loss: nan
agent1:                 episode reward: -0.6336,                 loss: 0.2448
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3250s / 217.3668 s
agent0:                 episode reward: 0.7356,                 loss: nan
agent1:                 episode reward: -0.7356,                 loss: 0.2442
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2543s / 218.6211 s
agent0:                 episode reward: 0.0760,                 loss: nan
agent1:                 episode reward: -0.0760,                 loss: 0.2432
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2705s / 219.8916 s
agent0:                 episode reward: 0.8989,                 loss: nan
agent1:                 episode reward: -0.8989,                 loss: 0.2413
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2483s / 221.1399 s
agent0:                 episode reward: 0.7639,                 loss: nan
agent1:                 episode reward: -0.7639,                 loss: 0.2419
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2691s / 222.4091 s
agent0:                 episode reward: 0.5798,                 loss: nan
agent1:                 episode reward: -0.5798,                 loss: 0.2668
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3024s / 223.7114 s
agent0:                 episode reward: 0.2899,                 loss: nan
agent1:                 episode reward: -0.2899,                 loss: 0.2659
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2637s / 224.9751 s
agent0:                 episode reward: 0.4841,                 loss: nan
agent1:                 episode reward: -0.4841,                 loss: 0.2651
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2695s / 226.2446 s
agent0:                 episode reward: 0.0377,                 loss: nan
agent1:                 episode reward: -0.0377,                 loss: 0.2651
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3518s / 227.5964 s
agent0:                 episode reward: 0.6378,                 loss: nan
agent1:                 episode reward: -0.6378,                 loss: 0.2651
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2898s / 228.8862 s
agent0:                 episode reward: 0.0072,                 loss: nan
agent1:                 episode reward: -0.0072,                 loss: 0.2835
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2967s / 230.1830 s
agent0:                 episode reward: 0.7440,                 loss: nan
agent1:                 episode reward: -0.7440,                 loss: 0.2849
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3116s / 231.4946 s
agent0:                 episode reward: -0.1705,                 loss: nan
agent1:                 episode reward: 0.1705,                 loss: 0.2833
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2863s / 232.7810 s
agent0:                 episode reward: 0.4530,                 loss: nan
agent1:                 episode reward: -0.4530,                 loss: 0.2838
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2834s / 234.0644 s
agent0:                 episode reward: -0.1240,                 loss: nan
agent1:                 episode reward: 0.1240,                 loss: 0.2823
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3222s / 235.3865 s
agent0:                 episode reward: -0.1447,                 loss: nan
agent1:                 episode reward: 0.1447,                 loss: 0.2908
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2922s / 236.6788 s
agent0:                 episode reward: -0.3794,                 loss: nan
agent1:                 episode reward: 0.3794,                 loss: 0.2879
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3753s / 238.0540 s
agent0:                 episode reward: 0.6178,                 loss: nan
agent1:                 episode reward: -0.6178,                 loss: 0.2869
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3077s / 239.3617 s
agent0:                 episode reward: 0.3985,                 loss: nan
agent1:                 episode reward: -0.3985,                 loss: 0.2844
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3126s / 240.6743 s
agent0:                 episode reward: -0.2828,                 loss: nan
agent1:                 episode reward: 0.2828,                 loss: 0.2860
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2902s / 241.9645 s
agent0:                 episode reward: 0.2326,                 loss: nan
agent1:                 episode reward: -0.2326,                 loss: 0.2921
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3086s / 243.2732 s
agent0:                 episode reward: 0.1696,                 loss: nan
agent1:                 episode reward: -0.1696,                 loss: 0.2920
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2907s / 244.5639 s
agent0:                 episode reward: 0.1871,                 loss: nan
agent1:                 episode reward: -0.1871,                 loss: 0.2900
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2959s / 245.8598 s
agent0:                 episode reward: 0.3367,                 loss: nan
agent1:                 episode reward: -0.3367,                 loss: 0.2893
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3594s / 247.2192 s
agent0:                 episode reward: -0.2704,                 loss: nan
agent1:                 episode reward: 0.2704,                 loss: 0.2876
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3460s / 248.5652 s
agent0:                 episode reward: 0.2526,                 loss: nan
agent1:                 episode reward: -0.2526,                 loss: 0.3037
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3248s / 249.8900 s
agent0:                 episode reward: -0.1467,                 loss: nan
agent1:                 episode reward: 0.1467,                 loss: 0.2995
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3213s / 251.2114 s
agent0:                 episode reward: 0.3619,                 loss: nan
agent1:                 episode reward: -0.3619,                 loss: 0.2984
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3246s / 252.5360 s
agent0:                 episode reward: 0.5605,                 loss: nan
agent1:                 episode reward: -0.5605,                 loss: 0.2969
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3077s / 253.8436 s
agent0:                 episode reward: 0.3859,                 loss: nan
agent1:                 episode reward: -0.3859,                 loss: 0.2973
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3223s / 255.1659 s
agent0:                 episode reward: 0.2353,                 loss: nan
agent1:                 episode reward: -0.2353,                 loss: 0.3301
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3367s / 256.5026 s
agent0:                 episode reward: -0.2738,                 loss: nan
agent1:                 episode reward: 0.2738,                 loss: 0.3339
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3880s / 257.8906 s
agent0:                 episode reward: 0.4344,                 loss: nan
agent1:                 episode reward: -0.4344,                 loss: 0.3315
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3445s / 259.2351 s
agent0:                 episode reward: 0.6566,                 loss: nan
agent1:                 episode reward: -0.6566,                 loss: 0.3316
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3344s / 260.5695 s
agent0:                 episode reward: 0.3923,                 loss: nan
agent1:                 episode reward: -0.3923,                 loss: 0.3294
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3477s / 261.9172 s
agent0:                 episode reward: -0.6120,                 loss: nan
agent1:                 episode reward: 0.6120,                 loss: 0.3569
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3256s / 263.2427 s
agent0:                 episode reward: 0.1033,                 loss: nan
agent1:                 episode reward: -0.1033,                 loss: 0.3573
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3802s / 264.6229 s
agent0:                 episode reward: -0.1096,                 loss: nan
agent1:                 episode reward: 0.1096,                 loss: 0.3567
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3607s / 265.9836 s
agent0:                 episode reward: -0.8228,                 loss: nan
agent1:                 episode reward: 0.8228,                 loss: 0.3558
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3461s / 267.3297 s
agent0:                 episode reward: -0.7676,                 loss: nan
agent1:                 episode reward: 0.7676,                 loss: 0.3569
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4244s / 268.7541 s
agent0:                 episode reward: 0.1416,                 loss: nan
agent1:                 episode reward: -0.1416,                 loss: 0.3247
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3664s / 270.1205 s
agent0:                 episode reward: 0.0325,                 loss: nan
agent1:                 episode reward: -0.0325,                 loss: 0.3118
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3485s / 271.4690 s
agent0:                 episode reward: -0.4070,                 loss: nan
agent1:                 episode reward: 0.4070,                 loss: 0.3138
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3787s / 272.8477 s
agent0:                 episode reward: -0.0068,                 loss: nan
agent1:                 episode reward: 0.0068,                 loss: 0.3097
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3656s / 274.2133 s
agent0:                 episode reward: 0.4069,                 loss: nan
agent1:                 episode reward: -0.4069,                 loss: 0.3099
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3577s / 275.5709 s
agent0:                 episode reward: 0.1501,                 loss: nan
agent1:                 episode reward: -0.1501,                 loss: 0.2557
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3719s / 276.9429 s
agent0:                 episode reward: 0.2415,                 loss: nan
agent1:                 episode reward: -0.2415,                 loss: 0.2423
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4210s / 278.3639 s
agent0:                 episode reward: -0.0883,                 loss: nan
agent1:                 episode reward: 0.0883,                 loss: 0.2401
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3636s / 279.7275 s
agent0:                 episode reward: -0.3005,                 loss: nan
agent1:                 episode reward: 0.3005,                 loss: 0.2426
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4026s / 281.1301 s
agent0:                 episode reward: -0.3146,                 loss: nan
agent1:                 episode reward: 0.3146,                 loss: 0.2401
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3833s / 282.5133 s
agent0:                 episode reward: 0.2421,                 loss: nan
agent1:                 episode reward: -0.2421,                 loss: 0.2167
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3571s / 283.8705 s
agent0:                 episode reward: 0.6604,                 loss: nan
agent1:                 episode reward: -0.6604,                 loss: 0.2093
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3610s / 285.2315 s
agent0:                 episode reward: -0.0535,                 loss: nan
agent1:                 episode reward: 0.0535,                 loss: 0.2080
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3852s / 286.6167 s
agent0:                 episode reward: -0.4692,                 loss: nan
agent1:                 episode reward: 0.4692,                 loss: 0.2070
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3526s / 287.9693 s
agent0:                 episode reward: 0.1453,                 loss: nan
agent1:                 episode reward: -0.1453,                 loss: 0.2078
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5060s / 289.4753 s
agent0:                 episode reward: -0.6915,                 loss: nan
agent1:                 episode reward: 0.6915,                 loss: 0.2235
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4928s / 290.9680 s
agent0:                 episode reward: 0.1258,                 loss: nan
agent1:                 episode reward: -0.1258,                 loss: 0.2224
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3999s / 292.3679 s
agent0:                 episode reward: 0.4444,                 loss: nan
agent1:                 episode reward: -0.4444,                 loss: 0.2214
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3884s / 293.7563 s
agent0:                 episode reward: 0.1892,                 loss: nan
agent1:                 episode reward: -0.1892,                 loss: 0.2224
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4086s / 295.1648 s
agent0:                 episode reward: 0.2282,                 loss: nan
agent1:                 episode reward: -0.2282,                 loss: 0.2198
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3937s / 296.5585 s
agent0:                 episode reward: -0.4742,                 loss: nan
agent1:                 episode reward: 0.4742,                 loss: 0.2446
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4277s / 297.9863 s
agent0:                 episode reward: 0.1797,                 loss: nan
agent1:                 episode reward: -0.1797,                 loss: 0.2426
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4924s / 299.4787 s
agent0:                 episode reward: 0.1474,                 loss: nan
agent1:                 episode reward: -0.1474,                 loss: 0.2412
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5350s / 301.0136 s
agent0:                 episode reward: 0.1383,                 loss: nan
agent1:                 episode reward: -0.1383,                 loss: 0.2418
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4660s / 302.4796 s
agent0:                 episode reward: 0.2519,                 loss: nan
agent1:                 episode reward: -0.2519,                 loss: 0.2417
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4276s / 303.9072 s
agent0:                 episode reward: 0.3653,                 loss: nan
agent1:                 episode reward: -0.3653,                 loss: 0.2800
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4336s / 305.3408 s
agent0:                 episode reward: -0.5395,                 loss: nan
agent1:                 episode reward: 0.5395,                 loss: 0.2788
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4558s / 306.7966 s
agent0:                 episode reward: 0.1567,                 loss: nan
agent1:                 episode reward: -0.1567,                 loss: 0.2802
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4129s / 308.2095 s
agent0:                 episode reward: -0.1799,                 loss: nan
agent1:                 episode reward: 0.1799,                 loss: 0.2818
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4978s / 309.7073 s
agent0:                 episode reward: -0.1602,                 loss: nan
agent1:                 episode reward: 0.1602,                 loss: 0.2791
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4329s / 311.1401 s
agent0:                 episode reward: 0.7548,                 loss: nan
agent1:                 episode reward: -0.7548,                 loss: 0.2952
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4322s / 312.5723 s
agent0:                 episode reward: 0.0618,                 loss: nan
agent1:                 episode reward: -0.0618,                 loss: 0.2941
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4492s / 314.0216 s
agent0:                 episode reward: 0.2370,                 loss: nan
agent1:                 episode reward: -0.2370,                 loss: 0.2930
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4133s / 315.4348 s
agent0:                 episode reward: 0.1839,                 loss: nan
agent1:                 episode reward: -0.1839,                 loss: 0.2934
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4285s / 316.8634 s
agent0:                 episode reward: 0.2911,                 loss: nan
agent1:                 episode reward: -0.2911,                 loss: 0.2930
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4329s / 318.2963 s
agent0:                 episode reward: 0.5449,                 loss: nan
agent1:                 episode reward: -0.5449,                 loss: 0.2970
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5141s / 319.8104 s
agent0:                 episode reward: 0.9740,                 loss: nan
agent1:                 episode reward: -0.9740,                 loss: 0.2917
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4617s / 321.2720 s
agent0:                 episode reward: 0.3472,                 loss: nan
agent1:                 episode reward: -0.3472,                 loss: 0.2913
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4695s / 322.7415 s
agent0:                 episode reward: -0.1354,                 loss: nan
agent1:                 episode reward: 0.1354,                 loss: 0.2901
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4242s / 324.1656 s
agent0:                 episode reward: -0.4368,                 loss: nan
agent1:                 episode reward: 0.4368,                 loss: 0.2901
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4918s / 325.6575 s
agent0:                 episode reward: -0.6073,                 loss: nan
agent1:                 episode reward: 0.6073,                 loss: 0.3053
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4253s / 327.0828 s
agent0:                 episode reward: 0.2024,                 loss: nan
agent1:                 episode reward: -0.2024,                 loss: 0.3018
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4755s / 328.5583 s
agent0:                 episode reward: -0.2120,                 loss: nan
agent1:                 episode reward: 0.2120,                 loss: 0.3022
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5414s / 330.0997 s
agent0:                 episode reward: -0.2090,                 loss: nan
agent1:                 episode reward: 0.2090,                 loss: 0.3027
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4771s / 331.5768 s
agent0:                 episode reward: 0.0000,                 loss: nan
agent1:                 episode reward: -0.0000,                 loss: 0.3018
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4456s / 333.0224 s
agent0:                 episode reward: -0.6949,                 loss: nan
agent1:                 episode reward: 0.6949,                 loss: 0.3301
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4485s / 334.4709 s
agent0:                 episode reward: 0.5283,                 loss: nan
agent1:                 episode reward: -0.5283,                 loss: 0.3347
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4540s / 335.9249 s
agent0:                 episode reward: 0.5757,                 loss: nan
agent1:                 episode reward: -0.5757,                 loss: 0.3340
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4842s / 337.4091 s
agent0:                 episode reward: -0.1292,                 loss: nan
agent1:                 episode reward: 0.1292,                 loss: 0.3344
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4705s / 338.8795 s
agent0:                 episode reward: 0.2035,                 loss: nan
agent1:                 episode reward: -0.2035,                 loss: 0.3331
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5510s / 340.4306 s
agent0:                 episode reward: 0.1997,                 loss: nan
agent1:                 episode reward: -0.1997,                 loss: 0.3418
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4782s / 341.9087 s
agent0:                 episode reward: -1.0817,                 loss: nan
agent1:                 episode reward: 1.0817,                 loss: 0.3377
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4739s / 343.3827 s
agent0:                 episode reward: -0.9781,                 loss: nan
agent1:                 episode reward: 0.9781,                 loss: 0.3371
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4642s / 344.8468 s
agent0:                 episode reward: 0.5201,                 loss: nan
agent1:                 episode reward: -0.5201,                 loss: 0.3359
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4749s / 346.3217 s
agent0:                 episode reward: -0.2137,                 loss: nan
agent1:                 episode reward: 0.2137,                 loss: 0.3361
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5027s / 347.8245 s
agent0:                 episode reward: 0.2782,                 loss: nan
agent1:                 episode reward: -0.2782,                 loss: 0.2948
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4835s / 349.3080 s
agent0:                 episode reward: 0.3178,                 loss: nan
agent1:                 episode reward: -0.3178,                 loss: 0.2854
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5656s / 350.8736 s
agent0:                 episode reward: -0.1995,                 loss: nan
agent1:                 episode reward: 0.1995,                 loss: 0.2839
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4976s / 352.3712 s
agent0:                 episode reward: -0.6597,                 loss: nan
agent1:                 episode reward: 0.6597,                 loss: 0.2848
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4752s / 353.8464 s
agent0:                 episode reward: 0.1770,                 loss: nan
agent1:                 episode reward: -0.1770,                 loss: 0.2829
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5026s / 355.3491 s
agent0:                 episode reward: -0.0017,                 loss: nan
agent1:                 episode reward: 0.0017,                 loss: 0.2453
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4742s / 356.8233 s
agent0:                 episode reward: 0.5331,                 loss: nan
agent1:                 episode reward: -0.5331,                 loss: 0.2359
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5171s / 358.3403 s
agent0:                 episode reward: 0.1701,                 loss: nan
agent1:                 episode reward: -0.1701,                 loss: 0.2358
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4902s / 359.8305 s
agent0:                 episode reward: -0.1159,                 loss: nan
agent1:                 episode reward: 0.1159,                 loss: 0.2338
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6263s / 361.4568 s
agent0:                 episode reward: -0.0701,                 loss: nan
agent1:                 episode reward: 0.0701,                 loss: 0.2340
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4922s / 362.9490 s
agent0:                 episode reward: -0.4684,                 loss: nan
agent1:                 episode reward: 0.4684,                 loss: 0.2270
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5906s / 364.5396 s
agent0:                 episode reward: 0.2055,                 loss: nan
agent1:                 episode reward: -0.2055,                 loss: 0.2239
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5042s / 366.0438 s
agent0:                 episode reward: 1.1927,                 loss: nan
agent1:                 episode reward: -1.1927,                 loss: 0.2229
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5160s / 367.5598 s
agent0:                 episode reward: 0.0632,                 loss: nan
agent1:                 episode reward: -0.0632,                 loss: 0.2220
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4948s / 369.0545 s
agent0:                 episode reward: 0.2175,                 loss: nan
agent1:                 episode reward: -0.2175,                 loss: 0.2203
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5968s / 370.6513 s
agent0:                 episode reward: -0.1440,                 loss: nan
agent1:                 episode reward: 0.1440,                 loss: 0.2369
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5432s / 372.1946 s
agent0:                 episode reward: 0.3461,                 loss: nan
agent1:                 episode reward: -0.3461,                 loss: 0.2347
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5259s / 373.7205 s
agent0:                 episode reward: 0.4443,                 loss: nan
agent1:                 episode reward: -0.4443,                 loss: 0.2351
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4967s / 375.2172 s
agent0:                 episode reward: 0.1625,                 loss: nan
agent1:                 episode reward: -0.1625,                 loss: 0.2358
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5234s / 376.7406 s
agent0:                 episode reward: -0.0586,                 loss: nan
agent1:                 episode reward: 0.0586,                 loss: 0.2335
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5027s / 378.2434 s
agent0:                 episode reward: -0.0728,                 loss: nan
agent1:                 episode reward: 0.0728,                 loss: 0.2529
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5549s / 379.7982 s
agent0:                 episode reward: 0.2035,                 loss: nan
agent1:                 episode reward: -0.2035,                 loss: 0.2502
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6013s / 381.3995 s
agent0:                 episode reward: -0.9709,                 loss: nan
agent1:                 episode reward: 0.9709,                 loss: 0.2514
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5486s / 382.9481 s
agent0:                 episode reward: -0.4682,                 loss: nan
agent1:                 episode reward: 0.4682,                 loss: 0.2501
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5519s / 384.5000 s
agent0:                 episode reward: 0.4707,                 loss: nan
agent1:                 episode reward: -0.4707,                 loss: 0.2520
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5417s / 386.0417 s
agent0:                 episode reward: -0.6834,                 loss: nan
agent1:                 episode reward: 0.6834,                 loss: 0.2801
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5434s / 387.5852 s
agent0:                 episode reward: -0.2490,                 loss: nan
agent1:                 episode reward: 0.2490,                 loss: 0.2824
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5808s / 389.1659 s
agent0:                 episode reward: -0.7345,                 loss: nan
agent1:                 episode reward: 0.7345,                 loss: 0.2812
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5380s / 390.7040 s
agent0:                 episode reward: -0.6428,                 loss: nan
agent1:                 episode reward: 0.6428,                 loss: 0.2826
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6960s / 392.3999 s
agent0:                 episode reward: -0.4877,                 loss: nan
agent1:                 episode reward: 0.4877,                 loss: 0.2814
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5751s / 393.9751 s
agent0:                 episode reward: -0.2606,                 loss: nan
agent1:                 episode reward: 0.2606,                 loss: 0.2914
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5539s / 395.5289 s
agent0:                 episode reward: -0.5935,                 loss: nan
agent1:                 episode reward: 0.5935,                 loss: 0.2881
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5890s / 397.1180 s
agent0:                 episode reward: 0.3190,                 loss: nan
agent1:                 episode reward: -0.3190,                 loss: 0.2863
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5689s / 398.6869 s
agent0:                 episode reward: -0.1249,                 loss: nan
agent1:                 episode reward: 0.1249,                 loss: 0.2851
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5724s / 400.2594 s
agent0:                 episode reward: -0.5885,                 loss: nan
agent1:                 episode reward: 0.5885,                 loss: 0.2839
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6506s / 401.9099 s
agent0:                 episode reward: -0.3622,                 loss: nan
agent1:                 episode reward: 0.3622,                 loss: 0.2915
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5999s / 403.5099 s
agent0:                 episode reward: 0.2590,                 loss: nan
agent1:                 episode reward: -0.2590,                 loss: 0.2875
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5906s / 405.1005 s
agent0:                 episode reward: -0.7766,                 loss: nan
agent1:                 episode reward: 0.7766,                 loss: 0.2848
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5796s / 406.6801 s
agent0:                 episode reward: -0.2597,                 loss: nan
agent1:                 episode reward: 0.2597,                 loss: 0.2858
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5681s / 408.2482 s
agent0:                 episode reward: -0.6722,                 loss: nan
agent1:                 episode reward: 0.6722,                 loss: 0.2855
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6041s / 409.8523 s
agent0:                 episode reward: -0.9577,                 loss: nan
agent1:                 episode reward: 0.9577,                 loss: 0.3052
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5803s / 411.4327 s
agent0:                 episode reward: -0.5323,                 loss: nan
agent1:                 episode reward: 0.5323,                 loss: 0.3030
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7383s / 413.1710 s
agent0:                 episode reward: -0.5502,                 loss: nan
agent1:                 episode reward: 0.5502,                 loss: 0.3026
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6275s / 414.7985 s
agent0:                 episode reward: -0.2000,                 loss: nan
agent1:                 episode reward: 0.2000,                 loss: 0.3021
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5914s / 416.3899 s
agent0:                 episode reward: -0.2201,                 loss: nan
agent1:                 episode reward: 0.2201,                 loss: 0.3007
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5953s / 417.9852 s
agent0:                 episode reward: 0.2862,                 loss: nan
agent1:                 episode reward: -0.2862,                 loss: 0.3232
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6069s / 419.5921 s
agent0:                 episode reward: -0.1967,                 loss: nan
agent1:                 episode reward: 0.1967,                 loss: 0.3189
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6622s / 421.2543 s
agent0:                 episode reward: -0.3317,                 loss: nan
agent1:                 episode reward: 0.3317,                 loss: 0.3172
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6989s / 422.9532 s
agent0:                 episode reward: -0.1472,                 loss: nan
agent1:                 episode reward: 0.1472,                 loss: 0.3170
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6185s / 424.5717 s
agent0:                 episode reward: -0.5160,                 loss: nan
agent1:                 episode reward: 0.5160,                 loss: 0.3172
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6046s / 426.1763 s
agent0:                 episode reward: -0.8645,                 loss: nan
agent1:                 episode reward: 0.8645,                 loss: 0.2891
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6243s / 427.8006 s
agent0:                 episode reward: 0.1852,                 loss: nan
agent1:                 episode reward: -0.1852,                 loss: 0.2772
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6086s / 429.4092 s
agent0:                 episode reward: 0.4072,                 loss: nan
agent1:                 episode reward: -0.4072,                 loss: 0.2773
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6649s / 431.0741 s
agent0:                 episode reward: -0.5697,                 loss: nan
agent1:                 episode reward: 0.5697,                 loss: 0.2750
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7144s / 432.7885 s
agent0:                 episode reward: -0.3994,                 loss: nan
agent1:                 episode reward: 0.3994,                 loss: 0.2763
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6251s / 434.4136 s
agent0:                 episode reward: -0.5606,                 loss: nan
agent1:                 episode reward: 0.5606,                 loss: 0.2261
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6146s / 436.0283 s
agent0:                 episode reward: -0.0668,                 loss: nan
agent1:                 episode reward: 0.0668,                 loss: 0.2121
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6261s / 437.6544 s
agent0:                 episode reward: -0.3920,                 loss: nan
agent1:                 episode reward: 0.3920,                 loss: 0.2110
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6620s / 439.3164 s
agent0:                 episode reward: -0.5012,                 loss: nan
agent1:                 episode reward: 0.5012,                 loss: 0.2085
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6327s / 440.9491 s
agent0:                 episode reward: -0.3502,                 loss: nan
agent1:                 episode reward: 0.3502,                 loss: 0.2072
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7289s / 442.6780 s
agent0:                 episode reward: 0.3900,                 loss: nan
agent1:                 episode reward: -0.3900,                 loss: 0.1917
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6378s / 444.3158 s
agent0:                 episode reward: 0.1713,                 loss: nan
agent1:                 episode reward: -0.1713,                 loss: 0.1832
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6597s / 445.9754 s
agent0:                 episode reward: 0.4202,                 loss: nan
agent1:                 episode reward: -0.4202,                 loss: 0.1814
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6792s / 447.6547 s
agent0:                 episode reward: -1.1309,                 loss: nan
agent1:                 episode reward: 1.1309,                 loss: 0.1817
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6651s / 449.3198 s
agent0:                 episode reward: -0.4227,                 loss: nan
agent1:                 episode reward: 0.4227,                 loss: 0.1812
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6440s / 450.9638 s
agent0:                 episode reward: 0.1406,                 loss: nan
agent1:                 episode reward: -0.1406,                 loss: 0.1839
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6860s / 452.6498 s
agent0:                 episode reward: -0.1455,                 loss: nan
agent1:                 episode reward: 0.1455,                 loss: 0.1812
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7598s / 454.4096 s
agent0:                 episode reward: -0.7534,                 loss: nan
agent1:                 episode reward: 0.7534,                 loss: 0.1826
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6543s / 456.0639 s
agent0:                 episode reward: -0.5018,                 loss: nan
agent1:                 episode reward: 0.5018,                 loss: 0.1815
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6655s / 457.7293 s
agent0:                 episode reward: -0.1062,                 loss: nan
agent1:                 episode reward: 0.1062,                 loss: 0.1795
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6673s / 459.3966 s
agent0:                 episode reward: -0.4706,                 loss: nan
agent1:                 episode reward: 0.4706,                 loss: 0.2133
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6776s / 461.0742 s
agent0:                 episode reward: -0.1294,                 loss: nan
agent1:                 episode reward: 0.1294,                 loss: 0.2169
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7231s / 462.7973 s
agent0:                 episode reward: -0.1955,                 loss: nan
agent1:                 episode reward: 0.1955,                 loss: 0.2163
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7823s / 464.5796 s
agent0:                 episode reward: 0.1545,                 loss: nan
agent1:                 episode reward: -0.1545,                 loss: 0.2145
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6682s / 466.2478 s
agent0:                 episode reward: -0.6207,                 loss: nan
agent1:                 episode reward: 0.6207,                 loss: 0.2137
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6918s / 467.9396 s
agent0:                 episode reward: 0.2585,                 loss: nan
agent1:                 episode reward: -0.2585,                 loss: 0.2491
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6919s / 469.6315 s
agent0:                 episode reward: -0.8616,                 loss: nan
agent1:                 episode reward: 0.8616,                 loss: 0.2513
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6984s / 471.3299 s
agent0:                 episode reward: 0.3451,                 loss: nan
agent1:                 episode reward: -0.3451,                 loss: 0.2522
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6932s / 473.0232 s
agent0:                 episode reward: -0.7619,                 loss: nan
agent1:                 episode reward: 0.7619,                 loss: 0.2490
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7648s / 474.7880 s
agent0:                 episode reward: -0.1142,                 loss: nan
agent1:                 episode reward: 0.1142,                 loss: 0.2502
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7040s / 476.4919 s
agent0:                 episode reward: 0.0422,                 loss: nan
agent1:                 episode reward: -0.0422,                 loss: 0.2741
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7031s / 478.1950 s
agent0:                 episode reward: -0.6079,                 loss: nan
agent1:                 episode reward: 0.6079,                 loss: 0.2753
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7643s / 479.9593 s
agent0:                 episode reward: -0.0415,                 loss: nan
agent1:                 episode reward: 0.0415,                 loss: 0.2746
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7360s / 481.6953 s
agent0:                 episode reward: -0.1920,                 loss: nan
agent1:                 episode reward: 0.1920,                 loss: 0.2727
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7276s / 483.4229 s
agent0:                 episode reward: 0.0377,                 loss: nan
agent1:                 episode reward: -0.0377,                 loss: 0.2737
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8020s / 485.2249 s
agent0:                 episode reward: -0.5127,                 loss: nan
agent1:                 episode reward: 0.5127,                 loss: 0.2781
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7118s / 486.9367 s
agent0:                 episode reward: -0.1518,                 loss: nan
agent1:                 episode reward: 0.1518,                 loss: 0.2744
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7406s / 488.6773 s
agent0:                 episode reward: -1.5016,                 loss: nan
agent1:                 episode reward: 1.5016,                 loss: 0.2748
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7069s / 490.3842 s
agent0:                 episode reward: -0.6055,                 loss: nan
agent1:                 episode reward: 0.6055,                 loss: 0.2741
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7413s / 492.1255 s
agent0:                 episode reward: -0.6173,                 loss: nan
agent1:                 episode reward: 0.6173,                 loss: 0.2742
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8034s / 493.9289 s
agent0:                 episode reward: -0.1882,                 loss: nan
agent1:                 episode reward: 0.1882,                 loss: 0.2789
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7314s / 495.6603 s
agent0:                 episode reward: 0.0115,                 loss: nan
agent1:                 episode reward: -0.0115,                 loss: 0.2751
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7754s / 497.4357 s
agent0:                 episode reward: 0.1038,                 loss: nan
agent1:                 episode reward: -0.1038,                 loss: 0.2743
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7247s / 499.1603 s
agent0:                 episode reward: -0.5696,                 loss: nan
agent1:                 episode reward: 0.5696,                 loss: 0.2735
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7530s / 500.9133 s
agent0:                 episode reward: 0.3104,                 loss: nan
agent1:                 episode reward: -0.3104,                 loss: 0.2729
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7536s / 502.6670 s
agent0:                 episode reward: 0.0770,                 loss: nan
agent1:                 episode reward: -0.0770,                 loss: 0.2987
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8713s / 504.5383 s
agent0:                 episode reward: -0.1650,                 loss: nan
agent1:                 episode reward: 0.1650,                 loss: 0.2965
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7487s / 506.2869 s
agent0:                 episode reward: -0.5867,                 loss: nan
agent1:                 episode reward: 0.5867,                 loss: 0.2939
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7475s / 508.0345 s
agent0:                 episode reward: -0.5094,                 loss: nan
agent1:                 episode reward: 0.5094,                 loss: 0.2952
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7604s / 509.7948 s
agent0:                 episode reward: -0.9681,                 loss: nan
agent1:                 episode reward: 0.9681,                 loss: 0.2930
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7460s / 511.5409 s
agent0:                 episode reward: 0.1306,                 loss: nan
agent1:                 episode reward: -0.1306,                 loss: 0.2903
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7850s / 513.3259 s
agent0:                 episode reward: -0.6553,                 loss: nan
agent1:                 episode reward: 0.6553,                 loss: 0.2826
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8904s / 515.2163 s
agent0:                 episode reward: 0.4300,                 loss: nan
agent1:                 episode reward: -0.4300,                 loss: 0.2804
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7773s / 516.9936 s
agent0:                 episode reward: -1.1881,                 loss: nan
agent1:                 episode reward: 1.1881,                 loss: 0.2787
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7975s / 518.7911 s
agent0:                 episode reward: -0.6113,                 loss: nan
agent1:                 episode reward: 0.6113,                 loss: 0.2800
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7720s / 520.5631 s
agent0:                 episode reward: -0.6407,                 loss: nan
agent1:                 episode reward: 0.6407,                 loss: 0.2270
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8066s / 522.3697 s
agent0:                 episode reward: -0.2685,                 loss: nan
agent1:                 episode reward: 0.2685,                 loss: 0.2077
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7951s / 524.1648 s
agent0:                 episode reward: -0.5544,                 loss: nan
agent1:                 episode reward: 0.5544,                 loss: 0.2091
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8495s / 526.0143 s
agent0:                 episode reward: -0.5647,                 loss: nan
agent1:                 episode reward: 0.5647,                 loss: 0.2062
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7851s / 527.7995 s
agent0:                 episode reward: -0.1684,                 loss: nan
agent1:                 episode reward: 0.1684,                 loss: 0.2036
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8110s / 529.6105 s
agent0:                 episode reward: -0.1591,                 loss: nan
agent1:                 episode reward: 0.1591,                 loss: 0.1744
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7978s / 531.4082 s
agent0:                 episode reward: -0.1834,                 loss: nan
agent1:                 episode reward: 0.1834,                 loss: 0.1644
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8029s / 533.2111 s
agent0:                 episode reward: -0.4222,                 loss: nan
agent1:                 episode reward: 0.4222,                 loss: 0.1625
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9251s / 535.1362 s
agent0:                 episode reward: -0.3970,                 loss: nan
agent1:                 episode reward: 0.3970,                 loss: 0.1601
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8015s / 536.9377 s
agent0:                 episode reward: -0.3207,                 loss: nan
agent1:                 episode reward: 0.3207,                 loss: 0.1598
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8302s / 538.7679 s
agent0:                 episode reward: -0.6312,                 loss: nan
agent1:                 episode reward: 0.6312,                 loss: 0.1715
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8440s / 540.6118 s
agent0:                 episode reward: 0.1382,                 loss: nan
agent1:                 episode reward: -0.1382,                 loss: 0.1711
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8433s / 542.4551 s
agent0:                 episode reward: 0.1620,                 loss: nan
agent1:                 episode reward: -0.1620,                 loss: 0.1698
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8953s / 544.3504 s
agent0:                 episode reward: -0.6562,                 loss: nan
agent1:                 episode reward: 0.6562,                 loss: 0.1670
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0446s / 546.3950 s
agent0:                 episode reward: -0.3083,                 loss: nan
agent1:                 episode reward: 0.3083,                 loss: 0.1670
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9308s / 548.3258 s
agent0:                 episode reward: -0.2910,                 loss: nan
agent1:                 episode reward: 0.2910,                 loss: 0.2022
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9483s / 550.2741 s
agent0:                 episode reward: -0.6295,                 loss: nan
agent1:                 episode reward: 0.6295,                 loss: 0.2041
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9239s / 552.1980 s
agent0:                 episode reward: -0.7036,                 loss: nan
agent1:                 episode reward: 0.7036,                 loss: 0.2040
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9983s / 554.1963 s
agent0:                 episode reward: 0.0954,                 loss: nan
agent1:                 episode reward: -0.0954,                 loss: 0.2036
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0655s / 556.2618 s
agent0:                 episode reward: -1.0270,                 loss: nan
agent1:                 episode reward: 1.0270,                 loss: 0.2032
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9695s / 558.2313 s
agent0:                 episode reward: -0.3499,                 loss: nan
agent1:                 episode reward: 0.3499,                 loss: 0.2327
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6813s / 559.9127 s
agent0:                 episode reward: -0.4756,                 loss: nan
agent1:                 episode reward: 0.4756,                 loss: 0.2356
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6828s / 561.5955 s
agent0:                 episode reward: -0.5607,                 loss: nan
agent1:                 episode reward: 0.5607,                 loss: 0.2329
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7061s / 563.3016 s
agent0:                 episode reward: -0.6439,                 loss: nan
agent1:                 episode reward: 0.6439,                 loss: 0.2335
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6935s / 564.9951 s
agent0:                 episode reward: 0.3037,                 loss: nan
agent1:                 episode reward: -0.3037,                 loss: 0.2334
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7402s / 566.7353 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.2646
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7010s / 568.4363 s
agent0:                 episode reward: -0.1132,                 loss: nan
agent1:                 episode reward: 0.1132,                 loss: 0.2683
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6947s / 570.1310 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.2668
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7119s / 571.8429 s
agent0:                 episode reward: -0.9605,                 loss: nan
agent1:                 episode reward: 0.9605,                 loss: 0.2654
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6955s / 573.5384 s
agent0:                 episode reward: 0.0034,                 loss: nan
agent1:                 episode reward: -0.0034,                 loss: 0.2643
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7034s / 575.2418 s
agent0:                 episode reward: -0.1399,                 loss: nan
agent1:                 episode reward: 0.1399,                 loss: 0.2791
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7775s / 577.0193 s
agent0:                 episode reward: -0.9364,                 loss: nan
agent1:                 episode reward: 0.9364,                 loss: 0.2782
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7446s / 578.7640 s
agent0:                 episode reward: -0.1800,                 loss: nan
agent1:                 episode reward: 0.1800,                 loss: 0.2773
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7259s / 580.4899 s
agent0:                 episode reward: 0.2524,                 loss: nan
agent1:                 episode reward: -0.2524,                 loss: 0.2744
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7377s / 582.2276 s
agent0:                 episode reward: 0.3469,                 loss: nan
agent1:                 episode reward: -0.3469,                 loss: 0.2763
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7212s / 583.9488 s
agent0:                 episode reward: 0.1498,                 loss: nan
agent1:                 episode reward: -0.1498,                 loss: 0.2819
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7219s / 585.6708 s
agent0:                 episode reward: 0.2501,                 loss: nan
agent1:                 episode reward: -0.2501,                 loss: 0.2796
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7897s / 587.4605 s
agent0:                 episode reward: -0.6295,                 loss: nan
agent1:                 episode reward: 0.6295,                 loss: 0.2799
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7194s / 589.1799 s
agent0:                 episode reward: -0.3741,                 loss: nan
agent1:                 episode reward: 0.3741,                 loss: 0.2782
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7313s / 590.9112 s
agent0:                 episode reward: -1.1835,                 loss: nan
agent1:                 episode reward: 1.1835,                 loss: 0.2770
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7249s / 592.6360 s
agent0:                 episode reward: 0.0059,                 loss: nan
agent1:                 episode reward: -0.0059,                 loss: 0.2970
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7330s / 594.3690 s
agent0:                 episode reward: -1.0485,                 loss: nan
agent1:                 episode reward: 1.0485,                 loss: 0.2992
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7621s / 596.1312 s
agent0:                 episode reward: -0.6986,                 loss: nan
agent1:                 episode reward: 0.6986,                 loss: 0.2977
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8190s / 597.9502 s
agent0:                 episode reward: -1.0559,                 loss: nan
agent1:                 episode reward: 1.0559,                 loss: 0.2975
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7585s / 599.7087 s
agent0:                 episode reward: -0.2157,                 loss: nan
agent1:                 episode reward: 0.2157,                 loss: 0.2959
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7276s / 601.4363 s
agent0:                 episode reward: -0.8227,                 loss: nan
agent1:                 episode reward: 0.8227,                 loss: 0.3170
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7406s / 603.1769 s
agent0:                 episode reward: -0.5902,                 loss: nan
agent1:                 episode reward: 0.5902,                 loss: 0.3136
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7682s / 604.9451 s
agent0:                 episode reward: 0.2682,                 loss: nan
agent1:                 episode reward: -0.2682,                 loss: 0.3118
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7682s / 606.7133 s
agent0:                 episode reward: -0.0971,                 loss: nan
agent1:                 episode reward: 0.0971,                 loss: 0.3121
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8272s / 608.5405 s
agent0:                 episode reward: -0.2393,                 loss: nan
agent1:                 episode reward: 0.2393,                 loss: 0.3133
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7571s / 610.2976 s
agent0:                 episode reward: -0.8728,                 loss: nan
agent1:                 episode reward: 0.8728,                 loss: 0.2899
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7777s / 612.0754 s
agent0:                 episode reward: -0.9551,                 loss: nan
agent1:                 episode reward: 0.9551,                 loss: 0.2769
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7601s / 613.8354 s
agent0:                 episode reward: -1.2014,                 loss: nan
agent1:                 episode reward: 1.2014,                 loss: 0.2777
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7878s / 615.6232 s
agent0:                 episode reward: -0.7323,                 loss: nan
agent1:                 episode reward: 0.7323,                 loss: 0.2756
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8162s / 617.4395 s
agent0:                 episode reward: -0.3235,                 loss: nan
agent1:                 episode reward: 0.3235,                 loss: 0.2755
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7625s / 619.2019 s
agent0:                 episode reward: -0.3717,                 loss: nan
agent1:                 episode reward: 0.3717,                 loss: 0.2246
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8748s / 621.0767 s
agent0:                 episode reward: -0.0500,                 loss: nan
agent1:                 episode reward: 0.0500,                 loss: 0.2112
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7997s / 622.8764 s
agent0:                 episode reward: -0.2946,                 loss: nan
agent1:                 episode reward: 0.2946,                 loss: 0.2100
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7700s / 624.6464 s
agent0:                 episode reward: -1.0488,                 loss: nan
agent1:                 episode reward: 1.0488,                 loss: 0.2077
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7899s / 626.4363 s
agent0:                 episode reward: -0.9165,                 loss: nan
agent1:                 episode reward: 0.9165,                 loss: 0.2099
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8457s / 628.2820 s
agent0:                 episode reward: 0.2427,                 loss: nan
agent1:                 episode reward: -0.2427,                 loss: 0.1825
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8398s / 630.1218 s
agent0:                 episode reward: -0.7000,                 loss: nan
agent1:                 episode reward: 0.7000,                 loss: 0.1757
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8017s / 631.9236 s
agent0:                 episode reward: -0.4826,                 loss: nan
agent1:                 episode reward: 0.4826,                 loss: 0.1747
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8198s / 633.7434 s
agent0:                 episode reward: -0.8303,                 loss: nan
agent1:                 episode reward: 0.8303,                 loss: 0.1739
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8236s / 635.5669 s
agent0:                 episode reward: -1.2264,                 loss: nan
agent1:                 episode reward: 1.2264,                 loss: 0.1728
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8152s / 637.3821 s
agent0:                 episode reward: -0.1249,                 loss: nan
agent1:                 episode reward: 0.1249,                 loss: 0.1723
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8712s / 639.2533 s
agent0:                 episode reward: -0.4085,                 loss: nan
agent1:                 episode reward: 0.4085,                 loss: 0.1667
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8174s / 641.0707 s
agent0:                 episode reward: -0.4506,                 loss: nan
agent1:                 episode reward: 0.4506,                 loss: 0.1669
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8403s / 642.9110 s
agent0:                 episode reward: -0.3330,                 loss: nan
agent1:                 episode reward: 0.3330,                 loss: 0.1640
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8275s / 644.7385 s
agent0:                 episode reward: -0.4684,                 loss: nan
agent1:                 episode reward: 0.4684,                 loss: 0.1652
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8569s / 646.5954 s
agent0:                 episode reward: 0.0551,                 loss: nan
agent1:                 episode reward: -0.0551,                 loss: 0.1909
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8885s / 648.4839 s
agent0:                 episode reward: -0.6022,                 loss: nan
agent1:                 episode reward: 0.6022,                 loss: 0.1912
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8757s / 650.3596 s
agent0:                 episode reward: -0.5446,                 loss: nan
agent1:                 episode reward: 0.5446,                 loss: 0.1918
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8398s / 652.1994 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.1916
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8759s / 654.0754 s
agent0:                 episode reward: -0.4067,                 loss: nan
agent1:                 episode reward: 0.4067,                 loss: 0.1895
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8635s / 655.9389 s
agent0:                 episode reward: -0.7619,                 loss: nan
agent1:                 episode reward: 0.7619,                 loss: 0.2208
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8408s / 657.7797 s
agent0:                 episode reward: -0.4442,                 loss: nan
agent1:                 episode reward: 0.4442,                 loss: 0.2240
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9105s / 659.6901 s
agent0:                 episode reward: -0.3364,                 loss: nan
agent1:                 episode reward: 0.3364,                 loss: 0.2228
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8753s / 661.5654 s
agent0:                 episode reward: -0.9336,                 loss: nan
agent1:                 episode reward: 0.9336,                 loss: 0.2239
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8924s / 663.4578 s
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
agent0:                 episode reward: -0.3399,                 loss: nan
agent1:                 episode reward: 0.3399,                 loss: 0.2218
Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8825s / 665.3403 s
agent0:                 episode reward: -1.0454,                 loss: nan
agent1:                 episode reward: 1.0454,                 loss: 0.2542
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8803s / 667.2206 s
agent0:                 episode reward: -0.7860,                 loss: nan
agent1:                 episode reward: 0.7860,                 loss: 0.2569
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9218s / 669.1424 s
agent0:                 episode reward: -0.2487,                 loss: nan
agent1:                 episode reward: 0.2487,                 loss: 0.2530
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9183s / 671.0606 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.2530
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8822s / 672.9428 s
agent0:                 episode reward: -0.6484,                 loss: nan
agent1:                 episode reward: 0.6484,                 loss: 0.2549
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8953s / 674.8381 s
agent0:                 episode reward: 0.1135,                 loss: nan
agent1:                 episode reward: -0.1135,                 loss: 0.2683
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8775s / 676.7156 s
agent0:                 episode reward: -0.4795,                 loss: nan
agent1:                 episode reward: 0.4795,                 loss: 0.2671
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9384s / 678.6540 s
agent0:                 episode reward: -1.0895,                 loss: nan
agent1:                 episode reward: 1.0895,                 loss: 0.2677
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9020s / 680.5559 s
agent0:                 episode reward: -0.9118,                 loss: nan
agent1:                 episode reward: 0.9118,                 loss: 0.2661
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8776s / 682.4335 s
agent0:                 episode reward: -0.1491,                 loss: nan
agent1:                 episode reward: 0.1491,                 loss: 0.2655
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8810s / 684.3145 s
agent0:                 episode reward: -0.4902,                 loss: nan
agent1:                 episode reward: 0.4902,                 loss: 0.2777
