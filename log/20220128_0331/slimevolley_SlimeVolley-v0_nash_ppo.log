pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'Tanh', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'Tanh', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220128_0331/slimevolley_SlimeVolley-v0_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220128_0331/slimevolley_SlimeVolley-v0_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 495.0,                last time consumption/overall running time: 3.6021s / 3.6021 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0209
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0739
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 597.4,                last time consumption/overall running time: 58.7104s / 62.3125 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0744
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0834
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 584.65,                last time consumption/overall running time: 56.3623s / 118.6748 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2049
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1994
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 563.35,                last time consumption/overall running time: 55.2370s / 173.9118 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2106
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2149
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 562.55,                last time consumption/overall running time: 55.1749s / 229.0867 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2387
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2399
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 603.35,                last time consumption/overall running time: 58.1570s / 287.2437 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2131
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2109
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 565.45,                last time consumption/overall running time: 54.2743s / 341.5180 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2292
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2356
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 539.5,                last time consumption/overall running time: 53.4530s / 394.9710 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2273
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2251
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 571.75,                last time consumption/overall running time: 56.6560s / 451.6270 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2530
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2567
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 572.05,                last time consumption/overall running time: 56.4349s / 508.0619 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2408
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2456
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 577.45,                last time consumption/overall running time: 56.3813s / 564.4432 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2337
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2330
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 599.65,                last time consumption/overall running time: 58.4852s / 622.9284 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2420
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2528
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 530.35,                last time consumption/overall running time: 52.6221s / 675.5505 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2416
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2531
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 559.9,                last time consumption/overall running time: 55.6162s / 731.1668 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2471
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2436
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 603.1,                last time consumption/overall running time: 57.8868s / 789.0536 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2445
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2378
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 536.2,                last time consumption/overall running time: 52.6742s / 841.7278 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2641
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2780
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 574.4,                last time consumption/overall running time: 56.4594s / 898.1871 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2648
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2735
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 615.4,                last time consumption/overall running time: 59.8618s / 958.0490 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2560
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2575
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 542.95,                last time consumption/overall running time: 53.0595s / 1011.1085 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2648
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2526
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 561.6,                last time consumption/overall running time: 55.9003s / 1067.0088 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2617
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2700
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 564.5,                last time consumption/overall running time: 55.6168s / 1122.6256 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2676
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2675
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 601.6,                last time consumption/overall running time: 58.2994s / 1180.9250 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2582
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2662
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 608.85,                last time consumption/overall running time: 59.7713s / 1240.6963 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2838
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3034
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 580.25,                last time consumption/overall running time: 57.6429s / 1298.3392 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2704
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2802
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 545.65,                last time consumption/overall running time: 53.6404s / 1351.9796 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2791
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2813
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 568.6,                last time consumption/overall running time: 55.6154s / 1407.5950 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2775
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2803
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 595.9,                last time consumption/overall running time: 57.8653s / 1465.4603 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2938
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3123
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 540.45,                last time consumption/overall running time: 53.0168s / 1518.4771 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3125
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3246
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 582.25,                last time consumption/overall running time: 57.4487s / 1575.9259 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3021
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3132
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 585.75,                last time consumption/overall running time: 57.3858s / 1633.3117 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2717
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2841
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 550.4,                last time consumption/overall running time: 53.8131s / 1687.1248 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2096
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2267
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 579.95,                last time consumption/overall running time: 56.5775s / 1743.7023 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.2509
env0_second_0:                 episode reward: -1.5500,                 loss: 0.2729
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 588.85,                last time consumption/overall running time: 57.2387s / 1800.9410 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.1972
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2114
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 597.95,                last time consumption/overall running time: 58.5758s / 1859.5168 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2282
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2489
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 570.45,                last time consumption/overall running time: 55.5708s / 1915.0877 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.2053
env0_second_0:                 episode reward: -1.5500,                 loss: 0.2241
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 575.75,                last time consumption/overall running time: 56.0514s / 1971.1390 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.1644
env0_second_0:                 episode reward: 1.1500,                 loss: 0.1792
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 556.9,                last time consumption/overall running time: 54.4538s / 2025.5928 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2096
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2368
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 575.2,                last time consumption/overall running time: 56.5599s / 2082.1527 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2199
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2269
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 570.95,                last time consumption/overall running time: 56.6057s / 2138.7584 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2410
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2542
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 558.3,                last time consumption/overall running time: 54.9809s / 2193.7394 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2428
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2512
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 578.35,                last time consumption/overall running time: 56.6786s / 2250.4180 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2593
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2753
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 529.2,                last time consumption/overall running time: 51.8751s / 2302.2931 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2589
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2576
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 553.95,                last time consumption/overall running time: 54.3224s / 2356.6154 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2782
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2819
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 549.9,                last time consumption/overall running time: 54.5938s / 2411.2093 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2625
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2612
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 578.7,                last time consumption/overall running time: 56.7188s / 2467.9280 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2904
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2857
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 605.5,                last time consumption/overall running time: 59.7608s / 2527.6888 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2842
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2899
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 559.25,                last time consumption/overall running time: 56.0984s / 2583.7872 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3033
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3135
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 604.7,                last time consumption/overall running time: 59.4786s / 2643.2658 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2793
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2813
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 618.45,                last time consumption/overall running time: 60.3433s / 2703.6091 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2858
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2821
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 573.4,                last time consumption/overall running time: 56.0805s / 2759.6896 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2373
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2469
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 599.6,                last time consumption/overall running time: 58.4253s / 2818.1149 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2375
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2437
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 584.1,                last time consumption/overall running time: 58.0775s / 2876.1924 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2543
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2753
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 548.65,                last time consumption/overall running time: 54.2683s / 2930.4607 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2361
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2479
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 593.35,                last time consumption/overall running time: 58.3297s / 2988.7904 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2394
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2495
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 604.5,                last time consumption/overall running time: 58.4353s / 3047.2257 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2443
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2568
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 592.25,                last time consumption/overall running time: 56.8860s / 3104.1118 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2337
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2465
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 607.05,                last time consumption/overall running time: 58.8448s / 3162.9566 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2556
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2637
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 510.6,                last time consumption/overall running time: 50.7624s / 3213.7190 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2440
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2541
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 578.7,                last time consumption/overall running time: 56.0312s / 3269.7502 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2742
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2880
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 555.05,                last time consumption/overall running time: 54.3724s / 3324.1226 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2755
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2733
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 573.75,                last time consumption/overall running time: 55.1123s / 3379.2349 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3156
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3183
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 581.25,                last time consumption/overall running time: 56.5077s / 3435.7426 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2949
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2963
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 569.75,                last time consumption/overall running time: 55.3706s / 3491.1132 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3047
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3048
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 568.7,                last time consumption/overall running time: 55.5845s / 3546.6977 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3118
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3193
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 557.55,                last time consumption/overall running time: 54.5104s / 3601.2081 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2844
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2872
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 559.85,                last time consumption/overall running time: 54.6907s / 3655.8988 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3282
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3333
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 581.9,                last time consumption/overall running time: 56.2923s / 3712.1911 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3081
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3247
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 546.6,                last time consumption/overall running time: 54.0798s / 3766.2708 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2893
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2885
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 536.2,                last time consumption/overall running time: 52.7570s / 3819.0278 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2632
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2768
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 556.0,                last time consumption/overall running time: 54.6832s / 3873.7110 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2603
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2724
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 607.1,                last time consumption/overall running time: 58.8656s / 3932.5766 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2849
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2946
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 558.7,                last time consumption/overall running time: 55.5080s / 3988.0846 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2712
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2743
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 574.4,                last time consumption/overall running time: 56.3401s / 4044.4247 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2693
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2786
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 578.65,                last time consumption/overall running time: 56.7926s / 4101.2173 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3117
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3170
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 616.4,                last time consumption/overall running time: 59.3040s / 4160.5212 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3383
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3347
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 562.0,                last time consumption/overall running time: 56.1823s / 4216.7036 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3348
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3299
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 550.3,                last time consumption/overall running time: 54.6093s / 4271.3129 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3409
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3446
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 590.55,                last time consumption/overall running time: 57.9940s / 4329.3069 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3100
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3136
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 575.45,                last time consumption/overall running time: 56.9725s / 4386.2794 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2974
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3033
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 565.7,                last time consumption/overall running time: 55.6712s / 4441.9506 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3076
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3140
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 606.85,                last time consumption/overall running time: 59.3837s / 4501.3343 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2915
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3041
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 538.4,                last time consumption/overall running time: 54.4609s / 4555.7953 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2591
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2574
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 515.15,                last time consumption/overall running time: 51.8441s / 4607.6394 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2748
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2862
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 574.8,                last time consumption/overall running time: 57.2136s / 4664.8530 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2964
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3076
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 574.75,                last time consumption/overall running time: 57.0337s / 4721.8867 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2908
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2944
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 574.15,                last time consumption/overall running time: 56.7104s / 4778.5971 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2996
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2976
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 578.35,                last time consumption/overall running time: 56.8848s / 4835.4819 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2942
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2966
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 551.0,                last time consumption/overall running time: 54.5492s / 4890.0312 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2833
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2922
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 552.8,                last time consumption/overall running time: 54.4157s / 4944.4469 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2755
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2768
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 527.75,                last time consumption/overall running time: 52.2448s / 4996.6916 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2987
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2962
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 592.8,                last time consumption/overall running time: 57.9309s / 5054.6225 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.2630
env0_second_0:                 episode reward: -1.2000,                 loss: 0.2709
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 541.8,                last time consumption/overall running time: 53.5293s / 5108.1518 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2802
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2902
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 562.3,                last time consumption/overall running time: 55.0003s / 5163.1521 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2612
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2669
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 543.6,                last time consumption/overall running time: 54.1404s / 5217.2925 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2823
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2795
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 598.9,                last time consumption/overall running time: 58.5110s / 5275.8034 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2733
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2709
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 602.95,                last time consumption/overall running time: 58.2869s / 5334.0903 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2404
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2427
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 587.6,                last time consumption/overall running time: 57.4070s / 5391.4973 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2551
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2562
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 546.1,                last time consumption/overall running time: 54.9406s / 5446.4378 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2734
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2815
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 568.0,                last time consumption/overall running time: 56.0626s / 5502.5005 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2616
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2550
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 559.7,                last time consumption/overall running time: 54.9044s / 5557.4049 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2385
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2554
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 583.05,                last time consumption/overall running time: 57.5881s / 5614.9930 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.2637
env0_second_0:                 episode reward: -1.3000,                 loss: 0.2738
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 564.9,                last time consumption/overall running time: 55.6719s / 5670.6649 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2883
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2971
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 581.4,                last time consumption/overall running time: 56.7384s / 5727.4034 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2746
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2769
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 617.2,                last time consumption/overall running time: 59.2479s / 5786.6512 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2782
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2868
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 533.5,                last time consumption/overall running time: 52.3225s / 5838.9737 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2503
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2604
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 584.3,                last time consumption/overall running time: 56.6079s / 5895.5817 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2659
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2649
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 565.55,                last time consumption/overall running time: 55.2667s / 5950.8484 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2691
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2786
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 557.3,                last time consumption/overall running time: 55.5014s / 6006.3498 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2914
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2928
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 590.25,                last time consumption/overall running time: 57.3956s / 6063.7454 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3165
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3144
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 575.0,                last time consumption/overall running time: 56.5127s / 6120.2581 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2862
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2934
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 543.65,                last time consumption/overall running time: 53.5107s / 6173.7688 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2836
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2877
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 580.45,                last time consumption/overall running time: 56.6959s / 6230.4647 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2841
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2878
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 561.15,                last time consumption/overall running time: 55.3546s / 6285.8194 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2804
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2880
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 581.15,                last time consumption/overall running time: 57.1128s / 6342.9322 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2507
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2635
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 608.1,                last time consumption/overall running time: 58.4609s / 6401.3931 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2539
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2719
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 590.75,                last time consumption/overall running time: 58.0991s / 6459.4923 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2961
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3027
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 557.1,                last time consumption/overall running time: 55.0612s / 6514.5535 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2614
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2631
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 577.6,                last time consumption/overall running time: 56.8902s / 6571.4436 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2746
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2729
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 554.2,                last time consumption/overall running time: 55.5074s / 6626.9510 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2608
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2683
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 609.0,                last time consumption/overall running time: 59.2348s / 6686.1858 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2446
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2567
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 557.4,                last time consumption/overall running time: 55.1329s / 6741.3187 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2226
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2181
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 572.6,                last time consumption/overall running time: 56.0179s / 6797.3367 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2234
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2283
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 563.2,                last time consumption/overall running time: 55.8628s / 6853.1994 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2339
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2480
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 600.55,                last time consumption/overall running time: 58.3832s / 6911.5826 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2229
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2305
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 601.75,                last time consumption/overall running time: 58.1678s / 6969.7504 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2139
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2092
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 592.75,                last time consumption/overall running time: 58.0707s / 7027.8211 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2013
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2108
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 610.05,                last time consumption/overall running time: 59.9457s / 7087.7668 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2486
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2695
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 581.6,                last time consumption/overall running time: 57.2289s / 7144.9957 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2240
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2414
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 622.0,                last time consumption/overall running time: 59.7760s / 7204.7717 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2329
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2440
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 642.75,                last time consumption/overall running time: 61.8674s / 7266.6391 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2180
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2135
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 569.4,                last time consumption/overall running time: 56.0016s / 7322.6407 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2584
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2649
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 573.65,                last time consumption/overall running time: 55.9441s / 7378.5848 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2312
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2306
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 574.8,                last time consumption/overall running time: 55.9138s / 7434.4986 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2493
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2607
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 596.2,                last time consumption/overall running time: 58.1744s / 7492.6730 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2547
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2588
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 585.9,                last time consumption/overall running time: 57.9327s / 7550.6057 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2559
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2724
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 561.3,                last time consumption/overall running time: 56.2009s / 7606.8066 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2586
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2720
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 567.2,                last time consumption/overall running time: 55.4434s / 7662.2500 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2219
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2255
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 546.3,                last time consumption/overall running time: 53.4473s / 7715.6972 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2514
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2586
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 544.25,                last time consumption/overall running time: 53.6075s / 7769.3047 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2485
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2524
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 560.6,                last time consumption/overall running time: 55.7643s / 7825.0691 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2495
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2589
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 530.9,                last time consumption/overall running time: 53.0629s / 7878.1320 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2671
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2872
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 558.75,                last time consumption/overall running time: 55.4887s / 7933.6206 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3088
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3205
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 549.8,                last time consumption/overall running time: 53.9867s / 7987.6074 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2880
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2927
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 593.65,                last time consumption/overall running time: 58.3646s / 8045.9720 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2940
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3068
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 581.55,                last time consumption/overall running time: 57.8094s / 8103.7814 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2892
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2931
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 582.3,                last time consumption/overall running time: 58.0575s / 8161.8389 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3001
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3110
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 560.65,                last time consumption/overall running time: 55.3662s / 8217.2051 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2865
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2975
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 540.45,                last time consumption/overall running time: 53.6773s / 8270.8824 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2896
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3003
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 594.7,                last time consumption/overall running time: 58.4754s / 8329.3579 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3036
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3134
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 560.4,                last time consumption/overall running time: 55.5163s / 8384.8742 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.3021
env0_second_0:                 episode reward: -1.1000,                 loss: 0.3104
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 557.95,                last time consumption/overall running time: 56.0804s / 8440.9546 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2816
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2903
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 583.25,                last time consumption/overall running time: 57.7572s / 8498.7118 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2863
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3040
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 564.8,                last time consumption/overall running time: 56.1634s / 8554.8752 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2830
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2997
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 580.35,                last time consumption/overall running time: 56.7359s / 8611.6111 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2786
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2870
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 558.35,                last time consumption/overall running time: 54.9499s / 8666.5610 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2764
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2866
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 601.1,                last time consumption/overall running time: 58.9563s / 8725.5173 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3054
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3096
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 549.6,                last time consumption/overall running time: 54.2355s / 8779.7528 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2809
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2856
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 554.45,                last time consumption/overall running time: 54.6932s / 8834.4460 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2876
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2911
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 578.55,                last time consumption/overall running time: 56.6554s / 8891.1014 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2844
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2913
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 524.0,                last time consumption/overall running time: 51.8646s / 8942.9660 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3019
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3106
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 551.05,                last time consumption/overall running time: 53.5149s / 8996.4809 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3052
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3143
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 549.8,                last time consumption/overall running time: 53.7458s / 9050.2267 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2659
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2732
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 541.3,                last time consumption/overall running time: 53.7475s / 9103.9742 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2623
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2726
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 561.7,                last time consumption/overall running time: 55.4401s / 9159.4143 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2662
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2685
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 577.95,                last time consumption/overall running time: 56.8153s / 9216.2296 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2512
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2569
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 576.3,                last time consumption/overall running time: 56.2345s / 9272.4641 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2741
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2767
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 590.2,                last time consumption/overall running time: 56.8079s / 9329.2720 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2880
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2974
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 568.5,                last time consumption/overall running time: 55.7680s / 9385.0399 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2365
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2420
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 559.1,                last time consumption/overall running time: 55.8115s / 9440.8514 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2673
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2703
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 555.25,                last time consumption/overall running time: 54.5585s / 9495.4099 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2273
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2433
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 543.9,                last time consumption/overall running time: 53.0236s / 9548.4335 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2263
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2402
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 564.0,                last time consumption/overall running time: 55.0003s / 9603.4338 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2688
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2840
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 602.1,                last time consumption/overall running time: 58.8750s / 9662.3088 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2427
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2571
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 581.6,                last time consumption/overall running time: 56.9139s / 9719.2227 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2551
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2685
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 555.8,                last time consumption/overall running time: 54.9532s / 9774.1759 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2688
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2780
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 564.3,                last time consumption/overall running time: 55.3268s / 9829.5028 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2573
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2675
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 587.55,                last time consumption/overall running time: 57.6856s / 9887.1883 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2876
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2927
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 578.45,                last time consumption/overall running time: 55.8391s / 9943.0274 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2650
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2747
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 547.2,                last time consumption/overall running time: 53.8394s / 9996.8667 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2665
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2671
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 592.3,                last time consumption/overall running time: 58.0954s / 10054.9621 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2807
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2956
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 603.1,                last time consumption/overall running time: 58.5955s / 10113.5576 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2739
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2878
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 518.85,                last time consumption/overall running time: 51.1638s / 10164.7214 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2774
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2908
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 583.05,                last time consumption/overall running time: 56.4669s / 10221.1883 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3203
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3329
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 561.35,                last time consumption/overall running time: 55.3721s / 10276.5603 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2989
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3054
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 565.5,                last time consumption/overall running time: 55.7441s / 10332.3044 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3327
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3421
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 551.85,                last time consumption/overall running time: 54.7051s / 10387.0095 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3415
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3474
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 582.75,                last time consumption/overall running time: 57.3540s / 10444.3634 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3562
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3686
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 561.95,                last time consumption/overall running time: 54.6757s / 10499.0391 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3508
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3491
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 545.95,                last time consumption/overall running time: 53.1849s / 10552.2240 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3335
env0_second_0:                 episode reward: -1.2000,                 loss: 0.3371
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 579.85,                last time consumption/overall running time: 55.8142s / 10608.0383 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3489
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3524
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 562.5,                last time consumption/overall running time: 54.4783s / 10662.5166 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3427
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3431
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 576.05,                last time consumption/overall running time: 56.0406s / 10718.5572 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3263
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3366
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 523.85,                last time consumption/overall running time: 51.9925s / 10770.5497 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3055
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3090
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 564.3,                last time consumption/overall running time: 55.3821s / 10825.9318 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3319
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3325
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 560.15,                last time consumption/overall running time: 54.5773s / 10880.5091 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3260
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3319
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 552.45,                last time consumption/overall running time: 54.6307s / 10935.1398 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3330
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3467
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 540.95,                last time consumption/overall running time: 53.1669s / 10988.3067 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3286
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3342
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 605.95,                last time consumption/overall running time: 58.3649s / 11046.6716 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3265
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3290
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 573.15,                last time consumption/overall running time: 56.1077s / 11102.7793 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3353
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3415
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 585.65,                last time consumption/overall running time: 56.7726s / 11159.5519 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3511
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3573
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 598.05,                last time consumption/overall running time: 56.9735s / 11216.5254 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3179
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3262
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 562.8,                last time consumption/overall running time: 54.5645s / 11271.0898 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3144
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3281
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 545.65,                last time consumption/overall running time: 54.1860s / 11325.2758 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3174
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3305
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 592.8,                last time consumption/overall running time: 58.0437s / 11383.3195 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3200
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3230
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 566.9,                last time consumption/overall running time: 56.1901s / 11439.5096 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3103
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3133
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 601.6,                last time consumption/overall running time: 58.8116s / 11498.3212 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3048
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3132
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 569.9,                last time consumption/overall running time: 55.8175s / 11554.1386 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2850
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2975
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 574.85,                last time consumption/overall running time: 56.8041s / 11610.9427 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2951
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3081
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 598.1,                last time consumption/overall running time: 57.4605s / 11668.4032 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2937
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3056
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 536.95,                last time consumption/overall running time: 51.7931s / 11720.1963 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2793
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2889
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 573.85,                last time consumption/overall running time: 55.4238s / 11775.6202 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2577
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2787
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 575.95,                last time consumption/overall running time: 56.1917s / 11831.8118 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3025
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3178
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 565.95,                last time consumption/overall running time: 55.0074s / 11886.8193 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3164
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3288
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 574.9,                last time consumption/overall running time: 55.1723s / 11941.9915 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3003
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3114
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 585.75,                last time consumption/overall running time: 56.9761s / 11998.9676 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3353
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3519
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 587.15,                last time consumption/overall running time: 56.5251s / 12055.4927 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3016
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3111
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 566.35,                last time consumption/overall running time: 54.8255s / 12110.3182 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2991
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3034
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 554.9,                last time consumption/overall running time: 55.0840s / 12165.4022 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2749
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2954
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 589.65,                last time consumption/overall running time: 57.6931s / 12223.0953 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2941
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2965
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 556.4,                last time consumption/overall running time: 54.6910s / 12277.7862 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3285
env0_second_0:                 episode reward: 1.3000,                 loss: 0.3305
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 585.5,                last time consumption/overall running time: 57.3602s / 12335.1464 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2836
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2865
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 604.9,                last time consumption/overall running time: 58.5500s / 12393.6964 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3071
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3172
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 576.65,                last time consumption/overall running time: 56.4724s / 12450.1688 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3052
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3179
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 577.85,                last time consumption/overall running time: 55.8133s / 12505.9821 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2890
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3115
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 582.4,                last time consumption/overall running time: 56.4869s / 12562.4690 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2761
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2888
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 564.8,                last time consumption/overall running time: 54.9781s / 12617.4471 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2931
env0_second_0:                 episode reward: 1.4500,                 loss: 0.3048
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 533.0,                last time consumption/overall running time: 52.6172s / 12670.0643 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3031
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3251
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 609.65,                last time consumption/overall running time: 58.8411s / 12728.9053 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3344
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3591
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 546.35,                last time consumption/overall running time: 53.5025s / 12782.4078 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3247
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3496
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 601.6,                last time consumption/overall running time: 58.6182s / 12841.0261 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3329
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3385
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 556.6,                last time consumption/overall running time: 54.9008s / 12895.9268 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3049
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3177
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 600.65,                last time consumption/overall running time: 57.7167s / 12953.6435 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2901
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3086
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 567.35,                last time consumption/overall running time: 54.6381s / 13008.2816 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2797
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2913
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 558.35,                last time consumption/overall running time: 55.0798s / 13063.3614 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2898
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3088
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 555.85,                last time consumption/overall running time: 54.9650s / 13118.3264 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3090
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3320
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 537.35,                last time consumption/overall running time: 52.3993s / 13170.7257 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2655
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2817
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 551.65,                last time consumption/overall running time: 55.0228s / 13225.7485 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3012
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3038
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 541.3,                last time consumption/overall running time: 53.9706s / 13279.7191 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3273
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3365
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 615.95,                last time consumption/overall running time: 60.7303s / 13340.4494 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3283
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3319
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 584.9,                last time consumption/overall running time: 57.4489s / 13397.8983 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2819
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2861
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 542.45,                last time consumption/overall running time: 53.9559s / 13451.8542 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2877
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2897
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 562.0,                last time consumption/overall running time: 55.5572s / 13507.4114 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2685
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2732
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 550.95,                last time consumption/overall running time: 54.0529s / 13561.4643 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2436
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2484
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 549.15,                last time consumption/overall running time: 54.5220s / 13615.9862 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2617
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2631
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 613.4,                last time consumption/overall running time: 59.6555s / 13675.6417 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2760
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2740
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 587.15,                last time consumption/overall running time: 57.2415s / 13732.8833 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2810
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2870
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 583.85,                last time consumption/overall running time: 57.0267s / 13789.9100 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3072
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3165
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 586.15,                last time consumption/overall running time: 57.2629s / 13847.1729 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3000
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3159
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 588.0,                last time consumption/overall running time: 57.8639s / 13905.0369 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2913
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3024
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 547.1,                last time consumption/overall running time: 53.9423s / 13958.9791 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2880
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2928
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 593.3,                last time consumption/overall running time: 58.7197s / 14017.6988 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3234
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3166
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 533.1,                last time consumption/overall running time: 53.5581s / 14071.2570 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2800
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2900
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 570.55,                last time consumption/overall running time: 56.3549s / 14127.6119 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3081
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3177
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 569.6,                last time consumption/overall running time: 55.9055s / 14183.5174 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2708
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2809
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 545.5,                last time consumption/overall running time: 53.7501s / 14237.2675 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2997
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2936
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 507.1,                last time consumption/overall running time: 50.4507s / 14287.7182 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2769
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2787
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 592.1,                last time consumption/overall running time: 57.8793s / 14345.5975 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3005
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2983
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 585.5,                last time consumption/overall running time: 57.6976s / 14403.2951 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3151
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3227
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 582.6,                last time consumption/overall running time: 56.8936s / 14460.1886 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3003
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3022
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 559.05,                last time consumption/overall running time: 55.6011s / 14515.7897 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3112
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3190
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 560.0,                last time consumption/overall running time: 55.0870s / 14570.8767 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2778
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2858
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 539.5,                last time consumption/overall running time: 53.5640s / 14624.4407 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2881
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2933
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 582.75,                last time consumption/overall running time: 56.7954s / 14681.2361 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3008
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3017
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 559.7,                last time consumption/overall running time: 55.5987s / 14736.8348 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2800
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2811
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 569.65,                last time consumption/overall running time: 56.2216s / 14793.0564 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2795
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2811
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 532.9,                last time consumption/overall running time: 53.0799s / 14846.1363 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2828
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2944
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 548.15,                last time consumption/overall running time: 54.6121s / 14900.7484 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2965
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3070
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 579.2,                last time consumption/overall running time: 57.3604s / 14958.1089 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3048
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3055
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 566.45,                last time consumption/overall running time: 55.7585s / 15013.8674 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2926
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3076
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 528.7,                last time consumption/overall running time: 52.7336s / 15066.6010 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3342
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3373
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 584.85,                last time consumption/overall running time: 56.5894s / 15123.1904 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2974
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3121
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 562.6,                last time consumption/overall running time: 55.1136s / 15178.3039 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3070
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3174
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 563.05,                last time consumption/overall running time: 55.4142s / 15233.7182 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3019
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3212
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 608.7,                last time consumption/overall running time: 59.2211s / 15292.9393 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2942
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2965
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 505.45,                last time consumption/overall running time: 50.5463s / 15343.4856 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2744
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2808
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 559.5,                last time consumption/overall running time: 55.1096s / 15398.5952 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3025
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3064
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 549.95,                last time consumption/overall running time: 54.4988s / 15453.0940 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2890
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3053
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 522.3,                last time consumption/overall running time: 52.6540s / 15505.7479 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2961
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3146
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 563.05,                last time consumption/overall running time: 55.8801s / 15561.6280 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2865
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2900
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 575.2,                last time consumption/overall running time: 56.7697s / 15618.3977 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2863
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2930
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 574.95,                last time consumption/overall running time: 55.8792s / 15674.2770 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2920
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2946
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 567.65,                last time consumption/overall running time: 54.8586s / 15729.1356 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3029
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3040
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 574.7,                last time consumption/overall running time: 56.3817s / 15785.5173 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2944
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3184
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 600.75,                last time consumption/overall running time: 58.0046s / 15843.5219 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2871
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2910
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 557.1,                last time consumption/overall running time: 55.2280s / 15898.7500 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.2932
env0_second_0:                 episode reward: -1.6000,                 loss: 0.3114
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 560.75,                last time consumption/overall running time: 55.4091s / 15954.1590 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2647
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2800
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 559.7,                last time consumption/overall running time: 55.1111s / 16009.2701 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2844
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2917
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 560.05,                last time consumption/overall running time: 54.5947s / 16063.8649 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3003
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3151
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 575.8,                last time consumption/overall running time: 55.7485s / 16119.6134 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3242
env0_second_0:                 episode reward: 1.3000,                 loss: 0.3315
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 577.7,                last time consumption/overall running time: 56.2374s / 16175.8507 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2874
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3045
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 586.45,                last time consumption/overall running time: 57.0809s / 16232.9316 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3041
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3357
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 593.05,                last time consumption/overall running time: 57.5736s / 16290.5052 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2815
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3029
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 566.25,                last time consumption/overall running time: 55.8562s / 16346.3615 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3186
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3218
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 556.55,                last time consumption/overall running time: 54.8881s / 16401.2496 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2710
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2969
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 538.9,                last time consumption/overall running time: 53.4804s / 16454.7300 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2361
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2420
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 580.0,                last time consumption/overall running time: 57.6128s / 16512.3428 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2618
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2682
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 588.25,                last time consumption/overall running time: 57.8436s / 16570.1863 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2617
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2721
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 564.0,                last time consumption/overall running time: 55.1779s / 16625.3642 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2932
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3079
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 587.4,                last time consumption/overall running time: 57.1187s / 16682.4829 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2982
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3060
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 542.0,                last time consumption/overall running time: 54.2203s / 16736.7032 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3031
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3115
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 541.15,                last time consumption/overall running time: 52.4682s / 16789.1714 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3197
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3329
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 599.8,                last time consumption/overall running time: 58.1415s / 16847.3130 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3293
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3357
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 555.35,                last time consumption/overall running time: 54.7633s / 16902.0763 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3001
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3183
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 573.4,                last time consumption/overall running time: 55.3694s / 16957.4457 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3126
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3199
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 587.85,                last time consumption/overall running time: 57.2129s / 17014.6586 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3088
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3124
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 560.05,                last time consumption/overall running time: 54.7543s / 17069.4130 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3166
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3349
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 575.9,                last time consumption/overall running time: 57.4290s / 17126.8419 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2988
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3058
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 560.9,                last time consumption/overall running time: 55.7286s / 17182.5705 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2924
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3025
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 571.8,                last time consumption/overall running time: 56.8316s / 17239.4022 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.3238
env0_second_0:                 episode reward: 1.4000,                 loss: 0.3389
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 542.85,                last time consumption/overall running time: 53.9388s / 17293.3409 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3165
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3296
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 566.7,                last time consumption/overall running time: 55.7420s / 17349.0829 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3453
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3635
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 566.25,                last time consumption/overall running time: 56.3041s / 17405.3870 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3235
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3346
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 593.5,                last time consumption/overall running time: 58.1606s / 17463.5476 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3637
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3801
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 572.4,                last time consumption/overall running time: 56.7070s / 17520.2547 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3568
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3723
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 564.9,                last time consumption/overall running time: 55.6013s / 17575.8560 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2963
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3027
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 552.0,                last time consumption/overall running time: 55.3036s / 17631.1596 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3521
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3649
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 574.65,                last time consumption/overall running time: 56.8656s / 17688.0252 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3778
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3879
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 546.7,                last time consumption/overall running time: 54.4404s / 17742.4655 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3379
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3461
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 565.3,                last time consumption/overall running time: 55.8931s / 17798.3586 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3788
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3878
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 551.9,                last time consumption/overall running time: 55.3599s / 17853.7185 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3169
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3333
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 578.7,                last time consumption/overall running time: 57.3172s / 17911.0357 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3079
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3286
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 597.25,                last time consumption/overall running time: 58.6113s / 17969.6470 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2831
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2856
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 554.05,                last time consumption/overall running time: 54.5004s / 18024.1474 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3311
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3341
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 534.95,                last time consumption/overall running time: 53.0723s / 18077.2197 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2875
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2950
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 576.8,                last time consumption/overall running time: 56.6353s / 18133.8550 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3346
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3376
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 591.05,                last time consumption/overall running time: 57.7978s / 18191.6528 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2999
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3108
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 540.25,                last time consumption/overall running time: 53.2879s / 18244.9407 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2689
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2877
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 533.4,                last time consumption/overall running time: 52.8741s / 18297.8149 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2846
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3018
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 582.6,                last time consumption/overall running time: 57.2717s / 18355.0865 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3191
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3410
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 528.85,                last time consumption/overall running time: 52.1674s / 18407.2540 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2854
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2944
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 552.0,                last time consumption/overall running time: 54.9147s / 18462.1687 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2771
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2930
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 568.25,                last time consumption/overall running time: 55.8943s / 18518.0630 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2840
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2900
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 552.75,                last time consumption/overall running time: 54.6361s / 18572.6992 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2726
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2829
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 548.95,                last time consumption/overall running time: 53.8896s / 18626.5887 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2416
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2598
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 599.3,                last time consumption/overall running time: 58.4272s / 18685.0160 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2759
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2896
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 558.95,                last time consumption/overall running time: 55.9979s / 18741.0139 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2672
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2870
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 614.2,                last time consumption/overall running time: 59.4027s / 18800.4166 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2501
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2571
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 578.4,                last time consumption/overall running time: 56.8283s / 18857.2449 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.2532
env0_second_0:                 episode reward: -1.2000,                 loss: 0.2640
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 580.7,                last time consumption/overall running time: 57.7090s / 18914.9538 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2632
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2712
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 580.0,                last time consumption/overall running time: 57.3355s / 18972.2893 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2733
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2849
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 579.55,                last time consumption/overall running time: 56.7774s / 19029.0667 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2641
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2756
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 566.35,                last time consumption/overall running time: 55.8956s / 19084.9623 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2927
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3095
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 546.9,                last time consumption/overall running time: 54.9405s / 19139.9027 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2744
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2937
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 563.05,                last time consumption/overall running time: 55.9844s / 19195.8871 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2749
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2881
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 573.2,                last time consumption/overall running time: 56.3583s / 19252.2455 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3043
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3220
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 569.35,                last time consumption/overall running time: 55.9410s / 19308.1865 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3132
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3261
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 569.6,                last time consumption/overall running time: 55.8552s / 19364.0417 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.2771
env0_second_0:                 episode reward: -1.2500,                 loss: 0.2911
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 579.75,                last time consumption/overall running time: 56.7881s / 19420.8297 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2967
env0_second_0:                 episode reward: -1.1000,                 loss: 0.3180
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 552.15,                last time consumption/overall running time: 54.8640s / 19475.6937 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2910
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2983
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 607.75,                last time consumption/overall running time: 59.1235s / 19534.8172 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2791
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2978
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 540.5,                last time consumption/overall running time: 53.5038s / 19588.3210 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2595
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2680
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 571.85,                last time consumption/overall running time: 55.9642s / 19644.2852 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3083
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3334
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 567.0,                last time consumption/overall running time: 54.8508s / 19699.1361 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2833
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3066
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 572.9,                last time consumption/overall running time: 56.0650s / 19755.2011 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2851
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2997
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 604.1,                last time consumption/overall running time: 58.6453s / 19813.8464 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2691
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2899
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 585.5,                last time consumption/overall running time: 56.6025s / 19870.4490 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2891
env0_second_0:                 episode reward: -1.1000,                 loss: 0.3103
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 589.25,                last time consumption/overall running time: 57.4732s / 19927.9221 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2940
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2971
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 572.65,                last time consumption/overall running time: 55.6620s / 19983.5842 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2392
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2461
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 569.45,                last time consumption/overall running time: 55.4022s / 20038.9863 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2878
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3020
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 549.65,                last time consumption/overall running time: 53.3848s / 20092.3711 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3358
env0_second_0:                 episode reward: -1.2000,                 loss: 0.3558
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 570.95,                last time consumption/overall running time: 55.8970s / 20148.2681 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3135
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3201
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 514.25,                last time consumption/overall running time: 51.6289s / 20199.8970 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3012
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3179
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 584.95,                last time consumption/overall running time: 57.6693s / 20257.5662 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2709
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2867
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 594.3,                last time consumption/overall running time: 58.6025s / 20316.1687 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2311
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2544
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 519.95,                last time consumption/overall running time: 51.4754s / 20367.6441 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2826
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2899
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 575.0,                last time consumption/overall running time: 56.6668s / 20424.3110 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2609
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2684
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 572.55,                last time consumption/overall running time: 56.0370s / 20480.3480 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2751
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2899
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 567.4,                last time consumption/overall running time: 55.4018s / 20535.7498 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3037
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3165
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 508.6,                last time consumption/overall running time: 50.4611s / 20586.2108 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2780
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2928
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 575.15,                last time consumption/overall running time: 55.5915s / 20641.8024 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2790
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2880
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 565.5,                last time consumption/overall running time: 55.9267s / 20697.7290 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2737
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2732
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 593.25,                last time consumption/overall running time: 58.8299s / 20756.5590 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2998
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3108
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 549.05,                last time consumption/overall running time: 53.7192s / 20810.2781 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.2982
env0_second_0:                 episode reward: -1.2000,                 loss: 0.3005
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 539.55,                last time consumption/overall running time: 53.6704s / 20863.9485 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3053
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3127
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 581.95,                last time consumption/overall running time: 57.1463s / 20921.0948 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2900
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2946
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 577.65,                last time consumption/overall running time: 56.2226s / 20977.3175 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2989
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3072
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 593.25,                last time consumption/overall running time: 57.4302s / 21034.7476 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2847
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2863
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 595.0,                last time consumption/overall running time: 59.1775s / 21093.9252 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2756
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2918
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 559.35,                last time consumption/overall running time: 54.6515s / 21148.5767 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3016
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3009
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 540.75,                last time consumption/overall running time: 53.0746s / 21201.6512 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2775
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2961
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 544.9,                last time consumption/overall running time: 53.7920s / 21255.4432 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2934
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2911
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 562.2,                last time consumption/overall running time: 55.0537s / 21310.4969 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3015
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3217
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 556.75,                last time consumption/overall running time: 54.9755s / 21365.4724 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3005
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3137
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 556.5,                last time consumption/overall running time: 54.9839s / 21420.4563 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3137
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3218
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 587.2,                last time consumption/overall running time: 56.9913s / 21477.4476 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2959
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2999
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 573.15,                last time consumption/overall running time: 56.4807s / 21533.9284 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2929
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3034
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 607.0,                last time consumption/overall running time: 59.3006s / 21593.2290 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3010
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3098
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 580.55,                last time consumption/overall running time: 56.4691s / 21649.6981 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2651
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2910
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 607.15,                last time consumption/overall running time: 58.5745s / 21708.2725 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2409
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2541
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 552.2,                last time consumption/overall running time: 54.7491s / 21763.0216 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2941
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3161
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 554.05,                last time consumption/overall running time: 55.2213s / 21818.2428 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3029
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3311
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 589.3,                last time consumption/overall running time: 57.4606s / 21875.7034 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2966
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3115
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 557.6,                last time consumption/overall running time: 55.2410s / 21930.9444 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2890
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3029
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 559.35,                last time consumption/overall running time: 54.4898s / 21985.4341 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2868
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2960
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 551.3,                last time consumption/overall running time: 54.4840s / 22039.9181 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2928
env0_second_0:                 episode reward: 0.6000,                 loss: 0.3051
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 561.0,                last time consumption/overall running time: 55.3793s / 22095.2974 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2905
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3055
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 544.7,                last time consumption/overall running time: 54.4603s / 22149.7577 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2892
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3024
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 583.8,                last time consumption/overall running time: 57.3285s / 22207.0862 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2981
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3107
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 559.1,                last time consumption/overall running time: 55.2687s / 22262.3549 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2851
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2873
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 597.65,                last time consumption/overall running time: 58.4460s / 22320.8009 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2717
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2805
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 592.4,                last time consumption/overall running time: 57.9737s / 22378.7746 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2882
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3070
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 596.05,                last time consumption/overall running time: 57.7623s / 22436.5369 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.3058
env0_second_0:                 episode reward: 1.6000,                 loss: 0.3169
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 542.9,                last time consumption/overall running time: 52.7393s / 22489.2762 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3036
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3153
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 560.25,                last time consumption/overall running time: 54.6497s / 22543.9259 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2715
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2849
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 611.85,                last time consumption/overall running time: 59.0969s / 22603.0227 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3043
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3098
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 555.55,                last time consumption/overall running time: 54.4741s / 22657.4969 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2912
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2996
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 545.7,                last time consumption/overall running time: 53.6868s / 22711.1837 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2942
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3161
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 546.35,                last time consumption/overall running time: 53.4987s / 22764.6824 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2577
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2743
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 548.65,                last time consumption/overall running time: 54.0447s / 22818.7271 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3317
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3490
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 573.85,                last time consumption/overall running time: 56.1039s / 22874.8310 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3127
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3245
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 580.4,                last time consumption/overall running time: 56.1334s / 22930.9644 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3130
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3261
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 561.65,                last time consumption/overall running time: 54.2600s / 22985.2244 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2795
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2829
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 574.4,                last time consumption/overall running time: 55.5163s / 23040.7407 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3242
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3344
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 572.5,                last time consumption/overall running time: 55.7527s / 23096.4933 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2959
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3025
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 545.7,                last time consumption/overall running time: 54.1240s / 23150.6173 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2974
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3055
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 570.0,                last time consumption/overall running time: 56.3467s / 23206.9640 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2977
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3181
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 528.0,                last time consumption/overall running time: 52.5350s / 23259.4990 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2859
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2958
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 551.8,                last time consumption/overall running time: 54.6904s / 23314.1894 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3024
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3290
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 545.7,                last time consumption/overall running time: 53.9332s / 23368.1226 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3300
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3344
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 543.75,                last time consumption/overall running time: 54.0591s / 23422.1816 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3085
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3211
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 559.05,                last time consumption/overall running time: 56.1465s / 23478.3281 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3334
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3395
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 578.05,                last time consumption/overall running time: 56.8297s / 23535.1578 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3144
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3174
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 583.2,                last time consumption/overall running time: 56.5036s / 23591.6614 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3133
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3319
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 536.55,                last time consumption/overall running time: 53.3354s / 23644.9967 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3140
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3325
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 575.05,                last time consumption/overall running time: 56.5362s / 23701.5329 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2967
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3124
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 572.65,                last time consumption/overall running time: 56.2865s / 23757.8194 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2951
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3035
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 578.25,                last time consumption/overall running time: 56.7668s / 23814.5863 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2967
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3139
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 586.45,                last time consumption/overall running time: 57.0156s / 23871.6018 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.3073
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3186
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 525.3,                last time consumption/overall running time: 51.4811s / 23923.0830 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3012
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3114
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 544.4,                last time consumption/overall running time: 53.5003s / 23976.5833 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2879
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3137
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 591.15,                last time consumption/overall running time: 57.5483s / 24034.1316 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2769
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3062
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 584.4,                last time consumption/overall running time: 57.0140s / 24091.1456 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2819
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2948
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 566.55,                last time consumption/overall running time: 55.7012s / 24146.8468 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2775
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2762
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 560.1,                last time consumption/overall running time: 55.2748s / 24202.1216 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2647
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2692
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 566.9,                last time consumption/overall running time: 54.8237s / 24256.9453 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2989
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3069
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 568.35,                last time consumption/overall running time: 56.1511s / 24313.0964 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3224
env0_second_0:                 episode reward: 0.2000,                 loss: 0.3342
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 561.4,                last time consumption/overall running time: 55.3932s / 24368.4896 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2583
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2679
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 543.05,                last time consumption/overall running time: 54.3627s / 24422.8523 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.2835
env0_second_0:                 episode reward: -1.6500,                 loss: 0.3065
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 593.85,                last time consumption/overall running time: 58.2819s / 24481.1342 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2706
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2867
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 569.35,                last time consumption/overall running time: 56.0962s / 24537.2304 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3040
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3263
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 563.8,                last time consumption/overall running time: 56.0760s / 24593.3064 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2586
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2739
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 620.9,                last time consumption/overall running time: 59.7540s / 24653.0603 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2731
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2859
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 551.35,                last time consumption/overall running time: 54.4336s / 24707.4940 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2715
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2822
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 557.5,                last time consumption/overall running time: 55.7234s / 24763.2173 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2634
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2797
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 543.4,                last time consumption/overall running time: 54.0707s / 24817.2880 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2722
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2810
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 597.6,                last time consumption/overall running time: 57.7693s / 24875.0573 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2681
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2820
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 604.7,                last time consumption/overall running time: 57.7910s / 24932.8483 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2775
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2975
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 560.55,                last time consumption/overall running time: 55.0953s / 24987.9436 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2856
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3114
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 541.1,                last time consumption/overall running time: 53.4725s / 25041.4161 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2762
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2895
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 561.85,                last time consumption/overall running time: 55.5174s / 25096.9335 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2959
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3263
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 590.35,                last time consumption/overall running time: 57.8316s / 25154.7650 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2707
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2860
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 582.95,                last time consumption/overall running time: 57.0122s / 25211.7772 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3044
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3256
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 573.25,                last time consumption/overall running time: 56.1897s / 25267.9669 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2860
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2972
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 583.95,                last time consumption/overall running time: 56.4831s / 25324.4500 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3014
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3050
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 603.2,                last time consumption/overall running time: 58.0778s / 25382.5278 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3273
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3447
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 548.1,                last time consumption/overall running time: 54.5759s / 25437.1037 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3032
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3217
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 567.8,                last time consumption/overall running time: 56.6055s / 25493.7092 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3512
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3488
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 596.85,                last time consumption/overall running time: 58.1166s / 25551.8258 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3247
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3349
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 546.35,                last time consumption/overall running time: 53.7242s / 25605.5500 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3300
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3499
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 557.05,                last time consumption/overall running time: 55.5182s / 25661.0682 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3448
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3597
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 588.55,                last time consumption/overall running time: 57.6789s / 25718.7471 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3080
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3151
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 567.45,                last time consumption/overall running time: 55.7369s / 25774.4840 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3168
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3278
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 608.05,                last time consumption/overall running time: 60.0229s / 25834.5069 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3015
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3087
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 592.0,                last time consumption/overall running time: 57.8417s / 25892.3486 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2511
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2721
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 609.6,                last time consumption/overall running time: 59.5917s / 25951.9403 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2880
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3012
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 607.05,                last time consumption/overall running time: 59.2046s / 26011.1450 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2790
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2965
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 621.5,                last time consumption/overall running time: 60.1419s / 26071.2869 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2821
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3030
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 586.85,                last time consumption/overall running time: 57.7611s / 26129.0480 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2848
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3061
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 587.4,                last time consumption/overall running time: 57.8237s / 26186.8718 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.3061
env0_second_0:                 episode reward: 1.4500,                 loss: 0.3259
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 580.85,                last time consumption/overall running time: 57.3748s / 26244.2466 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2961
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3121
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 558.2,                last time consumption/overall running time: 54.8590s / 26299.1056 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2736
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3044
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 573.7,                last time consumption/overall running time: 57.0321s / 26356.1377 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2969
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 564.75,                last time consumption/overall running time: 55.5013s / 26411.6390 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3245
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3381
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 573.65,                last time consumption/overall running time: 56.9832s / 26468.6221 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3048
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3230
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 590.75,                last time consumption/overall running time: 58.4710s / 26527.0931 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2547
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2703
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 578.4,                last time consumption/overall running time: 57.9285s / 26585.0216 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2808
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2874
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 579.8,                last time consumption/overall running time: 58.2655s / 26643.2871 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2822
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3031
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 567.85,                last time consumption/overall running time: 56.4783s / 26699.7653 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3504
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3639
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 560.25,                last time consumption/overall running time: 56.2138s / 26755.9791 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3104
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3242
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 606.5,                last time consumption/overall running time: 60.3259s / 26816.3050 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3142
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3230
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 646.6,                last time consumption/overall running time: 63.1454s / 26879.4504 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2949
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3106
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 626.65,                last time consumption/overall running time: 61.0005s / 26940.4509 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3319
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3506
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 577.85,                last time consumption/overall running time: 57.0942s / 26997.5451 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2843
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2968
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 565.95,                last time consumption/overall running time: 55.5411s / 27053.0862 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2549
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2873
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 683.65,                last time consumption/overall running time: 65.7692s / 27118.8554 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2712
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2873
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 597.5,                last time consumption/overall running time: 58.0425s / 27176.8979 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2807
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2937
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 663.1,                last time consumption/overall running time: 63.9500s / 27240.8479 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2522
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2710
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 639.6,                last time consumption/overall running time: 62.3462s / 27303.1941 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2477
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2703
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 606.85,                last time consumption/overall running time: 59.5356s / 27362.7297 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2626
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2797
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 598.1,                last time consumption/overall running time: 58.7801s / 27421.5098 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2850
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3103
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 648.4,                last time consumption/overall running time: 62.6386s / 27484.1484 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2386
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2636
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 639.1,                last time consumption/overall running time: 61.2062s / 27545.3546 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2559
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2724
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 613.95,                last time consumption/overall running time: 59.6798s / 27605.0344 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2767
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2937
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 609.05,                last time consumption/overall running time: 59.6117s / 27664.6461 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3046
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3120
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 679.1,                last time consumption/overall running time: 65.3487s / 27729.9947 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2456
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2594
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 611.65,                last time consumption/overall running time: 59.3960s / 27789.3908 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.2249
env0_second_0:                 episode reward: 1.8500,                 loss: 0.2416Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 635.1,                last time consumption/overall running time: 61.0220s / 27850.4127 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2431
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2619
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 629.0,                last time consumption/overall running time: 61.0210s / 27911.4337 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2537
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2746
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 629.75,                last time consumption/overall running time: 61.0947s / 27972.5284 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2302
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2547
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 602.45,                last time consumption/overall running time: 58.2629s / 28030.7912 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2266
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2415
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
