env_args:
    env_name: Pong-ram-v0
    env_type: gym
    num_envs: 2
    seed: [11, 22]

agent_args:
    hidden_dim: 64
    algorithm: DQN
    algorithm_spec:
        dueling: False
        replay_buffer_size: 1e5
        gamma: 0.99
        multi_step: 1
        target_update_interval: 1000 # updates skipped to update the target
        eps_start: 1.
        eps_final: 0.01
        eps_decay: 30000  # tune according to env

train_args:
    batch_size: 32
    max_episodes: 10000
    max_steps_per_episode: 10000
    train_start_frame: 10000
    optimizer: adam
    learning_rate: 1e-4
    device: gpu
    update_itr: 1  # iterations of updates per frame, 0~inf; <1 means several steps are skipped per update
    log_avg_window: 20 # average window length in logging
    log_interval: 20  # log print interval 
    render: True
