pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fd4a6f57e50>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.018 0.018 0.018 ... 0.018 0.018 0.018]
 [0.018 0.018 0.018 ... 0.018 0.018 0.018]]
Load checkpoints (policy family):  [['50' '5253' '7615' ... '37270' '38685' '39143']
 ['193' '5289' '7712' ... '37326' '38773' '39204']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_40000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220117153310_exploit_40000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220117153310_exploit_40000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.0685s / 6.0685 s
agent0:                 episode reward: -0.8113,                 loss: nan
agent1:                 episode reward: 0.8113,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.5633s / 12.6318 s
agent0:                 episode reward: 0.2431,                 loss: nan
agent1:                 episode reward: -0.2431,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 6.4618s / 19.0936 s
agent0:                 episode reward: 0.0960,                 loss: nan
agent1:                 episode reward: -0.0960,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.4128s / 25.5063 s
agent0:                 episode reward: -0.2529,                 loss: nan
agent1:                 episode reward: 0.2529,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.9028s / 32.4092 s
agent0:                 episode reward: -0.0867,                 loss: nan
agent1:                 episode reward: 0.0867,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.2578s / 39.6669 s
agent0:                 episode reward: 0.1989,                 loss: nan
agent1:                 episode reward: -0.1989,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 7.1493s / 46.8162 s
agent0:                 episode reward: -0.0528,                 loss: nan
agent1:                 episode reward: 0.0528,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 7.3757s / 54.1920 s
agent0:                 episode reward: 0.1404,                 loss: nan
agent1:                 episode reward: -0.1404,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 7.4681s / 61.6601 s
agent0:                 episode reward: 0.0584,                 loss: nan
agent1:                 episode reward: -0.0584,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 6.6346s / 68.2947 s
agent0:                 episode reward: -0.4329,                 loss: nan
agent1:                 episode reward: 0.4329,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 6.6931s / 74.9878 s
agent0:                 episode reward: 0.2147,                 loss: nan
agent1:                 episode reward: -0.2147,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 95.7513s / 170.7392 s
agent0:                 episode reward: -0.4085,                 loss: nan
agent1:                 episode reward: 0.4085,                 loss: 0.1998
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.2045s / 418.9436 s
agent0:                 episode reward: 0.0879,                 loss: nan
agent1:                 episode reward: -0.0879,                 loss: 0.1865
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9781s / 664.9217 s
agent0:                 episode reward: 0.1027,                 loss: nan
agent1:                 episode reward: -0.1027,                 loss: 0.1718
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.7380s / 902.6597 s
agent0:                 episode reward: 0.2927,                 loss: nan
agent1:                 episode reward: -0.2927,                 loss: 0.1634
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.2961s / 1140.9558 s
agent0:                 episode reward: 0.0250,                 loss: nan
agent1:                 episode reward: -0.0250,                 loss: 0.1588
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2111s / 1387.1668 s
agent0:                 episode reward: 0.2764,                 loss: nan
agent1:                 episode reward: -0.2764,                 loss: 0.1535
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8142s / 1632.9810 s
agent0:                 episode reward: -0.0430,                 loss: nan
agent1:                 episode reward: 0.0430,                 loss: 0.1511
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0178s / 1873.9988 s
agent0:                 episode reward: 0.1811,                 loss: nan
agent1:                 episode reward: -0.1811,                 loss: 0.1475
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6085s / 2118.6072 s
agent0:                 episode reward: 0.7167,                 loss: nan
agent1:                 episode reward: -0.7167,                 loss: 0.1463
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 238.8973s / 2357.5046 s
agent0:                 episode reward: 0.3468,                 loss: nan
agent1:                 episode reward: -0.3468,                 loss: 0.1447
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 234.0211s / 2591.5257 s
agent0:                 episode reward: 0.1509,                 loss: nan
agent1:                 episode reward: -0.1509,                 loss: 0.1434
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5510s / 2839.0767 s
agent0:                 episode reward: 0.5091,                 loss: nan
agent1:                 episode reward: -0.5091,                 loss: 0.1427
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5573s / 3092.6340 s
agent0:                 episode reward: 0.3138,                 loss: nan
agent1:                 episode reward: -0.3138,                 loss: 0.1404
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8510s / 3340.4849 s
agent0:                 episode reward: 0.0311,                 loss: nan
agent1:                 episode reward: -0.0311,                 loss: 0.1394
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.5757s / 3581.0606 s
agent0:                 episode reward: 0.4403,                 loss: nan
agent1:                 episode reward: -0.4403,                 loss: 0.1381
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4818s / 3822.5424 s
agent0:                 episode reward: -0.1670,                 loss: nan
agent1:                 episode reward: 0.1670,                 loss: 0.1357
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7923s / 4075.3346 s
agent0:                 episode reward: 0.1858,                 loss: nan
agent1:                 episode reward: -0.1858,                 loss: 0.1342
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2634s / 4321.5980 s
agent0:                 episode reward: 0.3360,                 loss: nan
agent1:                 episode reward: -0.3360,                 loss: 0.1356
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9297s / 4569.5277 s
agent0:                 episode reward: 0.0701,                 loss: nan
agent1:                 episode reward: -0.0701,                 loss: 0.1317
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.4395s / 4810.9673 s
agent0:                 episode reward: -0.2783,                 loss: nan
agent1:                 episode reward: 0.2783,                 loss: 0.1293
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5129s / 5056.4802 s
agent0:                 episode reward: -0.1698,                 loss: nan
agent1:                 episode reward: 0.1698,                 loss: 0.1301
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0372s / 5297.5174 s
agent0:                 episode reward: 0.3570,                 loss: nan
agent1:                 episode reward: -0.3570,                 loss: 0.1287
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.8481s / 5534.3655 s
agent0:                 episode reward: -0.0291,                 loss: nan
agent1:                 episode reward: 0.0291,                 loss: 0.1297
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1988s / 5778.5642 s
agent0:                 episode reward: 0.2116,                 loss: nan
agent1:                 episode reward: -0.2116,                 loss: 0.1293
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9429s / 6026.5071 s
agent0:                 episode reward: 0.0226,                 loss: nan
agent1:                 episode reward: -0.0226,                 loss: 0.1282
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9187s / 6270.4258 s
agent0:                 episode reward: 0.3037,                 loss: nan
agent1:                 episode reward: -0.3037,                 loss: 0.1288
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.5741s / 6511.9999 s
agent0:                 episode reward: 0.0268,                 loss: nan
agent1:                 episode reward: -0.0268,                 loss: 0.1263
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.1078s / 6751.1077 s
agent0:                 episode reward: -0.2642,                 loss: nan
agent1:                 episode reward: 0.2642,                 loss: 0.1267
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6706s / 7005.7783 s
agent0:                 episode reward: -0.4426,                 loss: nan
agent1:                 episode reward: 0.4426,                 loss: 0.1262
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.1894s / 7246.9677 s
agent0:                 episode reward: -0.3733,                 loss: nan
agent1:                 episode reward: 0.3733,                 loss: 0.1258
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1277s / 7499.0953 s
agent0:                 episode reward: -0.0165,                 loss: nan
agent1:                 episode reward: 0.0165,                 loss: 0.1243
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0771s / 7748.1725 s
agent0:                 episode reward: -0.0605,                 loss: nan
agent1:                 episode reward: 0.0605,                 loss: 0.1251
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2375s / 7991.4100 s
agent0:                 episode reward: -0.0342,                 loss: nan
agent1:                 episode reward: 0.0342,                 loss: 0.1250
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6064s / 8240.0163 s
agent0:                 episode reward: -0.1999,                 loss: nan
agent1:                 episode reward: 0.1999,                 loss: 0.1254
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6589s / 8482.6753 s
agent0:                 episode reward: -0.0059,                 loss: nan
agent1:                 episode reward: 0.0059,                 loss: 0.1207
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8820s / 8730.5572 s
agent0:                 episode reward: -0.0051,                 loss: nan
agent1:                 episode reward: 0.0051,                 loss: 0.1210
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.0915s / 8975.6488 s
agent0:                 episode reward: -0.1489,                 loss: nan
agent1:                 episode reward: 0.1489,                 loss: 0.1203
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 240.3587s / 9216.0075 s
agent0:                 episode reward: 0.0135,                 loss: nan
agent1:                 episode reward: -0.0135,                 loss: 0.1207
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.7517s / 9457.7592 s
agent0:                 episode reward: 0.1805,                 loss: nan
agent1:                 episode reward: -0.1805,                 loss: 0.1192
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.9483s / 9695.7075 s
agent0:                 episode reward: -0.0497,                 loss: nan
agent1:                 episode reward: 0.0497,                 loss: 0.1192
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6339s / 9940.3414 s
agent0:                 episode reward: 0.2468,                 loss: nan
agent1:                 episode reward: -0.2468,                 loss: 0.1178
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2058s / 10185.5472 s
agent0:                 episode reward: 0.1796,                 loss: nan
agent1:                 episode reward: -0.1796,                 loss: 0.1193
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.9308s / 10430.4780 s
agent0:                 episode reward: -0.2275,                 loss: nan
agent1:                 episode reward: 0.2275,                 loss: 0.1186
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5331s / 10679.0112 s
agent0:                 episode reward: 0.2251,                 loss: nan
agent1:                 episode reward: -0.2251,                 loss: 0.1176
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1275s / 10926.1387 s
agent0:                 episode reward: -0.0657,                 loss: nan
agent1:                 episode reward: 0.0657,                 loss: 0.1175
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7685s / 11169.9072 s
agent0:                 episode reward: -0.4214,                 loss: nan
agent1:                 episode reward: 0.4214,                 loss: 0.1175
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6952s / 11414.6024 s
agent0:                 episode reward: -0.2750,                 loss: nan
agent1:                 episode reward: 0.2750,                 loss: 0.1168
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3064s / 11657.9088 s
agent0:                 episode reward: 0.1965,                 loss: nan
agent1:                 episode reward: -0.1965,                 loss: 0.1157
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9668s / 11910.8756 s
agent0:                 episode reward: -0.0179,                 loss: nan
agent1:                 episode reward: 0.0179,                 loss: 0.1160
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.9962s / 12158.8718 s
agent0:                 episode reward: 0.0960,                 loss: nan
agent1:                 episode reward: -0.0960,                 loss: 0.1158
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5021s / 12403.3739 s
agent0:                 episode reward: -0.1109,                 loss: nan
agent1:                 episode reward: 0.1109,                 loss: 0.1164
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7486s / 12653.1225 s
agent0:                 episode reward: -0.1525,                 loss: nan
agent1:                 episode reward: 0.1525,                 loss: 0.1141
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.6299s / 12894.7524 s
agent0:                 episode reward: -0.2290,                 loss: nan
agent1:                 episode reward: 0.2290,                 loss: 0.1149
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2946s / 13142.0469 s
agent0:                 episode reward: 0.1992,                 loss: nan
agent1:                 episode reward: -0.1992,                 loss: 0.1158
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7634s / 13382.8103 s
agent0:                 episode reward: -0.0574,                 loss: nan
agent1:                 episode reward: 0.0574,                 loss: 0.1157
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1214s / 13633.9316 s
agent0:                 episode reward: 0.0054,                 loss: nan
agent1:                 episode reward: -0.0054,                 loss: 0.1158
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1433s / 13878.0749 s
agent0:                 episode reward: 0.1980,                 loss: nan
agent1:                 episode reward: -0.1980,                 loss: 0.1166
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2424s / 14128.3173 s
agent0:                 episode reward: 0.2390,                 loss: nan
agent1:                 episode reward: -0.2390,                 loss: 0.1164
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.5815s / 14378.8988 s
agent0:                 episode reward: -0.0758,                 loss: nan
agent1:                 episode reward: 0.0758,                 loss: 0.1160
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0662s / 14624.9650 s
agent0:                 episode reward: 0.5399,                 loss: nan
agent1:                 episode reward: -0.5399,                 loss: 0.1147
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7611s / 14872.7262 s
agent0:                 episode reward: 0.2410,                 loss: nan
agent1:                 episode reward: -0.2410,                 loss: 0.1160
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1529s / 15119.8790 s
agent0:                 episode reward: -0.1447,                 loss: nan
agent1:                 episode reward: 0.1447,                 loss: 0.1163
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5920s / 15366.4710 s
agent0:                 episode reward: -0.2725,                 loss: nan
agent1:                 episode reward: 0.2725,                 loss: 0.1156
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3839s / 15613.8549 s
agent0:                 episode reward: 0.1951,                 loss: nan
agent1:                 episode reward: -0.1951,                 loss: 0.1162
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.5335s / 15869.3884 s
agent0:                 episode reward: 0.2191,                 loss: nan
agent1:                 episode reward: -0.2191,                 loss: 0.1142
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1751s / 16112.5635 s
agent0:                 episode reward: -0.1672,                 loss: nan
agent1:                 episode reward: 0.1672,                 loss: 0.1148
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1186s / 16358.6821 s
agent0:                 episode reward: 0.0527,                 loss: nan
agent1:                 episode reward: -0.0527,                 loss: 0.1140
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5348s / 16610.2169 s
agent0:                 episode reward: 0.1500,                 loss: nan
agent1:                 episode reward: -0.1500,                 loss: 0.1180
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.2900s / 16851.5069 s
agent0:                 episode reward: 0.1966,                 loss: nan
agent1:                 episode reward: -0.1966,                 loss: 0.1180
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7953s / 17098.3022 s
agent0:                 episode reward: 0.2148,                 loss: nan
agent1:                 episode reward: -0.2148,                 loss: 0.1165
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.1968s / 17353.4990 s
agent0:                 episode reward: 0.1014,                 loss: nan
agent1:                 episode reward: -0.1014,                 loss: 0.1163
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1887s / 17605.6877 s
agent0:                 episode reward: 0.1416,                 loss: nan
agent1:                 episode reward: -0.1416,                 loss: 0.1161
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8295s / 17849.5172 s
agent0:                 episode reward: -0.4101,                 loss: nan
agent1:                 episode reward: 0.4101,                 loss: 0.1177
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6439s / 18104.1611 s
agent0:                 episode reward: -0.0846,                 loss: nan
agent1:                 episode reward: 0.0846,                 loss: 0.1166
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8583s / 18347.0194 s
agent0:                 episode reward: -0.0121,                 loss: nan
agent1:                 episode reward: 0.0121,                 loss: 0.1195
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3001s / 18596.3196 s
agent0:                 episode reward: 0.1716,                 loss: nan
agent1:                 episode reward: -0.1716,                 loss: 0.1176
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.3497s / 18839.6693 s
agent0:                 episode reward: -0.0801,                 loss: nan
agent1:                 episode reward: 0.0801,                 loss: 0.1169
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.7269s / 19084.3962 s
agent0:                 episode reward: -0.1691,                 loss: nan
agent1:                 episode reward: 0.1691,                 loss: 0.1178
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7488s / 19336.1449 s
agent0:                 episode reward: 0.0918,                 loss: nan
agent1:                 episode reward: -0.0918,                 loss: 0.1181
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8908s / 19582.0358 s
agent0:                 episode reward: -0.1472,                 loss: nan
agent1:                 episode reward: 0.1472,                 loss: 0.1178
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8581s / 19827.8939 s
agent0:                 episode reward: 0.1224,                 loss: nan
agent1:                 episode reward: -0.1224,                 loss: 0.1168
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1773s / 20075.0712 s
agent0:                 episode reward: -0.0226,                 loss: nan
agent1:                 episode reward: 0.0226,                 loss: 0.1175
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5661s / 20322.6372 s
agent0:                 episode reward: 0.2853,                 loss: nan
agent1:                 episode reward: -0.2853,                 loss: 0.1177
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.4116s / 20562.0488 s
agent0:                 episode reward: -0.0544,                 loss: nan
agent1:                 episode reward: 0.0544,                 loss: 0.1170
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1675s / 20816.2164 s
agent0:                 episode reward: 0.3418,                 loss: nan
agent1:                 episode reward: -0.3418,                 loss: 0.1206
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3808s / 21065.5971 s
agent0:                 episode reward: -0.1009,                 loss: nan
agent1:                 episode reward: 0.1009,                 loss: 0.1222
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0785s / 21307.6756 s
agent0:                 episode reward: -0.3104,                 loss: nan
agent1:                 episode reward: 0.3104,                 loss: 0.1210
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.2349s / 21553.9106 s
agent0:                 episode reward: 0.1530,                 loss: nan
agent1:                 episode reward: -0.1530,                 loss: 0.1229
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6660s / 21802.5766 s
agent0:                 episode reward: 0.0591,                 loss: nan
agent1:                 episode reward: -0.0591,                 loss: 0.1219
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9933s / 22055.5699 s
agent0:                 episode reward: -0.0814,                 loss: nan
agent1:                 episode reward: 0.0814,                 loss: 0.1211
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.1008s / 22302.6707 s
agent0:                 episode reward: -0.0801,                 loss: nan
agent1:                 episode reward: 0.0801,                 loss: 0.1199
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 259.8407s / 22562.5114 s
agent0:                 episode reward: 0.2037,                 loss: nan
agent1:                 episode reward: -0.2037,                 loss: 0.1218
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.8741s / 22819.3855 s
agent0:                 episode reward: -0.0893,                 loss: nan
agent1:                 episode reward: 0.0893,                 loss: 0.1209
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.8017s / 23063.1872 s
agent0:                 episode reward: 0.2368,                 loss: nan
agent1:                 episode reward: -0.2368,                 loss: 0.1208
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1987s / 23305.3860 s
agent0:                 episode reward: -0.2853,                 loss: nan
agent1:                 episode reward: 0.2853,                 loss: 0.1214
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5531s / 23549.9390 s
agent0:                 episode reward: -0.1257,                 loss: nan
agent1:                 episode reward: 0.1257,                 loss: 0.1210
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6109s / 23799.5500 s
agent0:                 episode reward: 0.3760,                 loss: nan
agent1:                 episode reward: -0.3760,                 loss: 0.1214
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2405s / 24043.7905 s
agent0:                 episode reward: -0.3895,                 loss: nan
agent1:                 episode reward: 0.3895,                 loss: 0.1207
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4141s / 24289.2046 s
agent0:                 episode reward: -0.1147,                 loss: nan
agent1:                 episode reward: 0.1147,                 loss: 0.1217
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4195s / 24535.6241 s
agent0:                 episode reward: -0.0479,                 loss: nan
agent1:                 episode reward: 0.0479,                 loss: 0.1214
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4685s / 24785.0926 s
agent0:                 episode reward: -0.2102,                 loss: nan
agent1:                 episode reward: 0.2102,                 loss: 0.1202
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5880s / 25036.6806 s
agent0:                 episode reward: 0.0415,                 loss: nan
agent1:                 episode reward: -0.0415,                 loss: 0.1185
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0431s / 25285.7237 s
agent0:                 episode reward: -0.2081,                 loss: nan
agent1:                 episode reward: 0.2081,                 loss: 0.1176
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1888s / 25530.9125 s
agent0:                 episode reward: -0.1211,                 loss: nan
agent1:                 episode reward: 0.1211,                 loss: 0.1174
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.6815s / 25770.5940 s
agent0:                 episode reward: -0.0086,                 loss: nan
agent1:                 episode reward: 0.0086,                 loss: 0.1176
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1017s / 26015.6957 s
agent0:                 episode reward: -0.2061,                 loss: nan
agent1:                 episode reward: 0.2061,                 loss: 0.1171
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.2032s / 26259.8989 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.1174
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.1218s / 26511.0208 s
agent0:                 episode reward: -0.1417,                 loss: nan
agent1:                 episode reward: 0.1417,                 loss: 0.1171
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4206s / 26755.4414 s
agent0:                 episode reward: -0.1702,                 loss: nan
agent1:                 episode reward: 0.1702,                 loss: 0.1173
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5125s / 27003.9538 s
agent0:                 episode reward: 0.1358,                 loss: nan
agent1:                 episode reward: -0.1358,                 loss: 0.1175
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.0253s / 27241.9791 s
agent0:                 episode reward: -0.0091,                 loss: nan
agent1:                 episode reward: 0.0091,                 loss: 0.1175
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5212s / 27494.5003 s
agent0:                 episode reward: -0.6318,                 loss: nan
agent1:                 episode reward: 0.6318,                 loss: 0.1182
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 235.7155s / 27730.2158 s
agent0:                 episode reward: 0.2724,                 loss: nan
agent1:                 episode reward: -0.2724,                 loss: 0.1178
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8143s / 27978.0302 s
agent0:                 episode reward: -0.3280,                 loss: nan
agent1:                 episode reward: 0.3280,                 loss: 0.1168
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9969s / 28224.0271 s
agent0:                 episode reward: -0.1527,                 loss: nan
agent1:                 episode reward: 0.1527,                 loss: 0.1178
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1211s / 28469.1482 s
agent0:                 episode reward: -0.2774,                 loss: nan
agent1:                 episode reward: 0.2774,                 loss: 0.1174
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9948s / 28715.1431 s
agent0:                 episode reward: 0.2811,                 loss: nan
agent1:                 episode reward: -0.2811,                 loss: 0.1182
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7292s / 28960.8723 s
agent0:                 episode reward: -0.4719,                 loss: nan
agent1:                 episode reward: 0.4719,                 loss: 0.1196
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1302s / 29207.0025 s
agent0:                 episode reward: 0.0435,                 loss: nan
agent1:                 episode reward: -0.0435,                 loss: 0.1212
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1008s / 29456.1032 s
agent0:                 episode reward: -0.2156,                 loss: nan
agent1:                 episode reward: 0.2156,                 loss: 0.1197
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6597s / 29700.7629 s
agent0:                 episode reward: 0.3457,                 loss: nan
agent1:                 episode reward: -0.3457,                 loss: 0.1199
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 236.7621s / 29937.5249 s
agent0:                 episode reward: -0.0577,                 loss: nan
agent1:                 episode reward: 0.0577,                 loss: 0.1200
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0482s / 30178.5732 s
agent0:                 episode reward: -0.1253,                 loss: nan
agent1:                 episode reward: 0.1253,                 loss: 0.1196
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4706s / 30421.0438 s
agent0:                 episode reward: 0.2765,                 loss: nan
agent1:                 episode reward: -0.2765,                 loss: 0.1210
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4096s / 30666.4534 s
agent0:                 episode reward: -0.2158,                 loss: nan
agent1:                 episode reward: 0.2158,                 loss: 0.1202
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7102s / 30913.1636 s
agent0:                 episode reward: -0.1460,                 loss: nan
agent1:                 episode reward: 0.1460,                 loss: 0.1207
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1006s / 31161.2641 s
agent0:                 episode reward: 0.0838,                 loss: nan
agent1:                 episode reward: -0.0838,                 loss: 0.1205
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 237.3863s / 31398.6504 s
agent0:                 episode reward: 0.0012,                 loss: nan
agent1:                 episode reward: -0.0012,                 loss: 0.1200
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 238.7027s / 31637.3531 s
agent0:                 episode reward: -0.1909,                 loss: nan
agent1:                 episode reward: 0.1909,                 loss: 0.1216
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 262.2594s / 31899.6125 s
agent0:                 episode reward: -0.0909,                 loss: nan
agent1:                 episode reward: 0.0909,                 loss: 0.1206
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8971s / 32151.5096 s
agent0:                 episode reward: -0.1039,                 loss: nan
agent1:                 episode reward: 0.1039,                 loss: 0.1200
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0569s / 32401.5665 s
agent0:                 episode reward: -0.4053,                 loss: nan
agent1:                 episode reward: 0.4053,                 loss: 0.1205
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0540s / 32651.6205 s
agent0:                 episode reward: 0.1554,                 loss: nan
agent1:                 episode reward: -0.1554,                 loss: 0.1209
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8070s / 32900.4275 s
agent0:                 episode reward: -0.0115,                 loss: nan
agent1:                 episode reward: 0.0115,                 loss: 0.1203
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0361s / 33147.4636 s
agent0:                 episode reward: -0.2071,                 loss: nan
agent1:                 episode reward: 0.2071,                 loss: 0.1199
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8531s / 33399.3166 s
agent0:                 episode reward: -0.1256,                 loss: nan
agent1:                 episode reward: 0.1256,                 loss: 0.1197
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2186s / 33642.5352 s
agent0:                 episode reward: 0.0440,                 loss: nan
agent1:                 episode reward: -0.0440,                 loss: 0.1189
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1291s / 33888.6643 s
agent0:                 episode reward: -0.2320,                 loss: nan
agent1:                 episode reward: 0.2320,                 loss: 0.1189
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.4718s / 34131.1360 s
agent0:                 episode reward: -0.3865,                 loss: nan
agent1:                 episode reward: 0.3865,                 loss: 0.1194
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8803s / 34374.0164 s
agent0:                 episode reward: 0.0871,                 loss: nan
agent1:                 episode reward: -0.0871,                 loss: 0.1183
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0612s / 34626.0776 s
agent0:                 episode reward: -0.2492,                 loss: nan
agent1:                 episode reward: 0.2492,                 loss: 0.1192
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9534s / 34870.0309 s
agent0:                 episode reward: 0.1363,                 loss: nan
agent1:                 episode reward: -0.1363,                 loss: 0.1201
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4999s / 35117.5308 s
agent0:                 episode reward: 0.0561,                 loss: nan
agent1:                 episode reward: -0.0561,                 loss: 0.1189
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8039s / 35369.3347 s
agent0:                 episode reward: -0.4584,                 loss: nan
agent1:                 episode reward: 0.4584,                 loss: 0.1185
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.0922s / 35609.4269 s
agent0:                 episode reward: 0.1225,                 loss: nan
agent1:                 episode reward: -0.1225,                 loss: 0.1190
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8752s / 35852.3022 s
agent0:                 episode reward: -0.4720,                 loss: nan
agent1:                 episode reward: 0.4720,                 loss: 0.1208
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0099s / 36102.3120 s
agent0:                 episode reward: -0.0275,                 loss: nan
agent1:                 episode reward: 0.0275,                 loss: 0.1203
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.5031s / 36357.8152 s
agent0:                 episode reward: -0.7794,                 loss: nan
agent1:                 episode reward: 0.7794,                 loss: 0.1198
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4379s / 36606.2531 s
agent0:                 episode reward: 0.3171,                 loss: nan
agent1:                 episode reward: -0.3171,                 loss: 0.1191
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7267s / 36854.9798 s
agent0:                 episode reward: -0.3539,                 loss: nan
agent1:                 episode reward: 0.3539,                 loss: 0.1175
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0313s / 37098.0111 s
agent0:                 episode reward: -0.1103,                 loss: nan
agent1:                 episode reward: 0.1103,                 loss: 0.1184
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1212s / 37343.1323 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1171
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 239.8994s / 37583.0317 s
agent0:                 episode reward: -0.0586,                 loss: nan
agent1:                 episode reward: 0.0586,                 loss: 0.1185
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7236s / 37837.7553 s
agent0:                 episode reward: -0.2365,                 loss: nan
agent1:                 episode reward: 0.2365,                 loss: 0.1192
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 241.0409s / 38078.7961 s
agent0:                 episode reward: -0.1462,                 loss: nan
agent1:                 episode reward: 0.1462,                 loss: 0.1199
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.6135s / 38322.4096 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.1191
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8804s / 38571.2900 s
agent0:                 episode reward: -0.4743,                 loss: nan
agent1:                 episode reward: 0.4743,                 loss: 0.1186
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4728s / 38820.7627 s
agent0:                 episode reward: -0.4515,                 loss: nan
agent1:                 episode reward: 0.4515,                 loss: 0.1189
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 241.8422s / 39062.6049 s
agent0:                 episode reward: 0.0293,                 loss: nan
agent1:                 episode reward: -0.0293,                 loss: 0.1185
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.6892s / 39308.2941 s
agent0:                 episode reward: 0.0209,                 loss: nan
agent1:                 episode reward: -0.0209,                 loss: 0.1201
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7855s / 39557.0797 s
agent0:                 episode reward: -0.4449,                 loss: nan
agent1:                 episode reward: 0.4449,                 loss: 0.1192
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4277s / 39804.5074 s
agent0:                 episode reward: 0.1296,                 loss: nan
agent1:                 episode reward: -0.1296,                 loss: 0.1181
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8557s / 40052.3631 s
agent0:                 episode reward: -0.3699,                 loss: nan
agent1:                 episode reward: 0.3699,                 loss: 0.1189
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.3353s / 40296.6984 s
agent0:                 episode reward: -0.1749,                 loss: nan
agent1:                 episode reward: 0.1749,                 loss: 0.1188
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4230s / 40546.1214 s
agent0:                 episode reward: -0.2998,                 loss: nan
agent1:                 episode reward: 0.2998,                 loss: 0.1176
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0857s / 40788.2071 s
agent0:                 episode reward: -0.0294,                 loss: nan
agent1:                 episode reward: 0.0294,                 loss: 0.1189
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6940s / 41036.9011 s
agent0:                 episode reward: -0.5684,                 loss: nan
agent1:                 episode reward: 0.5684,                 loss: 0.1196
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7272s / 41282.6283 s
agent0:                 episode reward: -0.1306,                 loss: nan
agent1:                 episode reward: 0.1306,                 loss: 0.1192
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8699s / 41534.4982 s
agent0:                 episode reward: -0.4585,                 loss: nan
agent1:                 episode reward: 0.4585,                 loss: 0.1181
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5776s / 41780.0758 s
agent0:                 episode reward: -0.2281,                 loss: nan
agent1:                 episode reward: 0.2281,                 loss: 0.1181
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1819s / 42026.2577 s
agent0:                 episode reward: -0.1513,                 loss: nan
agent1:                 episode reward: 0.1513,                 loss: 0.1188
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5532s / 42273.8109 s
agent0:                 episode reward: -0.3881,                 loss: nan
agent1:                 episode reward: 0.3881,                 loss: 0.1191
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9143s / 42525.7252 s
agent0:                 episode reward: 0.2124,                 loss: nan
agent1:                 episode reward: -0.2124,                 loss: 0.1172
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.0701s / 42767.7952 s
agent0:                 episode reward: -0.0682,                 loss: nan
agent1:                 episode reward: 0.0682,                 loss: 0.1181
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1356s / 43016.9309 s
agent0:                 episode reward: 0.0698,                 loss: nan
agent1:                 episode reward: -0.0698,                 loss: 0.1179
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9231s / 43267.8539 s
agent0:                 episode reward: -0.3707,                 loss: nan
agent1:                 episode reward: 0.3707,                 loss: 0.1193
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 259.7543s / 43527.6082 s
agent0:                 episode reward: -0.3372,                 loss: nan
agent1:                 episode reward: 0.3372,                 loss: 0.1190
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.4013s / 43776.0095 s
agent0:                 episode reward: -0.5760,                 loss: nan
agent1:                 episode reward: 0.5760,                 loss: 0.1186
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2612s / 44019.2707 s
agent0:                 episode reward: 0.2066,                 loss: nan
agent1:                 episode reward: -0.2066,                 loss: 0.1184
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1897s / 44272.4604 s
agent0:                 episode reward: 0.3062,                 loss: nan
agent1:                 episode reward: -0.3062,                 loss: 0.1179
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3078s / 44521.7682 s
agent0:                 episode reward: -0.1864,                 loss: nan
agent1:                 episode reward: 0.1864,                 loss: 0.1186
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3418s / 44769.1101 s
agent0:                 episode reward: 0.0681,                 loss: nan
agent1:                 episode reward: -0.0681,                 loss: 0.1187
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1955s / 45011.3056 s
agent0:                 episode reward: -0.2431,                 loss: nan
agent1:                 episode reward: 0.2431,                 loss: 0.1186
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7444s / 45259.0500 s
agent0:                 episode reward: -0.4115,                 loss: nan
agent1:                 episode reward: 0.4115,                 loss: 0.1188
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9700s / 45505.0200 s
agent0:                 episode reward: 0.0019,                 loss: nan
agent1:                 episode reward: -0.0019,                 loss: 0.1182
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1956s / 45754.2155 s
agent0:                 episode reward: -0.3183,                 loss: nan
agent1:                 episode reward: 0.3183,                 loss: 0.1193
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.4854s / 46001.7009 s
agent0:                 episode reward: -0.2026,                 loss: nan
agent1:                 episode reward: 0.2026,                 loss: 0.1178
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2158s / 46251.9167 s
agent0:                 episode reward: -0.4454,                 loss: nan
agent1:                 episode reward: 0.4454,                 loss: 0.1180
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4420s / 46503.3587 s
agent0:                 episode reward: -0.2497,                 loss: nan
agent1:                 episode reward: 0.2497,                 loss: 0.1181
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.7350s / 46743.0937 s
agent0:                 episode reward: 0.1206,                 loss: nan
agent1:                 episode reward: -0.1206,                 loss: 0.1194
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3085s / 46995.4021 s
agent0:                 episode reward: -0.0569,                 loss: nan
agent1:                 episode reward: 0.0569,                 loss: 0.1198
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6100s / 47240.0121 s
agent0:                 episode reward: -0.3715,                 loss: nan
agent1:                 episode reward: 0.3715,                 loss: 0.1185
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.7198s / 47485.7319 s
agent0:                 episode reward: -0.1979,                 loss: nan
agent1:                 episode reward: 0.1979,                 loss: 0.1186
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7390s / 47734.4709 s
agent0:                 episode reward: 0.3796,                 loss: nan
agent1:                 episode reward: -0.3796,                 loss: 0.1189
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.1673s / 47977.6382 s
agent0:                 episode reward: -0.3419,                 loss: nan
agent1:                 episode reward: 0.3419,                 loss: 0.1187
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 239.2697s / 48216.9079 s
agent0:                 episode reward: -0.0881,                 loss: nan
agent1:                 episode reward: 0.0881,                 loss: 0.1201
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1635s / 48466.0714 s
agent0:                 episode reward: -0.1443,                 loss: nan
agent1:                 episode reward: 0.1443,                 loss: 0.1187
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.5060s / 48723.5774 s
agent0:                 episode reward: -0.0843,                 loss: nan
agent1:                 episode reward: 0.0843,                 loss: 0.1175
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 241.3537s / 48964.9310 s
agent0:                 episode reward: -0.2522,                 loss: nan
agent1:                 episode reward: 0.2522,                 loss: 0.1177
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.5831s / 49221.5141 s
agent0:                 episode reward: -0.0847,                 loss: nan
agent1:                 episode reward: 0.0847,                 loss: 0.1195
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3656s / 49470.8797 s
agent0:                 episode reward: -0.3846,                 loss: nan
agent1:                 episode reward: 0.3846,                 loss: 0.1181
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.3509s / 49718.2306 s
agent0:                 episode reward: 0.1633,                 loss: nan
agent1:                 episode reward: -0.1633,                 loss: 0.1160
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.5885s / 49972.8191 s
agent0:                 episode reward: 0.2358,                 loss: nan
agent1:                 episode reward: -0.2358,                 loss: 0.1161
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.7414s / 50224.5605 s
agent0:                 episode reward: -0.1068,                 loss: nan
agent1:                 episode reward: 0.1068,                 loss: 0.1170
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5630s / 50473.1235 s
agent0:                 episode reward: -0.3247,                 loss: nan
agent1:                 episode reward: 0.3247,                 loss: 0.1172
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.7615s / 50725.8850 s
agent0:                 episode reward: 0.1923,                 loss: nan
agent1:                 episode reward: -0.1923,                 loss: 0.1174
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.9352s / 50980.8203 s
agent0:                 episode reward: -0.0682,                 loss: nan
agent1:                 episode reward: 0.0682,                 loss: 0.1154
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.5831s / 51226.4033 s
agent0:                 episode reward: 0.1141,                 loss: nan
agent1:                 episode reward: -0.1141,                 loss: 0.1150
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7779s / 51476.1813 s
agent0:                 episode reward: -0.5272,                 loss: nan
agent1:                 episode reward: 0.5272,                 loss: 0.1161
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.5883s / 51722.7696 s
agent0:                 episode reward: 0.2057,                 loss: nan
agent1:                 episode reward: -0.2057,                 loss: 0.1157
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.4549s / 51969.2244 s
agent0:                 episode reward: -0.2588,                 loss: nan
agent1:                 episode reward: 0.2588,                 loss: 0.1160
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7147s / 52218.9392 s
agent0:                 episode reward: -0.0445,                 loss: nan
agent1:                 episode reward: 0.0445,                 loss: 0.1158
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6733s / 52471.6125 s
agent0:                 episode reward: -0.1682,                 loss: nan
agent1:                 episode reward: 0.1682,                 loss: 0.1160
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.0577s / 52720.6702 s
agent0:                 episode reward: -0.1938,                 loss: nan
agent1:                 episode reward: 0.1938,                 loss: 0.1169
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.1257s / 52968.7959 s
agent0:                 episode reward: 0.4227,                 loss: nan
agent1:                 episode reward: -0.4227,                 loss: 0.1174
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0962s / 53220.8922 s
agent0:                 episode reward: -0.0036,                 loss: nan
agent1:                 episode reward: 0.0036,                 loss: 0.1142
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9101s / 53467.8023 s
agent0:                 episode reward: -0.3739,                 loss: nan
agent1:                 episode reward: 0.3739,                 loss: 0.1171
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7120s / 53715.5143 s
agent0:                 episode reward: -0.0637,                 loss: nan
agent1:                 episode reward: 0.0637,                 loss: 0.1173
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.8529s / 53956.3672 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.1167
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5553s / 54209.9225 s
agent0:                 episode reward: -0.1199,                 loss: nan
agent1:                 episode reward: 0.1199,                 loss: 0.1165
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6621s / 54464.5845 s
agent0:                 episode reward: 0.2142,                 loss: nan
agent1:                 episode reward: -0.2142,                 loss: 0.1175
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1865s / 54716.7711 s
agent0:                 episode reward: -0.0605,                 loss: nan
agent1:                 episode reward: 0.0605,                 loss: 0.1180
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.3752s / 54965.1463 s
agent0:                 episode reward: -0.3340,                 loss: nan
agent1:                 episode reward: 0.3340,                 loss: 0.1178
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.9674s / 55215.1136 s
agent0:                 episode reward: -0.3489,                 loss: nan
agent1:                 episode reward: 0.3489,                 loss: 0.1172
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.9349s / 55461.0485 s
agent0:                 episode reward: -0.1445,                 loss: nan
agent1:                 episode reward: 0.1445,                 loss: 0.1178
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5239s / 55709.5724 s
agent0:                 episode reward: -0.1189,                 loss: nan
agent1:                 episode reward: 0.1189,                 loss: 0.1168
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.7783s / 55964.3507 s
agent0:                 episode reward: -0.1307,                 loss: nan
agent1:                 episode reward: 0.1307,                 loss: 0.1178
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2114s / 56211.5620 s
agent0:                 episode reward: -0.2994,                 loss: nan
agent1:                 episode reward: 0.2994,                 loss: 0.1175
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.1423s / 56451.7043 s
agent0:                 episode reward: -0.3576,                 loss: nan
agent1:                 episode reward: 0.3576,                 loss: 0.1169
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0369s / 56703.7412 s
agent0:                 episode reward: -0.1176,                 loss: nan
agent1:                 episode reward: 0.1176,                 loss: 0.1182
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.0674s / 56959.8086 s
agent0:                 episode reward: -0.1825,                 loss: nan
agent1:                 episode reward: 0.1825,                 loss: 0.1174
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9937s / 57211.8023 s
agent0:                 episode reward: 0.1159,                 loss: nan
agent1:                 episode reward: -0.1159,                 loss: 0.1177
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.1690s / 57464.9713 s
agent0:                 episode reward: -0.3265,                 loss: nan
agent1:                 episode reward: 0.3265,                 loss: 0.1164
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5929s / 57713.5642 s
agent0:                 episode reward: -0.0384,                 loss: nan
agent1:                 episode reward: 0.0384,                 loss: 0.1171
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4528s / 57967.0170 s
agent0:                 episode reward: -0.1055,                 loss: nan
agent1:                 episode reward: 0.1055,                 loss: 0.1193
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.1623s / 58213.1793 s
agent0:                 episode reward: -0.2064,                 loss: nan
agent1:                 episode reward: 0.2064,                 loss: 0.1184
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 248.6650s / 58461.8443 s
agent0:                 episode reward: -0.2416,                 loss: nan
agent1:                 episode reward: 0.2416,                 loss: 0.1180
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8744s / 58710.7188 s
agent0:                 episode reward: -0.3407,                 loss: nan
agent1:                 episode reward: 0.3407,                 loss: 0.1180
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2776s / 58953.9964 s
agent0:                 episode reward: -0.0880,                 loss: nan
agent1:                 episode reward: 0.0880,                 loss: 0.1191
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4471s / 59199.4435 s
agent0:                 episode reward: -0.1720,                 loss: nan
agent1:                 episode reward: 0.1720,                 loss: 0.1188
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.4811s / 59449.9246 s
agent0:                 episode reward: -0.2187,                 loss: nan
agent1:                 episode reward: 0.2187,                 loss: 0.1189
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.3331s / 59701.2577 s
agent0:                 episode reward: -0.4598,                 loss: nan
agent1:                 episode reward: 0.4598,                 loss: 0.1188
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9488s / 59953.2065 s
agent0:                 episode reward: -0.2055,                 loss: nan
agent1:                 episode reward: 0.2055,                 loss: 0.1188
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9369s / 60200.1434 s
agent0:                 episode reward: -0.0738,                 loss: nan
agent1:                 episode reward: 0.0738,                 loss: 0.1181
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.6865s / 60447.8299 s
agent0:                 episode reward: -0.3253,                 loss: nan
agent1:                 episode reward: 0.3253,                 loss: 0.1189
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.6100s / 60697.4399 s
agent0:                 episode reward: -0.0425,                 loss: nan
agent1:                 episode reward: 0.0425,                 loss: 0.1203
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.6839s / 60949.1238 s
agent0:                 episode reward: -0.3357,                 loss: nan
agent1:                 episode reward: 0.3357,                 loss: 0.1170
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.1424s / 61194.2662 s
agent0:                 episode reward: -0.0988,                 loss: nan
agent1:                 episode reward: 0.0988,                 loss: 0.1184
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.6038s / 61440.8700 s
agent0:                 episode reward: -0.2948,                 loss: nan
agent1:                 episode reward: 0.2948,                 loss: 0.1177
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 243.0657s / 61683.9357 s
agent0:                 episode reward: -0.0613,                 loss: nan
agent1:                 episode reward: 0.0613,                 loss: 0.1185
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7326s / 61939.6683 s
agent0:                 episode reward: -0.2078,                 loss: nan
agent1:                 episode reward: 0.2078,                 loss: 0.1180
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.8297s / 62185.4980 s
agent0:                 episode reward: 0.2490,                 loss: nan
agent1:                 episode reward: -0.2490,                 loss: 0.1172
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0987s / 62435.5967 s
agent0:                 episode reward: -0.4476,                 loss: nan
agent1:                 episode reward: 0.4476,                 loss: 0.1179
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.8867s / 62683.4834 s
agent0:                 episode reward: -0.0167,                 loss: nan
agent1:                 episode reward: 0.0167,                 loss: 0.1166
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2455s / 62926.7290 s
agent0:                 episode reward: -0.2845,                 loss: nan
agent1:                 episode reward: 0.2845,                 loss: 0.1176
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2509s / 63176.9799 s
agent0:                 episode reward: -0.5325,                 loss: nan
agent1:                 episode reward: 0.5325,                 loss: 0.1182
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9992s / 63427.9791 s
agent0:                 episode reward: -0.3405,                 loss: nan
agent1:                 episode reward: 0.3405,                 loss: 0.1177
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2635s / 63680.2426 s
agent0:                 episode reward: -0.5629,                 loss: nan
agent1:                 episode reward: 0.5629,                 loss: 0.1169
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 262.0725s / 63942.3150 s
agent0:                 episode reward: -0.5314,                 loss: nan
agent1:                 episode reward: 0.5314,                 loss: 0.1164
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0768s / 64190.3919 s
agent0:                 episode reward: -0.5002,                 loss: nan
agent1:                 episode reward: 0.5002,                 loss: 0.1189
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.5085s / 64441.9003 s
agent0:                 episode reward: -0.2380,                 loss: nan
agent1:                 episode reward: 0.2380,                 loss: 0.1166
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7200s / 64692.6203 s
agent0:                 episode reward: -0.7728,                 loss: nan
agent1:                 episode reward: 0.7728,                 loss: 0.1179
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9977s / 64944.6180 s
agent0:                 episode reward: -0.0986,                 loss: nan
agent1:                 episode reward: 0.0986,                 loss: 0.1168
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7483s / 65192.3663 s
agent0:                 episode reward: -0.3505,                 loss: nan
agent1:                 episode reward: 0.3505,                 loss: 0.1171
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4388s / 65437.8052 s
agent0:                 episode reward: 0.0837,                 loss: nan
agent1:                 episode reward: -0.0837,                 loss: 0.1174
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7999s / 65687.6051 s
agent0:                 episode reward: -0.3380,                 loss: nan
agent1:                 episode reward: 0.3380,                 loss: 0.1172
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.8672s / 65932.4723 s
agent0:                 episode reward: 0.1793,                 loss: nan
agent1:                 episode reward: -0.1793,                 loss: 0.1181
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6853s / 66175.1576 s
agent0:                 episode reward: -0.8801,                 loss: nan
agent1:                 episode reward: 0.8801,                 loss: 0.1148
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4836s / 66428.6411 s
agent0:                 episode reward: -0.1966,                 loss: nan
agent1:                 episode reward: 0.1966,                 loss: 0.1170
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8345s / 66680.4756 s
agent0:                 episode reward: -0.4551,                 loss: nan
agent1:                 episode reward: 0.4551,                 loss: 0.1144
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 264.8133s / 66945.2889 s
agent0:                 episode reward: -0.2488,                 loss: nan
agent1:                 episode reward: 0.2488,                 loss: 0.1153
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.8353s / 67188.1242 s
agent0:                 episode reward: 0.1817,                 loss: nan
agent1:                 episode reward: -0.1817,                 loss: 0.1157
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0476s / 67443.1718 s
agent0:                 episode reward: -0.3777,                 loss: nan
agent1:                 episode reward: 0.3777,                 loss: 0.1141
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0433s / 67690.2151 s
agent0:                 episode reward: -0.4710,                 loss: nan
agent1:                 episode reward: 0.4710,                 loss: 0.1152
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0128s / 67942.2279 s
agent0:                 episode reward: -0.2913,                 loss: nan
agent1:                 episode reward: 0.2913,                 loss: 0.1154
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4090s / 68187.6368 s
agent0:                 episode reward: -0.2758,                 loss: nan
agent1:                 episode reward: 0.2758,                 loss: 0.1165
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8557s / 68434.4926 s
agent0:                 episode reward: -0.3169,                 loss: nan
agent1:                 episode reward: 0.3169,                 loss: 0.1156
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.4326s / 68685.9252 s
agent0:                 episode reward: -0.3276,                 loss: nan
agent1:                 episode reward: 0.3276,                 loss: 0.1151
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.2336s / 68933.1588 s
agent0:                 episode reward: -0.1820,                 loss: nan
agent1:                 episode reward: 0.1820,                 loss: 0.1156
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6638s / 69183.8226 s
agent0:                 episode reward: -0.2620,                 loss: nan
agent1:                 episode reward: 0.2620,                 loss: 0.1151
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.7907s / 69431.6133 s
agent0:                 episode reward: -0.5033,                 loss: nan
agent1:                 episode reward: 0.5033,                 loss: 0.1133
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.0103s / 69677.6236 s
agent0:                 episode reward: -0.3107,                 loss: nan
agent1:                 episode reward: 0.3107,                 loss: 0.1162
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.7385s / 69931.3621 s
agent0:                 episode reward: -0.3188,                 loss: nan
agent1:                 episode reward: 0.3188,                 loss: 0.1150
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 246.8721s / 70178.2342 s
agent0:                 episode reward: -0.4289,                 loss: nan
agent1:                 episode reward: 0.4289,                 loss: 0.1145
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.1539s / 70420.3881 s
agent0:                 episode reward: -0.6723,                 loss: nan
agent1:                 episode reward: 0.6723,                 loss: 0.1136
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 237.3663s / 70657.7545 s
agent0:                 episode reward: -0.2594,                 loss: nan
agent1:                 episode reward: 0.2594,                 loss: 0.1151
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.0869s / 70909.8414 s
agent0:                 episode reward: 0.2477,                 loss: nan
agent1:                 episode reward: -0.2477,                 loss: 0.1135
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4496s / 71162.2910 s
agent0:                 episode reward: -0.4751,                 loss: nan
agent1:                 episode reward: 0.4751,                 loss: 0.1158
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 244.4011s / 71406.6920 s
agent0:                 episode reward: -0.3823,                 loss: nan
agent1:                 episode reward: 0.3823,                 loss: 0.1140
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.8380s / 71658.5300 s
agent0:                 episode reward: 0.1097,                 loss: nan
agent1:                 episode reward: -0.1097,                 loss: 0.1135
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 242.6408s / 71901.1709 s
agent0:                 episode reward: 0.0554,                 loss: nan
agent1:                 episode reward: -0.0554,                 loss: 0.1148
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7235s / 72149.8944 s
agent0:                 episode reward: -0.1939,                 loss: nan
agent1:                 episode reward: 0.1939,                 loss: 0.1138
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.0796s / 72397.9740 s
agent0:                 episode reward: -0.5875,                 loss: nan
agent1:                 episode reward: 0.5875,                 loss: 0.1156
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 250.9256s / 72648.8996 s
agent0:                 episode reward: -0.1803,                 loss: nan
agent1:                 episode reward: 0.1803,                 loss: 0.1128
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2920s / 72901.1916 s
agent0:                 episode reward: -0.0171,                 loss: nan
agent1:                 episode reward: 0.0171,                 loss: 0.1145
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7675s / 73150.9591 s
agent0:                 episode reward: -0.7759,                 loss: nan
agent1:                 episode reward: 0.7759,                 loss: 0.1127
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.0082s / 73404.9673 s
agent0:                 episode reward: -0.4886,                 loss: nan
agent1:                 episode reward: 0.4886,                 loss: 0.1155
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.0432s / 73656.0105 s
agent0:                 episode reward: -0.1183,                 loss: nan
agent1:                 episode reward: 0.1183,                 loss: 0.1136
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 247.0168s / 73903.0273 s
agent0:                 episode reward: -0.1985,                 loss: nan
agent1:                 episode reward: 0.1985,                 loss: 0.1132
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.7365s / 74146.7638 s
agent0:                 episode reward: -0.2873,                 loss: nan
agent1:                 episode reward: 0.2873,                 loss: 0.1144
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 259.4206s / 74406.1845 s
agent0:                 episode reward: -0.1893,                 loss: nan
agent1:                 episode reward: 0.1893,                 loss: 0.1135
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.8802s / 74659.0647 s
agent0:                 episode reward: -0.2537,                 loss: nan
agent1:                 episode reward: 0.2537,                 loss: 0.1145
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.9772s / 74903.0419 s
agent0:                 episode reward: -0.2667,                 loss: nan
agent1:                 episode reward: 0.2667,                 loss: 0.1130
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 240.7546s / 75143.7965 s
agent0:                 episode reward: -0.0993,                 loss: nan
agent1:                 episode reward: 0.0993,                 loss: 0.1137
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4177s / 75393.2142 s
agent0:                 episode reward: -0.1497,                 loss: nan
agent1:                 episode reward: 0.1497,                 loss: 0.1137
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3213s / 75639.5355 s
agent0:                 episode reward: -0.3255,                 loss: nan
agent1:                 episode reward: 0.3255,                 loss: 0.1139
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7162s / 75888.2517 s
agent0:                 episode reward: -0.1831,                 loss: nan
agent1:                 episode reward: 0.1831,                 loss: 0.1148
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 256.8318s / 76145.0835 s
agent0:                 episode reward: -0.5214,                 loss: nan
agent1:                 episode reward: 0.5214,                 loss: 0.1133
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 255.9441s / 76401.0277 s
agent0:                 episode reward: -0.4082,                 loss: nan
agent1:                 episode reward: 0.4082,                 loss: 0.1146
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.8793s / 76654.9070 s
agent0:                 episode reward: -0.6225,                 loss: nan
agent1:                 episode reward: 0.6225,                 loss: 0.1132
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6113s / 76905.5183 s
agent0:                 episode reward: -0.1452,                 loss: nan
agent1:                 episode reward: 0.1452,                 loss: 0.1136
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 247.5510s / 77153.0693 s
agent0:                 episode reward: -0.4786,                 loss: nan
agent1:                 episode reward: 0.4786,                 loss: 0.1129
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9497s / 77405.0190 s
agent0:                 episode reward: -0.0618,                 loss: nan
agent1:                 episode reward: 0.0618,                 loss: 0.1140
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6502s / 77649.6692 s
agent0:                 episode reward: 0.0709,                 loss: nan
agent1:                 episode reward: -0.0709,                 loss: 0.1144
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.6738s / 77894.3429 s
agent0:                 episode reward: -0.3573,                 loss: nan
agent1:                 episode reward: 0.3573,                 loss: 0.1142
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.6079s / 78146.9508 s
agent0:                 episode reward: -0.2792,                 loss: nan
agent1:                 episode reward: 0.2792,                 loss: 0.1143
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.7777s / 78397.7285 s
agent0:                 episode reward: -0.2307,                 loss: nan
agent1:                 episode reward: 0.2307,                 loss: 0.1138
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.3488s / 78651.0773 s
agent0:                 episode reward: -0.4206,                 loss: nan
agent1:                 episode reward: 0.4206,                 loss: 0.1139
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 242.9335s / 78894.0108 s
agent0:                 episode reward: -0.3510,                 loss: nan
agent1:                 episode reward: 0.3510,                 loss: 0.1119
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5262s / 79142.5370 s
agent0:                 episode reward: -0.3159,                 loss: nan
agent1:                 episode reward: 0.3159,                 loss: 0.1138
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.5265s / 79395.0635 s
agent0:                 episode reward: -0.5099,                 loss: nan
agent1:                 episode reward: 0.5099,                 loss: 0.1142
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.4239s / 79647.4874 s
agent0:                 episode reward: -0.3784,                 loss: nan
agent1:                 episode reward: 0.3784,                 loss: 0.1112
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 244.1279s / 79891.6154 s
agent0:                 episode reward: 0.1464,                 loss: nan
agent1:                 episode reward: -0.1464,                 loss: 0.1121
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.4915s / 80141.1069 s
agent0:                 episode reward: -0.0754,                 loss: nan
agent1:                 episode reward: 0.0754,                 loss: 0.1140
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 253.5844s / 80394.6913 s
agent0:                 episode reward: -0.2088,                 loss: nan
agent1:                 episode reward: 0.2088,                 loss: 0.1121
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 245.4903s / 80640.1816 s
agent0:                 episode reward: -0.4656,                 loss: nan
agent1:                 episode reward: 0.4656,                 loss: 0.1134
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 257.7334s / 80897.9150 s
agent0:                 episode reward: -0.0137,                 loss: nan
agent1:                 episode reward: 0.0137,                 loss: 0.1144
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 257.2447s / 81155.1597 s
agent0:                 episode reward: -0.6282,                 loss: nan
agent1:                 episode reward: 0.6282,                 loss: 0.1126
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 250.0191s / 81405.1787 s
agent0:                 episode reward: -0.4802,                 loss: nan
agent1:                 episode reward: 0.4802,                 loss: 0.1135
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 246.9714s / 81652.1501 s
agent0:                 episode reward: -0.2608,                 loss: nan
agent1:                 episode reward: 0.2608,                 loss: 0.1121
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 254.3078s / 81906.4579 s
agent0:                 episode reward: -0.3558,                 loss: nan
agent1:                 episode reward: 0.3558,                 loss: 0.1127
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.7128s / 82155.1707 s
agent0:                 episode reward: 0.1282,                 loss: nan
agent1:                 episode reward: -0.1282,                 loss: 0.1126
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 256.6512s / 82411.8219 s
agent0:                 episode reward: -0.2454,                 loss: nan
agent1:                 episode reward: 0.2454,                 loss: 0.1133
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 248.5797s / 82660.4017 s
agent0:                 episode reward: -0.2740,                 loss: nan
agent1:                 episode reward: 0.2740,                 loss: 0.1126
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 252.1055s / 82912.5072 s
agent0:                 episode reward: -0.2211,                 loss: nan
agent1:                 episode reward: 0.2211,                 loss: 0.1154
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 240.0763s / 83152.5835 s
agent0:                 episode reward: -0.2737,                 loss: nan
agent1:                 episode reward: 0.2737,                 loss: 0.1141
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.6538s / 83403.2373 s
agent0:                 episode reward: -0.2259,                 loss: nan
agent1:                 episode reward: 0.2259,                 loss: 0.1155
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 242.2080s / 83645.4452 s
agent0:                 episode reward: -0.3572,                 loss: nan
agent1:                 episode reward: 0.3572,                 loss: 0.1147
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 243.2972s / 83888.7425 s
agent0:                 episode reward: -0.4296,                 loss: nan
agent1:                 episode reward: 0.4296,                 loss: 0.1146
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.9422s / 84141.6847 s
agent0:                 episode reward: -0.3599,                 loss: nan
agent1:                 episode reward: 0.3599,                 loss: 0.1158
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.0813s / 84396.7660 s
agent0:                 episode reward: -0.2135,                 loss: nan
agent1:                 episode reward: 0.2135,                 loss: 0.1146
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 249.2435s / 84646.0095 s
agent0:                 episode reward: 0.0400,                 loss: nan
agent1:                 episode reward: -0.0400,                 loss: 0.1146
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 250.2459s / 84896.2554 s
agent0:                 episode reward: -0.6265,                 loss: nan
agent1:                 episode reward: 0.6265,                 loss: 0.1144
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 248.8922s / 85145.1476 s
agent0:                 episode reward: -0.5033,                 loss: nan
agent1:                 episode reward: 0.5033,                 loss: 0.1152
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.3983s / 85390.5459 s
agent0:                 episode reward: -0.0698,                 loss: nan
agent1:                 episode reward: 0.0698,                 loss: 0.1148
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 249.7580s / 85640.3039 s
agent0:                 episode reward: -0.5014,                 loss: nan
agent1:                 episode reward: 0.5014,                 loss: 0.1143
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 254.6987s / 85895.0026 s
agent0:                 episode reward: -0.4684,                 loss: nan
agent1:                 episode reward: 0.4684,                 loss: 0.1141
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 245.2752s / 86140.2778 s
agent0:                 episode reward: -0.2152,                 loss: nan
agent1:                 episode reward: 0.2152,                 loss: 0.1139
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.8901s / 86396.1679 s
agent0:                 episode reward: -0.2834,                 loss: nan
agent1:                 episode reward: 0.2834,                 loss: 0.1135
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.1000s / 86645.2679 s
agent0:                 episode reward: -0.1819,                 loss: nan
agent1:                 episode reward: 0.1819,                 loss: 0.1145
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.4922s / 86899.7601 s
agent0:                 episode reward: -0.8168,                 loss: nan
agent1:                 episode reward: 0.8168,                 loss: 0.1126
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 252.3589s / 87152.1190 s
agent0:                 episode reward: -0.1961,                 loss: nan
agent1:                 episode reward: 0.1961,                 loss: 0.1118
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 255.7375s / 87407.8565 s
agent0:                 episode reward: -0.2692,                 loss: nan
agent1:                 episode reward: 0.2692,                 loss: 0.1118
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 254.1280s / 87661.9845 s
agent0:                 episode reward: -0.2388,                 loss: nan
agent1:                 episode reward: 0.2388,                 loss: 0.1132
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.7797s / 87908.7642 s
agent0:                 episode reward: -0.6716,                 loss: nan
agent1:                 episode reward: 0.6716,                 loss: 0.1123
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 238.6303s / 88147.3945 s
agent0:                 episode reward: -0.1401,                 loss: nan
agent1:                 episode reward: 0.1401,                 loss: 0.1122
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 244.5132s / 88391.9077 s
agent0:                 episode reward: -0.2084,                 loss: nan
agent1:                 episode reward: 0.2084,                 loss: 0.1118
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 261.3591s / 88653.2667 s
agent0:                 episode reward: -0.5621,                 loss: nan
agent1:                 episode reward: 0.5621,                 loss: 0.1113
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 249.3196s / 88902.5863 s
agent0:                 episode reward: -0.1482,                 loss: nan
agent1:                 episode reward: 0.1482,                 loss: 0.1121
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 252.2127s / 89154.7990 s
agent0:                 episode reward: -0.3669,                 loss: nan
agent1:                 episode reward: 0.3669,                 loss: 0.1110
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 255.6912s / 89410.4902 s
agent0:                 episode reward: -0.2621,                 loss: nan
agent1:                 episode reward: 0.2621,                 loss: 0.1131
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 251.9101s / 89662.4003 s
agent0:                 episode reward: -0.4058,                 loss: nan
agent1:                 episode reward: 0.4058,                 loss: 0.1100
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 253.4361s / 89915.8364 s
agent0:                 episode reward: -0.4024,                 loss: nan
agent1:                 episode reward: 0.4024,                 loss: 0.1113
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 246.3222s / 90162.1585 s