pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
random seed: [11, 67]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220112_0229/pettingzoo_pong_v2_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220112_0229/pettingzoo_pong_v2_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 1331.0,                last time consumption/overall running time: 18.6005s / 18.6005 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2931
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2756
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1184.1,                last time consumption/overall running time: 171.0943s / 189.6947 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2708
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2757
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1288.6,                last time consumption/overall running time: 185.1716s / 374.8663 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.4219
env0_second_0:                 episode reward: -0.8000,                 loss: 0.4170
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1207.5,                last time consumption/overall running time: 175.6900s / 550.5563 s
env0_first_0:                 episode reward: 5.4500,                 loss: 0.5259
env0_second_0:                 episode reward: -5.4500,                 loss: 0.5043
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1111.35,                last time consumption/overall running time: 160.6449s / 711.2011 s
env0_first_0:                 episode reward: 7.9000,                 loss: 0.5704
env0_second_0:                 episode reward: -7.9000,                 loss: 0.5448
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1089.9,                last time consumption/overall running time: 158.4206s / 869.6218 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.6514
env0_second_0:                 episode reward: -2.7500,                 loss: 0.6416
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1115.85,                last time consumption/overall running time: 162.5775s / 1032.1993 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.7093
env0_second_0:                 episode reward: -0.9000,                 loss: 0.7009
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1115.0,                last time consumption/overall running time: 162.8467s / 1195.0460 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.6854
env0_second_0:                 episode reward: 1.2000,                 loss: 0.6692
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1034.25,                last time consumption/overall running time: 150.3633s / 1345.4092 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.6505
env0_second_0:                 episode reward: -1.6500,                 loss: 0.6365
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1112.55,                last time consumption/overall running time: 162.2067s / 1507.6160 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.6691
env0_second_0:                 episode reward: -2.8000,                 loss: 0.6613
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1193.3,                last time consumption/overall running time: 172.2752s / 1679.8912 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.6954
env0_second_0:                 episode reward: 1.3000,                 loss: 0.6825
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1168.75,                last time consumption/overall running time: 167.3184s / 1847.2096 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.6877
env0_second_0:                 episode reward: 1.7000,                 loss: 0.6802
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1128.7,                last time consumption/overall running time: 160.7543s / 2007.9638 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.6714
env0_second_0:                 episode reward: 1.1000,                 loss: 0.6680
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1113.3,                last time consumption/overall running time: 159.1272s / 2167.0910 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.6179
env0_second_0:                 episode reward: -2.1500,                 loss: 0.6195
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1136.9,                last time consumption/overall running time: 162.9816s / 2330.0726 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.7013
env0_second_0:                 episode reward: -1.1000,                 loss: 0.7027
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1160.45,                last time consumption/overall running time: 166.0314s / 2496.1041 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.6707
env0_second_0:                 episode reward: -1.8000,                 loss: 0.6648
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1173.75,                last time consumption/overall running time: 167.7057s / 2663.8097 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.6358
env0_second_0:                 episode reward: 2.3500,                 loss: 0.6343
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1250.7,                last time consumption/overall running time: 178.6137s / 2842.4235 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.6633
env0_second_0:                 episode reward: -1.2500,                 loss: 0.6430
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1117.0,                last time consumption/overall running time: 156.7094s / 2999.1329 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.6231
env0_second_0:                 episode reward: -1.4500,                 loss: 0.6162
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1217.1,                last time consumption/overall running time: 171.1298s / 3170.2627 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.6660
env0_second_0:                 episode reward: -2.4500,                 loss: 0.6370
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1128.65,                last time consumption/overall running time: 160.6518s / 3330.9145 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.6387
env0_second_0:                 episode reward: -5.9000,                 loss: 0.6243
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1226.75,                last time consumption/overall running time: 173.4760s / 3504.3904 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.6375
env0_second_0:                 episode reward: -1.1000,                 loss: 0.6186
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1167.1,                last time consumption/overall running time: 167.5591s / 3671.9495 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.6017
env0_second_0:                 episode reward: -0.5000,                 loss: 0.5928
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1064.7,                last time consumption/overall running time: 150.5399s / 3822.4895 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.5699
env0_second_0:                 episode reward: -1.0000,                 loss: 0.5903
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1173.55,                last time consumption/overall running time: 167.7528s / 3990.2423 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.6179
env0_second_0:                 episode reward: 6.5500,                 loss: 0.6129
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1201.8,                last time consumption/overall running time: 171.4399s / 4161.6821 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.6445
env0_second_0:                 episode reward: -3.9000,                 loss: 0.6525
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1200.8,                last time consumption/overall running time: 170.5837s / 4332.2658 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.5720
env0_second_0:                 episode reward: -0.2500,                 loss: 0.5721
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1232.85,                last time consumption/overall running time: 173.6717s / 4505.9375 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.6139
env0_second_0:                 episode reward: -3.9500,                 loss: 0.6113
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1150.05,                last time consumption/overall running time: 165.5909s / 4671.5284 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.5766
env0_second_0:                 episode reward: 0.8500,                 loss: 0.5710
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1158.5,                last time consumption/overall running time: 167.2450s / 4838.7735 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.5864
env0_second_0:                 episode reward: -0.6000,                 loss: 0.5875
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1075.25,                last time consumption/overall running time: 155.5947s / 4994.3682 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.5915
env0_second_0:                 episode reward: -3.7500,                 loss: 0.5828
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1121.8,                last time consumption/overall running time: 162.3745s / 5156.7427 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.5753
env0_second_0:                 episode reward: 1.7000,                 loss: 0.5663
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1202.95,                last time consumption/overall running time: 173.2347s / 5329.9774 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.6020
env0_second_0:                 episode reward: 3.2500,                 loss: 0.6114
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1235.9,                last time consumption/overall running time: 177.4319s / 5507.4093 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.6000
env0_second_0:                 episode reward: -0.9000,                 loss: 0.6193
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1205.35,                last time consumption/overall running time: 174.4510s / 5681.8603 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.6369
env0_second_0:                 episode reward: -4.1000,                 loss: 0.6262
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1222.95,                last time consumption/overall running time: 175.7852s / 5857.6456 s
env0_first_0:                 episode reward: 5.0500,                 loss: 0.6449
env0_second_0:                 episode reward: -5.0500,                 loss: 0.6397
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1138.15,                last time consumption/overall running time: 165.0048s / 6022.6504 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.6058
env0_second_0:                 episode reward: 1.3500,                 loss: 0.5999
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1299.2,                last time consumption/overall running time: 184.8240s / 6207.4744 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.5916
env0_second_0:                 episode reward: 2.6500,                 loss: 0.5913
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1283.95,                last time consumption/overall running time: 181.5292s / 6389.0036 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.5789
env0_second_0:                 episode reward: 2.7500,                 loss: 0.5824
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1276.15,                last time consumption/overall running time: 181.8101s / 6570.8137 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.5739
env0_second_0:                 episode reward: 5.9000,                 loss: 0.5605
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1304.0,                last time consumption/overall running time: 185.5770s / 6756.3907 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.5820
env0_second_0:                 episode reward: 7.8500,                 loss: 0.5732
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1265.7,                last time consumption/overall running time: 178.8184s / 6935.2091 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.5447
env0_second_0:                 episode reward: 9.1000,                 loss: 0.5533
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1423.35,                last time consumption/overall running time: 200.5913s / 7135.8004 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.5688
env0_second_0:                 episode reward: 4.0500,                 loss: 0.5764
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1469.55,                last time consumption/overall running time: 204.6124s / 7340.4127 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.5273
env0_second_0:                 episode reward: 3.2000,                 loss: 0.5464
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1523.4,                last time consumption/overall running time: 209.7687s / 7550.1814 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.5060
env0_second_0:                 episode reward: 5.1500,                 loss: 0.5052
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1680.35,                last time consumption/overall running time: 233.9144s / 7784.0958 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.4650
env0_second_0:                 episode reward: 3.9000,                 loss: 0.4535
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1663.55,                last time consumption/overall running time: 231.7438s / 8015.8396 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.4625
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4566
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1739.15,                last time consumption/overall running time: 245.2331s / 8261.0727 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.4171
env0_second_0:                 episode reward: 2.4000,                 loss: 0.4037
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1725.1,                last time consumption/overall running time: 238.5973s / 8499.6700 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.3893
env0_second_0:                 episode reward: 2.0500,                 loss: 0.3830
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1724.4,                last time consumption/overall running time: 240.6187s / 8740.2887 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.3846
env0_second_0:                 episode reward: 1.9500,                 loss: 0.3652
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1854.95,                last time consumption/overall running time: 259.7180s / 9000.0068 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.3504
env0_second_0:                 episode reward: 1.5500,                 loss: 0.3306
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1895.0,                last time consumption/overall running time: 265.2588s / 9265.2656 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3379
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3220
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1905.95,                last time consumption/overall running time: 266.3780s / 9531.6436 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.3219
env0_second_0:                 episode reward: 1.7500,                 loss: 0.3107
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1864.3,                last time consumption/overall running time: 260.4661s / 9792.1097 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.3288
env0_second_0:                 episode reward: 3.8000,                 loss: 0.3060
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1893.05,                last time consumption/overall running time: 263.7057s / 10055.8154 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3116
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2903
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1861.55,                last time consumption/overall running time: 258.4155s / 10314.2309 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2934
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2750
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1923.1,                last time consumption/overall running time: 270.7607s / 10584.9916 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.2825
env0_second_0:                 episode reward: 2.8000,                 loss: 0.2598
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1986.4,                last time consumption/overall running time: 273.5891s / 10858.5807 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2831
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2568
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1900.9,                last time consumption/overall running time: 266.7891s / 11125.3698 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.2629
env0_second_0:                 episode reward: 2.2000,                 loss: 0.2422
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 2008.65,                last time consumption/overall running time: 282.7893s / 11408.1591 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.2620
env0_second_0:                 episode reward: -1.3000,                 loss: 0.2370
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 2026.95,                last time consumption/overall running time: 288.6581s / 11696.8173 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2522
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2374
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1991.1,                last time consumption/overall running time: 287.1661s / 11983.9834 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2413
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2191
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1982.05,                last time consumption/overall running time: 285.9388s / 12269.9221 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2607
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2489
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 2067.6,                last time consumption/overall running time: 297.3154s / 12567.2375 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2207
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2007
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1965.85,                last time consumption/overall running time: 281.7291s / 12848.9666 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2378
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2247
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1976.8,                last time consumption/overall running time: 282.6308s / 13131.5974 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2321
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2201
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1933.75,                last time consumption/overall running time: 278.6635s / 13410.2609 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2423
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2313
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1922.2,                last time consumption/overall running time: 285.3921s / 13695.6530 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.2344
env0_second_0:                 episode reward: 3.5500,                 loss: 0.2259
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1948.3,                last time consumption/overall running time: 280.0999s / 13975.7529 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2095
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2013
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1895.9,                last time consumption/overall running time: 272.9104s / 14248.6633 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.2182
env0_second_0:                 episode reward: 1.9500,                 loss: 0.2102
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1991.35,                last time consumption/overall running time: 285.8371s / 14534.5003 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2178
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2090
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1950.65,                last time consumption/overall running time: 285.9739s / 14820.4742 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2277
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2172
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1908.6,                last time consumption/overall running time: 272.6967s / 15093.1709 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2153
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2117
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1959.95,                last time consumption/overall running time: 283.5783s / 15376.7493 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.1939
env0_second_0:                 episode reward: 1.1000,                 loss: 0.1835
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1978.05,                last time consumption/overall running time: 284.0605s / 15660.8097 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.1914
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1833
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 2009.5,                last time consumption/overall running time: 289.9529s / 15950.7627 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.1909
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1901
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 2028.7,                last time consumption/overall running time: 291.4011s / 16242.1638 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.1898
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1814
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 2007.55,                last time consumption/overall running time: 288.8381s / 16531.0019 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.2042
env0_second_0:                 episode reward: 1.8000,                 loss: 0.2027
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1952.5,                last time consumption/overall running time: 282.3626s / 16813.3645 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1981
env0_second_0:                 episode reward: 3.2000,                 loss: 0.1811
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1960.45,                last time consumption/overall running time: 281.8756s / 17095.2401 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1925
env0_second_0:                 episode reward: 3.6000,                 loss: 0.1861
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1962.4,                last time consumption/overall running time: 284.4474s / 17379.6875 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.1942
env0_second_0:                 episode reward: 2.5000,                 loss: 0.1803
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1923.65,                last time consumption/overall running time: 275.9095s / 17655.5971 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2016
env0_second_0:                 episode reward: 1.5500,                 loss: 0.1917
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 2011.95,                last time consumption/overall running time: 289.7451s / 17945.3422 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2000
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1891
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 2001.75,                last time consumption/overall running time: 286.1318s / 18231.4740 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.1952
env0_second_0:                 episode reward: 1.5000,                 loss: 0.1948
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 2056.25,                last time consumption/overall running time: 296.3387s / 18527.8127 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.1885
env0_second_0:                 episode reward: 1.5500,                 loss: 0.1923
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1985.35,                last time consumption/overall running time: 286.0687s / 18813.8814 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.1811
env0_second_0:                 episode reward: 1.0500,                 loss: 0.1734
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 2031.25,                last time consumption/overall running time: 294.5282s / 19108.4096 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.1881
env0_second_0:                 episode reward: -0.8500,                 loss: 0.1850
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 2008.35,                last time consumption/overall running time: 289.2295s / 19397.6391 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.1705
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1688
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 2027.05,                last time consumption/overall running time: 291.0964s / 19688.7355 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.1744
env0_second_0:                 episode reward: 2.1500,                 loss: 0.1852
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1952.85,                last time consumption/overall running time: 280.2397s / 19968.9752 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.1770
env0_second_0:                 episode reward: 2.6000,                 loss: 0.1925
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1922.05,                last time consumption/overall running time: 279.1022s / 20248.0773 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2213
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1988
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 2033.8,                last time consumption/overall running time: 295.4169s / 20543.4943 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1849
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1887
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1985.45,                last time consumption/overall running time: 289.0957s / 20832.5900 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1756
env0_second_0:                 episode reward: 3.5000,                 loss: 0.1856
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 2050.05,                last time consumption/overall running time: 296.0553s / 21128.6453 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.1780
env0_second_0:                 episode reward: -0.5500,                 loss: 0.1888
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1961.25,                last time consumption/overall running time: 285.1283s / 21413.7735 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2049
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2087
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1851.75,                last time consumption/overall running time: 268.6316s / 21682.4052 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1834
env0_second_0:                 episode reward: 3.5000,                 loss: 0.1921
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1994.2,                last time consumption/overall running time: 285.8681s / 21968.2732 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.1829
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1861
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1929.45,                last time consumption/overall running time: 277.7871s / 22246.0604 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.1645
env0_second_0:                 episode reward: 1.7500,                 loss: 0.1666
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 2027.85,                last time consumption/overall running time: 291.8155s / 22537.8758 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.1444
env0_second_0:                 episode reward: 3.3000,                 loss: 0.1544
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2062.55,                last time consumption/overall running time: 297.5416s / 22835.4175 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.1530
env0_second_0:                 episode reward: 3.6500,                 loss: 0.1558
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 2049.15,                last time consumption/overall running time: 292.9120s / 23128.3295 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1618
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1641
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1982.65,                last time consumption/overall running time: 287.5441s / 23415.8735 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.1814
env0_second_0:                 episode reward: -0.4500,                 loss: 0.1810
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1953.2,                last time consumption/overall running time: 284.7060s / 23700.5795 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.1935
env0_second_0:                 episode reward: 2.1500,                 loss: 0.1932
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 2025.95,                last time consumption/overall running time: 294.1237s / 23994.7032 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.1720
env0_second_0:                 episode reward: 1.2500,                 loss: 0.1744
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 2050.1,                last time consumption/overall running time: 293.3663s / 24288.0696 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.1525
env0_second_0:                 episode reward: -0.5500,                 loss: 0.1591
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 2066.55,                last time consumption/overall running time: 300.4791s / 24588.5486 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.1840
env0_second_0:                 episode reward: 2.4000,                 loss: 0.1755
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1971.45,                last time consumption/overall running time: 285.2191s / 24873.7678 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.1656
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1721
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2099.6,                last time consumption/overall running time: 303.4652s / 25177.2330 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1600
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1662
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2025.55,                last time consumption/overall running time: 291.3789s / 25468.6119 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.1776
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1826
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 2041.35,                last time consumption/overall running time: 293.7624s / 25762.3743 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.1474
env0_second_0:                 episode reward: -0.9000,                 loss: 0.1542
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 2169.65,                last time consumption/overall running time: 313.1925s / 26075.5668 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.1514
env0_second_0:                 episode reward: 1.6500,                 loss: 0.1591
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 2053.05,                last time consumption/overall running time: 296.9365s / 26372.5033 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.1714
env0_second_0:                 episode reward: -0.7000,                 loss: 0.1728
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 2056.35,                last time consumption/overall running time: 298.7390s / 26671.2423 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1667
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1676
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 2098.2,                last time consumption/overall running time: 300.7384s / 26971.9807 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.1575
env0_second_0:                 episode reward: 1.4000,                 loss: 0.1626
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 2037.8,                last time consumption/overall running time: 294.1824s / 27266.1632 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.1685
env0_second_0:                 episode reward: 1.5500,                 loss: 0.1730
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 2075.05,                last time consumption/overall running time: 297.5716s / 27563.7348 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.1781
env0_second_0:                 episode reward: -1.0500,                 loss: 0.1753
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1941.85,                last time consumption/overall running time: 281.2863s / 27845.0211 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.1821
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1906
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 2021.2,                last time consumption/overall running time: 292.7339s / 28137.7550 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.1946
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2045
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 2001.5,                last time consumption/overall running time: 288.7723s / 28426.5273 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.1810
env0_second_0:                 episode reward: -1.6500,                 loss: 0.1941
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1936.95,                last time consumption/overall running time: 279.4274s / 28705.9547 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.1954
env0_second_0:                 episode reward: 1.9000,                 loss: 0.1942
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 2046.5,                last time consumption/overall running time: 292.6794s / 28998.6342 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.1980
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1914
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 2055.2,                last time consumption/overall running time: 297.8136s / 29296.4478 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.1798
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1924
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1923.0,                last time consumption/overall running time: 280.0572s / 29576.5050 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.1958
env0_second_0:                 episode reward: 2.4000,                 loss: 0.2006
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1953.55,                last time consumption/overall running time: 283.9953s / 29860.5003 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.1895
env0_second_0:                 episode reward: -1.3500,                 loss: 0.1990
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 2042.95,                last time consumption/overall running time: 295.1982s / 30155.6985 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.1875
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2099
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 2077.6,                last time consumption/overall running time: 297.1327s / 30452.8312 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.1684
env0_second_0:                 episode reward: -0.2000,                 loss: 0.1921
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2051.3,                last time consumption/overall running time: 296.2898s / 30749.1210 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.1648
env0_second_0:                 episode reward: -0.8500,                 loss: 0.1681
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 2131.05,                last time consumption/overall running time: 307.3354s / 31056.4564 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.1611
env0_second_0:                 episode reward: 2.4500,                 loss: 0.1671
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 2016.5,                last time consumption/overall running time: 292.4081s / 31348.8645 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1790
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1979
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1906.5,                last time consumption/overall running time: 275.2666s / 31624.1311 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2085
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2120
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1942.9,                last time consumption/overall running time: 283.2914s / 31907.4225 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.2057
env0_second_0:                 episode reward: 3.0500,                 loss: 0.2000
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 2035.7,                last time consumption/overall running time: 294.9208s / 32202.3433 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1835
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1912
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 2097.35,                last time consumption/overall running time: 300.9613s / 32503.3045 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.1901
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1833
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 2005.55,                last time consumption/overall running time: 292.5563s / 32795.8609 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.1839
env0_second_0:                 episode reward: -1.2000,                 loss: 0.1909
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 2129.0,                last time consumption/overall running time: 307.8161s / 33103.6770 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1787
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1828
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 2024.2,                last time consumption/overall running time: 295.9683s / 33399.6453 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.1907
env0_second_0:                 episode reward: 2.9000,                 loss: 0.1847
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1956.5,                last time consumption/overall running time: 285.3339s / 33684.9792 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.1887
env0_second_0:                 episode reward: 2.7000,                 loss: 0.2079
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 2070.85,                last time consumption/overall running time: 300.2074s / 33985.1866 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1652
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1714
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 2097.45,                last time consumption/overall running time: 300.7735s / 34285.9601 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.1719
env0_second_0:                 episode reward: 1.7500,                 loss: 0.1708
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 2055.0,                last time consumption/overall running time: 296.1475s / 34582.1077 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.1985
env0_second_0:                 episode reward: -1.9500,                 loss: 0.2062
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1950.6,                last time consumption/overall running time: 284.0526s / 34866.1603 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.1940
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2052
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 2104.75,                last time consumption/overall running time: 302.5414s / 35168.7017 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1889
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1857
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 2022.8,                last time consumption/overall running time: 289.4969s / 35458.1985 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2042
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2071
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 2034.95,                last time consumption/overall running time: 294.9060s / 35753.1045 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2033
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2009
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 2061.75,                last time consumption/overall running time: 296.7700s / 36049.8745 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.1723
env0_second_0:                 episode reward: 2.4000,                 loss: 0.1744
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 2056.3,                last time consumption/overall running time: 296.7547s / 36346.6292 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.1662
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1705
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 2041.35,                last time consumption/overall running time: 291.0403s / 36637.6695 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2031
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2170
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 2041.5,                last time consumption/overall running time: 293.5328s / 36931.2023 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.1839
env0_second_0:                 episode reward: -1.3500,                 loss: 0.1932
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 2002.8,                last time consumption/overall running time: 288.4719s / 37219.6743 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2136
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2181
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 2122.65,                last time consumption/overall running time: 305.7303s / 37525.4046 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.1950
env0_second_0:                 episode reward: -0.7000,                 loss: 0.1948
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 2080.1,                last time consumption/overall running time: 299.8098s / 37825.2144 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.1941
env0_second_0:                 episode reward: 2.3000,                 loss: 0.2120
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 2187.15,                last time consumption/overall running time: 311.4011s / 38136.6154 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.1808
env0_second_0:                 episode reward: -0.7000,                 loss: 0.1757
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1944.3,                last time consumption/overall running time: 279.3984s / 38416.0138 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2278
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2282
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 2170.5,                last time consumption/overall running time: 309.9472s / 38725.9610 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.1695
env0_second_0:                 episode reward: -1.3000,                 loss: 0.1702
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 2120.6,                last time consumption/overall running time: 302.9916s / 39028.9526 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.1805
env0_second_0:                 episode reward: -3.2000,                 loss: 0.1779
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 2089.25,                last time consumption/overall running time: 300.2863s / 39329.2389 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.1774
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1983
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 2088.9,                last time consumption/overall running time: 297.8955s / 39627.1344 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1791
env0_second_0:                 episode reward: 4.2000,                 loss: 0.1739
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1907.95,                last time consumption/overall running time: 273.5637s / 39900.6981 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.2151
env0_second_0:                 episode reward: 2.6500,                 loss: 0.2056
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 2133.6,                last time consumption/overall running time: 306.2017s / 40206.8998 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.1698
env0_second_0:                 episode reward: 1.1000,                 loss: 0.1736
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 2110.75,                last time consumption/overall running time: 303.7881s / 40510.6879 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.1942
env0_second_0:                 episode reward: 1.8500,                 loss: 0.1985
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 2096.6,                last time consumption/overall running time: 300.1714s / 40810.8593 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2134
env0_second_0:                 episode reward: 1.6000,                 loss: 0.2067
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1978.5,                last time consumption/overall running time: 281.4750s / 41092.3343 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2053
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2021
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 2096.4,                last time consumption/overall running time: 299.4533s / 41391.7876 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.1865
env0_second_0:                 episode reward: 2.8500,                 loss: 0.1830
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 2153.3,                last time consumption/overall running time: 308.5109s / 41700.2986 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.1782
env0_second_0:                 episode reward: 2.0500,                 loss: 0.1836
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 2036.9,                last time consumption/overall running time: 293.0516s / 41993.3501 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2195
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2255
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 2111.85,                last time consumption/overall running time: 302.7379s / 42296.0880 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.1989
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2006
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 2176.1,                last time consumption/overall running time: 312.0042s / 42608.0922 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.1826
env0_second_0:                 episode reward: 1.2000,                 loss: 0.1825
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 2164.0,                last time consumption/overall running time: 310.6052s / 42918.6974 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.1760
env0_second_0:                 episode reward: 2.2000,                 loss: 0.1840
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 2135.95,                last time consumption/overall running time: 305.4062s / 43224.1037 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.1842
env0_second_0:                 episode reward: 2.2500,                 loss: 0.1723
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 2133.1,                last time consumption/overall running time: 306.3734s / 43530.4771 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.1845
env0_second_0:                 episode reward: 2.1000,                 loss: 0.1762
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 2064.45,                last time consumption/overall running time: 295.6562s / 43826.1333 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.1863
env0_second_0:                 episode reward: 2.9500,                 loss: 0.2146
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 2250.4,                last time consumption/overall running time: 323.0491s / 44149.1824 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.1500
env0_second_0:                 episode reward: 1.7500,                 loss: 0.1558
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 2039.1,                last time consumption/overall running time: 290.1082s / 44439.2906 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.1848
env0_second_0:                 episode reward: 1.3500,                 loss: 0.1870
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 2053.15,                last time consumption/overall running time: 291.8657s / 44731.1563 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.1857
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2059
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 2096.2,                last time consumption/overall running time: 303.3759s / 45034.5322 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2033
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2400
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 2232.0,                last time consumption/overall running time: 321.6384s / 45356.1706 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.1548
env0_second_0:                 episode reward: 2.9500,                 loss: 0.1627
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 2150.7,                last time consumption/overall running time: 312.4425s / 45668.6131 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1921
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1808
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 2111.85,                last time consumption/overall running time: 305.0631s / 45973.6762 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.1811
env0_second_0:                 episode reward: 3.5000,                 loss: 0.1760
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 2065.6,                last time consumption/overall running time: 298.0731s / 46271.7494 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.2220
env0_second_0:                 episode reward: 3.8000,                 loss: 0.2264
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 2131.5,                last time consumption/overall running time: 304.9018s / 46576.6511 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.1907
env0_second_0:                 episode reward: 1.9000,                 loss: 0.1902
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 2192.55,                last time consumption/overall running time: 321.1043s / 46897.7554 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2061
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2002
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 2160.65,                last time consumption/overall running time: 310.1244s / 47207.8798 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.1750
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2138
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 2172.45,                last time consumption/overall running time: 314.2932s / 47522.1729 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.1607
env0_second_0:                 episode reward: 1.8500,                 loss: 0.1676
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 2145.95,                last time consumption/overall running time: 308.1825s / 47830.3555 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.1855
env0_second_0:                 episode reward: 1.2500,                 loss: 0.1895
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 2137.0,                last time consumption/overall running time: 307.1279s / 48137.4833 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.1928
env0_second_0:                 episode reward: 2.9500,                 loss: 0.1964
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 2079.05,                last time consumption/overall running time: 300.3117s / 48437.7951 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.1962
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2067
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 2239.5,                last time consumption/overall running time: 323.2967s / 48761.0917 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.2813
env0_second_0:                 episode reward: 3.5000,                 loss: 0.3264
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 2039.45,                last time consumption/overall running time: 296.4412s / 49057.5330 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.2216
env0_second_0:                 episode reward: 2.4500,                 loss: 0.2242
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 2117.85,                last time consumption/overall running time: 305.4615s / 49362.9945 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.1761
env0_second_0:                 episode reward: 4.5500,                 loss: 0.1813
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 2196.35,                last time consumption/overall running time: 317.8109s / 49680.8054 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.1850
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2074
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 2128.8,                last time consumption/overall running time: 305.9628s / 49986.7682 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.1499
env0_second_0:                 episode reward: 4.3000,                 loss: 0.1595
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 2151.85,                last time consumption/overall running time: 310.4159s / 50297.1842 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.1600
env0_second_0:                 episode reward: 4.6000,                 loss: 0.2029
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 2257.85,                last time consumption/overall running time: 324.6475s / 50621.8317 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.1708
env0_second_0:                 episode reward: 2.1500,                 loss: 0.2051
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 2208.3,                last time consumption/overall running time: 320.7298s / 50942.5614 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1521
env0_second_0:                 episode reward: 3.9500,                 loss: 0.1488
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 2258.95,                last time consumption/overall running time: 329.4063s / 51271.9677 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.1564
env0_second_0:                 episode reward: 2.5000,                 loss: 0.1541
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 2078.05,                last time consumption/overall running time: 302.9365s / 51574.9042 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1710
env0_second_0:                 episode reward: 3.6000,                 loss: 0.1710
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 2168.2,                last time consumption/overall running time: 311.8194s / 51886.7236 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.1377
env0_second_0:                 episode reward: 6.4500,                 loss: 0.1489
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 2162.35,                last time consumption/overall running time: 311.5428s / 52198.2664 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.1708
env0_second_0:                 episode reward: 2.5000,                 loss: 0.1811
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 2135.4,                last time consumption/overall running time: 307.0723s / 52505.3387 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.1545
env0_second_0:                 episode reward: 5.0000,                 loss: 0.1782
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 2146.85,                last time consumption/overall running time: 311.3808s / 52816.7195 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.1523
env0_second_0:                 episode reward: 5.1000,                 loss: 0.1710
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 2130.7,                last time consumption/overall running time: 311.0905s / 53127.8100 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.1646
env0_second_0:                 episode reward: 3.9500,                 loss: 0.1721
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 2220.45,                last time consumption/overall running time: 320.6213s / 53448.4314 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.1874
env0_second_0:                 episode reward: 4.1000,                 loss: 0.2138
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 2099.25,                last time consumption/overall running time: 305.3496s / 53753.7809 s
env0_first_0:                 episode reward: -5.5000,                 loss: 0.1508
env0_second_0:                 episode reward: 5.5000,                 loss: 0.1540
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 2160.6,                last time consumption/overall running time: 310.3618s / 54064.1427 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.1750
env0_second_0:                 episode reward: 4.5000,                 loss: 0.1981
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 2239.35,                last time consumption/overall running time: 324.2031s / 54388.3458 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.1512
env0_second_0:                 episode reward: 3.3000,                 loss: 0.1850
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 2099.3,                last time consumption/overall running time: 305.5583s / 54693.9042 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1387
env0_second_0:                 episode reward: 3.8000,                 loss: 0.1672
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 2180.2,                last time consumption/overall running time: 317.1022s / 55011.0064 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1627
env0_second_0:                 episode reward: 3.8000,                 loss: 0.1734
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 2070.85,                last time consumption/overall running time: 300.8380s / 55311.8444 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.1803
env0_second_0:                 episode reward: 2.3000,                 loss: 0.2089
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 2057.65,                last time consumption/overall running time: 298.8210s / 55610.6654 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.1589
env0_second_0:                 episode reward: 2.8000,                 loss: 0.1725
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 2220.4,                last time consumption/overall running time: 320.5654s / 55931.2309 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.1453
env0_second_0:                 episode reward: 4.0000,                 loss: 0.1592
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 2208.05,                last time consumption/overall running time: 320.5245s / 56251.7553 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1590
env0_second_0:                 episode reward: 4.2000,                 loss: 0.1929
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 2230.8,                last time consumption/overall running time: 320.3796s / 56572.1349 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.1376
env0_second_0:                 episode reward: 4.3000,                 loss: 0.1354
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 2330.55,                last time consumption/overall running time: 330.6791s / 56902.8140 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.1646
env0_second_0:                 episode reward: 2.8000,                 loss: 0.1730
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 2192.2,                last time consumption/overall running time: 315.0654s / 57217.8794 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.1553
env0_second_0:                 episode reward: 5.2500,                 loss: 0.1868
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 2306.9,                last time consumption/overall running time: 328.9259s / 57546.8053 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.1449
env0_second_0:                 episode reward: 3.8500,                 loss: 0.1510
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 2117.85,                last time consumption/overall running time: 304.8380s / 57851.6433 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.1621
env0_second_0:                 episode reward: 6.2000,                 loss: 0.1859
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 2233.7,                last time consumption/overall running time: 317.2394s / 58168.8826 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1649
env0_second_0:                 episode reward: 3.3500,                 loss: 0.1761
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 2210.3,                last time consumption/overall running time: 319.9712s / 58488.8538 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.1400
env0_second_0:                 episode reward: 5.1500,                 loss: 0.1596
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 2273.45,                last time consumption/overall running time: 324.5031s / 58813.3570 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.1602
env0_second_0:                 episode reward: 4.2500,                 loss: 0.1679
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 2346.25,                last time consumption/overall running time: 333.0510s / 59146.4079 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1551
env0_second_0:                 episode reward: 3.3500,                 loss: 0.1738
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 2329.7,                last time consumption/overall running time: 329.5176s / 59475.9255 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.1769
env0_second_0:                 episode reward: 5.0000,                 loss: 0.1722
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 2242.75,                last time consumption/overall running time: 319.8025s / 59795.7280 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.1421
env0_second_0:                 episode reward: 6.5500,                 loss: 0.1593
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 2312.5,                last time consumption/overall running time: 325.6632s / 60121.3912 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.1519
env0_second_0:                 episode reward: 3.5500,                 loss: 0.1645
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 2240.9,                last time consumption/overall running time: 313.8919s / 60435.2831 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.1385
env0_second_0:                 episode reward: 6.4000,                 loss: 0.1501
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 2265.9,                last time consumption/overall running time: 316.1977s / 60751.4807 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.1366
env0_second_0:                 episode reward: 4.3500,                 loss: 0.1422
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 2337.65,                last time consumption/overall running time: 329.0718s / 61080.5526 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1255
env0_second_0:                 episode reward: 4.2000,                 loss: 0.1433
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 2119.6,                last time consumption/overall running time: 300.5459s / 61381.0985 s
env0_first_0:                 episode reward: -5.8500,                 loss: 0.1631
env0_second_0:                 episode reward: 5.8500,                 loss: 0.1629
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 2300.7,                last time consumption/overall running time: 319.8026s / 61700.9011 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.1502
env0_second_0:                 episode reward: 5.9000,                 loss: 0.1552
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 2344.95,                last time consumption/overall running time: 330.7998s / 62031.7009 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.1392
env0_second_0:                 episode reward: 2.9500,                 loss: 0.1653
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 2379.75,                last time consumption/overall running time: 334.6279s / 62366.3289 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.1450
env0_second_0:                 episode reward: 4.5000,                 loss: 0.1603
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 2230.9,                last time consumption/overall running time: 306.9269s / 62673.2558 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.1350
env0_second_0:                 episode reward: 5.4500,                 loss: 0.1601
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 2306.7,                last time consumption/overall running time: 317.0725s / 62990.3283 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.1279
env0_second_0:                 episode reward: 4.4000,                 loss: 0.1459
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 2362.45,                last time consumption/overall running time: 327.5019s / 63317.8302 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.1072
env0_second_0:                 episode reward: 6.4000,                 loss: 0.1175
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 2138.05,                last time consumption/overall running time: 301.3991s / 63619.2293 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.1501
env0_second_0:                 episode reward: 4.3500,                 loss: 0.1867
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 2304.55,                last time consumption/overall running time: 321.8378s / 63941.0671 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.1317
env0_second_0:                 episode reward: 6.9000,                 loss: 0.1563
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 2085.9,                last time consumption/overall running time: 291.7159s / 64232.7830 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.1272
env0_second_0:                 episode reward: 6.9000,                 loss: 0.1442
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 2291.5,                last time consumption/overall running time: 321.6906s / 64554.4736 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.1286
env0_second_0:                 episode reward: 6.3500,                 loss: 0.1331
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 2236.75,                last time consumption/overall running time: 310.5371s / 64865.0106 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.1177
env0_second_0:                 episode reward: 7.6000,                 loss: 0.1296
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 2278.8,                last time consumption/overall running time: 303.2666s / 65168.2772 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.1422
env0_second_0:                 episode reward: 3.2000,                 loss: 0.1601
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 2162.55,                last time consumption/overall running time: 280.7564s / 65449.0336 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.1289
env0_second_0:                 episode reward: 6.7500,                 loss: 0.1555
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 2194.35,                last time consumption/overall running time: 284.6903s / 65733.7239 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.1421
env0_second_0:                 episode reward: 7.7500,                 loss: 0.1713
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1887.2,                last time consumption/overall running time: 246.3412s / 65980.0651 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.1467
env0_second_0:                 episode reward: 10.4000,                 loss: 0.1691
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1935.2,                last time consumption/overall running time: 250.2926s / 66230.3577 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.1560
env0_second_0:                 episode reward: 8.5000,                 loss: 0.2492
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 2148.95,                last time consumption/overall running time: 279.6751s / 66510.0328 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.1366
env0_second_0:                 episode reward: 8.1500,                 loss: 0.1580
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 2221.2,                last time consumption/overall running time: 288.9847s / 66799.0175 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.1000
env0_second_0:                 episode reward: 7.8500,                 loss: 0.1335
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 2168.25,                last time consumption/overall running time: 277.9247s / 67076.9422 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.1129
env0_second_0:                 episode reward: 9.8500,                 loss: 0.1326
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 2187.65,                last time consumption/overall running time: 279.9422s / 67356.8844 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.1254
env0_second_0:                 episode reward: 6.5500,                 loss: 0.1554
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 2215.45,                last time consumption/overall running time: 284.8350s / 67641.7193 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.1029
env0_second_0:                 episode reward: 9.2500,                 loss: 0.1255
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 2327.35,                last time consumption/overall running time: 300.1233s / 67941.8426 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0972
env0_second_0:                 episode reward: 9.1500,                 loss: 0.1091
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 2222.5,                last time consumption/overall running time: 284.4223s / 68226.2649 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.1165
env0_second_0:                 episode reward: 9.1000,                 loss: 0.1425
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 2146.75,                last time consumption/overall running time: 274.3587s / 68500.6236 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.1044
env0_second_0:                 episode reward: 10.4500,                 loss: 0.1274
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 2225.0,                last time consumption/overall running time: 286.4838s / 68787.1074 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.1021
env0_second_0:                 episode reward: 7.5000,                 loss: 0.1227
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 2038.4,                last time consumption/overall running time: 260.8706s / 69047.9781 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.1156
env0_second_0:                 episode reward: 11.1000,                 loss: 0.1359
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 2140.5,                last time consumption/overall running time: 275.1673s / 69323.1453 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.1124
env0_second_0:                 episode reward: 7.8000,                 loss: 0.1357
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 2161.55,                last time consumption/overall running time: 278.5898s / 69601.7351 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.1264
env0_second_0:                 episode reward: 9.1000,                 loss: 0.1381
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 2148.05,                last time consumption/overall running time: 275.6566s / 69877.3917 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.0882
env0_second_0:                 episode reward: 10.1500,                 loss: 0.1035
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 2128.25,                last time consumption/overall running time: 269.7307s / 70147.1224 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.1201
env0_second_0:                 episode reward: 11.3000,                 loss: 0.1511
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 2108.1,                last time consumption/overall running time: 271.0903s / 70418.2128 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0974
env0_second_0:                 episode reward: 8.8000,                 loss: 0.1151
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 2097.8,                last time consumption/overall running time: 266.1170s / 70684.3298 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0905
env0_second_0:                 episode reward: 10.5000,                 loss: 0.1216
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1979.9,                last time consumption/overall running time: 253.5022s / 70937.8320 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.1155
env0_second_0:                 episode reward: 12.2000,                 loss: 0.1256
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 2069.7,                last time consumption/overall running time: 266.2328s / 71204.0648 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.1009
env0_second_0:                 episode reward: 10.4500,                 loss: 0.1202
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 2234.85,                last time consumption/overall running time: 282.8347s / 71486.8995 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0835
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0894
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 2074.75,                last time consumption/overall running time: 265.7870s / 71752.6865 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.1138
env0_second_0:                 episode reward: 11.3000,                 loss: 0.1364
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 2109.35,                last time consumption/overall running time: 267.7133s / 72020.3998 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.1081
env0_second_0:                 episode reward: 10.2000,                 loss: 0.1392
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 2074.95,                last time consumption/overall running time: 265.1083s / 72285.5081 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.0949
env0_second_0:                 episode reward: 11.2000,                 loss: 0.1161
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 2229.1,                last time consumption/overall running time: 279.2745s / 72564.7826 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0967
env0_second_0:                 episode reward: 9.1000,                 loss: 0.1238
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 2143.55,                last time consumption/overall running time: 271.0914s / 72835.8740 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.0778
env0_second_0:                 episode reward: 11.1500,                 loss: 0.1217
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 2075.4,                last time consumption/overall running time: 264.4117s / 73100.2857 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0977
env0_second_0:                 episode reward: 11.9000,                 loss: 0.1214
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 2130.45,                last time consumption/overall running time: 265.8303s / 73366.1160 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0897
env0_second_0:                 episode reward: 10.5500,                 loss: 0.1177
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 2045.9,                last time consumption/overall running time: 260.8402s / 73626.9562 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.1013
env0_second_0:                 episode reward: 11.7000,                 loss: 0.1352
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 2257.45,                last time consumption/overall running time: 287.1100s / 73914.0662 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.0966
env0_second_0:                 episode reward: 9.8000,                 loss: 0.1188
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 2039.45,                last time consumption/overall running time: 264.1923s / 74178.2585 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0903
env0_second_0:                 episode reward: 11.1000,                 loss: 0.1176
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 2104.0,                last time consumption/overall running time: 267.5637s / 74445.8222 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.1045
env0_second_0:                 episode reward: 9.6000,                 loss: 0.1318
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 2046.55,                last time consumption/overall running time: 262.3398s / 74708.1620 s
env0_first_0:                 episode reward: -11.2000,                 loss: 0.1015
env0_second_0:                 episode reward: 11.2000,                 loss: 0.1247
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 2151.9,                last time consumption/overall running time: 274.2961s / 74982.4581 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0838
env0_second_0:                 episode reward: 12.9000,                 loss: 0.1109
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 2185.75,                last time consumption/overall running time: 278.4246s / 75260.8827 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.0861
env0_second_0:                 episode reward: 10.6000,                 loss: 0.1001
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 2164.15,                last time consumption/overall running time: 275.4247s / 75536.3073 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0827
env0_second_0:                 episode reward: 11.3000,                 loss: 0.1175
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1959.9,                last time consumption/overall running time: 249.8593s / 75786.1666 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0966
env0_second_0:                 episode reward: 11.9000,                 loss: 0.1192
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 2195.2,                last time consumption/overall running time: 279.2660s / 76065.4327 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0683
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0780
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 2074.8,                last time consumption/overall running time: 264.5491s / 76329.9817 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0557
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0905
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 2068.05,                last time consumption/overall running time: 264.7296s / 76594.7113 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.0537
env0_second_0:                 episode reward: 12.3000,                 loss: 0.1009
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 2182.8,                last time consumption/overall running time: 277.9017s / 76872.6131 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0698
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0896
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 2159.2,                last time consumption/overall running time: 273.8779s / 77146.4909 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0618
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0845
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 2159.6,                last time consumption/overall running time: 275.0563s / 77421.5472 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.0515
env0_second_0:                 episode reward: 13.3000,                 loss: 0.0708
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 2090.65,                last time consumption/overall running time: 266.0738s / 77687.6211 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0729
env0_second_0:                 episode reward: 11.9000,                 loss: 0.1029
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 2270.4,                last time consumption/overall running time: 286.0859s / 77973.7070 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0586
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0794
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 2203.25,                last time consumption/overall running time: 278.9934s / 78252.7004 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.0941
env0_second_0:                 episode reward: 11.3000,                 loss: 0.1342
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 2176.65,                last time consumption/overall running time: 272.5648s / 78525.2652 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0724
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0975
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 2077.25,                last time consumption/overall running time: 261.0389s / 78786.3042 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.0605
env0_second_0:                 episode reward: 14.3000,                 loss: 0.0883
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 2172.4,                last time consumption/overall running time: 274.2004s / 79060.5046 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0817
env0_second_0:                 episode reward: 11.9000,                 loss: 0.1167
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 2151.95,                last time consumption/overall running time: 270.1558s / 79330.6604 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0558
env0_second_0:                 episode reward: 12.2500,                 loss: 0.0821
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 2145.2,                last time consumption/overall running time: 272.2477s / 79602.9081 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.0533
env0_second_0:                 episode reward: 12.9000,                 loss: 0.0719
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 2171.25,                last time consumption/overall running time: 274.7937s / 79877.7018 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0667
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0855
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 2075.35,                last time consumption/overall running time: 260.3946s / 80138.0964 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.0596
env0_second_0:                 episode reward: 14.2500,                 loss: 0.1033
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 2153.0,                last time consumption/overall running time: 271.1134s / 80409.2097 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0771
env0_second_0:                 episode reward: 11.8000,                 loss: 0.0964
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 1975.4,                last time consumption/overall running time: 248.1501s / 80657.3599 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0741
env0_second_0:                 episode reward: 12.9500,                 loss: 0.1133
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 2154.35,                last time consumption/overall running time: 270.1802s / 80927.5401 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.0465
env0_second_0:                 episode reward: 14.1500,                 loss: 0.0632
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 2106.75,                last time consumption/overall running time: 265.0981s / 81192.6381 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.0612
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0810
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 2202.1,                last time consumption/overall running time: 276.0107s / 81468.6488 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.0642
env0_second_0:                 episode reward: 12.6000,                 loss: 0.0983
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 2055.3,                last time consumption/overall running time: 258.5372s / 81727.1860 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.0788
env0_second_0:                 episode reward: 13.7500,                 loss: 0.0972
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 2133.6,                last time consumption/overall running time: 269.1414s / 81996.3274 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.0940
env0_second_0:                 episode reward: 11.8000,                 loss: 0.1227
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 2108.2,                last time consumption/overall running time: 262.6697s / 82258.9971 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.1009
env0_second_0:                 episode reward: 12.1500,                 loss: 0.1247
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 2218.95,                last time consumption/overall running time: 271.6254s / 82530.6225 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.0907
env0_second_0:                 episode reward: 12.2500,                 loss: 0.1161
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 2281.5,                last time consumption/overall running time: 282.3706s / 82812.9931 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.0973
env0_second_0:                 episode reward: 12.4000,                 loss: 0.1241
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 2263.15,                last time consumption/overall running time: 274.6814s / 83087.6745 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.0688
env0_second_0:                 episode reward: 11.4000,                 loss: 0.1109
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 2247.85,                last time consumption/overall running time: 273.2964s / 83360.9709 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.0981
env0_second_0:                 episode reward: 11.9500,                 loss: 0.1228
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 2255.65,                last time consumption/overall running time: 271.3766s / 83632.3475 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.0686
env0_second_0:                 episode reward: 12.7500,                 loss: 0.0992
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 2161.35,                last time consumption/overall running time: 262.3895s / 83894.7370 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0802
env0_second_0:                 episode reward: 10.5000,                 loss: 0.1190
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 2186.6,                last time consumption/overall running time: 264.5315s / 84159.2685 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.1039
env0_second_0:                 episode reward: 11.9000,                 loss: 0.1489
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 2137.7,                last time consumption/overall running time: 256.4527s / 84415.7212 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0699
env0_second_0:                 episode reward: 15.2500,                 loss: 0.1045
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 2432.0,                last time consumption/overall running time: 293.2814s / 84709.0026 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0972
env0_second_0:                 episode reward: 10.0500,                 loss: 0.1251
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 2480.75,                last time consumption/overall running time: 299.2741s / 85008.2767 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.0954
env0_second_0:                 episode reward: 11.4500,                 loss: 0.1294
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 2862.5,                last time consumption/overall running time: 334.7431s / 85343.0198 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0804
env0_second_0:                 episode reward: 9.3500,                 loss: 0.1228
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 2818.45,                last time consumption/overall running time: 331.5467s / 85674.5665 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0828
env0_second_0:                 episode reward: 9.2500,                 loss: 0.1215
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 2639.9,                last time consumption/overall running time: 310.2744s / 85984.8409 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0755
env0_second_0:                 episode reward: 10.5000,                 loss: 0.1135
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 2759.3,                last time consumption/overall running time: 330.7189s / 86315.5598 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0794
env0_second_0:                 episode reward: 7.8000,                 loss: 0.1074
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 3087.1,                last time consumption/overall running time: 366.7286s / 86682.2884 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0720
env0_second_0:                 episode reward: 9.7000,                 loss: 0.1001
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 3470.55,                last time consumption/overall running time: 412.4201s / 87094.7085 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0422
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0823
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 2977.45,                last time consumption/overall running time: 343.4937s / 87438.2022 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0563
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0892
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 2914.65,                last time consumption/overall running time: 333.1858s / 87771.3880 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0801
env0_second_0:                 episode reward: 9.2500,                 loss: 0.1114
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 3022.65,                last time consumption/overall running time: 348.3914s / 88119.7794 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0889
env0_second_0:                 episode reward: 7.4000,                 loss: 0.1123
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 2890.85,                last time consumption/overall running time: 335.0785s / 88454.8579 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0721
env0_second_0:                 episode reward: 9.0000,                 loss: 0.0987
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 2883.95,                last time consumption/overall running time: 330.3211s / 88785.1790 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.1111
env0_second_0:                 episode reward: 9.4000,                 loss: 0.1456
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 3064.05,                last time consumption/overall running time: 347.0965s / 89132.2755 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0685
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0977
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 3287.9,                last time consumption/overall running time: 377.7941s / 89510.0697 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0765
env0_second_0:                 episode reward: 7.1000,                 loss: 0.1161
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 3190.8,                last time consumption/overall running time: 366.8286s / 89876.8983 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.0792
env0_second_0:                 episode reward: 6.7500,                 loss: 0.1131
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 3083.55,                last time consumption/overall running time: 348.7191s / 90225.6174 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.1010
env0_second_0:                 episode reward: 7.7000,                 loss: 0.1211
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 3041.65,                last time consumption/overall running time: 345.4703s / 90571.0877 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.1172
env0_second_0:                 episode reward: 6.6500,                 loss: 0.1639
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 3178.6,                last time consumption/overall running time: 365.0765s / 90936.1642 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0877
env0_second_0:                 episode reward: 8.1500,                 loss: 0.1143
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 2874.35,                last time consumption/overall running time: 321.0847s / 91257.2490 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0732
env0_second_0:                 episode reward: 9.6500,                 loss: 0.1112
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 3047.0,                last time consumption/overall running time: 339.1458s / 91596.3948 s
env0_first_0:                 episode reward: -10.5000,                 loss: 0.0696
env0_second_0:                 episode reward: 10.5000,                 loss: 0.1089
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 2878.1,                last time consumption/overall running time: 327.4392s / 91923.8339 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0774
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0983
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 3062.65,                last time consumption/overall running time: 349.5064s / 92273.3403 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0806
env0_second_0:                 episode reward: 8.1000,                 loss: 0.1168
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 3160.25,                last time consumption/overall running time: 354.8661s / 92628.2065 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0855
env0_second_0:                 episode reward: 7.6500,                 loss: 0.1193
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 3376.3,                last time consumption/overall running time: 379.0211s / 93007.2276 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0607
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0847
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 3101.95,                last time consumption/overall running time: 354.3151s / 93361.5427 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0819
env0_second_0:                 episode reward: 9.0500,                 loss: 0.1057
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 3215.2,                last time consumption/overall running time: 363.9241s / 93725.4668 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0853
env0_second_0:                 episode reward: 7.2000,                 loss: 0.1245
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 3335.3,                last time consumption/overall running time: 375.1816s / 94100.6484 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0838
env0_second_0:                 episode reward: 7.7500,                 loss: 0.1155
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 3209.9,                last time consumption/overall running time: 361.5690s / 94462.2174 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0887
env0_second_0:                 episode reward: 7.7000,                 loss: 0.1202
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 3278.15,                last time consumption/overall running time: 364.9578s / 94827.1753 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.0751
env0_second_0:                 episode reward: 6.2000,                 loss: 0.1061
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 3321.95,                last time consumption/overall running time: 372.8635s / 95200.0387 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0696
env0_second_0:                 episode reward: 6.8000,                 loss: 0.1099
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 3393.55,                last time consumption/overall running time: 381.8239s / 95581.8626 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0848
env0_second_0:                 episode reward: 7.3500,                 loss: 0.1054
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 3320.9,                last time consumption/overall running time: 368.1887s / 95950.0513 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0722
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0989
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 3267.55,                last time consumption/overall running time: 371.2630s / 96321.3144 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0665
env0_second_0:                 episode reward: 8.4000,                 loss: 0.1082
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 3143.7,                last time consumption/overall running time: 361.5107s / 96682.8251 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0655
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0934
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 3014.05,                last time consumption/overall running time: 336.6885s / 97019.5136 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0857
env0_second_0:                 episode reward: 8.9000,                 loss: 0.1174
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 3138.9,                last time consumption/overall running time: 354.2202s / 97373.7338 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0829
env0_second_0:                 episode reward: 9.2500,                 loss: 0.1216
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 3288.3,                last time consumption/overall running time: 373.5404s / 97747.2742 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0829
env0_second_0:                 episode reward: 7.7000,                 loss: 0.1251
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 3127.75,                last time consumption/overall running time: 355.8317s / 98103.1059 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0685
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0989
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 3252.9,                last time consumption/overall running time: 365.9006s / 98469.0065 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0838
env0_second_0:                 episode reward: 10.4000,                 loss: 0.1060
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 2913.25,                last time consumption/overall running time: 326.7608s / 98795.7672 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.0981
env0_second_0:                 episode reward: 10.9000,                 loss: 0.1227
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 3169.8,                last time consumption/overall running time: 354.6380s / 99150.4052 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.0846
env0_second_0:                 episode reward: 9.0000,                 loss: 0.1145
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 3442.6,                last time consumption/overall running time: 388.4676s / 99538.8729 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0602
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0986
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 3089.8,                last time consumption/overall running time: 350.3317s / 99889.2046 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0674
env0_second_0:                 episode reward: 10.6500,                 loss: 0.1157
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 3212.25,                last time consumption/overall running time: 356.7120s / 100245.9166 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0540
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0943
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 3333.65,                last time consumption/overall running time: 372.2100s / 100618.1266 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.0666
env0_second_0:                 episode reward: 9.6500,                 loss: 0.1008
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 3218.65,                last time consumption/overall running time: 361.4162s / 100979.5428 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.0740
env0_second_0:                 episode reward: 9.9000,                 loss: 0.1145
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 3302.25,                last time consumption/overall running time: 360.9659s / 101340.5087 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.0561
env0_second_0:                 episode reward: 8.8500,                 loss: 0.0856
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 3319.6,                last time consumption/overall running time: 370.8382s / 101711.3469 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.0501
env0_second_0:                 episode reward: 9.7500,                 loss: 0.0808
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 3403.5,                last time consumption/overall running time: 378.1645s / 102089.5114 s
env0_first_0:                 episode reward: -8.3500,                 loss: 0.0729
env0_second_0:                 episode reward: 8.3500,                 loss: 0.0956
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 3205.8,                last time consumption/overall running time: 360.0647s / 102449.5761 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0724
env0_second_0:                 episode reward: 9.7000,                 loss: 0.1084
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 3181.4,                last time consumption/overall running time: 356.1820s / 102805.7580 s
env0_first_0:                 episode reward: -9.2000,                 loss: 0.0553
env0_second_0:                 episode reward: 9.2000,                 loss: 0.0975
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 3250.5,                last time consumption/overall running time: 367.1622s / 103172.9203 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.0749
env0_second_0:                 episode reward: 11.5000,                 loss: 0.1030
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 3006.2,                last time consumption/overall running time: 351.7131s / 103524.6334 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0883
env0_second_0:                 episode reward: 10.7000,                 loss: 0.1306
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 3228.2,                last time consumption/overall running time: 354.0903s / 103878.7237 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0664
env0_second_0:                 episode reward: 11.0500,                 loss: 0.1014
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 3458.75,                last time consumption/overall running time: 384.1341s / 104262.8578 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0550
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0901
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 3482.05,                last time consumption/overall running time: 396.3415s / 104659.1992 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0653
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0827
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 3332.8,                last time consumption/overall running time: 372.1361s / 105031.3354 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0522
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0910
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 3742.5,                last time consumption/overall running time: 405.7988s / 105437.1341 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0601
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0854
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 3146.7,                last time consumption/overall running time: 350.1718s / 105787.3059 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0922
env0_second_0:                 episode reward: 10.0000,                 loss: 0.1319
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 3336.05,                last time consumption/overall running time: 363.0612s / 106150.3671 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0797
env0_second_0:                 episode reward: 9.1500,                 loss: 0.1103
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 3176.7,                last time consumption/overall running time: 343.8482s / 106494.2153 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0930
env0_second_0:                 episode reward: 6.8000,                 loss: 0.1200
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 3404.8,                last time consumption/overall running time: 385.0190s / 106879.2343 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0681
env0_second_0:                 episode reward: 8.6500,                 loss: 0.1076
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 3412.05,                last time consumption/overall running time: 363.5177s / 107242.7521 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0769
env0_second_0:                 episode reward: 8.5000,                 loss: 0.1234
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 3382.95,                last time consumption/overall running time: 361.1876s / 107603.9396 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0545
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0968
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 3578.45,                last time consumption/overall running time: 392.9167s / 107996.8564 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0717
env0_second_0:                 episode reward: 7.3000,                 loss: 0.1043
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 3514.45,                last time consumption/overall running time: 392.2128s / 108389.0692 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0747
env0_second_0:                 episode reward: 8.2500,                 loss: 0.1123
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 3372.7,                last time consumption/overall running time: 372.1628s / 108761.2320 s
env0_first_0:                 episode reward: -6.4000,                 loss: 0.0837
env0_second_0:                 episode reward: 6.4000,                 loss: 0.1206
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 3488.9,                last time consumption/overall running time: 388.3009s / 109149.5329 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0667
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0980
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 3490.6,                last time consumption/overall running time: 380.7564s / 109530.2893 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.0622
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0931
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 3512.65,                last time consumption/overall running time: 386.3798s / 109916.6691 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0737
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0841
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 3595.9,                last time consumption/overall running time: 389.7082s / 110306.3773 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0842
env0_second_0:                 episode reward: 7.6500,                 loss: 0.1092
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 3670.8,                last time consumption/overall running time: 404.2678s / 110710.6451 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0754
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0981
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 3531.2,                last time consumption/overall running time: 377.8498s / 111088.4948 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0924
env0_second_0:                 episode reward: 7.1000,                 loss: 0.1121
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 3557.5,                last time consumption/overall running time: 395.5731s / 111484.0680 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0697
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0888
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 3750.75,                last time consumption/overall running time: 418.9492s / 111903.0172 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0713
env0_second_0:                 episode reward: 5.8000,                 loss: 0.1208
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 3445.4,                last time consumption/overall running time: 378.8264s / 112281.8435 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0702
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0913
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 3338.35,                last time consumption/overall running time: 364.3351s / 112646.1786 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.0632
env0_second_0:                 episode reward: 9.4500,                 loss: 0.0906
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 3622.4,                last time consumption/overall running time: 395.1492s / 113041.3278 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0620
env0_second_0:                 episode reward: 9.2500,                 loss: 0.0821
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 3470.5,                last time consumption/overall running time: 384.8798s / 113426.2075 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0522
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0930
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 3417.4,                last time consumption/overall running time: 372.1816s / 113798.3891 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.0722
env0_second_0:                 episode reward: 10.1000,                 loss: 0.0937
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 3639.6,                last time consumption/overall running time: 399.0672s / 114197.4563 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0609
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0970
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 3372.75,                last time consumption/overall running time: 365.4222s / 114562.8785 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0641
env0_second_0:                 episode reward: 9.0500,                 loss: 0.0804
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 3457.2,                last time consumption/overall running time: 388.7006s / 114951.5792 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0482
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0798
env1_first_0:                 episode reward: -9.0000,                 loss: nan
env1_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 3366.0,                last time consumption/overall running time: 361.6500s / 115313.2291 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0540
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0776
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 3599.1,                last time consumption/overall running time: 400.3688s / 115713.5979 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0621
env0_second_0:                 episode reward: 7.7500,                 loss: 0.0984
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 3515.5,                last time consumption/overall running time: 378.3554s / 116091.9533 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0631
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0988
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 3226.0,                last time consumption/overall running time: 353.6873s / 116445.6406 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0652
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0923
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 3488.25,                last time consumption/overall running time: 381.4693s / 116827.1099 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0674
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0843
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 3696.9,                last time consumption/overall running time: 394.9298s / 117222.0398 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0507
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0772
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 3570.45,                last time consumption/overall running time: 391.3994s / 117613.4391 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0617
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0793
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 3553.9,                last time consumption/overall running time: 384.6563s / 117998.0954 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0532
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0764
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 3381.45,                last time consumption/overall running time: 376.5591s / 118374.6546 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0674
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0929
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 3564.3,                last time consumption/overall running time: 387.2281s / 118761.8827 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0451
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0850
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 3829.45,                last time consumption/overall running time: 411.4870s / 119173.3697 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0562
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0784
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 3634.7,                last time consumption/overall running time: 396.7131s / 119570.0828 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0701
env0_second_0:                 episode reward: 7.4000,                 loss: 0.0853
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 3521.9,                last time consumption/overall running time: 386.8422s / 119956.9250 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.0623
env0_second_0:                 episode reward: 8.8500,                 loss: 0.0820
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 3495.3,                last time consumption/overall running time: 388.6601s / 120345.5851 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.0602
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0943
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 3555.3,                last time consumption/overall running time: 386.3610s / 120731.9461 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0526
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0915
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 3739.55,                last time consumption/overall running time: 408.4554s / 121140.4015 s
env0_first_0:                 episode reward: -7.6500,                 loss: 0.0574
env0_second_0:                 episode reward: 7.6500,                 loss: 0.0708
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 3580.1,                last time consumption/overall running time: 380.2826s / 121520.6841 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0548
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0791
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 3492.5,                last time consumption/overall running time: 384.4455s / 121905.1296 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.0634
env0_second_0:                 episode reward: 9.1000,                 loss: 0.0790
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 3539.25,                last time consumption/overall running time: 386.6429s / 122291.7725 s
env0_first_0:                 episode reward: -8.8500,                 loss: 0.0451
env0_second_0:                 episode reward: 8.8500,                 loss: 0.0784
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 3757.2,                last time consumption/overall running time: 406.9236s / 122698.6961 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.0604
env0_second_0:                 episode reward: 5.6500,                 loss: 0.0943
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 3845.2,                last time consumption/overall running time: 413.3154s / 123112.0116 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0542
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0757
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 3453.15,                last time consumption/overall running time: 384.7631s / 123496.7747 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0809
env0_second_0:                 episode reward: 7.7000,                 loss: 3.9568
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 3484.2,                last time consumption/overall running time: 388.5104s / 123885.2851 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.0563
env0_second_0:                 episode reward: 8.7000,                 loss: 3.4538
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 3588.85,                last time consumption/overall running time: 397.4507s / 124282.7358 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0623
env0_second_0:                 episode reward: 7.8500,                 loss: 3.3304
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 3424.65,                last time consumption/overall running time: 368.9021s / 124651.6379 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0663
env0_second_0:                 episode reward: 8.5000,                 loss: 3.0762
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 3701.2,                last time consumption/overall running time: 409.3087s / 125060.9466 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0412
env0_second_0:                 episode reward: 8.2500,                 loss: 1.4094
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 3632.3,                last time consumption/overall running time: 401.4998s / 125462.4464 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0554
env0_second_0:                 episode reward: 9.7000,                 loss: 1.0921
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 3426.3,                last time consumption/overall running time: 376.6277s / 125839.0741 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0598
env0_second_0:                 episode reward: 8.1000,                 loss: 0.4786
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 3615.55,                last time consumption/overall running time: 398.8833s / 126237.9574 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0589
env0_second_0:                 episode reward: 9.2500,                 loss: 0.1540
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 3500.9,                last time consumption/overall running time: 383.2013s / 126621.1587 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0592
env0_second_0:                 episode reward: 8.8000,                 loss: 0.1256
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 3459.2,                last time consumption/overall running time: 374.9352s / 126996.0939 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0600
env0_second_0:                 episode reward: 9.1500,                 loss: 0.1195
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 3615.25,                last time consumption/overall running time: 398.4025s / 127394.4964 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0485
env0_second_0:                 episode reward: 9.1500,                 loss: 0.1014
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 3749.35,                last time consumption/overall running time: 399.9339s / 127794.4303 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.0507
env0_second_0:                 episode reward: 6.2500,                 loss: 0.0899
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 3334.2,                last time consumption/overall running time: 355.2117s / 128149.6420 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.0657
env0_second_0:                 episode reward: 9.6000,                 loss: 0.1014
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 3678.2,                last time consumption/overall running time: 404.3210s / 128553.9630 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0521
env0_second_0:                 episode reward: 7.7000,                 loss: 0.0951
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 3754.35,                last time consumption/overall running time: 417.3186s / 128971.2817 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0845
env0_second_0:                 episode reward: 3.6000,                 loss: 0.1449
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 3941.2,                last time consumption/overall running time: 434.9581s / 129406.2398 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0533
env0_second_0:                 episode reward: 4.9500,                 loss: 0.0924
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 3562.1,                last time consumption/overall running time: 382.4979s / 129788.7377 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0760
env0_second_0:                 episode reward: 6.9000,                 loss: 0.1172
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 3589.25,                last time consumption/overall running time: 395.6742s / 130184.4119 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0498
env0_second_0:                 episode reward: 8.2500,                 loss: 0.0780
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 3530.6,                last time consumption/overall running time: 412.2475s / 130596.6593 s
env0_first_0:                 episode reward: -7.7500,                 loss: 0.0821
env0_second_0:                 episode reward: 7.7500,                 loss: 0.1446
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 3623.65,                last time consumption/overall running time: 394.1808s / 130990.8401 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0587
env0_second_0:                 episode reward: 8.0500,                 loss: 0.0969
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 3489.1,                last time consumption/overall running time: 389.4507s / 131380.2907 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.0479
env0_second_0:                 episode reward: 9.4000,                 loss: 0.0893
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 3772.6,                last time consumption/overall running time: 410.5352s / 131790.8259 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0591
env0_second_0:                 episode reward: 7.9500,                 loss: 0.1151
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 3740.9,                last time consumption/overall running time: 413.9735s / 132204.7993 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.0613
env0_second_0:                 episode reward: 7.7000,                 loss: 0.1080
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 3741.85,                last time consumption/overall running time: 409.9898s / 132614.7892 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0540
env0_second_0:                 episode reward: 8.9000,                 loss: 0.1086
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 3652.85,                last time consumption/overall running time: 408.1549s / 133022.9441 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0560
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0787
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 3632.3,                last time consumption/overall running time: 398.8948s / 133421.8389 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0535
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0962
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 3346.9,                last time consumption/overall running time: 374.8322s / 133796.6711 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0503
env0_second_0:                 episode reward: 11.7500,                 loss: 0.0760
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 3492.0,                last time consumption/overall running time: 380.3074s / 134176.9785 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0552
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0863
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 3735.35,                last time consumption/overall running time: 410.4546s / 134587.4331 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0291
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0528
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 3588.35,                last time consumption/overall running time: 383.6647s / 134971.0977 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0585
env0_second_0:                 episode reward: 8.0000,                 loss: 0.1024
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 3506.5,                last time consumption/overall running time: 386.8439s / 135357.9417 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0589
env0_second_0:                 episode reward: 8.9000,                 loss: 0.0781
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 3364.7,                last time consumption/overall running time: 380.2698s / 135738.2114 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0619
env0_second_0:                 episode reward: 7.8000,                 loss: 0.1045
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 3623.35,                last time consumption/overall running time: 408.3712s / 136146.5827 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.0483
env0_second_0:                 episode reward: 9.1500,                 loss: 0.0711
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 3492.6,                last time consumption/overall running time: 387.4111s / 136533.9938 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0452
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0838
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 3644.45,                last time consumption/overall running time: 398.8246s / 136932.8184 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0403
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0645
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 3424.35,                last time consumption/overall running time: 383.7426s / 137316.5610 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.0567
env0_second_0:                 episode reward: 10.4000,                 loss: 0.0866
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 3598.75,                last time consumption/overall running time: 393.9162s / 137710.4771 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.0345
env0_second_0:                 episode reward: 8.5500,                 loss: 0.0576
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 3574.85,                last time consumption/overall running time: 401.8090s / 138112.2862 s
env0_first_0:                 episode reward: -8.6500,                 loss: 0.0618
env0_second_0:                 episode reward: 8.6500,                 loss: 0.1008
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 3811.55,                last time consumption/overall running time: 409.8167s / 138522.1029 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0550
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0825
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 3531.0,                last time consumption/overall running time: 394.1496s / 138916.2525 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.0528
env0_second_0:                 episode reward: 9.6000,                 loss: 0.0862
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 3198.3,                last time consumption/overall running time: 349.4358s / 139265.6882 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.0772
env0_second_0:                 episode reward: 7.8000,                 loss: 0.1051
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 3595.55,                last time consumption/overall running time: 393.4229s / 139659.1112 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0708
env0_second_0:                 episode reward: 6.8000,                 loss: 0.1017
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 3556.35,                last time consumption/overall running time: 398.0990s / 140057.2102 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0520
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0810
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 3702.1,                last time consumption/overall running time: 425.2057s / 140482.4159 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.0431
env0_second_0:                 episode reward: 7.3000,                 loss: 0.0769
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 3690.2,                last time consumption/overall running time: 415.9350s / 140898.3508 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0537
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0798
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 3553.85,                last time consumption/overall running time: 391.3292s / 141289.6800 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0417
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0792
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 3492.55,                last time consumption/overall running time: 384.3556s / 141674.0356 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.0612
env0_second_0:                 episode reward: 9.9500,                 loss: 0.0918
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 3792.15,                last time consumption/overall running time: 438.3470s / 142112.3826 s
env0_first_0:                 episode reward: -7.4000,                 loss: 0.0628
env0_second_0:                 episode reward: 7.4000,                 loss: 0.1113
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 3639.25,                last time consumption/overall running time: 402.6325s / 142515.0151 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0515
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0875
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 3645.05,                last time consumption/overall running time: 400.5800s / 142915.5952 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.0443
env0_second_0:                 episode reward: 8.0000,                 loss: 0.0814
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 3855.1,                last time consumption/overall running time: 421.8355s / 143337.4307 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.0451
env0_second_0:                 episode reward: 7.5500,                 loss: 0.0785
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 3549.35,                last time consumption/overall running time: 395.2002s / 143732.6308 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0601
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0814
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 3665.95,                last time consumption/overall running time: 412.2741s / 144144.9050 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0463
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0740
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 3848.5,                last time consumption/overall running time: 414.0733s / 144558.9782 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0406
env0_second_0:                 episode reward: 5.1000,                 loss: 0.0767
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 3553.05,                last time consumption/overall running time: 405.4397s / 144964.4179 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.0628
env0_second_0:                 episode reward: 8.8000,                 loss: 0.0895
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 4132.65,                last time consumption/overall running time: 444.6657s / 145409.0835 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.0514
env0_second_0:                 episode reward: 5.4500,                 loss: 0.0911
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 4062.15,                last time consumption/overall running time: 442.7744s / 145851.8579 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0347
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0632
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 3810.6,                last time consumption/overall running time: 420.2823s / 146272.1402 s
env0_first_0:                 episode reward: -7.4500,                 loss: 0.0471
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0682
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 3717.95,                last time consumption/overall running time: 404.8694s / 146677.0096 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.0460
env0_second_0:                 episode reward: 9.3000,                 loss: 0.0815
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 3610.7,                last time consumption/overall running time: 396.0723s / 147073.0819 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0664
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0986
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 3812.5,                last time consumption/overall running time: 412.7603s / 147485.8422 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0787
env0_second_0:                 episode reward: 4.1500,                 loss: 0.1164
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 4034.45,                last time consumption/overall running time: 442.5229s / 147928.3651 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0496
env0_second_0:                 episode reward: 5.2000,                 loss: 0.0804
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 3898.75,                last time consumption/overall running time: 423.4076s / 148351.7727 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.0643
env0_second_0:                 episode reward: 4.8500,                 loss: 0.1066
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 3793.0,                last time consumption/overall running time: 404.7724s / 148756.5451 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0602
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0998
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 3749.55,                last time consumption/overall running time: 408.0878s / 149164.6329 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0519
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0912
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 3856.95,                last time consumption/overall running time: 423.0662s / 149587.6991 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0575
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0864
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 4161.65,                last time consumption/overall running time: 444.8476s / 150032.5468 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0507
env0_second_0:                 episode reward: 4.4000,                 loss: 0.0809
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 3897.35,                last time consumption/overall running time: 427.0058s / 150459.5526 s
env0_first_0:                 episode reward: -6.9000,                 loss: 0.0441
env0_second_0:                 episode reward: 6.9000,                 loss: 0.0679
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 3862.75,                last time consumption/overall running time: 443.0704s / 150902.6230 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.0507
env0_second_0:                 episode reward: 6.4500,                 loss: 0.0827
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 3983.4,                last time consumption/overall running time: 440.9761s / 151343.5991 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.0652
env0_second_0:                 episode reward: 5.0000,                 loss: 0.0970
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 4073.5,                last time consumption/overall running time: 458.1039s / 151801.7030 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0547
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0899
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 4088.45,                last time consumption/overall running time: 444.2051s / 152245.9080 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0674
env0_second_0:                 episode reward: 3.5500,                 loss: 0.1101
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 3928.4,                last time consumption/overall running time: 421.1605s / 152667.0686 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0627
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0889
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 4347.8,                last time consumption/overall running time: 468.4567s / 153135.5253 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0431
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0743
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 4105.2,                last time consumption/overall running time: 461.4023s / 153596.9275 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0537
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0988
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 3919.85,                last time consumption/overall running time: 443.1999s / 154040.1275 sLoad pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -5.9500,                 loss: 0.0496
env0_second_0:                 episode reward: 5.9500,                 loss: 0.0791
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 4231.1,                last time consumption/overall running time: 455.1029s / 154495.2304 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.0511
env0_second_0:                 episode reward: 5.0500,                 loss: 0.0799
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 4007.1,                last time consumption/overall running time: 439.3409s / 154934.5713 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0526
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0928
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 4091.45,                last time consumption/overall running time: 450.8484s / 155385.4196 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0703
env0_second_0:                 episode reward: 4.4500,                 loss: 0.1150
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 3301.9,                last time consumption/overall running time: 358.6227s / 155744.0423 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0698
env0_second_0:                 episode reward: 9.2500,                 loss: 0.1008
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 3534.05,                last time consumption/overall running time: 395.1306s / 156139.1729 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.0582
env0_second_0:                 episode reward: 7.1000,                 loss: 0.0818
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 3870.9,                last time consumption/overall running time: 421.7860s / 156560.9589 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0430
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0935
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 4140.15,                last time consumption/overall running time: 450.8865s / 157011.8454 s
env0_first_0:                 episode reward: -5.9500,                 loss: 0.0374
env0_second_0:                 episode reward: 5.9500,                 loss: 0.0606
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 4100.9,                last time consumption/overall running time: 453.9794s / 157465.8248 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0451
env0_second_0:                 episode reward: 5.8000,                 loss: 0.0785
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 4166.95,                last time consumption/overall running time: 466.1171s / 157931.9419 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.0651
env0_second_0:                 episode reward: 5.0500,                 loss: 0.0944
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
