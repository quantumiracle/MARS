pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [756, 941, 514, 24, 756]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 50, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220508_1730/pettingzoo_tennis_v2_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220508_1730/pettingzoo_tennis_v2_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 87.7209s / 87.7209 s
env0_first_0:                 episode reward: 214.0000,                 loss: 0.0682
env0_second_0:                 episode reward: -214.0000,                 loss: nan
env1_first_0:                 episode reward: 219.0000,                 loss: nan
env1_second_0:                 episode reward: -219.0000,                 loss: nan
env2_first_0:                 episode reward: 216.0000,                 loss: nan
env2_second_0:                 episode reward: -216.0000,                 loss: nan
env3_first_0:                 episode reward: 219.0000,                 loss: nan
env3_second_0:                 episode reward: -219.0000,                 loss: nan
env4_first_0:                 episode reward: 216.0000,                 loss: nan
env4_second_0:                 episode reward: -216.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2989.8013s / 3077.5223 s
env0_first_0:                 episode reward: 216.1000,                 loss: 0.0182
env0_second_0:                 episode reward: -216.1000,                 loss: nan
env1_first_0:                 episode reward: 209.0000,                 loss: nan
env1_second_0:                 episode reward: -209.0000,                 loss: nan
env2_first_0:                 episode reward: 214.6000,                 loss: nan
env2_second_0:                 episode reward: -214.6000,                 loss: nan
env3_first_0:                 episode reward: 215.9000,                 loss: nan
env3_second_0:                 episode reward: -215.9000,                 loss: nan
env4_first_0:                 episode reward: 214.7000,                 loss: nan
env4_second_0:                 episode reward: -214.7000,                 loss: nan
Score delta: 431.0, update the opponent.
Episode: 41/10000 (0.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2892.3994s / 5969.9216 s
env0_first_0:                 episode reward: -219.0000,                 loss: nan
env0_second_0:                 episode reward: 219.0000,                 loss: 0.0152
env1_first_0:                 episode reward: -219.0000,                 loss: nan
env1_second_0:                 episode reward: 219.0000,                 loss: nan
env2_first_0:                 episode reward: -219.0000,                 loss: nan
env2_second_0:                 episode reward: 219.0000,                 loss: nan
env3_first_0:                 episode reward: -219.0000,                 loss: nan
env3_second_0:                 episode reward: 219.0000,                 loss: nan
env4_first_0:                 episode reward: -219.0000,                 loss: nan
env4_second_0:                 episode reward: 219.0000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 3386.3,                last time consumption/overall running time: 1141.8383s / 7111.7599 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.0237
env0_second_0:                 episode reward: 15.9000,                 loss: 0.0121
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
env2_first_0:                 episode reward: -20.7500,                 loss: nan
env2_second_0:                 episode reward: 20.7500,                 loss: nan
env3_first_0:                 episode reward: -5.1000,                 loss: nan
env3_second_0:                 episode reward: 5.1000,                 loss: nan
env4_first_0:                 episode reward: -8.9500,                 loss: nan
env4_second_0:                 episode reward: 8.9500,                 loss: nan
Score delta: 438.0, update the opponent.
Episode: 81/10000 (0.8100%),                 avg. length: 2863.55,                last time consumption/overall running time: 968.3943s / 8080.1542 s
env0_first_0:                 episode reward: 11.3000,                 loss: 0.0198
env0_second_0:                 episode reward: -11.3000,                 loss: nan
env1_first_0:                 episode reward: 15.4000,                 loss: nan
env1_second_0:                 episode reward: -15.4000,                 loss: nan
env2_first_0:                 episode reward: 13.9500,                 loss: nan
env2_second_0:                 episode reward: -13.9500,                 loss: nan
env3_first_0:                 episode reward: 9.9000,                 loss: nan
env3_second_0:                 episode reward: -9.9000,                 loss: nan
env4_first_0:                 episode reward: 11.4000,                 loss: nan
env4_second_0:                 episode reward: -11.4000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 2225.25,                last time consumption/overall running time: 750.3033s / 8830.4575 s
env0_first_0:                 episode reward: 10.0000,                 loss: 0.0207
env0_second_0:                 episode reward: -10.0000,                 loss: nan
env1_first_0:                 episode reward: 8.2500,                 loss: nan
env1_second_0:                 episode reward: -8.2500,                 loss: nan
env2_first_0:                 episode reward: 6.7000,                 loss: nan
env2_second_0:                 episode reward: -6.7000,                 loss: nan
env3_first_0:                 episode reward: 10.1000,                 loss: nan
env3_second_0:                 episode reward: -10.1000,                 loss: nan
env4_first_0:                 episode reward: 7.2000,                 loss: nan
env4_second_0:                 episode reward: -7.2000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1944.45,                last time consumption/overall running time: 657.7071s / 9488.1646 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0166
env0_second_0:                 episode reward: -20.8000,                 loss: nan
env1_first_0:                 episode reward: 20.2500,                 loss: nan
env1_second_0:                 episode reward: -20.2500,                 loss: nan
env2_first_0:                 episode reward: 20.3500,                 loss: nan
env2_second_0:                 episode reward: -20.3500,                 loss: nan
env3_first_0:                 episode reward: 21.3000,                 loss: nan
env3_second_0:                 episode reward: -21.3000,                 loss: nan
env4_first_0:                 episode reward: 20.0500,                 loss: nan
env4_second_0:                 episode reward: -20.0500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1734.85,                last time consumption/overall running time: 579.7780s / 10067.9427 s
env0_first_0:                 episode reward: 16.6000,                 loss: 0.0149
env0_second_0:                 episode reward: -16.6000,                 loss: nan
env1_first_0:                 episode reward: 17.7000,                 loss: nan
env1_second_0:                 episode reward: -17.7000,                 loss: nan
env2_first_0:                 episode reward: 16.6500,                 loss: nan
env2_second_0:                 episode reward: -16.6500,                 loss: nan
env3_first_0:                 episode reward: 15.5000,                 loss: nan
env3_second_0:                 episode reward: -15.5000,                 loss: nan
env4_first_0:                 episode reward: 17.1500,                 loss: nan
env4_second_0:                 episode reward: -17.1500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1831.85,                last time consumption/overall running time: 633.8357s / 10701.7784 s
env0_first_0:                 episode reward: 19.9500,                 loss: 0.0146
env0_second_0:                 episode reward: -19.9500,                 loss: nan
env1_first_0:                 episode reward: 22.2500,                 loss: nan
env1_second_0:                 episode reward: -22.2500,                 loss: nan
env2_first_0:                 episode reward: 22.8500,                 loss: nan
env2_second_0:                 episode reward: -22.8500,                 loss: nan
env3_first_0:                 episode reward: 23.0500,                 loss: nan
env3_second_0:                 episode reward: -23.0500,                 loss: nan
env4_first_0:                 episode reward: 22.9500,                 loss: nan
env4_second_0:                 episode reward: -22.9500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1871.05,                last time consumption/overall running time: 659.9994s / 11361.7777 s
env0_first_0:                 episode reward: 15.8000,                 loss: 0.0145
env0_second_0:                 episode reward: -15.8000,                 loss: nan
env1_first_0:                 episode reward: 18.0000,                 loss: nan
env1_second_0:                 episode reward: -18.0000,                 loss: nan
env2_first_0:                 episode reward: 14.5000,                 loss: nan
env2_second_0:                 episode reward: -14.5000,                 loss: nan
env3_first_0:                 episode reward: 12.0000,                 loss: nan
env3_second_0:                 episode reward: -12.0000,                 loss: nan
env4_first_0:                 episode reward: 15.0000,                 loss: nan
env4_second_0:                 episode reward: -15.0000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 2752.3,                last time consumption/overall running time: 960.5039s / 12322.2817 s
env0_first_0:                 episode reward: 34.1000,                 loss: 0.0136
env0_second_0:                 episode reward: -34.1000,                 loss: 0.0185
env1_first_0:                 episode reward: 35.1500,                 loss: nan
env1_second_0:                 episode reward: -35.1500,                 loss: nan
env2_first_0:                 episode reward: 36.3500,                 loss: nan
env2_second_0:                 episode reward: -36.3500,                 loss: nan
env3_first_0:                 episode reward: 33.7000,                 loss: nan
env3_second_0:                 episode reward: -33.7000,                 loss: nan
env4_first_0:                 episode reward: 34.6500,                 loss: nan
env4_second_0:                 episode reward: -34.6500,                 loss: nan
Score delta: 51.4, update the opponent.
Episode: 221/10000 (2.2100%),                 avg. length: 4350.25,                last time consumption/overall running time: 1518.6006s / 13840.8822 s
env0_first_0:                 episode reward: -26.0000,                 loss: 0.0266
env0_second_0:                 episode reward: 26.0000,                 loss: 0.0142
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
env2_first_0:                 episode reward: -9.6500,                 loss: nan
env2_second_0:                 episode reward: 9.6500,                 loss: nan
env3_first_0:                 episode reward: -19.0500,                 loss: nan
env3_second_0:                 episode reward: 19.0500,                 loss: nan
env4_first_0:                 episode reward: -5.6500,                 loss: nan
env4_second_0:                 episode reward: 5.6500,                 loss: nan
Score delta: 71.2, update the opponent.
Episode: 241/10000 (2.4100%),                 avg. length: 5023.15,                last time consumption/overall running time: 1746.1322s / 15587.0144 s
env0_first_0:                 episode reward: 18.0000,                 loss: 0.0164
env0_second_0:                 episode reward: -18.0000,                 loss: nan
env1_first_0:                 episode reward: 15.0500,                 loss: nan
env1_second_0:                 episode reward: -15.0500,                 loss: nan
env2_first_0:                 episode reward: 13.8500,                 loss: nan
env2_second_0:                 episode reward: -13.8500,                 loss: nan
env3_first_0:                 episode reward: 13.9500,                 loss: nan
env3_second_0:                 episode reward: -13.9500,                 loss: nan
env4_first_0:                 episode reward: 20.8500,                 loss: nan
env4_second_0:                 episode reward: -20.8500,                 loss: nan
Score delta: 82.8, update the opponent.
Episode: 261/10000 (2.6100%),                 avg. length: 4292.7,                last time consumption/overall running time: 1511.8393s / 17098.8537 s
env0_first_0:                 episode reward: 53.1500,                 loss: nan
env0_second_0:                 episode reward: -53.1500,                 loss: 0.0181
env1_first_0:                 episode reward: 52.1500,                 loss: nan
env1_second_0:                 episode reward: -52.1500,                 loss: nan
env2_first_0:                 episode reward: 52.6500,                 loss: nan
env2_second_0:                 episode reward: -52.6500,                 loss: nan
env3_first_0:                 episode reward: 53.6500,                 loss: nan
env3_second_0:                 episode reward: -53.6500,                 loss: nan
env4_first_0:                 episode reward: 57.3000,                 loss: nan
env4_second_0:                 episode reward: -57.3000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 4002.45,                last time consumption/overall running time: 1443.9702s / 18542.8239 s
env0_first_0:                 episode reward: 22.5000,                 loss: nan
env0_second_0:                 episode reward: -22.5000,                 loss: 0.0172
env1_first_0:                 episode reward: 22.0000,                 loss: nan
env1_second_0:                 episode reward: -22.0000,                 loss: nan
env2_first_0:                 episode reward: 25.2500,                 loss: nan
env2_second_0:                 episode reward: -25.2500,                 loss: nan
env3_first_0:                 episode reward: 25.2000,                 loss: nan
env3_second_0:                 episode reward: -25.2000,                 loss: nan
env4_first_0:                 episode reward: 22.4500,                 loss: nan
env4_second_0:                 episode reward: -22.4500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 2559.4,                last time consumption/overall running time: 918.4509s / 19461.2748 s
env0_first_0:                 episode reward: -7.1500,                 loss: nan
env0_second_0:                 episode reward: 7.1500,                 loss: 0.0164
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
env2_first_0:                 episode reward: -9.8500,                 loss: nan
env2_second_0:                 episode reward: 9.8500,                 loss: nan
env3_first_0:                 episode reward: -7.5000,                 loss: nan
env3_second_0:                 episode reward: 7.5000,                 loss: nan
env4_first_0:                 episode reward: -11.0500,                 loss: nan
env4_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 2463.05,                last time consumption/overall running time: 883.6170s / 20344.8918 s
env0_first_0:                 episode reward: -10.0500,                 loss: nan
env0_second_0:                 episode reward: 10.0500,                 loss: 0.0149
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
env2_first_0:                 episode reward: -8.7500,                 loss: nan
env2_second_0:                 episode reward: 8.7500,                 loss: nan
env3_first_0:                 episode reward: -4.7500,                 loss: nan
env3_second_0:                 episode reward: 4.7500,                 loss: nan
env4_first_0:                 episode reward: -5.2000,                 loss: nan
env4_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1934.4,                last time consumption/overall running time: 692.3947s / 21037.2865 s
env0_first_0:                 episode reward: -18.3000,                 loss: nan
env0_second_0:                 episode reward: 18.3000,                 loss: 0.0129
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
env2_first_0:                 episode reward: -18.2500,                 loss: nan
env2_second_0:                 episode reward: 18.2500,                 loss: nan
env3_first_0:                 episode reward: -17.7000,                 loss: nan
env3_second_0:                 episode reward: 17.7000,                 loss: nan
env4_first_0:                 episode reward: -17.2000,                 loss: nan
env4_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1794.85,                last time consumption/overall running time: 645.6984s / 21682.9849 s
env0_first_0:                 episode reward: -18.2500,                 loss: nan
env0_second_0:                 episode reward: 18.2500,                 loss: 0.0129
env1_first_0:                 episode reward: -18.2500,                 loss: nan
env1_second_0:                 episode reward: 18.2500,                 loss: nan
env2_first_0:                 episode reward: -18.9500,                 loss: nan
env2_second_0:                 episode reward: 18.9500,                 loss: nan
env3_first_0:                 episode reward: -19.1500,                 loss: nan
env3_second_0:                 episode reward: 19.1500,                 loss: nan
env4_first_0:                 episode reward: -19.6500,                 loss: nan
env4_second_0:                 episode reward: 19.6500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1754.85,                last time consumption/overall running time: 631.0439s / 22314.0288 s
env0_first_0:                 episode reward: -19.5500,                 loss: nan
env0_second_0:                 episode reward: 19.5500,                 loss: 0.0104
env1_first_0:                 episode reward: -20.7000,                 loss: nan
env1_second_0:                 episode reward: 20.7000,                 loss: nan
env2_first_0:                 episode reward: -20.7000,                 loss: nan
env2_second_0:                 episode reward: 20.7000,                 loss: nan
env3_first_0:                 episode reward: -20.6500,                 loss: nan
env3_second_0:                 episode reward: 20.6500,                 loss: nan
env4_first_0:                 episode reward: -21.1500,                 loss: nan
env4_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1674.65,                last time consumption/overall running time: 600.5909s / 22914.6197 s
env0_first_0:                 episode reward: -17.5000,                 loss: nan
env0_second_0:                 episode reward: 17.5000,                 loss: 0.0101
env1_first_0:                 episode reward: -19.6000,                 loss: nan
env1_second_0:                 episode reward: 19.6000,                 loss: nan
env2_first_0:                 episode reward: -19.5000,                 loss: nan
env2_second_0:                 episode reward: 19.5000,                 loss: nan
env3_first_0:                 episode reward: -19.5500,                 loss: nan
env3_second_0:                 episode reward: 19.5500,                 loss: nan
env4_first_0:                 episode reward: -19.9000,                 loss: nan
env4_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1746.65,                last time consumption/overall running time: 624.8338s / 23539.4536 s
env0_first_0:                 episode reward: -21.2000,                 loss: nan
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0096
env1_first_0:                 episode reward: -20.0000,                 loss: nan
env1_second_0:                 episode reward: 20.0000,                 loss: nan
env2_first_0:                 episode reward: -21.6000,                 loss: nan
env2_second_0:                 episode reward: 21.6000,                 loss: nan
env3_first_0:                 episode reward: -21.7000,                 loss: nan
env3_second_0:                 episode reward: 21.7000,                 loss: nan
env4_first_0:                 episode reward: -21.0500,                 loss: nan
env4_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1685.25,                last time consumption/overall running time: 599.9346s / 24139.3882 s
env0_first_0:                 episode reward: -22.1500,                 loss: nan
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0090
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
env2_first_0:                 episode reward: -22.0000,                 loss: nan
env2_second_0:                 episode reward: 22.0000,                 loss: nan
env3_first_0:                 episode reward: -21.8000,                 loss: nan
env3_second_0:                 episode reward: 21.8000,                 loss: nan
env4_first_0:                 episode reward: -21.6000,                 loss: nan
env4_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1704.9,                last time consumption/overall running time: 596.3564s / 24735.7446 s
env0_first_0:                 episode reward: -21.7500,                 loss: nan
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0089
env1_first_0:                 episode reward: -22.0000,                 loss: nan
env1_second_0:                 episode reward: 22.0000,                 loss: nan
env2_first_0:                 episode reward: -21.3500,                 loss: nan
env2_second_0:                 episode reward: 21.3500,                 loss: nan
env3_first_0:                 episode reward: -20.7500,                 loss: nan
env3_second_0:                 episode reward: 20.7500,                 loss: nan
env4_first_0:                 episode reward: -21.7500,                 loss: nan
env4_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1928.7,                last time consumption/overall running time: 676.5295s / 25412.2740 s
env0_first_0:                 episode reward: -18.0500,                 loss: nan
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0097
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
env2_first_0:                 episode reward: -16.8000,                 loss: nan
env2_second_0:                 episode reward: 16.8000,                 loss: nan
env3_first_0:                 episode reward: -16.6000,                 loss: nan
env3_second_0:                 episode reward: 16.6000,                 loss: nan
env4_first_0:                 episode reward: -16.1000,                 loss: nan
env4_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 2480.85,                last time consumption/overall running time: 846.2774s / 26258.5515 s
env0_first_0:                 episode reward: -26.9000,                 loss: 0.0192
env0_second_0:                 episode reward: 26.9000,                 loss: 0.0110
env1_first_0:                 episode reward: -26.7000,                 loss: nan
env1_second_0:                 episode reward: 26.7000,                 loss: nan
env2_first_0:                 episode reward: -26.9500,                 loss: nan
env2_second_0:                 episode reward: 26.9500,                 loss: nan
env3_first_0:                 episode reward: -26.5000,                 loss: nan
env3_second_0:                 episode reward: 26.5000,                 loss: nan
env4_first_0:                 episode reward: -25.8500,                 loss: nan
env4_second_0:                 episode reward: 25.8500,                 loss: nan
Score delta: 76.4, update the opponent.
Episode: 521/10000 (5.2100%),                 avg. length: 5315.1,                last time consumption/overall running time: 1804.2484s / 28062.7999 s
env0_first_0:                 episode reward: -22.0500,                 loss: 0.0150
env0_second_0:                 episode reward: 22.0500,                 loss: nan
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
env2_first_0:                 episode reward: -17.0500,                 loss: nan
env2_second_0:                 episode reward: 17.0500,                 loss: nan
env3_first_0:                 episode reward: -21.3000,                 loss: nan
env3_second_0:                 episode reward: 21.3000,                 loss: nan
env4_first_0:                 episode reward: -4.4500,                 loss: nan
env4_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 7962.45,                last time consumption/overall running time: 2708.5239s / 30771.3238 s
env0_first_0:                 episode reward: 76.7500,                 loss: 0.0127
env0_second_0:                 episode reward: -76.7500,                 loss: 0.0293
env1_first_0:                 episode reward: 83.0500,                 loss: nan
env1_second_0:                 episode reward: -83.0500,                 loss: nan
env2_first_0:                 episode reward: 77.1000,                 loss: nan
env2_second_0:                 episode reward: -77.1000,                 loss: nan
env3_first_0:                 episode reward: 82.4000,                 loss: nan
env3_second_0:                 episode reward: -82.4000,                 loss: nan
env4_first_0:                 episode reward: 90.3000,                 loss: nan
env4_second_0:                 episode reward: -90.3000,                 loss: nan
Score delta: 67.4, update the opponent.
Episode: 561/10000 (5.6100%),                 avg. length: 7032.35,                last time consumption/overall running time: 2423.8546s / 33195.1784 s
env0_first_0:                 episode reward: 74.9000,                 loss: nan
env0_second_0:                 episode reward: -74.9000,                 loss: 0.0163
env1_first_0:                 episode reward: 72.5500,                 loss: nan
env1_second_0:                 episode reward: -72.5500,                 loss: nan
env2_first_0:                 episode reward: 73.4000,                 loss: nan
env2_second_0:                 episode reward: -73.4000,                 loss: nan
env3_first_0:                 episode reward: 72.0000,                 loss: nan
env3_second_0:                 episode reward: -72.0000,                 loss: nan
env4_first_0:                 episode reward: 77.4000,                 loss: nan
env4_second_0:                 episode reward: -77.4000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 5966.85,                last time consumption/overall running time: 2142.0449s / 35337.2233 s
env0_first_0:                 episode reward: 29.8500,                 loss: nan
env0_second_0:                 episode reward: -29.8500,                 loss: 0.0149
env1_first_0:                 episode reward: 28.5000,                 loss: nan
env1_second_0:                 episode reward: -28.5000,                 loss: nan
env2_first_0:                 episode reward: 23.7500,                 loss: nan
env2_second_0:                 episode reward: -23.7500,                 loss: nan
env3_first_0:                 episode reward: 24.9500,                 loss: nan
env3_second_0:                 episode reward: -24.9500,                 loss: nan
env4_first_0:                 episode reward: 30.4500,                 loss: nan
env4_second_0:                 episode reward: -30.4500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 4568.2,                last time consumption/overall running time: 1638.9533s / 36976.1766 s
env0_first_0:                 episode reward: -4.9000,                 loss: nan
env0_second_0:                 episode reward: 4.9000,                 loss: 0.0124
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: -5.1000,                 loss: nan
env3_second_0:                 episode reward: 5.1000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 3372.95,                last time consumption/overall running time: 1219.4423s / 38195.6189 s
env0_first_0:                 episode reward: -10.8500,                 loss: nan
env0_second_0:                 episode reward: 10.8500,                 loss: 0.0119
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
env2_first_0:                 episode reward: -12.5000,                 loss: nan
env2_second_0:                 episode reward: 12.5000,                 loss: nan
env3_first_0:                 episode reward: -11.4000,                 loss: nan
env3_second_0:                 episode reward: 11.4000,                 loss: nan
env4_first_0:                 episode reward: -13.3000,                 loss: nan
env4_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 3893.15,                last time consumption/overall running time: 1403.0247s / 39598.6437 s
env0_first_0:                 episode reward: -0.1500,                 loss: nan
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -7.5000,                 loss: nan
env2_second_0:                 episode reward: 7.5000,                 loss: nan
env3_first_0:                 episode reward: -3.9000,                 loss: nan
env3_second_0:                 episode reward: 3.9000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 3085.5,                last time consumption/overall running time: 1124.3438s / 40722.9875 s
env0_first_0:                 episode reward: -14.6500,                 loss: nan
env0_second_0:                 episode reward: 14.6500,                 loss: 0.0104
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
env2_first_0:                 episode reward: -14.2500,                 loss: nan
env2_second_0:                 episode reward: 14.2500,                 loss: nan
env3_first_0:                 episode reward: -14.1000,                 loss: nan
env3_second_0:                 episode reward: 14.1000,                 loss: nan
env4_first_0:                 episode reward: -15.6500,                 loss: nan
env4_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 2650.35,                last time consumption/overall running time: 956.4979s / 41679.4854 s
env0_first_0:                 episode reward: -14.4500,                 loss: nan
env0_second_0:                 episode reward: 14.4500,                 loss: 0.0106
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
env2_first_0:                 episode reward: -15.9500,                 loss: nan
env2_second_0:                 episode reward: 15.9500,                 loss: nan
env3_first_0:                 episode reward: -14.0500,                 loss: nan
env3_second_0:                 episode reward: 14.0500,                 loss: nan
env4_first_0:                 episode reward: -14.8500,                 loss: nan
env4_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 3203.6,                last time consumption/overall running time: 1148.6268s / 42828.1122 s
env0_first_0:                 episode reward: -3.3500,                 loss: nan
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0108
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
env3_first_0:                 episode reward: -6.1500,                 loss: nan
env3_second_0:                 episode reward: 6.1500,                 loss: nan
env4_first_0:                 episode reward: -7.2500,                 loss: nan
env4_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 2732.45,                last time consumption/overall running time: 988.9546s / 43817.0668 s
env0_first_0:                 episode reward: -18.7000,                 loss: nan
env0_second_0:                 episode reward: 18.7000,                 loss: 0.0110
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
env2_first_0:                 episode reward: -14.2500,                 loss: nan
env2_second_0:                 episode reward: 14.2500,                 loss: nan
env3_first_0:                 episode reward: -15.3500,                 loss: nan
env3_second_0:                 episode reward: 15.3500,                 loss: nan
env4_first_0:                 episode reward: -14.8000,                 loss: nan
env4_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 2535.1,                last time consumption/overall running time: 912.3817s / 44729.4485 s
env0_first_0:                 episode reward: -18.5500,                 loss: nan
env0_second_0:                 episode reward: 18.5500,                 loss: 0.0110
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
env2_first_0:                 episode reward: -17.4000,                 loss: nan
env2_second_0:                 episode reward: 17.4000,                 loss: nan
env3_first_0:                 episode reward: -16.8500,                 loss: nan
env3_second_0:                 episode reward: 16.8500,                 loss: nan
env4_first_0:                 episode reward: -16.9500,                 loss: nan
env4_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 2418.45,                last time consumption/overall running time: 873.1618s / 45602.6104 s
env0_first_0:                 episode reward: -16.3500,                 loss: nan
env0_second_0:                 episode reward: 16.3500,                 loss: 0.0103
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
env2_first_0:                 episode reward: -17.5500,                 loss: nan
env2_second_0:                 episode reward: 17.5500,                 loss: nan
env3_first_0:                 episode reward: -18.2000,                 loss: nan
env3_second_0:                 episode reward: 18.2000,                 loss: nan
env4_first_0:                 episode reward: -17.7000,                 loss: nan
env4_second_0:                 episode reward: 17.7000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 2395.95,                last time consumption/overall running time: 857.3790s / 46459.9894 s
env0_first_0:                 episode reward: -16.7000,                 loss: nan
env0_second_0:                 episode reward: 16.7000,                 loss: 0.0105
env1_first_0:                 episode reward: -17.4500,                 loss: nan
env1_second_0:                 episode reward: 17.4500,                 loss: nan
env2_first_0:                 episode reward: -17.4500,                 loss: nan
env2_second_0:                 episode reward: 17.4500,                 loss: nan
env3_first_0:                 episode reward: -16.5000,                 loss: nan
env3_second_0:                 episode reward: 16.5000,                 loss: nan
env4_first_0:                 episode reward: -16.1000,                 loss: nan
env4_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 2486.4,                last time consumption/overall running time: 882.6527s / 47342.6421 s
env0_first_0:                 episode reward: -17.1000,                 loss: nan
env0_second_0:                 episode reward: 17.1000,                 loss: 0.0107
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
env2_first_0:                 episode reward: -14.7500,                 loss: nan
env2_second_0:                 episode reward: 14.7500,                 loss: nan
env3_first_0:                 episode reward: -16.5500,                 loss: nan
env3_second_0:                 episode reward: 16.5500,                 loss: nan
env4_first_0:                 episode reward: -14.9000,                 loss: nan
env4_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 2411.5,                last time consumption/overall running time: 864.6178s / 48207.2599 s
env0_first_0:                 episode reward: -18.0500,                 loss: nan
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0109
env1_first_0:                 episode reward: -18.0000,                 loss: nan
env1_second_0:                 episode reward: 18.0000,                 loss: nan
env2_first_0:                 episode reward: -19.1500,                 loss: nan
env2_second_0:                 episode reward: 19.1500,                 loss: nan
env3_first_0:                 episode reward: -17.0500,                 loss: nan
env3_second_0:                 episode reward: 17.0500,                 loss: nan
env4_first_0:                 episode reward: -19.3500,                 loss: nan
env4_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 2501.95,                last time consumption/overall running time: 895.9457s / 49103.2056 s
env0_first_0:                 episode reward: -17.4500,                 loss: nan
env0_second_0:                 episode reward: 17.4500,                 loss: 0.0103
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
env2_first_0:                 episode reward: -16.6500,                 loss: nan
env2_second_0:                 episode reward: 16.6500,                 loss: nan
env3_first_0:                 episode reward: -17.1000,                 loss: nan
env3_second_0:                 episode reward: 17.1000,                 loss: nan
env4_first_0:                 episode reward: -16.1500,                 loss: nan
env4_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 2671.55,                last time consumption/overall running time: 957.9785s / 50061.1841 s
env0_first_0:                 episode reward: -8.7500,                 loss: nan
env0_second_0:                 episode reward: 8.7500,                 loss: 0.0106
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
env2_first_0:                 episode reward: -10.6000,                 loss: nan
env2_second_0:                 episode reward: 10.6000,                 loss: nan
env3_first_0:                 episode reward: -8.6500,                 loss: nan
env3_second_0:                 episode reward: 8.6500,                 loss: nan
env4_first_0:                 episode reward: -8.9500,                 loss: nan
env4_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 2317.5,                last time consumption/overall running time: 836.1923s / 50897.3764 s
env0_first_0:                 episode reward: -13.3500,                 loss: nan
env0_second_0:                 episode reward: 13.3500,                 loss: 0.0108
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
env2_first_0:                 episode reward: -13.3000,                 loss: nan
env2_second_0:                 episode reward: 13.3000,                 loss: nan
env3_first_0:                 episode reward: -14.0000,                 loss: nan
env3_second_0:                 episode reward: 14.0000,                 loss: nan
env4_first_0:                 episode reward: -17.4500,                 loss: nan
env4_second_0:                 episode reward: 17.4500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 2261.35,                last time consumption/overall running time: 819.0977s / 51716.4741 s
env0_first_0:                 episode reward: -18.4000,                 loss: nan
env0_second_0:                 episode reward: 18.4000,                 loss: 0.0105
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
env2_first_0:                 episode reward: -19.2500,                 loss: nan
env2_second_0:                 episode reward: 19.2500,                 loss: nan
env3_first_0:                 episode reward: -19.7000,                 loss: nan
env3_second_0:                 episode reward: 19.7000,                 loss: nan
env4_first_0:                 episode reward: -19.1000,                 loss: nan
env4_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 2219.6,                last time consumption/overall running time: 797.0032s / 52513.4773 s
env0_first_0:                 episode reward: -16.0000,                 loss: nan
env0_second_0:                 episode reward: 16.0000,                 loss: 0.0107
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
env2_first_0:                 episode reward: -19.7500,                 loss: nan
env2_second_0:                 episode reward: 19.7500,                 loss: nan
env3_first_0:                 episode reward: -18.1500,                 loss: nan
env3_second_0:                 episode reward: 18.1500,                 loss: nan
env4_first_0:                 episode reward: -17.9500,                 loss: nan
env4_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 2425.5,                last time consumption/overall running time: 876.6405s / 53390.1178 s
env0_first_0:                 episode reward: -18.7000,                 loss: nan
env0_second_0:                 episode reward: 18.7000,                 loss: 0.0100
env1_first_0:                 episode reward: -18.2500,                 loss: nan
env1_second_0:                 episode reward: 18.2500,                 loss: nan
env2_first_0:                 episode reward: -17.8000,                 loss: nan
env2_second_0:                 episode reward: 17.8000,                 loss: nan
env3_first_0:                 episode reward: -19.0000,                 loss: nan
env3_second_0:                 episode reward: 19.0000,                 loss: nan
env4_first_0:                 episode reward: -17.2500,                 loss: nan
env4_second_0:                 episode reward: 17.2500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 2213.45,                last time consumption/overall running time: 792.1750s / 54182.2928 s
env0_first_0:                 episode reward: -20.8000,                 loss: nan
env0_second_0:                 episode reward: 20.8000,                 loss: 0.0097
env1_first_0:                 episode reward: -20.2000,                 loss: nan
env1_second_0:                 episode reward: 20.2000,                 loss: nan
env2_first_0:                 episode reward: -20.3500,                 loss: nan
env2_second_0:                 episode reward: 20.3500,                 loss: nan
env3_first_0:                 episode reward: -20.6000,                 loss: nan
env3_second_0:                 episode reward: 20.6000,                 loss: nan
env4_first_0:                 episode reward: -20.2500,                 loss: nan
env4_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 2300.55,                last time consumption/overall running time: 830.1792s / 55012.4720 s
env0_first_0:                 episode reward: -18.4000,                 loss: nan
env0_second_0:                 episode reward: 18.4000,                 loss: 0.0104
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
env2_first_0:                 episode reward: -17.6500,                 loss: nan
env2_second_0:                 episode reward: 17.6500,                 loss: nan
env3_first_0:                 episode reward: -17.9000,                 loss: nan
env3_second_0:                 episode reward: 17.9000,                 loss: nan
env4_first_0:                 episode reward: -19.7500,                 loss: nan
env4_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 2235.6,                last time consumption/overall running time: 803.7863s / 55816.2583 s
env0_first_0:                 episode reward: -18.4500,                 loss: nan
env0_second_0:                 episode reward: 18.4500,                 loss: 0.0102
env1_first_0:                 episode reward: -19.2000,                 loss: nan
env1_second_0:                 episode reward: 19.2000,                 loss: nan
env2_first_0:                 episode reward: -20.1000,                 loss: nan
env2_second_0:                 episode reward: 20.1000,                 loss: nan
env3_first_0:                 episode reward: -19.3000,                 loss: nan
env3_second_0:                 episode reward: 19.3000,                 loss: nan
env4_first_0:                 episode reward: -19.7500,                 loss: nan
env4_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 2303.95,                last time consumption/overall running time: 828.6519s / 56644.9102 s
env0_first_0:                 episode reward: -16.1000,                 loss: nan
env0_second_0:                 episode reward: 16.1000,                 loss: 0.0126
env1_first_0:                 episode reward: -16.5000,                 loss: nan
env1_second_0:                 episode reward: 16.5000,                 loss: nan
env2_first_0:                 episode reward: -16.5500,                 loss: nan
env2_second_0:                 episode reward: 16.5500,                 loss: nan
env3_first_0:                 episode reward: -19.4500,                 loss: nan
env3_second_0:                 episode reward: 19.4500,                 loss: nan
env4_first_0:                 episode reward: -17.5500,                 loss: nan
env4_second_0:                 episode reward: 17.5500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 2159.55,                last time consumption/overall running time: 781.9695s / 57426.8796 s
env0_first_0:                 episode reward: -19.7500,                 loss: nan
env0_second_0:                 episode reward: 19.7500,                 loss: 0.0132
env1_first_0:                 episode reward: -20.7000,                 loss: nan
env1_second_0:                 episode reward: 20.7000,                 loss: nan
env2_first_0:                 episode reward: -18.9000,                 loss: nan
env2_second_0:                 episode reward: 18.9000,                 loss: nan
env3_first_0:                 episode reward: -19.5000,                 loss: nan
env3_second_0:                 episode reward: 19.5000,                 loss: nan
env4_first_0:                 episode reward: -19.0000,                 loss: nan
env4_second_0:                 episode reward: 19.0000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 2306.4,                last time consumption/overall running time: 832.4217s / 58259.3014 s
env0_first_0:                 episode reward: -17.2500,                 loss: nan
env0_second_0:                 episode reward: 17.2500,                 loss: 0.0151
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
env2_first_0:                 episode reward: -18.3000,                 loss: nan
env2_second_0:                 episode reward: 18.3000,                 loss: nan
env3_first_0:                 episode reward: -17.8500,                 loss: nan
env3_second_0:                 episode reward: 17.8500,                 loss: nan
env4_first_0:                 episode reward: -18.9000,                 loss: nan
env4_second_0:                 episode reward: 18.9000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 2804.1,                last time consumption/overall running time: 1005.3606s / 59264.6620 s
env0_first_0:                 episode reward: -17.9000,                 loss: nan
env0_second_0:                 episode reward: 17.9000,                 loss: 0.0164
env1_first_0:                 episode reward: -16.3500,                 loss: nan
env1_second_0:                 episode reward: 16.3500,                 loss: nan
env2_first_0:                 episode reward: -16.2000,                 loss: nan
env2_second_0:                 episode reward: 16.2000,                 loss: nan
env3_first_0:                 episode reward: -19.7000,                 loss: nan
env3_second_0:                 episode reward: 19.7000,                 loss: nan
env4_first_0:                 episode reward: -18.8000,                 loss: nan
env4_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 2529.85,                last time consumption/overall running time: 888.3280s / 60152.9900 s
env0_first_0:                 episode reward: -12.4000,                 loss: nan
env0_second_0:                 episode reward: 12.4000,                 loss: 0.0182
env1_first_0:                 episode reward: -16.5500,                 loss: nan
env1_second_0:                 episode reward: 16.5500,                 loss: nan
env2_first_0:                 episode reward: -16.5500,                 loss: nan
env2_second_0:                 episode reward: 16.5500,                 loss: nan
env3_first_0:                 episode reward: -15.7000,                 loss: nan
env3_second_0:                 episode reward: 15.7000,                 loss: nan
env4_first_0:                 episode reward: -16.3000,                 loss: nan
env4_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 3240.1,                last time consumption/overall running time: 1134.7888s / 61287.7788 s
env0_first_0:                 episode reward: -17.2000,                 loss: nan
env0_second_0:                 episode reward: 17.2000,                 loss: 0.0166
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
env2_first_0:                 episode reward: -17.7500,                 loss: nan
env2_second_0:                 episode reward: 17.7500,                 loss: nan
env3_first_0:                 episode reward: -16.5500,                 loss: nan
env3_second_0:                 episode reward: 16.5500,                 loss: nan
env4_first_0:                 episode reward: -17.0000,                 loss: nan
env4_second_0:                 episode reward: 17.0000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 2352.25,                last time consumption/overall running time: 841.1186s / 62128.8974 s
env0_first_0:                 episode reward: -19.3500,                 loss: nan
env0_second_0:                 episode reward: 19.3500,                 loss: 0.0157
env1_first_0:                 episode reward: -19.3000,                 loss: nan
env1_second_0:                 episode reward: 19.3000,                 loss: nan
env2_first_0:                 episode reward: -17.6000,                 loss: nan
env2_second_0:                 episode reward: 17.6000,                 loss: nan
env3_first_0:                 episode reward: -17.9500,                 loss: nan
env3_second_0:                 episode reward: 17.9500,                 loss: nan
env4_first_0:                 episode reward: -17.8500,                 loss: nan
env4_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 2301.7,                last time consumption/overall running time: 814.8484s / 62943.7458 s
env0_first_0:                 episode reward: -20.5500,                 loss: nan
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0131
env1_first_0:                 episode reward: -19.4000,                 loss: nan
env1_second_0:                 episode reward: 19.4000,                 loss: nan
env2_first_0:                 episode reward: -17.9500,                 loss: nan
env2_second_0:                 episode reward: 17.9500,                 loss: nan
env3_first_0:                 episode reward: -20.9500,                 loss: nan
env3_second_0:                 episode reward: 20.9500,                 loss: nan
env4_first_0:                 episode reward: -20.1500,                 loss: nan
env4_second_0:                 episode reward: 20.1500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 2287.1,                last time consumption/overall running time: 807.7471s / 63751.4929 s
env0_first_0:                 episode reward: -18.0500,                 loss: nan
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0112
env1_first_0:                 episode reward: -18.7500,                 loss: nan
env1_second_0:                 episode reward: 18.7500,                 loss: nan
env2_first_0:                 episode reward: -18.4500,                 loss: nan
env2_second_0:                 episode reward: 18.4500,                 loss: nan
env3_first_0:                 episode reward: -19.1000,                 loss: nan
env3_second_0:                 episode reward: 19.1000,                 loss: nan
env4_first_0:                 episode reward: -18.7500,                 loss: nan
env4_second_0:                 episode reward: 18.7500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 2171.75,                last time consumption/overall running time: 756.6431s / 64508.1360 s
env0_first_0:                 episode reward: -20.1500,                 loss: nan
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0103
env1_first_0:                 episode reward: -18.4500,                 loss: nan
env1_second_0:                 episode reward: 18.4500,                 loss: nan
env2_first_0:                 episode reward: -20.3000,                 loss: nan
env2_second_0:                 episode reward: 20.3000,                 loss: nan
env3_first_0:                 episode reward: -20.8000,                 loss: nan
env3_second_0:                 episode reward: 20.8000,                 loss: nan
env4_first_0:                 episode reward: -19.0500,                 loss: nan
env4_second_0:                 episode reward: 19.0500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 2550.05,                last time consumption/overall running time: 883.4638s / 65391.5998 s
env0_first_0:                 episode reward: -16.6000,                 loss: nan
env0_second_0:                 episode reward: 16.6000,                 loss: 0.0102
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
env2_first_0:                 episode reward: -16.9500,                 loss: nan
env2_second_0:                 episode reward: 16.9500,                 loss: nan
env3_first_0:                 episode reward: -15.9000,                 loss: nan
env3_second_0:                 episode reward: 15.9000,                 loss: nan
env4_first_0:                 episode reward: -17.0000,                 loss: nan
env4_second_0:                 episode reward: 17.0000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 2370.35,                last time consumption/overall running time: 830.0864s / 66221.6862 s
env0_first_0:                 episode reward: -17.5000,                 loss: nan
env0_second_0:                 episode reward: 17.5000,                 loss: 0.0105
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
env2_first_0:                 episode reward: -17.3000,                 loss: nan
env2_second_0:                 episode reward: 17.3000,                 loss: nan
env3_first_0:                 episode reward: -15.9500,                 loss: nan
env3_second_0:                 episode reward: 15.9500,                 loss: nan
env4_first_0:                 episode reward: -17.2500,                 loss: nan
env4_second_0:                 episode reward: 17.2500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 2440.05,                last time consumption/overall running time: 846.9839s / 67068.6701 s
env0_first_0:                 episode reward: -16.9500,                 loss: nan
env0_second_0:                 episode reward: 16.9500,                 loss: 0.0106
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
env2_first_0:                 episode reward: -16.8000,                 loss: nan
env2_second_0:                 episode reward: 16.8000,                 loss: nan
env3_first_0:                 episode reward: -16.4000,                 loss: nan
env3_second_0:                 episode reward: 16.4000,                 loss: nan
env4_first_0:                 episode reward: -16.0000,                 loss: nan
env4_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 2394.3,                last time consumption/overall running time: 823.5081s / 67892.1782 s
env0_first_0:                 episode reward: -16.3500,                 loss: nan
env0_second_0:                 episode reward: 16.3500,                 loss: 0.0113
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
env2_first_0:                 episode reward: -17.7000,                 loss: nan
env2_second_0:                 episode reward: 17.7000,                 loss: nan
env3_first_0:                 episode reward: -17.2500,                 loss: nan
env3_second_0:                 episode reward: 17.2500,                 loss: nan
env4_first_0:                 episode reward: -17.8500,                 loss: nan
env4_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 2644.65,                last time consumption/overall running time: 914.3948s / 68806.5731 s
env0_first_0:                 episode reward: -18.9500,                 loss: nan
env0_second_0:                 episode reward: 18.9500,                 loss: 0.0112
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
env2_first_0:                 episode reward: -18.7000,                 loss: nan
env2_second_0:                 episode reward: 18.7000,                 loss: nan
env3_first_0:                 episode reward: -18.9000,                 loss: nan
env3_second_0:                 episode reward: 18.9000,                 loss: nan
env4_first_0:                 episode reward: -17.9500,                 loss: nan
env4_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 2795.95,                last time consumption/overall running time: 962.7095s / 69769.2825 s
env0_first_0:                 episode reward: -20.1000,                 loss: nan
env0_second_0:                 episode reward: 20.1000,                 loss: 0.0112
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
env2_first_0:                 episode reward: -21.2500,                 loss: nan
env2_second_0:                 episode reward: 21.2500,                 loss: nan
env3_first_0:                 episode reward: -22.4500,                 loss: nan
env3_second_0:                 episode reward: 22.4500,                 loss: nan
env4_first_0:                 episode reward: -22.5000,                 loss: nan
env4_second_0:                 episode reward: 22.5000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 2485.45,                last time consumption/overall running time: 854.0468s / 70623.3293 s
env0_first_0:                 episode reward: -20.2500,                 loss: nan
env0_second_0:                 episode reward: 20.2500,                 loss: 0.0117
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
env2_first_0:                 episode reward: -20.6000,                 loss: nan
env2_second_0:                 episode reward: 20.6000,                 loss: nan
env3_first_0:                 episode reward: -18.7500,                 loss: nan
env3_second_0:                 episode reward: 18.7500,                 loss: nan
env4_first_0:                 episode reward: -18.8500,                 loss: nan
env4_second_0:                 episode reward: 18.8500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 2573.2,                last time consumption/overall running time: 861.7808s / 71485.1102 s
env0_first_0:                 episode reward: -19.8000,                 loss: nan
env0_second_0:                 episode reward: 19.8000,                 loss: 0.0121
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
env2_first_0:                 episode reward: -20.5500,                 loss: nan
env2_second_0:                 episode reward: 20.5500,                 loss: nan
env3_first_0:                 episode reward: -19.1500,                 loss: nan
env3_second_0:                 episode reward: 19.1500,                 loss: nan
env4_first_0:                 episode reward: -19.9500,                 loss: nan
env4_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 2643.8,                last time consumption/overall running time: 891.5435s / 72376.6537 s
env0_first_0:                 episode reward: -21.8500,                 loss: nan
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0118
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
env2_first_0:                 episode reward: -21.6500,                 loss: nan
env2_second_0:                 episode reward: 21.6500,                 loss: nan
env3_first_0:                 episode reward: -19.1000,                 loss: nan
env3_second_0:                 episode reward: 19.1000,                 loss: nan
env4_first_0:                 episode reward: -20.6500,                 loss: nan
env4_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 2443.45,                last time consumption/overall running time: 825.6404s / 73202.2941 s
env0_first_0:                 episode reward: -21.0500,                 loss: nan
env0_second_0:                 episode reward: 21.0500,                 loss: 0.0112
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
env2_first_0:                 episode reward: -20.4000,                 loss: nan
env2_second_0:                 episode reward: 20.4000,                 loss: nan
env3_first_0:                 episode reward: -20.2000,                 loss: nan
env3_second_0:                 episode reward: 20.2000,                 loss: nan
env4_first_0:                 episode reward: -22.2500,                 loss: nan
env4_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 2388.5,                last time consumption/overall running time: 810.8913s / 74013.1854 s
env0_first_0:                 episode reward: -19.2500,                 loss: nan
env0_second_0:                 episode reward: 19.2500,                 loss: 0.0111
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
env2_first_0:                 episode reward: -20.6000,                 loss: nan
env2_second_0:                 episode reward: 20.6000,                 loss: nan
env3_first_0:                 episode reward: -20.5000,                 loss: nan
env3_second_0:                 episode reward: 20.5000,                 loss: nan
env4_first_0:                 episode reward: -19.9500,                 loss: nan
env4_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 2404.8,                last time consumption/overall running time: 812.3035s / 74825.4889 s
env0_first_0:                 episode reward: -22.1500,                 loss: nan
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0109
env1_first_0:                 episode reward: -23.4500,                 loss: nan
env1_second_0:                 episode reward: 23.4500,                 loss: nan
env2_first_0:                 episode reward: -22.1000,                 loss: nan
env2_second_0:                 episode reward: 22.1000,                 loss: nan
env3_first_0:                 episode reward: -22.7000,                 loss: nan
env3_second_0:                 episode reward: 22.7000,                 loss: nan
env4_first_0:                 episode reward: -22.8000,                 loss: nan
env4_second_0:                 episode reward: 22.8000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 2433.95,                last time consumption/overall running time: 804.5018s / 75629.9906 s
env0_first_0:                 episode reward: -26.7000,                 loss: 0.0174
env0_second_0:                 episode reward: 26.7000,                 loss: 0.0113
env1_first_0:                 episode reward: -26.6500,                 loss: nan
env1_second_0:                 episode reward: 26.6500,                 loss: nan
env2_first_0:                 episode reward: -25.9000,                 loss: nan
env2_second_0:                 episode reward: 25.9000,                 loss: nan
env3_first_0:                 episode reward: -24.5000,                 loss: nan
env3_second_0:                 episode reward: 24.5000,                 loss: nan
env4_first_0:                 episode reward: -23.7000,                 loss: nan
env4_second_0:                 episode reward: 23.7000,                 loss: nan
Score delta: 50.2, update the opponent.
Episode: 1481/10000 (14.8100%),                 avg. length: 4380.3,                last time consumption/overall running time: 1446.1212s / 77076.1118 s
env0_first_0:                 episode reward: -23.7500,                 loss: 0.0134
env0_second_0:                 episode reward: 23.7500,                 loss: nan
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
env2_first_0:                 episode reward: -20.6500,                 loss: nan
env2_second_0:                 episode reward: 20.6500,                 loss: nan
env3_first_0:                 episode reward: -23.2000,                 loss: nan
env3_second_0:                 episode reward: 23.2000,                 loss: nan
env4_first_0:                 episode reward: -26.8500,                 loss: nan
env4_second_0:                 episode reward: 26.8500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 7279.15,                last time consumption/overall running time: 2496.1794s / 79572.2912 s
env0_first_0:                 episode reward: 13.2000,                 loss: 0.0133
env0_second_0:                 episode reward: -13.2000,                 loss: nan
env1_first_0:                 episode reward: 19.7000,                 loss: nan
env1_second_0:                 episode reward: -19.7000,                 loss: nan
env2_first_0:                 episode reward: 13.2500,                 loss: nan
env2_second_0:                 episode reward: -13.2500,                 loss: nan
env3_first_0:                 episode reward: 12.4000,                 loss: nan
env3_second_0:                 episode reward: -12.4000,                 loss: nan
env4_first_0:                 episode reward: 12.4500,                 loss: nan
env4_second_0:                 episode reward: -12.4500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 6103.05,                last time consumption/overall running time: 2086.5468s / 81658.8380 s
env0_first_0:                 episode reward: 54.3000,                 loss: 0.0127
env0_second_0:                 episode reward: -54.3000,                 loss: 0.0182
env1_first_0:                 episode reward: 48.1500,                 loss: nan
env1_second_0:                 episode reward: -48.1500,                 loss: nan
env2_first_0:                 episode reward: 53.1500,                 loss: nan
env2_second_0:                 episode reward: -53.1500,                 loss: nan
env3_first_0:                 episode reward: 58.1500,                 loss: nan
env3_second_0:                 episode reward: -58.1500,                 loss: nan
env4_first_0:                 episode reward: 52.6000,                 loss: nan
env4_second_0:                 episode reward: -52.6000,                 loss: nan
Score delta: 61.4, update the opponent.
Episode: 1541/10000 (15.4100%),                 avg. length: 5860.1,                last time consumption/overall running time: 2014.0549s / 83672.8929 s
env0_first_0:                 episode reward: -3.1000,                 loss: nan
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0122
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
env2_first_0:                 episode reward: 8.8000,                 loss: nan
env2_second_0:                 episode reward: -8.8000,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 3022.75,                last time consumption/overall running time: 1056.2798s / 84729.1728 s
env0_first_0:                 episode reward: -15.7000,                 loss: nan
env0_second_0:                 episode reward: 15.7000,                 loss: 0.0110
env1_first_0:                 episode reward: -17.0000,                 loss: nan
env1_second_0:                 episode reward: 17.0000,                 loss: nan
env2_first_0:                 episode reward: -15.5500,                 loss: nan
env2_second_0:                 episode reward: 15.5500,                 loss: nan
env3_first_0:                 episode reward: -14.9000,                 loss: nan
env3_second_0:                 episode reward: 14.9000,                 loss: nan
env4_first_0:                 episode reward: -15.6500,                 loss: nan
env4_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 2592.75,                last time consumption/overall running time: 901.6382s / 85630.8109 s
env0_first_0:                 episode reward: -17.2000,                 loss: nan
env0_second_0:                 episode reward: 17.2000,                 loss: 0.0102
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
env2_first_0:                 episode reward: -17.7000,                 loss: nan
env2_second_0:                 episode reward: 17.7000,                 loss: nan
env3_first_0:                 episode reward: -17.3500,                 loss: nan
env3_second_0:                 episode reward: 17.3500,                 loss: nan
env4_first_0:                 episode reward: -17.6000,                 loss: nan
env4_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 2412.65,                last time consumption/overall running time: 865.4468s / 86496.2577 s
env0_first_0:                 episode reward: -18.3000,                 loss: nan
env0_second_0:                 episode reward: 18.3000,                 loss: 0.0100
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
env2_first_0:                 episode reward: -18.4500,                 loss: nan
env2_second_0:                 episode reward: 18.4500,                 loss: nan
env3_first_0:                 episode reward: -17.4500,                 loss: nan
env3_second_0:                 episode reward: 17.4500,                 loss: nan
env4_first_0:                 episode reward: -18.7000,                 loss: nan
env4_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 2226.3,                last time consumption/overall running time: 789.0461s / 87285.3038 s
env0_first_0:                 episode reward: -18.6000,                 loss: nan
env0_second_0:                 episode reward: 18.6000,                 loss: 0.0098
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
env2_first_0:                 episode reward: -19.5000,                 loss: nan
env2_second_0:                 episode reward: 19.5000,                 loss: nan
env3_first_0:                 episode reward: -19.1500,                 loss: nan
env3_second_0:                 episode reward: 19.1500,                 loss: nan
env4_first_0:                 episode reward: -19.8500,                 loss: nan
env4_second_0:                 episode reward: 19.8500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 2182.5,                last time consumption/overall running time: 782.7415s / 88068.0453 s
env0_first_0:                 episode reward: -17.7500,                 loss: nan
env0_second_0:                 episode reward: 17.7500,                 loss: 0.0102
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
env2_first_0:                 episode reward: -16.7500,                 loss: nan
env2_second_0:                 episode reward: 16.7500,                 loss: nan
env3_first_0:                 episode reward: -16.1500,                 loss: nan
env3_second_0:                 episode reward: 16.1500,                 loss: nan
env4_first_0:                 episode reward: -15.7500,                 loss: nan
env4_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 2599.25,                last time consumption/overall running time: 921.0248s / 88989.0701 s
env0_first_0:                 episode reward: -19.6000,                 loss: nan
env0_second_0:                 episode reward: 19.6000,                 loss: 0.0112
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
env2_first_0:                 episode reward: -19.4500,                 loss: nan
env2_second_0:                 episode reward: 19.4500,                 loss: nan
env3_first_0:                 episode reward: -19.4000,                 loss: nan
env3_second_0:                 episode reward: 19.4000,                 loss: nan
env4_first_0:                 episode reward: -19.1500,                 loss: nan
env4_second_0:                 episode reward: 19.1500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 2839.75,                last time consumption/overall running time: 1003.7253s / 89992.7954 s
env0_first_0:                 episode reward: -35.3000,                 loss: 0.0194
env0_second_0:                 episode reward: 35.3000,                 loss: 0.0110
env1_first_0:                 episode reward: -34.0500,                 loss: nan
env1_second_0:                 episode reward: 34.0500,                 loss: nan
env2_first_0:                 episode reward: -31.9000,                 loss: nan
env2_second_0:                 episode reward: 31.9000,                 loss: nan
env3_first_0:                 episode reward: -34.1000,                 loss: nan
env3_second_0:                 episode reward: 34.1000,                 loss: nan
env4_first_0:                 episode reward: -33.9500,                 loss: nan
env4_second_0:                 episode reward: 33.9500,                 loss: nan
Score delta: 52.6, update the opponent.
Episode: 1701/10000 (17.0100%),                 avg. length: 3695.75,                last time consumption/overall running time: 1312.5085s / 91305.3039 s
env0_first_0:                 episode reward: -15.8000,                 loss: 0.0149
env0_second_0:                 episode reward: 15.8000,                 loss: nan
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
env2_first_0:                 episode reward: -12.9500,                 loss: nan
env2_second_0:                 episode reward: 12.9500,                 loss: nan
env3_first_0:                 episode reward: -11.2000,                 loss: nan
env3_second_0:                 episode reward: 11.2000,                 loss: nan
env4_first_0:                 episode reward: -12.2500,                 loss: nan
env4_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 2621.05,                last time consumption/overall running time: 907.8044s / 92213.1083 s
env0_first_0:                 episode reward: 8.1500,                 loss: 0.0126
env0_second_0:                 episode reward: -8.1500,                 loss: nan
env1_first_0:                 episode reward: 8.8000,                 loss: nan
env1_second_0:                 episode reward: -8.8000,                 loss: nan
env2_first_0:                 episode reward: 6.8500,                 loss: nan
env2_second_0:                 episode reward: -6.8500,                 loss: nan
env3_first_0:                 episode reward: 6.6500,                 loss: nan
env3_second_0:                 episode reward: -6.6500,                 loss: nan
env4_first_0:                 episode reward: 8.7000,                 loss: nan
env4_second_0:                 episode reward: -8.7000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1905.2,                last time consumption/overall running time: 657.5464s / 92870.6547 s
env0_first_0:                 episode reward: 17.5000,                 loss: 0.0115
env0_second_0:                 episode reward: -17.5000,                 loss: nan
env1_first_0:                 episode reward: 18.6500,                 loss: nan
env1_second_0:                 episode reward: -18.6500,                 loss: nan
env2_first_0:                 episode reward: 18.4000,                 loss: nan
env2_second_0:                 episode reward: -18.4000,                 loss: nan
env3_first_0:                 episode reward: 18.0000,                 loss: nan
env3_second_0:                 episode reward: -18.0000,                 loss: nan
env4_first_0:                 episode reward: 18.1500,                 loss: nan
env4_second_0:                 episode reward: -18.1500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1732.4,                last time consumption/overall running time: 610.9117s / 93481.5664 s
env0_first_0:                 episode reward: 20.2000,                 loss: 0.0103
env0_second_0:                 episode reward: -20.2000,                 loss: nan
env1_first_0:                 episode reward: 19.9000,                 loss: nan
env1_second_0:                 episode reward: -19.9000,                 loss: nan
env2_first_0:                 episode reward: 20.3000,                 loss: nan
env2_second_0:                 episode reward: -20.3000,                 loss: nan
env3_first_0:                 episode reward: 20.4500,                 loss: nan
env3_second_0:                 episode reward: -20.4500,                 loss: nan
env4_first_0:                 episode reward: 20.3000,                 loss: nan
env4_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 2094.05,                last time consumption/overall running time: 740.1067s / 94221.6731 s
env0_first_0:                 episode reward: 10.4000,                 loss: 0.0099
env0_second_0:                 episode reward: -10.4000,                 loss: nan
env1_first_0:                 episode reward: 11.6500,                 loss: nan
env1_second_0:                 episode reward: -11.6500,                 loss: nan
env2_first_0:                 episode reward: 10.6000,                 loss: nan
env2_second_0:                 episode reward: -10.6000,                 loss: nan
env3_first_0:                 episode reward: 12.5000,                 loss: nan
env3_second_0:                 episode reward: -12.5000,                 loss: nan
env4_first_0:                 episode reward: 13.8500,                 loss: nan
env4_second_0:                 episode reward: -13.8500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1677.8,                last time consumption/overall running time: 590.7319s / 94812.4050 s
env0_first_0:                 episode reward: 19.5000,                 loss: 0.0101
env0_second_0:                 episode reward: -19.5000,                 loss: nan
env1_first_0:                 episode reward: 19.7000,                 loss: nan
env1_second_0:                 episode reward: -19.7000,                 loss: nan
env2_first_0:                 episode reward: 20.4000,                 loss: nan
env2_second_0:                 episode reward: -20.4000,                 loss: nan
env3_first_0:                 episode reward: 19.5000,                 loss: nan
env3_second_0:                 episode reward: -19.5000,                 loss: nan
env4_first_0:                 episode reward: 20.0000,                 loss: nan
env4_second_0:                 episode reward: -20.0000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1839.6,                last time consumption/overall running time: 637.0605s / 95449.4655 s
env0_first_0:                 episode reward: 18.3000,                 loss: 0.0102
env0_second_0:                 episode reward: -18.3000,                 loss: nan
env1_first_0:                 episode reward: 18.0000,                 loss: nan
env1_second_0:                 episode reward: -18.0000,                 loss: nan
env2_first_0:                 episode reward: 17.8500,                 loss: nan
env2_second_0:                 episode reward: -17.8500,                 loss: nan
env3_first_0:                 episode reward: 18.0500,                 loss: nan
env3_second_0:                 episode reward: -18.0500,                 loss: nan
env4_first_0:                 episode reward: 18.2500,                 loss: nan
env4_second_0:                 episode reward: -18.2500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1709.05,                last time consumption/overall running time: 617.5989s / 96067.0643 s
env0_first_0:                 episode reward: 19.9000,                 loss: 0.0094
env0_second_0:                 episode reward: -19.9000,                 loss: nan
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
env2_first_0:                 episode reward: 20.1500,                 loss: nan
env2_second_0:                 episode reward: -20.1500,                 loss: nan
env3_first_0:                 episode reward: 20.9000,                 loss: nan
env3_second_0:                 episode reward: -20.9000,                 loss: nan
env4_first_0:                 episode reward: 21.6500,                 loss: nan
env4_second_0:                 episode reward: -21.6500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1798.85,                last time consumption/overall running time: 675.1170s / 96742.1813 s
env0_first_0:                 episode reward: 17.2500,                 loss: 0.0094
env0_second_0:                 episode reward: -17.2500,                 loss: nan
env1_first_0:                 episode reward: 17.8500,                 loss: nan
env1_second_0:                 episode reward: -17.8500,                 loss: nan
env2_first_0:                 episode reward: 17.5500,                 loss: nan
env2_second_0:                 episode reward: -17.5500,                 loss: nan
env3_first_0:                 episode reward: 18.0500,                 loss: nan
env3_second_0:                 episode reward: -18.0500,                 loss: nan
env4_first_0:                 episode reward: 17.5000,                 loss: nan
env4_second_0:                 episode reward: -17.5000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1750.3,                last time consumption/overall running time: 683.4229s / 97425.6042 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.0099
env0_second_0:                 episode reward: -20.5000,                 loss: nan
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
env2_first_0:                 episode reward: 20.5000,                 loss: nan
env2_second_0:                 episode reward: -20.5000,                 loss: nan
env3_first_0:                 episode reward: 20.3500,                 loss: nan
env3_second_0:                 episode reward: -20.3500,                 loss: nan
env4_first_0:                 episode reward: 20.1000,                 loss: nan
env4_second_0:                 episode reward: -20.1000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 2634.0,                last time consumption/overall running time: 1020.2832s / 98445.8874 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0104
env0_second_0:                 episode reward: 2.8500,                 loss: nan
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
env2_first_0:                 episode reward: -5.8000,                 loss: nan
env2_second_0:                 episode reward: 5.8000,                 loss: nan
env3_first_0:                 episode reward: -4.8500,                 loss: nan
env3_second_0:                 episode reward: 4.8500,                 loss: nan
env4_first_0:                 episode reward: -6.4500,                 loss: nan
env4_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1623.0,                last time consumption/overall running time: 631.1023s / 99076.9898 s
env0_first_0:                 episode reward: 22.3000,                 loss: 0.0099
env0_second_0:                 episode reward: -22.3000,                 loss: nan
env1_first_0:                 episode reward: 22.0500,                 loss: nan
env1_second_0:                 episode reward: -22.0500,                 loss: nan
env2_first_0:                 episode reward: 22.1500,                 loss: nan
env2_second_0:                 episode reward: -22.1500,                 loss: nan
env3_first_0:                 episode reward: 22.2500,                 loss: nan
env3_second_0:                 episode reward: -22.2500,                 loss: nan
env4_first_0:                 episode reward: 22.1500,                 loss: nan
env4_second_0:                 episode reward: -22.1500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1592.2,                last time consumption/overall running time: 617.1395s / 99694.1293 s
env0_first_0:                 episode reward: 22.2500,                 loss: 0.0099
env0_second_0:                 episode reward: -22.2500,                 loss: nan
env1_first_0:                 episode reward: 22.3500,                 loss: nan
env1_second_0:                 episode reward: -22.3500,                 loss: nan
env2_first_0:                 episode reward: 22.2000,                 loss: nan
env2_second_0:                 episode reward: -22.2000,                 loss: nan
env3_first_0:                 episode reward: 21.7500,                 loss: nan
env3_second_0:                 episode reward: -21.7500,                 loss: nan
env4_first_0:                 episode reward: 22.1000,                 loss: nan
env4_second_0:                 episode reward: -22.1000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 2377.35,                last time consumption/overall running time: 921.4812s / 100615.6105 s
env0_first_0:                 episode reward: 8.3000,                 loss: 0.0106
env0_second_0:                 episode reward: -8.3000,                 loss: nan
env1_first_0:                 episode reward: 7.4000,                 loss: nan
env1_second_0:                 episode reward: -7.4000,                 loss: nan
env2_first_0:                 episode reward: 7.2000,                 loss: nan
env2_second_0:                 episode reward: -7.2000,                 loss: nan
env3_first_0:                 episode reward: 7.1500,                 loss: nan
env3_second_0:                 episode reward: -7.1500,                 loss: nan
env4_first_0:                 episode reward: 8.6000,                 loss: nan
env4_second_0:                 episode reward: -8.6000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2066.1,                last time consumption/overall running time: 807.4415s / 101423.0519 s
env0_first_0:                 episode reward: 14.8000,                 loss: 0.0102
env0_second_0:                 episode reward: -14.8000,                 loss: nan
env1_first_0:                 episode reward: 14.2500,                 loss: nan
env1_second_0:                 episode reward: -14.2500,                 loss: nan
env2_first_0:                 episode reward: 12.9500,                 loss: nan
env2_second_0:                 episode reward: -12.9500,                 loss: nan
env3_first_0:                 episode reward: 13.9500,                 loss: nan
env3_second_0:                 episode reward: -13.9500,                 loss: nan
env4_first_0:                 episode reward: 13.9000,                 loss: nan
env4_second_0:                 episode reward: -13.9000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1764.1,                last time consumption/overall running time: 692.3498s / 102115.4018 s
env0_first_0:                 episode reward: 19.7000,                 loss: 0.0107
env0_second_0:                 episode reward: -19.7000,                 loss: nan
env1_first_0:                 episode reward: 18.3000,                 loss: nan
env1_second_0:                 episode reward: -18.3000,                 loss: nan
env2_first_0:                 episode reward: 18.8000,                 loss: nan
env2_second_0:                 episode reward: -18.8000,                 loss: nan
env3_first_0:                 episode reward: 18.5500,                 loss: nan
env3_second_0:                 episode reward: -18.5500,                 loss: nan
env4_first_0:                 episode reward: 20.0500,                 loss: nan
env4_second_0:                 episode reward: -20.0500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1757.45,                last time consumption/overall running time: 675.1351s / 102790.5369 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0098
env0_second_0:                 episode reward: -20.7000,                 loss: nan
env1_first_0:                 episode reward: 20.2500,                 loss: nan
env1_second_0:                 episode reward: -20.2500,                 loss: nan
env2_first_0:                 episode reward: 21.5000,                 loss: nan
env2_second_0:                 episode reward: -21.5000,                 loss: nan
env3_first_0:                 episode reward: 21.3500,                 loss: nan
env3_second_0:                 episode reward: -21.3500,                 loss: nan
env4_first_0:                 episode reward: 20.0000,                 loss: nan
env4_second_0:                 episode reward: -20.0000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 2193.35,                last time consumption/overall running time: 823.7696s / 103614.3065 s
env0_first_0:                 episode reward: 6.8500,                 loss: 0.0100
env0_second_0:                 episode reward: -6.8500,                 loss: nan
env1_first_0:                 episode reward: 6.9000,                 loss: nan
env1_second_0:                 episode reward: -6.9000,                 loss: nan
env2_first_0:                 episode reward: 9.0000,                 loss: nan
env2_second_0:                 episode reward: -9.0000,                 loss: nan
env3_first_0:                 episode reward: 7.8000,                 loss: nan
env3_second_0:                 episode reward: -7.8000,                 loss: nan
env4_first_0:                 episode reward: 7.1500,                 loss: nan
env4_second_0:                 episode reward: -7.1500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1730.55,                last time consumption/overall running time: 649.5440s / 104263.8504 s
env0_first_0:                 episode reward: 19.3000,                 loss: 0.0097
env0_second_0:                 episode reward: -19.3000,                 loss: nan
env1_first_0:                 episode reward: 19.5000,                 loss: nan
env1_second_0:                 episode reward: -19.5000,                 loss: nan
env2_first_0:                 episode reward: 20.1500,                 loss: nan
env2_second_0:                 episode reward: -20.1500,                 loss: nan
env3_first_0:                 episode reward: 18.2000,                 loss: nan
env3_second_0:                 episode reward: -18.2000,                 loss: nan
env4_first_0:                 episode reward: 18.6000,                 loss: nan
env4_second_0:                 episode reward: -18.6000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 2115.55,                last time consumption/overall running time: 800.6695s / 105064.5199 s
env0_first_0:                 episode reward: 12.0500,                 loss: 0.0099
env0_second_0:                 episode reward: -12.0500,                 loss: nan
env1_first_0:                 episode reward: 13.3000,                 loss: nan
env1_second_0:                 episode reward: -13.3000,                 loss: nan
env2_first_0:                 episode reward: 9.8500,                 loss: nan
env2_second_0:                 episode reward: -9.8500,                 loss: nan
env3_first_0:                 episode reward: 9.7500,                 loss: nan
env3_second_0:                 episode reward: -9.7500,                 loss: nan
env4_first_0:                 episode reward: 12.3000,                 loss: nan
env4_second_0:                 episode reward: -12.3000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1634.15,                last time consumption/overall running time: 618.4415s / 105682.9614 s
env0_first_0:                 episode reward: 21.9500,                 loss: 0.0109
env0_second_0:                 episode reward: -21.9500,                 loss: nan
env1_first_0:                 episode reward: 21.6000,                 loss: nan
env1_second_0:                 episode reward: -21.6000,                 loss: nan
env2_first_0:                 episode reward: 22.0000,                 loss: nan
env2_second_0:                 episode reward: -22.0000,                 loss: nan
env3_first_0:                 episode reward: 21.3500,                 loss: nan
env3_second_0:                 episode reward: -21.3500,                 loss: nan
env4_first_0:                 episode reward: 22.3500,                 loss: nan
env4_second_0:                 episode reward: -22.3500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1671.55,                last time consumption/overall running time: 625.8329s / 106308.7943 s
env0_first_0:                 episode reward: 21.6500,                 loss: 0.0107
env0_second_0:                 episode reward: -21.6500,                 loss: nan
env1_first_0:                 episode reward: 21.9500,                 loss: nan
env1_second_0:                 episode reward: -21.9500,                 loss: nan
env2_first_0:                 episode reward: 21.1500,                 loss: nan
env2_second_0:                 episode reward: -21.1500,                 loss: nan
env3_first_0:                 episode reward: 21.8000,                 loss: nan
env3_second_0:                 episode reward: -21.8000,                 loss: nan
env4_first_0:                 episode reward: 21.0500,                 loss: nan
env4_second_0:                 episode reward: -21.0500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 1641.6,                last time consumption/overall running time: 620.2279s / 106929.0222 s
env0_first_0:                 episode reward: 21.6000,                 loss: 0.0094
env0_second_0:                 episode reward: -21.6000,                 loss: nan
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
env2_first_0:                 episode reward: 21.0500,                 loss: nan
env2_second_0:                 episode reward: -21.0500,                 loss: nan
env3_first_0:                 episode reward: 21.7000,                 loss: nan
env3_second_0:                 episode reward: -21.7000,                 loss: nan
env4_first_0:                 episode reward: 20.8000,                 loss: nan
env4_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1622.95,                last time consumption/overall running time: 611.1537s / 107540.1759 s
env0_first_0:                 episode reward: 22.0500,                 loss: 0.0088
env0_second_0:                 episode reward: -22.0500,                 loss: nan
env1_first_0:                 episode reward: 21.9500,                 loss: nan
env1_second_0:                 episode reward: -21.9500,                 loss: nan
env2_first_0:                 episode reward: 21.4500,                 loss: nan
env2_second_0:                 episode reward: -21.4500,                 loss: nan
env3_first_0:                 episode reward: 22.0000,                 loss: nan
env3_second_0:                 episode reward: -22.0000,                 loss: nan
env4_first_0:                 episode reward: 22.2500,                 loss: nan
env4_second_0:                 episode reward: -22.2500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1564.35,                last time consumption/overall running time: 591.6148s / 108131.7907 s
env0_first_0:                 episode reward: 22.3500,                 loss: 0.0087
env0_second_0:                 episode reward: -22.3500,                 loss: nan
env1_first_0:                 episode reward: 21.7000,                 loss: nan
env1_second_0:                 episode reward: -21.7000,                 loss: nan
env2_first_0:                 episode reward: 21.9500,                 loss: nan
env2_second_0:                 episode reward: -21.9500,                 loss: nan
env3_first_0:                 episode reward: 21.2000,                 loss: nan
env3_second_0:                 episode reward: -21.2000,                 loss: nan
env4_first_0:                 episode reward: 21.5000,                 loss: nan
env4_second_0:                 episode reward: -21.5000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1848.3,                last time consumption/overall running time: 695.9111s / 108827.7018 s
env0_first_0:                 episode reward: 15.2000,                 loss: 0.0092
env0_second_0:                 episode reward: -15.2000,                 loss: nan
env1_first_0:                 episode reward: 14.9000,                 loss: nan
env1_second_0:                 episode reward: -14.9000,                 loss: nan
env2_first_0:                 episode reward: 15.0500,                 loss: nan
env2_second_0:                 episode reward: -15.0500,                 loss: nan
env3_first_0:                 episode reward: 14.7500,                 loss: nan
env3_second_0:                 episode reward: -14.7500,                 loss: nan
env4_first_0:                 episode reward: 16.1500,                 loss: nan
env4_second_0:                 episode reward: -16.1500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 3543.8,                last time consumption/overall running time: 1329.8143s / 110157.5162 s
env0_first_0:                 episode reward: -21.1500,                 loss: 0.0101
env0_second_0:                 episode reward: 21.1500,                 loss: nan
env1_first_0:                 episode reward: -26.3500,                 loss: nan
env1_second_0:                 episode reward: 26.3500,                 loss: nan
env2_first_0:                 episode reward: -22.4000,                 loss: nan
env2_second_0:                 episode reward: 22.4000,                 loss: nan
env3_first_0:                 episode reward: -23.4500,                 loss: nan
env3_second_0:                 episode reward: 23.4500,                 loss: nan
env4_first_0:                 episode reward: -24.0500,                 loss: nan
env4_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 2045.7,                last time consumption/overall running time: 770.3435s / 110927.8597 s
env0_first_0:                 episode reward: 15.8000,                 loss: 0.0132
env0_second_0:                 episode reward: -15.8000,                 loss: nan
env1_first_0:                 episode reward: 14.5500,                 loss: nan
env1_second_0:                 episode reward: -14.5500,                 loss: nan
env2_first_0:                 episode reward: 15.9500,                 loss: nan
env2_second_0:                 episode reward: -15.9500,                 loss: nan
env3_first_0:                 episode reward: 16.4000,                 loss: nan
env3_second_0:                 episode reward: -16.4000,                 loss: nan
env4_first_0:                 episode reward: 16.7500,                 loss: nan
env4_second_0:                 episode reward: -16.7500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 1566.45,                last time consumption/overall running time: 596.1996s / 111524.0593 s
env0_first_0:                 episode reward: 21.9000,                 loss: 0.0149
env0_second_0:                 episode reward: -21.9000,                 loss: nan
env1_first_0:                 episode reward: 21.7000,                 loss: nan
env1_second_0:                 episode reward: -21.7000,                 loss: nan
env2_first_0:                 episode reward: 21.4500,                 loss: nan
env2_second_0:                 episode reward: -21.4500,                 loss: nan
env3_first_0:                 episode reward: 21.6000,                 loss: nan
env3_second_0:                 episode reward: -21.6000,                 loss: nan
env4_first_0:                 episode reward: 22.2000,                 loss: nan
env4_second_0:                 episode reward: -22.2000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 2580.95,                last time consumption/overall running time: 965.8971s / 112489.9564 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0126
env0_second_0:                 episode reward: 5.7000,                 loss: nan
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
env3_first_0:                 episode reward: -3.8500,                 loss: nan
env3_second_0:                 episode reward: 3.8500,                 loss: nan
env4_first_0:                 episode reward: -4.7500,                 loss: nan
env4_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 2090.65,                last time consumption/overall running time: 781.8738s / 113271.8302 s
env0_first_0:                 episode reward: 10.7000,                 loss: 0.0117
env0_second_0:                 episode reward: -10.7000,                 loss: nan
env1_first_0:                 episode reward: 11.9000,                 loss: nan
env1_second_0:                 episode reward: -11.9000,                 loss: nan
env2_first_0:                 episode reward: 11.3000,                 loss: nan
env2_second_0:                 episode reward: -11.3000,                 loss: nan
env3_first_0:                 episode reward: 10.4000,                 loss: nan
env3_second_0:                 episode reward: -10.4000,                 loss: nan
env4_first_0:                 episode reward: 10.3500,                 loss: nan
env4_second_0:                 episode reward: -10.3500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 2314.75,                last time consumption/overall running time: 859.8955s / 114131.7257 s
env0_first_0:                 episode reward: 7.3000,                 loss: 0.0115
env0_second_0:                 episode reward: -7.3000,                 loss: nan
env1_first_0:                 episode reward: 6.8500,                 loss: nan
env1_second_0:                 episode reward: -6.8500,                 loss: nan
env2_first_0:                 episode reward: 5.0500,                 loss: nan
env2_second_0:                 episode reward: -5.0500,                 loss: nan
env3_first_0:                 episode reward: 3.9500,                 loss: nan
env3_second_0:                 episode reward: -3.9500,                 loss: nan
env4_first_0:                 episode reward: 5.2500,                 loss: nan
env4_second_0:                 episode reward: -5.2500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1545.25,                last time consumption/overall running time: 584.6918s / 114716.4174 s
env0_first_0:                 episode reward: 22.8500,                 loss: 0.0113
env0_second_0:                 episode reward: -22.8500,                 loss: nan
env1_first_0:                 episode reward: 21.5500,                 loss: nan
env1_second_0:                 episode reward: -21.5500,                 loss: nan
env2_first_0:                 episode reward: 21.5500,                 loss: nan
env2_second_0:                 episode reward: -21.5500,                 loss: nan
env3_first_0:                 episode reward: 21.3500,                 loss: nan
env3_second_0:                 episode reward: -21.3500,                 loss: nan
env4_first_0:                 episode reward: 21.5500,                 loss: nan
env4_second_0:                 episode reward: -21.5500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1593.45,                last time consumption/overall running time: 595.9232s / 115312.3406 s
env0_first_0:                 episode reward: 22.1500,                 loss: 0.0109
env0_second_0:                 episode reward: -22.1500,                 loss: nan
env1_first_0:                 episode reward: 21.4500,                 loss: nan
env1_second_0:                 episode reward: -21.4500,                 loss: nan
env2_first_0:                 episode reward: 21.9500,                 loss: nan
env2_second_0:                 episode reward: -21.9500,                 loss: nan
env3_first_0:                 episode reward: 22.1500,                 loss: nan
env3_second_0:                 episode reward: -22.1500,                 loss: nan
env4_first_0:                 episode reward: 21.8000,                 loss: nan
env4_second_0:                 episode reward: -21.8000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1597.3,                last time consumption/overall running time: 598.8790s / 115911.2196 s
env0_first_0:                 episode reward: 20.4000,                 loss: 0.0116
env0_second_0:                 episode reward: -20.4000,                 loss: nan
env1_first_0:                 episode reward: 21.8000,                 loss: nan
env1_second_0:                 episode reward: -21.8000,                 loss: nan
env2_first_0:                 episode reward: 20.7500,                 loss: nan
env2_second_0:                 episode reward: -20.7500,                 loss: nan
env3_first_0:                 episode reward: 21.0500,                 loss: nan
env3_second_0:                 episode reward: -21.0500,                 loss: nan
env4_first_0:                 episode reward: 21.0500,                 loss: nan
env4_second_0:                 episode reward: -21.0500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 1617.3,                last time consumption/overall running time: 604.6352s / 116515.8548 s
env0_first_0:                 episode reward: 19.9000,                 loss: 0.0108
env0_second_0:                 episode reward: -19.9000,                 loss: nan
env1_first_0:                 episode reward: 19.3500,                 loss: nan
env1_second_0:                 episode reward: -19.3500,                 loss: nan
env2_first_0:                 episode reward: 20.3000,                 loss: nan
env2_second_0:                 episode reward: -20.3000,                 loss: nan
env3_first_0:                 episode reward: 19.7500,                 loss: nan
env3_second_0:                 episode reward: -19.7500,                 loss: nan
env4_first_0:                 episode reward: 21.7000,                 loss: nan
env4_second_0:                 episode reward: -21.7000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1616.0,                last time consumption/overall running time: 605.6425s / 117121.4973 s
env0_first_0:                 episode reward: 21.2000,                 loss: 0.0108
env0_second_0:                 episode reward: -21.2000,                 loss: nan
env1_first_0:                 episode reward: 21.4500,                 loss: nan
env1_second_0:                 episode reward: -21.4500,                 loss: nan
env2_first_0:                 episode reward: 21.1500,                 loss: nan
env2_second_0:                 episode reward: -21.1500,                 loss: nan
env3_first_0:                 episode reward: 21.3000,                 loss: nan
env3_second_0:                 episode reward: -21.3000,                 loss: nan
env4_first_0:                 episode reward: 21.4500,                 loss: nan
env4_second_0:                 episode reward: -21.4500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1627.8,                last time consumption/overall running time: 613.0320s / 117734.5294 s
env0_first_0:                 episode reward: 18.9000,                 loss: 0.0116
env0_second_0:                 episode reward: -18.9000,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
env2_first_0:                 episode reward: 19.6000,                 loss: nan
env2_second_0:                 episode reward: -19.6000,                 loss: nan
env3_first_0:                 episode reward: 19.4500,                 loss: nan
env3_second_0:                 episode reward: -19.4500,                 loss: nan
env4_first_0:                 episode reward: 21.9000,                 loss: nan
env4_second_0:                 episode reward: -21.9000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1606.65,                last time consumption/overall running time: 595.4398s / 118329.9691 s
env0_first_0:                 episode reward: 21.2000,                 loss: 0.0110
env0_second_0:                 episode reward: -21.2000,                 loss: nan
env1_first_0:                 episode reward: 21.6500,                 loss: nan
env1_second_0:                 episode reward: -21.6500,                 loss: nan
env2_first_0:                 episode reward: 20.9500,                 loss: nan
env2_second_0:                 episode reward: -20.9500,                 loss: nan
env3_first_0:                 episode reward: 21.6000,                 loss: nan
env3_second_0:                 episode reward: -21.6000,                 loss: nan
env4_first_0:                 episode reward: 21.1500,                 loss: nan
env4_second_0:                 episode reward: -21.1500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1640.45,                last time consumption/overall running time: 608.8396s / 118938.8088 s
env0_first_0:                 episode reward: 22.6500,                 loss: 0.0116
env0_second_0:                 episode reward: -22.6500,                 loss: nan
env1_first_0:                 episode reward: 22.4000,                 loss: nan
env1_second_0:                 episode reward: -22.4000,                 loss: nan
env2_first_0:                 episode reward: 21.6000,                 loss: nan
env2_second_0:                 episode reward: -21.6000,                 loss: nan
env3_first_0:                 episode reward: 22.3000,                 loss: nan
env3_second_0:                 episode reward: -22.3000,                 loss: nan
env4_first_0:                 episode reward: 21.6000,                 loss: nan
env4_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1792.35,                last time consumption/overall running time: 664.2101s / 119603.0189 s
env0_first_0:                 episode reward: 20.3000,                 loss: 0.0112
env0_second_0:                 episode reward: -20.3000,                 loss: nan
env1_first_0:                 episode reward: 19.0500,                 loss: nan
env1_second_0:                 episode reward: -19.0500,                 loss: nan
env2_first_0:                 episode reward: 19.3500,                 loss: nan
env2_second_0:                 episode reward: -19.3500,                 loss: nan
env3_first_0:                 episode reward: 19.9000,                 loss: nan
env3_second_0:                 episode reward: -19.9000,                 loss: nan
env4_first_0:                 episode reward: 19.7500,                 loss: nan
env4_second_0:                 episode reward: -19.7500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 1680.0,                last time consumption/overall running time: 620.7973s / 120223.8162 s
env0_first_0:                 episode reward: 21.6000,                 loss: 0.0115
env0_second_0:                 episode reward: -21.6000,                 loss: nan
env1_first_0:                 episode reward: 21.1000,                 loss: nan
env1_second_0:                 episode reward: -21.1000,                 loss: nan
env2_first_0:                 episode reward: 21.3000,                 loss: nan
env2_second_0:                 episode reward: -21.3000,                 loss: nan
env3_first_0:                 episode reward: 21.3000,                 loss: nan
env3_second_0:                 episode reward: -21.3000,                 loss: nan
env4_first_0:                 episode reward: 21.3500,                 loss: nan
env4_second_0:                 episode reward: -21.3500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1772.7,                last time consumption/overall running time: 664.1995s / 120888.0158 s
env0_first_0:                 episode reward: 18.2500,                 loss: 0.0115
env0_second_0:                 episode reward: -18.2500,                 loss: nan
env1_first_0:                 episode reward: 18.8500,                 loss: nan
env1_second_0:                 episode reward: -18.8500,                 loss: nan
env2_first_0:                 episode reward: 18.7000,                 loss: nan
env2_second_0:                 episode reward: -18.7000,                 loss: nan
env3_first_0:                 episode reward: 17.5000,                 loss: nan
env3_second_0:                 episode reward: -17.5000,                 loss: nan
env4_first_0:                 episode reward: 17.9000,                 loss: nan
env4_second_0:                 episode reward: -17.9000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1584.75,                last time consumption/overall running time: 591.5607s / 121479.5765 s
env0_first_0:                 episode reward: 22.1000,                 loss: 0.0109
env0_second_0:                 episode reward: -22.1000,                 loss: nan
env1_first_0:                 episode reward: 22.3500,                 loss: nan
env1_second_0:                 episode reward: -22.3500,                 loss: nan
env2_first_0:                 episode reward: 21.8500,                 loss: nan
env2_second_0:                 episode reward: -21.8500,                 loss: nan
env3_first_0:                 episode reward: 22.1500,                 loss: nan
env3_second_0:                 episode reward: -22.1500,                 loss: nan
env4_first_0:                 episode reward: 21.3000,                 loss: nan
env4_second_0:                 episode reward: -21.3000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1655.25,                last time consumption/overall running time: 612.7451s / 122092.3216 s
env0_first_0:                 episode reward: 19.7000,                 loss: 0.0101
env0_second_0:                 episode reward: -19.7000,                 loss: nan
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
env2_first_0:                 episode reward: 20.5500,                 loss: nan
env2_second_0:                 episode reward: -20.5500,                 loss: nan
env3_first_0:                 episode reward: 20.4500,                 loss: nan
env3_second_0:                 episode reward: -20.4500,                 loss: nan
env4_first_0:                 episode reward: 20.3000,                 loss: nan
env4_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1945.35,                last time consumption/overall running time: 725.2888s / 122817.6103 s
env0_first_0:                 episode reward: 13.3000,                 loss: 0.0098
env0_second_0:                 episode reward: -13.3000,                 loss: nan
env1_first_0:                 episode reward: 14.4500,                 loss: nan
env1_second_0:                 episode reward: -14.4500,                 loss: nan
env2_first_0:                 episode reward: 13.9500,                 loss: nan
env2_second_0:                 episode reward: -13.9500,                 loss: nan
env3_first_0:                 episode reward: 15.3500,                 loss: nan
env3_second_0:                 episode reward: -15.3500,                 loss: nan
env4_first_0:                 episode reward: 14.5500,                 loss: nan
env4_second_0:                 episode reward: -14.5500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1548.3,                last time consumption/overall running time: 575.7627s / 123393.3730 s
env0_first_0:                 episode reward: 21.9000,                 loss: 0.0099
env0_second_0:                 episode reward: -21.9000,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
env2_first_0:                 episode reward: 21.7000,                 loss: nan
env2_second_0:                 episode reward: -21.7000,                 loss: nan
env3_first_0:                 episode reward: 21.2000,                 loss: nan
env3_second_0:                 episode reward: -21.2000,                 loss: nan
env4_first_0:                 episode reward: 22.6500,                 loss: nan
env4_second_0:                 episode reward: -22.6500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1576.85,                last time consumption/overall running time: 581.9029s / 123975.2759 s
env0_first_0:                 episode reward: 22.3000,                 loss: 0.0094
env0_second_0:                 episode reward: -22.3000,                 loss: nan
env1_first_0:                 episode reward: 22.5500,                 loss: nan
env1_second_0:                 episode reward: -22.5500,                 loss: nan
env2_first_0:                 episode reward: 22.4500,                 loss: nan
env2_second_0:                 episode reward: -22.4500,                 loss: nan
env3_first_0:                 episode reward: 22.4000,                 loss: nan
env3_second_0:                 episode reward: -22.4000,                 loss: nan
env4_first_0:                 episode reward: 21.7500,                 loss: nan
env4_second_0:                 episode reward: -21.7500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 1586.15,                last time consumption/overall running time: 593.7407s / 124569.0166 s
env0_first_0:                 episode reward: 22.6500,                 loss: 0.0090
env0_second_0:                 episode reward: -22.6500,                 loss: nan
env1_first_0:                 episode reward: 21.2500,                 loss: nan
env1_second_0:                 episode reward: -21.2500,                 loss: nan
env2_first_0:                 episode reward: 22.0500,                 loss: nan
env2_second_0:                 episode reward: -22.0500,                 loss: nan
env3_first_0:                 episode reward: 21.5000,                 loss: nan
env3_second_0:                 episode reward: -21.5000,                 loss: nan
env4_first_0:                 episode reward: 20.6500,                 loss: nan
env4_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1635.45,                last time consumption/overall running time: 609.8002s / 125178.8167 s
env0_first_0:                 episode reward: 21.2500,                 loss: 0.0092
env0_second_0:                 episode reward: -21.2500,                 loss: nan
env1_first_0:                 episode reward: 21.7500,                 loss: nan
env1_second_0:                 episode reward: -21.7500,                 loss: nan
env2_first_0:                 episode reward: 21.7500,                 loss: nan
env2_second_0:                 episode reward: -21.7500,                 loss: nan
env3_first_0:                 episode reward: 21.1000,                 loss: nan
env3_second_0:                 episode reward: -21.1000,                 loss: nan
env4_first_0:                 episode reward: 21.6500,                 loss: nan
env4_second_0:                 episode reward: -21.6500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 1784.45,                last time consumption/overall running time: 654.6968s / 125833.5135 s
env0_first_0:                 episode reward: 16.9500,                 loss: 0.0092
env0_second_0:                 episode reward: -16.9500,                 loss: nan
env1_first_0:                 episode reward: 15.4000,                 loss: nan
env1_second_0:                 episode reward: -15.4000,                 loss: nan
env2_first_0:                 episode reward: 16.5500,                 loss: nan
env2_second_0:                 episode reward: -16.5500,                 loss: nan
env3_first_0:                 episode reward: 14.9500,                 loss: nan
env3_second_0:                 episode reward: -14.9500,                 loss: nan
env4_first_0:                 episode reward: 16.4500,                 loss: nan
env4_second_0:                 episode reward: -16.4500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1556.45,                last time consumption/overall running time: 570.9513s / 126404.4648 s
env0_first_0:                 episode reward: 22.0000,                 loss: 0.0097
env0_second_0:                 episode reward: -22.0000,                 loss: nan
env1_first_0:                 episode reward: 21.9500,                 loss: nan
env1_second_0:                 episode reward: -21.9500,                 loss: nan
env2_first_0:                 episode reward: 21.5500,                 loss: nan
env2_second_0:                 episode reward: -21.5500,                 loss: nan
env3_first_0:                 episode reward: 21.8500,                 loss: nan
env3_second_0:                 episode reward: -21.8500,                 loss: nan
env4_first_0:                 episode reward: 21.5500,                 loss: nan
env4_second_0:                 episode reward: -21.5500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1679.25,                last time consumption/overall running time: 618.6015s / 127023.0663 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.0103
env0_second_0:                 episode reward: -20.5000,                 loss: nan
env1_first_0:                 episode reward: 21.1000,                 loss: nan
env1_second_0:                 episode reward: -21.1000,                 loss: nan
env2_first_0:                 episode reward: 21.6500,                 loss: nan
env2_second_0:                 episode reward: -21.6500,                 loss: nan
env3_first_0:                 episode reward: 20.9000,                 loss: nan
env3_second_0:                 episode reward: -20.9000,                 loss: nan
env4_first_0:                 episode reward: 21.1500,                 loss: nan
env4_second_0:                 episode reward: -21.1500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 1681.3,                last time consumption/overall running time: 620.6319s / 127643.6982 s
env0_first_0:                 episode reward: 20.4000,                 loss: 0.0109
env0_second_0:                 episode reward: -20.4000,                 loss: nan
env1_first_0:                 episode reward: 19.7000,                 loss: nan
env1_second_0:                 episode reward: -19.7000,                 loss: nan
env2_first_0:                 episode reward: 20.4000,                 loss: nan
env2_second_0:                 episode reward: -20.4000,                 loss: nan
env3_first_0:                 episode reward: 20.9500,                 loss: nan
env3_second_0:                 episode reward: -20.9500,                 loss: nan
env4_first_0:                 episode reward: 19.7500,                 loss: nan
env4_second_0:                 episode reward: -19.7500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1892.8,                last time consumption/overall running time: 694.3143s / 128338.0126 s
env0_first_0:                 episode reward: 15.8000,                 loss: 0.0115
env0_second_0:                 episode reward: -15.8000,                 loss: nan
env1_first_0:                 episode reward: 19.4000,                 loss: nan
env1_second_0:                 episode reward: -19.4000,                 loss: nan
env2_first_0:                 episode reward: 16.4500,                 loss: nan
env2_second_0:                 episode reward: -16.4500,                 loss: nan
env3_first_0:                 episode reward: 19.1500,                 loss: nan
env3_second_0:                 episode reward: -19.1500,                 loss: nan
env4_first_0:                 episode reward: 17.9000,                 loss: nan
env4_second_0:                 episode reward: -17.9000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1698.8,                last time consumption/overall running time: 628.0030s / 128966.0155 s
env0_first_0:                 episode reward: 20.3500,                 loss: 0.0116
env0_second_0:                 episode reward: -20.3500,                 loss: nan
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
env2_first_0:                 episode reward: 20.3500,                 loss: nan
env2_second_0:                 episode reward: -20.3500,                 loss: nan
env3_first_0:                 episode reward: 20.5500,                 loss: nan
env3_second_0:                 episode reward: -20.5500,                 loss: nan
env4_first_0:                 episode reward: 21.2000,                 loss: nan
env4_second_0:                 episode reward: -21.2000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1659.8,                last time consumption/overall running time: 604.4929s / 129570.5084 s
env0_first_0:                 episode reward: 19.2500,                 loss: 0.0113
env0_second_0:                 episode reward: -19.2500,                 loss: nan
env1_first_0:                 episode reward: 19.9000,                 loss: nan
env1_second_0:                 episode reward: -19.9000,                 loss: nan
env2_first_0:                 episode reward: 19.6000,                 loss: nan
env2_second_0:                 episode reward: -19.6000,                 loss: nan
env3_first_0:                 episode reward: 20.2500,                 loss: nan
env3_second_0:                 episode reward: -20.2500,                 loss: nan
env4_first_0:                 episode reward: 20.1000,                 loss: nan
env4_second_0:                 episode reward: -20.1000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1606.2,                last time consumption/overall running time: 590.5162s / 130161.0246 s
env0_first_0:                 episode reward: 21.7500,                 loss: 0.0105
env0_second_0:                 episode reward: -21.7500,                 loss: nan
env1_first_0:                 episode reward: 21.8500,                 loss: nan
env1_second_0:                 episode reward: -21.8500,                 loss: nan
env2_first_0:                 episode reward: 21.8000,                 loss: nan
env2_second_0:                 episode reward: -21.8000,                 loss: nan
env3_first_0:                 episode reward: 21.6500,                 loss: nan
env3_second_0:                 episode reward: -21.6500,                 loss: nan
env4_first_0:                 episode reward: 21.6000,                 loss: nan
env4_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1768.0,                last time consumption/overall running time: 649.3765s / 130810.4011 s
env0_first_0:                 episode reward: 20.1500,                 loss: 0.0095
env0_second_0:                 episode reward: -20.1500,                 loss: nan
env1_first_0:                 episode reward: 19.8000,                 loss: nan
env1_second_0:                 episode reward: -19.8000,                 loss: nan
env2_first_0:                 episode reward: 19.8000,                 loss: nan
env2_second_0:                 episode reward: -19.8000,                 loss: nan
env3_first_0:                 episode reward: 20.4000,                 loss: nan
env3_second_0:                 episode reward: -20.4000,                 loss: nan
env4_first_0:                 episode reward: 20.4000,                 loss: nan
env4_second_0:                 episode reward: -20.4000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1664.2,                last time consumption/overall running time: 613.3635s / 131423.7646 s
env0_first_0:                 episode reward: 21.5000,                 loss: 0.0089
env0_second_0:                 episode reward: -21.5000,                 loss: nan
env1_first_0:                 episode reward: 21.3000,                 loss: nan
env1_second_0:                 episode reward: -21.3000,                 loss: nan
env2_first_0:                 episode reward: 20.5500,                 loss: nan
env2_second_0:                 episode reward: -20.5500,                 loss: nan
env3_first_0:                 episode reward: 20.7500,                 loss: nan
env3_second_0:                 episode reward: -20.7500,                 loss: nan
env4_first_0:                 episode reward: 21.6500,                 loss: nan
env4_second_0:                 episode reward: -21.6500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1599.8,                last time consumption/overall running time: 591.8531s / 132015.6177 s
env0_first_0:                 episode reward: 21.2000,                 loss: 0.0084
env0_second_0:                 episode reward: -21.2000,                 loss: nan
env1_first_0:                 episode reward: 21.6500,                 loss: nan
env1_second_0:                 episode reward: -21.6500,                 loss: nan
env2_first_0:                 episode reward: 21.4000,                 loss: nan
env2_second_0:                 episode reward: -21.4000,                 loss: nan
env3_first_0:                 episode reward: 21.6000,                 loss: nan
env3_second_0:                 episode reward: -21.6000,                 loss: nan
env4_first_0:                 episode reward: 21.2500,                 loss: nan
env4_second_0:                 episode reward: -21.2500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 1695.95,                last time consumption/overall running time: 636.2031s / 132651.8208 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0086
env0_second_0:                 episode reward: -21.0000,                 loss: nan
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
env2_first_0:                 episode reward: 20.8000,                 loss: nan
env2_second_0:                 episode reward: -20.8000,                 loss: nan
env3_first_0:                 episode reward: 20.3000,                 loss: nan
env3_second_0:                 episode reward: -20.3000,                 loss: nan
env4_first_0:                 episode reward: 20.9000,                 loss: nan
env4_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1635.05,                last time consumption/overall running time: 604.0214s / 133255.8421 s
env0_first_0:                 episode reward: 21.2000,                 loss: 0.0082
env0_second_0:                 episode reward: -21.2000,                 loss: nan
env1_first_0:                 episode reward: 21.3000,                 loss: nan
env1_second_0:                 episode reward: -21.3000,                 loss: nan
env2_first_0:                 episode reward: 21.7500,                 loss: nan
env2_second_0:                 episode reward: -21.7500,                 loss: nan
env3_first_0:                 episode reward: 21.2500,                 loss: nan
env3_second_0:                 episode reward: -21.2500,                 loss: nan
env4_first_0:                 episode reward: 21.0500,                 loss: nan
env4_second_0:                 episode reward: -21.0500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 1600.05,                last time consumption/overall running time: 588.7191s / 133844.5612 s
env0_first_0:                 episode reward: 21.7500,                 loss: 0.0085
env0_second_0:                 episode reward: -21.7500,                 loss: nan
env1_first_0:                 episode reward: 21.7000,                 loss: nan
env1_second_0:                 episode reward: -21.7000,                 loss: nan
env2_first_0:                 episode reward: 21.6000,                 loss: nan
env2_second_0:                 episode reward: -21.6000,                 loss: nan
env3_first_0:                 episode reward: 22.0000,                 loss: nan
env3_second_0:                 episode reward: -22.0000,                 loss: nan
env4_first_0:                 episode reward: 21.5500,                 loss: nan
env4_second_0:                 episode reward: -21.5500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1671.65,                last time consumption/overall running time: 620.6294s / 134465.1906 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0086
env0_second_0:                 episode reward: -20.6000,                 loss: nan
env1_first_0:                 episode reward: 21.3500,                 loss: nan
env1_second_0:                 episode reward: -21.3500,                 loss: nan
env2_first_0:                 episode reward: 20.5500,                 loss: nan
env2_second_0:                 episode reward: -20.5500,                 loss: nan
env3_first_0:                 episode reward: 21.3000,                 loss: nan
env3_second_0:                 episode reward: -21.3000,                 loss: nan
env4_first_0:                 episode reward: 20.7500,                 loss: nan
env4_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1618.6,                last time consumption/overall running time: 587.4039s / 135052.5944 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0084
env0_second_0:                 episode reward: -20.4500,                 loss: nan
env1_first_0:                 episode reward: 21.1000,                 loss: nan
env1_second_0:                 episode reward: -21.1000,                 loss: nan
env2_first_0:                 episode reward: 20.7000,                 loss: nan
env2_second_0:                 episode reward: -20.7000,                 loss: nan
env3_first_0:                 episode reward: 20.8500,                 loss: nan
env3_second_0:                 episode reward: -20.8500,                 loss: nan
env4_first_0:                 episode reward: 21.9500,                 loss: nan
env4_second_0:                 episode reward: -21.9500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1903.85,                last time consumption/overall running time: 694.8001s / 135747.3946 s
env0_first_0:                 episode reward: 15.7500,                 loss: 0.0089
env0_second_0:                 episode reward: -15.7500,                 loss: nan
env1_first_0:                 episode reward: 15.1500,                 loss: nan
env1_second_0:                 episode reward: -15.1500,                 loss: nan
env2_first_0:                 episode reward: 15.5500,                 loss: nan
env2_second_0:                 episode reward: -15.5500,                 loss: nan
env3_first_0:                 episode reward: 15.3000,                 loss: nan
env3_second_0:                 episode reward: -15.3000,                 loss: nan
env4_first_0:                 episode reward: 15.3500,                 loss: nan
env4_second_0:                 episode reward: -15.3500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1643.25,                last time consumption/overall running time: 604.7439s / 136352.1384 s
env0_first_0:                 episode reward: 21.6500,                 loss: 0.0092
env0_second_0:                 episode reward: -21.6500,                 loss: nan
env1_first_0:                 episode reward: 21.4500,                 loss: nan
env1_second_0:                 episode reward: -21.4500,                 loss: nan
env2_first_0:                 episode reward: 21.4500,                 loss: nan
env2_second_0:                 episode reward: -21.4500,                 loss: nan
env3_first_0:                 episode reward: 20.8500,                 loss: nan
env3_second_0:                 episode reward: -20.8500,                 loss: nan
env4_first_0:                 episode reward: 21.0000,                 loss: nan
env4_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1554.3,                last time consumption/overall running time: 580.1421s / 136932.2806 s
env0_first_0:                 episode reward: 21.9000,                 loss: 0.0093
env0_second_0:                 episode reward: -21.9000,                 loss: nan
env1_first_0:                 episode reward: 22.0000,                 loss: nan
env1_second_0:                 episode reward: -22.0000,                 loss: nan
env2_first_0:                 episode reward: 22.0000,                 loss: nan
env2_second_0:                 episode reward: -22.0000,                 loss: nan
env3_first_0:                 episode reward: 21.8500,                 loss: nan
env3_second_0:                 episode reward: -21.8500,                 loss: nan
env4_first_0:                 episode reward: 22.3500,                 loss: nan
env4_second_0:                 episode reward: -22.3500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1556.05,                last time consumption/overall running time: 571.4450s / 137503.7256 s
env0_first_0:                 episode reward: 22.0500,                 loss: 0.0089
env0_second_0:                 episode reward: -22.0500,                 loss: nan
env1_first_0:                 episode reward: 22.1500,                 loss: nan
env1_second_0:                 episode reward: -22.1500,                 loss: nan
env2_first_0:                 episode reward: 23.0000,                 loss: nan
env2_second_0:                 episode reward: -23.0000,                 loss: nan
env3_first_0:                 episode reward: 22.8500,                 loss: nan
env3_second_0:                 episode reward: -22.8500,                 loss: nan
env4_first_0:                 episode reward: 22.7500,                 loss: nan
env4_second_0:                 episode reward: -22.7500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 2051.05,                last time consumption/overall running time: 751.4080s / 138255.1335 s
env0_first_0:                 episode reward: 10.6000,                 loss: 0.0091
env0_second_0:                 episode reward: -10.6000,                 loss: nan
env1_first_0:                 episode reward: 10.7500,                 loss: nan
env1_second_0:                 episode reward: -10.7500,                 loss: nan
env2_first_0:                 episode reward: 10.3500,                 loss: nan
env2_second_0:                 episode reward: -10.3500,                 loss: nan
env3_first_0:                 episode reward: 10.0500,                 loss: nan
env3_second_0:                 episode reward: -10.0500,                 loss: nan
env4_first_0:                 episode reward: 10.6000,                 loss: nan
env4_second_0:                 episode reward: -10.6000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1507.1,                last time consumption/overall running time: 557.1659s / 138812.2994 s
env0_first_0:                 episode reward: 22.8500,                 loss: 0.0090
env0_second_0:                 episode reward: -22.8500,                 loss: nan
env1_first_0:                 episode reward: 22.6500,                 loss: nan
env1_second_0:                 episode reward: -22.6500,                 loss: nan
env2_first_0:                 episode reward: 22.8500,                 loss: nan
env2_second_0:                 episode reward: -22.8500,                 loss: nan
env3_first_0:                 episode reward: 22.0500,                 loss: nan
env3_second_0:                 episode reward: -22.0500,                 loss: nan
env4_first_0:                 episode reward: 22.6500,                 loss: nan
env4_second_0:                 episode reward: -22.6500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1694.35,                last time consumption/overall running time: 625.4212s / 139437.7206 s
env0_first_0:                 episode reward: 19.6500,                 loss: 0.0087
env0_second_0:                 episode reward: -19.6500,                 loss: nan
env1_first_0:                 episode reward: 19.2500,                 loss: nan
env1_second_0:                 episode reward: -19.2500,                 loss: nan
env2_first_0:                 episode reward: 19.3500,                 loss: nan
env2_second_0:                 episode reward: -19.3500,                 loss: nan
env3_first_0:                 episode reward: 18.9000,                 loss: nan
env3_second_0:                 episode reward: -18.9000,                 loss: nan
env4_first_0:                 episode reward: 19.6000,                 loss: nan
env4_second_0:                 episode reward: -19.6000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1584.75,                last time consumption/overall running time: 584.2870s / 140022.0076 s
env0_first_0:                 episode reward: 21.9000,                 loss: 0.0087
env0_second_0:                 episode reward: -21.9000,                 loss: nan
env1_first_0:                 episode reward: 22.2500,                 loss: nan
env1_second_0:                 episode reward: -22.2500,                 loss: nan
env2_first_0:                 episode reward: 22.2500,                 loss: nan
env2_second_0:                 episode reward: -22.2500,                 loss: nan
env3_first_0:                 episode reward: 21.7000,                 loss: nan
env3_second_0:                 episode reward: -21.7000,                 loss: nan
env4_first_0:                 episode reward: 21.7500,                 loss: nan
env4_second_0:                 episode reward: -21.7500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1581.05,                last time consumption/overall running time: 580.2378s / 140602.2454 s
env0_first_0:                 episode reward: 21.3500,                 loss: 0.0085
env0_second_0:                 episode reward: -21.3500,                 loss: nan
env1_first_0:                 episode reward: 21.8000,                 loss: nan
env1_second_0:                 episode reward: -21.8000,                 loss: nan
env2_first_0:                 episode reward: 21.6000,                 loss: nan
env2_second_0:                 episode reward: -21.6000,                 loss: nan
env3_first_0:                 episode reward: 22.3000,                 loss: nan
env3_second_0:                 episode reward: -22.3000,                 loss: nan
env4_first_0:                 episode reward: 22.3000,                 loss: nan
env4_second_0:                 episode reward: -22.3000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1567.8,                last time consumption/overall running time: 575.7273s / 141177.9726 s
env0_first_0:                 episode reward: 21.6000,                 loss: 0.0086
env0_second_0:                 episode reward: -21.6000,                 loss: nan
env1_first_0:                 episode reward: 21.8500,                 loss: nan
env1_second_0:                 episode reward: -21.8500,                 loss: nan
env2_first_0:                 episode reward: 22.2500,                 loss: nan
env2_second_0:                 episode reward: -22.2500,                 loss: nan
env3_first_0:                 episode reward: 22.4000,                 loss: nan
env3_second_0:                 episode reward: -22.4000,                 loss: nan
env4_first_0:                 episode reward: 21.6500,                 loss: nan
env4_second_0:                 episode reward: -21.6500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1661.3,                last time consumption/overall running time: 608.2181s / 141786.1907 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0086
env0_second_0:                 episode reward: -20.8000,                 loss: nan
env1_first_0:                 episode reward: 21.3500,                 loss: nan
env1_second_0:                 episode reward: -21.3500,                 loss: nan
env2_first_0:                 episode reward: 21.0000,                 loss: nan
env2_second_0:                 episode reward: -21.0000,                 loss: nan
env3_first_0:                 episode reward: 20.7500,                 loss: nan
env3_second_0:                 episode reward: -20.7500,                 loss: nan
env4_first_0:                 episode reward: 21.6000,                 loss: nan
env4_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1612.6,                last time consumption/overall running time: 591.9902s / 142378.1810 s
env0_first_0:                 episode reward: 22.0000,                 loss: 0.0087
env0_second_0:                 episode reward: -22.0000,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
env2_first_0:                 episode reward: 21.6500,                 loss: nan
env2_second_0:                 episode reward: -21.6500,                 loss: nan
env3_first_0:                 episode reward: 21.6000,                 loss: nan
env3_second_0:                 episode reward: -21.6000,                 loss: nan
env4_first_0:                 episode reward: 21.9500,                 loss: nan
env4_second_0:                 episode reward: -21.9500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1636.75,                last time consumption/overall running time: 601.6605s / 142979.8414 s
env0_first_0:                 episode reward: 20.1500,                 loss: 0.0086
env0_second_0:                 episode reward: -20.1500,                 loss: nan
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
env2_first_0:                 episode reward: 20.3000,                 loss: nan
env2_second_0:                 episode reward: -20.3000,                 loss: nan
env3_first_0:                 episode reward: 20.4000,                 loss: nan
env3_second_0:                 episode reward: -20.4000,                 loss: nan
env4_first_0:                 episode reward: 20.0500,                 loss: nan
env4_second_0:                 episode reward: -20.0500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1550.45,                last time consumption/overall running time: 569.8069s / 143549.6483 s
env0_first_0:                 episode reward: 22.6000,                 loss: 0.0084
env0_second_0:                 episode reward: -22.6000,                 loss: nan
env1_first_0:                 episode reward: 21.9000,                 loss: nan
env1_second_0:                 episode reward: -21.9000,                 loss: nan
env2_first_0:                 episode reward: 21.3000,                 loss: nan
env2_second_0:                 episode reward: -21.3000,                 loss: nan
env3_first_0:                 episode reward: 22.2000,                 loss: nan
env3_second_0:                 episode reward: -22.2000,                 loss: nan
env4_first_0:                 episode reward: 22.2000,                 loss: nan
env4_second_0:                 episode reward: -22.2000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1664.5,                last time consumption/overall running time: 611.6225s / 144161.2708 s
env0_first_0:                 episode reward: 22.1500,                 loss: 0.0086
env0_second_0:                 episode reward: -22.1500,                 loss: nan
env1_first_0:                 episode reward: 21.4500,                 loss: nan
env1_second_0:                 episode reward: -21.4500,                 loss: nan
env2_first_0:                 episode reward: 21.8500,                 loss: nan
env2_second_0:                 episode reward: -21.8500,                 loss: nan
env3_first_0:                 episode reward: 22.2500,                 loss: nan
env3_second_0:                 episode reward: -22.2500,                 loss: nan
env4_first_0:                 episode reward: 21.8500,                 loss: nan
env4_second_0:                 episode reward: -21.8500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1618.2,                last time consumption/overall running time: 594.8492s / 144756.1201 s
env0_first_0:                 episode reward: 21.7000,                 loss: 0.0084
env0_second_0:                 episode reward: -21.7000,                 loss: nan
env1_first_0:                 episode reward: 21.9000,                 loss: nan
env1_second_0:                 episode reward: -21.9000,                 loss: nan
env2_first_0:                 episode reward: 21.7000,                 loss: nan
env2_second_0:                 episode reward: -21.7000,                 loss: nan
env3_first_0:                 episode reward: 21.9000,                 loss: nan
env3_second_0:                 episode reward: -21.9000,                 loss: nan
env4_first_0:                 episode reward: 22.1500,                 loss: nan
env4_second_0:                 episode reward: -22.1500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1549.45,                last time consumption/overall running time: 569.2023s / 145325.3224 s
env0_first_0:                 episode reward: 22.4500,                 loss: 0.0086
env0_second_0:                 episode reward: -22.4500,                 loss: nan
env1_first_0:                 episode reward: 21.6500,                 loss: nan
env1_second_0:                 episode reward: -21.6500,                 loss: nan
env2_first_0:                 episode reward: 21.3000,                 loss: nan
env2_second_0:                 episode reward: -21.3000,                 loss: nan
env3_first_0:                 episode reward: 21.8500,                 loss: nan
env3_second_0:                 episode reward: -21.8500,                 loss: nan
env4_first_0:                 episode reward: 21.9500,                 loss: nan
env4_second_0:                 episode reward: -21.9500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1597.1,                last time consumption/overall running time: 586.7150s / 145912.0373 s
env0_first_0:                 episode reward: 22.6500,                 loss: 0.0086
env0_second_0:                 episode reward: -22.6500,                 loss: nan
env1_first_0:                 episode reward: 22.8500,                 loss: nan
env1_second_0:                 episode reward: -22.8500,                 loss: nan
env2_first_0:                 episode reward: 23.0500,                 loss: nan
env2_second_0:                 episode reward: -23.0500,                 loss: nan
env3_first_0:                 episode reward: 23.2500,                 loss: nan
env3_second_0:                 episode reward: -23.2500,                 loss: nan
env4_first_0:                 episode reward: 22.8500,                 loss: nan
env4_second_0:                 episode reward: -22.8500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1623.75,                last time consumption/overall running time: 600.5537s / 146512.5911 s
env0_first_0:                 episode reward: 21.1000,                 loss: 0.0088
env0_second_0:                 episode reward: -21.1000,                 loss: nan
env1_first_0:                 episode reward: 22.3000,                 loss: nan
env1_second_0:                 episode reward: -22.3000,                 loss: nan
env2_first_0:                 episode reward: 20.8500,                 loss: nan
env2_second_0:                 episode reward: -20.8500,                 loss: nan
env3_first_0:                 episode reward: 21.7000,                 loss: nan
env3_second_0:                 episode reward: -21.7000,                 loss: nan
env4_first_0:                 episode reward: 21.2000,                 loss: nan
env4_second_0:                 episode reward: -21.2000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1731.35,                last time consumption/overall running time: 635.3902s / 147147.9813 s
env0_first_0:                 episode reward: 19.1500,                 loss: 0.0095
env0_second_0:                 episode reward: -19.1500,                 loss: nan
env1_first_0:                 episode reward: 18.9500,                 loss: nan
env1_second_0:                 episode reward: -18.9500,                 loss: nan
env2_first_0:                 episode reward: 18.9000,                 loss: nan
env2_second_0:                 episode reward: -18.9000,                 loss: nan
env3_first_0:                 episode reward: 17.7500,                 loss: nan
env3_second_0:                 episode reward: -17.7500,                 loss: nan
env4_first_0:                 episode reward: 18.5000,                 loss: nan
env4_second_0:                 episode reward: -18.5000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1593.6,                last time consumption/overall running time: 588.8769s / 147736.8582 s
env0_first_0:                 episode reward: 22.7000,                 loss: 0.0100
env0_second_0:                 episode reward: -22.7000,                 loss: nan
env1_first_0:                 episode reward: 22.0500,                 loss: nan
env1_second_0:                 episode reward: -22.0500,                 loss: nan
env2_first_0:                 episode reward: 22.3000,                 loss: nan
env2_second_0:                 episode reward: -22.3000,                 loss: nan
env3_first_0:                 episode reward: 22.4000,                 loss: nan
env3_second_0:                 episode reward: -22.4000,                 loss: nan
env4_first_0:                 episode reward: 22.3500,                 loss: nan
env4_second_0:                 episode reward: -22.3500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1608.25,                last time consumption/overall running time: 589.4971s / 148326.3553 s
env0_first_0:                 episode reward: 22.3500,                 loss: 0.0104
env0_second_0:                 episode reward: -22.3500,                 loss: nan
env1_first_0:                 episode reward: 22.1500,                 loss: nan
env1_second_0:                 episode reward: -22.1500,                 loss: nan
env2_first_0:                 episode reward: 21.8500,                 loss: nan
env2_second_0:                 episode reward: -21.8500,                 loss: nan
env3_first_0:                 episode reward: 21.7000,                 loss: nan
env3_second_0:                 episode reward: -21.7000,                 loss: nan
env4_first_0:                 episode reward: 21.9000,                 loss: nan
env4_second_0:                 episode reward: -21.9000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1682.45,                last time consumption/overall running time: 626.3421s / 148952.6973 s
env0_first_0:                 episode reward: 22.8500,                 loss: 0.0104
env0_second_0:                 episode reward: -22.8500,                 loss: nan
env1_first_0:                 episode reward: 22.4000,                 loss: nan
env1_second_0:                 episode reward: -22.4000,                 loss: nan
env2_first_0:                 episode reward: 23.0000,                 loss: nan
env2_second_0:                 episode reward: -23.0000,                 loss: nan
env3_first_0:                 episode reward: 22.7500,                 loss: nan
env3_second_0:                 episode reward: -22.7500,                 loss: nan
env4_first_0:                 episode reward: 22.8000,                 loss: nan
env4_second_0:                 episode reward: -22.8000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1627.15,                last time consumption/overall running time: 605.1432s / 149557.8405 s
env0_first_0:                 episode reward: 22.7000,                 loss: 0.0107
env0_second_0:                 episode reward: -22.7000,                 loss: nan
env1_first_0:                 episode reward: 22.5500,                 loss: nan
env1_second_0:                 episode reward: -22.5500,                 loss: nan
env2_first_0:                 episode reward: 22.6000,                 loss: nan
env2_second_0:                 episode reward: -22.6000,                 loss: nan
env3_first_0:                 episode reward: 22.5500,                 loss: nan
env3_second_0:                 episode reward: -22.5500,                 loss: nan
env4_first_0:                 episode reward: 22.5500,                 loss: nan
env4_second_0:                 episode reward: -22.5500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1717.05,                last time consumption/overall running time: 632.3025s / 150190.1430 s
env0_first_0:                 episode reward: 22.7500,                 loss: 0.0104
env0_second_0:                 episode reward: -22.7500,                 loss: nan
env1_first_0:                 episode reward: 22.5500,                 loss: nan
env1_second_0:                 episode reward: -22.5500,                 loss: nan
env2_first_0:                 episode reward: 21.8000,                 loss: nan
env2_second_0:                 episode reward: -21.8000,                 loss: nan
env3_first_0:                 episode reward: 22.2500,                 loss: nan
env3_second_0:                 episode reward: -22.2500,                 loss: nan
env4_first_0:                 episode reward: 22.0500,                 loss: nan
env4_second_0:                 episode reward: -22.0500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1576.4,                last time consumption/overall running time: 575.3147s / 150765.4577 s
env0_first_0:                 episode reward: 24.3500,                 loss: 0.0096
env0_second_0:                 episode reward: -24.3500,                 loss: nan
env1_first_0:                 episode reward: 24.3000,                 loss: nan
env1_second_0:                 episode reward: -24.3000,                 loss: nan
env2_first_0:                 episode reward: 24.5000,                 loss: nan
env2_second_0:                 episode reward: -24.5000,                 loss: nan
env3_first_0:                 episode reward: 24.3500,                 loss: nan
env3_second_0:                 episode reward: -24.3500,                 loss: nan
env4_first_0:                 episode reward: 24.2500,                 loss: nan
env4_second_0:                 episode reward: -24.2500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 2006.95,                last time consumption/overall running time: 736.4786s / 151501.9363 s
env0_first_0:                 episode reward: 13.9000,                 loss: 0.0097
env0_second_0:                 episode reward: -13.9000,                 loss: nan
env1_first_0:                 episode reward: 13.7000,                 loss: nan
env1_second_0:                 episode reward: -13.7000,                 loss: nan
env2_first_0:                 episode reward: 13.3000,                 loss: nan
env2_second_0:                 episode reward: -13.3000,                 loss: nan
env3_first_0:                 episode reward: 14.0500,                 loss: nan
env3_second_0:                 episode reward: -14.0500,                 loss: nan
env4_first_0:                 episode reward: 13.8500,                 loss: nan
env4_second_0:                 episode reward: -13.8500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1604.1,                last time consumption/overall running time: 589.3512s / 152091.2875 s
env0_first_0:                 episode reward: 23.1500,                 loss: 0.0097
env0_second_0:                 episode reward: -23.1500,                 loss: nan
env1_first_0:                 episode reward: 22.9500,                 loss: nan
env1_second_0:                 episode reward: -22.9500,                 loss: nan
env2_first_0:                 episode reward: 22.5500,                 loss: nan
env2_second_0:                 episode reward: -22.5500,                 loss: nan
env3_first_0:                 episode reward: 22.6000,                 loss: nan
env3_second_0:                 episode reward: -22.6000,                 loss: nan
env4_first_0:                 episode reward: 23.3500,                 loss: nan
env4_second_0:                 episode reward: -23.3500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1771.8,                last time consumption/overall running time: 656.7840s / 152748.0715 s
env0_first_0:                 episode reward: 19.1500,                 loss: 0.0101
env0_second_0:                 episode reward: -19.1500,                 loss: nan
env1_first_0:                 episode reward: 18.5500,                 loss: nan
env1_second_0:                 episode reward: -18.5500,                 loss: nan
env2_first_0:                 episode reward: 19.4000,                 loss: nan
env2_second_0:                 episode reward: -19.4000,                 loss: nan
env3_first_0:                 episode reward: 17.9000,                 loss: nan
env3_second_0:                 episode reward: -17.9000,                 loss: nan
env4_first_0:                 episode reward: 18.6500,                 loss: nan
env4_second_0:                 episode reward: -18.6500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1648.35,                last time consumption/overall running time: 605.3089s / 153353.3804 s
env0_first_0:                 episode reward: 21.7500,                 loss: 0.0104
env0_second_0:                 episode reward: -21.7500,                 loss: nan
env1_first_0:                 episode reward: 21.7500,                 loss: nan
env1_second_0:                 episode reward: -21.7500,                 loss: nan
env2_first_0:                 episode reward: 22.2500,                 loss: nan
env2_second_0:                 episode reward: -22.2500,                 loss: nan
env3_first_0:                 episode reward: 21.3500,                 loss: nan
env3_second_0:                 episode reward: -21.3500,                 loss: nan
env4_first_0:                 episode reward: 21.6000,                 loss: nan
env4_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1619.85,                last time consumption/overall running time: 596.9640s / 153950.3443 s
env0_first_0:                 episode reward: 21.6500,                 loss: 0.0106
env0_second_0:                 episode reward: -21.6500,                 loss: nan
env1_first_0:                 episode reward: 23.0500,                 loss: nan
env1_second_0:                 episode reward: -23.0500,                 loss: nan
env2_first_0:                 episode reward: 22.6500,                 loss: nan
env2_second_0:                 episode reward: -22.6500,                 loss: nan
env3_first_0:                 episode reward: 22.0000,                 loss: nan
env3_second_0:                 episode reward: -22.0000,                 loss: nan
env4_first_0:                 episode reward: 22.6500,                 loss: nan
env4_second_0:                 episode reward: -22.6500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1562.25,                last time consumption/overall running time: 576.9262s / 154527.2705 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0109
env0_second_0:                 episode reward: -20.8500,                 loss: nan
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
env2_first_0:                 episode reward: 21.3000,                 loss: nan
env2_second_0:                 episode reward: -21.3000,                 loss: nan
env3_first_0:                 episode reward: 20.5500,                 loss: nan
env3_second_0:                 episode reward: -20.5500,                 loss: nan
env4_first_0:                 episode reward: 21.4000,                 loss: nan
env4_second_0:                 episode reward: -21.4000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1526.0,                last time consumption/overall running time: 553.5381s / 155080.8086 s
env0_first_0:                 episode reward: 22.3000,                 loss: 0.0102
env0_second_0:                 episode reward: -22.3000,                 loss: nan
env1_first_0:                 episode reward: 22.8000,                 loss: nan
env1_second_0:                 episode reward: -22.8000,                 loss: nan
env2_first_0:                 episode reward: 22.6000,                 loss: nan
env2_second_0:                 episode reward: -22.6000,                 loss: nan
env3_first_0:                 episode reward: 22.7500,                 loss: nan
env3_second_0:                 episode reward: -22.7500,                 loss: nan
env4_first_0:                 episode reward: 23.0000,                 loss: nan
env4_second_0:                 episode reward: -23.0000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1554.95,                last time consumption/overall running time: 582.8304s / 155663.6390 s
env0_first_0:                 episode reward: 23.2000,                 loss: 0.0097
env0_second_0:                 episode reward: -23.2000,                 loss: nan
env1_first_0:                 episode reward: 23.5000,                 loss: nan
env1_second_0:                 episode reward: -23.5000,                 loss: nan
env2_first_0:                 episode reward: 23.2500,                 loss: nan
env2_second_0:                 episode reward: -23.2500,                 loss: nan
env3_first_0:                 episode reward: 22.9500,                 loss: nan
env3_second_0:                 episode reward: -22.9500,                 loss: nan
env4_first_0:                 episode reward: 23.2500,                 loss: nan
env4_second_0:                 episode reward: -23.2500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1622.6,                last time consumption/overall running time: 603.6652s / 156267.3042 s
env0_first_0:                 episode reward: 21.6500,                 loss: 0.0091
env0_second_0:                 episode reward: -21.6500,                 loss: nan
env1_first_0:                 episode reward: 21.8000,                 loss: nan
env1_second_0:                 episode reward: -21.8000,                 loss: nan
env2_first_0:                 episode reward: 21.9500,                 loss: nan
env2_second_0:                 episode reward: -21.9500,                 loss: nan
env3_first_0:                 episode reward: 21.6000,                 loss: nan
env3_second_0:                 episode reward: -21.6000,                 loss: nan
env4_first_0:                 episode reward: 20.0500,                 loss: nan
env4_second_0:                 episode reward: -20.0500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1614.75,                last time consumption/overall running time: 591.0635s / 156858.3677 s
env0_first_0:                 episode reward: 23.2000,                 loss: 0.0095
env0_second_0:                 episode reward: -23.2000,                 loss: nan
env1_first_0:                 episode reward: 22.3500,                 loss: nan
env1_second_0:                 episode reward: -22.3500,                 loss: nan
env2_first_0:                 episode reward: 23.4000,                 loss: nan
env2_second_0:                 episode reward: -23.4000,                 loss: nan
env3_first_0:                 episode reward: 22.6500,                 loss: nan
env3_second_0:                 episode reward: -22.6500,                 loss: nan
env4_first_0:                 episode reward: 22.8000,                 loss: nan
env4_second_0:                 episode reward: -22.8000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1701.55,                last time consumption/overall running time: 629.3999s / 157487.7677 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0099
env0_second_0:                 episode reward: -20.7000,                 loss: nan
env1_first_0:                 episode reward: 21.9000,                 loss: nan
env1_second_0:                 episode reward: -21.9000,                 loss: nan
env2_first_0:                 episode reward: 21.7500,                 loss: nan
env2_second_0:                 episode reward: -21.7500,                 loss: nan
env3_first_0:                 episode reward: 21.8000,                 loss: nan
env3_second_0:                 episode reward: -21.8000,                 loss: nan
env4_first_0:                 episode reward: 22.0000,                 loss: nan
env4_second_0:                 episode reward: -22.0000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1543.4,                last time consumption/overall running time: 570.8628s / 158058.6305 s
env0_first_0:                 episode reward: 22.3000,                 loss: 0.0100
env0_second_0:                 episode reward: -22.3000,                 loss: nan
env1_first_0:                 episode reward: 23.3000,                 loss: nan
env1_second_0:                 episode reward: -23.3000,                 loss: nan
env2_first_0:                 episode reward: 22.8500,                 loss: nan
env2_second_0:                 episode reward: -22.8500,                 loss: nan
env3_first_0:                 episode reward: 22.6000,                 loss: nan
env3_second_0:                 episode reward: -22.6000,                 loss: nan
env4_first_0:                 episode reward: 22.9000,                 loss: nan
env4_second_0:                 episode reward: -22.9000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 1577.4,                last time consumption/overall running time: 579.9896s / 158638.6201 s
env0_first_0:                 episode reward: 23.3000,                 loss: 0.0099
env0_second_0:                 episode reward: -23.3000,                 loss: nan
env1_first_0:                 episode reward: 23.7000,                 loss: nan
env1_second_0:                 episode reward: -23.7000,                 loss: nan
env2_first_0:                 episode reward: 23.0000,                 loss: nan
env2_second_0:                 episode reward: -23.0000,                 loss: nan
env3_first_0:                 episode reward: 23.4500,                 loss: nan
env3_second_0:                 episode reward: -23.4500,                 loss: nan
env4_first_0:                 episode reward: 23.2500,                 loss: nan
env4_second_0:                 episode reward: -23.2500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 2150.8,                last time consumption/overall running time: 789.3099s / 159427.9299 s
env0_first_0:                 episode reward: 7.8500,                 loss: 0.0094
env0_second_0:                 episode reward: -7.8500,                 loss: nan
env1_first_0:                 episode reward: 8.7000,                 loss: nan
env1_second_0:                 episode reward: -8.7000,                 loss: nan
env2_first_0:                 episode reward: 7.1000,                 loss: nan
env2_second_0:                 episode reward: -7.1000,                 loss: nan
env3_first_0:                 episode reward: 8.1000,                 loss: nan
env3_second_0:                 episode reward: -8.1000,                 loss: nan
env4_first_0:                 episode reward: 8.0500,                 loss: nan
env4_second_0:                 episode reward: -8.0500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1529.9,                last time consumption/overall running time: 562.1473s / 159990.0772 s
env0_first_0:                 episode reward: 22.4000,                 loss: 0.0095
env0_second_0:                 episode reward: -22.4000,                 loss: nan
env1_first_0:                 episode reward: 22.8500,                 loss: nan
env1_second_0:                 episode reward: -22.8500,                 loss: nan
env2_first_0:                 episode reward: 21.8000,                 loss: nan
env2_second_0:                 episode reward: -21.8000,                 loss: nan
env3_first_0:                 episode reward: 21.6500,                 loss: nan
env3_second_0:                 episode reward: -21.6500,                 loss: nan
env4_first_0:                 episode reward: 23.5000,                 loss: nan
env4_second_0:                 episode reward: -23.5000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1503.0,                last time consumption/overall running time: 559.1179s / 160549.1952 s
env0_first_0:                 episode reward: 23.7000,                 loss: 0.0098
env0_second_0:                 episode reward: -23.7000,                 loss: nan
env1_first_0:                 episode reward: 24.0000,                 loss: nan
env1_second_0:                 episode reward: -24.0000,                 loss: nan
env2_first_0:                 episode reward: 23.6000,                 loss: nan
env2_second_0:                 episode reward: -23.6000,                 loss: nan
env3_first_0:                 episode reward: 24.1500,                 loss: nan
env3_second_0:                 episode reward: -24.1500,                 loss: nan
env4_first_0:                 episode reward: 23.6500,                 loss: nan
env4_second_0:                 episode reward: -23.6500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 1575.55,                last time consumption/overall running time: 585.5810s / 161134.7761 s
env0_first_0:                 episode reward: 22.0500,                 loss: 0.0092
env0_second_0:                 episode reward: -22.0500,                 loss: nan
env1_first_0:                 episode reward: 22.6500,                 loss: nan
env1_second_0:                 episode reward: -22.6500,                 loss: nan
env2_first_0:                 episode reward: 22.3500,                 loss: nan
env2_second_0:                 episode reward: -22.3500,                 loss: nan
env3_first_0:                 episode reward: 22.3500,                 loss: nan
env3_second_0:                 episode reward: -22.3500,                 loss: nan
env4_first_0:                 episode reward: 21.7000,                 loss: nan
env4_second_0:                 episode reward: -21.7000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1597.75,                last time consumption/overall running time: 606.8884s / 161741.6645 s
env0_first_0:                 episode reward: 21.9500,                 loss: 0.0086
env0_second_0:                 episode reward: -21.9500,                 loss: nan
env1_first_0:                 episode reward: 22.0000,                 loss: nan
env1_second_0:                 episode reward: -22.0000,                 loss: nan
env2_first_0:                 episode reward: 21.4500,                 loss: nan
env2_second_0:                 episode reward: -21.4500,                 loss: nan
env3_first_0:                 episode reward: 21.4000,                 loss: nan
env3_second_0:                 episode reward: -21.4000,                 loss: nan
env4_first_0:                 episode reward: 21.8500,                 loss: nan
env4_second_0:                 episode reward: -21.8500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1560.75,                last time consumption/overall running time: 578.0445s / 162319.7090 s
env0_first_0:                 episode reward: 22.6500,                 loss: 0.0083
env0_second_0:                 episode reward: -22.6500,                 loss: nan
env1_first_0:                 episode reward: 22.3000,                 loss: nan
env1_second_0:                 episode reward: -22.3000,                 loss: nan
env2_first_0:                 episode reward: 22.5500,                 loss: nan
env2_second_0:                 episode reward: -22.5500,                 loss: nan
env3_first_0:                 episode reward: 22.7000,                 loss: nan
env3_second_0:                 episode reward: -22.7000,                 loss: nan
env4_first_0:                 episode reward: 22.1000,                 loss: nan
env4_second_0:                 episode reward: -22.1000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1516.45,                last time consumption/overall running time: 561.3181s / 162881.0271 s
env0_first_0:                 episode reward: 21.9500,                 loss: 0.0080
env0_second_0:                 episode reward: -21.9500,                 loss: nan
env1_first_0:                 episode reward: 22.7000,                 loss: nan
env1_second_0:                 episode reward: -22.7000,                 loss: nan
env2_first_0:                 episode reward: 21.6500,                 loss: nan
env2_second_0:                 episode reward: -21.6500,                 loss: nan
env3_first_0:                 episode reward: 22.0500,                 loss: nan
env3_second_0:                 episode reward: -22.0500,                 loss: nan
env4_first_0:                 episode reward: 21.9500,                 loss: nan
env4_second_0:                 episode reward: -21.9500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1533.75,                last time consumption/overall running time: 564.5434s / 163445.5705 s
env0_first_0:                 episode reward: 22.8500,                 loss: 0.0079
env0_second_0:                 episode reward: -22.8500,                 loss: nan
env1_first_0:                 episode reward: 22.2000,                 loss: nan
env1_second_0:                 episode reward: -22.2000,                 loss: nan
env2_first_0:                 episode reward: 23.1000,                 loss: nan
env2_second_0:                 episode reward: -23.1000,                 loss: nan
env3_first_0:                 episode reward: 22.2000,                 loss: nan
env3_second_0:                 episode reward: -22.2000,                 loss: nan
env4_first_0:                 episode reward: 22.7000,                 loss: nan
env4_second_0:                 episode reward: -22.7000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1521.2,                last time consumption/overall running time: 571.1535s / 164016.7240 s
env0_first_0:                 episode reward: 22.0000,                 loss: 0.0084
env0_second_0:                 episode reward: -22.0000,                 loss: nan
env1_first_0:                 episode reward: 22.0500,                 loss: nan
env1_second_0:                 episode reward: -22.0500,                 loss: nan
env2_first_0:                 episode reward: 22.4500,                 loss: nan
env2_second_0:                 episode reward: -22.4500,                 loss: nan
env3_first_0:                 episode reward: 22.1000,                 loss: nan
env3_second_0:                 episode reward: -22.1000,                 loss: nan
env4_first_0:                 episode reward: 22.5500,                 loss: nan
env4_second_0:                 episode reward: -22.5500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1514.45,                last time consumption/overall running time: 568.9060s / 164585.6300 s
env0_first_0:                 episode reward: 22.1500,                 loss: 0.0092
env0_second_0:                 episode reward: -22.1500,                 loss: nan
env1_first_0:                 episode reward: 22.6500,                 loss: nan
env1_second_0:                 episode reward: -22.6500,                 loss: nan
env2_first_0:                 episode reward: 22.5500,                 loss: nan
env2_second_0:                 episode reward: -22.5500,                 loss: nan
env3_first_0:                 episode reward: 22.3000,                 loss: nan
env3_second_0:                 episode reward: -22.3000,                 loss: nan
env4_first_0:                 episode reward: 22.6500,                 loss: nan
env4_second_0:                 episode reward: -22.6500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1484.7,                last time consumption/overall running time: 552.4022s / 165138.0322 s
env0_first_0:                 episode reward: 23.3000,                 loss: 0.0095
env0_second_0:                 episode reward: -23.3000,                 loss: nan
env1_first_0:                 episode reward: 22.7500,                 loss: nan
env1_second_0:                 episode reward: -22.7500,                 loss: nan
env2_first_0:                 episode reward: 22.7500,                 loss: nan
env2_second_0:                 episode reward: -22.7500,                 loss: nan
env3_first_0:                 episode reward: 22.8000,                 loss: nan
env3_second_0:                 episode reward: -22.8000,                 loss: nan
env4_first_0:                 episode reward: 22.6500,                 loss: nan
env4_second_0:                 episode reward: -22.6500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1863.4,                last time consumption/overall running time: 705.9150s / 165843.9472 s
env0_first_0:                 episode reward: 19.5500,                 loss: 0.0098
env0_second_0:                 episode reward: -19.5500,                 loss: nan
env1_first_0:                 episode reward: 19.4500,                 loss: nan
env1_second_0:                 episode reward: -19.4500,                 loss: nan
env2_first_0:                 episode reward: 19.3500,                 loss: nan
env2_second_0:                 episode reward: -19.3500,                 loss: nan
env3_first_0:                 episode reward: 15.8500,                 loss: nan
env3_second_0:                 episode reward: -15.8500,                 loss: nan
env4_first_0:                 episode reward: 15.9000,                 loss: nan
env4_second_0:                 episode reward: -15.9000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 1852.85,                last time consumption/overall running time: 697.6700s / 166541.6172 s
env0_first_0:                 episode reward: 20.3500,                 loss: 0.0105
env0_second_0:                 episode reward: -20.3500,                 loss: nan
env1_first_0:                 episode reward: 20.3500,                 loss: nan
env1_second_0:                 episode reward: -20.3500,                 loss: nan
env2_first_0:                 episode reward: 20.6000,                 loss: nan
env2_second_0:                 episode reward: -20.6000,                 loss: nan
env3_first_0:                 episode reward: 20.9000,                 loss: nan
env3_second_0:                 episode reward: -20.9000,                 loss: nan
env4_first_0:                 episode reward: 20.2000,                 loss: nan
env4_second_0:                 episode reward: -20.2000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1648.0,                last time consumption/overall running time: 623.9486s / 167165.5657 s
env0_first_0:                 episode reward: 23.3000,                 loss: 0.0112
env0_second_0:                 episode reward: -23.3000,                 loss: nan
env1_first_0:                 episode reward: 23.6500,                 loss: nan
env1_second_0:                 episode reward: -23.6500,                 loss: nan
env2_first_0:                 episode reward: 22.4500,                 loss: nan
env2_second_0:                 episode reward: -22.4500,                 loss: nan
env3_first_0:                 episode reward: 22.3000,                 loss: nan
env3_second_0:                 episode reward: -22.3000,                 loss: nan
env4_first_0:                 episode reward: 23.5000,                 loss: nan
env4_second_0:                 episode reward: -23.5000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1762.65,                last time consumption/overall running time: 660.3419s / 167825.9076 s
env0_first_0:                 episode reward: 21.7500,                 loss: 0.0108
env0_second_0:                 episode reward: -21.7500,                 loss: nan
env1_first_0:                 episode reward: 21.4000,                 loss: nan
env1_second_0:                 episode reward: -21.4000,                 loss: nan
env2_first_0:                 episode reward: 21.5500,                 loss: nan
env2_second_0:                 episode reward: -21.5500,                 loss: nan
env3_first_0:                 episode reward: 22.0000,                 loss: nan
env3_second_0:                 episode reward: -22.0000,                 loss: nan
env4_first_0:                 episode reward: 21.2000,                 loss: nan
env4_second_0:                 episode reward: -21.2000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 1563.8,                last time consumption/overall running time: 583.9032s / 168409.8108 s
env0_first_0:                 episode reward: 23.4500,                 loss: 0.0105
env0_second_0:                 episode reward: -23.4500,                 loss: nan
env1_first_0:                 episode reward: 23.4000,                 loss: nan
env1_second_0:                 episode reward: -23.4000,                 loss: nan
env2_first_0:                 episode reward: 23.5500,                 loss: nan
env2_second_0:                 episode reward: -23.5500,                 loss: nan
env3_first_0:                 episode reward: 23.6000,                 loss: nan
env3_second_0:                 episode reward: -23.6000,                 loss: nan
env4_first_0:                 episode reward: 23.0500,                 loss: nan
env4_second_0:                 episode reward: -23.0500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 1691.6,                last time consumption/overall running time: 641.2946s / 169051.1054 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0100
env0_second_0:                 episode reward: -20.4500,                 loss: nan
env1_first_0:                 episode reward: 19.1500,                 loss: nan
env1_second_0:                 episode reward: -19.1500,                 loss: nan
env2_first_0:                 episode reward: 20.5000,                 loss: nan
env2_second_0:                 episode reward: -20.5000,                 loss: nan
env3_first_0:                 episode reward: 20.9500,                 loss: nan
env3_second_0:                 episode reward: -20.9500,                 loss: nan
env4_first_0:                 episode reward: 18.7000,                 loss: nan
env4_second_0:                 episode reward: -18.7000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 1634.9,                last time consumption/overall running time: 606.6607s / 169657.7660 s
env0_first_0:                 episode reward: 21.0500,                 loss: 0.0094
env0_second_0:                 episode reward: -21.0500,                 loss: nan
env1_first_0:                 episode reward: 21.4000,                 loss: nan
env1_second_0:                 episode reward: -21.4000,                 loss: nan
env2_first_0:                 episode reward: 20.4500,                 loss: nan
env2_second_0:                 episode reward: -20.4500,                 loss: nan
env3_first_0:                 episode reward: 20.1500,                 loss: nan
env3_second_0:                 episode reward: -20.1500,                 loss: nan
env4_first_0:                 episode reward: 21.7000,                 loss: nan
env4_second_0:                 episode reward: -21.7000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1700.7,                last time consumption/overall running time: 637.8832s / 170295.6492 s
env0_first_0:                 episode reward: 21.8000,                 loss: 0.0095
env0_second_0:                 episode reward: -21.8000,                 loss: nan
env1_first_0:                 episode reward: 21.2000,                 loss: nan
env1_second_0:                 episode reward: -21.2000,                 loss: nan
env2_first_0:                 episode reward: 21.4500,                 loss: nan
env2_second_0:                 episode reward: -21.4500,                 loss: nan
env3_first_0:                 episode reward: 20.7500,                 loss: nan
env3_second_0:                 episode reward: -20.7500,                 loss: nan
env4_first_0:                 episode reward: 21.2500,                 loss: nan
env4_second_0:                 episode reward: -21.2500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 1599.5,                last time consumption/overall running time: 590.4233s / 170886.0725 s
env0_first_0:                 episode reward: 20.0000,                 loss: 0.0098
env0_second_0:                 episode reward: -20.0000,                 loss: nan
env1_first_0:                 episode reward: 20.2000,                 loss: nan
env1_second_0:                 episode reward: -20.2000,                 loss: nan
env2_first_0:                 episode reward: 20.5000,                 loss: nan
env2_second_0:                 episode reward: -20.5000,                 loss: nan
env3_first_0:                 episode reward: 19.2500,                 loss: nan
env3_second_0:                 episode reward: -19.2500,                 loss: nan
env4_first_0:                 episode reward: 21.6500,                 loss: nan
env4_second_0:                 episode reward: -21.6500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1604.15,                last time consumption/overall running time: 594.1777s / 171480.2502 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0099
env0_second_0:                 episode reward: -20.9000,                 loss: nan
env1_first_0:                 episode reward: 19.9500,                 loss: nan
env1_second_0:                 episode reward: -19.9500,                 loss: nan
env2_first_0:                 episode reward: 20.6000,                 loss: nan
env2_second_0:                 episode reward: -20.6000,                 loss: nan
env3_first_0:                 episode reward: 21.2500,                 loss: nan
env3_second_0:                 episode reward: -21.2500,                 loss: nan
env4_first_0:                 episode reward: 20.5000,                 loss: nan
env4_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 1598.7,                last time consumption/overall running time: 591.6715s / 172071.9217 s
env0_first_0:                 episode reward: 22.7000,                 loss: 0.0098
env0_second_0:                 episode reward: -22.7000,                 loss: 0.0204
env1_first_0:                 episode reward: 23.1500,                 loss: nan
env1_second_0:                 episode reward: -23.1500,                 loss: nan
env2_first_0:                 episode reward: 23.4500,                 loss: nan
env2_second_0:                 episode reward: -23.4500,                 loss: nan
env3_first_0:                 episode reward: 22.8000,                 loss: nan
env3_second_0:                 episode reward: -22.8000,                 loss: nan
env4_first_0:                 episode reward: 22.9500,                 loss: nan
env4_second_0:                 episode reward: -22.9500,                 loss: nan
Score delta: 50.2, update the opponent.
Episode: 4241/10000 (42.4100%),                 avg. length: 4230.95,                last time consumption/overall running time: 1579.6690s / 173651.5907 s
env0_first_0:                 episode reward: 10.0500,                 loss: nan
env0_second_0:                 episode reward: -10.0500,                 loss: 0.0155
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 5.2500,                 loss: nan
env2_second_0:                 episode reward: -5.2500,                 loss: nan
env3_first_0:                 episode reward: 10.1000,                 loss: nan
env3_second_0:                 episode reward: -10.1000,                 loss: nan
env4_first_0:                 episode reward: 11.4500,                 loss: nan
env4_second_0:                 episode reward: -11.4500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 4300.95,                last time consumption/overall running time: 1596.7310s / 175248.3217 s
env0_first_0:                 episode reward: -12.1500,                 loss: nan
env0_second_0:                 episode reward: 12.1500,                 loss: 0.0149
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
env2_first_0:                 episode reward: -25.4500,                 loss: nan
env2_second_0:                 episode reward: 25.4500,                 loss: nan
env3_first_0:                 episode reward: -18.7500,                 loss: nan
env3_second_0:                 episode reward: 18.7500,                 loss: nan
env4_first_0:                 episode reward: -14.8500,                 loss: nan
env4_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 5929.6,                last time consumption/overall running time: 2200.6912s / 177449.0129 s
env0_first_0:                 episode reward: -76.4000,                 loss: 0.0148
env0_second_0:                 episode reward: 76.4000,                 loss: 0.0148
env1_first_0:                 episode reward: -70.6000,                 loss: nan
env1_second_0:                 episode reward: 70.6000,                 loss: nan
env2_first_0:                 episode reward: -74.0000,                 loss: nan
env2_second_0:                 episode reward: 74.0000,                 loss: nan
env3_first_0:                 episode reward: -74.2500,                 loss: nan
env3_second_0:                 episode reward: 74.2500,                 loss: nan
env4_first_0:                 episode reward: -76.7500,                 loss: nan
env4_second_0:                 episode reward: 76.7500,                 loss: nan
Score delta: 61.4, update the opponent.
Episode: 4301/10000 (43.0100%),                 avg. length: 2664.6,                last time consumption/overall running time: 1004.2464s / 178453.2593 s
env0_first_0:                 episode reward: 10.0000,                 loss: 0.0152
env0_second_0:                 episode reward: -10.0000,                 loss: nan
env1_first_0:                 episode reward: 13.5000,                 loss: nan
env1_second_0:                 episode reward: -13.5000,                 loss: nan
env2_first_0:                 episode reward: 12.5000,                 loss: nan
env2_second_0:                 episode reward: -12.5000,                 loss: nan
env3_first_0:                 episode reward: 11.8000,                 loss: nan
env3_second_0:                 episode reward: -11.8000,                 loss: nan
env4_first_0:                 episode reward: 11.4000,                 loss: nan
env4_second_0:                 episode reward: -11.4000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 2056.4,                last time consumption/overall running time: 774.3717s / 179227.6310 s
env0_first_0:                 episode reward: 17.7000,                 loss: 0.0145
env0_second_0:                 episode reward: -17.7000,                 loss: nan
env1_first_0:                 episode reward: 17.8500,                 loss: nan
env1_second_0:                 episode reward: -17.8500,                 loss: nan
env2_first_0:                 episode reward: 18.3500,                 loss: nan
env2_second_0:                 episode reward: -18.3500,                 loss: nan
env3_first_0:                 episode reward: 17.4000,                 loss: nan
env3_second_0:                 episode reward: -17.4000,                 loss: nan
env4_first_0:                 episode reward: 17.5000,                 loss: nan
env4_second_0:                 episode reward: -17.5000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 2934.45,                last time consumption/overall running time: 1104.7590s / 180332.3900 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.0129
env0_second_0:                 episode reward: 5.9000,                 loss: nan
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
env2_first_0:                 episode reward: -4.1000,                 loss: nan
env2_second_0:                 episode reward: 4.1000,                 loss: nan
env3_first_0:                 episode reward: -4.6000,                 loss: nan
env3_second_0:                 episode reward: 4.6000,                 loss: nan
env4_first_0:                 episode reward: -4.7500,                 loss: nan
env4_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 2733.85,                last time consumption/overall running time: 1018.3524s / 181350.7423 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0142
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 1968.75,                last time consumption/overall running time: 731.1093s / 182081.8516 s
env0_first_0:                 episode reward: 19.9000,                 loss: 0.0138
env0_second_0:                 episode reward: -19.9000,                 loss: nan
env1_first_0:                 episode reward: 20.1000,                 loss: nan
env1_second_0:                 episode reward: -20.1000,                 loss: nan
env2_first_0:                 episode reward: 19.4000,                 loss: nan
env2_second_0:                 episode reward: -19.4000,                 loss: nan
env3_first_0:                 episode reward: 18.8000,                 loss: nan
env3_second_0:                 episode reward: -18.8000,                 loss: nan
env4_first_0:                 episode reward: 19.1000,                 loss: nan
env4_second_0:                 episode reward: -19.1000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 1852.6,                last time consumption/overall running time: 689.4246s / 182771.2762 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0127
env0_second_0:                 episode reward: -20.5500,                 loss: nan
env1_first_0:                 episode reward: 20.0000,                 loss: nan
env1_second_0:                 episode reward: -20.0000,                 loss: nan
env2_first_0:                 episode reward: 19.8000,                 loss: nan
env2_second_0:                 episode reward: -19.8000,                 loss: nan
env3_first_0:                 episode reward: 19.9500,                 loss: nan
env3_second_0:                 episode reward: -19.9500,                 loss: nan
env4_first_0:                 episode reward: 19.9500,                 loss: nan
env4_second_0:                 episode reward: -19.9500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1812.6,                last time consumption/overall running time: 664.0812s / 183435.3574 s
env0_first_0:                 episode reward: 19.5500,                 loss: 0.0129
env0_second_0:                 episode reward: -19.5500,                 loss: nan
env1_first_0:                 episode reward: 19.2500,                 loss: nan
env1_second_0:                 episode reward: -19.2500,                 loss: nan
env2_first_0:                 episode reward: 17.8500,                 loss: nan
env2_second_0:                 episode reward: -17.8500,                 loss: nan
env3_first_0:                 episode reward: 19.6500,                 loss: nan
env3_second_0:                 episode reward: -19.6500,                 loss: nan
env4_first_0:                 episode reward: 19.3500,                 loss: nan
env4_second_0:                 episode reward: -19.3500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1770.9,                last time consumption/overall running time: 658.0939s / 184093.4513 s
env0_first_0:                 episode reward: 19.0500,                 loss: 0.0122
env0_second_0:                 episode reward: -19.0500,                 loss: nan
env1_first_0:                 episode reward: 19.2000,                 loss: nan
env1_second_0:                 episode reward: -19.2000,                 loss: nan
env2_first_0:                 episode reward: 19.5000,                 loss: nan
env2_second_0:                 episode reward: -19.5000,                 loss: nan
env3_first_0:                 episode reward: 19.7000,                 loss: nan
env3_second_0:                 episode reward: -19.7000,                 loss: nan
env4_first_0:                 episode reward: 19.1500,                 loss: nan
env4_second_0:                 episode reward: -19.1500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 2021.65,                last time consumption/overall running time: 754.1781s / 184847.6294 s
env0_first_0:                 episode reward: 15.2500,                 loss: 0.0132
env0_second_0:                 episode reward: -15.2500,                 loss: nan
env1_first_0:                 episode reward: 13.6000,                 loss: nan
env1_second_0:                 episode reward: -13.6000,                 loss: nan
env2_first_0:                 episode reward: 17.3500,                 loss: nan
env2_second_0:                 episode reward: -17.3500,                 loss: nan
env3_first_0:                 episode reward: 16.5500,                 loss: nan
env3_second_0:                 episode reward: -16.5500,                 loss: nan
env4_first_0:                 episode reward: 16.7000,                 loss: nan
env4_second_0:                 episode reward: -16.7000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 2060.8,                last time consumption/overall running time: 753.3199s / 185600.9493 s
env0_first_0:                 episode reward: 15.0000,                 loss: 0.0131
env0_second_0:                 episode reward: -15.0000,                 loss: nan
env1_first_0:                 episode reward: 14.1000,                 loss: nan
env1_second_0:                 episode reward: -14.1000,                 loss: nan
env2_first_0:                 episode reward: 14.9500,                 loss: nan
env2_second_0:                 episode reward: -14.9500,                 loss: nan
env3_first_0:                 episode reward: 15.2000,                 loss: nan
env3_second_0:                 episode reward: -15.2000,                 loss: nan
env4_first_0:                 episode reward: 12.9000,                 loss: nan
env4_second_0:                 episode reward: -12.9000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1925.55,                last time consumption/overall running time: 712.3303s / 186313.2796 s
env0_first_0:                 episode reward: 20.0500,                 loss: 0.0120
env0_second_0:                 episode reward: -20.0500,                 loss: nan
env1_first_0:                 episode reward: 19.6500,                 loss: nan
env1_second_0:                 episode reward: -19.6500,                 loss: nan
env2_first_0:                 episode reward: 20.0500,                 loss: nan
env2_second_0:                 episode reward: -20.0500,                 loss: nan
env3_first_0:                 episode reward: 19.0500,                 loss: nan
env3_second_0:                 episode reward: -19.0500,                 loss: nan
env4_first_0:                 episode reward: 20.7000,                 loss: nan
env4_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 2318.9,                last time consumption/overall running time: 848.4992s / 187161.7787 s
env0_first_0:                 episode reward: 7.6000,                 loss: 0.0113
env0_second_0:                 episode reward: -7.6000,                 loss: nan
env1_first_0:                 episode reward: 8.9500,                 loss: nan
env1_second_0:                 episode reward: -8.9500,                 loss: nan
env2_first_0:                 episode reward: 8.3000,                 loss: nan
env2_second_0:                 episode reward: -8.3000,                 loss: nan
env3_first_0:                 episode reward: 8.7500,                 loss: nan
env3_second_0:                 episode reward: -8.7500,                 loss: nan
env4_first_0:                 episode reward: 9.5500,                 loss: nan
env4_second_0:                 episode reward: -9.5500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1726.95,                last time consumption/overall running time: 634.1355s / 187795.9142 s
env0_first_0:                 episode reward: 18.7000,                 loss: 0.0108
env0_second_0:                 episode reward: -18.7000,                 loss: nan
env1_first_0:                 episode reward: 22.2000,                 loss: nan
env1_second_0:                 episode reward: -22.2000,                 loss: nan
env2_first_0:                 episode reward: 18.9000,                 loss: nan
env2_second_0:                 episode reward: -18.9000,                 loss: nan
env3_first_0:                 episode reward: 18.4500,                 loss: nan
env3_second_0:                 episode reward: -18.4500,                 loss: nan
env4_first_0:                 episode reward: 21.1500,                 loss: nan
env4_second_0:                 episode reward: -21.1500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1821.75,                last time consumption/overall running time: 668.2194s / 188464.1336 s
env0_first_0:                 episode reward: 21.0500,                 loss: 0.0105
env0_second_0:                 episode reward: -21.0500,                 loss: nan
env1_first_0:                 episode reward: 21.4000,                 loss: nan
env1_second_0:                 episode reward: -21.4000,                 loss: nan
env2_first_0:                 episode reward: 20.9000,                 loss: nan
env2_second_0:                 episode reward: -20.9000,                 loss: nan
env3_first_0:                 episode reward: 21.4500,                 loss: nan
env3_second_0:                 episode reward: -21.4500,                 loss: nan
env4_first_0:                 episode reward: 21.1000,                 loss: nan
env4_second_0:                 episode reward: -21.1000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1775.3,                last time consumption/overall running time: 643.1333s / 189107.2669 s
env0_first_0:                 episode reward: 20.3000,                 loss: 0.0096
env0_second_0:                 episode reward: -20.3000,                 loss: nan
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
env2_first_0:                 episode reward: 20.3500,                 loss: nan
env2_second_0:                 episode reward: -20.3500,                 loss: nan
env3_first_0:                 episode reward: 21.2500,                 loss: nan
env3_second_0:                 episode reward: -21.2500,                 loss: nan
env4_first_0:                 episode reward: 20.5500,                 loss: nan
env4_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1705.15,                last time consumption/overall running time: 621.3106s / 189728.5775 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0092
env0_second_0:                 episode reward: -21.0000,                 loss: nan
env1_first_0:                 episode reward: 20.3500,                 loss: nan
env1_second_0:                 episode reward: -20.3500,                 loss: nan
env2_first_0:                 episode reward: 21.5500,                 loss: nan
env2_second_0:                 episode reward: -21.5500,                 loss: nan
env3_first_0:                 episode reward: 19.5000,                 loss: nan
env3_second_0:                 episode reward: -19.5000,                 loss: nan
env4_first_0:                 episode reward: 20.4500,                 loss: nan
env4_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1713.3,                last time consumption/overall running time: 620.9270s / 190349.5045 s
env0_first_0:                 episode reward: 18.3500,                 loss: 0.0093
env0_second_0:                 episode reward: -18.3500,                 loss: nan
env1_first_0:                 episode reward: 18.7000,                 loss: nan
env1_second_0:                 episode reward: -18.7000,                 loss: nan
env2_first_0:                 episode reward: 19.4500,                 loss: nan
env2_second_0:                 episode reward: -19.4500,                 loss: nan
env3_first_0:                 episode reward: 19.3500,                 loss: nan
env3_second_0:                 episode reward: -19.3500,                 loss: nan
env4_first_0:                 episode reward: 18.9500,                 loss: nan
env4_second_0:                 episode reward: -18.9500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1615.55,                last time consumption/overall running time: 595.4389s / 190944.9434 s
env0_first_0:                 episode reward: 22.0000,                 loss: 0.0090
env0_second_0:                 episode reward: -22.0000,                 loss: nan
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
env2_first_0:                 episode reward: 21.4000,                 loss: nan
env2_second_0:                 episode reward: -21.4000,                 loss: nan
env3_first_0:                 episode reward: 20.6000,                 loss: nan
env3_second_0:                 episode reward: -20.6000,                 loss: nan
env4_first_0:                 episode reward: 21.3500,                 loss: nan
env4_second_0:                 episode reward: -21.3500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1611.6,                last time consumption/overall running time: 592.8577s / 191537.8011 s
env0_first_0:                 episode reward: 21.6500,                 loss: 0.0095
env0_second_0:                 episode reward: -21.6500,                 loss: nan
env1_first_0:                 episode reward: 21.9500,                 loss: nan
env1_second_0:                 episode reward: -21.9500,                 loss: nan
env2_first_0:                 episode reward: 21.9500,                 loss: nan
env2_second_0:                 episode reward: -21.9500,                 loss: nan
env3_first_0:                 episode reward: 21.8000,                 loss: nan
env3_second_0:                 episode reward: -21.8000,                 loss: nan
env4_first_0:                 episode reward: 21.8500,                 loss: nan
env4_second_0:                 episode reward: -21.8500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1605.4,                last time consumption/overall running time: 595.8338s / 192133.6349 s
env0_first_0:                 episode reward: 22.4000,                 loss: 0.0087
env0_second_0:                 episode reward: -22.4000,                 loss: nan
env1_first_0:                 episode reward: 21.8500,                 loss: nan
env1_second_0:                 episode reward: -21.8500,                 loss: nan
env2_first_0:                 episode reward: 22.6000,                 loss: nan
env2_second_0:                 episode reward: -22.6000,                 loss: nan
env3_first_0:                 episode reward: 21.7000,                 loss: nan
env3_second_0:                 episode reward: -21.7000,                 loss: nan
env4_first_0:                 episode reward: 22.1000,                 loss: nan
env4_second_0:                 episode reward: -22.1000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1510.65,                last time consumption/overall running time: 564.4623s / 192698.0972 s
env0_first_0:                 episode reward: 22.4000,                 loss: 0.0084
env0_second_0:                 episode reward: -22.4000,                 loss: nan
env1_first_0:                 episode reward: 22.7500,                 loss: nan
env1_second_0:                 episode reward: -22.7500,                 loss: nan
env2_first_0:                 episode reward: 22.6000,                 loss: nan
env2_second_0:                 episode reward: -22.6000,                 loss: nan
env3_first_0:                 episode reward: 22.6000,                 loss: nan
env3_second_0:                 episode reward: -22.6000,                 loss: nan
env4_first_0:                 episode reward: 22.3500,                 loss: nan
env4_second_0:                 episode reward: -22.3500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1533.8,                last time consumption/overall running time: 565.3221s / 193263.4193 s
env0_first_0:                 episode reward: 23.1500,                 loss: 0.0084
env0_second_0:                 episode reward: -23.1500,                 loss: nan
env1_first_0:                 episode reward: 23.1000,                 loss: nan
env1_second_0:                 episode reward: -23.1000,                 loss: nan
env2_first_0:                 episode reward: 22.9000,                 loss: nan
env2_second_0:                 episode reward: -22.9000,                 loss: nan
env3_first_0:                 episode reward: 22.3000,                 loss: nan
env3_second_0:                 episode reward: -22.3000,                 loss: nan
env4_first_0:                 episode reward: 22.7500,                 loss: nan
env4_second_0:                 episode reward: -22.7500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1907.7,                last time consumption/overall running time: 707.9420s / 193971.3613 s
env0_first_0:                 episode reward: 14.3500,                 loss: 0.0088
env0_second_0:                 episode reward: -14.3500,                 loss: nan
env1_first_0:                 episode reward: 14.2000,                 loss: nan
env1_second_0:                 episode reward: -14.2000,                 loss: nan
env2_first_0:                 episode reward: 13.6500,                 loss: nan
env2_second_0:                 episode reward: -13.6500,                 loss: nan
env3_first_0:                 episode reward: 14.5000,                 loss: nan
env3_second_0:                 episode reward: -14.5000,                 loss: nan
env4_first_0:                 episode reward: 13.7500,                 loss: nan
env4_second_0:                 episode reward: -13.7500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1618.7,                last time consumption/overall running time: 595.7045s / 194567.0658 s
env0_first_0:                 episode reward: 21.1500,                 loss: 0.0099
env0_second_0:                 episode reward: -21.1500,                 loss: nan
env1_first_0:                 episode reward: 21.1500,                 loss: nan
env1_second_0:                 episode reward: -21.1500,                 loss: nan
env2_first_0:                 episode reward: 21.5000,                 loss: nan
env2_second_0:                 episode reward: -21.5000,                 loss: nan
env3_first_0:                 episode reward: 21.7000,                 loss: nan
env3_second_0:                 episode reward: -21.7000,                 loss: nan
env4_first_0:                 episode reward: 21.9000,                 loss: nan
env4_second_0:                 episode reward: -21.9000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1546.4,                last time consumption/overall running time: 575.1441s / 195142.2099 s
env0_first_0:                 episode reward: 21.4000,                 loss: 0.0102
env0_second_0:                 episode reward: -21.4000,                 loss: nan
env1_first_0:                 episode reward: 21.8000,                 loss: nan
env1_second_0:                 episode reward: -21.8000,                 loss: nan
env2_first_0:                 episode reward: 21.4000,                 loss: nan
env2_second_0:                 episode reward: -21.4000,                 loss: nan
env3_first_0:                 episode reward: 22.8500,                 loss: nan
env3_second_0:                 episode reward: -22.8500,                 loss: nan
env4_first_0:                 episode reward: 21.4500,                 loss: nan
env4_second_0:                 episode reward: -21.4500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 3401.35,                last time consumption/overall running time: 1254.7810s / 196396.9909 s
env0_first_0:                 episode reward: -22.5000,                 loss: 0.0110
env0_second_0:                 episode reward: 22.5000,                 loss: nan
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
env2_first_0:                 episode reward: -20.8000,                 loss: nan
env2_second_0:                 episode reward: 20.8000,                 loss: nan
env3_first_0:                 episode reward: -19.7500,                 loss: nan
env3_second_0:                 episode reward: 19.7500,                 loss: nan
env4_first_0:                 episode reward: -21.9500,                 loss: nan
env4_second_0:                 episode reward: 21.9500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1698.15,                last time consumption/overall running time: 631.6477s / 197028.6386 s
env0_first_0:                 episode reward: 20.1500,                 loss: 0.0111
env0_second_0:                 episode reward: -20.1500,                 loss: nan
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
env2_first_0:                 episode reward: 21.3500,                 loss: nan
env2_second_0:                 episode reward: -21.3500,                 loss: nan
env3_first_0:                 episode reward: 21.4500,                 loss: nan
env3_second_0:                 episode reward: -21.4500,                 loss: nan
env4_first_0:                 episode reward: 20.7500,                 loss: nan
env4_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1596.0,                last time consumption/overall running time: 594.3956s / 197623.0342 s
env0_first_0:                 episode reward: 21.5500,                 loss: 0.0110
env0_second_0:                 episode reward: -21.5500,                 loss: nan
env1_first_0:                 episode reward: 21.9000,                 loss: nan
env1_second_0:                 episode reward: -21.9000,                 loss: nan
env2_first_0:                 episode reward: 21.1500,                 loss: nan
env2_second_0:                 episode reward: -21.1500,                 loss: nan
env3_first_0:                 episode reward: 21.1000,                 loss: nan
env3_second_0:                 episode reward: -21.1000,                 loss: nan
env4_first_0:                 episode reward: 21.0500,                 loss: nan
env4_second_0:                 episode reward: -21.0500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1589.35,                last time consumption/overall running time: 590.2652s / 198213.2994 s
env0_first_0:                 episode reward: 22.3500,                 loss: 0.0118
env0_second_0:                 episode reward: -22.3500,                 loss: nan
env1_first_0:                 episode reward: 21.9000,                 loss: nan
env1_second_0:                 episode reward: -21.9000,                 loss: nan
env2_first_0:                 episode reward: 22.6500,                 loss: nan
env2_second_0:                 episode reward: -22.6500,                 loss: nan
env3_first_0:                 episode reward: 22.1000,                 loss: nan
env3_second_0:                 episode reward: -22.1000,                 loss: nan
env4_first_0:                 episode reward: 22.0000,                 loss: nan
env4_second_0:                 episode reward: -22.0000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1643.2,                last time consumption/overall running time: 608.5834s / 198821.8828 s
env0_first_0:                 episode reward: 19.9500,                 loss: 0.0098
env0_second_0:                 episode reward: -19.9500,                 loss: nan
env1_first_0:                 episode reward: 20.1000,                 loss: nan
env1_second_0:                 episode reward: -20.1000,                 loss: nan
env2_first_0:                 episode reward: 20.9500,                 loss: nan
env2_second_0:                 episode reward: -20.9500,                 loss: nan
env3_first_0:                 episode reward: 20.5500,                 loss: nan
env3_second_0:                 episode reward: -20.5500,                 loss: nan
env4_first_0:                 episode reward: 21.7500,                 loss: nan
env4_second_0:                 episode reward: -21.7500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1751.55,                last time consumption/overall running time: 644.7094s / 199466.5922 s
env0_first_0:                 episode reward: 16.1500,                 loss: 0.0094
env0_second_0:                 episode reward: -16.1500,                 loss: nan
env1_first_0:                 episode reward: 17.5500,                 loss: nan
env1_second_0:                 episode reward: -17.5500,                 loss: nan
env2_first_0:                 episode reward: 17.9000,                 loss: nan
env2_second_0:                 episode reward: -17.9000,                 loss: nan
env3_first_0:                 episode reward: 17.5000,                 loss: nan
env3_second_0:                 episode reward: -17.5000,                 loss: nan
env4_first_0:                 episode reward: 18.2000,                 loss: nan
env4_second_0:                 episode reward: -18.2000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1680.35,                last time consumption/overall running time: 620.9983s / 200087.5905 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0093
env0_second_0:                 episode reward: -20.9500,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
env2_first_0:                 episode reward: 21.3000,                 loss: nan
env2_second_0:                 episode reward: -21.3000,                 loss: nan
env3_first_0:                 episode reward: 21.5000,                 loss: nan
env3_second_0:                 episode reward: -21.5000,                 loss: nan
env4_first_0:                 episode reward: 21.2000,                 loss: nan
env4_second_0:                 episode reward: -21.2000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 1567.8,                last time consumption/overall running time: 582.9650s / 200670.5555 s
env0_first_0:                 episode reward: 22.0000,                 loss: 0.0094
env0_second_0:                 episode reward: -22.0000,                 loss: nan
env1_first_0:                 episode reward: 21.9500,                 loss: nan
env1_second_0:                 episode reward: -21.9500,                 loss: nan
env2_first_0:                 episode reward: 21.6000,                 loss: nan
env2_second_0:                 episode reward: -21.6000,                 loss: nan
env3_first_0:                 episode reward: 22.0500,                 loss: nan
env3_second_0:                 episode reward: -22.0500,                 loss: nan
env4_first_0:                 episode reward: 22.7500,                 loss: nan
env4_second_0:                 episode reward: -22.7500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1506.3,                last time consumption/overall running time: 553.7630s / 201224.3185 s
env0_first_0:                 episode reward: 21.7500,                 loss: 0.0096
env0_second_0:                 episode reward: -21.7500,                 loss: nan
env1_first_0:                 episode reward: 21.4000,                 loss: nan
env1_second_0:                 episode reward: -21.4000,                 loss: nan
env2_first_0:                 episode reward: 22.8000,                 loss: nan
env2_second_0:                 episode reward: -22.8000,                 loss: nan
env3_first_0:                 episode reward: 21.9000,                 loss: nan
env3_second_0:                 episode reward: -21.9000,                 loss: nan
env4_first_0:                 episode reward: 22.2000,                 loss: nan
env4_second_0:                 episode reward: -22.2000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1489.1,                last time consumption/overall running time: 545.7757s / 201770.0943 s
env0_first_0:                 episode reward: 22.5500,                 loss: 0.0094
env0_second_0:                 episode reward: -22.5500,                 loss: nan
env1_first_0:                 episode reward: 22.3500,                 loss: nan
env1_second_0:                 episode reward: -22.3500,                 loss: nan
env2_first_0:                 episode reward: 22.0000,                 loss: nan
env2_second_0:                 episode reward: -22.0000,                 loss: nan
env3_first_0:                 episode reward: 22.1000,                 loss: nan
env3_second_0:                 episode reward: -22.1000,                 loss: nan
env4_first_0:                 episode reward: 22.5500,                 loss: nan
env4_second_0:                 episode reward: -22.5500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1497.05,                last time consumption/overall running time: 558.6762s / 202328.7704 s
env0_first_0:                 episode reward: 22.7500,                 loss: 0.0093
env0_second_0:                 episode reward: -22.7500,                 loss: nan
env1_first_0:                 episode reward: 22.0500,                 loss: nan
env1_second_0:                 episode reward: -22.0500,                 loss: nan
env2_first_0:                 episode reward: 22.5000,                 loss: nan
env2_second_0:                 episode reward: -22.5000,                 loss: nan
env3_first_0:                 episode reward: 22.0500,                 loss: nan
env3_second_0:                 episode reward: -22.0500,                 loss: nan
env4_first_0:                 episode reward: 22.5000,                 loss: nan
env4_second_0:                 episode reward: -22.5000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 2034.55,                last time consumption/overall running time: 752.2595s / 203081.0299 s
env0_first_0:                 episode reward: 12.1000,                 loss: 0.0092
env0_second_0:                 episode reward: -12.1000,                 loss: nan
env1_first_0:                 episode reward: 12.4500,                 loss: nan
env1_second_0:                 episode reward: -12.4500,                 loss: nan
env2_first_0:                 episode reward: 12.6500,                 loss: nan
env2_second_0:                 episode reward: -12.6500,                 loss: nan
env3_first_0:                 episode reward: 11.8500,                 loss: nan
env3_second_0:                 episode reward: -11.8500,                 loss: nan
env4_first_0:                 episode reward: 12.3500,                 loss: nan
env4_second_0:                 episode reward: -12.3500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1560.45,                last time consumption/overall running time: 581.8357s / 203662.8656 s
env0_first_0:                 episode reward: 22.0000,                 loss: 0.0098
env0_second_0:                 episode reward: -22.0000,                 loss: nan
env1_first_0:                 episode reward: 21.3500,                 loss: nan
env1_second_0:                 episode reward: -21.3500,                 loss: nan
env2_first_0:                 episode reward: 22.4000,                 loss: nan
env2_second_0:                 episode reward: -22.4000,                 loss: nan
env3_first_0:                 episode reward: 21.8000,                 loss: nan
env3_second_0:                 episode reward: -21.8000,                 loss: nan
env4_first_0:                 episode reward: 21.6500,                 loss: nan
env4_second_0:                 episode reward: -21.6500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1540.8,                last time consumption/overall running time: 579.0502s / 204241.9159 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0099
env0_second_0:                 episode reward: -21.0000,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
env2_first_0:                 episode reward: 21.0500,                 loss: nan
env2_second_0:                 episode reward: -21.0500,                 loss: nan
env3_first_0:                 episode reward: 21.3000,                 loss: nan
env3_second_0:                 episode reward: -21.3000,                 loss: nan
env4_first_0:                 episode reward: 20.6500,                 loss: nan
env4_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 1569.75,                last time consumption/overall running time: 590.4775s / 204832.3933 s
env0_first_0:                 episode reward: 21.4500,                 loss: 0.0096
env0_second_0:                 episode reward: -21.4500,                 loss: nan
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
env2_first_0:                 episode reward: 20.9500,                 loss: nan
env2_second_0:                 episode reward: -20.9500,                 loss: nan
env3_first_0:                 episode reward: 20.8000,                 loss: nan
env3_second_0:                 episode reward: -20.8000,                 loss: nan
env4_first_0:                 episode reward: 22.1000,                 loss: nan
env4_second_0:                 episode reward: -22.1000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1621.1,                last time consumption/overall running time: 625.2178s / 205457.6112 s
env0_first_0:                 episode reward: 21.5500,                 loss: 0.0091
env0_second_0:                 episode reward: -21.5500,                 loss: nan
env1_first_0:                 episode reward: 21.2500,                 loss: nan
env1_second_0:                 episode reward: -21.2500,                 loss: nan
env2_first_0:                 episode reward: 21.8000,                 loss: nan
env2_second_0:                 episode reward: -21.8000,                 loss: nan
env3_first_0:                 episode reward: 21.2000,                 loss: nan
env3_second_0:                 episode reward: -21.2000,                 loss: nan
env4_first_0:                 episode reward: 21.3000,                 loss: nan
env4_second_0:                 episode reward: -21.3000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1632.55,                last time consumption/overall running time: 615.4305s / 206073.0416 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0091
env0_second_0:                 episode reward: -20.4500,                 loss: nan
env1_first_0:                 episode reward: 19.9000,                 loss: nan
env1_second_0:                 episode reward: -19.9000,                 loss: nan
env2_first_0:                 episode reward: 19.7000,                 loss: nan
env2_second_0:                 episode reward: -19.7000,                 loss: nan
env3_first_0:                 episode reward: 20.6500,                 loss: nan
env3_second_0:                 episode reward: -20.6500,                 loss: nan
env4_first_0:                 episode reward: 20.5500,                 loss: nan
env4_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 2500.3,                last time consumption/overall running time: 935.9517s / 207008.9934 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -2.9000,                 loss: nan
env4_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 2172.75,                last time consumption/overall running time: 824.9884s / 207833.9818 s
env0_first_0:                 episode reward: 12.9500,                 loss: 0.0105
env0_second_0:                 episode reward: -12.9500,                 loss: nan
env1_first_0:                 episode reward: 12.9500,                 loss: nan
env1_second_0:                 episode reward: -12.9500,                 loss: nan
env2_first_0:                 episode reward: 9.8500,                 loss: nan
env2_second_0:                 episode reward: -9.8500,                 loss: nan
env3_first_0:                 episode reward: 10.4000,                 loss: nan
env3_second_0:                 episode reward: -10.4000,                 loss: nan
env4_first_0:                 episode reward: 11.4000,                 loss: nan
env4_second_0:                 episode reward: -11.4000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1685.85,                last time consumption/overall running time: 637.3303s / 208471.3121 s
env0_first_0:                 episode reward: 20.3000,                 loss: 0.0103
env0_second_0:                 episode reward: -20.3000,                 loss: nan
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
env2_first_0:                 episode reward: 20.6000,                 loss: nan
env2_second_0:                 episode reward: -20.6000,                 loss: nan
env3_first_0:                 episode reward: 20.0000,                 loss: nan
env3_second_0:                 episode reward: -20.0000,                 loss: nan
env4_first_0:                 episode reward: 19.7000,                 loss: nan
env4_second_0:                 episode reward: -19.7000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1595.55,                last time consumption/overall running time: 598.7106s / 209070.0227 s
env0_first_0:                 episode reward: 22.4000,                 loss: 0.0107
env0_second_0:                 episode reward: -22.4000,                 loss: nan
env1_first_0:                 episode reward: 21.4500,                 loss: nan
env1_second_0:                 episode reward: -21.4500,                 loss: nan
env2_first_0:                 episode reward: 22.0500,                 loss: nan
env2_second_0:                 episode reward: -22.0500,                 loss: nan
env3_first_0:                 episode reward: 22.0000,                 loss: nan
env3_second_0:                 episode reward: -22.0000,                 loss: nan
env4_first_0:                 episode reward: 21.3000,                 loss: nan
env4_second_0:                 episode reward: -21.3000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1726.8,                last time consumption/overall running time: 653.7138s / 209723.7365 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0107
env0_second_0:                 episode reward: -20.6000,                 loss: nan
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
env2_first_0:                 episode reward: 21.0500,                 loss: nan
env2_second_0:                 episode reward: -21.0500,                 loss: nan
env3_first_0:                 episode reward: 21.3500,                 loss: nan
env3_second_0:                 episode reward: -21.3500,                 loss: nan
env4_first_0:                 episode reward: 21.1000,                 loss: nan
env4_second_0:                 episode reward: -21.1000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1822.0,                last time consumption/overall running time: 693.8948s / 210417.6313 s
env0_first_0:                 episode reward: 18.5500,                 loss: 0.0092
env0_second_0:                 episode reward: -18.5500,                 loss: nan
env1_first_0:                 episode reward: 19.2500,                 loss: nan
env1_second_0:                 episode reward: -19.2500,                 loss: nan
env2_first_0:                 episode reward: 19.4000,                 loss: nan
env2_second_0:                 episode reward: -19.4000,                 loss: nan
env3_first_0:                 episode reward: 19.3000,                 loss: nan
env3_second_0:                 episode reward: -19.3000,                 loss: nan
env4_first_0:                 episode reward: 19.8500,                 loss: nan
env4_second_0:                 episode reward: -19.8500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1694.7,                last time consumption/overall running time: 643.2673s / 211060.8986 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0087
env0_second_0:                 episode reward: -20.8500,                 loss: nan
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
env2_first_0:                 episode reward: 20.1000,                 loss: nan
env2_second_0:                 episode reward: -20.1000,                 loss: nan
env3_first_0:                 episode reward: 20.9500,                 loss: nan
env3_second_0:                 episode reward: -20.9500,                 loss: nan
env4_first_0:                 episode reward: 19.9500,                 loss: nan
env4_second_0:                 episode reward: -19.9500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1577.55,                last time consumption/overall running time: 593.0554s / 211653.9540 s
env0_first_0:                 episode reward: 22.4000,                 loss: 0.0086
env0_second_0:                 episode reward: -22.4000,                 loss: nan
env1_first_0:                 episode reward: 22.6000,                 loss: nan
env1_second_0:                 episode reward: -22.6000,                 loss: nan
env2_first_0:                 episode reward: 21.9500,                 loss: nan
env2_second_0:                 episode reward: -21.9500,                 loss: nan
env3_first_0:                 episode reward: 21.4000,                 loss: nan
env3_second_0:                 episode reward: -21.4000,                 loss: nan
env4_first_0:                 episode reward: 20.6500,                 loss: nan
env4_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1611.5,                last time consumption/overall running time: 608.8339s / 212262.7878 s
env0_first_0:                 episode reward: 22.7500,                 loss: 0.0081
env0_second_0:                 episode reward: -22.7500,                 loss: nan
env1_first_0:                 episode reward: 22.5000,                 loss: nan
env1_second_0:                 episode reward: -22.5000,                 loss: nan
env2_first_0:                 episode reward: 22.1500,                 loss: nan
env2_second_0:                 episode reward: -22.1500,                 loss: nan
env3_first_0:                 episode reward: 23.0000,                 loss: nan
env3_second_0:                 episode reward: -23.0000,                 loss: nan
env4_first_0:                 episode reward: 22.5000,                 loss: nan
env4_second_0:                 episode reward: -22.5000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1836.35,                last time consumption/overall running time: 700.1520s / 212962.9398 s
env0_first_0:                 episode reward: 15.4000,                 loss: 0.0082
env0_second_0:                 episode reward: -15.4000,                 loss: nan
env1_first_0:                 episode reward: 15.6500,                 loss: nan
env1_second_0:                 episode reward: -15.6500,                 loss: nan
env2_first_0:                 episode reward: 15.3500,                 loss: nan
env2_second_0:                 episode reward: -15.3500,                 loss: nan
env3_first_0:                 episode reward: 15.9000,                 loss: nan
env3_second_0:                 episode reward: -15.9000,                 loss: nan
env4_first_0:                 episode reward: 15.8500,                 loss: nan
env4_second_0:                 episode reward: -15.8500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1803.75,                last time consumption/overall running time: 677.8044s / 213640.7442 s
env0_first_0:                 episode reward: 16.7000,                 loss: 0.0089
env0_second_0:                 episode reward: -16.7000,                 loss: nan
env1_first_0:                 episode reward: 17.0000,                 loss: nan
env1_second_0:                 episode reward: -17.0000,                 loss: nan
env2_first_0:                 episode reward: 16.9500,                 loss: nan
env2_second_0:                 episode reward: -16.9500,                 loss: nan
env3_first_0:                 episode reward: 16.5000,                 loss: nan
env3_second_0:                 episode reward: -16.5000,                 loss: nan
env4_first_0:                 episode reward: 16.7500,                 loss: nan
env4_second_0:                 episode reward: -16.7500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1656.85,                last time consumption/overall running time: 620.7595s / 214261.5037 s
env0_first_0:                 episode reward: 21.5000,                 loss: 0.0095
env0_second_0:                 episode reward: -21.5000,                 loss: nan
env1_first_0:                 episode reward: 21.1500,                 loss: nan
env1_second_0:                 episode reward: -21.1500,                 loss: nan
env2_first_0:                 episode reward: 20.9000,                 loss: nan
env2_second_0:                 episode reward: -20.9000,                 loss: nan
env3_first_0:                 episode reward: 20.9000,                 loss: nan
env3_second_0:                 episode reward: -20.9000,                 loss: nan
env4_first_0:                 episode reward: 21.2000,                 loss: nan
env4_second_0:                 episode reward: -21.2000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1679.45,                last time consumption/overall running time: 637.7365s / 214899.2402 s
env0_first_0:                 episode reward: 22.3000,                 loss: 0.0101
env0_second_0:                 episode reward: -22.3000,                 loss: nan
env1_first_0:                 episode reward: 22.5500,                 loss: nan
env1_second_0:                 episode reward: -22.5500,                 loss: nan
env2_first_0:                 episode reward: 22.6500,                 loss: nan
env2_second_0:                 episode reward: -22.6500,                 loss: nan
env3_first_0:                 episode reward: 22.7000,                 loss: nan
env3_second_0:                 episode reward: -22.7000,                 loss: nan
env4_first_0:                 episode reward: 22.1000,                 loss: nan
env4_second_0:                 episode reward: -22.1000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 1710.65,                last time consumption/overall running time: 647.2118s / 215546.4520 s
env0_first_0:                 episode reward: 21.5000,                 loss: 0.0095
env0_second_0:                 episode reward: -21.5000,                 loss: nan
env1_first_0:                 episode reward: 21.6500,                 loss: nan
env1_second_0:                 episode reward: -21.6500,                 loss: nan
env2_first_0:                 episode reward: 21.9500,                 loss: nan
env2_second_0:                 episode reward: -21.9500,                 loss: nan
env3_first_0:                 episode reward: 22.0500,                 loss: nan
env3_second_0:                 episode reward: -22.0500,                 loss: nan
env4_first_0:                 episode reward: 21.8000,                 loss: nan
env4_second_0:                 episode reward: -21.8000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 1643.5,                last time consumption/overall running time: 622.6962s / 216169.1482 s
env0_first_0:                 episode reward: 21.2500,                 loss: 0.0091
env0_second_0:                 episode reward: -21.2500,                 loss: nan
env1_first_0:                 episode reward: 21.7500,                 loss: nan
env1_second_0:                 episode reward: -21.7500,                 loss: nan
env2_first_0:                 episode reward: 21.2500,                 loss: nan
env2_second_0:                 episode reward: -21.2500,                 loss: nan
env3_first_0:                 episode reward: 20.9000,                 loss: nan
env3_second_0:                 episode reward: -20.9000,                 loss: nan
env4_first_0:                 episode reward: 20.9500,                 loss: nan
env4_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 1569.05,                last time consumption/overall running time: 586.2389s / 216755.3871 s
env0_first_0:                 episode reward: 21.1000,                 loss: 0.0088
env0_second_0:                 episode reward: -21.1000,                 loss: nan
env1_first_0:                 episode reward: 21.0500,                 loss: nan
env1_second_0:                 episode reward: -21.0500,                 loss: nan
env2_first_0:                 episode reward: 21.6000,                 loss: nan
env2_second_0:                 episode reward: -21.6000,                 loss: nan
env3_first_0:                 episode reward: 21.0000,                 loss: nan
env3_second_0:                 episode reward: -21.0000,                 loss: nan
env4_first_0:                 episode reward: 20.8500,                 loss: nan
env4_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 1571.95,                last time consumption/overall running time: 586.9994s / 217342.3865 s
env0_first_0:                 episode reward: 22.0000,                 loss: 0.0087
env0_second_0:                 episode reward: -22.0000,                 loss: nan
env1_first_0:                 episode reward: 21.0500,                 loss: nan
env1_second_0:                 episode reward: -21.0500,                 loss: nan
env2_first_0:                 episode reward: 20.9000,                 loss: nan
env2_second_0:                 episode reward: -20.9000,                 loss: nan
env3_first_0:                 episode reward: 21.3000,                 loss: nan
env3_second_0:                 episode reward: -21.3000,                 loss: nan
env4_first_0:                 episode reward: 21.5000,                 loss: nan
env4_second_0:                 episode reward: -21.5000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 1707.15,                last time consumption/overall running time: 636.2625s / 217978.6490 s
env0_first_0:                 episode reward: 18.6500,                 loss: 0.0086
env0_second_0:                 episode reward: -18.6500,                 loss: nan
env1_first_0:                 episode reward: 18.7000,                 loss: nan
env1_second_0:                 episode reward: -18.7000,                 loss: nan
env2_first_0:                 episode reward: 19.3000,                 loss: nan
env2_second_0:                 episode reward: -19.3000,                 loss: nan
env3_first_0:                 episode reward: 19.0000,                 loss: nan
env3_second_0:                 episode reward: -19.0000,                 loss: nan
env4_first_0:                 episode reward: 19.3500,                 loss: nan
env4_second_0:                 episode reward: -19.3500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 1610.3,                last time consumption/overall running time: 599.8851s / 218578.5341 s
env0_first_0:                 episode reward: 21.4000,                 loss: 0.0087
env0_second_0:                 episode reward: -21.4000,                 loss: nan
env1_first_0:                 episode reward: 21.4500,                 loss: nan
env1_second_0:                 episode reward: -21.4500,                 loss: nan
env2_first_0:                 episode reward: 21.1500,                 loss: nan
env2_second_0:                 episode reward: -21.1500,                 loss: nan
env3_first_0:                 episode reward: 21.5000,                 loss: nan
env3_second_0:                 episode reward: -21.5000,                 loss: nan
env4_first_0:                 episode reward: 21.3500,                 loss: nan
env4_second_0:                 episode reward: -21.3500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1617.9,                last time consumption/overall running time: 613.1313s / 219191.6654 s
env0_first_0:                 episode reward: 22.4500,                 loss: 0.0089
env0_second_0:                 episode reward: -22.4500,                 loss: nan
env1_first_0:                 episode reward: 21.6500,                 loss: nan
env1_second_0:                 episode reward: -21.6500,                 loss: nan
env2_first_0:                 episode reward: 21.4500,                 loss: nan
env2_second_0:                 episode reward: -21.4500,                 loss: nan
env3_first_0:                 episode reward: 20.9000,                 loss: nan
env3_second_0:                 episode reward: -20.9000,                 loss: nan
env4_first_0:                 episode reward: 21.6000,                 loss: nan
env4_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1568.6,                last time consumption/overall running time: 592.6373s / 219784.3027 s
env0_first_0:                 episode reward: 21.2500,                 loss: 0.0088
env0_second_0:                 episode reward: -21.2500,                 loss: nan
env1_first_0:                 episode reward: 21.0500,                 loss: nan
env1_second_0:                 episode reward: -21.0500,                 loss: nan
env2_first_0:                 episode reward: 21.2500,                 loss: nan
env2_second_0:                 episode reward: -21.2500,                 loss: nan
env3_first_0:                 episode reward: 21.1500,                 loss: nan
env3_second_0:                 episode reward: -21.1500,                 loss: nan
env4_first_0:                 episode reward: 20.2000,                 loss: nan
env4_second_0:                 episode reward: -20.2000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 1622.3,                last time consumption/overall running time: 610.6830s / 220394.9857 s
env0_first_0:                 episode reward: 22.2000,                 loss: 0.0089
env0_second_0:                 episode reward: -22.2000,                 loss: nan
env1_first_0:                 episode reward: 20.3500,                 loss: nan
env1_second_0:                 episode reward: -20.3500,                 loss: nan
env2_first_0:                 episode reward: 21.5000,                 loss: nan
env2_second_0:                 episode reward: -21.5000,                 loss: nan
env3_first_0:                 episode reward: 19.8500,                 loss: nan
env3_second_0:                 episode reward: -19.8500,                 loss: nan
env4_first_0:                 episode reward: 22.3500,                 loss: nan
env4_second_0:                 episode reward: -22.3500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1639.4,                last time consumption/overall running time: 620.8174s / 221015.8031 s
env0_first_0:                 episode reward: 21.2500,                 loss: 0.0090
env0_second_0:                 episode reward: -21.2500,                 loss: nan
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
env2_first_0:                 episode reward: 20.8500,                 loss: nan
env2_second_0:                 episode reward: -20.8500,                 loss: nan
env3_first_0:                 episode reward: 20.7500,                 loss: nan
env3_second_0:                 episode reward: -20.7500,                 loss: nan
env4_first_0:                 episode reward: 21.0500,                 loss: nan
env4_second_0:                 episode reward: -21.0500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 1567.45,                last time consumption/overall running time: 598.4117s / 221614.2148 s
env0_first_0:                 episode reward: 21.6500,                 loss: 0.0091
env0_second_0:                 episode reward: -21.6500,                 loss: nan
env1_first_0:                 episode reward: 21.7500,                 loss: nan
env1_second_0:                 episode reward: -21.7500,                 loss: nan
env2_first_0:                 episode reward: 21.1000,                 loss: nan
env2_second_0:                 episode reward: -21.1000,                 loss: nan
env3_first_0:                 episode reward: 20.9000,                 loss: nan
env3_second_0:                 episode reward: -20.9000,                 loss: nan
env4_first_0:                 episode reward: 21.6000,                 loss: nan
env4_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1565.35,                last time consumption/overall running time: 583.2919s / 222197.5067 s
env0_first_0:                 episode reward: 22.2500,                 loss: 0.0092
env0_second_0:                 episode reward: -22.2500,                 loss: nan
env1_first_0:                 episode reward: 22.5000,                 loss: nan
env1_second_0:                 episode reward: -22.5000,                 loss: nan
env2_first_0:                 episode reward: 22.4500,                 loss: nan
env2_second_0:                 episode reward: -22.4500,                 loss: nan
env3_first_0:                 episode reward: 22.0500,                 loss: nan
env3_second_0:                 episode reward: -22.0500,                 loss: nan
env4_first_0:                 episode reward: 21.7000,                 loss: nan
env4_second_0:                 episode reward: -21.7000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1605.95,                last time consumption/overall running time: 598.0157s / 222795.5224 s
env0_first_0:                 episode reward: 22.4000,                 loss: 0.0090
env0_second_0:                 episode reward: -22.4000,                 loss: nan
env1_first_0:                 episode reward: 22.3000,                 loss: nan
env1_second_0:                 episode reward: -22.3000,                 loss: nan
env2_first_0:                 episode reward: 22.5500,                 loss: nan
env2_second_0:                 episode reward: -22.5500,                 loss: nan
env3_first_0:                 episode reward: 22.4000,                 loss: nan
env3_second_0:                 episode reward: -22.4000,                 loss: nan
env4_first_0:                 episode reward: 22.9000,                 loss: nan
env4_second_0:                 episode reward: -22.9000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 1554.2,                last time consumption/overall running time: 588.7901s / 223384.3125 s
env0_first_0:                 episode reward: 22.5000,                 loss: 0.0092
env0_second_0:                 episode reward: -22.5000,                 loss: nan
env1_first_0:                 episode reward: 23.0500,                 loss: nan
env1_second_0:                 episode reward: -23.0500,                 loss: nan
env2_first_0:                 episode reward: 22.6000,                 loss: nan
env2_second_0:                 episode reward: -22.6000,                 loss: nan
env3_first_0:                 episode reward: 22.3500,                 loss: nan
env3_second_0:                 episode reward: -22.3500,                 loss: nan
env4_first_0:                 episode reward: 22.5500,                 loss: nan
env4_second_0:                 episode reward: -22.5500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 1532.0,                last time consumption/overall running time: 573.1974s / 223957.5099 s
env0_first_0:                 episode reward: 23.1500,                 loss: 0.0091
env0_second_0:                 episode reward: -23.1500,                 loss: nan
env1_first_0:                 episode reward: 22.8500,                 loss: nan
env1_second_0:                 episode reward: -22.8500,                 loss: nan
env2_first_0:                 episode reward: 22.3500,                 loss: nan
env2_second_0:                 episode reward: -22.3500,                 loss: nan
env3_first_0:                 episode reward: 20.0500,                 loss: nan
env3_second_0:                 episode reward: -20.0500,                 loss: nan
env4_first_0:                 episode reward: 23.4000,                 loss: nan
env4_second_0:                 episode reward: -23.4000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 1528.65,                last time consumption/overall running time: 573.3334s / 224530.8433 s
env0_first_0:                 episode reward: 22.9000,                 loss: 0.0090
env0_second_0:                 episode reward: -22.9000,                 loss: nan
env1_first_0:                 episode reward: 22.5000,                 loss: nan
env1_second_0:                 episode reward: -22.5000,                 loss: nan
env2_first_0:                 episode reward: 22.4000,                 loss: nan
env2_second_0:                 episode reward: -22.4000,                 loss: nan
env3_first_0:                 episode reward: 22.7000,                 loss: nan
env3_second_0:                 episode reward: -22.7000,                 loss: nan
env4_first_0:                 episode reward: 22.6500,                 loss: nan
env4_second_0:                 episode reward: -22.6500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 1590.1,                last time consumption/overall running time: 595.1785s / 225126.0218 s
env0_first_0:                 episode reward: 22.7500,                 loss: 0.0089
env0_second_0:                 episode reward: -22.7500,                 loss: nan
env1_first_0:                 episode reward: 22.5500,                 loss: nan
env1_second_0:                 episode reward: -22.5500,                 loss: nan
env2_first_0:                 episode reward: 22.3500,                 loss: nan
env2_second_0:                 episode reward: -22.3500,                 loss: nan
env3_first_0:                 episode reward: 22.1000,                 loss: nan
env3_second_0:                 episode reward: -22.1000,                 loss: nan
env4_first_0:                 episode reward: 22.4000,                 loss: nan
env4_second_0:                 episode reward: -22.4000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 1632.35,                last time consumption/overall running time: 620.1526s / 225746.1744 s
env0_first_0:                 episode reward: 22.5500,                 loss: 0.0098
env0_second_0:                 episode reward: -22.5500,                 loss: nan
env1_first_0:                 episode reward: 22.1000,                 loss: nan
env1_second_0:                 episode reward: -22.1000,                 loss: nan
env2_first_0:                 episode reward: 21.5000,                 loss: nan
env2_second_0:                 episode reward: -21.5000,                 loss: nan
env3_first_0:                 episode reward: 22.3500,                 loss: nan
env3_second_0:                 episode reward: -22.3500,                 loss: nan
env4_first_0:                 episode reward: 21.1000,                 loss: nan
env4_second_0:                 episode reward: -21.1000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 1570.35,                last time consumption/overall running time: 591.0746s / 226337.2490 s
env0_first_0:                 episode reward: 21.7500,                 loss: 0.0099
env0_second_0:                 episode reward: -21.7500,                 loss: nan
env1_first_0:                 episode reward: 21.3000,                 loss: nan
env1_second_0:                 episode reward: -21.3000,                 loss: nan
env2_first_0:                 episode reward: 21.9500,                 loss: nan
env2_second_0:                 episode reward: -21.9500,                 loss: nan
env3_first_0:                 episode reward: 22.8000,                 loss: nan
env3_second_0:                 episode reward: -22.8000,                 loss: nan
env4_first_0:                 episode reward: 22.5000,                 loss: nan
env4_second_0:                 episode reward: -22.5000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 1644.05,                last time consumption/overall running time: 621.0013s / 226958.2503 s
env0_first_0:                 episode reward: 21.8000,                 loss: 0.0100
env0_second_0:                 episode reward: -21.8000,                 loss: nan
env1_first_0:                 episode reward: 21.6000,                 loss: nan
env1_second_0:                 episode reward: -21.6000,                 loss: nan
env2_first_0:                 episode reward: 22.2000,                 loss: nan
env2_second_0:                 episode reward: -22.2000,                 loss: nan
env3_first_0:                 episode reward: 22.3000,                 loss: nan
env3_second_0:                 episode reward: -22.3000,                 loss: nan
env4_first_0:                 episode reward: 22.5500,                 loss: nan
env4_second_0:                 episode reward: -22.5500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 1631.7,                last time consumption/overall running time: 627.4581s / 227585.7084 s
env0_first_0:                 episode reward: 21.5500,                 loss: 0.0104
env0_second_0:                 episode reward: -21.5500,                 loss: nan
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
env2_first_0:                 episode reward: 17.7000,                 loss: nan
env2_second_0:                 episode reward: -17.7000,                 loss: nan
env3_first_0:                 episode reward: 20.0500,                 loss: nan
env3_second_0:                 episode reward: -20.0500,                 loss: nan
env4_first_0:                 episode reward: 19.0500,                 loss: nan
env4_second_0:                 episode reward: -19.0500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 1590.0,                last time consumption/overall running time: 602.0678s / 228187.7763 s
env0_first_0:                 episode reward: 22.5000,                 loss: 0.0101
env0_second_0:                 episode reward: -22.5000,                 loss: nan
env1_first_0:                 episode reward: 23.6000,                 loss: nan
env1_second_0:                 episode reward: -23.6000,                 loss: nan
env2_first_0:                 episode reward: 22.6500,                 loss: nan
env2_second_0:                 episode reward: -22.6500,                 loss: nan
env3_first_0:                 episode reward: 23.1500,                 loss: nan
env3_second_0:                 episode reward: -23.1500,                 loss: nan
env4_first_0:                 episode reward: 23.4000,                 loss: nan
env4_second_0:                 episode reward: -23.4000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 1485.65,                last time consumption/overall running time: 549.8520s / 228737.6283 s
env0_first_0:                 episode reward: 22.4500,                 loss: 0.0104
env0_second_0:                 episode reward: -22.4500,                 loss: nan
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
env2_first_0:                 episode reward: 21.1500,                 loss: nan
env2_second_0:                 episode reward: -21.1500,                 loss: nan
env3_first_0:                 episode reward: 22.5000,                 loss: nan
env3_second_0:                 episode reward: -22.5000,                 loss: nan
env4_first_0:                 episode reward: 20.6500,                 loss: nan
env4_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 1594.7,                last time consumption/overall running time: 587.4598s / 229325.0881 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0100
env0_second_0:                 episode reward: -20.5500,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
env2_first_0:                 episode reward: 21.4500,                 loss: nan
env2_second_0:                 episode reward: -21.4500,                 loss: nan
env3_first_0:                 episode reward: 21.6000,                 loss: nan
env3_second_0:                 episode reward: -21.6000,                 loss: nan
env4_first_0:                 episode reward: 21.4000,                 loss: nan
env4_second_0:                 episode reward: -21.4000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 1789.95,                last time consumption/overall running time: 666.3250s / 229991.4131 s
env0_first_0:                 episode reward: 18.9500,                 loss: 0.0097
env0_second_0:                 episode reward: -18.9500,                 loss: nan
env1_first_0:                 episode reward: 18.9500,                 loss: nan
env1_second_0:                 episode reward: -18.9500,                 loss: nan
env2_first_0:                 episode reward: 19.3000,                 loss: nan
env2_second_0:                 episode reward: -19.3000,                 loss: nan
env3_first_0:                 episode reward: 19.8500,                 loss: nan
env3_second_0:                 episode reward: -19.8500,                 loss: nan
env4_first_0:                 episode reward: 19.7000,                 loss: nan
env4_second_0:                 episode reward: -19.7000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 1572.15,                last time consumption/overall running time: 592.7735s / 230584.1866 s
env0_first_0:                 episode reward: 22.4000,                 loss: 0.0100
env0_second_0:                 episode reward: -22.4000,                 loss: nan
env1_first_0:                 episode reward: 21.7000,                 loss: nan
env1_second_0:                 episode reward: -21.7000,                 loss: nan
env2_first_0:                 episode reward: 21.5000,                 loss: nan
env2_second_0:                 episode reward: -21.5000,                 loss: nan
env3_first_0:                 episode reward: 21.9000,                 loss: nan
env3_second_0:                 episode reward: -21.9000,                 loss: nan
env4_first_0:                 episode reward: 21.9000,                 loss: nan
env4_second_0:                 episode reward: -21.9000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 1515.2,                last time consumption/overall running time: 566.6291s / 231150.8157 s
env0_first_0:                 episode reward: 21.5000,                 loss: 0.0103
env0_second_0:                 episode reward: -21.5000,                 loss: nan
env1_first_0:                 episode reward: 21.8000,                 loss: nan
env1_second_0:                 episode reward: -21.8000,                 loss: nan
env2_first_0:                 episode reward: 20.9000,                 loss: nan
env2_second_0:                 episode reward: -20.9000,                 loss: nan
env3_first_0:                 episode reward: 21.7000,                 loss: nan
env3_second_0:                 episode reward: -21.7000,                 loss: nan
env4_first_0:                 episode reward: 21.4500,                 loss: nan
env4_second_0:                 episode reward: -21.4500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 1602.95,                last time consumption/overall running time: 591.9393s / 231742.7550 s
env0_first_0:                 episode reward: 20.1500,                 loss: 0.0097
env0_second_0:                 episode reward: -20.1500,                 loss: nan
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
env2_first_0:                 episode reward: 19.9000,                 loss: nan
env2_second_0:                 episode reward: -19.9000,                 loss: nan
env3_first_0:                 episode reward: 20.1500,                 loss: nan
env3_second_0:                 episode reward: -20.1500,                 loss: nan
env4_first_0:                 episode reward: 19.6500,                 loss: nan
env4_second_0:                 episode reward: -19.6500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 1578.75,                last time consumption/overall running time: 589.7233s / 232332.4783 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0092
env0_second_0:                 episode reward: -20.4500,                 loss: nan
env1_first_0:                 episode reward: 21.2000,                 loss: nan
env1_second_0:                 episode reward: -21.2000,                 loss: nan
env2_first_0:                 episode reward: 20.5500,                 loss: nan
env2_second_0:                 episode reward: -20.5500,                 loss: nan
env3_first_0:                 episode reward: 20.8000,                 loss: nan
env3_second_0:                 episode reward: -20.8000,                 loss: nan
env4_first_0:                 episode reward: 21.8000,                 loss: nan
env4_second_0:                 episode reward: -21.8000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 1634.55,                last time consumption/overall running time: 606.7815s / 232939.2598 s
env0_first_0:                 episode reward: 20.3500,                 loss: 0.0092
env0_second_0:                 episode reward: -20.3500,                 loss: nan
env1_first_0:                 episode reward: 20.2500,                 loss: nan
env1_second_0:                 episode reward: -20.2500,                 loss: nan
env2_first_0:                 episode reward: 21.1000,                 loss: nan
env2_second_0:                 episode reward: -21.1000,                 loss: nan
env3_first_0:                 episode reward: 21.3000,                 loss: nan
env3_second_0:                 episode reward: -21.3000,                 loss: nan
env4_first_0:                 episode reward: 20.4000,                 loss: nan
env4_second_0:                 episode reward: -20.4000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 2908.45,                last time consumption/overall running time: 1073.8470s / 234013.1068 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0104
env0_second_0:                 episode reward: 7.3500,                 loss: nan
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
env2_first_0:                 episode reward: -8.7500,                 loss: nan
env2_second_0:                 episode reward: 8.7500,                 loss: nan
env3_first_0:                 episode reward: -9.8000,                 loss: nan
env3_second_0:                 episode reward: 9.8000,                 loss: nan
env4_first_0:                 episode reward: -8.3000,                 loss: nan
env4_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 2018.65,                last time consumption/overall running time: 748.2784s / 234761.3852 s
env0_first_0:                 episode reward: 13.0500,                 loss: 0.0128
env0_second_0:                 episode reward: -13.0500,                 loss: nan
env1_first_0:                 episode reward: 13.3500,                 loss: nan
env1_second_0:                 episode reward: -13.3500,                 loss: nan
env2_first_0:                 episode reward: 12.8000,                 loss: nan
env2_second_0:                 episode reward: -12.8000,                 loss: nan
env3_first_0:                 episode reward: 14.3000,                 loss: nan
env3_second_0:                 episode reward: -14.3000,                 loss: nan
env4_first_0:                 episode reward: 13.6500,                 loss: nan
env4_second_0:                 episode reward: -13.6500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 1611.2,                last time consumption/overall running time: 596.2727s / 235357.6579 s
env0_first_0:                 episode reward: 19.9500,                 loss: 0.0127
env0_second_0:                 episode reward: -19.9500,                 loss: nan
env1_first_0:                 episode reward: 19.5000,                 loss: nan
env1_second_0:                 episode reward: -19.5000,                 loss: nan
env2_first_0:                 episode reward: 19.1000,                 loss: nan
env2_second_0:                 episode reward: -19.1000,                 loss: nan
env3_first_0:                 episode reward: 19.8000,                 loss: nan
env3_second_0:                 episode reward: -19.8000,                 loss: nan
env4_first_0:                 episode reward: 19.8500,                 loss: nan
env4_second_0:                 episode reward: -19.8500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1786.2,                last time consumption/overall running time: 658.0628s / 236015.7207 s
env0_first_0:                 episode reward: 17.4000,                 loss: 0.0114
env0_second_0:                 episode reward: -17.4000,                 loss: nan
env1_first_0:                 episode reward: 16.5500,                 loss: nan
env1_second_0:                 episode reward: -16.5500,                 loss: nan
env2_first_0:                 episode reward: 18.4500,                 loss: nan
env2_second_0:                 episode reward: -18.4500,                 loss: nan
env3_first_0:                 episode reward: 17.2000,                 loss: nan
env3_second_0:                 episode reward: -17.2000,                 loss: nan
env4_first_0:                 episode reward: 17.2000,                 loss: nan
env4_second_0:                 episode reward: -17.2000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 1970.5,                last time consumption/overall running time: 727.4142s / 236743.1349 s
env0_first_0:                 episode reward: 13.5000,                 loss: 0.0099
env0_second_0:                 episode reward: -13.5000,                 loss: nan
env1_first_0:                 episode reward: 13.0000,                 loss: nan
env1_second_0:                 episode reward: -13.0000,                 loss: nan
env2_first_0:                 episode reward: 12.8000,                 loss: nan
env2_second_0:                 episode reward: -12.8000,                 loss: nan
env3_first_0:                 episode reward: 14.0000,                 loss: nan
env3_second_0:                 episode reward: -14.0000,                 loss: nan
env4_first_0:                 episode reward: 11.3500,                 loss: nan
env4_second_0:                 episode reward: -11.3500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 1971.6,                last time consumption/overall running time: 731.1323s / 237474.2672 s
env0_first_0:                 episode reward: 15.6500,                 loss: 0.0105
env0_second_0:                 episode reward: -15.6500,                 loss: nan
env1_first_0:                 episode reward: 15.2000,                 loss: nan
env1_second_0:                 episode reward: -15.2000,                 loss: nan
env2_first_0:                 episode reward: 15.5500,                 loss: nan
env2_second_0:                 episode reward: -15.5500,                 loss: nan
env3_first_0:                 episode reward: 15.7000,                 loss: nan
env3_second_0:                 episode reward: -15.7000,                 loss: nan
env4_first_0:                 episode reward: 15.9500,                 loss: nan
env4_second_0:                 episode reward: -15.9500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 1512.55,                last time consumption/overall running time: 553.6034s / 238027.8705 s
env0_first_0:                 episode reward: 21.7000,                 loss: 0.0106
env0_second_0:                 episode reward: -21.7000,                 loss: nan
env1_first_0:                 episode reward: 22.0500,                 loss: nan
env1_second_0:                 episode reward: -22.0500,                 loss: nan
env2_first_0:                 episode reward: 21.5000,                 loss: nan
env2_second_0:                 episode reward: -21.5000,                 loss: nan
env3_first_0:                 episode reward: 21.1500,                 loss: nan
env3_second_0:                 episode reward: -21.1500,                 loss: nan
env4_first_0:                 episode reward: 21.8500,                 loss: nan
env4_second_0:                 episode reward: -21.8500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 1728.0,                last time consumption/overall running time: 633.4687s / 238661.3392 s
env0_first_0:                 episode reward: 18.7000,                 loss: 0.0097
env0_second_0:                 episode reward: -18.7000,                 loss: nan
env1_first_0:                 episode reward: 19.4500,                 loss: nan
env1_second_0:                 episode reward: -19.4500,                 loss: nan
env2_first_0:                 episode reward: 19.9500,                 loss: nan
env2_second_0:                 episode reward: -19.9500,                 loss: nan
env3_first_0:                 episode reward: 18.9000,                 loss: nan
env3_second_0:                 episode reward: -18.9000,                 loss: nan
env4_first_0:                 episode reward: 19.1000,                 loss: nan
env4_second_0:                 episode reward: -19.1000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 1553.75,                last time consumption/overall running time: 571.6544s / 239232.9937 s
env0_first_0:                 episode reward: 21.1000,                 loss: 0.0090
env0_second_0:                 episode reward: -21.1000,                 loss: nan
env1_first_0:                 episode reward: 21.2500,                 loss: nan
env1_second_0:                 episode reward: -21.2500,                 loss: nan
env2_first_0:                 episode reward: 21.2500,                 loss: nan
env2_second_0:                 episode reward: -21.2500,                 loss: nan
env3_first_0:                 episode reward: 21.3500,                 loss: nan
env3_second_0:                 episode reward: -21.3500,                 loss: nan
env4_first_0:                 episode reward: 21.5000,                 loss: nan
env4_second_0:                 episode reward: -21.5000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 1547.7,                last time consumption/overall running time: 574.0364s / 239807.0301 s
env0_first_0:                 episode reward: 22.0500,                 loss: 0.0086
env0_second_0:                 episode reward: -22.0500,                 loss: nan
env1_first_0:                 episode reward: 22.1500,                 loss: nan
env1_second_0:                 episode reward: -22.1500,                 loss: nan
env2_first_0:                 episode reward: 22.2500,                 loss: nan
env2_second_0:                 episode reward: -22.2500,                 loss: nan
env3_first_0:                 episode reward: 22.1000,                 loss: nan
env3_second_0:                 episode reward: -22.1000,                 loss: nan
env4_first_0:                 episode reward: 22.1000,                 loss: nan
env4_second_0:                 episode reward: -22.1000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 1589.35,                last time consumption/overall running time: 583.6937s / 240390.7238 s
env0_first_0:                 episode reward: 21.2000,                 loss: 0.0088
env0_second_0:                 episode reward: -21.2000,                 loss: nan
env1_first_0:                 episode reward: 21.1000,                 loss: nan
env1_second_0:                 episode reward: -21.1000,                 loss: nan
env2_first_0:                 episode reward: 21.9500,                 loss: nan
env2_second_0:                 episode reward: -21.9500,                 loss: nan
env3_first_0:                 episode reward: 21.3500,                 loss: nan
env3_second_0:                 episode reward: -21.3500,                 loss: nan
env4_first_0:                 episode reward: 21.0500,                 loss: nan
env4_second_0:                 episode reward: -21.0500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 2096.95,                last time consumption/overall running time: 776.1623s / 241166.8861 s
env0_first_0:                 episode reward: 7.7000,                 loss: 0.0089
env0_second_0:                 episode reward: -7.7000,                 loss: nan
env1_first_0:                 episode reward: 8.3500,                 loss: nan
env1_second_0:                 episode reward: -8.3500,                 loss: nan
env2_first_0:                 episode reward: 8.1500,                 loss: nan
env2_second_0:                 episode reward: -8.1500,                 loss: nan
env3_first_0:                 episode reward: 8.1500,                 loss: nan
env3_second_0:                 episode reward: -8.1500,                 loss: nan
env4_first_0:                 episode reward: 8.2000,                 loss: nan
env4_second_0:                 episode reward: -8.2000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 1691.95,                last time consumption/overall running time: 624.3202s / 241791.2063 s
env0_first_0:                 episode reward: 17.2500,                 loss: 0.0092
env0_second_0:                 episode reward: -17.2500,                 loss: nan
env1_first_0:                 episode reward: 18.7000,                 loss: nan
env1_second_0:                 episode reward: -18.7000,                 loss: nan
env2_first_0:                 episode reward: 19.1000,                 loss: nan
env2_second_0:                 episode reward: -19.1000,                 loss: nan
env3_first_0:                 episode reward: 17.6000,                 loss: nan
env3_second_0:                 episode reward: -17.6000,                 loss: nan
env4_first_0:                 episode reward: 19.0000,                 loss: nan
env4_second_0:                 episode reward: -19.0000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 1567.05,                last time consumption/overall running time: 582.9366s / 242374.1428 s
env0_first_0:                 episode reward: 21.7500,                 loss: 0.0095
env0_second_0:                 episode reward: -21.7500,                 loss: nan
env1_first_0:                 episode reward: 21.9000,                 loss: nan
env1_second_0:                 episode reward: -21.9000,                 loss: nan
env2_first_0:                 episode reward: 21.8500,                 loss: nan
env2_second_0:                 episode reward: -21.8500,                 loss: nan
env3_first_0:                 episode reward: 21.8000,                 loss: nan
env3_second_0:                 episode reward: -21.8000,                 loss: nan
env4_first_0:                 episode reward: 21.9500,                 loss: nan
env4_second_0:                 episode reward: -21.9500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 1596.8,                last time consumption/overall running time: 587.9255s / 242962.0683 s
env0_first_0:                 episode reward: 20.3500,                 loss: 0.0096
env0_second_0:                 episode reward: -20.3500,                 loss: nan
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
env2_first_0:                 episode reward: 21.2000,                 loss: nan
env2_second_0:                 episode reward: -21.2000,                 loss: nan
env3_first_0:                 episode reward: 21.9500,                 loss: nan
env3_second_0:                 episode reward: -21.9500,                 loss: nan
env4_first_0:                 episode reward: 21.5000,                 loss: nan
env4_second_0:                 episode reward: -21.5000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 1672.25,                last time consumption/overall running time: 620.8865s / 243582.9548 s
env0_first_0:                 episode reward: 20.0000,                 loss: 0.0089
env0_second_0:                 episode reward: -20.0000,                 loss: nan
env1_first_0:                 episode reward: 20.4000,                 loss: nan
env1_second_0:                 episode reward: -20.4000,                 loss: nan
env2_first_0:                 episode reward: 19.3000,                 loss: nan
env2_second_0:                 episode reward: -19.3000,                 loss: nan
env3_first_0:                 episode reward: 20.8000,                 loss: nan
env3_second_0:                 episode reward: -20.8000,                 loss: nan
env4_first_0:                 episode reward: 19.4000,                 loss: nan
env4_second_0:                 episode reward: -19.4000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 1625.55,                last time consumption/overall running time: 600.8441s / 244183.7989 s
env0_first_0:                 episode reward: 21.1500,                 loss: 0.0089
env0_second_0:                 episode reward: -21.1500,                 loss: nan
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
env2_first_0:                 episode reward: 21.1500,                 loss: nan
env2_second_0:                 episode reward: -21.1500,                 loss: nan
env3_first_0:                 episode reward: 21.1000,                 loss: nan
env3_second_0:                 episode reward: -21.1000,                 loss: nan
env4_first_0:                 episode reward: 21.1500,                 loss: nan
env4_second_0:                 episode reward: -21.1500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 1759.05,                last time consumption/overall running time: 652.2074s / 244836.0063 s
env0_first_0:                 episode reward: 18.3500,                 loss: 0.0088
env0_second_0:                 episode reward: -18.3500,                 loss: nan
env1_first_0:                 episode reward: 18.7500,                 loss: nan
env1_second_0:                 episode reward: -18.7500,                 loss: nan
env2_first_0:                 episode reward: 18.2500,                 loss: nan
env2_second_0:                 episode reward: -18.2500,                 loss: nan
env3_first_0:                 episode reward: 18.0500,                 loss: nan
env3_second_0:                 episode reward: -18.0500,                 loss: nan
env4_first_0:                 episode reward: 18.0000,                 loss: nan
env4_second_0:                 episode reward: -18.0000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 1761.3,                last time consumption/overall running time: 651.4883s / 245487.4946 s
env0_first_0:                 episode reward: 17.2000,                 loss: 0.0096
env0_second_0:                 episode reward: -17.2000,                 loss: nan
env1_first_0:                 episode reward: 17.5000,                 loss: nan
env1_second_0:                 episode reward: -17.5000,                 loss: nan
env2_first_0:                 episode reward: 16.4000,                 loss: nan
env2_second_0:                 episode reward: -16.4000,                 loss: nan
env3_first_0:                 episode reward: 19.3500,                 loss: nan
env3_second_0:                 episode reward: -19.3500,                 loss: nan
env4_first_0:                 episode reward: 17.2500,                 loss: nan
env4_second_0:                 episode reward: -17.2500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 1987.85,                last time consumption/overall running time: 735.0167s / 246222.5113 s
env0_first_0:                 episode reward: 12.7500,                 loss: 0.0097
env0_second_0:                 episode reward: -12.7500,                 loss: nan
env1_first_0:                 episode reward: 12.5500,                 loss: nan
env1_second_0:                 episode reward: -12.5500,                 loss: nan
env2_first_0:                 episode reward: 13.7000,                 loss: nan
env2_second_0:                 episode reward: -13.7000,                 loss: nan
env3_first_0:                 episode reward: 13.4500,                 loss: nan
env3_second_0:                 episode reward: -13.4500,                 loss: nan
env4_first_0:                 episode reward: 12.4500,                 loss: nan
env4_second_0:                 episode reward: -12.4500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 1774.45,                last time consumption/overall running time: 658.2853s / 246880.7966 s
env0_first_0:                 episode reward: 16.4500,                 loss: 0.0104
env0_second_0:                 episode reward: -16.4500,                 loss: nan
env1_first_0:                 episode reward: 14.6500,                 loss: nan
env1_second_0:                 episode reward: -14.6500,                 loss: nan
env2_first_0:                 episode reward: 15.9000,                 loss: nan
env2_second_0:                 episode reward: -15.9000,                 loss: nan
env3_first_0:                 episode reward: 18.0000,                 loss: nan
env3_second_0:                 episode reward: -18.0000,                 loss: nan
env4_first_0:                 episode reward: 17.3500,                 loss: nan
env4_second_0:                 episode reward: -17.3500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 1563.1,                last time consumption/overall running time: 588.5390s / 247469.3356 s
env0_first_0:                 episode reward: 21.4500,                 loss: 0.0102
env0_second_0:                 episode reward: -21.4500,                 loss: nan
env1_first_0:                 episode reward: 21.6500,                 loss: nan
env1_second_0:                 episode reward: -21.6500,                 loss: nan
env2_first_0:                 episode reward: 22.1500,                 loss: nan
env2_second_0:                 episode reward: -22.1500,                 loss: nan
env3_first_0:                 episode reward: 22.1000,                 loss: nan
env3_second_0:                 episode reward: -22.1000,                 loss: nan
env4_first_0:                 episode reward: 21.6500,                 loss: nan
env4_second_0:                 episode reward: -21.6500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 1557.05,                last time consumption/overall running time: 588.3422s / 248057.6779 s
env0_first_0:                 episode reward: 22.0000,                 loss: 0.0106
env0_second_0:                 episode reward: -22.0000,                 loss: nan
env1_first_0:                 episode reward: 21.8500,                 loss: nan
env1_second_0:                 episode reward: -21.8500,                 loss: nan
env2_first_0:                 episode reward: 21.9500,                 loss: nan
env2_second_0:                 episode reward: -21.9500,                 loss: nan
env3_first_0:                 episode reward: 22.3000,                 loss: nan
env3_second_0:                 episode reward: -22.3000,                 loss: nan
env4_first_0:                 episode reward: 22.1500,                 loss: nan
env4_second_0:                 episode reward: -22.1500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 1580.15,                last time consumption/overall running time: 598.6275s / 248656.3054 s
env0_first_0:                 episode reward: 22.2000,                 loss: 0.0102
env0_second_0:                 episode reward: -22.2000,                 loss: nan
env1_first_0:                 episode reward: 22.0500,                 loss: nan
env1_second_0:                 episode reward: -22.0500,                 loss: nan
env2_first_0:                 episode reward: 22.3500,                 loss: nan
env2_second_0:                 episode reward: -22.3500,                 loss: nan
env3_first_0:                 episode reward: 22.4500,                 loss: nan
env3_second_0:                 episode reward: -22.4500,                 loss: nan
env4_first_0:                 episode reward: 22.3000,                 loss: nan
env4_second_0:                 episode reward: -22.3000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 1695.1,                last time consumption/overall running time: 635.4103s / 249291.7157 s
env0_first_0:                 episode reward: 18.9000,                 loss: 0.0098
env0_second_0:                 episode reward: -18.9000,                 loss: nan
env1_first_0:                 episode reward: 18.9500,                 loss: nan
env1_second_0:                 episode reward: -18.9500,                 loss: nan
env2_first_0:                 episode reward: 18.1000,                 loss: nan
env2_second_0:                 episode reward: -18.1000,                 loss: nan
env3_first_0:                 episode reward: 18.8000,                 loss: nan
env3_second_0:                 episode reward: -18.8000,                 loss: nan
env4_first_0:                 episode reward: 17.9500,                 loss: nan
env4_second_0:                 episode reward: -17.9500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 1612.9,                last time consumption/overall running time: 604.6839s / 249896.3996 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0099
env0_second_0:                 episode reward: -20.7000,                 loss: nan
env1_first_0:                 episode reward: 19.6000,                 loss: nan
env1_second_0:                 episode reward: -19.6000,                 loss: nan
env2_first_0:                 episode reward: 20.9000,                 loss: nan
env2_second_0:                 episode reward: -20.9000,                 loss: nan
env3_first_0:                 episode reward: 21.2000,                 loss: nan
env3_second_0:                 episode reward: -21.2000,                 loss: nan
env4_first_0:                 episode reward: 21.3500,                 loss: nan
env4_second_0:                 episode reward: -21.3500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 1538.55,                last time consumption/overall running time: 583.0765s / 250479.4761 s
env0_first_0:                 episode reward: 21.5000,                 loss: 0.0097
env0_second_0:                 episode reward: -21.5000,                 loss: nan
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
env2_first_0:                 episode reward: 20.8500,                 loss: nan
env2_second_0:                 episode reward: -20.8500,                 loss: nan
env3_first_0:                 episode reward: 21.3000,                 loss: nan
env3_second_0:                 episode reward: -21.3000,                 loss: nan
env4_first_0:                 episode reward: 20.9500,                 loss: nan
env4_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 1636.35,                last time consumption/overall running time: 616.9536s / 251096.4297 s
env0_first_0:                 episode reward: 19.1000,                 loss: 0.0096
env0_second_0:                 episode reward: -19.1000,                 loss: nan
env1_first_0:                 episode reward: 19.3000,                 loss: nan
env1_second_0:                 episode reward: -19.3000,                 loss: nan
env2_first_0:                 episode reward: 20.3000,                 loss: nan
env2_second_0:                 episode reward: -20.3000,                 loss: nan
env3_first_0:                 episode reward: 21.4000,                 loss: nan
env3_second_0:                 episode reward: -21.4000,                 loss: nan
env4_first_0:                 episode reward: 19.4000,                 loss: nan
env4_second_0:                 episode reward: -19.4000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 1646.65,                last time consumption/overall running time: 628.2559s / 251724.6857 s
env0_first_0:                 episode reward: 22.0500,                 loss: 0.0098
env0_second_0:                 episode reward: -22.0500,                 loss: nan
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
env2_first_0:                 episode reward: 21.6500,                 loss: nan
env2_second_0:                 episode reward: -21.6500,                 loss: nan
env3_first_0:                 episode reward: 20.5500,                 loss: nan
env3_second_0:                 episode reward: -20.5500,                 loss: nan
env4_first_0:                 episode reward: 21.6500,                 loss: nan
env4_second_0:                 episode reward: -21.6500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 1541.95,                last time consumption/overall running time: 599.6882s / 252324.3739 s
env0_first_0:                 episode reward: 22.7500,                 loss: 0.0098
env0_second_0:                 episode reward: -22.7500,                 loss: nan
env1_first_0:                 episode reward: 22.6500,                 loss: nan
env1_second_0:                 episode reward: -22.6500,                 loss: nan
env2_first_0:                 episode reward: 22.1000,                 loss: nan
env2_second_0:                 episode reward: -22.1000,                 loss: nan
env3_first_0:                 episode reward: 22.4500,                 loss: nan
env3_second_0:                 episode reward: -22.4500,                 loss: nan
env4_first_0:                 episode reward: 21.8500,                 loss: nan
env4_second_0:                 episode reward: -21.8500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 1587.65,                last time consumption/overall running time: 619.9404s / 252944.3142 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.0097
env0_second_0:                 episode reward: -20.5000,                 loss: nan
env1_first_0:                 episode reward: 21.5000,                 loss: nan
env1_second_0:                 episode reward: -21.5000,                 loss: nan
env2_first_0:                 episode reward: 21.8500,                 loss: nan
env2_second_0:                 episode reward: -21.8500,                 loss: nan
env3_first_0:                 episode reward: 20.6500,                 loss: nan
env3_second_0:                 episode reward: -20.6500,                 loss: nan
env4_first_0:                 episode reward: 21.6000,                 loss: nan
env4_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 1691.35,                last time consumption/overall running time: 855.6545s / 253799.9687 s
env0_first_0:                 episode reward: 19.7000,                 loss: 0.0101
env0_second_0:                 episode reward: -19.7000,                 loss: nan
env1_first_0:                 episode reward: 19.7500,                 loss: nan
env1_second_0:                 episode reward: -19.7500,                 loss: nan
env2_first_0:                 episode reward: 20.1000,                 loss: nan
env2_second_0:                 episode reward: -20.1000,                 loss: nan
env3_first_0:                 episode reward: 19.6000,                 loss: nan
env3_second_0:                 episode reward: -19.6000,                 loss: nan
env4_first_0:                 episode reward: 19.6000,                 loss: nan
env4_second_0:                 episode reward: -19.6000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 1643.4,                last time consumption/overall running time: 928.4759s / 254728.4446 s
env0_first_0:                 episode reward: 21.1000,                 loss: 0.0106
env0_second_0:                 episode reward: -21.1000,                 loss: nan
env1_first_0:                 episode reward: 21.3000,                 loss: nan
env1_second_0:                 episode reward: -21.3000,                 loss: nan
env2_first_0:                 episode reward: 20.2500,                 loss: nan
env2_second_0:                 episode reward: -20.2500,                 loss: nan
env3_first_0:                 episode reward: 20.5500,                 loss: nan
env3_second_0:                 episode reward: -20.5500,                 loss: nan
env4_first_0:                 episode reward: 21.4500,                 loss: nan
env4_second_0:                 episode reward: -21.4500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 1787.55,                last time consumption/overall running time: 987.3706s / 255715.8152 s
env0_first_0:                 episode reward: 18.4500,                 loss: 0.0113
env0_second_0:                 episode reward: -18.4500,                 loss: nan
env1_first_0:                 episode reward: 19.4000,                 loss: nan
env1_second_0:                 episode reward: -19.4000,                 loss: nan
env2_first_0:                 episode reward: 18.8000,                 loss: nan
env2_second_0:                 episode reward: -18.8000,                 loss: nan
env3_first_0:                 episode reward: 18.9500,                 loss: nan
env3_second_0:                 episode reward: -18.9500,                 loss: nan
env4_first_0:                 episode reward: 19.7000,                 loss: nan
env4_second_0:                 episode reward: -19.7000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 1631.8,                last time consumption/overall running time: 905.1902s / 256621.0054 s
env0_first_0:                 episode reward: 21.5500,                 loss: 0.0115
env0_second_0:                 episode reward: -21.5500,                 loss: nan
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
env2_first_0:                 episode reward: 21.3500,                 loss: nan
env2_second_0:                 episode reward: -21.3500,                 loss: nan
env3_first_0:                 episode reward: 20.4000,                 loss: nan
env3_second_0:                 episode reward: -20.4000,                 loss: nan
env4_first_0:                 episode reward: 20.3000,                 loss: nan
env4_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 2633.35,                last time consumption/overall running time: 1462.1337s / 258083.1391 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 1658.65,                last time consumption/overall running time: 918.2570s / 259001.3961 s
env0_first_0:                 episode reward: 21.7500,                 loss: 0.0114
env0_second_0:                 episode reward: -21.7500,                 loss: nan
env1_first_0:                 episode reward: 22.1000,                 loss: nan
env1_second_0:                 episode reward: -22.1000,                 loss: nan
env2_first_0:                 episode reward: 21.6500,                 loss: nan
env2_second_0:                 episode reward: -21.6500,                 loss: nan
env3_first_0:                 episode reward: 21.0500,                 loss: nan
env3_second_0:                 episode reward: -21.0500,                 loss: nan
env4_first_0:                 episode reward: 21.6500,                 loss: nan
env4_second_0:                 episode reward: -21.6500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 2095.1,                last time consumption/overall running time: 1165.9802s / 260167.3763 s
env0_first_0:                 episode reward: 9.1000,                 loss: 0.0120
env0_second_0:                 episode reward: -9.1000,                 loss: nan
env1_first_0:                 episode reward: 9.6500,                 loss: nan
env1_second_0:                 episode reward: -9.6500,                 loss: nan
env2_first_0:                 episode reward: 9.0500,                 loss: nan
env2_second_0:                 episode reward: -9.0500,                 loss: nan
env3_first_0:                 episode reward: 9.3000,                 loss: nan
env3_second_0:                 episode reward: -9.3000,                 loss: nan
env4_first_0:                 episode reward: 9.7000,                 loss: nan
env4_second_0:                 episode reward: -9.7000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 1746.75,                last time consumption/overall running time: 960.5910s / 261127.9673 s
env0_first_0:                 episode reward: 21.2500,                 loss: 0.0121
env0_second_0:                 episode reward: -21.2500,                 loss: nan
env1_first_0:                 episode reward: 21.5500,                 loss: nan
env1_second_0:                 episode reward: -21.5500,                 loss: nan
env2_first_0:                 episode reward: 20.1000,                 loss: nan
env2_second_0:                 episode reward: -20.1000,                 loss: nan
env3_first_0:                 episode reward: 20.5500,                 loss: nan
env3_second_0:                 episode reward: -20.5500,                 loss: nan
env4_first_0:                 episode reward: 21.1500,                 loss: nan
env4_second_0:                 episode reward: -21.1500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 1705.65,                last time consumption/overall running time: 906.5729s / 262034.5402 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0113
env0_second_0:                 episode reward: -20.8000,                 loss: nan
env1_first_0:                 episode reward: 21.0500,                 loss: nan
env1_second_0:                 episode reward: -21.0500,                 loss: nan
env2_first_0:                 episode reward: 20.6500,                 loss: nan
env2_second_0:                 episode reward: -20.6500,                 loss: nan
env3_first_0:                 episode reward: 21.2500,                 loss: nan
env3_second_0:                 episode reward: -21.2500,                 loss: nan
env4_first_0:                 episode reward: 19.8500,                 loss: nan
env4_second_0:                 episode reward: -19.8500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 2727.95,                last time consumption/overall running time: 1443.7979s / 263478.3380 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 1767.4,                last time consumption/overall running time: 951.6117s / 264429.9497 s
env0_first_0:                 episode reward: 16.9500,                 loss: 0.0113
env0_second_0:                 episode reward: -16.9500,                 loss: nan
env1_first_0:                 episode reward: 16.9500,                 loss: nan
env1_second_0:                 episode reward: -16.9500,                 loss: nan
env2_first_0:                 episode reward: 17.6000,                 loss: nan
env2_second_0:                 episode reward: -17.6000,                 loss: nan
env3_first_0:                 episode reward: 16.7000,                 loss: nan
env3_second_0:                 episode reward: -16.7000,                 loss: nan
env4_first_0:                 episode reward: 20.1000,                 loss: nan
env4_second_0:                 episode reward: -20.1000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 1815.55,                last time consumption/overall running time: 962.9717s / 265392.9215 s
env0_first_0:                 episode reward: 17.8500,                 loss: 0.0119
env0_second_0:                 episode reward: -17.8500,                 loss: nan
env1_first_0:                 episode reward: 17.8500,                 loss: nan
env1_second_0:                 episode reward: -17.8500,                 loss: nan
env2_first_0:                 episode reward: 18.6000,                 loss: nan
env2_second_0:                 episode reward: -18.6000,                 loss: nan
env3_first_0:                 episode reward: 19.2500,                 loss: nan
env3_second_0:                 episode reward: -19.2500,                 loss: nan
env4_first_0:                 episode reward: 18.2500,                 loss: nan
env4_second_0:                 episode reward: -18.2500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 1760.7,                last time consumption/overall running time: 934.5719s / 266327.4933 s
env0_first_0:                 episode reward: 19.2500,                 loss: 0.0116
env0_second_0:                 episode reward: -19.2500,                 loss: nan
env1_first_0:                 episode reward: 20.1000,                 loss: nan
env1_second_0:                 episode reward: -20.1000,                 loss: nan
env2_first_0:                 episode reward: 19.6500,                 loss: nan
env2_second_0:                 episode reward: -19.6500,                 loss: nan
env3_first_0:                 episode reward: 19.2500,                 loss: nan
env3_second_0:                 episode reward: -19.2500,                 loss: nan
env4_first_0:                 episode reward: 19.3500,                 loss: nan
env4_second_0:                 episode reward: -19.3500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 1751.8,                last time consumption/overall running time: 925.0351s / 267252.5284 s
env0_first_0:                 episode reward: 20.4000,                 loss: 0.0109
env0_second_0:                 episode reward: -20.4000,                 loss: nan
env1_first_0:                 episode reward: 20.5000,                 loss: nan
env1_second_0:                 episode reward: -20.5000,                 loss: nan
env2_first_0:                 episode reward: 21.0000,                 loss: nan
env2_second_0:                 episode reward: -21.0000,                 loss: nan
env3_first_0:                 episode reward: 21.0000,                 loss: nan
env3_second_0:                 episode reward: -21.0000,                 loss: nan
env4_first_0:                 episode reward: 20.6000,                 loss: nan
env4_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1863.75,                last time consumption/overall running time: 983.0481s / 268235.5765 s
env0_first_0:                 episode reward: 18.2000,                 loss: 0.0105
env0_second_0:                 episode reward: -18.2000,                 loss: nan
env1_first_0:                 episode reward: 18.4500,                 loss: nan
env1_second_0:                 episode reward: -18.4500,                 loss: nan
env2_first_0:                 episode reward: 17.5500,                 loss: nan
env2_second_0:                 episode reward: -17.5500,                 loss: nan
env3_first_0:                 episode reward: 17.8000,                 loss: nan
env3_second_0:                 episode reward: -17.8000,                 loss: nan
env4_first_0:                 episode reward: 18.4500,                 loss: nan
env4_second_0:                 episode reward: -18.4500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 1747.5,                last time consumption/overall running time: 927.2804s / 269162.8569 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0106
env0_second_0:                 episode reward: -20.5500,                 loss: nan
env1_first_0:                 episode reward: 20.2000,                 loss: nan
env1_second_0:                 episode reward: -20.2000,                 loss: nan
env2_first_0:                 episode reward: 20.8500,                 loss: nan
env2_second_0:                 episode reward: -20.8500,                 loss: nan
env3_first_0:                 episode reward: 21.3500,                 loss: nan
env3_second_0:                 episode reward: -21.3500,                 loss: nan
env4_first_0:                 episode reward: 21.1500,                 loss: nan
env4_second_0:                 episode reward: -21.1500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 1749.6,                last time consumption/overall running time: 918.7595s / 270081.6164 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0114
env0_second_0:                 episode reward: -20.4500,                 loss: nan
env1_first_0:                 episode reward: 21.5500,                 loss: nan
env1_second_0:                 episode reward: -21.5500,                 loss: nan
env2_first_0:                 episode reward: 20.5000,                 loss: nan
env2_second_0:                 episode reward: -20.5000,                 loss: nan
env3_first_0:                 episode reward: 19.1000,                 loss: nan
env3_second_0:                 episode reward: -19.1000,                 loss: nan
env4_first_0:                 episode reward: 21.2000,                 loss: nan
env4_second_0:                 episode reward: -21.2000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 1893.8,                last time consumption/overall running time: 956.6106s / 271038.2271 s
env0_first_0:                 episode reward: 15.9000,                 loss: 0.0106
env0_second_0:                 episode reward: -15.9000,                 loss: nan
env1_first_0:                 episode reward: 18.3500,                 loss: nan
env1_second_0:                 episode reward: -18.3500,                 loss: nan
env2_first_0:                 episode reward: 15.7500,                 loss: nan
env2_second_0:                 episode reward: -15.7500,                 loss: nan
env3_first_0:                 episode reward: 15.9000,                 loss: nan
env3_second_0:                 episode reward: -15.9000,                 loss: nan
env4_first_0:                 episode reward: 15.0500,                 loss: nan
env4_second_0:                 episode reward: -15.0500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 1728.7,                last time consumption/overall running time: 877.9989s / 271916.2259 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0103
env0_second_0:                 episode reward: -20.9500,                 loss: nan
env1_first_0:                 episode reward: 21.3000,                 loss: nan
env1_second_0:                 episode reward: -21.3000,                 loss: nan
env2_first_0:                 episode reward: 21.1500,                 loss: nan
env2_second_0:                 episode reward: -21.1500,                 loss: nan
env3_first_0:                 episode reward: 21.3000,                 loss: nan
env3_second_0:                 episode reward: -21.3000,                 loss: nan
env4_first_0:                 episode reward: 20.3500,                 loss: nan
env4_second_0:                 episode reward: -20.3500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 2018.75,                last time consumption/overall running time: 1026.3699s / 272942.5958 s
env0_first_0:                 episode reward: 13.8500,                 loss: 0.0105
env0_second_0:                 episode reward: -13.8500,                 loss: nan
env1_first_0:                 episode reward: 14.0500,                 loss: nan
env1_second_0:                 episode reward: -14.0500,                 loss: nan
env2_first_0:                 episode reward: 14.0000,                 loss: nan
env2_second_0:                 episode reward: -14.0000,                 loss: nan
env3_first_0:                 episode reward: 14.2500,                 loss: nan
env3_second_0:                 episode reward: -14.2500,                 loss: nan
env4_first_0:                 episode reward: 14.2500,                 loss: nan
env4_second_0:                 episode reward: -14.2500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 1914.1,                last time consumption/overall running time: 975.8296s / 273918.4255 s
env0_first_0:                 episode reward: 16.7500,                 loss: 0.0107
env0_second_0:                 episode reward: -16.7500,                 loss: nan
env1_first_0:                 episode reward: 16.1500,                 loss: nan
env1_second_0:                 episode reward: -16.1500,                 loss: nan
env2_first_0:                 episode reward: 17.9500,                 loss: nan
env2_second_0:                 episode reward: -17.9500,                 loss: nan
env3_first_0:                 episode reward: 15.6000,                 loss: nan
env3_second_0:                 episode reward: -15.6000,                 loss: nan
env4_first_0:                 episode reward: 16.8000,                 loss: nan
env4_second_0:                 episode reward: -16.8000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 2031.9,                last time consumption/overall running time: 1021.5005s / 274939.9260 s
env0_first_0:                 episode reward: 16.1000,                 loss: 0.0111
env0_second_0:                 episode reward: -16.1000,                 loss: nan
env1_first_0:                 episode reward: 13.5500,                 loss: nan
env1_second_0:                 episode reward: -13.5500,                 loss: nan
env2_first_0:                 episode reward: 16.3500,                 loss: nan
env2_second_0:                 episode reward: -16.3500,                 loss: nan
env3_first_0:                 episode reward: 14.9000,                 loss: nan
env3_second_0:                 episode reward: -14.9000,                 loss: nan
env4_first_0:                 episode reward: 15.0500,                 loss: nan
env4_second_0:                 episode reward: -15.0500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 2393.65,                last time consumption/overall running time: 1206.3290s / 276146.2550 s
env0_first_0:                 episode reward: 11.5000,                 loss: 0.0111
env0_second_0:                 episode reward: -11.5000,                 loss: nan
env1_first_0:                 episode reward: 8.1500,                 loss: nan
env1_second_0:                 episode reward: -8.1500,                 loss: nan
env2_first_0:                 episode reward: 10.7000,                 loss: nan
env2_second_0:                 episode reward: -10.7000,                 loss: nan
env3_first_0:                 episode reward: 6.5500,                 loss: nan
env3_second_0:                 episode reward: -6.5500,                 loss: nan
env4_first_0:                 episode reward: 7.3000,                 loss: nan
env4_second_0:                 episode reward: -7.3000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 1916.95,                last time consumption/overall running time: 972.4654s / 277118.7204 s
env0_first_0:                 episode reward: 18.0500,                 loss: 0.0112
env0_second_0:                 episode reward: -18.0500,                 loss: nan
env1_first_0:                 episode reward: 18.9500,                 loss: nan
env1_second_0:                 episode reward: -18.9500,                 loss: nan
env2_first_0:                 episode reward: 16.2500,                 loss: nan
env2_second_0:                 episode reward: -16.2500,                 loss: nan
env3_first_0:                 episode reward: 19.1000,                 loss: nan
env3_second_0:                 episode reward: -19.1000,                 loss: nan
env4_first_0:                 episode reward: 18.5500,                 loss: nan
env4_second_0:                 episode reward: -18.5500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 2259.35,                last time consumption/overall running time: 1156.5254s / 278275.2458 s
env0_first_0:                 episode reward: 10.8000,                 loss: 0.0110
env0_second_0:                 episode reward: -10.8000,                 loss: nan
env1_first_0:                 episode reward: 10.7000,                 loss: nan
env1_second_0:                 episode reward: -10.7000,                 loss: nan
env2_first_0:                 episode reward: 9.9500,                 loss: nan
env2_second_0:                 episode reward: -9.9500,                 loss: nan
env3_first_0:                 episode reward: 10.8500,                 loss: nan
env3_second_0:                 episode reward: -10.8500,                 loss: nan
env4_first_0:                 episode reward: 7.8000,                 loss: nan
env4_second_0:                 episode reward: -7.8000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 1833.4,                last time consumption/overall running time: 938.8301s / 279214.0759 s
env0_first_0:                 episode reward: 18.2000,                 loss: 0.0103
env0_second_0:                 episode reward: -18.2000,                 loss: nan
env1_first_0:                 episode reward: 18.3500,                 loss: nan
env1_second_0:                 episode reward: -18.3500,                 loss: nan
env2_first_0:                 episode reward: 17.0000,                 loss: nan
env2_second_0:                 episode reward: -17.0000,                 loss: nan
env3_first_0:                 episode reward: 17.9000,                 loss: nan
env3_second_0:                 episode reward: -17.9000,                 loss: nan
env4_first_0:                 episode reward: 18.9000,                 loss: nan
env4_second_0:                 episode reward: -18.9000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 1695.05,                last time consumption/overall running time: 853.3708s / 280067.4468 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.0099
env0_second_0:                 episode reward: -20.5000,                 loss: nan
env1_first_0:                 episode reward: 20.3000,                 loss: nan
env1_second_0:                 episode reward: -20.3000,                 loss: nan
env2_first_0:                 episode reward: 17.7000,                 loss: nan
env2_second_0:                 episode reward: -17.7000,                 loss: nan
env3_first_0:                 episode reward: 17.8500,                 loss: nan
env3_second_0:                 episode reward: -17.8500,                 loss: nan
env4_first_0:                 episode reward: 17.8000,                 loss: nan
env4_second_0:                 episode reward: -17.8000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 1674.25,                last time consumption/overall running time: 847.3856s / 280914.8323 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0097
env0_second_0:                 episode reward: -20.9500,                 loss: nan
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
env2_first_0:                 episode reward: 20.8500,                 loss: nan
env2_second_0:                 episode reward: -20.8500,                 loss: nan
env3_first_0:                 episode reward: 20.5000,                 loss: nan
env3_second_0:                 episode reward: -20.5000,                 loss: nan
env4_first_0:                 episode reward: 21.9500,                 loss: nan
env4_second_0:                 episode reward: -21.9500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 1780.15,                last time consumption/overall running time: 843.7385s / 281758.5708 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0095
env0_second_0:                 episode reward: -20.7000,                 loss: nan
env1_first_0:                 episode reward: 20.1500,                 loss: nan
env1_second_0:                 episode reward: -20.1500,                 loss: nan
env2_first_0:                 episode reward: 21.7000,                 loss: nan
env2_second_0:                 episode reward: -21.7000,                 loss: nan
env3_first_0:                 episode reward: 21.5500,                 loss: nan
env3_second_0:                 episode reward: -21.5500,                 loss: nan
env4_first_0:                 episode reward: 20.5000,                 loss: nan
env4_second_0:                 episode reward: -20.5000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 1687.8,                last time consumption/overall running time: 801.0880s / 282559.6588 s
env0_first_0:                 episode reward: 21.1000,                 loss: 0.0095
env0_second_0:                 episode reward: -21.1000,                 loss: nan
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
env2_first_0:                 episode reward: 20.7500,                 loss: nan
env2_second_0:                 episode reward: -20.7500,                 loss: nan
env3_first_0:                 episode reward: 21.3500,                 loss: nan
env3_second_0:                 episode reward: -21.3500,                 loss: nan
env4_first_0:                 episode reward: 20.9000,                 loss: nan
env4_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 1854.05,                last time consumption/overall running time: 880.8313s / 283440.4902 s
env0_first_0:                 episode reward: 17.8500,                 loss: 0.0093
env0_second_0:                 episode reward: -17.8500,                 loss: nan
env1_first_0:                 episode reward: 17.4000,                 loss: nan
env1_second_0:                 episode reward: -17.4000,                 loss: nan
env2_first_0:                 episode reward: 18.0500,                 loss: nan
env2_second_0:                 episode reward: -18.0500,                 loss: nan
env3_first_0:                 episode reward: 17.4500,                 loss: nan
env3_second_0:                 episode reward: -17.4500,                 loss: nan
env4_first_0:                 episode reward: 17.5000,                 loss: nan
env4_second_0:                 episode reward: -17.5000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 1804.75,                last time consumption/overall running time: 844.8084s / 284285.2986 s
env0_first_0:                 episode reward: 18.3500,                 loss: 0.0095
env0_second_0:                 episode reward: -18.3500,                 loss: nan
env1_first_0:                 episode reward: 19.1000,                 loss: nan
env1_second_0:                 episode reward: -19.1000,                 loss: nan
env2_first_0:                 episode reward: 19.2500,                 loss: nan
env2_second_0:                 episode reward: -19.2500,                 loss: nan
env3_first_0:                 episode reward: 19.7000,                 loss: nan
env3_second_0:                 episode reward: -19.7000,                 loss: nan
env4_first_0:                 episode reward: 19.7500,                 loss: nan
env4_second_0:                 episode reward: -19.7500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 1594.4,                last time consumption/overall running time: 748.9994s / 285034.2980 s
env0_first_0:                 episode reward: 22.2000,                 loss: 0.0091
env0_second_0:                 episode reward: -22.2000,                 loss: nan
env1_first_0:                 episode reward: 21.1500,                 loss: nan
env1_second_0:                 episode reward: -21.1500,                 loss: nan
env2_first_0:                 episode reward: 21.5000,                 loss: nan
env2_second_0:                 episode reward: -21.5000,                 loss: nan
env3_first_0:                 episode reward: 22.2500,                 loss: nan
env3_second_0:                 episode reward: -22.2500,                 loss: nan
env4_first_0:                 episode reward: 21.7500,                 loss: nan
env4_second_0:                 episode reward: -21.7500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 2196.25,                last time consumption/overall running time: 1014.5686s / 286048.8666 s
env0_first_0:                 episode reward: 7.7500,                 loss: 0.0096
env0_second_0:                 episode reward: -7.7500,                 loss: nan
env1_first_0:                 episode reward: 7.6000,                 loss: nan
env1_second_0:                 episode reward: -7.6000,                 loss: nan
env2_first_0:                 episode reward: 7.9500,                 loss: nan
env2_second_0:                 episode reward: -7.9500,                 loss: nan
env3_first_0:                 episode reward: 8.9500,                 loss: nan
env3_second_0:                 episode reward: -8.9500,                 loss: nan
env4_first_0:                 episode reward: 7.1500,                 loss: nan
env4_second_0:                 episode reward: -7.1500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 1657.8,                last time consumption/overall running time: 777.7600s / 286826.6266 s
env0_first_0:                 episode reward: 22.5000,                 loss: 0.0100
env0_second_0:                 episode reward: -22.5000,                 loss: nan
env1_first_0:                 episode reward: 22.1000,                 loss: nan
env1_second_0:                 episode reward: -22.1000,                 loss: nan
env2_first_0:                 episode reward: 22.2500,                 loss: nan
env2_second_0:                 episode reward: -22.2500,                 loss: nan
env3_first_0:                 episode reward: 22.6500,                 loss: nan
env3_second_0:                 episode reward: -22.6500,                 loss: nan
env4_first_0:                 episode reward: 22.6000,                 loss: nan
env4_second_0:                 episode reward: -22.6000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 1598.65,                last time consumption/overall running time: 752.3756s / 287579.0022 s
env0_first_0:                 episode reward: 23.0000,                 loss: 0.0100
env0_second_0:                 episode reward: -23.0000,                 loss: nan
env1_first_0:                 episode reward: 22.8500,                 loss: nan
env1_second_0:                 episode reward: -22.8500,                 loss: nan
env2_first_0:                 episode reward: 22.3500,                 loss: nan
env2_second_0:                 episode reward: -22.3500,                 loss: nan
env3_first_0:                 episode reward: 22.7000,                 loss: nan
env3_second_0:                 episode reward: -22.7000,                 loss: nan
env4_first_0:                 episode reward: 22.0500,                 loss: nan
env4_second_0:                 episode reward: -22.0500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 1689.15,                last time consumption/overall running time: 788.1373s / 288367.1395 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0099
env0_second_0:                 episode reward: -21.0000,                 loss: nan
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
env2_first_0:                 episode reward: 20.9000,                 loss: nan
env2_second_0:                 episode reward: -20.9000,                 loss: nan
env3_first_0:                 episode reward: 20.8000,                 loss: nan
env3_second_0:                 episode reward: -20.8000,                 loss: nan
env4_first_0:                 episode reward: 20.4500,                 loss: nan
env4_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 1606.75,                last time consumption/overall running time: 756.3313s / 289123.4708 s