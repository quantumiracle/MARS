2022-05-11 01:17:17.161613: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 01:17:17.161677: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 01:17:17.161682: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fbb5c600550>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510124814/mdp_arbitrary_mdp_selfplay2/40000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510124814/mdp_arbitrary_mdp_selfplay2/40000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510124814_exploit_40000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510124814_exploit_40000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8126s / 0.8126 s
agent0:                 episode reward: 2.9761,                 loss: nan
agent1:                 episode reward: -2.9761,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0721s / 0.8848 s
agent0:                 episode reward: 1.5817,                 loss: nan
agent1:                 episode reward: -1.5817,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0623s / 0.9470 s
agent0:                 episode reward: 1.9932,                 loss: nan
agent1:                 episode reward: -1.9932,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0631s / 1.0101 s
agent0:                 episode reward: 1.4572,                 loss: nan
agent1:                 episode reward: -1.4572,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5882s / 1.5982 s
agent0:                 episode reward: 1.6142,                 loss: nan
agent1:                 episode reward: -1.6142,                 loss: 0.4055
Episode: 101/30000 (0.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6665s / 2.2648 s
agent0:                 episode reward: 0.9882,                 loss: nan
agent1:                 episode reward: -0.9882,                 loss: 0.3734
Episode: 121/30000 (0.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6637s / 2.9285 s
agent0:                 episode reward: 2.0562,                 loss: nan
agent1:                 episode reward: -2.0562,                 loss: 0.3666
Episode: 141/30000 (0.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6597s / 3.5882 s
agent0:                 episode reward: 1.3158,                 loss: nan
agent1:                 episode reward: -1.3158,                 loss: 0.3596
Episode: 161/30000 (0.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6767s / 4.2649 s
agent0:                 episode reward: 1.8337,                 loss: nan
agent1:                 episode reward: -1.8337,                 loss: 0.3527
Episode: 181/30000 (0.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6667s / 4.9316 s
agent0:                 episode reward: 0.9941,                 loss: nan
agent1:                 episode reward: -0.9941,                 loss: 0.3677
Episode: 201/30000 (0.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6645s / 5.5960 s
agent0:                 episode reward: 2.2212,                 loss: nan
agent1:                 episode reward: -2.2212,                 loss: 0.3676
Episode: 221/30000 (0.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6729s / 6.2690 s
agent0:                 episode reward: 0.9663,                 loss: nan
agent1:                 episode reward: -0.9663,                 loss: 0.3676
Episode: 241/30000 (0.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6793s / 6.9482 s
agent0:                 episode reward: 1.4566,                 loss: nan
agent1:                 episode reward: -1.4566,                 loss: 0.3667
Episode: 261/30000 (0.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6852s / 7.6335 s
agent0:                 episode reward: 1.9442,                 loss: nan
agent1:                 episode reward: -1.9442,                 loss: 0.3638
Episode: 281/30000 (0.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6893s / 8.3227 s
agent0:                 episode reward: 1.3115,                 loss: nan
agent1:                 episode reward: -1.3115,                 loss: 0.3629
Episode: 301/30000 (1.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6794s / 9.0022 s
agent0:                 episode reward: 1.6768,                 loss: nan
agent1:                 episode reward: -1.6768,                 loss: 0.3592
Episode: 321/30000 (1.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7060s / 9.7081 s
agent0:                 episode reward: 1.2671,                 loss: nan
agent1:                 episode reward: -1.2671,                 loss: 0.3574
Episode: 341/30000 (1.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6847s / 10.3928 s
agent0:                 episode reward: 1.5431,                 loss: nan
agent1:                 episode reward: -1.5431,                 loss: 0.3537
Episode: 361/30000 (1.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7446s / 11.1374 s
agent0:                 episode reward: 1.2057,                 loss: nan
agent1:                 episode reward: -1.2057,                 loss: 0.3543
Episode: 381/30000 (1.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6900s / 11.8274 s
agent0:                 episode reward: 1.4388,                 loss: nan
agent1:                 episode reward: -1.4388,                 loss: 0.3148
Episode: 401/30000 (1.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6883s / 12.5158 s
agent0:                 episode reward: 1.5464,                 loss: nan
agent1:                 episode reward: -1.5464,                 loss: 0.3031
Episode: 421/30000 (1.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6982s / 13.2140 s
agent0:                 episode reward: 1.4551,                 loss: nan
agent1:                 episode reward: -1.4551,                 loss: 0.3001
Episode: 441/30000 (1.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6966s / 13.9106 s
agent0:                 episode reward: 1.1236,                 loss: nan
agent1:                 episode reward: -1.1236,                 loss: 0.2991
Episode: 461/30000 (1.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6996s / 14.6102 s
agent0:                 episode reward: 0.5489,                 loss: nan
agent1:                 episode reward: -0.5489,                 loss: 0.2965
Episode: 481/30000 (1.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7033s / 15.3135 s
agent0:                 episode reward: 1.9228,                 loss: nan
agent1:                 episode reward: -1.9228,                 loss: 0.2453
Episode: 501/30000 (1.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7019s / 16.0154 s
agent0:                 episode reward: 1.3422,                 loss: nan
agent1:                 episode reward: -1.3422,                 loss: 0.2286
Episode: 521/30000 (1.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7236s / 16.7390 s
agent0:                 episode reward: 1.2221,                 loss: nan
agent1:                 episode reward: -1.2221,                 loss: 0.2232
Episode: 541/30000 (1.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7181s / 17.4571 s
agent0:                 episode reward: 1.8772,                 loss: nan
agent1:                 episode reward: -1.8772,                 loss: 0.2186
Episode: 561/30000 (1.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7286s / 18.1857 s
agent0:                 episode reward: 1.4586,                 loss: nan
agent1:                 episode reward: -1.4586,                 loss: 0.2144
Episode: 581/30000 (1.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7137s / 18.8994 s
agent0:                 episode reward: 1.3539,                 loss: nan
agent1:                 episode reward: -1.3539,                 loss: 0.2114
Episode: 601/30000 (2.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7206s / 19.6200 s
agent0:                 episode reward: 1.3658,                 loss: nan
agent1:                 episode reward: -1.3658,                 loss: 0.2078
Episode: 621/30000 (2.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7233s / 20.3433 s
agent0:                 episode reward: 1.7840,                 loss: nan
agent1:                 episode reward: -1.7840,                 loss: 0.2094
Episode: 641/30000 (2.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7565s / 21.0998 s
agent0:                 episode reward: 2.2300,                 loss: nan
agent1:                 episode reward: -2.2300,                 loss: 0.2084
Episode: 661/30000 (2.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7332s / 21.8329 s
agent0:                 episode reward: 1.5882,                 loss: nan
agent1:                 episode reward: -1.5882,                 loss: 0.2070
Episode: 681/30000 (2.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7158s / 22.5488 s
agent0:                 episode reward: 1.8309,                 loss: nan
agent1:                 episode reward: -1.8309,                 loss: 0.2147
Episode: 701/30000 (2.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7405s / 23.2892 s
agent0:                 episode reward: 1.8913,                 loss: nan
agent1:                 episode reward: -1.8913,                 loss: 0.2149
Episode: 721/30000 (2.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7309s / 24.0201 s
agent0:                 episode reward: 1.1555,                 loss: nan
agent1:                 episode reward: -1.1555,                 loss: 0.2135
Episode: 741/30000 (2.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7288s / 24.7489 s
agent0:                 episode reward: 1.2530,                 loss: nan
agent1:                 episode reward: -1.2530,                 loss: 0.2131
Episode: 761/30000 (2.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7352s / 25.4841 s
agent0:                 episode reward: 1.5230,                 loss: nan
agent1:                 episode reward: -1.5230,                 loss: 0.2149
Episode: 781/30000 (2.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7537s / 26.2378 s
agent0:                 episode reward: 0.9214,                 loss: nan
agent1:                 episode reward: -0.9214,                 loss: 0.2541
Episode: 801/30000 (2.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7410s / 26.9788 s
agent0:                 episode reward: 1.1914,                 loss: nan
agent1:                 episode reward: -1.1914,                 loss: 0.2582
Episode: 821/30000 (2.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7428s / 27.7216 s
agent0:                 episode reward: 1.5099,                 loss: nan
agent1:                 episode reward: -1.5099,                 loss: 0.2563
Episode: 841/30000 (2.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7390s / 28.4606 s
agent0:                 episode reward: 0.8373,                 loss: nan
agent1:                 episode reward: -0.8373,                 loss: 0.2572
Episode: 861/30000 (2.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7490s / 29.2095 s
agent0:                 episode reward: 1.9341,                 loss: nan
agent1:                 episode reward: -1.9341,                 loss: 0.2566
Episode: 881/30000 (2.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7446s / 29.9541 s
agent0:                 episode reward: 1.3201,                 loss: nan
agent1:                 episode reward: -1.3201,                 loss: 0.2851
Episode: 901/30000 (3.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7479s / 30.7020 s
agent0:                 episode reward: 1.7609,                 loss: nan
agent1:                 episode reward: -1.7609,                 loss: 0.2844
Episode: 921/30000 (3.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8182s / 31.5202 s
agent0:                 episode reward: 1.4839,                 loss: nan
agent1:                 episode reward: -1.4839,                 loss: 0.2817
Episode: 941/30000 (3.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7776s / 32.2978 s
agent0:                 episode reward: 1.4777,                 loss: nan
agent1:                 episode reward: -1.4777,                 loss: 0.2795
Episode: 961/30000 (3.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7595s / 33.0573 s
agent0:                 episode reward: 1.1700,                 loss: nan
agent1:                 episode reward: -1.1700,                 loss: 0.2781
Episode: 981/30000 (3.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7566s / 33.8140 s
agent0:                 episode reward: 1.3766,                 loss: nan
agent1:                 episode reward: -1.3766,                 loss: 0.2828
Episode: 1001/30000 (3.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7771s / 34.5910 s
agent0:                 episode reward: 1.6130,                 loss: nan
agent1:                 episode reward: -1.6130,                 loss: 0.2770
Episode: 1021/30000 (3.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7735s / 35.3645 s
agent0:                 episode reward: 1.1073,                 loss: nan
agent1:                 episode reward: -1.1073,                 loss: 0.2715
Episode: 1041/30000 (3.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7802s / 36.1447 s
agent0:                 episode reward: 1.0508,                 loss: nan
agent1:                 episode reward: -1.0508,                 loss: 0.2668
Episode: 1061/30000 (3.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7689s / 36.9136 s
agent0:                 episode reward: 0.2547,                 loss: nan
agent1:                 episode reward: -0.2547,                 loss: 0.2646
Episode: 1081/30000 (3.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7801s / 37.6937 s
agent0:                 episode reward: 1.7350,                 loss: nan
agent1:                 episode reward: -1.7350,                 loss: 0.2516
Episode: 1101/30000 (3.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7801s / 38.4738 s
agent0:                 episode reward: 1.4023,                 loss: nan
agent1:                 episode reward: -1.4023,                 loss: 0.2432
Episode: 1121/30000 (3.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7756s / 39.2494 s
agent0:                 episode reward: 0.7647,                 loss: nan
agent1:                 episode reward: -0.7647,                 loss: 0.2428
Episode: 1141/30000 (3.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7822s / 40.0316 s
agent0:                 episode reward: 0.7370,                 loss: nan
agent1:                 episode reward: -0.7370,                 loss: 0.2421
Episode: 1161/30000 (3.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7766s / 40.8082 s
agent0:                 episode reward: 0.7146,                 loss: nan
agent1:                 episode reward: -0.7146,                 loss: 0.2417
Episode: 1181/30000 (3.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8259s / 41.6342 s
agent0:                 episode reward: 1.7217,                 loss: nan
agent1:                 episode reward: -1.7217,                 loss: 0.2431
Episode: 1201/30000 (4.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7849s / 42.4191 s
agent0:                 episode reward: 1.2966,                 loss: nan
agent1:                 episode reward: -1.2966,                 loss: 0.2396
Episode: 1221/30000 (4.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8018s / 43.2209 s
agent0:                 episode reward: 1.0316,                 loss: nan
agent1:                 episode reward: -1.0316,                 loss: 0.2391
Episode: 1241/30000 (4.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7937s / 44.0146 s
agent0:                 episode reward: 0.7164,                 loss: nan
agent1:                 episode reward: -0.7164,                 loss: 0.2402
Episode: 1261/30000 (4.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7927s / 44.8072 s
agent0:                 episode reward: 2.0521,                 loss: nan
agent1:                 episode reward: -2.0521,                 loss: 0.2394
Episode: 1281/30000 (4.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7871s / 45.5943 s
agent0:                 episode reward: 1.1319,                 loss: nan
agent1:                 episode reward: -1.1319,                 loss: 0.2685
Episode: 1301/30000 (4.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7869s / 46.3812 s
agent0:                 episode reward: 0.5762,                 loss: nan
agent1:                 episode reward: -0.5762,                 loss: 0.2679
Episode: 1321/30000 (4.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7970s / 47.1782 s
agent0:                 episode reward: 1.5733,                 loss: nan
agent1:                 episode reward: -1.5733,                 loss: 0.2669
Episode: 1341/30000 (4.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7946s / 47.9728 s
agent0:                 episode reward: 1.4032,                 loss: nan
agent1:                 episode reward: -1.4032,                 loss: 0.2664
Episode: 1361/30000 (4.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7956s / 48.7684 s
agent0:                 episode reward: 1.4318,                 loss: nan
agent1:                 episode reward: -1.4318,                 loss: 0.2664
Episode: 1381/30000 (4.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7934s / 49.5618 s
agent0:                 episode reward: 1.4138,                 loss: nan
agent1:                 episode reward: -1.4138,                 loss: 0.2794
Episode: 1401/30000 (4.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8244s / 50.3862 s
agent0:                 episode reward: 1.1216,                 loss: nan
agent1:                 episode reward: -1.1216,                 loss: 0.2745
Episode: 1421/30000 (4.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8205s / 51.2067 s
agent0:                 episode reward: 1.2515,                 loss: nan
agent1:                 episode reward: -1.2515,                 loss: 0.2745
Episode: 1441/30000 (4.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8506s / 52.0573 s
agent0:                 episode reward: 1.1516,                 loss: nan
agent1:                 episode reward: -1.1516,                 loss: 0.2720
Episode: 1461/30000 (4.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8128s / 52.8702 s
agent0:                 episode reward: 0.5586,                 loss: nan
agent1:                 episode reward: -0.5586,                 loss: 0.2711
Episode: 1481/30000 (4.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8117s / 53.6818 s
agent0:                 episode reward: 1.6087,                 loss: nan
agent1:                 episode reward: -1.6087,                 loss: 0.2465
Episode: 1501/30000 (5.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8123s / 54.4941 s
agent0:                 episode reward: 1.6029,                 loss: nan
agent1:                 episode reward: -1.6029,                 loss: 0.2333
Episode: 1521/30000 (5.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8127s / 55.3068 s
agent0:                 episode reward: 0.1721,                 loss: nan
agent1:                 episode reward: -0.1721,                 loss: 0.2319
Episode: 1541/30000 (5.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8196s / 56.1263 s
agent0:                 episode reward: 1.4311,                 loss: nan
agent1:                 episode reward: -1.4311,                 loss: 0.2302
Episode: 1561/30000 (5.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8151s / 56.9415 s
agent0:                 episode reward: 0.8429,                 loss: nan
agent1:                 episode reward: -0.8429,                 loss: 0.2299
Episode: 1581/30000 (5.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8219s / 57.7634 s
agent0:                 episode reward: 0.9367,                 loss: nan
agent1:                 episode reward: -0.9367,                 loss: 0.1750
Episode: 1601/30000 (5.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8225s / 58.5859 s
agent0:                 episode reward: 1.0169,                 loss: nan
agent1:                 episode reward: -1.0169,                 loss: 0.1556
Episode: 1621/30000 (5.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8459s / 59.4318 s
agent0:                 episode reward: 1.8931,                 loss: nan
agent1:                 episode reward: -1.8931,                 loss: 0.1537
Episode: 1641/30000 (5.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8214s / 60.2532 s
agent0:                 episode reward: 0.5107,                 loss: nan
agent1:                 episode reward: -0.5107,                 loss: 0.1519
Episode: 1661/30000 (5.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8182s / 61.0714 s
agent0:                 episode reward: 2.0480,                 loss: nan
agent1:                 episode reward: -2.0480,                 loss: 0.1499
Episode: 1681/30000 (5.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8444s / 61.9158 s
agent0:                 episode reward: 1.3175,                 loss: nan
agent1:                 episode reward: -1.3175,                 loss: 0.1552
Episode: 1701/30000 (5.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8749s / 62.7907 s
agent0:                 episode reward: 1.9181,                 loss: nan
agent1:                 episode reward: -1.9181,                 loss: 0.1534
Episode: 1721/30000 (5.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8250s / 63.6157 s
agent0:                 episode reward: 1.2698,                 loss: nan
agent1:                 episode reward: -1.2698,                 loss: 0.1525
Episode: 1741/30000 (5.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8323s / 64.4480 s
agent0:                 episode reward: 1.3871,                 loss: nan
agent1:                 episode reward: -1.3871,                 loss: 0.1529
Episode: 1761/30000 (5.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8540s / 65.3020 s
agent0:                 episode reward: 1.3129,                 loss: nan
agent1:                 episode reward: -1.3129,                 loss: 0.1527
Episode: 1781/30000 (5.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8324s / 66.1344 s
agent0:                 episode reward: 1.4867,                 loss: nan
agent1:                 episode reward: -1.4867,                 loss: 0.1765
Episode: 1801/30000 (6.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8406s / 66.9750 s
agent0:                 episode reward: 1.1395,                 loss: nan
agent1:                 episode reward: -1.1395,                 loss: 0.1776
Episode: 1821/30000 (6.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8776s / 67.8526 s
agent0:                 episode reward: 1.0884,                 loss: nan
agent1:                 episode reward: -1.0884,                 loss: 0.1769
Episode: 1841/30000 (6.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8417s / 68.6943 s
agent0:                 episode reward: 0.8950,                 loss: nan
agent1:                 episode reward: -0.8950,                 loss: 0.1759
Episode: 1861/30000 (6.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8415s / 69.5358 s
agent0:                 episode reward: 0.9237,                 loss: nan
agent1:                 episode reward: -0.9237,                 loss: 0.1775
Episode: 1881/30000 (6.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8481s / 70.3839 s
agent0:                 episode reward: 1.7639,                 loss: nan
agent1:                 episode reward: -1.7639,                 loss: 0.2146
Episode: 1901/30000 (6.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8573s / 71.2413 s
agent0:                 episode reward: 0.8108,                 loss: nan
agent1:                 episode reward: -0.8108,                 loss: 0.2147
Episode: 1921/30000 (6.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8546s / 72.0959 s
agent0:                 episode reward: 0.4009,                 loss: nan
agent1:                 episode reward: -0.4009,                 loss: 0.2138
Episode: 1941/30000 (6.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9105s / 73.0064 s
agent0:                 episode reward: 0.8585,                 loss: nan
agent1:                 episode reward: -0.8585,                 loss: 0.2132
Episode: 1961/30000 (6.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8620s / 73.8684 s
agent0:                 episode reward: 1.7241,                 loss: nan
agent1:                 episode reward: -1.7241,                 loss: 0.2102
Episode: 1981/30000 (6.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8628s / 74.7312 s
agent0:                 episode reward: 1.6929,                 loss: nan
agent1:                 episode reward: -1.6929,                 loss: 0.2452
Episode: 2001/30000 (6.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8604s / 75.5916 s
agent0:                 episode reward: 1.8132,                 loss: nan
agent1:                 episode reward: -1.8132,                 loss: 0.2418
Episode: 2021/30000 (6.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8846s / 76.4761 s
agent0:                 episode reward: 0.7565,                 loss: nan
agent1:                 episode reward: -0.7565,                 loss: 0.2429
Episode: 2041/30000 (6.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8745s / 77.3506 s
agent0:                 episode reward: 1.3854,                 loss: nan
agent1:                 episode reward: -1.3854,                 loss: 0.2438
Episode: 2061/30000 (6.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8791s / 78.2297 s
agent0:                 episode reward: 0.9517,                 loss: nan
agent1:                 episode reward: -0.9517,                 loss: 0.2421
Episode: 2081/30000 (6.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8701s / 79.0998 s
agent0:                 episode reward: 0.8066,                 loss: nan
agent1:                 episode reward: -0.8066,                 loss: 0.2535
Episode: 2101/30000 (7.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8732s / 79.9730 s
agent0:                 episode reward: 1.3903,                 loss: nan
agent1:                 episode reward: -1.3903,                 loss: 0.2519
Episode: 2121/30000 (7.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8765s / 80.8495 s
agent0:                 episode reward: 1.6971,                 loss: nan
agent1:                 episode reward: -1.6971,                 loss: 0.2500
Episode: 2141/30000 (7.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8886s / 81.7381 s
agent0:                 episode reward: 1.2605,                 loss: nan
agent1:                 episode reward: -1.2605,                 loss: 0.2507
Episode: 2161/30000 (7.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9174s / 82.6555 s
agent0:                 episode reward: 1.5482,                 loss: nan
agent1:                 episode reward: -1.5482,                 loss: 0.2498
Episode: 2181/30000 (7.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9078s / 83.5634 s
agent0:                 episode reward: 0.5352,                 loss: nan
agent1:                 episode reward: -0.5352,                 loss: 0.2475
Episode: 2201/30000 (7.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9033s / 84.4667 s
agent0:                 episode reward: 0.7555,                 loss: nan
agent1:                 episode reward: -0.7555,                 loss: 0.2462
Episode: 2221/30000 (7.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9434s / 85.4101 s
agent0:                 episode reward: 0.6652,                 loss: nan
agent1:                 episode reward: -0.6652,                 loss: 0.2453
Episode: 2241/30000 (7.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9016s / 86.3117 s
agent0:                 episode reward: 1.1394,                 loss: nan
agent1:                 episode reward: -1.1394,                 loss: 0.2437
Episode: 2261/30000 (7.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8912s / 87.2030 s
agent0:                 episode reward: 0.9054,                 loss: nan
agent1:                 episode reward: -0.9054,                 loss: 0.2425
Episode: 2281/30000 (7.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9032s / 88.1062 s
agent0:                 episode reward: 0.7042,                 loss: nan
agent1:                 episode reward: -0.7042,                 loss: 0.2854
Episode: 2301/30000 (7.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9033s / 89.0095 s
agent0:                 episode reward: 0.5390,                 loss: nan
agent1:                 episode reward: -0.5390,                 loss: 0.2847
Episode: 2321/30000 (7.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8920s / 89.9015 s
agent0:                 episode reward: 0.6174,                 loss: nan
agent1:                 episode reward: -0.6174,                 loss: 0.2822
Episode: 2341/30000 (7.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8981s / 90.7996 s
agent0:                 episode reward: 0.6486,                 loss: nan
agent1:                 episode reward: -0.6486,                 loss: 0.2799
Episode: 2361/30000 (7.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9059s / 91.7055 s
agent0:                 episode reward: 0.3789,                 loss: nan
agent1:                 episode reward: -0.3789,                 loss: 0.2783
Episode: 2381/30000 (7.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9534s / 92.6589 s
agent0:                 episode reward: 0.3986,                 loss: nan
agent1:                 episode reward: -0.3986,                 loss: 0.2663
Episode: 2401/30000 (8.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9269s / 93.5858 s
agent0:                 episode reward: 1.3291,                 loss: nan
agent1:                 episode reward: -1.3291,                 loss: 0.2533
Episode: 2421/30000 (8.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9071s / 94.4930 s
agent0:                 episode reward: 0.7135,                 loss: nan
agent1:                 episode reward: -0.7135,                 loss: 0.2525
Episode: 2441/30000 (8.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9208s / 95.4138 s
agent0:                 episode reward: 1.3106,                 loss: nan
agent1:                 episode reward: -1.3106,                 loss: 0.2497
Episode: 2461/30000 (8.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9176s / 96.3314 s
agent0:                 episode reward: 0.9744,                 loss: nan
agent1:                 episode reward: -0.9744,                 loss: 0.2493
Episode: 2481/30000 (8.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9084s / 97.2398 s
agent0:                 episode reward: 1.4581,                 loss: nan
agent1:                 episode reward: -1.4581,                 loss: 0.1853
Episode: 2501/30000 (8.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9574s / 98.1973 s
agent0:                 episode reward: 1.1285,                 loss: nan
agent1:                 episode reward: -1.1285,                 loss: 0.1640
Episode: 2521/30000 (8.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9212s / 99.1184 s
agent0:                 episode reward: 0.3917,                 loss: nan
agent1:                 episode reward: -0.3917,                 loss: 0.1632
Episode: 2541/30000 (8.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9159s / 100.0343 s
agent0:                 episode reward: 1.4525,                 loss: nan
agent1:                 episode reward: -1.4525,                 loss: 0.1624
Episode: 2561/30000 (8.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9392s / 100.9735 s
agent0:                 episode reward: 1.2171,                 loss: nan
agent1:                 episode reward: -1.2171,                 loss: 0.1618
Episode: 2581/30000 (8.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9365s / 101.9099 s
agent0:                 episode reward: 0.3679,                 loss: nan
agent1:                 episode reward: -0.3679,                 loss: 0.1386
Episode: 2601/30000 (8.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9487s / 102.8586 s
agent0:                 episode reward: 1.1793,                 loss: nan
agent1:                 episode reward: -1.1793,                 loss: 0.1297
Episode: 2621/30000 (8.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9665s / 103.8251 s
agent0:                 episode reward: 0.7729,                 loss: nan
agent1:                 episode reward: -0.7729,                 loss: 0.1290
Episode: 2641/30000 (8.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9268s / 104.7519 s
agent0:                 episode reward: 0.8567,                 loss: nan
agent1:                 episode reward: -0.8567,                 loss: 0.1288
Episode: 2661/30000 (8.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9357s / 105.6876 s
agent0:                 episode reward: 1.8709,                 loss: nan
agent1:                 episode reward: -1.8709,                 loss: 0.1285
Episode: 2681/30000 (8.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9383s / 106.6260 s
agent0:                 episode reward: 0.9438,                 loss: nan
agent1:                 episode reward: -0.9438,                 loss: 0.1628
Episode: 2701/30000 (9.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9417s / 107.5677 s
agent0:                 episode reward: 1.3332,                 loss: nan
agent1:                 episode reward: -1.3332,                 loss: 0.1631
Episode: 2721/30000 (9.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9644s / 108.5321 s
agent0:                 episode reward: 0.2300,                 loss: nan
agent1:                 episode reward: -0.2300,                 loss: 0.1627
Episode: 2741/30000 (9.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9585s / 109.4906 s
agent0:                 episode reward: 1.0413,                 loss: nan
agent1:                 episode reward: -1.0413,                 loss: 0.1630
Episode: 2761/30000 (9.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9475s / 110.4380 s
agent0:                 episode reward: 0.7076,                 loss: nan
agent1:                 episode reward: -0.7076,                 loss: 0.1626
Episode: 2781/30000 (9.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9441s / 111.3821 s
agent0:                 episode reward: -0.1496,                 loss: nan
agent1:                 episode reward: 0.1496,                 loss: 0.1899
Episode: 2801/30000 (9.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9461s / 112.3283 s
agent0:                 episode reward: 0.9895,                 loss: nan
agent1:                 episode reward: -0.9895,                 loss: 0.1927
Episode: 2821/30000 (9.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0150s / 113.3432 s
agent0:                 episode reward: 1.4296,                 loss: nan
agent1:                 episode reward: -1.4296,                 loss: 0.1918
Episode: 2841/30000 (9.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9556s / 114.2989 s
agent0:                 episode reward: 1.1464,                 loss: nan
agent1:                 episode reward: -1.1464,                 loss: 0.1903
Episode: 2861/30000 (9.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9397s / 115.2386 s
agent0:                 episode reward: 0.2798,                 loss: nan
agent1:                 episode reward: -0.2798,                 loss: 0.1920
Episode: 2881/30000 (9.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9721s / 116.2106 s
agent0:                 episode reward: 1.1200,                 loss: nan
agent1:                 episode reward: -1.1200,                 loss: 0.2263
Episode: 2901/30000 (9.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9546s / 117.1652 s
agent0:                 episode reward: 0.1416,                 loss: nan
agent1:                 episode reward: -0.1416,                 loss: 0.2267
Episode: 2921/30000 (9.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9862s / 118.1514 s
agent0:                 episode reward: 0.9284,                 loss: nan
agent1:                 episode reward: -0.9284,                 loss: 0.2289
Episode: 2941/30000 (9.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9598s / 119.1113 s
agent0:                 episode reward: 0.3658,                 loss: nan
agent1:                 episode reward: -0.3658,                 loss: 0.2274
Episode: 2961/30000 (9.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9649s / 120.0762 s
agent0:                 episode reward: 0.9856,                 loss: nan
agent1:                 episode reward: -0.9856,                 loss: 0.2282
Episode: 2981/30000 (9.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9579s / 121.0341 s
agent0:                 episode reward: 1.3823,                 loss: nan
agent1:                 episode reward: -1.3823,                 loss: 0.2682
Episode: 3001/30000 (10.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9612s / 121.9954 s
agent0:                 episode reward: 0.0422,                 loss: nan
agent1:                 episode reward: -0.0422,                 loss: 0.2710
Episode: 3021/30000 (10.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9697s / 122.9651 s
agent0:                 episode reward: 1.3474,                 loss: nan
agent1:                 episode reward: -1.3474,                 loss: 0.2727
Episode: 3041/30000 (10.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0076s / 123.9727 s
agent0:                 episode reward: 1.2102,                 loss: nan
agent1:                 episode reward: -1.2102,                 loss: 0.2696
Episode: 3061/30000 (10.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9710s / 124.9436 s
agent0:                 episode reward: 0.9951,                 loss: nan
agent1:                 episode reward: -0.9951,                 loss: 0.2690
Episode: 3081/30000 (10.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9906s / 125.9342 s
agent0:                 episode reward: 0.4344,                 loss: nan
agent1:                 episode reward: -0.4344,                 loss: 0.2747
Episode: 3101/30000 (10.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9707s / 126.9049 s
agent0:                 episode reward: 0.8062,                 loss: nan
agent1:                 episode reward: -0.8062,                 loss: 0.2732
Episode: 3121/30000 (10.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9676s / 127.8725 s
agent0:                 episode reward: 0.6410,                 loss: nan
agent1:                 episode reward: -0.6410,                 loss: 0.2730
Episode: 3141/30000 (10.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9851s / 128.8576 s
agent0:                 episode reward: 0.5985,                 loss: nan
agent1:                 episode reward: -0.5985,                 loss: 0.2729
Episode: 3161/30000 (10.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9754s / 129.8329 s
agent0:                 episode reward: 0.8307,                 loss: nan
agent1:                 episode reward: -0.8307,                 loss: 0.2709
Episode: 3181/30000 (10.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9755s / 130.8085 s
agent0:                 episode reward: 0.2988,                 loss: nan
agent1:                 episode reward: -0.2988,                 loss: 0.2935
Episode: 3201/30000 (10.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9850s / 131.7934 s
agent0:                 episode reward: 1.7232,                 loss: nan
agent1:                 episode reward: -1.7232,                 loss: 0.2913
Episode: 3221/30000 (10.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9794s / 132.7728 s
agent0:                 episode reward: 1.4193,                 loss: nan
agent1:                 episode reward: -1.4193,                 loss: 0.2884
Episode: 3241/30000 (10.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0281s / 133.8009 s
agent0:                 episode reward: 1.0885,                 loss: nan
agent1:                 episode reward: -1.0885,                 loss: 0.2866
Episode: 3261/30000 (10.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0011s / 134.8020 s
agent0:                 episode reward: 0.4148,                 loss: nan
agent1:                 episode reward: -0.4148,                 loss: 0.2881
Episode: 3281/30000 (10.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9789s / 135.7809 s
agent0:                 episode reward: 1.0076,                 loss: nan
agent1:                 episode reward: -1.0076,                 loss: 0.2649
Episode: 3301/30000 (11.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9848s / 136.7657 s
agent0:                 episode reward: 0.6093,                 loss: nan
agent1:                 episode reward: -0.6093,                 loss: 0.2500
Episode: 3321/30000 (11.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0015s / 137.7672 s
agent0:                 episode reward: 0.3482,                 loss: nan
agent1:                 episode reward: -0.3482,                 loss: 0.2479
Episode: 3341/30000 (11.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9970s / 138.7641 s
agent0:                 episode reward: 1.0838,                 loss: nan
agent1:                 episode reward: -1.0838,                 loss: 0.2484
Episode: 3361/30000 (11.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9950s / 139.7592 s
agent0:                 episode reward: 0.8985,                 loss: nan
agent1:                 episode reward: -0.8985,                 loss: 0.2458
Episode: 3381/30000 (11.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0102s / 140.7694 s
agent0:                 episode reward: 0.2744,                 loss: nan
agent1:                 episode reward: -0.2744,                 loss: 0.1788
Episode: 3401/30000 (11.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9975s / 141.7669 s
agent0:                 episode reward: 1.1063,                 loss: nan
agent1:                 episode reward: -1.1063,                 loss: 0.1571
Episode: 3421/30000 (11.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0132s / 142.7801 s
agent0:                 episode reward: 1.5443,                 loss: nan
agent1:                 episode reward: -1.5443,                 loss: 0.1558
Episode: 3441/30000 (11.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0378s / 143.8179 s
agent0:                 episode reward: 1.1832,                 loss: nan
agent1:                 episode reward: -1.1832,                 loss: 0.1547
Episode: 3461/30000 (11.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0355s / 144.8534 s
agent0:                 episode reward: 0.8026,                 loss: nan
agent1:                 episode reward: -0.8026,                 loss: 0.1562
Episode: 3481/30000 (11.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0424s / 145.8958 s
agent0:                 episode reward: 1.5643,                 loss: nan
agent1:                 episode reward: -1.5643,                 loss: 0.1233
Episode: 3501/30000 (11.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0642s / 146.9600 s
agent0:                 episode reward: 0.6120,                 loss: nan
agent1:                 episode reward: -0.6120,                 loss: 0.1135
Episode: 3521/30000 (11.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0157s / 147.9757 s
agent0:                 episode reward: 0.3810,                 loss: nan
agent1:                 episode reward: -0.3810,                 loss: 0.1118
Episode: 3541/30000 (11.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0728s / 149.0485 s
agent0:                 episode reward: 0.4329,                 loss: nan
agent1:                 episode reward: -0.4329,                 loss: 0.1126
Episode: 3561/30000 (11.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0141s / 150.0626 s
agent0:                 episode reward: 0.8490,                 loss: nan
agent1:                 episode reward: -0.8490,                 loss: 0.1130
Episode: 3581/30000 (11.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0287s / 151.0913 s
agent0:                 episode reward: 0.3187,                 loss: nan
agent1:                 episode reward: -0.3187,                 loss: 0.1428
Episode: 3601/30000 (12.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0225s / 152.1138 s
agent0:                 episode reward: 1.1876,                 loss: nan
agent1:                 episode reward: -1.1876,                 loss: 0.1455
Episode: 3621/30000 (12.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0198s / 153.1336 s
agent0:                 episode reward: 1.4789,                 loss: nan
agent1:                 episode reward: -1.4789,                 loss: 0.1466
Episode: 3641/30000 (12.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0710s / 154.2046 s
agent0:                 episode reward: 0.6429,                 loss: nan
agent1:                 episode reward: -0.6429,                 loss: 0.1454
Episode: 3661/30000 (12.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0425s / 155.2471 s
agent0:                 episode reward: 1.0501,                 loss: nan
agent1:                 episode reward: -1.0501,                 loss: 0.1445
Episode: 3681/30000 (12.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0263s / 156.2734 s
agent0:                 episode reward: 0.5169,                 loss: nan
agent1:                 episode reward: -0.5169,                 loss: 0.1747
Episode: 3701/30000 (12.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0359s / 157.3093 s
agent0:                 episode reward: 0.5969,                 loss: nan
agent1:                 episode reward: -0.5969,                 loss: 0.1798
Episode: 3721/30000 (12.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0358s / 158.3451 s
agent0:                 episode reward: 0.6285,                 loss: nan
agent1:                 episode reward: -0.6285,                 loss: 0.1791
Episode: 3741/30000 (12.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0509s / 159.3960 s
agent0:                 episode reward: 0.8088,                 loss: nan
agent1:                 episode reward: -0.8088,                 loss: 0.1773
Episode: 3761/30000 (12.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0301s / 160.4261 s
agent0:                 episode reward: 0.7506,                 loss: nan
agent1:                 episode reward: -0.7506,                 loss: 0.1778
Episode: 3781/30000 (12.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0392s / 161.4653 s
agent0:                 episode reward: 0.0861,                 loss: nan
agent1:                 episode reward: -0.0861,                 loss: 0.2001
Episode: 3801/30000 (12.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0682s / 162.5335 s
agent0:                 episode reward: 0.7928,                 loss: nan
agent1:                 episode reward: -0.7928,                 loss: 0.2026
Episode: 3821/30000 (12.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0378s / 163.5713 s
agent0:                 episode reward: 0.9343,                 loss: nan
agent1:                 episode reward: -0.9343,                 loss: 0.2016
Episode: 3841/30000 (12.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1061s / 164.6774 s
agent0:                 episode reward: 0.5182,                 loss: nan
agent1:                 episode reward: -0.5182,                 loss: 0.2004
Episode: 3861/30000 (12.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0523s / 165.7296 s
agent0:                 episode reward: 0.7103,                 loss: nan
agent1:                 episode reward: -0.7103,                 loss: 0.1992
Episode: 3881/30000 (12.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0477s / 166.7773 s
agent0:                 episode reward: 0.7048,                 loss: nan
agent1:                 episode reward: -0.7048,                 loss: 0.2490
Episode: 3901/30000 (13.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0725s / 167.8498 s
agent0:                 episode reward: 1.1893,                 loss: nan
agent1:                 episode reward: -1.1893,                 loss: 0.2564
Episode: 3921/30000 (13.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0583s / 168.9080 s
agent0:                 episode reward: 0.3363,                 loss: nan
agent1:                 episode reward: -0.3363,                 loss: 0.2537
Episode: 3941/30000 (13.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0563s / 169.9643 s
agent0:                 episode reward: 0.7819,                 loss: nan
agent1:                 episode reward: -0.7819,                 loss: 0.2550
Episode: 3961/30000 (13.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0721s / 171.0365 s
agent0:                 episode reward: 0.4332,                 loss: nan
agent1:                 episode reward: -0.4332,                 loss: 0.2545
Episode: 3981/30000 (13.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0589s / 172.0954 s
agent0:                 episode reward: 1.1696,                 loss: nan
agent1:                 episode reward: -1.1696,                 loss: 0.3026
Episode: 4001/30000 (13.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0669s / 173.1623 s
agent0:                 episode reward: 1.3441,                 loss: nan
agent1:                 episode reward: -1.3441,                 loss: 0.3073
Episode: 4021/30000 (13.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0647s / 174.2269 s
agent0:                 episode reward: 1.1175,                 loss: nan
agent1:                 episode reward: -1.1175,                 loss: 0.3039
Episode: 4041/30000 (13.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1116s / 175.3385 s
agent0:                 episode reward: 0.6840,                 loss: nan
agent1:                 episode reward: -0.6840,                 loss: 0.3053
Episode: 4061/30000 (13.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0892s / 176.4277 s
agent0:                 episode reward: 0.9341,                 loss: nan
agent1:                 episode reward: -0.9341,                 loss: 0.3024
Episode: 4081/30000 (13.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0717s / 177.4993 s
agent0:                 episode reward: -0.3283,                 loss: nan
agent1:                 episode reward: 0.3283,                 loss: 0.2756
Episode: 4101/30000 (13.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0692s / 178.5685 s
agent0:                 episode reward: 0.0422,                 loss: nan
agent1:                 episode reward: -0.0422,                 loss: 0.2672
Episode: 4121/30000 (13.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0915s / 179.6600 s
agent0:                 episode reward: 0.8232,                 loss: nan
agent1:                 episode reward: -0.8232,                 loss: 0.2655
Episode: 4141/30000 (13.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0759s / 180.7359 s
agent0:                 episode reward: 0.4549,                 loss: nan
agent1:                 episode reward: -0.4549,                 loss: 0.2644
Episode: 4161/30000 (13.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0829s / 181.8188 s
agent0:                 episode reward: -0.1192,                 loss: nan
agent1:                 episode reward: 0.1192,                 loss: 0.2632
Episode: 4181/30000 (13.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0760s / 182.8947 s
agent0:                 episode reward: 0.7435,                 loss: nan
agent1:                 episode reward: -0.7435,                 loss: 0.2175
Episode: 4201/30000 (14.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0812s / 183.9759 s
agent0:                 episode reward: 0.4562,                 loss: nan
agent1:                 episode reward: -0.4562,                 loss: 0.2017
Episode: 4221/30000 (14.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1411s / 185.1170 s
agent0:                 episode reward: 0.4062,                 loss: nan
agent1:                 episode reward: -0.4062,                 loss: 0.2026
Episode: 4241/30000 (14.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0816s / 186.1986 s
agent0:                 episode reward: 0.1402,                 loss: nan
agent1:                 episode reward: -0.1402,                 loss: 0.1998
Episode: 4261/30000 (14.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0872s / 187.2858 s
agent0:                 episode reward: 1.3968,                 loss: nan
agent1:                 episode reward: -1.3968,                 loss: 0.2002
Episode: 4281/30000 (14.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1057s / 188.3916 s
agent0:                 episode reward: 0.2772,                 loss: nan
agent1:                 episode reward: -0.2772,                 loss: 0.1765
Episode: 4301/30000 (14.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0977s / 189.4893 s
agent0:                 episode reward: 1.5515,                 loss: nan
agent1:                 episode reward: -1.5515,                 loss: 0.1667
Episode: 4321/30000 (14.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0927s / 190.5820 s
agent0:                 episode reward: 0.6254,                 loss: nan
agent1:                 episode reward: -0.6254,                 loss: 0.1679
Episode: 4341/30000 (14.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1021s / 191.6841 s
agent0:                 episode reward: -0.1627,                 loss: nan
agent1:                 episode reward: 0.1627,                 loss: 0.1663
Episode: 4361/30000 (14.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1098s / 192.7940 s
agent0:                 episode reward: 0.3035,                 loss: nan
agent1:                 episode reward: -0.3035,                 loss: 0.1654
Episode: 4381/30000 (14.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0986s / 193.8926 s
agent0:                 episode reward: 0.7327,                 loss: nan
agent1:                 episode reward: -0.7327,                 loss: 0.1496
Episode: 4401/30000 (14.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1506s / 195.0432 s
agent0:                 episode reward: 0.8890,                 loss: nan
agent1:                 episode reward: -0.8890,                 loss: 0.1425
Episode: 4421/30000 (14.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1060s / 196.1492 s
agent0:                 episode reward: 0.8945,                 loss: nan
agent1:                 episode reward: -0.8945,                 loss: 0.1408
Episode: 4441/30000 (14.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1164s / 197.2656 s
agent0:                 episode reward: 0.4449,                 loss: nan
agent1:                 episode reward: -0.4449,                 loss: 0.1396
Episode: 4461/30000 (14.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1033s / 198.3689 s
agent0:                 episode reward: 0.6558,                 loss: nan
agent1:                 episode reward: -0.6558,                 loss: 0.1402
Episode: 4481/30000 (14.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1048s / 199.4737 s
agent0:                 episode reward: 0.4811,                 loss: nan
agent1:                 episode reward: -0.4811,                 loss: 0.1411
Episode: 4501/30000 (15.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1154s / 200.5891 s
agent0:                 episode reward: 0.2297,                 loss: nan
agent1:                 episode reward: -0.2297,                 loss: 0.1385
Episode: 4521/30000 (15.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1255s / 201.7146 s
agent0:                 episode reward: 0.9006,                 loss: nan
agent1:                 episode reward: -0.9006,                 loss: 0.1382
Episode: 4541/30000 (15.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1162s / 202.8308 s
agent0:                 episode reward: 0.9987,                 loss: nan
agent1:                 episode reward: -0.9987,                 loss: 0.1366
Episode: 4561/30000 (15.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1345s / 203.9652 s
agent0:                 episode reward: 0.0583,                 loss: nan
agent1:                 episode reward: -0.0583,                 loss: 0.1379
Episode: 4581/30000 (15.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1182s / 205.0835 s
agent0:                 episode reward: 1.2808,                 loss: nan
agent1:                 episode reward: -1.2808,                 loss: 0.1634
Episode: 4601/30000 (15.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1766s / 206.2601 s
agent0:                 episode reward: 0.7250,                 loss: nan
agent1:                 episode reward: -0.7250,                 loss: 0.1654
Episode: 4621/30000 (15.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1294s / 207.3895 s
agent0:                 episode reward: 0.5632,                 loss: nan
agent1:                 episode reward: -0.5632,                 loss: 0.1673
Episode: 4641/30000 (15.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1252s / 208.5147 s
agent0:                 episode reward: 0.1686,                 loss: nan
agent1:                 episode reward: -0.1686,                 loss: 0.1672
Episode: 4661/30000 (15.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1600s / 209.6746 s
agent0:                 episode reward: 0.3731,                 loss: nan
agent1:                 episode reward: -0.3731,                 loss: 0.1663
Episode: 4681/30000 (15.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1302s / 210.8048 s
agent0:                 episode reward: 1.1540,                 loss: nan
agent1:                 episode reward: -1.1540,                 loss: 0.2070
Episode: 4701/30000 (15.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1362s / 211.9410 s
agent0:                 episode reward: -0.0686,                 loss: nan
agent1:                 episode reward: 0.0686,                 loss: 0.2138
Episode: 4721/30000 (15.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1461s / 213.0871 s
agent0:                 episode reward: 0.2214,                 loss: nan
agent1:                 episode reward: -0.2214,                 loss: 0.2112
Episode: 4741/30000 (15.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1382s / 214.2253 s
agent0:                 episode reward: 1.1057,                 loss: nan
agent1:                 episode reward: -1.1057,                 loss: 0.2110
Episode: 4761/30000 (15.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1633s / 215.3886 s
agent0:                 episode reward: -0.4679,                 loss: nan
agent1:                 episode reward: 0.4679,                 loss: 0.2127
Episode: 4781/30000 (15.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1912s / 216.5798 s
agent0:                 episode reward: 0.0313,                 loss: nan
agent1:                 episode reward: -0.0313,                 loss: 0.2412
Episode: 4801/30000 (16.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1651s / 217.7449 s
agent0:                 episode reward: -0.0453,                 loss: nan
agent1:                 episode reward: 0.0453,                 loss: 0.2483
Episode: 4821/30000 (16.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1654s / 218.9103 s
agent0:                 episode reward: 0.5906,                 loss: nan
agent1:                 episode reward: -0.5906,                 loss: 0.2466
Episode: 4841/30000 (16.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1585s / 220.0688 s
agent0:                 episode reward: 1.5566,                 loss: nan
agent1:                 episode reward: -1.5566,                 loss: 0.2467
Episode: 4861/30000 (16.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1676s / 221.2364 s
agent0:                 episode reward: 0.5714,                 loss: nan
agent1:                 episode reward: -0.5714,                 loss: 0.2471
Episode: 4881/30000 (16.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1583s / 222.3947 s
agent0:                 episode reward: 0.3438,                 loss: nan
agent1:                 episode reward: -0.3438,                 loss: 0.2482
Episode: 4901/30000 (16.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1553s / 223.5500 s
agent0:                 episode reward: -0.1462,                 loss: nan
agent1:                 episode reward: 0.1462,                 loss: 0.2494
Episode: 4921/30000 (16.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1654s / 224.7154 s
agent0:                 episode reward: 0.3489,                 loss: nan
agent1:                 episode reward: -0.3489,                 loss: 0.2468
Episode: 4941/30000 (16.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2212s / 225.9366 s
agent0:                 episode reward: 0.5519,                 loss: nan
agent1:                 episode reward: -0.5519,                 loss: 0.2490
Episode: 4961/30000 (16.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1648s / 227.1014 s
agent0:                 episode reward: 0.7762,                 loss: nan
agent1:                 episode reward: -0.7762,                 loss: 0.2476
Episode: 4981/30000 (16.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1652s / 228.2666 s
agent0:                 episode reward: 0.7338,                 loss: nan
agent1:                 episode reward: -0.7338,                 loss: 0.2403
Episode: 5001/30000 (16.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1641s / 229.4307 s
agent0:                 episode reward: 0.3632,                 loss: nan
agent1:                 episode reward: -0.3632,                 loss: 0.2372
Episode: 5021/30000 (16.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1767s / 230.6075 s
agent0:                 episode reward: 0.3181,                 loss: nan
agent1:                 episode reward: -0.3181,                 loss: 0.2376
Episode: 5041/30000 (16.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1698s / 231.7773 s
agent0:                 episode reward: -0.3207,                 loss: nan
agent1:                 episode reward: 0.3207,                 loss: 0.2387
Episode: 5061/30000 (16.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1652s / 232.9425 s
agent0:                 episode reward: 0.5664,                 loss: nan
agent1:                 episode reward: -0.5664,                 loss: 0.2366
Episode: 5081/30000 (16.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1928s / 234.1353 s
agent0:                 episode reward: 0.6002,                 loss: nan
agent1:                 episode reward: -0.6002,                 loss: 0.1979
Episode: 5101/30000 (17.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1687s / 235.3039 s
agent0:                 episode reward: 1.3813,                 loss: nan
agent1:                 episode reward: -1.3813,                 loss: 0.1891
Episode: 5121/30000 (17.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2291s / 236.5330 s
agent0:                 episode reward: -0.2440,                 loss: nan
agent1:                 episode reward: 0.2440,                 loss: 0.1888
Episode: 5141/30000 (17.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1769s / 237.7099 s
agent0:                 episode reward: 0.3758,                 loss: nan
agent1:                 episode reward: -0.3758,                 loss: 0.1879
Episode: 5161/30000 (17.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1811s / 238.8910 s
agent0:                 episode reward: 0.2658,                 loss: nan
agent1:                 episode reward: -0.2658,                 loss: 0.1891
Episode: 5181/30000 (17.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1927s / 240.0837 s
agent0:                 episode reward: -0.3280,                 loss: nan
agent1:                 episode reward: 0.3280,                 loss: 0.2065
Episode: 5201/30000 (17.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1860s / 241.2697 s
agent0:                 episode reward: 0.6670,                 loss: nan
agent1:                 episode reward: -0.6670,                 loss: 0.2064
Episode: 5221/30000 (17.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2093s / 242.4790 s
agent0:                 episode reward: 0.0049,                 loss: nan
agent1:                 episode reward: -0.0049,                 loss: 0.2057
Episode: 5241/30000 (17.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1841s / 243.6631 s
agent0:                 episode reward: 0.2007,                 loss: nan
agent1:                 episode reward: -0.2007,                 loss: 0.2068
Episode: 5261/30000 (17.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1910s / 244.8542 s
agent0:                 episode reward: 1.2166,                 loss: nan
agent1:                 episode reward: -1.2166,                 loss: 0.2076
Episode: 5281/30000 (17.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2018s / 246.0559 s
agent0:                 episode reward: 0.2945,                 loss: nan
agent1:                 episode reward: -0.2945,                 loss: 0.1794
Episode: 5301/30000 (17.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2259s / 247.2819 s
agent0:                 episode reward: 0.6191,                 loss: nan
agent1:                 episode reward: -0.6191,                 loss: 0.1716
Episode: 5321/30000 (17.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1885s / 248.4704 s
agent0:                 episode reward: 1.1476,                 loss: nan
agent1:                 episode reward: -1.1476,                 loss: 0.1732
Episode: 5341/30000 (17.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2009s / 249.6713 s
agent0:                 episode reward: 0.9105,                 loss: nan
agent1:                 episode reward: -0.9105,                 loss: 0.1744
Episode: 5361/30000 (17.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2252s / 250.8966 s
agent0:                 episode reward: -0.1856,                 loss: nan
agent1:                 episode reward: 0.1856,                 loss: 0.1731
Episode: 5381/30000 (17.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2021s / 252.0986 s
agent0:                 episode reward: 0.1091,                 loss: nan
agent1:                 episode reward: -0.1091,                 loss: 0.1548
Episode: 5401/30000 (18.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1984s / 253.2970 s
agent0:                 episode reward: 0.0405,                 loss: nan
agent1:                 episode reward: -0.0405,                 loss: 0.1499
Episode: 5421/30000 (18.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2112s / 254.5082 s
agent0:                 episode reward: 0.0172,                 loss: nan
agent1:                 episode reward: -0.0172,                 loss: 0.1499
Episode: 5441/30000 (18.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1998s / 255.7080 s
agent0:                 episode reward: 1.2795,                 loss: nan
agent1:                 episode reward: -1.2795,                 loss: 0.1482
Episode: 5461/30000 (18.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2377s / 256.9457 s
agent0:                 episode reward: 0.6193,                 loss: nan
agent1:                 episode reward: -0.6193,                 loss: 0.1491
Episode: 5481/30000 (18.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2057s / 258.1514 s
agent0:                 episode reward: 0.6673,                 loss: nan
agent1:                 episode reward: -0.6673,                 loss: 0.1800
Episode: 5501/30000 (18.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2275s / 259.3789 s
agent0:                 episode reward: 0.2522,                 loss: nan
agent1:                 episode reward: -0.2522,                 loss: 0.1807
Episode: 5521/30000 (18.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2286s / 260.6075 s
agent0:                 episode reward: 0.4165,                 loss: nan
agent1:                 episode reward: -0.4165,                 loss: 0.1830
Episode: 5541/30000 (18.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2100s / 261.8174 s
agent0:                 episode reward: 0.6057,                 loss: nan
agent1:                 episode reward: -0.6057,                 loss: 0.1835
Episode: 5561/30000 (18.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2139s / 263.0313 s
agent0:                 episode reward: 0.5212,                 loss: nan
agent1:                 episode reward: -0.5212,                 loss: 0.1829
Episode: 5581/30000 (18.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2214s / 264.2527 s
agent0:                 episode reward: 0.6586,                 loss: nan
agent1:                 episode reward: -0.6586,                 loss: 0.1905
Episode: 5601/30000 (18.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2238s / 265.4765 s
agent0:                 episode reward: -0.5302,                 loss: nan
agent1:                 episode reward: 0.5302,                 loss: 0.1917
Episode: 5621/30000 (18.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2678s / 266.7443 s
agent0:                 episode reward: 0.8187,                 loss: nan
agent1:                 episode reward: -0.8187,                 loss: 0.1920
Episode: 5641/30000 (18.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2445s / 267.9888 s
agent0:                 episode reward: 0.8792,                 loss: nan
agent1:                 episode reward: -0.8792,                 loss: 0.1898
Episode: 5661/30000 (18.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2310s / 269.2198 s
agent0:                 episode reward: 0.5966,                 loss: nan
agent1:                 episode reward: -0.5966,                 loss: 0.1901
Episode: 5681/30000 (18.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2321s / 270.4518 s
agent0:                 episode reward: 0.2683,                 loss: nan
agent1:                 episode reward: -0.2683,                 loss: 0.2151
Episode: 5701/30000 (19.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2227s / 271.6746 s
agent0:                 episode reward: 0.8168,                 loss: nan
agent1:                 episode reward: -0.8168,                 loss: 0.2185
Episode: 5721/30000 (19.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2396s / 272.9142 s
agent0:                 episode reward: 0.6004,                 loss: nan
agent1:                 episode reward: -0.6004,                 loss: 0.2183
Episode: 5741/30000 (19.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2280s / 274.1422 s
agent0:                 episode reward: 0.8470,                 loss: nan
agent1:                 episode reward: -0.8470,                 loss: 0.2203
Episode: 5761/30000 (19.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2487s / 275.3909 s
agent0:                 episode reward: 0.1230,                 loss: nan
agent1:                 episode reward: -0.1230,                 loss: 0.2204
Episode: 5781/30000 (19.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2567s / 276.6476 s
agent0:                 episode reward: 0.3223,                 loss: nan
agent1:                 episode reward: -0.3223,                 loss: 0.2094
Episode: 5801/30000 (19.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2778s / 277.9254 s
agent0:                 episode reward: 0.2772,                 loss: nan
agent1:                 episode reward: -0.2772,                 loss: 0.2051
Episode: 5821/30000 (19.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2524s / 279.1778 s
agent0:                 episode reward: -0.1430,                 loss: nan
agent1:                 episode reward: 0.1430,                 loss: 0.2052
Episode: 5841/30000 (19.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2509s / 280.4287 s
agent0:                 episode reward: 0.3104,                 loss: nan
agent1:                 episode reward: -0.3104,                 loss: 0.2041
Episode: 5861/30000 (19.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2479s / 281.6766 s
agent0:                 episode reward: -0.2240,                 loss: nan
agent1:                 episode reward: 0.2240,                 loss: 0.2045
Episode: 5881/30000 (19.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2364s / 282.9130 s
agent0:                 episode reward: -0.5739,                 loss: nan
agent1:                 episode reward: 0.5739,                 loss: 0.1770
Episode: 5901/30000 (19.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2960s / 284.2090 s
agent0:                 episode reward: 0.5534,                 loss: nan
agent1:                 episode reward: -0.5534,                 loss: 0.1684
Episode: 5921/30000 (19.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2482s / 285.4572 s
agent0:                 episode reward: 1.4772,                 loss: nan
agent1:                 episode reward: -1.4772,                 loss: 0.1693
Episode: 5941/30000 (19.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2604s / 286.7177 s
agent0:                 episode reward: 0.1229,                 loss: nan
agent1:                 episode reward: -0.1229,                 loss: 0.1692
Episode: 5961/30000 (19.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3071s / 288.0248 s
agent0:                 episode reward: 0.0488,                 loss: nan
agent1:                 episode reward: -0.0488,                 loss: 0.1682
Episode: 5981/30000 (19.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2541s / 289.2789 s
agent0:                 episode reward: 1.4579,                 loss: nan
agent1:                 episode reward: -1.4579,                 loss: 0.1778
Episode: 6001/30000 (20.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2820s / 290.5609 s
agent0:                 episode reward: -0.3394,                 loss: nan
agent1:                 episode reward: 0.3394,                 loss: 0.1759
Episode: 6021/30000 (20.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2568s / 291.8177 s
agent0:                 episode reward: 0.5103,                 loss: nan
agent1:                 episode reward: -0.5103,                 loss: 0.1780
Episode: 6041/30000 (20.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2694s / 293.0871 s
agent0:                 episode reward: 1.0255,                 loss: nan
agent1:                 episode reward: -1.0255,                 loss: 0.1780
Episode: 6061/30000 (20.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2758s / 294.3629 s
agent0:                 episode reward: 0.4522,                 loss: nan
agent1:                 episode reward: -0.4522,                 loss: 0.1760
Episode: 6081/30000 (20.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2768s / 295.6397 s
agent0:                 episode reward: 0.3351,                 loss: nan
agent1:                 episode reward: -0.3351,                 loss: 0.1719
Episode: 6101/30000 (20.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2941s / 296.9338 s
agent0:                 episode reward: 0.8102,                 loss: nan
agent1:                 episode reward: -0.8102,                 loss: 0.1703
Episode: 6121/30000 (20.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3161s / 298.2499 s
agent0:                 episode reward: 0.1564,                 loss: nan
agent1:                 episode reward: -0.1564,                 loss: 0.1697
Episode: 6141/30000 (20.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2703s / 299.5203 s
agent0:                 episode reward: 0.1546,                 loss: nan
agent1:                 episode reward: -0.1546,                 loss: 0.1695
Episode: 6161/30000 (20.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2982s / 300.8184 s
agent0:                 episode reward: 0.3722,                 loss: nan
agent1:                 episode reward: -0.3722,                 loss: 0.1695
Episode: 6181/30000 (20.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2745s / 302.0929 s
agent0:                 episode reward: -0.3219,                 loss: nan
agent1:                 episode reward: 0.3219,                 loss: 0.1926
Episode: 6201/30000 (20.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2755s / 303.3683 s
agent0:                 episode reward: 0.5443,                 loss: nan
agent1:                 episode reward: -0.5443,                 loss: 0.1962
Episode: 6221/30000 (20.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2753s / 304.6436 s
agent0:                 episode reward: 0.1666,                 loss: nan
agent1:                 episode reward: -0.1666,                 loss: 0.1956
Episode: 6241/30000 (20.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2862s / 305.9298 s
agent0:                 episode reward: -0.1866,                 loss: nan
agent1:                 episode reward: 0.1866,                 loss: 0.1954
Episode: 6261/30000 (20.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2837s / 307.2135 s
agent0:                 episode reward: 0.1257,                 loss: nan
agent1:                 episode reward: -0.1257,                 loss: 0.1952
Episode: 6281/30000 (20.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3374s / 308.5510 s
agent0:                 episode reward: 0.1132,                 loss: nan
agent1:                 episode reward: -0.1132,                 loss: 0.2004
Episode: 6301/30000 (21.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3631s / 309.9141 s
agent0:                 episode reward: 0.3937,                 loss: nan
agent1:                 episode reward: -0.3937,                 loss: 0.1988
Episode: 6321/30000 (21.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3071s / 311.2211 s
agent0:                 episode reward: 0.8050,                 loss: nan
agent1:                 episode reward: -0.8050,                 loss: 0.1993
Episode: 6341/30000 (21.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2993s / 312.5204 s
agent0:                 episode reward: 0.9333,                 loss: nan
agent1:                 episode reward: -0.9333,                 loss: 0.2009
Episode: 6361/30000 (21.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3014s / 313.8218 s
agent0:                 episode reward: 0.2972,                 loss: nan
agent1:                 episode reward: -0.2972,                 loss: 0.1979
Episode: 6381/30000 (21.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3279s / 315.1497 s
agent0:                 episode reward: 0.0929,                 loss: nan
agent1:                 episode reward: -0.0929,                 loss: 0.2084
Episode: 6401/30000 (21.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3071s / 316.4568 s
agent0:                 episode reward: 0.3208,                 loss: nan
agent1:                 episode reward: -0.3208,                 loss: 0.2083
Episode: 6421/30000 (21.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3690s / 317.8259 s
agent0:                 episode reward: -0.4732,                 loss: nan
agent1:                 episode reward: 0.4732,                 loss: 0.2072
Episode: 6441/30000 (21.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3177s / 319.1436 s
agent0:                 episode reward: 0.6072,                 loss: nan
agent1:                 episode reward: -0.6072,                 loss: 0.2064
Episode: 6461/30000 (21.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3747s / 320.5183 s
agent0:                 episode reward: 0.1979,                 loss: nan
agent1:                 episode reward: -0.1979,                 loss: 0.2077
Episode: 6481/30000 (21.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3382s / 321.8565 s
agent0:                 episode reward: 0.2095,                 loss: nan
agent1:                 episode reward: -0.2095,                 loss: 0.1845
Episode: 6501/30000 (21.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3349s / 323.1914 s
agent0:                 episode reward: -0.3339,                 loss: nan
agent1:                 episode reward: 0.3339,                 loss: 0.1754
Episode: 6521/30000 (21.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3230s / 324.5144 s
agent0:                 episode reward: 0.1816,                 loss: nan
agent1:                 episode reward: -0.1816,                 loss: 0.1773
Episode: 6541/30000 (21.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3387s / 325.8531 s
agent0:                 episode reward: 0.1240,                 loss: nan
agent1:                 episode reward: -0.1240,                 loss: 0.1767
Episode: 6561/30000 (21.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3283s / 327.1814 s
agent0:                 episode reward: 0.3137,                 loss: nan
agent1:                 episode reward: -0.3137,                 loss: 0.1769
Episode: 6581/30000 (21.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3734s / 328.5548 s
agent0:                 episode reward: -0.1197,                 loss: nan
agent1:                 episode reward: 0.1197,                 loss: 0.1895
Episode: 6601/30000 (22.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3403s / 329.8951 s
agent0:                 episode reward: -0.7149,                 loss: nan
agent1:                 episode reward: 0.7149,                 loss: 0.1894
Episode: 6621/30000 (22.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3377s / 331.2328 s
agent0:                 episode reward: 0.3764,                 loss: nan
agent1:                 episode reward: -0.3764,                 loss: 0.1904
Episode: 6641/30000 (22.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3512s / 332.5841 s
agent0:                 episode reward: -0.0666,                 loss: nan
agent1:                 episode reward: 0.0666,                 loss: 0.1912
Episode: 6661/30000 (22.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3456s / 333.9297 s
agent0:                 episode reward: 0.4457,                 loss: nan
agent1:                 episode reward: -0.4457,                 loss: 0.1891
Episode: 6681/30000 (22.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3743s / 335.3040 s
agent0:                 episode reward: 0.4754,                 loss: nan
agent1:                 episode reward: -0.4754,                 loss: 0.1700
Episode: 6701/30000 (22.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3433s / 336.6473 s
agent0:                 episode reward: 0.3564,                 loss: nan
agent1:                 episode reward: -0.3564,                 loss: 0.1654
Episode: 6721/30000 (22.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3578s / 338.0051 s
agent0:                 episode reward: -0.2030,                 loss: nan
agent1:                 episode reward: 0.2030,                 loss: 0.1667
Episode: 6741/30000 (22.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4083s / 339.4134 s
agent0:                 episode reward: -0.1681,                 loss: nan
agent1:                 episode reward: 0.1681,                 loss: 0.1666
Episode: 6761/30000 (22.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3532s / 340.7666 s
agent0:                 episode reward: -0.4235,                 loss: nan
agent1:                 episode reward: 0.4235,                 loss: 0.1675
Episode: 6781/30000 (22.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3788s / 342.1455 s
agent0:                 episode reward: -0.6366,                 loss: nan
agent1:                 episode reward: 0.6366,                 loss: 0.1759
Episode: 6801/30000 (22.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3744s / 343.5198 s
agent0:                 episode reward: 0.0387,                 loss: nan
agent1:                 episode reward: -0.0387,                 loss: 0.1794
Episode: 6821/30000 (22.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3741s / 344.8939 s
agent0:                 episode reward: 0.1008,                 loss: nan
agent1:                 episode reward: -0.1008,                 loss: 0.1778
Episode: 6841/30000 (22.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3572s / 346.2510 s
agent0:                 episode reward: 0.0539,                 loss: nan
agent1:                 episode reward: -0.0539,                 loss: 0.1778
Episode: 6861/30000 (22.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3765s / 347.6276 s
agent0:                 episode reward: 0.0506,                 loss: nan
agent1:                 episode reward: -0.0506,                 loss: 0.1777
Episode: 6881/30000 (22.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4109s / 349.0385 s
agent0:                 episode reward: 0.3994,                 loss: nan
agent1:                 episode reward: -0.3994,                 loss: 0.1805
Episode: 6901/30000 (23.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3945s / 350.4330 s
agent0:                 episode reward: -0.3329,                 loss: nan
agent1:                 episode reward: 0.3329,                 loss: 0.1817
Episode: 6921/30000 (23.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4201s / 351.8531 s
agent0:                 episode reward: 0.0966,                 loss: nan
agent1:                 episode reward: -0.0966,                 loss: 0.1808
Episode: 6941/30000 (23.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3864s / 353.2396 s
agent0:                 episode reward: -0.6216,                 loss: nan
agent1:                 episode reward: 0.6216,                 loss: 0.1795
Episode: 6961/30000 (23.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3787s / 354.6183 s
agent0:                 episode reward: 0.4877,                 loss: nan
agent1:                 episode reward: -0.4877,                 loss: 0.1798
Episode: 6981/30000 (23.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3809s / 355.9992 s
agent0:                 episode reward: -0.1623,                 loss: nan
agent1:                 episode reward: 0.1623,                 loss: 0.1919
Episode: 7001/30000 (23.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3960s / 357.3952 s
agent0:                 episode reward: 0.5869,                 loss: nan
agent1:                 episode reward: -0.5869,                 loss: 0.1930
Episode: 7021/30000 (23.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4498s / 358.8450 s
agent0:                 episode reward: -0.7710,                 loss: nan
agent1:                 episode reward: 0.7710,                 loss: 0.1931
Episode: 7041/30000 (23.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4133s / 360.2583 s
agent0:                 episode reward: -0.1459,                 loss: nan
agent1:                 episode reward: 0.1459,                 loss: 0.1936
Episode: 7061/30000 (23.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3999s / 361.6582 s
agent0:                 episode reward: -0.1924,                 loss: nan
agent1:                 episode reward: 0.1924,                 loss: 0.1943
Episode: 7081/30000 (23.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4053s / 363.0635 s
agent0:                 episode reward: 0.1750,                 loss: nan
agent1:                 episode reward: -0.1750,                 loss: 0.2022
Episode: 7101/30000 (23.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4064s / 364.4699 s
agent0:                 episode reward: 0.3218,                 loss: nan
agent1:                 episode reward: -0.3218,                 loss: 0.2031
Episode: 7121/30000 (23.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4252s / 365.8952 s
agent0:                 episode reward: -0.3087,                 loss: nan
agent1:                 episode reward: 0.3087,                 loss: 0.2063
Episode: 7141/30000 (23.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4249s / 367.3201 s
agent0:                 episode reward: -0.3218,                 loss: nan
agent1:                 episode reward: 0.3218,                 loss: 0.2039
Episode: 7161/30000 (23.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4116s / 368.7317 s
agent0:                 episode reward: 0.7132,                 loss: nan
agent1:                 episode reward: -0.7132,                 loss: 0.2046
Episode: 7181/30000 (23.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4490s / 370.1807 s
agent0:                 episode reward: 0.0338,                 loss: nan
agent1:                 episode reward: -0.0338,                 loss: 0.2017
Episode: 7201/30000 (24.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4298s / 371.6105 s
agent0:                 episode reward: 0.8243,                 loss: nan
agent1:                 episode reward: -0.8243,                 loss: 0.1975
Episode: 7221/30000 (24.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4161s / 373.0266 s
agent0:                 episode reward: 0.6256,                 loss: nan
agent1:                 episode reward: -0.6256,                 loss: 0.1991
Episode: 7241/30000 (24.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4297s / 374.4563 s
agent0:                 episode reward: -0.2638,                 loss: nan
agent1:                 episode reward: 0.2638,                 loss: 0.2003
Episode: 7261/30000 (24.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4445s / 375.9008 s
agent0:                 episode reward: 0.3272,                 loss: nan
agent1:                 episode reward: -0.3272,                 loss: 0.1985
Episode: 7281/30000 (24.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4337s / 377.3346 s
agent0:                 episode reward: 0.4983,                 loss: nan
agent1:                 episode reward: -0.4983,                 loss: 0.2083
Episode: 7301/30000 (24.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4286s / 378.7631 s
agent0:                 episode reward: -0.1996,                 loss: nan
agent1:                 episode reward: 0.1996,                 loss: 0.2085
Episode: 7321/30000 (24.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4843s / 380.2474 s
agent0:                 episode reward: -0.0952,                 loss: nan
agent1:                 episode reward: 0.0952,                 loss: 0.2055
Episode: 7341/30000 (24.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4524s / 381.6999 s
agent0:                 episode reward: -0.4939,                 loss: nan
agent1:                 episode reward: 0.4939,                 loss: 0.2066
Episode: 7361/30000 (24.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4401s / 383.1400 s
agent0:                 episode reward: -0.4007,                 loss: nan
agent1:                 episode reward: 0.4007,                 loss: 0.2079
Episode: 7381/30000 (24.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4596s / 384.5996 s
agent0:                 episode reward: 0.3357,                 loss: nan
agent1:                 episode reward: -0.3357,                 loss: 0.1752
Episode: 7401/30000 (24.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4444s / 386.0440 s
agent0:                 episode reward: -0.3786,                 loss: nan
agent1:                 episode reward: 0.3786,                 loss: 0.1713
Episode: 7421/30000 (24.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4415s / 387.4854 s
agent0:                 episode reward: -1.0073,                 loss: nan
agent1:                 episode reward: 1.0073,                 loss: 0.1696
Episode: 7441/30000 (24.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4446s / 388.9300 s
agent0:                 episode reward: 0.1269,                 loss: nan
agent1:                 episode reward: -0.1269,                 loss: 0.1722
Episode: 7461/30000 (24.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5472s / 390.4772 s
agent0:                 episode reward: 1.0320,                 loss: nan
agent1:                 episode reward: -1.0320,                 loss: 0.1698
Episode: 7481/30000 (24.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4757s / 391.9529 s
agent0:                 episode reward: 0.0365,                 loss: nan
agent1:                 episode reward: -0.0365,                 loss: 0.1649
Episode: 7501/30000 (25.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4821s / 393.4350 s
agent0:                 episode reward: -0.5372,                 loss: nan
agent1:                 episode reward: 0.5372,                 loss: 0.1618
Episode: 7521/30000 (25.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4630s / 394.8980 s
agent0:                 episode reward: -0.2811,                 loss: nan
agent1:                 episode reward: 0.2811,                 loss: 0.1629
Episode: 7541/30000 (25.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4786s / 396.3765 s
agent0:                 episode reward: 0.1536,                 loss: nan
agent1:                 episode reward: -0.1536,                 loss: 0.1617
Episode: 7561/30000 (25.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4735s / 397.8500 s
agent0:                 episode reward: 0.1166,                 loss: nan
agent1:                 episode reward: -0.1166,                 loss: 0.1617
Episode: 7581/30000 (25.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5168s / 399.3668 s
agent0:                 episode reward: -0.1385,                 loss: nan
agent1:                 episode reward: 0.1385,                 loss: 0.1743
Episode: 7601/30000 (25.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5544s / 400.9212 s
agent0:                 episode reward: -0.2084,                 loss: nan
agent1:                 episode reward: 0.2084,                 loss: 0.1748
Episode: 7621/30000 (25.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4971s / 402.4183 s
agent0:                 episode reward: -0.2867,                 loss: nan
agent1:                 episode reward: 0.2867,                 loss: 0.1749
Episode: 7641/30000 (25.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5169s / 403.9353 s
agent0:                 episode reward: 0.6954,                 loss: nan
agent1:                 episode reward: -0.6954,                 loss: 0.1723
Episode: 7661/30000 (25.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4941s / 405.4294 s
agent0:                 episode reward: 0.1660,                 loss: nan
agent1:                 episode reward: -0.1660,                 loss: 0.1734
Episode: 7681/30000 (25.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4935s / 406.9229 s
agent0:                 episode reward: 0.1326,                 loss: nan
agent1:                 episode reward: -0.1326,                 loss: 0.2040
Episode: 7701/30000 (25.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5018s / 408.4247 s
agent0:                 episode reward: -0.4788,                 loss: nan
agent1:                 episode reward: 0.4788,                 loss: 0.2092
Episode: 7721/30000 (25.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5424s / 409.9671 s
agent0:                 episode reward: 0.5383,                 loss: nan
agent1:                 episode reward: -0.5383,                 loss: 0.2117
Episode: 7741/30000 (25.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5327s / 411.4998 s
agent0:                 episode reward: -0.4945,                 loss: nan
agent1:                 episode reward: 0.4945,                 loss: 0.2082
Episode: 7761/30000 (25.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5123s / 413.0121 s
agent0:                 episode reward: 0.2270,                 loss: nan
agent1:                 episode reward: -0.2270,                 loss: 0.2073
Episode: 7781/30000 (25.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5281s / 414.5402 s
agent0:                 episode reward: -0.3846,                 loss: nan
agent1:                 episode reward: 0.3846,                 loss: 0.2340
Episode: 7801/30000 (26.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5061s / 416.0463 s
agent0:                 episode reward: -0.2997,                 loss: nan
agent1:                 episode reward: 0.2997,                 loss: 0.2352
Episode: 7821/30000 (26.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5670s / 417.6133 s
agent0:                 episode reward: -0.0168,                 loss: nan
agent1:                 episode reward: 0.0168,                 loss: 0.2346
Episode: 7841/30000 (26.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5132s / 419.1264 s
agent0:                 episode reward: 0.0040,                 loss: nan
agent1:                 episode reward: -0.0040,                 loss: 0.2339
Episode: 7861/30000 (26.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5617s / 420.6881 s
agent0:                 episode reward: -0.1166,                 loss: nan
agent1:                 episode reward: 0.1166,                 loss: 0.2330
Episode: 7881/30000 (26.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5285s / 422.2166 s
agent0:                 episode reward: -0.0575,                 loss: nan
agent1:                 episode reward: 0.0575,                 loss: 0.1895
Episode: 7901/30000 (26.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5211s / 423.7378 s
agent0:                 episode reward: -0.5252,                 loss: nan
agent1:                 episode reward: 0.5252,                 loss: 0.1815
Episode: 7921/30000 (26.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5267s / 425.2645 s
agent0:                 episode reward: 0.0467,                 loss: nan
agent1:                 episode reward: -0.0467,                 loss: 0.1793
Episode: 7941/30000 (26.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5500s / 426.8144 s
agent0:                 episode reward: 0.2208,                 loss: nan
agent1:                 episode reward: -0.2208,                 loss: 0.1790
Episode: 7961/30000 (26.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5272s / 428.3417 s
agent0:                 episode reward: -0.4104,                 loss: nan
agent1:                 episode reward: 0.4104,                 loss: 0.1797
Episode: 7981/30000 (26.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5340s / 429.8757 s
agent0:                 episode reward: 0.1382,                 loss: nan
agent1:                 episode reward: -0.1382,                 loss: 0.1683
Episode: 8001/30000 (26.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5718s / 431.4475 s
agent0:                 episode reward: -0.5061,                 loss: nan
agent1:                 episode reward: 0.5061,                 loss: 0.1637
Episode: 8021/30000 (26.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5541s / 433.0016 s
agent0:                 episode reward: 0.4897,                 loss: nan
agent1:                 episode reward: -0.4897,                 loss: 0.1655
Episode: 8041/30000 (26.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5712s / 434.5727 s
agent0:                 episode reward: 0.1628,                 loss: nan
agent1:                 episode reward: -0.1628,                 loss: 0.1662
Episode: 8061/30000 (26.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5396s / 436.1123 s
agent0:                 episode reward: 0.7525,                 loss: nan
agent1:                 episode reward: -0.7525,                 loss: 0.1657
Episode: 8081/30000 (26.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5457s / 437.6580 s
agent0:                 episode reward: -0.2499,                 loss: nan
agent1:                 episode reward: 0.2499,                 loss: 0.1859
Episode: 8101/30000 (27.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5562s / 439.2142 s
agent0:                 episode reward: -0.5742,                 loss: nan
agent1:                 episode reward: 0.5742,                 loss: 0.1856
Episode: 8121/30000 (27.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5925s / 440.8067 s
agent0:                 episode reward: -0.0501,                 loss: nan
agent1:                 episode reward: 0.0501,                 loss: 0.1850
Episode: 8141/30000 (27.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5779s / 442.3846 s
agent0:                 episode reward: 0.4180,                 loss: nan
agent1:                 episode reward: -0.4180,                 loss: 0.1855
Episode: 8161/30000 (27.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5668s / 443.9514 s
agent0:                 episode reward: -0.1983,                 loss: nan
agent1:                 episode reward: 0.1983,                 loss: 0.1864
Episode: 8181/30000 (27.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5675s / 445.5190 s
agent0:                 episode reward: -0.4821,                 loss: nan
agent1:                 episode reward: 0.4821,                 loss: 0.1936
Episode: 8201/30000 (27.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5702s / 447.0892 s
agent0:                 episode reward: 0.0805,                 loss: nan
agent1:                 episode reward: -0.0805,                 loss: 0.1930
Episode: 8221/30000 (27.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5598s / 448.6489 s
agent0:                 episode reward: -0.1133,                 loss: nan
agent1:                 episode reward: 0.1133,                 loss: 0.1957
Episode: 8241/30000 (27.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5868s / 450.2357 s
agent0:                 episode reward: 0.1819,                 loss: nan
agent1:                 episode reward: -0.1819,                 loss: 0.1940
Episode: 8261/30000 (27.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6453s / 451.8810 s
agent0:                 episode reward: -0.1510,                 loss: nan
agent1:                 episode reward: 0.1510,                 loss: 0.1921
Episode: 8281/30000 (27.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5724s / 453.4534 s
agent0:                 episode reward: -0.0044,                 loss: nan
agent1:                 episode reward: 0.0044,                 loss: 0.1797
Episode: 8301/30000 (27.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5715s / 455.0249 s
agent0:                 episode reward: -0.2333,                 loss: nan
agent1:                 episode reward: 0.2333,                 loss: 0.1755
Episode: 8321/30000 (27.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5822s / 456.6072 s
agent0:                 episode reward: -0.0766,                 loss: nan
agent1:                 episode reward: 0.0766,                 loss: 0.1753
Episode: 8341/30000 (27.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5736s / 458.1807 s
agent0:                 episode reward: 0.2359,                 loss: nan
agent1:                 episode reward: -0.2359,                 loss: 0.1756
Episode: 8361/30000 (27.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5998s / 459.7805 s
agent0:                 episode reward: -0.0466,                 loss: nan
agent1:                 episode reward: 0.0466,                 loss: 0.1744
Episode: 8381/30000 (27.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6320s / 461.4125 s
agent0:                 episode reward: 0.0078,                 loss: nan
agent1:                 episode reward: -0.0078,                 loss: 0.1618
Episode: 8401/30000 (28.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6076s / 463.0201 s
agent0:                 episode reward: 0.0199,                 loss: nan
agent1:                 episode reward: -0.0199,                 loss: 0.1600
Episode: 8421/30000 (28.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5993s / 464.6194 s
agent0:                 episode reward: 0.0965,                 loss: nan
agent1:                 episode reward: -0.0965,                 loss: 0.1621
Episode: 8441/30000 (28.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5927s / 466.2121 s
agent0:                 episode reward: -0.1160,                 loss: nan
agent1:                 episode reward: 0.1160,                 loss: 0.1595
Episode: 8461/30000 (28.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6367s / 467.8489 s
agent0:                 episode reward: -0.7178,                 loss: nan
agent1:                 episode reward: 0.7178,                 loss: 0.1595
Episode: 8481/30000 (28.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5970s / 469.4458 s
agent0:                 episode reward: -0.2270,                 loss: nan
agent1:                 episode reward: 0.2270,                 loss: 0.1679
Episode: 8501/30000 (28.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5979s / 471.0438 s
agent0:                 episode reward: 0.0513,                 loss: nan
agent1:                 episode reward: -0.0513,                 loss: 0.1686
Episode: 8521/30000 (28.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6546s / 472.6983 s
agent0:                 episode reward: 0.1336,                 loss: nan
agent1:                 episode reward: -0.1336,                 loss: 0.1678
Episode: 8541/30000 (28.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6130s / 474.3113 s
agent0:                 episode reward: -0.2817,                 loss: nan
agent1:                 episode reward: 0.2817,                 loss: 0.1681
Episode: 8561/30000 (28.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6198s / 475.9311 s
agent0:                 episode reward: 0.4947,                 loss: nan
agent1:                 episode reward: -0.4947,                 loss: 0.1679
Episode: 8581/30000 (28.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6203s / 477.5514 s
agent0:                 episode reward: -0.1438,                 loss: nan
agent1:                 episode reward: 0.1438,                 loss: 0.1857
Episode: 8601/30000 (28.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6074s / 479.1588 s
agent0:                 episode reward: -0.0305,                 loss: nan
agent1:                 episode reward: 0.0305,                 loss: 0.1874
Episode: 8621/30000 (28.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6270s / 480.7858 s
agent0:                 episode reward: 0.0469,                 loss: nan
agent1:                 episode reward: -0.0469,                 loss: 0.1872
Episode: 8641/30000 (28.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6577s / 482.4435 s
agent0:                 episode reward: -0.1938,                 loss: nan
agent1:                 episode reward: 0.1938,                 loss: 0.1884
Episode: 8661/30000 (28.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6549s / 484.0984 s
agent0:                 episode reward: -0.3535,                 loss: nan
agent1:                 episode reward: 0.3535,                 loss: 0.1874
Episode: 8681/30000 (28.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6264s / 485.7248 s
agent0:                 episode reward: -0.2335,                 loss: nan
agent1:                 episode reward: 0.2335,                 loss: 0.2082
Episode: 8701/30000 (29.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6266s / 487.3513 s
agent0:                 episode reward: 0.1783,                 loss: nan
agent1:                 episode reward: -0.1783,                 loss: 0.2106
Episode: 8721/30000 (29.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6278s / 488.9791 s
agent0:                 episode reward: -0.6024,                 loss: nan
agent1:                 episode reward: 0.6024,                 loss: 0.2103
Episode: 8741/30000 (29.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6336s / 490.6127 s
agent0:                 episode reward: -0.3618,                 loss: nan
agent1:                 episode reward: 0.3618,                 loss: 0.2101
Episode: 8761/30000 (29.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6928s / 492.3055 s
agent0:                 episode reward: -0.4064,                 loss: nan
agent1:                 episode reward: 0.4064,                 loss: 0.2105
Episode: 8781/30000 (29.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6446s / 493.9502 s
agent0:                 episode reward: 0.1123,                 loss: nan
agent1:                 episode reward: -0.1123,                 loss: 0.1978
Episode: 8801/30000 (29.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6490s / 495.5992 s
agent0:                 episode reward: -0.8530,                 loss: nan
agent1:                 episode reward: 0.8530,                 loss: 0.1936
Episode: 8821/30000 (29.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6560s / 497.2552 s
agent0:                 episode reward: 0.3119,                 loss: nan
agent1:                 episode reward: -0.3119,                 loss: 0.1919
Episode: 8841/30000 (29.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6512s / 498.9064 s
agent0:                 episode reward: 0.0525,                 loss: nan
agent1:                 episode reward: -0.0525,                 loss: 0.1911
Episode: 8861/30000 (29.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6683s / 500.5747 s
agent0:                 episode reward: 0.0202,                 loss: nan
agent1:                 episode reward: -0.0202,                 loss: 0.1914
Episode: 8881/30000 (29.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6988s / 502.2734 s
agent0:                 episode reward: 0.1019,                 loss: nan
agent1:                 episode reward: -0.1019,                 loss: 0.1725
Episode: 8901/30000 (29.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6715s / 503.9449 s
agent0:                 episode reward: 0.0284,                 loss: nan
agent1:                 episode reward: -0.0284,                 loss: 0.1665
Episode: 8921/30000 (29.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6505s / 505.5954 s
agent0:                 episode reward: -0.4733,                 loss: nan
agent1:                 episode reward: 0.4733,                 loss: 0.1661
Episode: 8941/30000 (29.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6721s / 507.2675 s
agent0:                 episode reward: 0.0421,                 loss: nan
agent1:                 episode reward: -0.0421,                 loss: 0.1668
Episode: 8961/30000 (29.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6785s / 508.9459 s
agent0:                 episode reward: 0.1700,                 loss: nan
agent1:                 episode reward: -0.1700,                 loss: 0.1644
Episode: 8981/30000 (29.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6611s / 510.6070 s
agent0:                 episode reward: 0.3573,                 loss: nan
agent1:                 episode reward: -0.3573,                 loss: 0.1624
Episode: 9001/30000 (30.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7061s / 512.3132 s
agent0:                 episode reward: -0.0013,                 loss: nan
agent1:                 episode reward: 0.0013,                 loss: 0.1591
Episode: 9021/30000 (30.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6921s / 514.0053 s
agent0:                 episode reward: -0.8647,                 loss: nan
agent1:                 episode reward: 0.8647,                 loss: 0.1573
Episode: 9041/30000 (30.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6788s / 515.6840 s
agent0:                 episode reward: -0.0278,                 loss: nan
agent1:                 episode reward: 0.0278,                 loss: 0.1588
Episode: 9061/30000 (30.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6983s / 517.3823 s
agent0:                 episode reward: -0.8895,                 loss: nan
agent1:                 episode reward: 0.8895,                 loss: 0.1572
Episode: 9081/30000 (30.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6920s / 519.0743 s
agent0:                 episode reward: -0.4779,                 loss: nan
agent1:                 episode reward: 0.4779,                 loss: 0.1755
Episode: 9101/30000 (30.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6859s / 520.7602 s
agent0:                 episode reward: 0.0427,                 loss: nan
agent1:                 episode reward: -0.0427,                 loss: 0.1755
Episode: 9121/30000 (30.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7553s / 522.5155 s
agent0:                 episode reward: -0.7828,                 loss: nan
agent1:                 episode reward: 0.7828,                 loss: 0.1767
Episode: 9141/30000 (30.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7031s / 524.2187 s
agent0:                 episode reward: -0.1349,                 loss: nan
agent1:                 episode reward: 0.1349,                 loss: 0.1758
Episode: 9161/30000 (30.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7193s / 525.9379 s
agent0:                 episode reward: -0.6560,                 loss: nan
agent1:                 episode reward: 0.6560,                 loss: 0.1751
Episode: 9181/30000 (30.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7136s / 527.6515 s
agent0:                 episode reward: 0.2075,                 loss: nan
agent1:                 episode reward: -0.2075,                 loss: 0.1870
Episode: 9201/30000 (30.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7299s / 529.3814 s
agent0:                 episode reward: -1.0439,                 loss: nan
agent1:                 episode reward: 1.0439,                 loss: 0.1840
Episode: 9221/30000 (30.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7121s / 531.0935 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.1839
Episode: 9241/30000 (30.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7413s / 532.8348 s
agent0:                 episode reward: -0.8854,                 loss: nan
agent1:                 episode reward: 0.8854,                 loss: 0.1834
Episode: 9261/30000 (30.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7478s / 534.5826 s
agent0:                 episode reward: -0.9403,                 loss: nan
agent1:                 episode reward: 0.9403,                 loss: 0.1839
Episode: 9281/30000 (30.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7077s / 536.2903 s
agent0:                 episode reward: 0.1235,                 loss: nan
agent1:                 episode reward: -0.1235,                 loss: 0.1678
Episode: 9301/30000 (31.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7189s / 538.0092 s
agent0:                 episode reward: -0.5281,                 loss: nan
agent1:                 episode reward: 0.5281,                 loss: 0.1596
Episode: 9321/30000 (31.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7076s / 539.7168 s
agent0:                 episode reward: -0.6245,                 loss: nan
agent1:                 episode reward: 0.6245,                 loss: 0.1598
Episode: 9341/30000 (31.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7215s / 541.4383 s
agent0:                 episode reward: 0.0903,                 loss: nan
agent1:                 episode reward: -0.0903,                 loss: 0.1590
Episode: 9361/30000 (31.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8048s / 543.2431 s
agent0:                 episode reward: 0.7830,                 loss: nan
agent1:                 episode reward: -0.7830,                 loss: 0.1591
Episode: 9381/30000 (31.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7414s / 544.9845 s
agent0:                 episode reward: -0.1390,                 loss: nan
agent1:                 episode reward: 0.1390,                 loss: 0.1402
Episode: 9401/30000 (31.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7401s / 546.7246 s
agent0:                 episode reward: -0.2970,                 loss: nan
agent1:                 episode reward: 0.2970,                 loss: 0.1351
Episode: 9421/30000 (31.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7149s / 548.4395 s
agent0:                 episode reward: -0.9319,                 loss: nan
agent1:                 episode reward: 0.9319,                 loss: 0.1358
Episode: 9441/30000 (31.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7508s / 550.1903 s
agent0:                 episode reward: -0.6765,                 loss: nan
agent1:                 episode reward: 0.6765,                 loss: 0.1355
Episode: 9461/30000 (31.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7430s / 551.9333 s
agent0:                 episode reward: -0.4500,                 loss: nan
agent1:                 episode reward: 0.4500,                 loss: 0.1352
Episode: 9481/30000 (31.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7873s / 553.7206 s
agent0:                 episode reward: -0.2235,                 loss: nan
agent1:                 episode reward: 0.2235,                 loss: 0.1472
Episode: 9501/30000 (31.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7538s / 555.4743 s
agent0:                 episode reward: -0.1523,                 loss: nan
agent1:                 episode reward: 0.1523,                 loss: 0.1464
Episode: 9521/30000 (31.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7431s / 557.2175 s
agent0:                 episode reward: 0.0273,                 loss: nan
agent1:                 episode reward: -0.0273,                 loss: 0.1477
Episode: 9541/30000 (31.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7930s / 559.0105 s
agent0:                 episode reward: -0.8447,                 loss: nan
agent1:                 episode reward: 0.8447,                 loss: 0.1455
Episode: 9561/30000 (31.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7630s / 560.7735 s
agent0:                 episode reward: 0.1303,                 loss: nan
agent1:                 episode reward: -0.1303,                 loss: 0.1451
Episode: 9581/30000 (31.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7640s / 562.5376 s
agent0:                 episode reward: -1.0144,                 loss: nan
agent1:                 episode reward: 1.0144,                 loss: 0.2000
Episode: 9601/30000 (32.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8239s / 564.3614 s
agent0:                 episode reward: -1.0298,                 loss: nan
agent1:                 episode reward: 1.0298,                 loss: 0.2054
Episode: 9621/30000 (32.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7645s / 566.1259 s
agent0:                 episode reward: -0.5186,                 loss: nan
agent1:                 episode reward: 0.5186,                 loss: 0.2085
Episode: 9641/30000 (32.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7963s / 567.9222 s
agent0:                 episode reward: -0.0613,                 loss: nan
agent1:                 episode reward: 0.0613,                 loss: 0.2047
Episode: 9661/30000 (32.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7745s / 569.6967 s
agent0:                 episode reward: 0.3030,                 loss: nan
agent1:                 episode reward: -0.3030,                 loss: 0.2049
Episode: 9681/30000 (32.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7836s / 571.4803 s
agent0:                 episode reward: -0.1997,                 loss: nan
agent1:                 episode reward: 0.1997,                 loss: 0.2198
Episode: 9701/30000 (32.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8045s / 573.2848 s
agent0:                 episode reward: 0.0513,                 loss: nan
agent1:                 episode reward: -0.0513,                 loss: 0.2204
Episode: 9721/30000 (32.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8466s / 575.1314 s
agent0:                 episode reward: -0.0990,                 loss: nan
agent1:                 episode reward: 0.0990,                 loss: 0.2202
Episode: 9741/30000 (32.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7959s / 576.9273 s
agent0:                 episode reward: -0.0270,                 loss: nan
agent1:                 episode reward: 0.0270,                 loss: 0.2177
Episode: 9761/30000 (32.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7839s / 578.7113 s
agent0:                 episode reward: -0.6874,                 loss: nan
agent1:                 episode reward: 0.6874,                 loss: 0.2171
Episode: 9781/30000 (32.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7954s / 580.5066 s
agent0:                 episode reward: -0.2489,                 loss: nan
agent1:                 episode reward: 0.2489,                 loss: 0.1827
Episode: 9801/30000 (32.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7970s / 582.3036 s
agent0:                 episode reward: -0.4180,                 loss: nan
agent1:                 episode reward: 0.4180,                 loss: 0.1727
Episode: 9821/30000 (32.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8689s / 584.1726 s
agent0:                 episode reward: -0.6577,                 loss: nan
agent1:                 episode reward: 0.6577,                 loss: 0.1725
Episode: 9841/30000 (32.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8030s / 585.9756 s
agent0:                 episode reward: -0.1721,                 loss: nan
agent1:                 episode reward: 0.1721,                 loss: 0.1713
Episode: 9861/30000 (32.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7982s / 587.7738 s
agent0:                 episode reward: -0.3158,                 loss: nan
agent1:                 episode reward: 0.3158,                 loss: 0.1705
Episode: 9881/30000 (32.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8146s / 589.5883 s
agent0:                 episode reward: 0.0624,                 loss: nan
agent1:                 episode reward: -0.0624,                 loss: 0.1548
Episode: 9901/30000 (33.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8210s / 591.4093 s
agent0:                 episode reward: -0.9700,                 loss: nan
agent1:                 episode reward: 0.9700,                 loss: 0.1482
Episode: 9921/30000 (33.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8228s / 593.2321 s
agent0:                 episode reward: 0.2051,                 loss: nan
agent1:                 episode reward: -0.2051,                 loss: 0.1475
Episode: 9941/30000 (33.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8690s / 595.1011 s
agent0:                 episode reward: -0.0269,                 loss: nan
agent1:                 episode reward: 0.0269,                 loss: 0.1466
Episode: 9961/30000 (33.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8057s / 596.9068 s
agent0:                 episode reward: -0.5381,                 loss: nan
agent1:                 episode reward: 0.5381,                 loss: 0.1481
Episode: 9981/30000 (33.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8264s / 598.7332 s
agent0:                 episode reward: -0.3743,                 loss: nan
agent1:                 episode reward: 0.3743,                 loss: 0.1527
Episode: 10001/30000 (33.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8344s / 600.5675 s
agent0:                 episode reward: -0.7422,                 loss: nan
agent1:                 episode reward: 0.7422,                 loss: 0.1512
Episode: 10021/30000 (33.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8193s / 602.3868 s
agent0:                 episode reward: -0.2083,                 loss: nan
agent1:                 episode reward: 0.2083,                 loss: 0.1513
Episode: 10041/30000 (33.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8315s / 604.2183 s
agent0:                 episode reward: -0.2953,                 loss: nan
agent1:                 episode reward: 0.2953,                 loss: 0.1499
Episode: 10061/30000 (33.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8805s / 606.0987 s
agent0:                 episode reward: 0.0777,                 loss: nan
agent1:                 episode reward: -0.0777,                 loss: 0.1495
Episode: 10081/30000 (33.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8419s / 607.9407 s
agent0:                 episode reward: -1.3031,                 loss: nan
agent1:                 episode reward: 1.3031,                 loss: 0.1887
Episode: 10101/30000 (33.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8339s / 609.7746 s
agent0:                 episode reward: -0.0035,                 loss: nan
agent1:                 episode reward: 0.0035,                 loss: 0.1924
Episode: 10121/30000 (33.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8210s / 611.5956 s
agent0:                 episode reward: -0.2977,                 loss: nan
agent1:                 episode reward: 0.2977,                 loss: 0.1934
Episode: 10141/30000 (33.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8474s / 613.4430 s
agent0:                 episode reward: -0.2470,                 loss: nan
agent1:                 episode reward: 0.2470,                 loss: 0.1928
Episode: 10161/30000 (33.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8868s / 615.3299 s
agent0:                 episode reward: -0.5881,                 loss: nan
agent1:                 episode reward: 0.5881,                 loss: 0.1932
Episode: 10181/30000 (33.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8376s / 617.1675 s
agent0:                 episode reward: -0.7424,                 loss: nan
agent1:                 episode reward: 0.7424,                 loss: 0.1731
Episode: 10201/30000 (34.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8392s / 619.0067 s
agent0:                 episode reward: 0.1746,                 loss: nan
agent1:                 episode reward: -0.1746,                 loss: 0.1669
Episode: 10221/30000 (34.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8254s / 620.8322 s
agent0:                 episode reward: -0.4713,                 loss: nan
agent1:                 episode reward: 0.4713,                 loss: 0.1662
Episode: 10241/30000 (34.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8382s / 622.6704 s
agent0:                 episode reward: -0.5103,                 loss: nan
agent1:                 episode reward: 0.5103,                 loss: 0.1670
Episode: 10261/30000 (34.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8387s / 624.5091 s
agent0:                 episode reward: -0.5193,                 loss: nan
agent1:                 episode reward: 0.5193,                 loss: 0.1662
Episode: 10281/30000 (34.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8896s / 626.3987 s
agent0:                 episode reward: -0.2418,                 loss: nan
agent1:                 episode reward: 0.2418,                 loss: 0.1515
Episode: 10301/30000 (34.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8630s / 628.2616 s
agent0:                 episode reward: -0.5870,                 loss: nan
agent1:                 episode reward: 0.5870,                 loss: 0.1479
Episode: 10321/30000 (34.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8258s / 630.0875 s
agent0:                 episode reward: -0.3180,                 loss: nan
agent1:                 episode reward: 0.3180,                 loss: 0.1489
Episode: 10341/30000 (34.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8386s / 631.9261 s
agent0:                 episode reward: 0.3410,                 loss: nan
agent1:                 episode reward: -0.3410,                 loss: 0.1481
Episode: 10361/30000 (34.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8497s / 633.7758 s
agent0:                 episode reward: -0.5862,                 loss: nan
agent1:                 episode reward: 0.5862,                 loss: 0.1473
Episode: 10381/30000 (34.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8769s / 635.6527 s
agent0:                 episode reward: -0.8917,                 loss: nan
agent1:                 episode reward: 0.8917,                 loss: 0.1507
Episode: 10401/30000 (34.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8396s / 637.4923 s
agent0:                 episode reward: -0.6985,                 loss: nan
agent1:                 episode reward: 0.6985,                 loss: 0.1490
Episode: 10421/30000 (34.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8688s / 639.3611 s
agent0:                 episode reward: -0.1824,                 loss: nan
agent1:                 episode reward: 0.1824,                 loss: 0.1494
Episode: 10441/30000 (34.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8251s / 641.1862 s
agent0:                 episode reward: -0.5858,                 loss: nan
agent1:                 episode reward: 0.5858,                 loss: 0.1487
Episode: 10461/30000 (34.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8941s / 643.0804 s
agent0:                 episode reward: -0.1971,                 loss: nan
agent1:                 episode reward: 0.1971,                 loss: 0.1484
Episode: 10481/30000 (34.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8411s / 644.9215 s
agent0:                 episode reward: -0.7413,                 loss: nan
agent1:                 episode reward: 0.7413,                 loss: 0.1828
Episode: 10501/30000 (35.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8892s / 646.8107 s
agent0:                 episode reward: -0.5686,                 loss: nan
agent1:                 episode reward: 0.5686,                 loss: 0.1875
Episode: 10521/30000 (35.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8422s / 648.6528 s
agent0:                 episode reward: 0.5714,                 loss: nan
agent1:                 episode reward: -0.5714,                 loss: 0.1874
Episode: 10541/30000 (35.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8474s / 650.5002 s
agent0:                 episode reward: -1.2589,                 loss: nan
agent1:                 episode reward: 1.2589,                 loss: 0.1886
Episode: 10561/30000 (35.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8385s / 652.3387 s
agent0:                 episode reward: -0.3477,                 loss: nan
agent1:                 episode reward: 0.3477,                 loss: 0.1887
Episode: 10581/30000 (35.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8307s / 654.1694 s
agent0:                 episode reward: -0.8428,                 loss: nan
agent1:                 episode reward: 0.8428,                 loss: 0.2189
Episode: 10601/30000 (35.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8934s / 656.0628 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.2230
Episode: 10621/30000 (35.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8518s / 657.9145 s
agent0:                 episode reward: -0.1789,                 loss: nan
agent1:                 episode reward: 0.1789,                 loss: 0.2229
Episode: 10641/30000 (35.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8559s / 659.7705 s
agent0:                 episode reward: 0.0484,                 loss: nan
agent1:                 episode reward: -0.0484,                 loss: 0.2229
Episode: 10661/30000 (35.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8395s / 661.6100 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.2218
Episode: 10681/30000 (35.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8477s / 663.4577 s
agent0:                 episode reward: -1.0614,                 loss: nan
agent1:                 episode reward: 1.0614,                 loss: 0.1877
Episode: 10701/30000 (35.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8430s / 665.3007 s
agent0:                 episode reward: -0.3114,                 loss: nan
agent1:                 episode reward: 0.3114,                 loss: 0.1815
Episode: 10721/30000 (35.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9089s / 667.2096 s
agent0:                 episode reward: -0.4083,                 loss: nan
agent1:                 episode reward: 0.4083,                 loss: 0.1823
Episode: 10741/30000 (35.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8411s / 669.0507 s
agent0:                 episode reward: -0.5405,                 loss: nan
agent1:                 episode reward: 0.5405,                 loss: 0.1806
Episode: 10761/30000 (35.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8484s / 670.8991 s
agent0:                 episode reward: -0.8301,                 loss: nan
agent1:                 episode reward: 0.8301,                 loss: 0.1823
Episode: 10781/30000 (35.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8504s / 672.7495 s
agent0:                 episode reward: -0.2916,                 loss: nan
agent1:                 episode reward: 0.2916,                 loss: 0.1748
Episode: 10801/30000 (36.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8360s / 674.5855 s
agent0:                 episode reward: -0.4516,                 loss: nan
agent1:                 episode reward: 0.4516,                 loss: 0.1703
Episode: 10821/30000 (36.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9046s / 676.4900 s
agent0:                 episode reward: -0.8410,                 loss: nan
agent1:                 episode reward: 0.8410,                 loss: 0.1692
Episode: 10841/30000 (36.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8476s / 678.3376 s
agent0:                 episode reward: -0.1071,                 loss: nan
agent1:                 episode reward: 0.1071,                 loss: 0.1695
Episode: 10861/30000 (36.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8448s / 680.1824 s
agent0:                 episode reward: -0.6493,                 loss: nan
agent1:                 episode reward: 0.6493,                 loss: 0.1704
Episode: 10881/30000 (36.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8570s / 682.0394 s
agent0:                 episode reward: -0.6673,                 loss: nan
agent1:                 episode reward: 0.6673,                 loss: 0.1889
Episode: 10901/30000 (36.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8560s / 683.8953 s
agent0:                 episode reward: -0.9667,                 loss: nan
agent1:                 episode reward: 0.9667,                 loss: 0.1898
Episode: 10921/30000 (36.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8558s / 685.7512 s
agent0:                 episode reward: -0.2983,                 loss: nan
agent1:                 episode reward: 0.2983,                 loss: 0.1925
Episode: 10941/30000 (36.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8812s / 687.6323 s
agent0:                 episode reward: 0.3874,                 loss: nan
agent1:                 episode reward: -0.3874,                 loss: 0.1916
Episode: 10961/30000 (36.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8446s / 689.4770 s
agent0:                 episode reward: -1.4861,                 loss: nan
agent1:                 episode reward: 1.4861,                 loss: 0.1902
Episode: 10981/30000 (36.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8649s / 691.3418 s
agent0:                 episode reward: -0.0041,                 loss: nan
agent1:                 episode reward: 0.0041,                 loss: 0.1912
Episode: 11001/30000 (36.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8369s / 693.1788 s
agent0:                 episode reward: -0.3904,                 loss: nan
agent1:                 episode reward: 0.3904,                 loss: 0.1871
Episode: 11021/30000 (36.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8391s / 695.0179 s
agent0:                 episode reward: -0.1583,                 loss: nan
agent1:                 episode reward: 0.1583,                 loss: 0.1881
Episode: 11041/30000 (36.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8931s / 696.9110 s
agent0:                 episode reward: 0.0323,                 loss: nan
agent1:                 episode reward: -0.0323,                 loss: 0.1866
Episode: 11061/30000 (36.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8325s / 698.7435 s
agent0:                 episode reward: -0.7627,                 loss: nan
agent1:                 episode reward: 0.7627,                 loss: 0.1878
Episode: 11081/30000 (36.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8612s / 700.6047 s
agent0:                 episode reward: -0.3880,                 loss: nan
agent1:                 episode reward: 0.3880,                 loss: 0.1833
Episode: 11101/30000 (37.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8281s / 702.4328 s
agent0:                 episode reward: -1.3192,                 loss: nan
agent1:                 episode reward: 1.3192,                 loss: 0.1782
Episode: 11121/30000 (37.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8510s / 704.2837 s
agent0:                 episode reward: -1.1437,                 loss: nan
agent1:                 episode reward: 1.1437,                 loss: 0.1760
Episode: 11141/30000 (37.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8446s / 706.1284 s
agent0:                 episode reward: -0.7181,                 loss: nan
agent1:                 episode reward: 0.7181,                 loss: 0.1744
Episode: 11161/30000 (37.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8941s / 708.0224 s
agent0:                 episode reward: -0.7077,                 loss: nan
agent1:                 episode reward: 0.7077,                 loss: 0.1764
Episode: 11181/30000 (37.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8330s / 709.8554 s
agent0:                 episode reward: -0.0596,                 loss: nan
agent1:                 episode reward: 0.0596,                 loss: 0.1642
Episode: 11201/30000 (37.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8341s / 711.6895 s
agent0:                 episode reward: -0.6812,                 loss: nan
agent1:                 episode reward: 0.6812,                 loss: 0.1580
Episode: 11221/30000 (37.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8372s / 713.5267 s
agent0:                 episode reward: -1.0150,                 loss: nan
agent1:                 episode reward: 1.0150,                 loss: 0.1574
Episode: 11241/30000 (37.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8520s / 715.3787 s
agent0:                 episode reward: -0.2549,                 loss: nan
agent1:                 episode reward: 0.2549,                 loss: 0.1596
Episode: 11261/30000 (37.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8980s / 717.2767 s
agent0:                 episode reward: -0.7741,                 loss: nan
agent1:                 episode reward: 0.7741,                 loss: 0.1583
Episode: 11281/30000 (37.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8500s / 719.1268 s
agent0:                 episode reward: -0.7966,                 loss: nan
agent1:                 episode reward: 0.7966,                 loss: 0.1541
Episode: 11301/30000 (37.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8490s / 720.9757 s
agent0:                 episode reward: -0.6393,                 loss: nan
agent1:                 episode reward: 0.6393,                 loss: 0.1498
Episode: 11321/30000 (37.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8304s / 722.8061 s
agent0:                 episode reward: 0.4725,                 loss: nan
agent1:                 episode reward: -0.4725,                 loss: 0.1500
Episode: 11341/30000 (37.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8630s / 724.6692 s
agent0:                 episode reward: -1.1216,                 loss: nan
agent1:                 episode reward: 1.1216,                 loss: 0.1492
Episode: 11361/30000 (37.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8534s / 726.5225 s
agent0:                 episode reward: -0.3033,                 loss: nan
agent1:                 episode reward: 0.3033,                 loss: 0.1490
Episode: 11381/30000 (37.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8748s / 728.3974 s
agent0:                 episode reward: -1.5032,                 loss: nan
agent1:                 episode reward: 1.5032,                 loss: 0.1923
Episode: 11401/30000 (38.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8305s / 730.2279 s
agent0:                 episode reward: -0.0105,                 loss: nan
agent1:                 episode reward: 0.0105,                 loss: 0.1974
Episode: 11421/30000 (38.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8203s / 732.0483 s
agent0:                 episode reward: -0.4385,                 loss: nan
agent1:                 episode reward: 0.4385,                 loss: 0.1959
Episode: 11441/30000 (38.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8509s / 733.8992 s
agent0:                 episode reward: -0.7997,                 loss: nan
agent1:                 episode reward: 0.7997,                 loss: 0.1978
Episode: 11461/30000 (38.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8265s / 735.7257 s
agent0:                 episode reward: -0.3320,                 loss: nan
agent1:                 episode reward: 0.3320,                 loss: 0.1962
Episode: 11481/30000 (38.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8913s / 737.6171 s
agent0:                 episode reward: -0.5423,                 loss: nan
agent1:                 episode reward: 0.5423,                 loss: 0.2476
Episode: 11501/30000 (38.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8491s / 739.4661 s
agent0:                 episode reward: -0.0725,                 loss: nan
agent1:                 episode reward: 0.0725,                 loss: 0.2495
Episode: 11521/30000 (38.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8466s / 741.3127 s
agent0:                 episode reward: -0.8789,                 loss: nan
agent1:                 episode reward: 0.8789,                 loss: 0.2484
Episode: 11541/30000 (38.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8374s / 743.1501 s
agent0:                 episode reward: -0.8066,                 loss: nan
agent1:                 episode reward: 0.8066,                 loss: 0.2458
Episode: 11561/30000 (38.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8286s / 744.9787 s
agent0:                 episode reward: -0.2481,                 loss: nan
agent1:                 episode reward: 0.2481,                 loss: 0.2459
Episode: 11581/30000 (38.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8515s / 746.8301 s
agent0:                 episode reward: -0.7709,                 loss: nan
agent1:                 episode reward: 0.7709,                 loss: 0.2000
Episode: 11601/30000 (38.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8830s / 748.7132 s
agent0:                 episode reward: -0.8944,                 loss: nan
agent1:                 episode reward: 0.8944,                 loss: 0.1871
Episode: 11621/30000 (38.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8479s / 750.5611 s
agent0:                 episode reward: -0.0753,                 loss: nan
agent1:                 episode reward: 0.0753,                 loss: 0.1861
Episode: 11641/30000 (38.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8293s / 752.3904 s
agent0:                 episode reward: -0.9443,                 loss: nan
agent1:                 episode reward: 0.9443,                 loss: 0.1854
Episode: 11661/30000 (38.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8340s / 754.2244 s
agent0:                 episode reward: -0.3149,                 loss: nan
agent1:                 episode reward: 0.3149,                 loss: 0.1847
Episode: 11681/30000 (38.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8317s / 756.0562 s
agent0:                 episode reward: -0.6080,                 loss: nan
agent1:                 episode reward: 0.6080,                 loss: 0.1555
Episode: 11701/30000 (39.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9114s / 757.9676 s
agent0:                 episode reward: -0.4405,                 loss: nan
agent1:                 episode reward: 0.4405,                 loss: 0.1441
Episode: 11721/30000 (39.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8284s / 759.7960 s
agent0:                 episode reward: -0.0578,                 loss: nan
agent1:                 episode reward: 0.0578,                 loss: 0.1418
Episode: 11741/30000 (39.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8307s / 761.6267 s
agent0:                 episode reward: -0.8309,                 loss: nan
agent1:                 episode reward: 0.8309,                 loss: 0.1422
Episode: 11761/30000 (39.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8429s / 763.4696 s
agent0:                 episode reward: -0.7737,                 loss: nan
agent1:                 episode reward: 0.7737,                 loss: 0.1403
Episode: 11781/30000 (39.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8262s / 765.2958 s
agent0:                 episode reward: -1.4023,                 loss: nan
agent1:                 episode reward: 1.4023,                 loss: 0.1538
Episode: 11801/30000 (39.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8724s / 767.1683 s
agent0:                 episode reward: -1.1012,                 loss: nan
agent1:                 episode reward: 1.1012,                 loss: 0.1525
Episode: 11821/30000 (39.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8715s / 769.0398 s
agent0:                 episode reward: -0.3558,                 loss: nan
agent1:                 episode reward: 0.3558,                 loss: 0.1532
Episode: 11841/30000 (39.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8154s / 770.8552 s
agent0:                 episode reward: -0.5952,                 loss: nan
agent1:                 episode reward: 0.5952,                 loss: 0.1523
Episode: 11861/30000 (39.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8406s / 772.6957 s
agent0:                 episode reward: -0.1220,                 loss: nan
agent1:                 episode reward: 0.1220,                 loss: 0.1516
Episode: 11881/30000 (39.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8423s / 774.5381 s
agent0:                 episode reward: -1.4323,                 loss: nan
agent1:                 episode reward: 1.4323,                 loss: 0.1887
Episode: 11901/30000 (39.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8363s / 776.3744 s
agent0:                 episode reward: -1.3128,                 loss: nan
agent1:                 episode reward: 1.3128,                 loss: 0.1867
Episode: 11921/30000 (39.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8477s / 778.2221 s
agent0:                 episode reward: -0.5667,                 loss: nan
agent1:                 episode reward: 0.5667,                 loss: 0.1863
Episode: 11941/30000 (39.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8658s / 780.0879 s
agent0:                 episode reward: -0.8980,                 loss: nan
agent1:                 episode reward: 0.8980,                 loss: 0.1860
Episode: 11961/30000 (39.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8363s / 781.9242 s
agent0:                 episode reward: -0.4529,                 loss: nan
agent1:                 episode reward: 0.4529,                 loss: 0.1859
Episode: 11981/30000 (39.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8475s / 783.7718 s
agent0:                 episode reward: -1.0419,                 loss: nan
agent1:                 episode reward: 1.0419,                 loss: 0.1708
Episode: 12001/30000 (40.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8183s / 785.5901 s
agent0:                 episode reward: -0.3434,                 loss: nan
agent1:                 episode reward: 0.3434,                 loss: 0.1586
Episode: 12021/30000 (40.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8368s / 787.4269 s
agent0:                 episode reward: -1.3070,                 loss: nan
agent1:                 episode reward: 1.3070,                 loss: 0.1594
Episode: 12041/30000 (40.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8627s / 789.2896 s
agent0:                 episode reward: -0.6410,                 loss: nan
agent1:                 episode reward: 0.6410,                 loss: 0.1586
Episode: 12061/30000 (40.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8594s / 791.1490 s
agent0:                 episode reward: -1.2541,                 loss: nan
agent1:                 episode reward: 1.2541,                 loss: 0.1582
Episode: 12081/30000 (40.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8351s / 792.9842 s
agent0:                 episode reward: -0.9688,                 loss: nan
agent1:                 episode reward: 0.9688,                 loss: 0.1452
Episode: 12101/30000 (40.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8294s / 794.8136 s
agent0:                 episode reward: -1.4918,                 loss: nan
agent1:                 episode reward: 1.4918,                 loss: 0.1373
Episode: 12121/30000 (40.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8349s / 796.6484 s
agent0:                 episode reward: -0.7198,                 loss: nan
agent1:                 episode reward: 0.7198,                 loss: 0.1343
Episode: 12141/30000 (40.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8220s / 798.4704 s
agent0:                 episode reward: -0.7491,                 loss: nan
agent1:                 episode reward: 0.7491,                 loss: 0.1343
Episode: 12161/30000 (40.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8904s / 800.3608 s
agent0:                 episode reward: -0.5972,                 loss: nan
agent1:                 episode reward: 0.5972,                 loss: 0.1356
Episode: 12181/30000 (40.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8412s / 802.2019 s
agent0:                 episode reward: -0.7985,                 loss: nan
agent1:                 episode reward: 0.7985,                 loss: 0.1486
Episode: 12201/30000 (40.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8290s / 804.0309 s
agent0:                 episode reward: -0.2087,                 loss: nan
agent1:                 episode reward: 0.2087,                 loss: 0.1442
Episode: 12221/30000 (40.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8465s / 805.8774 s
agent0:                 episode reward: -0.7647,                 loss: nan
agent1:                 episode reward: 0.7647,                 loss: 0.1439
Episode: 12241/30000 (40.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8266s / 807.7040 s
agent0:                 episode reward: -0.2334,                 loss: nan
agent1:                 episode reward: 0.2334,                 loss: 0.1443
Episode: 12261/30000 (40.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8901s / 809.5942 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.1417
Episode: 12281/30000 (40.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8420s / 811.4361 s
agent0:                 episode reward: -0.0650,                 loss: nan
agent1:                 episode reward: 0.0650,                 loss: 0.2019
Episode: 12301/30000 (41.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8205s / 813.2566 s
agent0:                 episode reward: -0.4243,                 loss: nan
agent1:                 episode reward: 0.4243,                 loss: 0.2050
Episode: 12321/30000 (41.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8535s / 815.1101 s
agent0:                 episode reward: -1.2636,                 loss: nan
agent1:                 episode reward: 1.2636,                 loss: 0.2071
Episode: 12341/30000 (41.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8360s / 816.9461 s
agent0:                 episode reward: -0.7667,                 loss: nan
agent1:                 episode reward: 0.7667,                 loss: 0.2070
Episode: 12361/30000 (41.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8550s / 818.8011 s
agent0:                 episode reward: -1.0266,                 loss: nan
agent1:                 episode reward: 1.0266,                 loss: 0.2052
Episode: 12381/30000 (41.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8785s / 820.6796 s
agent0:                 episode reward: -1.1383,                 loss: nan
agent1:                 episode reward: 1.1383,                 loss: 0.2589
Episode: 12401/30000 (41.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8337s / 822.5134 s
agent0:                 episode reward: -0.4932,                 loss: nan
agent1:                 episode reward: 0.4932,                 loss: 0.2575
Episode: 12421/30000 (41.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8351s / 824.3484 s
agent0:                 episode reward: -1.3361,                 loss: nan
agent1:                 episode reward: 1.3361,                 loss: 0.2559
Episode: 12441/30000 (41.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8505s / 826.1989 s
agent0:                 episode reward: -0.6217,                 loss: nan
agent1:                 episode reward: 0.6217,                 loss: 0.2562
Episode: 12461/30000 (41.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8397s / 828.0387 s
agent0:                 episode reward: -0.1607,                 loss: nan
agent1:                 episode reward: 0.1607,                 loss: 0.2597
Episode: 12481/30000 (41.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8773s / 829.9159 s
agent0:                 episode reward: -0.5696,                 loss: nan
agent1:                 episode reward: 0.5696,                 loss: 0.2037
Episode: 12501/30000 (41.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8197s / 831.7357 s
agent0:                 episode reward: -1.0655,                 loss: nan
agent1:                 episode reward: 1.0655,                 loss: 0.1844
Episode: 12521/30000 (41.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8490s / 833.5846 s
agent0:                 episode reward: -0.3383,                 loss: nan
agent1:                 episode reward: 0.3383,                 loss: 0.1816
Episode: 12541/30000 (41.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8515s / 835.4362 s
agent0:                 episode reward: -1.2030,                 loss: nan
agent1:                 episode reward: 1.2030,                 loss: 0.1814
Episode: 12561/30000 (41.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8247s / 837.2609 s
agent0:                 episode reward: -1.4857,                 loss: nan
agent1:                 episode reward: 1.4857,                 loss: 0.1824
Episode: 12581/30000 (41.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8348s / 839.0957 s
agent0:                 episode reward: -0.2444,                 loss: nan
agent1:                 episode reward: 0.2444,                 loss: 0.1429
Episode: 12601/30000 (42.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8846s / 840.9803 s
agent0:                 episode reward: -0.6280,                 loss: nan
agent1:                 episode reward: 0.6280,                 loss: 0.1283
Episode: 12621/30000 (42.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8539s / 842.8341 s
agent0:                 episode reward: -0.3464,                 loss: nan
agent1:                 episode reward: 0.3464,                 loss: 0.1281
Episode: 12641/30000 (42.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8341s / 844.6682 s
agent0:                 episode reward: -0.8119,                 loss: nan
agent1:                 episode reward: 0.8119,                 loss: 0.1286
Episode: 12661/30000 (42.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8265s / 846.4947 s
agent0:                 episode reward: 0.5293,                 loss: nan
agent1:                 episode reward: -0.5293,                 loss: 0.1279
Episode: 12681/30000 (42.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8429s / 848.3376 s
agent0:                 episode reward: -0.7240,                 loss: nan
agent1:                 episode reward: 0.7240,                 loss: 0.1486
Episode: 12701/30000 (42.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8769s / 850.2145 s
agent0:                 episode reward: -0.8723,                 loss: nan
agent1:                 episode reward: 0.8723,                 loss: 0.1493
Episode: 12721/30000 (42.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8289s / 852.0433 s
agent0:                 episode reward: -0.7568,                 loss: nan
agent1:                 episode reward: 0.7568,                 loss: 0.1511
Episode: 12741/30000 (42.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8498s / 853.8931 s
agent0:                 episode reward: -0.4745,                 loss: nan
agent1:                 episode reward: 0.4745,                 loss: 0.1481
Episode: 12761/30000 (42.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8803s / 855.7734 s
agent0:                 episode reward: -1.9924,                 loss: nan
agent1:                 episode reward: 1.9924,                 loss: 0.1498
Episode: 12781/30000 (42.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8372s / 857.6106 s
agent0:                 episode reward: -0.8211,                 loss: nan
agent1:                 episode reward: 0.8211,                 loss: 0.1668
Episode: 12801/30000 (42.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8639s / 859.4745 s
agent0:                 episode reward: -1.2059,                 loss: nan
agent1:                 episode reward: 1.2059,                 loss: 0.1686
Episode: 12821/30000 (42.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8765s / 861.3510 s
agent0:                 episode reward: -1.1407,                 loss: nan
agent1:                 episode reward: 1.1407,                 loss: 0.1667
Episode: 12841/30000 (42.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8378s / 863.1888 s
agent0:                 episode reward: -0.6695,                 loss: nan
agent1:                 episode reward: 0.6695,                 loss: 0.1672
Episode: 12861/30000 (42.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8209s / 865.0097 s
agent0:                 episode reward: -0.5826,                 loss: nan
agent1:                 episode reward: 0.5826,                 loss: 0.1662
Episode: 12881/30000 (42.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8675s / 866.8772 s
agent0:                 episode reward: -0.4913,                 loss: nan
agent1:                 episode reward: 0.4913,                 loss: 0.1992
Episode: 12901/30000 (43.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8629s / 868.7400 s
agent0:                 episode reward: -0.3794,                 loss: nan
agent1:                 episode reward: 0.3794,                 loss: 0.2011
Episode: 12921/30000 (43.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8878s / 870.6278 s
agent0:                 episode reward: -0.1227,                 loss: nan
agent1:                 episode reward: 0.1227,                 loss: 0.2019
Episode: 12941/30000 (43.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8451s / 872.4729 s
agent0:                 episode reward: -0.4567,                 loss: nan
agent1:                 episode reward: 0.4567,                 loss: 0.2001
Episode: 12961/30000 (43.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8358s / 874.3087 s
agent0:                 episode reward: -1.0921,                 loss: nan
agent1:                 episode reward: 1.0921,                 loss: 0.2001
Episode: 12981/30000 (43.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8516s / 876.1603 s
agent0:                 episode reward: -1.0619,                 loss: nan
agent1:                 episode reward: 1.0619,                 loss: 0.1901
Episode: 13001/30000 (43.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8520s / 878.0123 s
agent0:                 episode reward: -0.1898,                 loss: nan
agent1:                 episode reward: 0.1898,                 loss: 0.1858
Episode: 13021/30000 (43.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8222s / 879.8344 s
agent0:                 episode reward: -1.0843,                 loss: nan
agent1:                 episode reward: 1.0843,                 loss: 0.1852
Episode: 13041/30000 (43.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9387s / 881.7731 s
agent0:                 episode reward: -0.9652,                 loss: nan
agent1:                 episode reward: 0.9652,                 loss: 0.1852
Episode: 13061/30000 (43.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8413s / 883.6144 s
agent0:                 episode reward: -0.3619,                 loss: nan
agent1:                 episode reward: 0.3619,                 loss: 0.1838
Episode: 13081/30000 (43.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8316s / 885.4459 s
agent0:                 episode reward: -0.2512,                 loss: nan
agent1:                 episode reward: 0.2512,                 loss: 0.1698
Episode: 13101/30000 (43.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8280s / 887.2739 s
agent0:                 episode reward: -0.7777,                 loss: nan
agent1:                 episode reward: 0.7777,                 loss: 0.1616
Episode: 13121/30000 (43.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8427s / 889.1166 s
agent0:                 episode reward: -1.2269,                 loss: nan
agent1:                 episode reward: 1.2269,                 loss: 0.1635
Episode: 13141/30000 (43.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9026s / 891.0192 s
agent0:                 episode reward: -0.2846,                 loss: nan
agent1:                 episode reward: 0.2846,                 loss: 0.1628
Episode: 13161/30000 (43.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8396s / 892.8588 s
agent0:                 episode reward: -0.7627,                 loss: nan
agent1:                 episode reward: 0.7627,                 loss: 0.1621
Episode: 13181/30000 (43.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8283s / 894.6871 s
agent0:                 episode reward: -1.6050,                 loss: nan
agent1:                 episode reward: 1.6050,                 loss: 0.2026
Episode: 13201/30000 (44.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8618s / 896.5489 s
agent0:                 episode reward: -0.5881,                 loss: nan
agent1:                 episode reward: 0.5881,                 loss: 0.2061
Episode: 13221/30000 (44.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8667s / 898.4156 s
agent0:                 episode reward: -0.4186,                 loss: nan
agent1:                 episode reward: 0.4186,                 loss: 0.2044
Episode: 13241/30000 (44.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8782s / 900.2938 s
agent0:                 episode reward: -0.1535,                 loss: nan
agent1:                 episode reward: 0.1535,                 loss: 0.2029
Episode: 13261/30000 (44.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8951s / 902.1889 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.2046
Episode: 13281/30000 (44.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8608s / 904.0497 s
agent0:                 episode reward: -1.0642,                 loss: nan
agent1:                 episode reward: 1.0642,                 loss: 0.2540
Episode: 13301/30000 (44.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8792s / 905.9289 s
agent0:                 episode reward: -0.3745,                 loss: nan
agent1:                 episode reward: 0.3745,                 loss: 0.2560
Episode: 13321/30000 (44.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8782s / 907.8071 s
agent0:                 episode reward: -0.5592,                 loss: nan
agent1:                 episode reward: 0.5592,                 loss: 0.2554
Episode: 13341/30000 (44.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8699s / 909.6769 s
agent0:                 episode reward: -1.4470,                 loss: nan
agent1:                 episode reward: 1.4470,                 loss: 0.2549
Episode: 13361/30000 (44.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9189s / 911.5959 s
agent0:                 episode reward: -0.8776,                 loss: nan
agent1:                 episode reward: 0.8776,                 loss: 0.2542
Episode: 13381/30000 (44.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8638s / 913.4597 s
agent0:                 episode reward: -1.2735,                 loss: nan
agent1:                 episode reward: 1.2735,                 loss: 0.2037
Episode: 13401/30000 (44.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8893s / 915.3489 s
agent0:                 episode reward: -0.1220,                 loss: nan
agent1:                 episode reward: 0.1220,                 loss: 0.1929
Episode: 13421/30000 (44.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8626s / 917.2116 s
agent0:                 episode reward: -0.3764,                 loss: nan
agent1:                 episode reward: 0.3764,                 loss: 0.1942
Episode: 13441/30000 (44.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8496s / 919.0612 s
agent0:                 episode reward: -0.7815,                 loss: nan
agent1:                 episode reward: 0.7815,                 loss: 0.1939
Episode: 13461/30000 (44.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8521s / 920.9133 s
agent0:                 episode reward: -0.8978,                 loss: nan
agent1:                 episode reward: 0.8978,                 loss: 0.1938
Episode: 13481/30000 (44.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8804s / 922.7936 s
agent0:                 episode reward: -0.8383,                 loss: nan
agent1:                 episode reward: 0.8383,                 loss: 0.1697
Episode: 13501/30000 (45.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8851s / 924.6787 s
agent0:                 episode reward: -1.5363,                 loss: nan
agent1:                 episode reward: 1.5363,                 loss: 0.1632
Episode: 13521/30000 (45.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8521s / 926.5308 s
agent0:                 episode reward: -0.4868,                 loss: nan
agent1:                 episode reward: 0.4868,                 loss: 0.1651
Episode: 13541/30000 (45.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8380s / 928.3689 s
agent0:                 episode reward: -0.7802,                 loss: nan
agent1:                 episode reward: 0.7802,                 loss: 0.1634
Episode: 13561/30000 (45.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8499s / 930.2188 s
agent0:                 episode reward: -0.9675,                 loss: nan
agent1:                 episode reward: 0.9675,                 loss: 0.1637
Episode: 13581/30000 (45.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8828s / 932.1016 s
agent0:                 episode reward: -1.1459,                 loss: nan
agent1:                 episode reward: 1.1459,                 loss: 0.1576
Episode: 13601/30000 (45.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8488s / 933.9504 s
agent0:                 episode reward: -0.9261,                 loss: nan
agent1:                 episode reward: 0.9261,                 loss: 0.1554
Episode: 13621/30000 (45.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8435s / 935.7939 s
agent0:                 episode reward: -1.5799,                 loss: nan
agent1:                 episode reward: 1.5799,                 loss: 0.1550
Episode: 13641/30000 (45.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8385s / 937.6324 s
agent0:                 episode reward: -0.1503,                 loss: nan
agent1:                 episode reward: 0.1503,                 loss: 0.1551
Episode: 13661/30000 (45.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8490s / 939.4814 s
agent0:                 episode reward: -1.3606,                 loss: nan
agent1:                 episode reward: 1.3606,                 loss: 0.1540
Episode: 13681/30000 (45.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8639s / 941.3453 s
agent0:                 episode reward: -1.2831,                 loss: nan
agent1:                 episode reward: 1.2831,                 loss: 0.1757
Episode: 13701/30000 (45.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8758s / 943.2212 s
agent0:                 episode reward: -0.9401,                 loss: nan
agent1:                 episode reward: 0.9401,                 loss: 0.1777
Episode: 13721/30000 (45.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8377s / 945.0589 s
agent0:                 episode reward: -0.8532,                 loss: nan
agent1:                 episode reward: 0.8532,                 loss: 0.1786
Episode: 13741/30000 (45.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8365s / 946.8954 s
agent0:                 episode reward: -0.8773,                 loss: nan
agent1:                 episode reward: 0.8773,                 loss: 0.1787
Episode: 13761/30000 (45.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8305s / 948.7259 s
agent0:                 episode reward: -0.7632,                 loss: nan
agent1:                 episode reward: 0.7632,                 loss: 0.1771
Episode: 13781/30000 (45.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8620s / 950.5879 s
agent0:                 episode reward: -1.6808,                 loss: nan
agent1:                 episode reward: 1.6808,                 loss: 0.1881
Episode: 13801/30000 (46.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8815s / 952.4693 s
agent0:                 episode reward: -0.4621,                 loss: nan
agent1:                 episode reward: 0.4621,                 loss: 0.1889
Episode: 13821/30000 (46.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8457s / 954.3151 s
agent0:                 episode reward: -1.2362,                 loss: nan
agent1:                 episode reward: 1.2362,                 loss: 0.1865
Episode: 13841/30000 (46.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8338s / 956.1488 s
agent0:                 episode reward: -0.4599,                 loss: nan
agent1:                 episode reward: 0.4599,                 loss: 0.1882
Episode: 13861/30000 (46.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8524s / 958.0012 s
agent0:                 episode reward: -1.1424,                 loss: nan
agent1:                 episode reward: 1.1424,                 loss: 0.1880
Episode: 13881/30000 (46.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8526s / 959.8538 s
agent0:                 episode reward: -1.1584,                 loss: nan
agent1:                 episode reward: 1.1584,                 loss: 0.1824
Episode: 13901/30000 (46.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8498s / 961.7037 s
agent0:                 episode reward: -1.5113,                 loss: nan
agent1:                 episode reward: 1.5113,                 loss: 0.1800
Episode: 13921/30000 (46.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8790s / 963.5826 s
agent0:                 episode reward: -0.1148,                 loss: nan
agent1:                 episode reward: 0.1148,                 loss: 0.1781
Episode: 13941/30000 (46.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8575s / 965.4402 s
agent0:                 episode reward: -0.7230,                 loss: nan
agent1:                 episode reward: 0.7230,                 loss: 0.1785
Episode: 13961/30000 (46.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8571s / 967.2972 s
agent0:                 episode reward: -1.0180,                 loss: nan
agent1:                 episode reward: 1.0180,                 loss: 0.1794
Episode: 13981/30000 (46.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8550s / 969.1522 s
agent0:                 episode reward: -0.5958,                 loss: nan
agent1:                 episode reward: 0.5958,                 loss: 0.1650
Episode: 14001/30000 (46.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8458s / 970.9981 s
agent0:                 episode reward: -0.7273,                 loss: nan
agent1:                 episode reward: 0.7273,                 loss: 0.1630
Episode: 14021/30000 (46.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8736s / 972.8717 s
agent0:                 episode reward: -1.1288,                 loss: nan
agent1:                 episode reward: 1.1288,                 loss: 0.1621
Episode: 14041/30000 (46.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8675s / 974.7392 s
agent0:                 episode reward: -1.1040,                 loss: nan
agent1:                 episode reward: 1.1040,                 loss: 0.1610
Episode: 14061/30000 (46.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8391s / 976.5783 s
agent0:                 episode reward: -1.3197,                 loss: nan
agent1:                 episode reward: 1.3197,                 loss: 0.1602
Episode: 14081/30000 (46.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8377s / 978.4160 s
agent0:                 episode reward: -1.0702,                 loss: nan
agent1:                 episode reward: 1.0702,                 loss: 0.1637
Episode: 14101/30000 (47.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8481s / 980.2641 s
agent0:                 episode reward: -1.0892,                 loss: nan
agent1:                 episode reward: 1.0892,                 loss: 0.1649
Episode: 14121/30000 (47.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8397s / 982.1037 s
agent0:                 episode reward: -1.1004,                 loss: nan
agent1:                 episode reward: 1.1004,                 loss: 0.1638
Episode: 14141/30000 (47.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9034s / 984.0071 s
agent0:                 episode reward: -1.5426,                 loss: nan
agent1:                 episode reward: 1.5426,                 loss: 0.1627
Episode: 14161/30000 (47.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8522s / 985.8593 s
agent0:                 episode reward: -1.1959,                 loss: nan
agent1:                 episode reward: 1.1959,                 loss: 0.1640
Episode: 14181/30000 (47.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8347s / 987.6941 s
agent0:                 episode reward: -1.4019,                 loss: nan
agent1:                 episode reward: 1.4019,                 loss: 0.2022
Episode: 14201/30000 (47.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8447s / 989.5387 s
agent0:                 episode reward: -0.1442,                 loss: nan
agent1:                 episode reward: 0.1442,                 loss: 0.2055
Episode: 14221/30000 (47.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8507s / 991.3894 s
agent0:                 episode reward: -0.5958,                 loss: nan
agent1:                 episode reward: 0.5958,                 loss: 0.2074
Episode: 14241/30000 (47.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8938s / 993.2832 s
agent0:                 episode reward: -0.9948,                 loss: nan
agent1:                 episode reward: 0.9948,                 loss: 0.2054
Episode: 14261/30000 (47.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8489s / 995.1321 s
agent0:                 episode reward: -0.9488,                 loss: nan
agent1:                 episode reward: 0.9488,                 loss: 0.2080
Episode: 14281/30000 (47.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8446s / 996.9767 s
agent0:                 episode reward: -0.3678,                 loss: nan
agent1:                 episode reward: 0.3678,                 loss: 0.2319
Episode: 14301/30000 (47.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8519s / 998.8286 s
agent0:                 episode reward: -1.1436,                 loss: nan
agent1:                 episode reward: 1.1436,                 loss: 0.2331
Episode: 14321/30000 (47.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8833s / 1000.7118 s
agent0:                 episode reward: -0.8314,                 loss: nan
agent1:                 episode reward: 0.8314,                 loss: 0.2318
Episode: 14341/30000 (47.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8382s / 1002.5501 s
agent0:                 episode reward: -0.3810,                 loss: nan
agent1:                 episode reward: 0.3810,                 loss: 0.2296
Episode: 14361/30000 (47.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8930s / 1004.4431 s
agent0:                 episode reward: -1.0938,                 loss: nan
agent1:                 episode reward: 1.0938,                 loss: 0.2304
Episode: 14381/30000 (47.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8387s / 1006.2818 s
agent0:                 episode reward: -0.4357,                 loss: nan
agent1:                 episode reward: 0.4357,                 loss: 0.2141
Episode: 14401/30000 (48.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8727s / 1008.1546 s
agent0:                 episode reward: -0.0201,                 loss: nan
agent1:                 episode reward: 0.0201,                 loss: 0.2057
Episode: 14421/30000 (48.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8553s / 1010.0098 s
agent0:                 episode reward: -1.0471,                 loss: nan
agent1:                 episode reward: 1.0471,                 loss: 0.2050
Episode: 14441/30000 (48.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8420s / 1011.8518 s
agent0:                 episode reward: -1.3607,                 loss: nan
agent1:                 episode reward: 1.3607,                 loss: 0.2042
Episode: 14461/30000 (48.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8919s / 1013.7437 s
agent0:                 episode reward: -0.8257,                 loss: nan
agent1:                 episode reward: 0.8257,                 loss: 0.2049
Episode: 14481/30000 (48.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8341s / 1015.5778 s
agent0:                 episode reward: -0.9986,                 loss: nan
agent1:                 episode reward: 0.9986,                 loss: 0.1660
Episode: 14501/30000 (48.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8573s / 1017.4351 s
agent0:                 episode reward: -1.2162,                 loss: nan
agent1:                 episode reward: 1.2162,                 loss: 0.1543
Episode: 14521/30000 (48.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8326s / 1019.2677 s
agent0:                 episode reward: -0.9619,                 loss: nan
agent1:                 episode reward: 0.9619,                 loss: 0.1530
Episode: 14541/30000 (48.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8486s / 1021.1163 s
agent0:                 episode reward: -1.0674,                 loss: nan
agent1:                 episode reward: 1.0674,                 loss: 0.1566
Episode: 14561/30000 (48.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8527s / 1022.9689 s
agent0:                 episode reward: -1.0015,                 loss: nan
agent1:                 episode reward: 1.0015,                 loss: 0.1563
Episode: 14581/30000 (48.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9123s / 1024.8813 s
agent0:                 episode reward: -1.2348,                 loss: nan
agent1:                 episode reward: 1.2348,                 loss: 0.1707
Episode: 14601/30000 (48.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8355s / 1026.7167 s
agent0:                 episode reward: -0.5680,                 loss: nan
agent1:                 episode reward: 0.5680,                 loss: 0.1694
Episode: 14621/30000 (48.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8484s / 1028.5651 s
agent0:                 episode reward: -0.8885,                 loss: nan
agent1:                 episode reward: 0.8885,                 loss: 0.1691
Episode: 14641/30000 (48.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8485s / 1030.4136 s
agent0:                 episode reward: -0.8012,                 loss: nan
agent1:                 episode reward: 0.8012,                 loss: 0.1690
Episode: 14661/30000 (48.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8657s / 1032.2793 s
agent0:                 episode reward: -1.3310,                 loss: nan
agent1:                 episode reward: 1.3310,                 loss: 0.1689
Episode: 14681/30000 (48.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9103s / 1034.1896 s
agent0:                 episode reward: -1.0269,                 loss: nan
agent1:                 episode reward: 1.0269,                 loss: 0.1872
Episode: 14701/30000 (49.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8524s / 1036.0420 s
agent0:                 episode reward: -1.5465,                 loss: nan
agent1:                 episode reward: 1.5465,                 loss: 0.1844
Episode: 14721/30000 (49.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8524s / 1037.8944 s
agent0:                 episode reward: -1.2662,                 loss: nan
agent1:                 episode reward: 1.2662,                 loss: 0.1858
Episode: 14741/30000 (49.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8494s / 1039.7438 s
agent0:                 episode reward: -1.0334,                 loss: nan
agent1:                 episode reward: 1.0334,                 loss: 0.1834
Episode: 14761/30000 (49.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8893s / 1041.6331 s
agent0:                 episode reward: -0.3624,                 loss: nan
agent1:                 episode reward: 0.3624,                 loss: 0.1852
Episode: 14781/30000 (49.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8558s / 1043.4889 s
agent0:                 episode reward: -0.9113,                 loss: nan
agent1:                 episode reward: 0.9113,                 loss: 0.2156
Episode: 14801/30000 (49.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9370s / 1045.4259 s
agent0:                 episode reward: -1.1494,                 loss: nan
agent1:                 episode reward: 1.1494,                 loss: 0.2171
Episode: 14821/30000 (49.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8453s / 1047.2711 s
agent0:                 episode reward: -0.9254,                 loss: nan
agent1:                 episode reward: 0.9254,                 loss: 0.2174
Episode: 14841/30000 (49.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8648s / 1049.1359 s
agent0:                 episode reward: -1.0248,                 loss: nan
agent1:                 episode reward: 1.0248,                 loss: 0.2168
Episode: 14861/30000 (49.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8540s / 1050.9900 s
agent0:                 episode reward: -0.7740,                 loss: nan
agent1:                 episode reward: 0.7740,                 loss: 0.2183
Episode: 14881/30000 (49.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8580s / 1052.8479 s
agent0:                 episode reward: -1.3522,                 loss: nan
agent1:                 episode reward: 1.3522,                 loss: 0.2104
Episode: 14901/30000 (49.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8908s / 1054.7387 s
agent0:                 episode reward: -0.6876,                 loss: nan
agent1:                 episode reward: 0.6876,                 loss: 0.2009
Episode: 14921/30000 (49.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8476s / 1056.5864 s
agent0:                 episode reward: -1.7001,                 loss: nan
agent1:                 episode reward: 1.7001,                 loss: 0.2003
Episode: 14941/30000 (49.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8860s / 1058.4724 s
agent0:                 episode reward: -0.9143,                 loss: nan
agent1:                 episode reward: 0.9143,                 loss: 0.2003
Episode: 14961/30000 (49.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8477s / 1060.3201 s
agent0:                 episode reward: -1.3288,                 loss: nan
agent1:                 episode reward: 1.3288,                 loss: 0.1996
Episode: 14981/30000 (49.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8746s / 1062.1947 s
agent0:                 episode reward: -1.1252,                 loss: nan
agent1:                 episode reward: 1.1252,                 loss: 0.1926
Episode: 15001/30000 (50.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8647s / 1064.0594 s
agent0:                 episode reward: -0.7709,                 loss: nan
agent1:                 episode reward: 0.7709,                 loss: 0.1830
Episode: 15021/30000 (50.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9111s / 1065.9705 s
agent0:                 episode reward: -1.0677,                 loss: nan
agent1:                 episode reward: 1.0677,                 loss: 0.1798
Episode: 15041/30000 (50.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8557s / 1067.8262 s
agent0:                 episode reward: -0.8805,                 loss: nan
agent1:                 episode reward: 0.8805,                 loss: 0.1779
Episode: 15061/30000 (50.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8369s / 1069.6630 s
agent0:                 episode reward: -0.6899,                 loss: nan
agent1:                 episode reward: 0.6899,                 loss: 0.1787
Episode: 15081/30000 (50.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8637s / 1071.5267 s
agent0:                 episode reward: -0.8691,                 loss: nan
agent1:                 episode reward: 0.8691,                 loss: 0.2429
Episode: 15101/30000 (50.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8466s / 1073.3734 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.2448
Episode: 15121/30000 (50.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8917s / 1075.2651 s
agent0:                 episode reward: -2.1765,                 loss: nan
agent1:                 episode reward: 2.1765,                 loss: 0.2469
Episode: 15141/30000 (50.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8673s / 1077.1323 s
agent0:                 episode reward: -1.3060,                 loss: nan
agent1:                 episode reward: 1.3060,                 loss: 0.2448
Episode: 15161/30000 (50.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8522s / 1078.9845 s
agent0:                 episode reward: -1.2640,                 loss: nan
agent1:                 episode reward: 1.2640,                 loss: 0.2419
Episode: 15181/30000 (50.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8595s / 1080.8441 s
agent0:                 episode reward: -0.9995,                 loss: nan
agent1:                 episode reward: 0.9995,                 loss: 0.2042
Episode: 15201/30000 (50.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8688s / 1082.7128 s
agent0:                 episode reward: -1.2186,                 loss: nan
agent1:                 episode reward: 1.2186,                 loss: 0.1924
Episode: 15221/30000 (50.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8405s / 1084.5534 s
agent0:                 episode reward: -0.5730,                 loss: nan
agent1:                 episode reward: 0.5730,                 loss: 0.1895
Episode: 15241/30000 (50.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9006s / 1086.4540 s
agent0:                 episode reward: -0.7698,                 loss: nan
agent1:                 episode reward: 0.7698,                 loss: 0.1883
Episode: 15261/30000 (50.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8584s / 1088.3124 s
agent0:                 episode reward: -0.4312,                 loss: nan
agent1:                 episode reward: 0.4312,                 loss: 0.1887
Episode: 15281/30000 (50.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8379s / 1090.1502 s
agent0:                 episode reward: -1.4406,                 loss: nan
agent1:                 episode reward: 1.4406,                 loss: 0.1642
Episode: 15301/30000 (51.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8876s / 1092.0378 s
agent0:                 episode reward: -0.8369,                 loss: nan
agent1:                 episode reward: 0.8369,                 loss: 0.1529
Episode: 15321/30000 (51.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8458s / 1093.8836 s
agent0:                 episode reward: -1.5855,                 loss: nan
agent1:                 episode reward: 1.5855,                 loss: 0.1521
Episode: 15341/30000 (51.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8972s / 1095.7808 s
agent0:                 episode reward: -0.6512,                 loss: nan
agent1:                 episode reward: 0.6512,                 loss: 0.1541
Episode: 15361/30000 (51.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8802s / 1097.6610 s
agent0:                 episode reward: -1.0967,                 loss: nan
agent1:                 episode reward: 1.0967,                 loss: 0.1520
Episode: 15381/30000 (51.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8556s / 1099.5166 s
agent0:                 episode reward: -1.0939,                 loss: nan
agent1:                 episode reward: 1.0939,                 loss: 0.1341
Episode: 15401/30000 (51.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8535s / 1101.3701 s
agent0:                 episode reward: -1.1921,                 loss: nan
agent1:                 episode reward: 1.1921,                 loss: 0.1260
Episode: 15421/30000 (51.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8545s / 1103.2246 s
agent0:                 episode reward: -1.9235,                 loss: nan
agent1:                 episode reward: 1.9235,                 loss: 0.1260
Episode: 15441/30000 (51.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8478s / 1105.0724 s
agent0:                 episode reward: -1.1398,                 loss: nan
agent1:                 episode reward: 1.1398,                 loss: 0.1279
Episode: 15461/30000 (51.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9039s / 1106.9763 s
agent0:                 episode reward: -1.2939,                 loss: nan
agent1:                 episode reward: 1.2939,                 loss: 0.1259
Episode: 15481/30000 (51.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8593s / 1108.8357 s
agent0:                 episode reward: -1.2748,                 loss: nan
agent1:                 episode reward: 1.2748,                 loss: 0.1500
Episode: 15501/30000 (51.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8525s / 1110.6881 s
agent0:                 episode reward: -0.8430,                 loss: nan
agent1:                 episode reward: 0.8430,                 loss: 0.1501
Episode: 15521/30000 (51.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8525s / 1112.5406 s
agent0:                 episode reward: -0.9393,                 loss: nan
agent1:                 episode reward: 0.9393,                 loss: 0.1506
Episode: 15541/30000 (51.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8426s / 1114.3832 s
agent0:                 episode reward: -1.7856,                 loss: nan
agent1:                 episode reward: 1.7856,                 loss: 0.1490
Episode: 15561/30000 (51.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9027s / 1116.2859 s
agent0:                 episode reward: -1.8233,                 loss: nan
agent1:                 episode reward: 1.8233,                 loss: 0.1511
Episode: 15581/30000 (51.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8400s / 1118.1259 s
agent0:                 episode reward: -1.2090,                 loss: nan
agent1:                 episode reward: 1.2090,                 loss: 0.1968
Episode: 15601/30000 (52.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8439s / 1119.9698 s
agent0:                 episode reward: -0.6587,                 loss: nan
agent1:                 episode reward: 0.6587,                 loss: 0.2008
Episode: 15621/30000 (52.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8785s / 1121.8482 s
agent0:                 episode reward: -1.1402,                 loss: nan
agent1:                 episode reward: 1.1402,                 loss: 0.1993
Episode: 15641/30000 (52.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8696s / 1123.7179 s
agent0:                 episode reward: -1.4040,                 loss: nan
agent1:                 episode reward: 1.4040,                 loss: 0.1994
Episode: 15661/30000 (52.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8615s / 1125.5794 s
agent0:                 episode reward: -1.3482,                 loss: nan
agent1:                 episode reward: 1.3482,                 loss: 0.2009
Episode: 15681/30000 (52.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8990s / 1127.4783 s
agent0:                 episode reward: -1.2099,                 loss: nan
agent1:                 episode reward: 1.2099,                 loss: 0.2396
Episode: 15701/30000 (52.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8494s / 1129.3277 s
agent0:                 episode reward: -1.7168,                 loss: nan
agent1:                 episode reward: 1.7168,                 loss: 0.2382
Episode: 15721/30000 (52.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8469s / 1131.1747 s
agent0:                 episode reward: -1.5712,                 loss: nan
agent1:                 episode reward: 1.5712,                 loss: 0.2391
Episode: 15741/30000 (52.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8582s / 1133.0329 s
agent0:                 episode reward: -0.8104,                 loss: nan
agent1:                 episode reward: 0.8104,                 loss: 0.2354
Episode: 15761/30000 (52.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8560s / 1134.8889 s
agent0:                 episode reward: -0.6447,                 loss: nan
agent1:                 episode reward: 0.6447,                 loss: 0.2375
Episode: 15781/30000 (52.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8853s / 1136.7741 s
agent0:                 episode reward: -0.8483,                 loss: nan
agent1:                 episode reward: 0.8483,                 loss: 0.2330
Episode: 15801/30000 (52.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8491s / 1138.6232 s
agent0:                 episode reward: -0.9201,                 loss: nan
agent1:                 episode reward: 0.9201,                 loss: 0.2300
Episode: 15821/30000 (52.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8698s / 1140.4930 s
agent0:                 episode reward: -1.6024,                 loss: nan
agent1:                 episode reward: 1.6024,                 loss: 0.2284
Episode: 15841/30000 (52.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8830s / 1142.3760 s
agent0:                 episode reward: -1.4178,                 loss: nan
agent1:                 episode reward: 1.4178,                 loss: 0.2263
Episode: 15861/30000 (52.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8414s / 1144.2174 s
agent0:                 episode reward: -0.6150,                 loss: nan
agent1:                 episode reward: 0.6150,                 loss: 0.2256
Episode: 15881/30000 (52.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8663s / 1146.0837 s
agent0:                 episode reward: -0.3357,                 loss: nan
agent1:                 episode reward: 0.3357,                 loss: 0.1912
Episode: 15901/30000 (53.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8862s / 1147.9699 s
agent0:                 episode reward: -1.1539,                 loss: nan
agent1:                 episode reward: 1.1539,                 loss: 0.1790
Episode: 15921/30000 (53.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8733s / 1149.8432 s
agent0:                 episode reward: -1.7343,                 loss: nan
agent1:                 episode reward: 1.7343,                 loss: 0.1792
Episode: 15941/30000 (53.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8568s / 1151.7000 s
agent0:                 episode reward: -0.8392,                 loss: nan
agent1:                 episode reward: 0.8392,                 loss: 0.1777
Episode: 15961/30000 (53.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8439s / 1153.5440 s
agent0:                 episode reward: -1.3483,                 loss: nan
agent1:                 episode reward: 1.3483,                 loss: 0.1778
Episode: 15981/30000 (53.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8491s / 1155.3931 s
agent0:                 episode reward: -1.4708,                 loss: nan
agent1:                 episode reward: 1.4708,                 loss: 0.2127
Episode: 16001/30000 (53.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9078s / 1157.3009 s
agent0:                 episode reward: -1.0396,                 loss: nan
agent1:                 episode reward: 1.0396,                 loss: 0.2183
Episode: 16021/30000 (53.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8425s / 1159.1434 s
agent0:                 episode reward: -1.5916,                 loss: nan
agent1:                 episode reward: 1.5916,                 loss: 0.2180
Episode: 16041/30000 (53.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8631s / 1161.0065 s
agent0:                 episode reward: -0.2012,                 loss: nan
agent1:                 episode reward: 0.2012,                 loss: 0.2189
Episode: 16061/30000 (53.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8526s / 1162.8591 s
agent0:                 episode reward: -1.9903,                 loss: nan
agent1:                 episode reward: 1.9903,                 loss: 0.2172
Episode: 16081/30000 (53.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8472s / 1164.7063 s
agent0:                 episode reward: -1.8747,                 loss: nan
agent1:                 episode reward: 1.8747,                 loss: 0.2317
Episode: 16101/30000 (53.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8611s / 1166.5674 s
agent0:                 episode reward: -0.6084,                 loss: nan
agent1:                 episode reward: 0.6084,                 loss: 0.2290
Episode: 16121/30000 (53.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8886s / 1168.4560 s
agent0:                 episode reward: -1.1621,                 loss: nan
agent1:                 episode reward: 1.1621,                 loss: 0.2286
Episode: 16141/30000 (53.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8567s / 1170.3127 s
agent0:                 episode reward: -0.9535,                 loss: nan
agent1:                 episode reward: 0.9535,                 loss: 0.2291
Episode: 16161/30000 (53.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8530s / 1172.1657 s
agent0:                 episode reward: -0.7842,                 loss: nan
agent1:                 episode reward: 0.7842,                 loss: 0.2267
Episode: 16181/30000 (53.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8569s / 1174.0226 s
agent0:                 episode reward: -1.1015,                 loss: nan
agent1:                 episode reward: 1.1015,                 loss: 0.2066
Episode: 16201/30000 (54.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8749s / 1175.8975 s
agent0:                 episode reward: -1.0959,                 loss: nan
agent1:                 episode reward: 1.0959,                 loss: 0.1999
Episode: 16221/30000 (54.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8882s / 1177.7857 s
agent0:                 episode reward: -1.1303,                 loss: nan
agent1:                 episode reward: 1.1303,                 loss: 0.2003
Episode: 16241/30000 (54.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8599s / 1179.6456 s
agent0:                 episode reward: -0.5831,                 loss: nan
agent1:                 episode reward: 0.5831,                 loss: 0.1998
Episode: 16261/30000 (54.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8582s / 1181.5038 s
agent0:                 episode reward: -1.4556,                 loss: nan
agent1:                 episode reward: 1.4556,                 loss: 0.2003
Episode: 16281/30000 (54.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8797s / 1183.3834 s
agent0:                 episode reward: -0.8545,                 loss: nan
agent1:                 episode reward: 0.8545,                 loss: 0.1804
Episode: 16301/30000 (54.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8568s / 1185.2402 s
agent0:                 episode reward: -0.9740,                 loss: nan
agent1:                 episode reward: 0.9740,                 loss: 0.1740
Episode: 16321/30000 (54.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8444s / 1187.0846 s
agent0:                 episode reward: -0.9478,                 loss: nan
agent1:                 episode reward: 0.9478,                 loss: 0.1739
Episode: 16341/30000 (54.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8979s / 1188.9826 s
agent0:                 episode reward: -1.4208,                 loss: nan
agent1:                 episode reward: 1.4208,                 loss: 0.1728
Episode: 16361/30000 (54.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8904s / 1190.8730 s
agent0:                 episode reward: -1.2332,                 loss: nan
agent1:                 episode reward: 1.2332,                 loss: 0.1747
Episode: 16381/30000 (54.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8537s / 1192.7267 s
agent0:                 episode reward: -1.5754,                 loss: nan
agent1:                 episode reward: 1.5754,                 loss: 0.1744
Episode: 16401/30000 (54.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8632s / 1194.5899 s
agent0:                 episode reward: -1.5367,                 loss: nan
agent1:                 episode reward: 1.5367,                 loss: 0.1712
Episode: 16421/30000 (54.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8545s / 1196.4445 s
agent0:                 episode reward: -1.4734,                 loss: nan
agent1:                 episode reward: 1.4734,                 loss: 0.1708
Episode: 16441/30000 (54.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8919s / 1198.3363 s
agent0:                 episode reward: -1.3893,                 loss: nan
agent1:                 episode reward: 1.3893,                 loss: 0.1719
Episode: 16461/30000 (54.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8817s / 1200.2180 s
agent0:                 episode reward: -2.3383,                 loss: nan
agent1:                 episode reward: 2.3383,                 loss: 0.1714
Episode: 16481/30000 (54.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8635s / 1202.0815 s
agent0:                 episode reward: -1.2251,                 loss: nan
agent1:                 episode reward: 1.2251,                 loss: 0.2063
Episode: 16501/30000 (55.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8562s / 1203.9377 s
agent0:                 episode reward: -0.6691,                 loss: nan
agent1:                 episode reward: 0.6691,                 loss: 0.2067
Episode: 16521/30000 (55.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8569s / 1205.7946 s
agent0:                 episode reward: -0.8257,                 loss: nan
agent1:                 episode reward: 0.8257,                 loss: 0.2066
Episode: 16541/30000 (55.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8630s / 1207.6576 s
agent0:                 episode reward: -1.3792,                 loss: nan
agent1:                 episode reward: 1.3792,                 loss: 0.2043
Episode: 16561/30000 (55.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8993s / 1209.5569 s
agent0:                 episode reward: -0.8064,                 loss: nan
agent1:                 episode reward: 0.8064,                 loss: 0.2067
Episode: 16581/30000 (55.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8725s / 1211.4294 s
agent0:                 episode reward: -0.4819,                 loss: nan
agent1:                 episode reward: 0.4819,                 loss: 0.2383
Episode: 16601/30000 (55.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8589s / 1213.2883 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.2394
Episode: 16621/30000 (55.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8774s / 1215.1657 s
agent0:                 episode reward: -1.0075,                 loss: nan
agent1:                 episode reward: 1.0075,                 loss: 0.2396
Episode: 16641/30000 (55.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8728s / 1217.0385 s
agent0:                 episode reward: -1.0645,                 loss: nan
agent1:                 episode reward: 1.0645,                 loss: 0.2358
Episode: 16661/30000 (55.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9114s / 1218.9499 s
agent0:                 episode reward: -0.7769,                 loss: nan
agent1:                 episode reward: 0.7769,                 loss: 0.2384
Episode: 16681/30000 (55.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8620s / 1220.8119 s
agent0:                 episode reward: -1.6123,                 loss: nan
agent1:                 episode reward: 1.6123,                 loss: 0.2454
Episode: 16701/30000 (55.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8575s / 1222.6694 s
agent0:                 episode reward: -0.9667,                 loss: nan
agent1:                 episode reward: 0.9667,                 loss: 0.2378
Episode: 16721/30000 (55.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8707s / 1224.5401 s
agent0:                 episode reward: -1.2815,                 loss: nan
agent1:                 episode reward: 1.2815,                 loss: 0.2381
Episode: 16741/30000 (55.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8645s / 1226.4046 s
agent0:                 episode reward: -0.6785,                 loss: nan
agent1:                 episode reward: 0.6785,                 loss: 0.2383
Episode: 16761/30000 (55.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8444s / 1228.2491 s
agent0:                 episode reward: -0.5758,                 loss: nan
agent1:                 episode reward: 0.5758,                 loss: 0.2388
Episode: 16781/30000 (55.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9204s / 1230.1695 s
agent0:                 episode reward: -1.6270,                 loss: nan
agent1:                 episode reward: 1.6270,                 loss: 0.2015
Episode: 16801/30000 (56.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8656s / 1232.0351 s
agent0:                 episode reward: -1.2454,                 loss: nan
agent1:                 episode reward: 1.2454,                 loss: 0.1886
Episode: 16821/30000 (56.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8860s / 1233.9211 s
agent0:                 episode reward: -1.4560,                 loss: nan
agent1:                 episode reward: 1.4560,                 loss: 0.1892
Episode: 16841/30000 (56.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8837s / 1235.8049 s
agent0:                 episode reward: -0.7338,                 loss: nan
agent1:                 episode reward: 0.7338,                 loss: 0.1871
Episode: 16861/30000 (56.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8796s / 1237.6844 s
agent0:                 episode reward: -0.9723,                 loss: nan
agent1:                 episode reward: 0.9723,                 loss: 0.1868
Episode: 16881/30000 (56.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9162s / 1239.6006 s
agent0:                 episode reward: -1.8395,                 loss: nan
agent1:                 episode reward: 1.8395,                 loss: 0.2035
Episode: 16901/30000 (56.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8851s / 1241.4857 s
agent0:                 episode reward: -1.4327,                 loss: nan
agent1:                 episode reward: 1.4327,                 loss: 0.1957
Episode: 16921/30000 (56.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8742s / 1243.3599 s
agent0:                 episode reward: -1.5001,                 loss: nan
agent1:                 episode reward: 1.5001,                 loss: 0.1989
Episode: 16941/30000 (56.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8695s / 1245.2294 s
agent0:                 episode reward: -0.8540,                 loss: nan
agent1:                 episode reward: 0.8540,                 loss: 0.1987
Episode: 16961/30000 (56.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8603s / 1247.0897 s
agent0:                 episode reward: -0.9293,                 loss: nan
agent1:                 episode reward: 0.9293,                 loss: 0.1980
Episode: 16981/30000 (56.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9002s / 1248.9899 s
agent0:                 episode reward: -1.5954,                 loss: nan
agent1:                 episode reward: 1.5954,                 loss: 0.2292
Episode: 17001/30000 (56.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9123s / 1250.9021 s
agent0:                 episode reward: -1.3468,                 loss: nan
agent1:                 episode reward: 1.3468,                 loss: 0.2254
Episode: 17021/30000 (56.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8697s / 1252.7718 s
agent0:                 episode reward: -0.7588,                 loss: nan
agent1:                 episode reward: 0.7588,                 loss: 0.2266
Episode: 17041/30000 (56.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8781s / 1254.6499 s
agent0:                 episode reward: -0.5294,                 loss: nan
agent1:                 episode reward: 0.5294,                 loss: 0.2258
Episode: 17061/30000 (56.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8785s / 1256.5285 s
agent0:                 episode reward: -1.0566,                 loss: nan
agent1:                 episode reward: 1.0566,                 loss: 0.2289
Episode: 17081/30000 (56.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8888s / 1258.4173 s
agent0:                 episode reward: -0.7838,                 loss: nan
agent1:                 episode reward: 0.7838,                 loss: 0.2422
Episode: 17101/30000 (57.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9108s / 1260.3281 s
agent0:                 episode reward: -1.4264,                 loss: nan
agent1:                 episode reward: 1.4264,                 loss: 0.2376
Episode: 17121/30000 (57.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8631s / 1262.1912 s
agent0:                 episode reward: -1.1583,                 loss: nan
agent1:                 episode reward: 1.1583,                 loss: 0.2356
Episode: 17141/30000 (57.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8885s / 1264.0797 s
agent0:                 episode reward: -0.2203,                 loss: nan
agent1:                 episode reward: 0.2203,                 loss: 0.2367
Episode: 17161/30000 (57.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8940s / 1265.9737 s
agent0:                 episode reward: -0.6738,                 loss: nan
agent1:                 episode reward: 0.6738,                 loss: 0.2365
Episode: 17181/30000 (57.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8690s / 1267.8427 s
agent0:                 episode reward: -1.2589,                 loss: nan
agent1:                 episode reward: 1.2589,                 loss: 0.2153
Episode: 17201/30000 (57.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9503s / 1269.7930 s
agent0:                 episode reward: -1.1471,                 loss: nan
agent1:                 episode reward: 1.1471,                 loss: 0.2066
Episode: 17221/30000 (57.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8707s / 1271.6637 s
agent0:                 episode reward: -1.3463,                 loss: nan
agent1:                 episode reward: 1.3463,                 loss: 0.2060
Episode: 17241/30000 (57.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8847s / 1273.5484 s
agent0:                 episode reward: -0.8857,                 loss: nan
agent1:                 episode reward: 0.8857,                 loss: 0.2052
Episode: 17261/30000 (57.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8774s / 1275.4258 s
agent0:                 episode reward: -1.4484,                 loss: nan
agent1:                 episode reward: 1.4484,                 loss: 0.2065
Episode: 17281/30000 (57.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8651s / 1277.2909 s
agent0:                 episode reward: -0.9630,                 loss: nan
agent1:                 episode reward: 0.9630,                 loss: 0.2030
Episode: 17301/30000 (57.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8990s / 1279.1899 s
agent0:                 episode reward: -2.1008,                 loss: nan
agent1:                 episode reward: 2.1008,                 loss: 0.1939
Episode: 17321/30000 (57.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9105s / 1281.1004 s
agent0:                 episode reward: -2.5258,                 loss: nan
agent1:                 episode reward: 2.5258,                 loss: 0.1931
Episode: 17341/30000 (57.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8837s / 1282.9841 s
agent0:                 episode reward: -0.4826,                 loss: nan
agent1:                 episode reward: 0.4826,                 loss: 0.1924
Episode: 17361/30000 (57.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8884s / 1284.8725 s
agent0:                 episode reward: -1.1805,                 loss: nan
agent1:                 episode reward: 1.1805,                 loss: 0.1922
Episode: 17381/30000 (57.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8671s / 1286.7397 s
agent0:                 episode reward: -0.5493,                 loss: nan
agent1:                 episode reward: 0.5493,                 loss: 0.2235
Episode: 17401/30000 (58.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8574s / 1288.5971 s
agent0:                 episode reward: -1.0172,                 loss: nan
agent1:                 episode reward: 1.0172,                 loss: 0.2266
Episode: 17421/30000 (58.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9153s / 1290.5124 s
agent0:                 episode reward: -1.2926,                 loss: nan
agent1:                 episode reward: 1.2926,                 loss: 0.2264
Episode: 17441/30000 (58.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8808s / 1292.3932 s
agent0:                 episode reward: -1.6193,                 loss: nan
agent1:                 episode reward: 1.6193,                 loss: 0.2252
Episode: 17461/30000 (58.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8987s / 1294.2919 s
agent0:                 episode reward: -1.5505,                 loss: nan
agent1:                 episode reward: 1.5505,                 loss: 0.2270
Episode: 17481/30000 (58.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8817s / 1296.1736 s
agent0:                 episode reward: -1.7217,                 loss: nan
agent1:                 episode reward: 1.7217,                 loss: 0.2181
Episode: 17501/30000 (58.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8608s / 1298.0344 s
agent0:                 episode reward: -1.4188,                 loss: nan
agent1:                 episode reward: 1.4188,                 loss: 0.2133
Episode: 17521/30000 (58.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8998s / 1299.9342 s
agent0:                 episode reward: -2.0847,                 loss: nan
agent1:                 episode reward: 2.0847,                 loss: 0.2120
Episode: 17541/30000 (58.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9111s / 1301.8453 s
agent0:                 episode reward: -1.6519,                 loss: nan
agent1:                 episode reward: 1.6519,                 loss: 0.2138
Episode: 17561/30000 (58.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8743s / 1303.7196 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.2149
Episode: 17581/30000 (58.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8846s / 1305.6042 s
agent0:                 episode reward: -0.9404,                 loss: nan
agent1:                 episode reward: 0.9404,                 loss: 0.2039
Episode: 17601/30000 (58.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8947s / 1307.4988 s
agent0:                 episode reward: -1.3123,                 loss: nan
agent1:                 episode reward: 1.3123,                 loss: 0.1986
Episode: 17621/30000 (58.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8882s / 1309.3870 s
agent0:                 episode reward: -1.2335,                 loss: nan
agent1:                 episode reward: 1.2335,                 loss: 0.1975
Episode: 17641/30000 (58.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9195s / 1311.3065 s
agent0:                 episode reward: -1.2164,                 loss: nan
agent1:                 episode reward: 1.2164,                 loss: 0.1992
Episode: 17661/30000 (58.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8794s / 1313.1859 s
agent0:                 episode reward: -1.3560,                 loss: nan
agent1:                 episode reward: 1.3560,                 loss: 0.2005
Episode: 17681/30000 (58.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9071s / 1315.0930 s
agent0:                 episode reward: -1.1004,                 loss: nan
agent1:                 episode reward: 1.1004,                 loss: 0.1999
Episode: 17701/30000 (59.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8736s / 1316.9667 s
agent0:                 episode reward: -1.0974,                 loss: nan
agent1:                 episode reward: 1.0974,                 loss: 0.1953
Episode: 17721/30000 (59.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8777s / 1318.8443 s
agent0:                 episode reward: -1.0462,                 loss: nan
agent1:                 episode reward: 1.0462,                 loss: 0.1950
Episode: 17741/30000 (59.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8876s / 1320.7319 s
agent0:                 episode reward: -0.4188,                 loss: nan
agent1:                 episode reward: 0.4188,                 loss: 0.1946
Episode: 17761/30000 (59.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9369s / 1322.6687 s
agent0:                 episode reward: -1.2516,                 loss: nan
agent1:                 episode reward: 1.2516,                 loss: 0.1962
Episode: 17781/30000 (59.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9208s / 1324.5896 s
agent0:                 episode reward: -1.8360,                 loss: nan
agent1:                 episode reward: 1.8360,                 loss: 0.1936
Episode: 17801/30000 (59.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8883s / 1326.4778 s
agent0:                 episode reward: -1.2942,                 loss: nan
agent1:                 episode reward: 1.2942,                 loss: 0.1912
Episode: 17821/30000 (59.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8797s / 1328.3576 s
agent0:                 episode reward: -0.6241,                 loss: nan
agent1:                 episode reward: 0.6241,                 loss: 0.1904
Episode: 17841/30000 (59.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8816s / 1330.2392 s
agent0:                 episode reward: -1.0360,                 loss: nan
agent1:                 episode reward: 1.0360,                 loss: 0.1899
Episode: 17861/30000 (59.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9352s / 1332.1744 s
agent0:                 episode reward: -1.1748,                 loss: nan
agent1:                 episode reward: 1.1748,                 loss: 0.1886
Episode: 17881/30000 (59.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8858s / 1334.0603 s
agent0:                 episode reward: -1.0521,                 loss: nan
agent1:                 episode reward: 1.0521,                 loss: 0.2112
Episode: 17901/30000 (59.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8839s / 1335.9441 s
agent0:                 episode reward: -1.5608,                 loss: nan
agent1:                 episode reward: 1.5608,                 loss: 0.2135
Episode: 17921/30000 (59.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8914s / 1337.8355 s
agent0:                 episode reward: -1.0928,                 loss: nan
agent1:                 episode reward: 1.0928,                 loss: 0.2142
Episode: 17941/30000 (59.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8949s / 1339.7304 s
agent0:                 episode reward: -1.9206,                 loss: nan
agent1:                 episode reward: 1.9206,                 loss: 0.2123
Episode: 17961/30000 (59.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9562s / 1341.6866 s
agent0:                 episode reward: -0.8388,                 loss: nan
agent1:                 episode reward: 0.8388,                 loss: 0.2140
Episode: 17981/30000 (59.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8765s / 1343.5631 s
agent0:                 episode reward: -1.8209,                 loss: nan
agent1:                 episode reward: 1.8209,                 loss: 0.2264
Episode: 18001/30000 (60.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8963s / 1345.4594 s
agent0:                 episode reward: -1.0302,                 loss: nan
agent1:                 episode reward: 1.0302,                 loss: 0.2284
Episode: 18021/30000 (60.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8737s / 1347.3331 s
agent0:                 episode reward: -1.2748,                 loss: nan
agent1:                 episode reward: 1.2748,                 loss: 0.2255
Episode: 18041/30000 (60.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8927s / 1349.2257 s
agent0:                 episode reward: -1.8564,                 loss: nan
agent1:                 episode reward: 1.8564,                 loss: 0.2268
Episode: 18061/30000 (60.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8749s / 1351.1006 s
agent0:                 episode reward: -1.2423,                 loss: nan
agent1:                 episode reward: 1.2423,                 loss: 0.2258
Episode: 18081/30000 (60.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9349s / 1353.0355 s
agent0:                 episode reward: -1.5813,                 loss: nan
agent1:                 episode reward: 1.5813,                 loss: 0.2245
Episode: 18101/30000 (60.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8893s / 1354.9248 s
agent0:                 episode reward: -1.1434,                 loss: nan
agent1:                 episode reward: 1.1434,                 loss: 0.2243
Episode: 18121/30000 (60.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8978s / 1356.8227 s
agent0:                 episode reward: -1.6580,                 loss: nan
agent1:                 episode reward: 1.6580,                 loss: 0.2247
Episode: 18141/30000 (60.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8730s / 1358.6957 s
agent0:                 episode reward: -1.4747,                 loss: nan
agent1:                 episode reward: 1.4747,                 loss: 0.2220
Episode: 18161/30000 (60.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8725s / 1360.5682 s
agent0:                 episode reward: -1.1612,                 loss: nan
agent1:                 episode reward: 1.1612,                 loss: 0.2220
Episode: 18181/30000 (60.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9239s / 1362.4921 s
agent0:                 episode reward: -1.4899,                 loss: nan
agent1:                 episode reward: 1.4899,                 loss: 0.2315
Episode: 18201/30000 (60.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8927s / 1364.3847 s
agent0:                 episode reward: -1.2188,                 loss: nan
agent1:                 episode reward: 1.2188,                 loss: 0.2291
Episode: 18221/30000 (60.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9028s / 1366.2876 s
agent0:                 episode reward: -1.5497,                 loss: nan
agent1:                 episode reward: 1.5497,                 loss: 0.2304
Episode: 18241/30000 (60.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8941s / 1368.1817 s
agent0:                 episode reward: -1.4633,                 loss: nan
agent1:                 episode reward: 1.4633,                 loss: 0.2294
Episode: 18261/30000 (60.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8682s / 1370.0499 s
agent0:                 episode reward: -1.7042,                 loss: nan
agent1:                 episode reward: 1.7042,                 loss: 0.2308
Episode: 18281/30000 (60.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9321s / 1371.9820 s
agent0:                 episode reward: -1.9794,                 loss: nan
agent1:                 episode reward: 1.9794,                 loss: 0.2571
Episode: 18301/30000 (61.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9106s / 1373.8926 s
agent0:                 episode reward: -1.2780,                 loss: nan
agent1:                 episode reward: 1.2780,                 loss: 0.2593
Episode: 18321/30000 (61.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8906s / 1375.7832 s
agent0:                 episode reward: -0.7652,                 loss: nan
agent1:                 episode reward: 0.7652,                 loss: 0.2592
Episode: 18341/30000 (61.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8813s / 1377.6645 s
agent0:                 episode reward: -2.0718,                 loss: nan
agent1:                 episode reward: 2.0718,                 loss: 0.2575
Episode: 18361/30000 (61.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8679s / 1379.5324 s
agent0:                 episode reward: -0.7261,                 loss: nan
agent1:                 episode reward: 0.7261,                 loss: 0.2582
Episode: 18381/30000 (61.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8827s / 1381.4151 s
agent0:                 episode reward: -1.5185,                 loss: nan
agent1:                 episode reward: 1.5185,                 loss: 0.2496
Episode: 18401/30000 (61.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9418s / 1383.3569 s
agent0:                 episode reward: -0.7570,                 loss: nan
agent1:                 episode reward: 0.7570,                 loss: 0.2462
Episode: 18421/30000 (61.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8770s / 1385.2339 s
agent0:                 episode reward: -2.4310,                 loss: nan
agent1:                 episode reward: 2.4310,                 loss: 0.2452
Episode: 18441/30000 (61.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8962s / 1387.1301 s
agent0:                 episode reward: -0.3332,                 loss: nan
agent1:                 episode reward: 0.3332,                 loss: 0.2468
Episode: 18461/30000 (61.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8750s / 1389.0050 s
agent0:                 episode reward: -1.1455,                 loss: nan
agent1:                 episode reward: 1.1455,                 loss: 0.2468
Episode: 18481/30000 (61.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9000s / 1390.9051 s
agent0:                 episode reward: -1.3189,                 loss: nan
agent1:                 episode reward: 1.3189,                 loss: 0.2485
Episode: 18501/30000 (61.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9285s / 1392.8336 s
agent0:                 episode reward: -0.7813,                 loss: nan
agent1:                 episode reward: 0.7813,                 loss: 0.2480
Episode: 18521/30000 (61.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8936s / 1394.7272 s
agent0:                 episode reward: -1.4067,                 loss: nan
agent1:                 episode reward: 1.4067,                 loss: 0.2479
Episode: 18541/30000 (61.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8807s / 1396.6079 s
agent0:                 episode reward: -1.8549,                 loss: nan
agent1:                 episode reward: 1.8549,                 loss: 0.2466
Episode: 18561/30000 (61.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8936s / 1398.5014 s
agent0:                 episode reward: -1.2128,                 loss: nan
agent1:                 episode reward: 1.2128,                 loss: 0.2468
Episode: 18581/30000 (61.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8802s / 1400.3816 s
agent0:                 episode reward: -1.5304,                 loss: nan
agent1:                 episode reward: 1.5304,                 loss: 0.2265
Episode: 18601/30000 (62.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8885s / 1402.2702 s
agent0:                 episode reward: -1.6083,                 loss: nan
agent1:                 episode reward: 1.6083,                 loss: 0.2192
Episode: 18621/30000 (62.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9095s / 1404.1796 s
agent0:                 episode reward: -0.4982,                 loss: nan
agent1:                 episode reward: 0.4982,                 loss: 0.2182
Episode: 18641/30000 (62.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8774s / 1406.0571 s
agent0:                 episode reward: -2.1009,                 loss: nan
agent1:                 episode reward: 2.1009,                 loss: 0.2183
Episode: 18661/30000 (62.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9077s / 1407.9648 s
agent0:                 episode reward: -1.3308,                 loss: nan
agent1:                 episode reward: 1.3308,                 loss: 0.2176
Episode: 18681/30000 (62.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8796s / 1409.8444 s
agent0:                 episode reward: -1.1520,                 loss: nan
agent1:                 episode reward: 1.1520,                 loss: 0.2276
Episode: 18701/30000 (62.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8867s / 1411.7311 s
agent0:                 episode reward: -1.9649,                 loss: nan
agent1:                 episode reward: 1.9649,                 loss: 0.2280
Episode: 18721/30000 (62.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9273s / 1413.6584 s
agent0:                 episode reward: -1.5209,                 loss: nan
agent1:                 episode reward: 1.5209,                 loss: 0.2257
Episode: 18741/30000 (62.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9031s / 1415.5615 s
agent0:                 episode reward: -1.0643,                 loss: nan
agent1:                 episode reward: 1.0643,                 loss: 0.2271
Episode: 18761/30000 (62.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8912s / 1417.4528 s
agent0:                 episode reward: -1.5266,                 loss: nan
agent1:                 episode reward: 1.5266,                 loss: 0.2269
Episode: 18781/30000 (62.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8931s / 1419.3459 s
agent0:                 episode reward: -1.3261,                 loss: nan
agent1:                 episode reward: 1.3261,                 loss: 0.2218
Episode: 18801/30000 (62.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8718s / 1421.2176 s
agent0:                 episode reward: -1.6521,                 loss: nan
agent1:                 episode reward: 1.6521,                 loss: 0.2183
Episode: 18821/30000 (62.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9057s / 1423.1233 s
agent0:                 episode reward: -1.4291,                 loss: nan
agent1:                 episode reward: 1.4291,                 loss: 0.2189
Episode: 18841/30000 (62.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9263s / 1425.0496 s
agent0:                 episode reward: -1.2051,                 loss: nan
agent1:                 episode reward: 1.2051,                 loss: 0.2180
Episode: 18861/30000 (62.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8774s / 1426.9270 s
agent0:                 episode reward: -0.8419,                 loss: nan
agent1:                 episode reward: 0.8419,                 loss: 0.2193
Episode: 18881/30000 (62.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8817s / 1428.8087 s
agent0:                 episode reward: -0.8493,                 loss: nan
agent1:                 episode reward: 0.8493,                 loss: 0.2359
Episode: 18901/30000 (63.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8811s / 1430.6898 s
agent0:                 episode reward: -1.1210,                 loss: nan
agent1:                 episode reward: 1.1210,                 loss: 0.2363
Episode: 18921/30000 (63.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8950s / 1432.5848 s
agent0:                 episode reward: -1.2458,                 loss: nan
agent1:                 episode reward: 1.2458,                 loss: 0.2359
Episode: 18941/30000 (63.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9400s / 1434.5248 s
agent0:                 episode reward: -1.6697,                 loss: nan
agent1:                 episode reward: 1.6697,                 loss: 0.2377
Episode: 18961/30000 (63.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8872s / 1436.4121 s
agent0:                 episode reward: -1.1613,                 loss: nan
agent1:                 episode reward: 1.1613,                 loss: 0.2384
Episode: 18981/30000 (63.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8901s / 1438.3022 s
agent0:                 episode reward: -0.3339,                 loss: nan
agent1:                 episode reward: 0.3339,                 loss: 0.2591
Episode: 19001/30000 (63.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8965s / 1440.1987 s
agent0:                 episode reward: -1.5561,                 loss: nan
agent1:                 episode reward: 1.5561,                 loss: 0.2636
Episode: 19021/30000 (63.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8808s / 1442.0795 s
agent0:                 episode reward: -1.7763,                 loss: nan
agent1:                 episode reward: 1.7763,                 loss: 0.2619
Episode: 19041/30000 (63.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9310s / 1444.0105 s
agent0:                 episode reward: -0.7721,                 loss: nan
agent1:                 episode reward: 0.7721,                 loss: 0.2610
Episode: 19061/30000 (63.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8928s / 1445.9033 s
agent0:                 episode reward: -1.8847,                 loss: nan
agent1:                 episode reward: 1.8847,                 loss: 0.2615
Episode: 19081/30000 (63.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8873s / 1447.7906 s
agent0:                 episode reward: -1.2798,                 loss: nan
agent1:                 episode reward: 1.2798,                 loss: 0.2519
Episode: 19101/30000 (63.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8980s / 1449.6886 s
agent0:                 episode reward: -2.6379,                 loss: nan
agent1:                 episode reward: 2.6379,                 loss: 0.2498
Episode: 19121/30000 (63.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8820s / 1451.5706 s
agent0:                 episode reward: -1.2090,                 loss: nan
agent1:                 episode reward: 1.2090,                 loss: 0.2482
Episode: 19141/30000 (63.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8900s / 1453.4606 s
agent0:                 episode reward: -1.1527,                 loss: nan
agent1:                 episode reward: 1.1527,                 loss: 0.2476
Episode: 19161/30000 (63.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9418s / 1455.4024 s
agent0:                 episode reward: -1.0052,                 loss: nan
agent1:                 episode reward: 1.0052,                 loss: 0.2481
Episode: 19181/30000 (63.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8979s / 1457.3003 s
agent0:                 episode reward: -0.8727,                 loss: nan
agent1:                 episode reward: 0.8727,                 loss: 0.2472
Episode: 19201/30000 (64.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8979s / 1459.1983 s
agent0:                 episode reward: -1.5819,                 loss: nan
agent1:                 episode reward: 1.5819,                 loss: 0.2484
Episode: 19221/30000 (64.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8903s / 1461.0886 s
agent0:                 episode reward: -1.8917,                 loss: nan
agent1:                 episode reward: 1.8917,                 loss: 0.2470
Episode: 19241/30000 (64.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8998s / 1462.9884 s
agent0:                 episode reward: -1.2883,                 loss: nan
agent1:                 episode reward: 1.2883,                 loss: 0.2473
Episode: 19261/30000 (64.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9599s / 1464.9482 s
agent0:                 episode reward: -1.1098,                 loss: nan
agent1:                 episode reward: 1.1098,                 loss: 0.2473
Episode: 19281/30000 (64.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8921s / 1466.8403 s
agent0:                 episode reward: -1.8360,                 loss: nan
agent1:                 episode reward: 1.8360,                 loss: 0.2313
Episode: 19301/30000 (64.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9040s / 1468.7443 s
agent0:                 episode reward: -1.8825,                 loss: nan
agent1:                 episode reward: 1.8825,                 loss: 0.2245
Episode: 19321/30000 (64.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9040s / 1470.6483 s
agent0:                 episode reward: -1.7271,                 loss: nan
agent1:                 episode reward: 1.7271,                 loss: 0.2248
Episode: 19341/30000 (64.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8790s / 1472.5273 s
agent0:                 episode reward: -1.4433,                 loss: nan
agent1:                 episode reward: 1.4433,                 loss: 0.2248
Episode: 19361/30000 (64.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9578s / 1474.4851 s
agent0:                 episode reward: -2.1257,                 loss: nan
agent1:                 episode reward: 2.1257,                 loss: 0.2277
Episode: 19381/30000 (64.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8883s / 1476.3734 s
agent0:                 episode reward: -1.0662,                 loss: nan
agent1:                 episode reward: 1.0662,                 loss: 0.2113
Episode: 19401/30000 (64.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8896s / 1478.2631 s
agent0:                 episode reward: -1.9903,                 loss: nan
agent1:                 episode reward: 1.9903,                 loss: 0.2069
Episode: 19421/30000 (64.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8904s / 1480.1535 s
agent0:                 episode reward: -1.3643,                 loss: nan
agent1:                 episode reward: 1.3643,                 loss: 0.2083
Episode: 19441/30000 (64.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8986s / 1482.0521 s
agent0:                 episode reward: -1.5592,                 loss: nan
agent1:                 episode reward: 1.5592,                 loss: 0.2071
Episode: 19461/30000 (64.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8941s / 1483.9462 s
agent0:                 episode reward: -1.3844,                 loss: nan
agent1:                 episode reward: 1.3844,                 loss: 0.2081
Episode: 19481/30000 (64.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9560s / 1485.9021 s
agent0:                 episode reward: -1.9781,                 loss: nan
agent1:                 episode reward: 1.9781,                 loss: 0.2364
Episode: 19501/30000 (65.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8786s / 1487.7807 s
agent0:                 episode reward: -0.7538,                 loss: nan
agent1:                 episode reward: 0.7538,                 loss: 0.2371
Episode: 19521/30000 (65.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8977s / 1489.6784 s
agent0:                 episode reward: -0.7611,                 loss: nan
agent1:                 episode reward: 0.7611,                 loss: 0.2369
Episode: 19541/30000 (65.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8934s / 1491.5718 s
agent0:                 episode reward: -1.2540,                 loss: nan
agent1:                 episode reward: 1.2540,                 loss: 0.2366
Episode: 19561/30000 (65.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8848s / 1493.4566 s
agent0:                 episode reward: -1.3606,                 loss: nan
agent1:                 episode reward: 1.3606,                 loss: 0.2355
Episode: 19581/30000 (65.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9292s / 1495.3858 s
agent0:                 episode reward: -1.1212,                 loss: nan
agent1:                 episode reward: 1.1212,                 loss: 0.2253
Episode: 19601/30000 (65.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8829s / 1497.2686 s
agent0:                 episode reward: -0.8044,                 loss: nan
agent1:                 episode reward: 0.8044,                 loss: 0.2221
Episode: 19621/30000 (65.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8937s / 1499.1623 s
agent0:                 episode reward: -1.5918,                 loss: nan
agent1:                 episode reward: 1.5918,                 loss: 0.2237
Episode: 19641/30000 (65.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8954s / 1501.0577 s
agent0:                 episode reward: -1.8728,                 loss: nan
agent1:                 episode reward: 1.8728,                 loss: 0.2228
Episode: 19661/30000 (65.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8833s / 1502.9410 s
agent0:                 episode reward: -1.5817,                 loss: nan
agent1:                 episode reward: 1.5817,                 loss: 0.2218
Episode: 19681/30000 (65.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8973s / 1504.8383 s
agent0:                 episode reward: -1.9971,                 loss: nan
agent1:                 episode reward: 1.9971,                 loss: 0.2391
Episode: 19701/30000 (65.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9596s / 1506.7978 s
agent0:                 episode reward: -1.1715,                 loss: nan
agent1:                 episode reward: 1.1715,                 loss: 0.2399
Episode: 19721/30000 (65.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8753s / 1508.6731 s
agent0:                 episode reward: -1.0025,                 loss: nan
agent1:                 episode reward: 1.0025,                 loss: 0.2396
Episode: 19741/30000 (65.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8878s / 1510.5609 s
agent0:                 episode reward: -0.9353,                 loss: nan
agent1:                 episode reward: 0.9353,                 loss: 0.2415
Episode: 19761/30000 (65.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8843s / 1512.4452 s
agent0:                 episode reward: -1.6717,                 loss: nan
agent1:                 episode reward: 1.6717,                 loss: 0.2412
Episode: 19781/30000 (65.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8887s / 1514.3340 s
agent0:                 episode reward: -1.1685,                 loss: nan
agent1:                 episode reward: 1.1685,                 loss: 0.2461
Episode: 19801/30000 (66.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9563s / 1516.2902 s
agent0:                 episode reward: -2.3699,                 loss: nan
agent1:                 episode reward: 2.3699,                 loss: 0.2429
Episode: 19821/30000 (66.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8790s / 1518.1693 s
agent0:                 episode reward: -1.0691,                 loss: nan
agent1:                 episode reward: 1.0691,                 loss: 0.2467
Episode: 19841/30000 (66.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8867s / 1520.0560 s
agent0:                 episode reward: -1.4898,                 loss: nan
agent1:                 episode reward: 1.4898,                 loss: 0.2446
Episode: 19861/30000 (66.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8857s / 1521.9417 s
agent0:                 episode reward: -0.7946,                 loss: nan
agent1:                 episode reward: 0.7946,                 loss: 0.2455
Episode: 19881/30000 (66.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9010s / 1523.8427 s
agent0:                 episode reward: -0.7081,                 loss: nan
agent1:                 episode reward: 0.7081,                 loss: 0.2545
Episode: 19901/30000 (66.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9289s / 1525.7716 s
agent0:                 episode reward: -1.5257,                 loss: nan
agent1:                 episode reward: 1.5257,                 loss: 0.2528
Episode: 19921/30000 (66.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8875s / 1527.6591 s
agent0:                 episode reward: -1.1034,                 loss: nan
agent1:                 episode reward: 1.1034,                 loss: 0.2538
Episode: 19941/30000 (66.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8824s / 1529.5414 s
agent0:                 episode reward: -1.1990,                 loss: nan
agent1:                 episode reward: 1.1990,                 loss: 0.2546
Episode: 19961/30000 (66.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9045s / 1531.4459 s
agent0:                 episode reward: -1.1578,                 loss: nan
agent1:                 episode reward: 1.1578,                 loss: 0.2539
Episode: 19981/30000 (66.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8737s / 1533.3196 s
agent0:                 episode reward: -1.2699,                 loss: nan
agent1:                 episode reward: 1.2699,                 loss: 0.2559
Episode: 20001/30000 (66.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8917s / 1535.2113 s
agent0:                 episode reward: -1.2573,                 loss: nan
agent1:                 episode reward: 1.2573,                 loss: 0.2506
Episode: 20021/30000 (66.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9320s / 1537.1433 s
agent0:                 episode reward: -0.7722,                 loss: nan
agent1:                 episode reward: 0.7722,                 loss: 0.2510
Episode: 20041/30000 (66.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8789s / 1539.0222 s
agent0:                 episode reward: -1.5234,                 loss: nan
agent1:                 episode reward: 1.5234,                 loss: 0.2523
Episode: 20061/30000 (66.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8945s / 1540.9168 s
agent0:                 episode reward: -1.2608,                 loss: nan
agent1:                 episode reward: 1.2608,                 loss: 0.2504
Episode: 20081/30000 (66.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8870s / 1542.8038 s
agent0:                 episode reward: -2.0059,                 loss: nan
agent1:                 episode reward: 2.0059,                 loss: 0.2435
Episode: 20101/30000 (67.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8712s / 1544.6750 s
agent0:                 episode reward: -1.5999,                 loss: nan
agent1:                 episode reward: 1.5999,                 loss: 0.2397
Episode: 20121/30000 (67.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9152s / 1546.5902 s
agent0:                 episode reward: -0.9940,                 loss: nan
agent1:                 episode reward: 0.9940,                 loss: 0.2377
Episode: 20141/30000 (67.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8912s / 1548.4814 s
agent0:                 episode reward: -1.6497,                 loss: nan
agent1:                 episode reward: 1.6497,                 loss: 0.2364
Episode: 20161/30000 (67.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8806s / 1550.3620 s
agent0:                 episode reward: -0.9491,                 loss: nan
agent1:                 episode reward: 0.9491,                 loss: 0.2378
Episode: 20181/30000 (67.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8924s / 1552.2543 s
agent0:                 episode reward: -2.5428,                 loss: nan
agent1:                 episode reward: 2.5428,                 loss: 0.2209
Episode: 20201/30000 (67.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8831s / 1554.1374 s
agent0:                 episode reward: -1.8004,                 loss: nan
agent1:                 episode reward: 1.8004,                 loss: 0.2144
Episode: 20221/30000 (67.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8880s / 1556.0254 s
agent0:                 episode reward: -1.1083,                 loss: nan
agent1:                 episode reward: 1.1083,                 loss: 0.2157
Episode: 20241/30000 (67.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9497s / 1557.9751 s
agent0:                 episode reward: -1.9203,                 loss: nan
agent1:                 episode reward: 1.9203,                 loss: 0.2179
Episode: 20261/30000 (67.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8905s / 1559.8656 s
agent0:                 episode reward: -1.3269,                 loss: nan
agent1:                 episode reward: 1.3269,                 loss: 0.2140
Episode: 20281/30000 (67.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8943s / 1561.7600 s
agent0:                 episode reward: -1.9159,                 loss: nan
agent1:                 episode reward: 1.9159,                 loss: 0.2126
Episode: 20301/30000 (67.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8911s / 1563.6511 s
agent0:                 episode reward: -2.3144,                 loss: nan
agent1:                 episode reward: 2.3144,                 loss: 0.2100
Episode: 20321/30000 (67.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8985s / 1565.5496 s
agent0:                 episode reward: -1.1958,                 loss: nan
agent1:                 episode reward: 1.1958,                 loss: 0.2096
Episode: 20341/30000 (67.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9561s / 1567.5056 s
agent0:                 episode reward: -1.4777,                 loss: nan
agent1:                 episode reward: 1.4777,                 loss: 0.2094
Episode: 20361/30000 (67.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8849s / 1569.3905 s
agent0:                 episode reward: -1.7715,                 loss: nan
agent1:                 episode reward: 1.7715,                 loss: 0.2117
Episode: 20381/30000 (67.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8914s / 1571.2819 s
agent0:                 episode reward: -1.4864,                 loss: nan
agent1:                 episode reward: 1.4864,                 loss: 0.2184
Episode: 20401/30000 (68.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9053s / 1573.1873 s
agent0:                 episode reward: -2.7857,                 loss: nan
agent1:                 episode reward: 2.7857,                 loss: 0.2147
Episode: 20421/30000 (68.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8897s / 1575.0770 s
agent0:                 episode reward: -0.9469,                 loss: nan
agent1:                 episode reward: 0.9469,                 loss: 0.2180
Episode: 20441/30000 (68.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9375s / 1577.0146 s
agent0:                 episode reward: -1.3673,                 loss: nan
agent1:                 episode reward: 1.3673,                 loss: 0.2168
Episode: 20461/30000 (68.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8968s / 1578.9113 s
agent0:                 episode reward: -1.1789,                 loss: nan
agent1:                 episode reward: 1.1789,                 loss: 0.2160
Episode: 20481/30000 (68.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8900s / 1580.8014 s
agent0:                 episode reward: -1.3671,                 loss: nan
agent1:                 episode reward: 1.3671,                 loss: 0.2321
Episode: 20501/30000 (68.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9242s / 1582.7255 s
agent0:                 episode reward: -2.0574,                 loss: nan
agent1:                 episode reward: 2.0574,                 loss: 0.2328
Episode: 20521/30000 (68.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8811s / 1584.6066 s
agent0:                 episode reward: -1.4481,                 loss: nan
agent1:                 episode reward: 1.4481,                 loss: 0.2330
Episode: 20541/30000 (68.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9000s / 1586.5065 s
agent0:                 episode reward: -1.6049,                 loss: nan
agent1:                 episode reward: 1.6049,                 loss: 0.2308
Episode: 20561/30000 (68.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9488s / 1588.4554 s
agent0:                 episode reward: -0.9113,                 loss: nan
agent1:                 episode reward: 0.9113,                 loss: 0.2324
Episode: 20581/30000 (68.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9058s / 1590.3612 s
agent0:                 episode reward: -1.3327,                 loss: nan
agent1:                 episode reward: 1.3327,                 loss: 0.2470
Episode: 20601/30000 (68.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9065s / 1592.2677 s
agent0:                 episode reward: -1.5652,                 loss: nan
agent1:                 episode reward: 1.5652,                 loss: 0.2447
Episode: 20621/30000 (68.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8945s / 1594.1622 s
agent0:                 episode reward: -1.3822,                 loss: nan
agent1:                 episode reward: 1.3822,                 loss: 0.2453
Episode: 20641/30000 (68.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8874s / 1596.0496 s
agent0:                 episode reward: -2.1357,                 loss: nan
agent1:                 episode reward: 2.1357,                 loss: 0.2463
Episode: 20661/30000 (68.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9675s / 1598.0171 s
agent0:                 episode reward: -1.9086,                 loss: nan
agent1:                 episode reward: 1.9086,                 loss: 0.2451
Episode: 20681/30000 (68.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8936s / 1599.9108 s
agent0:                 episode reward: -1.3773,                 loss: nan
agent1:                 episode reward: 1.3773,                 loss: 0.2752
Episode: 20701/30000 (69.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8959s / 1601.8066 s
agent0:                 episode reward: -1.2972,                 loss: nan
agent1:                 episode reward: 1.2972,                 loss: 0.2752
Episode: 20721/30000 (69.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9165s / 1603.7231 s
agent0:                 episode reward: -1.6162,                 loss: nan
agent1:                 episode reward: 1.6162,                 loss: 0.2760
Episode: 20741/30000 (69.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8933s / 1605.6164 s
agent0:                 episode reward: -1.8177,                 loss: nan
agent1:                 episode reward: 1.8177,                 loss: 0.2754
Episode: 20761/30000 (69.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9687s / 1607.5851 s
agent0:                 episode reward: -1.2911,                 loss: nan
agent1:                 episode reward: 1.2911,                 loss: 0.2743
Episode: 20781/30000 (69.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9005s / 1609.4856 s
agent0:                 episode reward: -1.6414,                 loss: nan
agent1:                 episode reward: 1.6414,                 loss: 0.2695
Episode: 20801/30000 (69.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8938s / 1611.3794 s
agent0:                 episode reward: -1.5357,                 loss: nan
agent1:                 episode reward: 1.5357,                 loss: 0.2652
Episode: 20821/30000 (69.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9025s / 1613.2819 s
agent0:                 episode reward: -1.2764,                 loss: nan
agent1:                 episode reward: 1.2764,                 loss: 0.2656
Episode: 20841/30000 (69.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9075s / 1615.1894 s
agent0:                 episode reward: -1.4399,                 loss: nan
agent1:                 episode reward: 1.4399,                 loss: 0.2644
Episode: 20861/30000 (69.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8978s / 1617.0872 s
agent0:                 episode reward: -1.7642,                 loss: nan
agent1:                 episode reward: 1.7642,                 loss: 0.2640
Episode: 20881/30000 (69.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9501s / 1619.0373 s
agent0:                 episode reward: -1.5025,                 loss: nan
agent1:                 episode reward: 1.5025,                 loss: 0.2734
Episode: 20901/30000 (69.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8992s / 1620.9364 s
agent0:                 episode reward: -1.6045,                 loss: nan
agent1:                 episode reward: 1.6045,                 loss: 0.2699
Episode: 20921/30000 (69.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8946s / 1622.8311 s
agent0:                 episode reward: -1.2410,                 loss: nan
agent1:                 episode reward: 1.2410,                 loss: 0.2724
Episode: 20941/30000 (69.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9218s / 1624.7529 s
agent0:                 episode reward: -1.6250,                 loss: nan
agent1:                 episode reward: 1.6250,                 loss: 0.2681
Episode: 20961/30000 (69.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8902s / 1626.6431 s
agent0:                 episode reward: -0.7852,                 loss: nan
agent1:                 episode reward: 0.7852,                 loss: 0.2727
Episode: 20981/30000 (69.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9884s / 1628.6315 s
agent0:                 episode reward: -1.3798,                 loss: nan
agent1:                 episode reward: 1.3798,                 loss: 0.2474
Episode: 21001/30000 (70.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8939s / 1630.5254 s
agent0:                 episode reward: -2.0141,                 loss: nan
agent1:                 episode reward: 2.0141,                 loss: 0.2374
Episode: 21021/30000 (70.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8962s / 1632.4216 s
agent0:                 episode reward: -1.6185,                 loss: nan
agent1:                 episode reward: 1.6185,                 loss: 0.2390
Episode: 21041/30000 (70.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8905s / 1634.3121 s
agent0:                 episode reward: -1.2723,                 loss: nan
agent1:                 episode reward: 1.2723,                 loss: 0.2391
Episode: 21061/30000 (70.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8937s / 1636.2059 s
agent0:                 episode reward: -1.2414,                 loss: nan
agent1:                 episode reward: 1.2414,                 loss: 0.2385
Episode: 21081/30000 (70.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9180s / 1638.1239 s
agent0:                 episode reward: -1.4524,                 loss: nan
agent1:                 episode reward: 1.4524,                 loss: 0.2090
Episode: 21101/30000 (70.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9368s / 1640.0607 s
agent0:                 episode reward: -0.7259,                 loss: nan
agent1:                 episode reward: 0.7259,                 loss: 0.1997
Episode: 21121/30000 (70.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9025s / 1641.9632 s
agent0:                 episode reward: -2.2059,                 loss: nan
agent1:                 episode reward: 2.2059,                 loss: 0.1995
Episode: 21141/30000 (70.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8790s / 1643.8422 s
agent0:                 episode reward: -1.1373,                 loss: nan
agent1:                 episode reward: 1.1373,                 loss: 0.1990
Episode: 21161/30000 (70.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8987s / 1645.7409 s
agent0:                 episode reward: -1.3339,                 loss: nan
agent1:                 episode reward: 1.3339,                 loss: 0.1989
Episode: 21181/30000 (70.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8890s / 1647.6299 s
agent0:                 episode reward: -1.0953,                 loss: nan
agent1:                 episode reward: 1.0953,                 loss: 0.2113
Episode: 21201/30000 (70.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9672s / 1649.5971 s
agent0:                 episode reward: -1.5196,                 loss: nan
agent1:                 episode reward: 1.5196,                 loss: 0.2126
Episode: 21221/30000 (70.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8879s / 1651.4850 s
agent0:                 episode reward: -1.4536,                 loss: nan
agent1:                 episode reward: 1.4536,                 loss: 0.2114
Episode: 21241/30000 (70.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8913s / 1653.3763 s
agent0:                 episode reward: -1.4764,                 loss: nan
agent1:                 episode reward: 1.4764,                 loss: 0.2102
Episode: 21261/30000 (70.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9068s / 1655.2831 s
agent0:                 episode reward: -1.0454,                 loss: nan
agent1:                 episode reward: 1.0454,                 loss: 0.2111
Episode: 21281/30000 (70.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9122s / 1657.1953 s
agent0:                 episode reward: -1.5985,                 loss: nan
agent1:                 episode reward: 1.5985,                 loss: 0.2283
Episode: 21301/30000 (71.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9392s / 1659.1345 s
agent0:                 episode reward: -1.3939,                 loss: nan
agent1:                 episode reward: 1.3939,                 loss: 0.2292
Episode: 21321/30000 (71.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8967s / 1661.0312 s
agent0:                 episode reward: -1.9303,                 loss: nan
agent1:                 episode reward: 1.9303,                 loss: 0.2287
Episode: 21341/30000 (71.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9037s / 1662.9350 s
agent0:                 episode reward: -1.8347,                 loss: nan
agent1:                 episode reward: 1.8347,                 loss: 0.2306
Episode: 21361/30000 (71.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9082s / 1664.8432 s
agent0:                 episode reward: -1.5577,                 loss: nan
agent1:                 episode reward: 1.5577,                 loss: 0.2301
Episode: 21381/30000 (71.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8880s / 1666.7312 s
agent0:                 episode reward: -1.5828,                 loss: nan
agent1:                 episode reward: 1.5828,                 loss: 0.2537
Episode: 21401/30000 (71.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8915s / 1668.6227 s
agent0:                 episode reward: -1.6428,                 loss: nan
agent1:                 episode reward: 1.6428,                 loss: 0.2551
Episode: 21421/30000 (71.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9443s / 1670.5670 s
agent0:                 episode reward: -1.9438,                 loss: nan
agent1:                 episode reward: 1.9438,                 loss: 0.2531
Episode: 21441/30000 (71.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8909s / 1672.4579 s
agent0:                 episode reward: -1.6337,                 loss: nan
agent1:                 episode reward: 1.6337,                 loss: 0.2530
Episode: 21461/30000 (71.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9067s / 1674.3647 s
agent0:                 episode reward: -1.6869,                 loss: nan
agent1:                 episode reward: 1.6869,                 loss: 0.2523
Episode: 21481/30000 (71.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8845s / 1676.2491 s
agent0:                 episode reward: -1.3519,                 loss: nan
agent1:                 episode reward: 1.3519,                 loss: 0.2826
Episode: 21501/30000 (71.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8860s / 1678.1351 s
agent0:                 episode reward: -1.4390,                 loss: nan
agent1:                 episode reward: 1.4390,                 loss: 0.2860
Episode: 21521/30000 (71.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9338s / 1680.0690 s
agent0:                 episode reward: -1.3334,                 loss: nan
agent1:                 episode reward: 1.3334,                 loss: 0.2842
Episode: 21541/30000 (71.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9042s / 1681.9732 s
agent0:                 episode reward: -1.1836,                 loss: nan
agent1:                 episode reward: 1.1836,                 loss: 0.2853
Episode: 21561/30000 (71.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8857s / 1683.8588 s
agent0:                 episode reward: -1.1290,                 loss: nan
agent1:                 episode reward: 1.1290,                 loss: 0.2831
Episode: 21581/30000 (71.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8877s / 1685.7465 s
agent0:                 episode reward: -1.7688,                 loss: nan
agent1:                 episode reward: 1.7688,                 loss: 0.2719
Episode: 21601/30000 (72.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9038s / 1687.6503 s
agent0:                 episode reward: -1.7299,                 loss: nan
agent1:                 episode reward: 1.7299,                 loss: 0.2666
Episode: 21621/30000 (72.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9476s / 1689.5979 s
agent0:                 episode reward: -1.4515,                 loss: nan
agent1:                 episode reward: 1.4515,                 loss: 0.2673
Episode: 21641/30000 (72.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8926s / 1691.4905 s
agent0:                 episode reward: -1.1990,                 loss: nan
agent1:                 episode reward: 1.1990,                 loss: 0.2682
Episode: 21661/30000 (72.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8921s / 1693.3826 s
agent0:                 episode reward: -1.7988,                 loss: nan
agent1:                 episode reward: 1.7988,                 loss: 0.2681
Episode: 21681/30000 (72.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8839s / 1695.2665 s
agent0:                 episode reward: -1.1611,                 loss: nan
agent1:                 episode reward: 1.1611,                 loss: 0.2441
Episode: 21701/30000 (72.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8805s / 1697.1469 s
agent0:                 episode reward: -1.8811,                 loss: nan
agent1:                 episode reward: 1.8811,                 loss: 0.2376
Episode: 21721/30000 (72.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9105s / 1699.0574 s
agent0:                 episode reward: -2.3129,                 loss: nan
agent1:                 episode reward: 2.3129,                 loss: 0.2388
Episode: 21741/30000 (72.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9195s / 1700.9769 s
agent0:                 episode reward: -1.4879,                 loss: nan
agent1:                 episode reward: 1.4879,                 loss: 0.2378
Episode: 21761/30000 (72.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8984s / 1702.8754 s
agent0:                 episode reward: -2.5171,                 loss: nan
agent1:                 episode reward: 2.5171,                 loss: 0.2383
Episode: 21781/30000 (72.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8948s / 1704.7702 s
agent0:                 episode reward: -1.5487,                 loss: nan
agent1:                 episode reward: 1.5487,                 loss: 0.2446
Episode: 21801/30000 (72.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9357s / 1706.7058 s
agent0:                 episode reward: -1.7046,                 loss: nan
agent1:                 episode reward: 1.7046,                 loss: 0.2433
Episode: 21821/30000 (72.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9008s / 1708.6066 s
agent0:                 episode reward: -2.0005,                 loss: nan
agent1:                 episode reward: 2.0005,                 loss: 0.2435
Episode: 21841/30000 (72.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9367s / 1710.5433 s
agent0:                 episode reward: -1.6881,                 loss: nan
agent1:                 episode reward: 1.6881,                 loss: 0.2423
Episode: 21861/30000 (72.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8968s / 1712.4401 s
agent0:                 episode reward: -0.8572,                 loss: nan
agent1:                 episode reward: 0.8572,                 loss: 0.2432
Episode: 21881/30000 (72.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8956s / 1714.3357 s
agent0:                 episode reward: -2.0698,                 loss: nan
agent1:                 episode reward: 2.0698,                 loss: 0.2619
Episode: 21901/30000 (73.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8970s / 1716.2327 s
agent0:                 episode reward: -1.5305,                 loss: nan
agent1:                 episode reward: 1.5305,                 loss: 0.2652
Episode: 21921/30000 (73.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8926s / 1718.1253 s
agent0:                 episode reward: -1.4963,                 loss: nan
agent1:                 episode reward: 1.4963,                 loss: 0.2623
Episode: 21941/30000 (73.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9357s / 1720.0610 s
agent0:                 episode reward: -1.3616,                 loss: nan
agent1:                 episode reward: 1.3616,                 loss: 0.2616
Episode: 21961/30000 (73.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9059s / 1721.9668 s
agent0:                 episode reward: -1.5796,                 loss: nan
agent1:                 episode reward: 1.5796,                 loss: 0.2601
Episode: 21981/30000 (73.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9082s / 1723.8751 s
agent0:                 episode reward: -2.5291,                 loss: nan
agent1:                 episode reward: 2.5291,                 loss: 0.2612
Episode: 22001/30000 (73.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8786s / 1725.7536 s
agent0:                 episode reward: -1.7514,                 loss: nan
agent1:                 episode reward: 1.7514,                 loss: 0.2598
Episode: 22021/30000 (73.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8768s / 1727.6305 s
agent0:                 episode reward: -1.2396,                 loss: nan
agent1:                 episode reward: 1.2396,                 loss: 0.2577
Episode: 22041/30000 (73.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8947s / 1729.5252 s
agent0:                 episode reward: -1.6323,                 loss: nan
agent1:                 episode reward: 1.6323,                 loss: 0.2587
Episode: 22061/30000 (73.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9341s / 1731.4593 s
agent0:                 episode reward: -1.7550,                 loss: nan
agent1:                 episode reward: 1.7550,                 loss: 0.2566
Episode: 22081/30000 (73.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8874s / 1733.3467 s
agent0:                 episode reward: -2.2212,                 loss: nan
agent1:                 episode reward: 2.2212,                 loss: 0.2309
Episode: 22101/30000 (73.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8753s / 1735.2220 s
agent0:                 episode reward: -1.3416,                 loss: nan
agent1:                 episode reward: 1.3416,                 loss: 0.2232
Episode: 22121/30000 (73.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8853s / 1737.1072 s
agent0:                 episode reward: -1.2170,                 loss: nan
agent1:                 episode reward: 1.2170,                 loss: 0.2229
Episode: 22141/30000 (73.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8913s / 1738.9985 s
agent0:                 episode reward: -1.7104,                 loss: nan
agent1:                 episode reward: 1.7104,                 loss: 0.2232
Episode: 22161/30000 (73.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9835s / 1740.9820 s
agent0:                 episode reward: -1.7952,                 loss: nan
agent1:                 episode reward: 1.7952,                 loss: 0.2246
Episode: 22181/30000 (73.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8854s / 1742.8674 s
agent0:                 episode reward: -1.6958,                 loss: nan
agent1:                 episode reward: 1.6958,                 loss: 0.2173
Episode: 22201/30000 (74.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8844s / 1744.7518 s
agent0:                 episode reward: -1.5385,                 loss: nan
agent1:                 episode reward: 1.5385,                 loss: 0.2131
Episode: 22221/30000 (74.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8890s / 1746.6408 s
agent0:                 episode reward: -1.2332,                 loss: nan
agent1:                 episode reward: 1.2332,                 loss: 0.2139
Episode: 22241/30000 (74.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9000s / 1748.5408 s
agent0:                 episode reward: -1.6313,                 loss: nan
agent1:                 episode reward: 1.6313,                 loss: 0.2134
Episode: 22261/30000 (74.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8913s / 1750.4321 s
agent0:                 episode reward: -1.1943,                 loss: nan
agent1:                 episode reward: 1.1943,                 loss: 0.2133
Episode: 22281/30000 (74.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9110s / 1752.3431 s
agent0:                 episode reward: -1.8607,                 loss: nan
agent1:                 episode reward: 1.8607,                 loss: 0.2430
Episode: 22301/30000 (74.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8977s / 1754.2408 s
agent0:                 episode reward: -1.4575,                 loss: nan
agent1:                 episode reward: 1.4575,                 loss: 0.2460
Episode: 22321/30000 (74.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8970s / 1756.1378 s
agent0:                 episode reward: -1.8554,                 loss: nan
agent1:                 episode reward: 1.8554,                 loss: 0.2456
Episode: 22341/30000 (74.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8755s / 1758.0133 s
agent0:                 episode reward: -1.5447,                 loss: nan
agent1:                 episode reward: 1.5447,                 loss: 0.2431
Episode: 22361/30000 (74.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8973s / 1759.9106 s
agent0:                 episode reward: -1.3178,                 loss: nan
agent1:                 episode reward: 1.3178,                 loss: 0.2453
Episode: 22381/30000 (74.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9238s / 1761.8344 s
agent0:                 episode reward: -1.4733,                 loss: nan
agent1:                 episode reward: 1.4733,                 loss: 0.2561
Episode: 22401/30000 (74.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8842s / 1763.7186 s
agent0:                 episode reward: -0.9166,                 loss: nan
agent1:                 episode reward: 0.9166,                 loss: 0.2566
Episode: 22421/30000 (74.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8943s / 1765.6128 s
agent0:                 episode reward: -1.1687,                 loss: nan
agent1:                 episode reward: 1.1687,                 loss: 0.2559
Episode: 22441/30000 (74.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8752s / 1767.4880 s
agent0:                 episode reward: -1.9914,                 loss: nan
agent1:                 episode reward: 1.9914,                 loss: 0.2558
Episode: 22461/30000 (74.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8780s / 1769.3661 s
agent0:                 episode reward: -1.6907,                 loss: nan
agent1:                 episode reward: 1.6907,                 loss: 0.2568
Episode: 22481/30000 (74.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9153s / 1771.2814 s
agent0:                 episode reward: -1.6794,                 loss: nan
agent1:                 episode reward: 1.6794,                 loss: 0.2523
Episode: 22501/30000 (75.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9202s / 1773.2016 s
agent0:                 episode reward: -1.4866,                 loss: nan
agent1:                 episode reward: 1.4866,                 loss: 0.2503
Episode: 22521/30000 (75.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8826s / 1775.0842 s
agent0:                 episode reward: -1.7106,                 loss: nan
agent1:                 episode reward: 1.7106,                 loss: 0.2519
Episode: 22541/30000 (75.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8746s / 1776.9588 s
agent0:                 episode reward: -1.7209,                 loss: nan
agent1:                 episode reward: 1.7209,                 loss: 0.2498
Episode: 22561/30000 (75.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8870s / 1778.8459 s
agent0:                 episode reward: -1.4270,                 loss: nan
agent1:                 episode reward: 1.4270,                 loss: 0.2517
Episode: 22581/30000 (75.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9000s / 1780.7459 s
agent0:                 episode reward: -1.5269,                 loss: nan
agent1:                 episode reward: 1.5269,                 loss: 0.2443
Episode: 22601/30000 (75.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9483s / 1782.6943 s
agent0:                 episode reward: -1.5854,                 loss: nan
agent1:                 episode reward: 1.5854,                 loss: 0.2417
Episode: 22621/30000 (75.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8829s / 1784.5772 s
agent0:                 episode reward: -2.4939,                 loss: nan
agent1:                 episode reward: 2.4939,                 loss: 0.2410
Episode: 22641/30000 (75.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9007s / 1786.4779 s
agent0:                 episode reward: -1.4832,                 loss: nan
agent1:                 episode reward: 1.4832,                 loss: 0.2381
Episode: 22661/30000 (75.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8746s / 1788.3525 s
agent0:                 episode reward: -1.7217,                 loss: nan
agent1:                 episode reward: 1.7217,                 loss: 0.2410
Episode: 22681/30000 (75.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9073s / 1790.2598 s
agent0:                 episode reward: -1.0295,                 loss: nan
agent1:                 episode reward: 1.0295,                 loss: 0.2384
Episode: 22701/30000 (75.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9203s / 1792.1801 s
agent0:                 episode reward: -1.2866,                 loss: nan
agent1:                 episode reward: 1.2866,                 loss: 0.2354
Episode: 22721/30000 (75.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8883s / 1794.0684 s
agent0:                 episode reward: -1.6431,                 loss: nan
agent1:                 episode reward: 1.6431,                 loss: 0.2347
Episode: 22741/30000 (75.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8878s / 1795.9562 s
agent0:                 episode reward: -1.5327,                 loss: nan
agent1:                 episode reward: 1.5327,                 loss: 0.2357
Episode: 22761/30000 (75.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8966s / 1797.8527 s
agent0:                 episode reward: -2.0540,                 loss: nan
agent1:                 episode reward: 2.0540,                 loss: 0.2355
Episode: 22781/30000 (75.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8917s / 1799.7444 s
agent0:                 episode reward: -1.8015,                 loss: nan
agent1:                 episode reward: 1.8015,                 loss: 0.2599
Episode: 22801/30000 (76.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9061s / 1801.6506 s
agent0:                 episode reward: -1.2468,                 loss: nan
agent1:                 episode reward: 1.2468,                 loss: 0.2607
Episode: 22821/30000 (76.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9125s / 1803.5631 s
agent0:                 episode reward: -0.7990,                 loss: nan
agent1:                 episode reward: 0.7990,                 loss: 0.2602
Episode: 22841/30000 (76.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8816s / 1805.4447 s
agent0:                 episode reward: -1.3490,                 loss: nan
agent1:                 episode reward: 1.3490,                 loss: 0.2591
Episode: 22861/30000 (76.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9107s / 1807.3554 s
agent0:                 episode reward: -1.6444,                 loss: nan
agent1:                 episode reward: 1.6444,                 loss: 0.2597
Episode: 22881/30000 (76.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8787s / 1809.2341 s
agent0:                 episode reward: -1.5699,                 loss: nan
agent1:                 episode reward: 1.5699,                 loss: 0.2611
Episode: 22901/30000 (76.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9018s / 1811.1359 s
agent0:                 episode reward: -1.6370,                 loss: nan
agent1:                 episode reward: 1.6370,                 loss: 0.2558
Episode: 22921/30000 (76.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9195s / 1813.0554 s
agent0:                 episode reward: -1.6741,                 loss: nan
agent1:                 episode reward: 1.6741,                 loss: 0.2561
Episode: 22941/30000 (76.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9111s / 1814.9665 s
agent0:                 episode reward: -2.0146,                 loss: nan
agent1:                 episode reward: 2.0146,                 loss: 0.2559
Episode: 22961/30000 (76.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9175s / 1816.8840 s
agent0:                 episode reward: -1.3112,                 loss: nan
agent1:                 episode reward: 1.3112,                 loss: 0.2548
Episode: 22981/30000 (76.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9153s / 1818.7993 s
agent0:                 episode reward: -1.1493,                 loss: nan
agent1:                 episode reward: 1.1493,                 loss: 0.2383
Episode: 23001/30000 (76.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9399s / 1820.7392 s
agent0:                 episode reward: -1.1133,                 loss: nan
agent1:                 episode reward: 1.1133,                 loss: 0.2322
Episode: 23021/30000 (76.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0159s / 1822.7551 s
agent0:                 episode reward: -1.8622,                 loss: nan
agent1:                 episode reward: 1.8622,                 loss: 0.2305
Episode: 23041/30000 (76.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8873s / 1824.6424 s
agent0:                 episode reward: -1.9123,                 loss: nan
agent1:                 episode reward: 1.9123,                 loss: 0.2314
Episode: 23061/30000 (76.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9103s / 1826.5527 s
agent0:                 episode reward: -1.8389,                 loss: nan
agent1:                 episode reward: 1.8389,                 loss: 0.2304
Episode: 23081/30000 (76.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8790s / 1828.4317 s
agent0:                 episode reward: -1.6609,                 loss: nan
agent1:                 episode reward: 1.6609,                 loss: 0.2513
Episode: 23101/30000 (77.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9024s / 1830.3341 s
agent0:                 episode reward: -0.9372,                 loss: nan
agent1:                 episode reward: 0.9372,                 loss: 0.2551
Episode: 23121/30000 (77.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9376s / 1832.2717 s
agent0:                 episode reward: -0.9189,                 loss: nan
agent1:                 episode reward: 0.9189,                 loss: 0.2535
Episode: 23141/30000 (77.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9587s / 1834.2304 s
agent0:                 episode reward: -1.3458,                 loss: nan
agent1:                 episode reward: 1.3458,                 loss: 0.2540
Episode: 23161/30000 (77.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9160s / 1836.1465 s
agent0:                 episode reward: -1.8362,                 loss: nan
agent1:                 episode reward: 1.8362,                 loss: 0.2561
Episode: 23181/30000 (77.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8887s / 1838.0351 s
agent0:                 episode reward: -1.2376,                 loss: nan
agent1:                 episode reward: 1.2376,                 loss: 0.2375
Episode: 23201/30000 (77.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9000s / 1839.9351 s
agent0:                 episode reward: -1.6499,                 loss: nan
agent1:                 episode reward: 1.6499,                 loss: 0.2345
Episode: 23221/30000 (77.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9069s / 1841.8421 s
agent0:                 episode reward: -1.8669,                 loss: nan
agent1:                 episode reward: 1.8669,                 loss: 0.2342
Episode: 23241/30000 (77.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9308s / 1843.7729 s
agent0:                 episode reward: -1.3698,                 loss: nan
agent1:                 episode reward: 1.3698,                 loss: 0.2336
Episode: 23261/30000 (77.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8841s / 1845.6569 s
agent0:                 episode reward: -1.2750,                 loss: nan
agent1:                 episode reward: 1.2750,                 loss: 0.2338
Episode: 23281/30000 (77.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9053s / 1847.5622 s
agent0:                 episode reward: -1.6252,                 loss: nan
agent1:                 episode reward: 1.6252,                 loss: 0.2228
Episode: 23301/30000 (77.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8855s / 1849.4477 s
agent0:                 episode reward: -1.4090,                 loss: nan
agent1:                 episode reward: 1.4090,                 loss: 0.2189
Episode: 23321/30000 (77.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8928s / 1851.3405 s
agent0:                 episode reward: -1.5681,                 loss: nan
agent1:                 episode reward: 1.5681,                 loss: 0.2185
Episode: 23341/30000 (77.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9418s / 1853.2823 s
agent0:                 episode reward: -1.6943,                 loss: nan
agent1:                 episode reward: 1.6943,                 loss: 0.2184
Episode: 23361/30000 (77.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8912s / 1855.1735 s
agent0:                 episode reward: -2.3473,                 loss: nan
agent1:                 episode reward: 2.3473,                 loss: 0.2184
Episode: 23381/30000 (77.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9154s / 1857.0890 s
agent0:                 episode reward: -1.7064,                 loss: nan
agent1:                 episode reward: 1.7064,                 loss: 0.2212
Episode: 23401/30000 (78.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8795s / 1858.9685 s
agent0:                 episode reward: -0.9677,                 loss: nan
agent1:                 episode reward: 0.9677,                 loss: 0.2188
Episode: 23421/30000 (78.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8739s / 1860.8423 s
agent0:                 episode reward: -1.4608,                 loss: nan
agent1:                 episode reward: 1.4608,                 loss: 0.2179
Episode: 23441/30000 (78.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8814s / 1862.7237 s
agent0:                 episode reward: -1.3686,                 loss: nan
agent1:                 episode reward: 1.3686,                 loss: 0.2191
Episode: 23461/30000 (78.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9547s / 1864.6784 s
agent0:                 episode reward: -1.3557,                 loss: nan
agent1:                 episode reward: 1.3557,                 loss: 0.2199
Episode: 23481/30000 (78.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8916s / 1866.5700 s
agent0:                 episode reward: -1.6270,                 loss: nan
agent1:                 episode reward: 1.6270,                 loss: 0.2242
Episode: 23501/30000 (78.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9005s / 1868.4705 s
agent0:                 episode reward: -0.8937,                 loss: nan
agent1:                 episode reward: 0.8937,                 loss: 0.2231
Episode: 23521/30000 (78.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8815s / 1870.3520 s
agent0:                 episode reward: -1.3998,                 loss: nan
agent1:                 episode reward: 1.3998,                 loss: 0.2233
Episode: 23541/30000 (78.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8957s / 1872.2477 s
agent0:                 episode reward: -0.7063,                 loss: nan
agent1:                 episode reward: 0.7063,                 loss: 0.2208
Episode: 23561/30000 (78.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9815s / 1874.2292 s
agent0:                 episode reward: -1.4467,                 loss: nan
agent1:                 episode reward: 1.4467,                 loss: 0.2238
Episode: 23581/30000 (78.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8819s / 1876.1111 s
agent0:                 episode reward: -1.3943,                 loss: nan
agent1:                 episode reward: 1.3943,                 loss: 0.2495
Episode: 23601/30000 (78.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9041s / 1878.0152 s
agent0:                 episode reward: -2.1595,                 loss: nan
agent1:                 episode reward: 2.1595,                 loss: 0.2480
Episode: 23621/30000 (78.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8992s / 1879.9144 s
agent0:                 episode reward: -1.6427,                 loss: nan
agent1:                 episode reward: 1.6427,                 loss: 0.2490
Episode: 23641/30000 (78.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9239s / 1881.8383 s
agent0:                 episode reward: -1.2089,                 loss: nan
agent1:                 episode reward: 1.2089,                 loss: 0.2489
Episode: 23661/30000 (78.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9266s / 1883.7650 s
agent0:                 episode reward: -1.6243,                 loss: nan
agent1:                 episode reward: 1.6243,                 loss: 0.2476
Episode: 23681/30000 (78.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9049s / 1885.6699 s
agent0:                 episode reward: -1.6011,                 loss: nan
agent1:                 episode reward: 1.6011,                 loss: 0.2937
Episode: 23701/30000 (79.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8798s / 1887.5497 s
agent0:                 episode reward: -1.2933,                 loss: nan
agent1:                 episode reward: 1.2933,                 loss: 0.2963
Episode: 23721/30000 (79.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9074s / 1889.4571 s
agent0:                 episode reward: -2.4055,                 loss: nan
agent1:                 episode reward: 2.4055,                 loss: 0.2962
Episode: 23741/30000 (79.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8897s / 1891.3467 s
agent0:                 episode reward: -1.7445,                 loss: nan
agent1:                 episode reward: 1.7445,                 loss: 0.2970
Episode: 23761/30000 (79.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8872s / 1893.2339 s
agent0:                 episode reward: -1.2157,                 loss: nan
agent1:                 episode reward: 1.2157,                 loss: 0.2964
Episode: 23781/30000 (79.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9403s / 1895.1743 s
agent0:                 episode reward: -1.2910,                 loss: nan
agent1:                 episode reward: 1.2910,                 loss: 0.2843
Episode: 23801/30000 (79.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8894s / 1897.0636 s
agent0:                 episode reward: -2.1411,                 loss: nan
agent1:                 episode reward: 2.1411,                 loss: 0.2797
Episode: 23821/30000 (79.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9055s / 1898.9691 s
agent0:                 episode reward: -1.9817,                 loss: nan
agent1:                 episode reward: 1.9817,                 loss: 0.2823
Episode: 23841/30000 (79.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8967s / 1900.8658 s
agent0:                 episode reward: -1.5959,                 loss: nan
agent1:                 episode reward: 1.5959,                 loss: 0.2827
Episode: 23861/30000 (79.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8915s / 1902.7573 s
agent0:                 episode reward: -1.1415,                 loss: nan
agent1:                 episode reward: 1.1415,                 loss: 0.2802
Episode: 23881/30000 (79.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9452s / 1904.7025 s
agent0:                 episode reward: -1.5652,                 loss: nan
agent1:                 episode reward: 1.5652,                 loss: 0.2586
Episode: 23901/30000 (79.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8974s / 1906.5999 s
agent0:                 episode reward: -1.9905,                 loss: nan
agent1:                 episode reward: 1.9905,                 loss: 0.2541
Episode: 23921/30000 (79.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8978s / 1908.4977 s
agent0:                 episode reward: -1.6412,                 loss: nan
agent1:                 episode reward: 1.6412,                 loss: 0.2535
Episode: 23941/30000 (79.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8965s / 1910.3942 s
agent0:                 episode reward: -1.7779,                 loss: nan
agent1:                 episode reward: 1.7779,                 loss: 0.2521
Episode: 23961/30000 (79.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8963s / 1912.2905 s
agent0:                 episode reward: -2.0939,                 loss: nan
agent1:                 episode reward: 2.0939,                 loss: 0.2525
Episode: 23981/30000 (79.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9227s / 1914.2132 s
agent0:                 episode reward: -1.9607,                 loss: nan
agent1:                 episode reward: 1.9607,                 loss: 0.2354
Episode: 24001/30000 (80.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9511s / 1916.1643 s
agent0:                 episode reward: -1.5455,                 loss: nan
agent1:                 episode reward: 1.5455,                 loss: 0.2283
Episode: 24021/30000 (80.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8970s / 1918.0613 s
agent0:                 episode reward: -0.8185,                 loss: nan
agent1:                 episode reward: 0.8185,                 loss: 0.2287
Episode: 24041/30000 (80.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9002s / 1919.9614 s
agent0:                 episode reward: -1.5800,                 loss: nan
agent1:                 episode reward: 1.5800,                 loss: 0.2291
Episode: 24061/30000 (80.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9119s / 1921.8734 s
agent0:                 episode reward: -1.4364,                 loss: nan
agent1:                 episode reward: 1.4364,                 loss: 0.2287
Episode: 24081/30000 (80.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9056s / 1923.7789 s
agent0:                 episode reward: -1.6606,                 loss: nan
agent1:                 episode reward: 1.6606,                 loss: 0.2213
Episode: 24101/30000 (80.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9251s / 1925.7040 s
agent0:                 episode reward: -1.3718,                 loss: nan
agent1:                 episode reward: 1.3718,                 loss: 0.2183
Episode: 24121/30000 (80.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8883s / 1927.5923 s
agent0:                 episode reward: -1.8838,                 loss: nan
agent1:                 episode reward: 1.8838,                 loss: 0.2162
Episode: 24141/30000 (80.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8894s / 1929.4817 s
agent0:                 episode reward: -1.4638,                 loss: nan
agent1:                 episode reward: 1.4638,                 loss: 0.2178
Episode: 24161/30000 (80.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9147s / 1931.3964 s
agent0:                 episode reward: -0.9875,                 loss: nan
agent1:                 episode reward: 0.9875,                 loss: 0.2187
Episode: 24181/30000 (80.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8942s / 1933.2906 s
agent0:                 episode reward: -1.8292,                 loss: nan
agent1:                 episode reward: 1.8292,                 loss: 0.2231
Episode: 24201/30000 (80.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9413s / 1935.2319 s
agent0:                 episode reward: -1.4703,                 loss: nan
agent1:                 episode reward: 1.4703,                 loss: 0.2232
Episode: 24221/30000 (80.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8980s / 1937.1299 s
agent0:                 episode reward: -0.9227,                 loss: nan
agent1:                 episode reward: 0.9227,                 loss: 0.2229
Episode: 24241/30000 (80.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9093s / 1939.0392 s
agent0:                 episode reward: -1.9653,                 loss: nan
agent1:                 episode reward: 1.9653,                 loss: 0.2210
Episode: 24261/30000 (80.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8934s / 1940.9326 s
agent0:                 episode reward: -1.0495,                 loss: nan
agent1:                 episode reward: 1.0495,                 loss: 0.2229
Episode: 24281/30000 (80.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9205s / 1942.8531 s
agent0:                 episode reward: -0.9489,                 loss: nan
agent1:                 episode reward: 0.9489,                 loss: 0.2454
Episode: 24301/30000 (81.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9008s / 1944.7539 s
agent0:                 episode reward: -1.3237,                 loss: nan
agent1:                 episode reward: 1.3237,                 loss: 0.2487
Episode: 24321/30000 (81.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9487s / 1946.7027 s
agent0:                 episode reward: -1.3303,                 loss: nan
agent1:                 episode reward: 1.3303,                 loss: 0.2491
Episode: 24341/30000 (81.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9105s / 1948.6132 s
agent0:                 episode reward: -0.7990,                 loss: nan
agent1:                 episode reward: 0.7990,                 loss: 0.2478
Episode: 24361/30000 (81.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8954s / 1950.5086 s
agent0:                 episode reward: -1.4207,                 loss: nan
agent1:                 episode reward: 1.4207,                 loss: 0.2480
Episode: 24381/30000 (81.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9069s / 1952.4155 s
agent0:                 episode reward: -1.3442,                 loss: nan
agent1:                 episode reward: 1.3442,                 loss: 0.2529
Episode: 24401/30000 (81.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8864s / 1954.3019 s
agent0:                 episode reward: -1.2153,                 loss: nan
agent1:                 episode reward: 1.2153,                 loss: 0.2514
Episode: 24421/30000 (81.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9524s / 1956.2542 s
agent0:                 episode reward: -1.9553,                 loss: nan
agent1:                 episode reward: 1.9553,                 loss: 0.2511
Episode: 24441/30000 (81.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9011s / 1958.1553 s
agent0:                 episode reward: -1.9416,                 loss: nan
agent1:                 episode reward: 1.9416,                 loss: 0.2521
Episode: 24461/30000 (81.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8875s / 1960.0428 s
agent0:                 episode reward: -1.1596,                 loss: nan
agent1:                 episode reward: 1.1596,                 loss: 0.2512
Episode: 24481/30000 (81.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9226s / 1961.9654 s
agent0:                 episode reward: -1.6844,                 loss: nan
agent1:                 episode reward: 1.6844,                 loss: 0.2769
Episode: 24501/30000 (81.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9342s / 1963.8997 s
agent0:                 episode reward: -1.8618,                 loss: nan
agent1:                 episode reward: 1.8618,                 loss: 0.2788
Episode: 24521/30000 (81.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9406s / 1965.8403 s
agent0:                 episode reward: -1.6394,                 loss: nan
agent1:                 episode reward: 1.6394,                 loss: 0.2773
Episode: 24541/30000 (81.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8999s / 1967.7403 s
agent0:                 episode reward: -1.8192,                 loss: nan
agent1:                 episode reward: 1.8192,                 loss: 0.2767
Episode: 24561/30000 (81.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9020s / 1969.6422 s
agent0:                 episode reward: -1.7232,                 loss: nan
agent1:                 episode reward: 1.7232,                 loss: 0.2774
Episode: 24581/30000 (81.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8890s / 1971.5312 s
agent0:                 episode reward: -1.9461,                 loss: nan
agent1:                 episode reward: 1.9461,                 loss: 0.2890
Episode: 24601/30000 (82.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9169s / 1973.4481 s
agent0:                 episode reward: -1.4082,                 loss: nan
agent1:                 episode reward: 1.4082,                 loss: 0.2895
Episode: 24621/30000 (82.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8952s / 1975.3434 s
agent0:                 episode reward: -1.4846,                 loss: nan
agent1:                 episode reward: 1.4846,                 loss: 0.2872
Episode: 24641/30000 (82.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9508s / 1977.2942 s
agent0:                 episode reward: -1.6957,                 loss: nan
agent1:                 episode reward: 1.6957,                 loss: 0.2873
Episode: 24661/30000 (82.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8922s / 1979.1863 s
agent0:                 episode reward: -1.3395,                 loss: nan
agent1:                 episode reward: 1.3395,                 loss: 0.2880
Episode: 24681/30000 (82.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9050s / 1981.0913 s
agent0:                 episode reward: -0.7552,                 loss: nan
agent1:                 episode reward: 0.7552,                 loss: 0.2467
Episode: 24701/30000 (82.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9140s / 1983.0054 s
agent0:                 episode reward: -1.4163,                 loss: nan
agent1:                 episode reward: 1.4163,                 loss: 0.2352
Episode: 24721/30000 (82.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9062s / 1984.9115 s
agent0:                 episode reward: -1.2826,                 loss: nan
agent1:                 episode reward: 1.2826,                 loss: 0.2340
Episode: 24741/30000 (82.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9284s / 1986.8399 s
agent0:                 episode reward: -1.3207,                 loss: nan
agent1:                 episode reward: 1.3207,                 loss: 0.2339
Episode: 24761/30000 (82.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8996s / 1988.7395 s
agent0:                 episode reward: -0.8775,                 loss: nan
agent1:                 episode reward: 0.8775,                 loss: 0.2359
Episode: 24781/30000 (82.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9052s / 1990.6447 s
agent0:                 episode reward: -1.7539,                 loss: nan
agent1:                 episode reward: 1.7539,                 loss: 0.2168
Episode: 24801/30000 (82.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9222s / 1992.5669 s
agent0:                 episode reward: -1.0895,                 loss: nan
agent1:                 episode reward: 1.0895,                 loss: 0.2114
Episode: 24821/30000 (82.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9163s / 1994.4832 s
agent0:                 episode reward: -2.3349,                 loss: nan
agent1:                 episode reward: 2.3349,                 loss: 0.2111
Episode: 24841/30000 (82.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9198s / 1996.4030 s
agent0:                 episode reward: -2.5856,                 loss: nan
agent1:                 episode reward: 2.5856,                 loss: 0.2111
Episode: 24861/30000 (82.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9216s / 1998.3246 s
agent0:                 episode reward: -0.5942,                 loss: nan
agent1:                 episode reward: 0.5942,                 loss: 0.2106
Episode: 24881/30000 (82.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9070s / 2000.2316 s
agent0:                 episode reward: -1.5018,                 loss: nan
agent1:                 episode reward: 1.5018,                 loss: 0.2005
Episode: 24901/30000 (83.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8883s / 2002.1199 s
agent0:                 episode reward: -1.5137,                 loss: nan
agent1:                 episode reward: 1.5137,                 loss: 0.1962
Episode: 24921/30000 (83.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9554s / 2004.0753 s
agent0:                 episode reward: -1.9396,                 loss: nan
agent1:                 episode reward: 1.9396,                 loss: 0.1961
Episode: 24941/30000 (83.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9234s / 2005.9986 s
agent0:                 episode reward: -1.7564,                 loss: nan
agent1:                 episode reward: 1.7564,                 loss: 0.1957
Episode: 24961/30000 (83.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9387s / 2007.9373 s
agent0:                 episode reward: -0.8009,                 loss: nan
agent1:                 episode reward: 0.8009,                 loss: 0.1949
Episode: 24981/30000 (83.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9161s / 2009.8534 s
agent0:                 episode reward: -1.1568,                 loss: nan
agent1:                 episode reward: 1.1568,                 loss: 0.2217
Episode: 25001/30000 (83.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8937s / 2011.7471 s
agent0:                 episode reward: -2.0265,                 loss: nan
agent1:                 episode reward: 2.0265,                 loss: 0.2202
Episode: 25021/30000 (83.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9069s / 2013.6541 s
agent0:                 episode reward: -1.8431,                 loss: nan
agent1:                 episode reward: 1.8431,                 loss: 0.2225
Episode: 25041/30000 (83.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9107s / 2015.5648 s
agent0:                 episode reward: -1.6783,                 loss: nan
agent1:                 episode reward: 1.6783,                 loss: 0.2228
Episode: 25061/30000 (83.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9360s / 2017.5008 s
agent0:                 episode reward: -1.3419,                 loss: nan
agent1:                 episode reward: 1.3419,                 loss: 0.2216
Episode: 25081/30000 (83.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9049s / 2019.4058 s
agent0:                 episode reward: -1.5923,                 loss: nan
agent1:                 episode reward: 1.5923,                 loss: 0.2621
Episode: 25101/30000 (83.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9060s / 2021.3118 s
agent0:                 episode reward: -1.7880,                 loss: nan
agent1:                 episode reward: 1.7880,                 loss: 0.2662
Episode: 25121/30000 (83.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9229s / 2023.2347 s
agent0:                 episode reward: -2.0632,                 loss: nan
agent1:                 episode reward: 2.0632,                 loss: 0.2674
Episode: 25141/30000 (83.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8987s / 2025.1334 s
agent0:                 episode reward: -2.4642,                 loss: nan
agent1:                 episode reward: 2.4642,                 loss: 0.2672
Episode: 25161/30000 (83.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9055s / 2027.0389 s
agent0:                 episode reward: -1.7952,                 loss: nan
agent1:                 episode reward: 1.7952,                 loss: 0.2656
Episode: 25181/30000 (83.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9131s / 2028.9519 s
agent0:                 episode reward: -2.0702,                 loss: nan
agent1:                 episode reward: 2.0702,                 loss: 0.2853
Episode: 25201/30000 (84.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9079s / 2030.8599 s
agent0:                 episode reward: -1.0668,                 loss: nan
agent1:                 episode reward: 1.0668,                 loss: 0.2870
Episode: 25221/30000 (84.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8930s / 2032.7528 s
agent0:                 episode reward: -2.6780,                 loss: nan
agent1:                 episode reward: 2.6780,                 loss: 0.2870
Episode: 25241/30000 (84.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9155s / 2034.6683 s
agent0:                 episode reward: -1.7228,                 loss: nan
agent1:                 episode reward: 1.7228,                 loss: 0.2841
Episode: 25261/30000 (84.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9189s / 2036.5872 s
agent0:                 episode reward: -1.3522,                 loss: nan
agent1:                 episode reward: 1.3522,                 loss: 0.2868
Episode: 25281/30000 (84.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9370s / 2038.5243 s
agent0:                 episode reward: -1.0085,                 loss: nan
agent1:                 episode reward: 1.0085,                 loss: 0.2880
Episode: 25301/30000 (84.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9108s / 2040.4351 s
agent0:                 episode reward: -1.0170,                 loss: nan
agent1:                 episode reward: 1.0170,                 loss: 0.2855
Episode: 25321/30000 (84.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8989s / 2042.3340 s
agent0:                 episode reward: -1.7144,                 loss: nan
agent1:                 episode reward: 1.7144,                 loss: 0.2840
Episode: 25341/30000 (84.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9006s / 2044.2346 s
agent0:                 episode reward: -1.8262,                 loss: nan
agent1:                 episode reward: 1.8262,                 loss: 0.2837
Episode: 25361/30000 (84.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9013s / 2046.1359 s
agent0:                 episode reward: -1.3309,                 loss: nan
agent1:                 episode reward: 1.3309,                 loss: 0.2852
Episode: 25381/30000 (84.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9616s / 2048.0975 s
agent0:                 episode reward: -1.3789,                 loss: nan
agent1:                 episode reward: 1.3789,                 loss: 0.2843
Episode: 25401/30000 (84.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8896s / 2049.9871 s
agent0:                 episode reward: -1.5440,                 loss: nan
agent1:                 episode reward: 1.5440,                 loss: 0.2832
Episode: 25421/30000 (84.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9245s / 2051.9115 s
agent0:                 episode reward: -2.1085,                 loss: nan
agent1:                 episode reward: 2.1085,                 loss: 0.2808
Episode: 25441/30000 (84.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9043s / 2053.8158 s
agent0:                 episode reward: -1.6018,                 loss: nan
agent1:                 episode reward: 1.6018,                 loss: 0.2815
Episode: 25461/30000 (84.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9263s / 2055.7422 s
agent0:                 episode reward: -1.6093,                 loss: nan
agent1:                 episode reward: 1.6093,                 loss: 0.2803
Episode: 25481/30000 (84.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9043s / 2057.6464 s
agent0:                 episode reward: -1.7390,                 loss: nan
agent1:                 episode reward: 1.7390,                 loss: 0.3011
Episode: 25501/30000 (85.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9518s / 2059.5982 s
agent0:                 episode reward: -1.7983,                 loss: nan
agent1:                 episode reward: 1.7983,                 loss: 0.3047
Episode: 25521/30000 (85.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8940s / 2061.4922 s
agent0:                 episode reward: -1.3778,                 loss: nan
agent1:                 episode reward: 1.3778,                 loss: 0.3022
Episode: 25541/30000 (85.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9079s / 2063.4001 s
agent0:                 episode reward: -0.8801,                 loss: nan
agent1:                 episode reward: 0.8801,                 loss: 0.3026
Episode: 25561/30000 (85.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9026s / 2065.3027 s
agent0:                 episode reward: -1.3071,                 loss: nan
agent1:                 episode reward: 1.3071,                 loss: 0.3026
Episode: 25581/30000 (85.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9093s / 2067.2120 s
agent0:                 episode reward: -1.1885,                 loss: nan
agent1:                 episode reward: 1.1885,                 loss: 0.2769
Episode: 25601/30000 (85.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9335s / 2069.1455 s
agent0:                 episode reward: -2.1362,                 loss: nan
agent1:                 episode reward: 2.1362,                 loss: 0.2695
Episode: 25621/30000 (85.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9190s / 2071.0645 s
agent0:                 episode reward: -1.7531,                 loss: nan
agent1:                 episode reward: 1.7531,                 loss: 0.2715
Episode: 25641/30000 (85.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9235s / 2072.9880 s
agent0:                 episode reward: -2.1307,                 loss: nan
agent1:                 episode reward: 2.1307,                 loss: 0.2702
Episode: 25661/30000 (85.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9086s / 2074.8965 s
agent0:                 episode reward: -2.4637,                 loss: nan
agent1:                 episode reward: 2.4637,                 loss: 0.2724
Episode: 25681/30000 (85.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8996s / 2076.7961 s
agent0:                 episode reward: -1.6187,                 loss: nan
agent1:                 episode reward: 1.6187,                 loss: 0.2404
Episode: 25701/30000 (85.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9374s / 2078.7335 s
agent0:                 episode reward: -1.8204,                 loss: nan
agent1:                 episode reward: 1.8204,                 loss: 0.2339
Episode: 25721/30000 (85.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9025s / 2080.6359 s
agent0:                 episode reward: -1.6386,                 loss: nan
agent1:                 episode reward: 1.6386,                 loss: 0.2338
Episode: 25741/30000 (85.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9068s / 2082.5427 s
agent0:                 episode reward: -1.9915,                 loss: nan
agent1:                 episode reward: 1.9915,                 loss: 0.2331
Episode: 25761/30000 (85.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9136s / 2084.4563 s
agent0:                 episode reward: -1.7329,                 loss: nan
agent1:                 episode reward: 1.7329,                 loss: 0.2324
Episode: 25781/30000 (85.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9044s / 2086.3607 s
agent0:                 episode reward: -1.7609,                 loss: nan
agent1:                 episode reward: 1.7609,                 loss: 0.2268
Episode: 25801/30000 (86.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9052s / 2088.2659 s
agent0:                 episode reward: -1.1326,                 loss: nan
agent1:                 episode reward: 1.1326,                 loss: 0.2252
Episode: 25821/30000 (86.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9446s / 2090.2105 s
agent0:                 episode reward: -1.8736,                 loss: nan
agent1:                 episode reward: 1.8736,                 loss: 0.2246
Episode: 25841/30000 (86.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9023s / 2092.1128 s
agent0:                 episode reward: -2.2307,                 loss: nan
agent1:                 episode reward: 2.2307,                 loss: 0.2239
Episode: 25861/30000 (86.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9132s / 2094.0260 s
agent0:                 episode reward: -2.2835,                 loss: nan
agent1:                 episode reward: 2.2835,                 loss: 0.2245
Episode: 25881/30000 (86.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9077s / 2095.9337 s
agent0:                 episode reward: -2.0677,                 loss: nan
agent1:                 episode reward: 2.0677,                 loss: 0.2295
Episode: 25901/30000 (86.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9240s / 2097.8577 s
agent0:                 episode reward: -2.6823,                 loss: nan
agent1:                 episode reward: 2.6823,                 loss: 0.2265
Episode: 25921/30000 (86.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9510s / 2099.8087 s
agent0:                 episode reward: -2.1477,                 loss: nan
agent1:                 episode reward: 2.1477,                 loss: 0.2279
Episode: 25941/30000 (86.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8986s / 2101.7074 s
agent0:                 episode reward: -1.3640,                 loss: nan
agent1:                 episode reward: 1.3640,                 loss: 0.2277
Episode: 25961/30000 (86.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9052s / 2103.6126 s
agent0:                 episode reward: -1.7614,                 loss: nan
agent1:                 episode reward: 1.7614,                 loss: 0.2271
Episode: 25981/30000 (86.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9081s / 2105.5207 s
agent0:                 episode reward: -1.7393,                 loss: nan
agent1:                 episode reward: 1.7393,                 loss: 0.2382
Episode: 26001/30000 (86.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8940s / 2107.4147 s
agent0:                 episode reward: -1.0938,                 loss: nan
agent1:                 episode reward: 1.0938,                 loss: 0.2423
Episode: 26021/30000 (86.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9466s / 2109.3613 s
agent0:                 episode reward: -1.5880,                 loss: nan
agent1:                 episode reward: 1.5880,                 loss: 0.2398
Episode: 26041/30000 (86.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8877s / 2111.2490 s
agent0:                 episode reward: -1.6617,                 loss: nan
agent1:                 episode reward: 1.6617,                 loss: 0.2388
Episode: 26061/30000 (86.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9028s / 2113.1518 s
agent0:                 episode reward: -1.4699,                 loss: nan
agent1:                 episode reward: 1.4699,                 loss: 0.2394
Episode: 26081/30000 (86.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9235s / 2115.0754 s
agent0:                 episode reward: -2.0732,                 loss: nan
agent1:                 episode reward: 2.0732,                 loss: 0.2462
Episode: 26101/30000 (87.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8893s / 2116.9647 s
agent0:                 episode reward: -0.8763,                 loss: nan
agent1:                 episode reward: 0.8763,                 loss: 0.2447
Episode: 26121/30000 (87.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9149s / 2118.8796 s
agent0:                 episode reward: -1.0858,                 loss: nan
agent1:                 episode reward: 1.0858,                 loss: 0.2449
Episode: 26141/30000 (87.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9539s / 2120.8334 s
agent0:                 episode reward: -2.2171,                 loss: nan
agent1:                 episode reward: 2.2171,                 loss: 0.2449
Episode: 26161/30000 (87.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9003s / 2122.7338 s
agent0:                 episode reward: -1.5939,                 loss: nan
agent1:                 episode reward: 1.5939,                 loss: 0.2463
Episode: 26181/30000 (87.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9115s / 2124.6453 s
agent0:                 episode reward: -1.4925,                 loss: nan
agent1:                 episode reward: 1.4925,                 loss: 0.2580
Episode: 26201/30000 (87.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9069s / 2126.5522 s
agent0:                 episode reward: -0.9851,                 loss: nan
agent1:                 episode reward: 0.9851,                 loss: 0.2585
Episode: 26221/30000 (87.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8940s / 2128.4462 s
agent0:                 episode reward: -1.3147,                 loss: nan
agent1:                 episode reward: 1.3147,                 loss: 0.2592
Episode: 26241/30000 (87.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9575s / 2130.4037 s
agent0:                 episode reward: -1.0491,                 loss: nan
agent1:                 episode reward: 1.0491,                 loss: 0.2593
Episode: 26261/30000 (87.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8884s / 2132.2922 s
agent0:                 episode reward: -1.9208,                 loss: nan
agent1:                 episode reward: 1.9208,                 loss: 0.2575
Episode: 26281/30000 (87.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9252s / 2134.2174 s
agent0:                 episode reward: -1.7463,                 loss: nan
agent1:                 episode reward: 1.7463,                 loss: 0.2805
Episode: 26301/30000 (87.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9051s / 2136.1225 s
agent0:                 episode reward: -1.9316,                 loss: nan
agent1:                 episode reward: 1.9316,                 loss: 0.2824
Episode: 26321/30000 (87.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8981s / 2138.0205 s
agent0:                 episode reward: -1.8906,                 loss: nan
agent1:                 episode reward: 1.8906,                 loss: 0.2827
Episode: 26341/30000 (87.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9629s / 2139.9834 s
agent0:                 episode reward: -1.5162,                 loss: nan
agent1:                 episode reward: 1.5162,                 loss: 0.2814
Episode: 26361/30000 (87.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8976s / 2141.8810 s
agent0:                 episode reward: -1.9777,                 loss: nan
agent1:                 episode reward: 1.9777,                 loss: 0.2820
Episode: 26381/30000 (87.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8888s / 2143.7698 s
agent0:                 episode reward: -1.5315,                 loss: nan
agent1:                 episode reward: 1.5315,                 loss: 0.2778
Episode: 26401/30000 (88.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9173s / 2145.6871 s
agent0:                 episode reward: -1.2756,                 loss: nan
agent1:                 episode reward: 1.2756,                 loss: 0.2767
Episode: 26421/30000 (88.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9162s / 2147.6033 s
agent0:                 episode reward: -1.4392,                 loss: nan
agent1:                 episode reward: 1.4392,                 loss: 0.2742
Episode: 26441/30000 (88.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9010s / 2149.5043 s
agent0:                 episode reward: -1.8890,                 loss: nan
agent1:                 episode reward: 1.8890,                 loss: 0.2748
Episode: 26461/30000 (88.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9700s / 2151.4743 s
agent0:                 episode reward: -1.2764,                 loss: nan
agent1:                 episode reward: 1.2764,                 loss: 0.2763
Episode: 26481/30000 (88.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9054s / 2153.3797 s
agent0:                 episode reward: -1.7875,                 loss: nan
agent1:                 episode reward: 1.7875,                 loss: 0.2814
Episode: 26501/30000 (88.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9298s / 2155.3095 s
agent0:                 episode reward: -2.0315,                 loss: nan
agent1:                 episode reward: 2.0315,                 loss: 0.2801
Episode: 26521/30000 (88.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9091s / 2157.2186 s
agent0:                 episode reward: -2.3955,                 loss: nan
agent1:                 episode reward: 2.3955,                 loss: 0.2792
Episode: 26541/30000 (88.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8999s / 2159.1185 s
agent0:                 episode reward: -1.1998,                 loss: nan
agent1:                 episode reward: 1.1998,                 loss: 0.2783
Episode: 26561/30000 (88.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9565s / 2161.0750 s
agent0:                 episode reward: -1.8640,                 loss: nan
agent1:                 episode reward: 1.8640,                 loss: 0.2808
Episode: 26581/30000 (88.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9079s / 2162.9829 s
agent0:                 episode reward: -1.9173,                 loss: nan
agent1:                 episode reward: 1.9173,                 loss: 0.2767
Episode: 26601/30000 (88.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9248s / 2164.9077 s
agent0:                 episode reward: -1.0909,                 loss: nan
agent1:                 episode reward: 1.0909,                 loss: 0.2745
Episode: 26621/30000 (88.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9178s / 2166.8255 s
agent0:                 episode reward: -1.4598,                 loss: nan
agent1:                 episode reward: 1.4598,                 loss: 0.2737
Episode: 26641/30000 (88.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9212s / 2168.7467 s
agent0:                 episode reward: -1.6446,                 loss: nan
agent1:                 episode reward: 1.6446,                 loss: 0.2739
Episode: 26661/30000 (88.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9428s / 2170.6895 s
agent0:                 episode reward: -2.0111,                 loss: nan
agent1:                 episode reward: 2.0111,                 loss: 0.2738
Episode: 26681/30000 (88.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9386s / 2172.6281 s
agent0:                 episode reward: -1.7143,                 loss: nan
agent1:                 episode reward: 1.7143,                 loss: 0.2654
Episode: 26701/30000 (89.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9072s / 2174.5353 s
agent0:                 episode reward: -2.3092,                 loss: nan
agent1:                 episode reward: 2.3092,                 loss: 0.2630
Episode: 26721/30000 (89.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9177s / 2176.4530 s
agent0:                 episode reward: -1.9159,                 loss: nan
agent1:                 episode reward: 1.9159,                 loss: 0.2635
Episode: 26741/30000 (89.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9194s / 2178.3724 s
agent0:                 episode reward: -0.9150,                 loss: nan
agent1:                 episode reward: 0.9150,                 loss: 0.2652
Episode: 26761/30000 (89.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9145s / 2180.2869 s
agent0:                 episode reward: -1.6920,                 loss: nan
agent1:                 episode reward: 1.6920,                 loss: 0.2627
Episode: 26781/30000 (89.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9434s / 2182.2302 s
agent0:                 episode reward: -1.3446,                 loss: nan
agent1:                 episode reward: 1.3446,                 loss: 0.2581
Episode: 26801/30000 (89.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9341s / 2184.1644 s
agent0:                 episode reward: -2.1204,                 loss: nan
agent1:                 episode reward: 2.1204,                 loss: 0.2524
Episode: 26821/30000 (89.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9155s / 2186.0799 s
agent0:                 episode reward: -1.9824,                 loss: nan
agent1:                 episode reward: 1.9824,                 loss: 0.2537
Episode: 26841/30000 (89.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9236s / 2188.0035 s
agent0:                 episode reward: -0.8975,                 loss: nan
agent1:                 episode reward: 0.8975,                 loss: 0.2532
Episode: 26861/30000 (89.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9432s / 2189.9466 s
agent0:                 episode reward: -1.4418,                 loss: nan
agent1:                 episode reward: 1.4418,                 loss: 0.2520
Episode: 26881/30000 (89.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9658s / 2191.9124 s
agent0:                 episode reward: -1.3568,                 loss: nan
agent1:                 episode reward: 1.3568,                 loss: 0.2722
Episode: 26901/30000 (89.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9234s / 2193.8358 s
agent0:                 episode reward: -1.5679,                 loss: nan
agent1:                 episode reward: 1.5679,                 loss: 0.2734
Episode: 26921/30000 (89.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9193s / 2195.7552 s
agent0:                 episode reward: -2.1607,                 loss: nan
agent1:                 episode reward: 2.1607,                 loss: 0.2724
Episode: 26941/30000 (89.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9255s / 2197.6807 s
agent0:                 episode reward: -2.3578,                 loss: nan
agent1:                 episode reward: 2.3578,                 loss: 0.2717
Episode: 26961/30000 (89.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9240s / 2199.6046 s
agent0:                 episode reward: -1.7058,                 loss: nan
agent1:                 episode reward: 1.7058,                 loss: 0.2724
Episode: 26981/30000 (89.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9408s / 2201.5454 s
agent0:                 episode reward: -1.0646,                 loss: nan
agent1:                 episode reward: 1.0646,                 loss: 0.2729
Episode: 27001/30000 (90.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9154s / 2203.4609 s
agent0:                 episode reward: -0.7633,                 loss: nan
agent1:                 episode reward: 0.7633,                 loss: 0.2687
Episode: 27021/30000 (90.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9500s / 2205.4109 s
agent0:                 episode reward: -2.1353,                 loss: nan
agent1:                 episode reward: 2.1353,                 loss: 0.2672
Episode: 27041/30000 (90.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9253s / 2207.3361 s
agent0:                 episode reward: -2.2544,                 loss: nan
agent1:                 episode reward: 2.2544,                 loss: 0.2658
Episode: 27061/30000 (90.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9217s / 2209.2579 s
agent0:                 episode reward: -1.8248,                 loss: nan
agent1:                 episode reward: 1.8248,                 loss: 0.2673
Episode: 27081/30000 (90.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9348s / 2211.1927 s
agent0:                 episode reward: -1.8208,                 loss: nan
agent1:                 episode reward: 1.8208,                 loss: 0.2710
Episode: 27101/30000 (90.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9480s / 2213.1406 s
agent0:                 episode reward: -0.9947,                 loss: nan
agent1:                 episode reward: 0.9947,                 loss: 0.2674
Episode: 27121/30000 (90.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9453s / 2215.0859 s
agent0:                 episode reward: -1.4079,                 loss: nan
agent1:                 episode reward: 1.4079,                 loss: 0.2652
Episode: 27141/30000 (90.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9134s / 2216.9993 s
agent0:                 episode reward: -1.7217,                 loss: nan
agent1:                 episode reward: 1.7217,                 loss: 0.2675
Episode: 27161/30000 (90.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9135s / 2218.9128 s
agent0:                 episode reward: -1.7258,                 loss: nan
agent1:                 episode reward: 1.7258,                 loss: 0.2664
Episode: 27181/30000 (90.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9374s / 2220.8502 s
agent0:                 episode reward: -0.4616,                 loss: nan
agent1:                 episode reward: 0.4616,                 loss: 0.2657
Episode: 27201/30000 (90.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9691s / 2222.8193 s
agent0:                 episode reward: -1.1015,                 loss: nan
agent1:                 episode reward: 1.1015,                 loss: 0.2615
Episode: 27221/30000 (90.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9253s / 2224.7445 s
agent0:                 episode reward: -1.5875,                 loss: nan
agent1:                 episode reward: 1.5875,                 loss: 0.2606
Episode: 27241/30000 (90.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9299s / 2226.6745 s
agent0:                 episode reward: -1.8758,                 loss: nan
agent1:                 episode reward: 1.8758,                 loss: 0.2604
Episode: 27261/30000 (90.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9172s / 2228.5917 s
agent0:                 episode reward: -1.3812,                 loss: nan
agent1:                 episode reward: 1.3812,                 loss: 0.2619
Episode: 27281/30000 (90.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9355s / 2230.5272 s
agent0:                 episode reward: -1.6151,                 loss: nan
agent1:                 episode reward: 1.6151,                 loss: 0.2860
Episode: 27301/30000 (91.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9538s / 2232.4810 s
agent0:                 episode reward: -1.1348,                 loss: nan
agent1:                 episode reward: 1.1348,                 loss: 0.2906
Episode: 27321/30000 (91.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9157s / 2234.3967 s
agent0:                 episode reward: -1.4815,                 loss: nan
agent1:                 episode reward: 1.4815,                 loss: 0.2910
Episode: 27341/30000 (91.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9388s / 2236.3355 s
agent0:                 episode reward: -1.6104,                 loss: nan
agent1:                 episode reward: 1.6104,                 loss: 0.2891
Episode: 27361/30000 (91.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9397s / 2238.2752 s
agent0:                 episode reward: -1.4505,                 loss: nan
agent1:                 episode reward: 1.4505,                 loss: 0.2896
Episode: 27381/30000 (91.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9199s / 2240.1951 s
agent0:                 episode reward: -1.0969,                 loss: nan
agent1:                 episode reward: 1.0969,                 loss: 0.2738
Episode: 27401/30000 (91.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9568s / 2242.1519 s
agent0:                 episode reward: -2.4622,                 loss: nan
agent1:                 episode reward: 2.4622,                 loss: 0.2679
Episode: 27421/30000 (91.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9147s / 2244.0666 s
agent0:                 episode reward: -1.4972,                 loss: nan
agent1:                 episode reward: 1.4972,                 loss: 0.2697
Episode: 27441/30000 (91.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9200s / 2245.9866 s
agent0:                 episode reward: -1.2068,                 loss: nan
agent1:                 episode reward: 1.2068,                 loss: 0.2690
Episode: 27461/30000 (91.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9504s / 2247.9371 s
agent0:                 episode reward: -2.0562,                 loss: nan
agent1:                 episode reward: 2.0562,                 loss: 0.2678
Episode: 27481/30000 (91.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9083s / 2249.8454 s
agent0:                 episode reward: -1.4627,                 loss: nan
agent1:                 episode reward: 1.4627,                 loss: 0.2743
Episode: 27501/30000 (91.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9439s / 2251.7893 s
agent0:                 episode reward: -1.1230,                 loss: nan
agent1:                 episode reward: 1.1230,                 loss: 0.2716
Episode: 27521/30000 (91.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9675s / 2253.7568 s
agent0:                 episode reward: -1.1492,                 loss: nan
agent1:                 episode reward: 1.1492,                 loss: 0.2730
Episode: 27541/30000 (91.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9456s / 2255.7024 s
agent0:                 episode reward: -1.4317,                 loss: nan
agent1:                 episode reward: 1.4317,                 loss: 0.2709
Episode: 27561/30000 (91.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9179s / 2257.6203 s
agent0:                 episode reward: -1.7487,                 loss: nan
agent1:                 episode reward: 1.7487,                 loss: 0.2719
Episode: 27581/30000 (91.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9160s / 2259.5362 s
agent0:                 episode reward: -2.0362,                 loss: nan
agent1:                 episode reward: 2.0362,                 loss: 0.2553
Episode: 27601/30000 (92.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9145s / 2261.4507 s
agent0:                 episode reward: -1.8461,                 loss: nan
agent1:                 episode reward: 1.8461,                 loss: 0.2501
Episode: 27621/30000 (92.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0079s / 2263.4586 s
agent0:                 episode reward: -1.4620,                 loss: nan
agent1:                 episode reward: 1.4620,                 loss: 0.2503
Episode: 27641/30000 (92.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9342s / 2265.3928 s
agent0:                 episode reward: -1.3128,                 loss: nan
agent1:                 episode reward: 1.3128,                 loss: 0.2499
Episode: 27661/30000 (92.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9200s / 2267.3128 s
agent0:                 episode reward: -1.8978,                 loss: nan
agent1:                 episode reward: 1.8978,                 loss: 0.2508
Episode: 27681/30000 (92.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9225s / 2269.2354 s
agent0:                 episode reward: -2.4842,                 loss: nan
agent1:                 episode reward: 2.4842,                 loss: 0.2496
Episode: 27701/30000 (92.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9283s / 2271.1637 s
agent0:                 episode reward: -1.4857,                 loss: nan
agent1:                 episode reward: 1.4857,                 loss: 0.2478
Episode: 27721/30000 (92.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9808s / 2273.1445 s
agent0:                 episode reward: -1.6486,                 loss: nan
agent1:                 episode reward: 1.6486,                 loss: 0.2453
Episode: 27741/30000 (92.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9366s / 2275.0812 s
agent0:                 episode reward: -2.1074,                 loss: nan
agent1:                 episode reward: 2.1074,                 loss: 0.2493
Episode: 27761/30000 (92.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9231s / 2277.0043 s
agent0:                 episode reward: -2.3158,                 loss: nan
agent1:                 episode reward: 2.3158,                 loss: 0.2462
Episode: 27781/30000 (92.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9326s / 2278.9369 s
agent0:                 episode reward: -1.7388,                 loss: nan
agent1:                 episode reward: 1.7388,                 loss: 0.2730
Episode: 27801/30000 (92.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9647s / 2280.9017 s
agent0:                 episode reward: -1.9547,                 loss: nan
agent1:                 episode reward: 1.9547,                 loss: 0.2757
Episode: 27821/30000 (92.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9542s / 2282.8559 s
agent0:                 episode reward: -2.7566,                 loss: nan
agent1:                 episode reward: 2.7566,                 loss: 0.2759
Episode: 27841/30000 (92.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9455s / 2284.8014 s
agent0:                 episode reward: -1.7991,                 loss: nan
agent1:                 episode reward: 1.7991,                 loss: 0.2782
Episode: 27861/30000 (92.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9332s / 2286.7346 s
agent0:                 episode reward: -1.6174,                 loss: nan
agent1:                 episode reward: 1.6174,                 loss: 0.2766
Episode: 27881/30000 (92.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9349s / 2288.6696 s
agent0:                 episode reward: -0.8844,                 loss: nan
agent1:                 episode reward: 0.8844,                 loss: 0.2813
Episode: 27901/30000 (93.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9357s / 2290.6053 s
agent0:                 episode reward: -1.6303,                 loss: nan
agent1:                 episode reward: 1.6303,                 loss: 0.2814
Episode: 27921/30000 (93.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9213s / 2292.5266 s
agent0:                 episode reward: -1.7727,                 loss: nan
agent1:                 episode reward: 1.7727,                 loss: 0.2815
Episode: 27941/30000 (93.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9624s / 2294.4890 s
agent0:                 episode reward: -1.9456,                 loss: nan
agent1:                 episode reward: 1.9456,                 loss: 0.2793
Episode: 27961/30000 (93.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9414s / 2296.4304 s
agent0:                 episode reward: -1.4903,                 loss: nan
agent1:                 episode reward: 1.4903,                 loss: 0.2799
Episode: 27981/30000 (93.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9657s / 2298.3961 s
agent0:                 episode reward: -1.2294,                 loss: nan
agent1:                 episode reward: 1.2294,                 loss: 0.2739
Episode: 28001/30000 (93.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9177s / 2300.3138 s
agent0:                 episode reward: -1.3430,                 loss: nan
agent1:                 episode reward: 1.3430,                 loss: 0.2691
Episode: 28021/30000 (93.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9501s / 2302.2639 s
agent0:                 episode reward: -1.9697,                 loss: nan
agent1:                 episode reward: 1.9697,                 loss: 0.2724
Episode: 28041/30000 (93.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9584s / 2304.2222 s
agent0:                 episode reward: -1.6608,                 loss: nan
agent1:                 episode reward: 1.6608,                 loss: 0.2687
Episode: 28061/30000 (93.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9498s / 2306.1720 s
agent0:                 episode reward: -2.2321,                 loss: nan
agent1:                 episode reward: 2.2321,                 loss: 0.2716
Episode: 28081/30000 (93.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9250s / 2308.0970 s
agent0:                 episode reward: -1.6127,                 loss: nan
agent1:                 episode reward: 1.6127,                 loss: 0.2912
Episode: 28101/30000 (93.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9241s / 2310.0211 s
agent0:                 episode reward: -2.3142,                 loss: nan
agent1:                 episode reward: 2.3142,                 loss: 0.2922
Episode: 28121/30000 (93.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9339s / 2311.9550 s
agent0:                 episode reward: -2.0103,                 loss: nan
agent1:                 episode reward: 2.0103,                 loss: 0.2930
Episode: 28141/30000 (93.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0055s / 2313.9604 s
agent0:                 episode reward: -2.4554,                 loss: nan
agent1:                 episode reward: 2.4554,                 loss: 0.2931
Episode: 28161/30000 (93.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9233s / 2315.8837 s
agent0:                 episode reward: -1.2523,                 loss: nan
agent1:                 episode reward: 1.2523,                 loss: 0.2948
Episode: 28181/30000 (93.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9295s / 2317.8132 s
agent0:                 episode reward: -2.3217,                 loss: nan
agent1:                 episode reward: 2.3217,                 loss: 0.2960
Episode: 28201/30000 (94.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9119s / 2319.7251 s
agent0:                 episode reward: -1.8113,                 loss: nan
agent1:                 episode reward: 1.8113,                 loss: 0.2947
Episode: 28221/30000 (94.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9335s / 2321.6585 s
agent0:                 episode reward: -1.8882,                 loss: nan
agent1:                 episode reward: 1.8882,                 loss: 0.2928
Episode: 28241/30000 (94.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9371s / 2323.5956 s
agent0:                 episode reward: -1.4746,                 loss: nan
agent1:                 episode reward: 1.4746,                 loss: 0.2918
Episode: 28261/30000 (94.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9752s / 2325.5708 s
agent0:                 episode reward: -1.6055,                 loss: nan
agent1:                 episode reward: 1.6055,                 loss: 0.2948
Episode: 28281/30000 (94.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9432s / 2327.5140 s
agent0:                 episode reward: -1.2498,                 loss: nan
agent1:                 episode reward: 1.2498,                 loss: 0.2804
Episode: 28301/30000 (94.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9273s / 2329.4414 s
agent0:                 episode reward: -1.5147,                 loss: nan
agent1:                 episode reward: 1.5147,                 loss: 0.2781
Episode: 28321/30000 (94.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9490s / 2331.3903 s
agent0:                 episode reward: -1.8274,                 loss: nan
agent1:                 episode reward: 1.8274,                 loss: 0.2765
Episode: 28341/30000 (94.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9209s / 2333.3113 s
agent0:                 episode reward: -1.9702,                 loss: nan
agent1:                 episode reward: 1.9702,                 loss: 0.2773
Episode: 28361/30000 (94.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9882s / 2335.2994 s
agent0:                 episode reward: -1.3528,                 loss: nan
agent1:                 episode reward: 1.3528,                 loss: 0.2763
Episode: 28381/30000 (94.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9339s / 2337.2333 s
agent0:                 episode reward: -1.3831,                 loss: nan
agent1:                 episode reward: 1.3831,                 loss: 0.2712
Episode: 28401/30000 (94.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9368s / 2339.1701 s
agent0:                 episode reward: -1.3114,                 loss: nan
agent1:                 episode reward: 1.3114,                 loss: 0.2681
Episode: 28421/30000 (94.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9306s / 2341.1007 s
agent0:                 episode reward: -1.5552,                 loss: nan
agent1:                 episode reward: 1.5552,                 loss: 0.2687
Episode: 28441/30000 (94.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9223s / 2343.0230 s
agent0:                 episode reward: -1.1825,                 loss: nan
agent1:                 episode reward: 1.1825,                 loss: 0.2693
Episode: 28461/30000 (94.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9636s / 2344.9866 s
agent0:                 episode reward: -1.8269,                 loss: nan
agent1:                 episode reward: 1.8269,                 loss: 0.2679
Episode: 28481/30000 (94.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9549s / 2346.9415 s
agent0:                 episode reward: -2.0170,                 loss: nan
agent1:                 episode reward: 2.0170,                 loss: 0.2641
Episode: 28501/30000 (95.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9161s / 2348.8576 s
agent0:                 episode reward: -1.2362,                 loss: nan
agent1:                 episode reward: 1.2362,                 loss: 0.2632
Episode: 28521/30000 (95.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9248s / 2350.7824 s
agent0:                 episode reward: -2.0962,                 loss: nan
agent1:                 episode reward: 2.0962,                 loss: 0.2634
Episode: 28541/30000 (95.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9302s / 2352.7126 s
agent0:                 episode reward: -1.7257,                 loss: nan
agent1:                 episode reward: 1.7257,                 loss: 0.2625
Episode: 28561/30000 (95.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9760s / 2354.6887 s
agent0:                 episode reward: -1.1632,                 loss: nan
agent1:                 episode reward: 1.1632,                 loss: 0.2610
Episode: 28581/30000 (95.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9364s / 2356.6250 s
agent0:                 episode reward: -1.2934,                 loss: nan
agent1:                 episode reward: 1.2934,                 loss: 0.2557
Episode: 28601/30000 (95.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9381s / 2358.5631 s
agent0:                 episode reward: -1.3196,                 loss: nan
agent1:                 episode reward: 1.3196,                 loss: 0.2548
Episode: 28621/30000 (95.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9214s / 2360.4845 s
agent0:                 episode reward: -1.7405,                 loss: nan
agent1:                 episode reward: 1.7405,                 loss: 0.2545
Episode: 28641/30000 (95.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9261s / 2362.4106 s
agent0:                 episode reward: -1.8949,                 loss: nan
agent1:                 episode reward: 1.8949,                 loss: 0.2537
Episode: 28661/30000 (95.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9457s / 2364.3562 s
agent0:                 episode reward: -0.8626,                 loss: nan
agent1:                 episode reward: 0.8626,                 loss: 0.2545
Episode: 28681/30000 (95.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9744s / 2366.3307 s
agent0:                 episode reward: -1.3832,                 loss: nan
agent1:                 episode reward: 1.3832,                 loss: 0.2560
Episode: 28701/30000 (95.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9399s / 2368.2705 s
agent0:                 episode reward: -1.4832,                 loss: nan
agent1:                 episode reward: 1.4832,                 loss: 0.2544
Episode: 28721/30000 (95.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9174s / 2370.1879 s
agent0:                 episode reward: -1.7754,                 loss: nan
agent1:                 episode reward: 1.7754,                 loss: 0.2544
Episode: 28741/30000 (95.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9409s / 2372.1288 s
agent0:                 episode reward: -1.2544,                 loss: nan
agent1:                 episode reward: 1.2544,                 loss: 0.2541
Episode: 28761/30000 (95.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9378s / 2374.0666 s
agent0:                 episode reward: -2.0413,                 loss: nan
agent1:                 episode reward: 2.0413,                 loss: 0.2555
Episode: 28781/30000 (95.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9667s / 2376.0333 s
agent0:                 episode reward: -1.8340,                 loss: nan
agent1:                 episode reward: 1.8340,                 loss: 0.2570
Episode: 28801/30000 (96.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9400s / 2377.9733 s
agent0:                 episode reward: -2.0650,                 loss: nan
agent1:                 episode reward: 2.0650,                 loss: 0.2562
Episode: 28821/30000 (96.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9450s / 2379.9183 s
agent0:                 episode reward: -1.8370,                 loss: nan
agent1:                 episode reward: 1.8370,                 loss: 0.2558
Episode: 28841/30000 (96.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9321s / 2381.8504 s
agent0:                 episode reward: -1.5176,                 loss: nan
agent1:                 episode reward: 1.5176,                 loss: 0.2563
Episode: 28861/30000 (96.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9287s / 2383.7791 s
agent0:                 episode reward: -1.3212,                 loss: nan
agent1:                 episode reward: 1.3212,                 loss: 0.2554
Episode: 28881/30000 (96.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9824s / 2385.7615 s
agent0:                 episode reward: -1.8842,                 loss: nan
agent1:                 episode reward: 1.8842,                 loss: 0.2573
Episode: 28901/30000 (96.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9272s / 2387.6887 s
agent0:                 episode reward: -1.7585,                 loss: nan
agent1:                 episode reward: 1.7585,                 loss: 0.2583
Episode: 28921/30000 (96.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9585s / 2389.6472 s
agent0:                 episode reward: -1.5919,                 loss: nan
agent1:                 episode reward: 1.5919,                 loss: 0.2593
Episode: 28941/30000 (96.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9424s / 2391.5897 s
agent0:                 episode reward: -1.3652,                 loss: nan
agent1:                 episode reward: 1.3652,                 loss: 0.2573
Episode: 28961/30000 (96.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9261s / 2393.5158 s
agent0:                 episode reward: -1.7082,                 loss: nan
agent1:                 episode reward: 1.7082,                 loss: 0.2590
Episode: 28981/30000 (96.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9712s / 2395.4871 s
agent0:                 episode reward: -1.3988,                 loss: nan
agent1:                 episode reward: 1.3988,                 loss: 0.2953
Episode: 29001/30000 (96.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9533s / 2397.4404 s
agent0:                 episode reward: -1.0740,                 loss: nan
agent1:                 episode reward: 1.0740,                 loss: 0.3005
Episode: 29021/30000 (96.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9287s / 2399.3691 s
agent0:                 episode reward: -0.7152,                 loss: nan
agent1:                 episode reward: 0.7152,                 loss: 0.3014
Episode: 29041/30000 (96.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9375s / 2401.3065 s
agent0:                 episode reward: -1.4434,                 loss: nan
agent1:                 episode reward: 1.4434,                 loss: 0.3020
Episode: 29061/30000 (96.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9233s / 2403.2298 s
agent0:                 episode reward: -1.5848,                 loss: nan
agent1:                 episode reward: 1.5848,                 loss: 0.3020
Episode: 29081/30000 (96.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9550s / 2405.1848 s
agent0:                 episode reward: -2.2797,                 loss: nan
agent1:                 episode reward: 2.2797,                 loss: 0.3059
Episode: 29101/30000 (97.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0009s / 2407.1858 s
agent0:                 episode reward: -1.5466,                 loss: nan
agent1:                 episode reward: 1.5466,                 loss: 0.3053
Episode: 29121/30000 (97.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9394s / 2409.1251 s
agent0:                 episode reward: -1.3667,                 loss: nan
agent1:                 episode reward: 1.3667,                 loss: 0.3052
Episode: 29141/30000 (97.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9397s / 2411.0649 s
agent0:                 episode reward: -1.8228,                 loss: nan
agent1:                 episode reward: 1.8228,                 loss: 0.3064
Episode: 29161/30000 (97.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9585s / 2413.0233 s
agent0:                 episode reward: -1.5315,                 loss: nan
agent1:                 episode reward: 1.5315,                 loss: 0.3050
Episode: 29181/30000 (97.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9329s / 2414.9562 s
agent0:                 episode reward: -1.4835,                 loss: nan
agent1:                 episode reward: 1.4835,                 loss: 0.2881
Episode: 29201/30000 (97.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9721s / 2416.9282 s
agent0:                 episode reward: -1.8257,                 loss: nan
agent1:                 episode reward: 1.8257,                 loss: 0.2854
Episode: 29221/30000 (97.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9413s / 2418.8695 s
agent0:                 episode reward: -2.1326,                 loss: nan
agent1:                 episode reward: 2.1326,                 loss: 0.2849
Episode: 29241/30000 (97.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9175s / 2420.7870 s
agent0:                 episode reward: -1.5971,                 loss: nan
agent1:                 episode reward: 1.5971,                 loss: 0.2867
Episode: 29261/30000 (97.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9647s / 2422.7517 s
agent0:                 episode reward: -2.6775,                 loss: nan
agent1:                 episode reward: 2.6775,                 loss: 0.2860
Episode: 29281/30000 (97.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9180s / 2424.6697 s
agent0:                 episode reward: -1.0811,                 loss: nan
agent1:                 episode reward: 1.0811,                 loss: 0.2663
Episode: 29301/30000 (97.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9638s / 2426.6335 s
agent0:                 episode reward: -1.8701,                 loss: nan
agent1:                 episode reward: 1.8701,                 loss: 0.2623
Episode: 29321/30000 (97.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9634s / 2428.5968 s
agent0:                 episode reward: -1.9165,                 loss: nan
agent1:                 episode reward: 1.9165,                 loss: 0.2587
Episode: 29341/30000 (97.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9520s / 2430.5488 s
agent0:                 episode reward: -1.7813,                 loss: nan
agent1:                 episode reward: 1.7813,                 loss: 0.2628
Episode: 29361/30000 (97.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9333s / 2432.4821 s
agent0:                 episode reward: -1.6677,                 loss: nan
agent1:                 episode reward: 1.6677,                 loss: 0.2607
Episode: 29381/30000 (97.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9419s / 2434.4240 s
agent0:                 episode reward: -1.5250,                 loss: nan
agent1:                 episode reward: 1.5250,                 loss: 0.2514
Episode: 29401/30000 (98.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9963s / 2436.4202 s
agent0:                 episode reward: -1.7290,                 loss: nan
agent1:                 episode reward: 1.7290,                 loss: 0.2458
Episode: 29421/30000 (98.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9626s / 2438.3828 s
agent0:                 episode reward: -1.1969,                 loss: nan
agent1:                 episode reward: 1.1969,                 loss: 0.2465
Episode: 29441/30000 (98.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9484s / 2440.3312 s
agent0:                 episode reward: -1.6828,                 loss: nan
agent1:                 episode reward: 1.6828,                 loss: 0.2458
Episode: 29461/30000 (98.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9296s / 2442.2608 s
agent0:                 episode reward: -2.0600,                 loss: nan
agent1:                 episode reward: 2.0600,                 loss: 0.2441
Episode: 29481/30000 (98.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9350s / 2444.1959 s
agent0:                 episode reward: -1.2774,                 loss: nan
agent1:                 episode reward: 1.2774,                 loss: 0.2222
Episode: 29501/30000 (98.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9487s / 2446.1446 s
agent0:                 episode reward: -2.0821,                 loss: nan
agent1:                 episode reward: 2.0821,                 loss: 0.2152
Episode: 29521/30000 (98.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9833s / 2448.1278 s
agent0:                 episode reward: -1.8022,                 loss: nan
agent1:                 episode reward: 1.8022,                 loss: 0.2128
Episode: 29541/30000 (98.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9340s / 2450.0619 s
agent0:                 episode reward: -2.1153,                 loss: nan
agent1:                 episode reward: 2.1153,                 loss: 0.2135
Episode: 29561/30000 (98.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9272s / 2451.9890 s/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

agent0:                 episode reward: -1.7331,                 loss: nan
agent1:                 episode reward: 1.7331,                 loss: 0.2136
Episode: 29581/30000 (98.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9274s / 2453.9164 s
agent0:                 episode reward: -1.2496,                 loss: nan
agent1:                 episode reward: 1.2496,                 loss: 0.2293
Episode: 29601/30000 (98.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9457s / 2455.8622 s
agent0:                 episode reward: -1.7736,                 loss: nan
agent1:                 episode reward: 1.7736,                 loss: 0.2281
Episode: 29621/30000 (98.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9707s / 2457.8329 s
agent0:                 episode reward: -1.4832,                 loss: nan
agent1:                 episode reward: 1.4832,                 loss: 0.2273
Episode: 29641/30000 (98.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9349s / 2459.7678 s
agent0:                 episode reward: -2.5337,                 loss: nan
agent1:                 episode reward: 2.5337,                 loss: 0.2272
Episode: 29661/30000 (98.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9202s / 2461.6880 s
agent0:                 episode reward: -3.0149,                 loss: nan
agent1:                 episode reward: 3.0149,                 loss: 0.2298
Episode: 29681/30000 (98.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9465s / 2463.6345 s
agent0:                 episode reward: -0.6980,                 loss: nan
agent1:                 episode reward: 0.6980,                 loss: 0.2752
Episode: 29701/30000 (99.0033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9209s / 2465.5554 s
agent0:                 episode reward: -1.0452,                 loss: nan
agent1:                 episode reward: 1.0452,                 loss: 0.2818
Episode: 29721/30000 (99.0700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9960s / 2467.5514 s
agent0:                 episode reward: -2.1744,                 loss: nan
agent1:                 episode reward: 2.1744,                 loss: 0.2821
Episode: 29741/30000 (99.1367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9441s / 2469.4955 s
agent0:                 episode reward: -1.8332,                 loss: nan
agent1:                 episode reward: 1.8332,                 loss: 0.2815
Episode: 29761/30000 (99.2033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9517s / 2471.4472 s
agent0:                 episode reward: -1.6369,                 loss: nan
agent1:                 episode reward: 1.6369,                 loss: 0.2834
Episode: 29781/30000 (99.2700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9340s / 2473.3812 s
agent0:                 episode reward: -2.0281,                 loss: nan
agent1:                 episode reward: 2.0281,                 loss: 0.2749
Episode: 29801/30000 (99.3367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9494s / 2475.3306 s
agent0:                 episode reward: -1.3498,                 loss: nan
agent1:                 episode reward: 1.3498,                 loss: 0.2709
Episode: 29821/30000 (99.4033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9641s / 2477.2948 s
agent0:                 episode reward: -2.0919,                 loss: nan
agent1:                 episode reward: 2.0919,                 loss: 0.2701
Episode: 29841/30000 (99.4700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9543s / 2479.2491 s
agent0:                 episode reward: -2.0261,                 loss: nan
agent1:                 episode reward: 2.0261,                 loss: 0.2692
Episode: 29861/30000 (99.5367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9309s / 2481.1800 s
agent0:                 episode reward: -1.3420,                 loss: nan
agent1:                 episode reward: 1.3420,                 loss: 0.2703
Episode: 29881/30000 (99.6033%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9363s / 2483.1163 s
agent0:                 episode reward: -1.4826,                 loss: nan
agent1:                 episode reward: 1.4826,                 loss: 0.2787
Episode: 29901/30000 (99.6700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9382s / 2485.0545 s
agent0:                 episode reward: -1.5708,                 loss: nan
agent1:                 episode reward: 1.5708,                 loss: 0.2775
Episode: 29921/30000 (99.7367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9192s / 2486.9736 s
agent0:                 episode reward: -1.1961,                 loss: nan
agent1:                 episode reward: 1.1961,                 loss: 0.2780
Episode: 29941/30000 (99.8033%),                 avg. length: 9.0,                last time consumption/overall running time: 2.0014s / 2488.9750 s
agent0:                 episode reward: -1.7394,                 loss: nan
agent1:                 episode reward: 1.7394,                 loss: 0.2762
Episode: 29961/30000 (99.8700%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9330s / 2490.9081 s
agent0:                 episode reward: -1.5543,                 loss: nan
agent1:                 episode reward: 1.5543,                 loss: 0.2794
Episode: 29981/30000 (99.9367%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9230s / 2492.8311 s
agent0:                 episode reward: -2.1561,                 loss: nan
agent1:                 episode reward: 2.1561,                 loss: 0.2763
