2022-05-10 17:16:41.568875: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 17:16:41.568940: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-10 17:16:41.568945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fcfcf57f5c0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/6000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510161908/mdp_arbitrary_mdp_selfplay2/6000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510161908_exploit_6000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510161908_exploit_6000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8026s / 0.8026 s
agent0:                 episode reward: -0.3360,                 loss: nan
agent1:                 episode reward: 0.3360,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0634s / 0.8661 s
agent0:                 episode reward: 1.1130,                 loss: nan
agent1:                 episode reward: -1.1130,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0650s / 0.9311 s
agent0:                 episode reward: 1.2281,                 loss: nan
agent1:                 episode reward: -1.2281,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.0795s / 1.0106 s
agent0:                 episode reward: 0.3371,                 loss: nan
agent1:                 episode reward: -0.3371,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5852s / 1.5957 s
agent0:                 episode reward: 0.5251,                 loss: nan
agent1:                 episode reward: -0.5251,                 loss: 0.4490
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6692s / 2.2649 s
agent0:                 episode reward: 0.5473,                 loss: nan
agent1:                 episode reward: -0.5473,                 loss: 0.4244
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7314s / 2.9963 s
agent0:                 episode reward: 1.1336,                 loss: nan
agent1:                 episode reward: -1.1336,                 loss: 0.4123
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6841s / 3.6804 s
agent0:                 episode reward: 0.2348,                 loss: nan
agent1:                 episode reward: -0.2348,                 loss: 0.4099
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6887s / 4.3691 s
agent0:                 episode reward: 0.5732,                 loss: nan
agent1:                 episode reward: -0.5732,                 loss: 0.4096
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6894s / 5.0584 s
agent0:                 episode reward: 0.8984,                 loss: nan
agent1:                 episode reward: -0.8984,                 loss: 0.3987
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6880s / 5.7465 s
agent0:                 episode reward: 0.2530,                 loss: nan
agent1:                 episode reward: -0.2530,                 loss: 0.3968
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6862s / 6.4326 s
agent0:                 episode reward: 1.3966,                 loss: nan
agent1:                 episode reward: -1.3966,                 loss: 0.3970
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7358s / 7.1684 s
agent0:                 episode reward: 0.2759,                 loss: nan
agent1:                 episode reward: -0.2759,                 loss: 0.3977
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7080s / 7.8764 s
agent0:                 episode reward: 0.4710,                 loss: nan
agent1:                 episode reward: -0.4710,                 loss: 0.3989
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7047s / 8.5811 s
agent0:                 episode reward: 0.9543,                 loss: nan
agent1:                 episode reward: -0.9543,                 loss: 0.3833
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7773s / 9.3584 s
agent0:                 episode reward: 0.2312,                 loss: nan
agent1:                 episode reward: -0.2312,                 loss: 0.3755
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7079s / 10.0663 s
agent0:                 episode reward: 0.6224,                 loss: nan
agent1:                 episode reward: -0.6224,                 loss: 0.3749
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7137s / 10.7800 s
agent0:                 episode reward: 0.6291,                 loss: nan
agent1:                 episode reward: -0.6291,                 loss: 0.3747
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7159s / 11.4959 s
agent0:                 episode reward: -0.2091,                 loss: nan
agent1:                 episode reward: 0.2091,                 loss: 0.3737
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7032s / 12.1991 s
agent0:                 episode reward: 0.4638,                 loss: nan
agent1:                 episode reward: -0.4638,                 loss: 0.3467
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7502s / 12.9493 s
agent0:                 episode reward: 0.8404,                 loss: nan
agent1:                 episode reward: -0.8404,                 loss: 0.3434
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7347s / 13.6841 s
agent0:                 episode reward: 0.3999,                 loss: nan
agent1:                 episode reward: -0.3999,                 loss: 0.3420
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7441s / 14.4281 s
agent0:                 episode reward: 0.1982,                 loss: nan
agent1:                 episode reward: -0.1982,                 loss: 0.3412
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7187s / 15.1469 s
agent0:                 episode reward: 0.6139,                 loss: nan
agent1:                 episode reward: -0.6139,                 loss: 0.3403
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7523s / 15.8992 s
agent0:                 episode reward: 0.6094,                 loss: nan
agent1:                 episode reward: -0.6094,                 loss: 0.3156
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7412s / 16.6404 s
agent0:                 episode reward: -0.1825,                 loss: nan
agent1:                 episode reward: 0.1825,                 loss: 0.3121
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7340s / 17.3743 s
agent0:                 episode reward: 0.7932,                 loss: nan
agent1:                 episode reward: -0.7932,                 loss: 0.3115
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7258s / 18.1001 s
agent0:                 episode reward: 0.6076,                 loss: nan
agent1:                 episode reward: -0.6076,                 loss: 0.3117
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7581s / 18.8583 s
agent0:                 episode reward: 0.5748,                 loss: nan
agent1:                 episode reward: -0.5748,                 loss: 0.3129
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7925s / 19.6507 s
agent0:                 episode reward: 0.9118,                 loss: nan
agent1:                 episode reward: -0.9118,                 loss: 0.3077
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7366s / 20.3874 s
agent0:                 episode reward: 0.1006,                 loss: nan
agent1:                 episode reward: -0.1006,                 loss: 0.3079
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7406s / 21.1279 s
agent0:                 episode reward: 0.6016,                 loss: nan
agent1:                 episode reward: -0.6016,                 loss: 0.3065
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7337s / 21.8616 s
agent0:                 episode reward: 0.9249,                 loss: nan
agent1:                 episode reward: -0.9249,                 loss: 0.3040
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7395s / 22.6011 s
agent0:                 episode reward: 0.3336,                 loss: nan
agent1:                 episode reward: -0.3336,                 loss: 0.3018
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7490s / 23.3501 s
agent0:                 episode reward: 1.2174,                 loss: nan
agent1:                 episode reward: -1.2174,                 loss: 0.2997
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7668s / 24.1169 s
agent0:                 episode reward: 0.9848,                 loss: nan
agent1:                 episode reward: -0.9848,                 loss: 0.2985
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7509s / 24.8678 s
agent0:                 episode reward: -0.1230,                 loss: nan
agent1:                 episode reward: 0.1230,                 loss: 0.2981
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7624s / 25.6302 s
agent0:                 episode reward: 0.3348,                 loss: nan
agent1:                 episode reward: -0.3348,                 loss: 0.2974
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7557s / 26.3859 s
agent0:                 episode reward: -0.4908,                 loss: nan
agent1:                 episode reward: 0.4908,                 loss: 0.2983
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7626s / 27.1485 s
agent0:                 episode reward: 0.5732,                 loss: nan
agent1:                 episode reward: -0.5732,                 loss: 0.2973
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7554s / 27.9039 s
agent0:                 episode reward: -0.3505,                 loss: nan
agent1:                 episode reward: 0.3505,                 loss: 0.2979
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7761s / 28.6800 s
agent0:                 episode reward: 1.1715,                 loss: nan
agent1:                 episode reward: -1.1715,                 loss: 0.2964
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8308s / 29.5108 s
agent0:                 episode reward: 0.1788,                 loss: nan
agent1:                 episode reward: -0.1788,                 loss: 0.2965
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7753s / 30.2861 s
agent0:                 episode reward: 0.7179,                 loss: nan
agent1:                 episode reward: -0.7179,                 loss: 0.2938
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7680s / 31.0541 s
agent0:                 episode reward: -0.1665,                 loss: nan
agent1:                 episode reward: 0.1665,                 loss: 0.3030
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7958s / 31.8499 s
agent0:                 episode reward: 1.4127,                 loss: nan
agent1:                 episode reward: -1.4127,                 loss: 0.3033
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8234s / 32.6733 s
agent0:                 episode reward: 0.6317,                 loss: nan
agent1:                 episode reward: -0.6317,                 loss: 0.3035
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8144s / 33.4876 s
agent0:                 episode reward: 0.9622,                 loss: nan
agent1:                 episode reward: -0.9622,                 loss: 0.2996
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8034s / 34.2910 s
agent0:                 episode reward: 0.6249,                 loss: nan
agent1:                 episode reward: -0.6249,                 loss: 0.3001
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7976s / 35.0887 s
agent0:                 episode reward: 0.3483,                 loss: nan
agent1:                 episode reward: -0.3483,                 loss: 0.3086
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7806s / 35.8693 s
agent0:                 episode reward: 0.6159,                 loss: nan
agent1:                 episode reward: -0.6159,                 loss: 0.3100
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8188s / 36.6880 s
agent0:                 episode reward: 0.9348,                 loss: nan
agent1:                 episode reward: -0.9348,                 loss: 0.3089
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7920s / 37.4801 s
agent0:                 episode reward: 0.8071,                 loss: nan
agent1:                 episode reward: -0.8071,                 loss: 0.3067
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7934s / 38.2735 s
agent0:                 episode reward: 0.3977,                 loss: nan
agent1:                 episode reward: -0.3977,                 loss: 0.3070
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7948s / 39.0683 s
agent0:                 episode reward: 0.8838,                 loss: nan
agent1:                 episode reward: -0.8838,                 loss: 0.3151
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8634s / 39.9318 s
agent0:                 episode reward: 0.0341,                 loss: nan
agent1:                 episode reward: -0.0341,                 loss: 0.3155
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8259s / 40.7576 s
agent0:                 episode reward: 1.1260,                 loss: nan
agent1:                 episode reward: -1.1260,                 loss: 0.3153
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8058s / 41.5635 s
agent0:                 episode reward: 0.7357,                 loss: nan
agent1:                 episode reward: -0.7357,                 loss: 0.3144
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8069s / 42.3703 s
agent0:                 episode reward: -0.0838,                 loss: nan
agent1:                 episode reward: 0.0838,                 loss: 0.3146
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8177s / 43.1881 s
agent0:                 episode reward: 0.4956,                 loss: nan
agent1:                 episode reward: -0.4956,                 loss: 0.3240
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8249s / 44.0130 s
agent0:                 episode reward: 0.3249,                 loss: nan
agent1:                 episode reward: -0.3249,                 loss: 0.3260
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8151s / 44.8281 s
agent0:                 episode reward: 0.8662,                 loss: nan
agent1:                 episode reward: -0.8662,                 loss: 0.3252
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8114s / 45.6395 s
agent0:                 episode reward: 0.9971,                 loss: nan
agent1:                 episode reward: -0.9971,                 loss: 0.3234
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8138s / 46.4533 s
agent0:                 episode reward: 0.7025,                 loss: nan
agent1:                 episode reward: -0.7025,                 loss: 0.3230
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8104s / 47.2636 s
agent0:                 episode reward: -0.4143,                 loss: nan
agent1:                 episode reward: 0.4143,                 loss: 0.3390
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8161s / 48.0797 s
agent0:                 episode reward: 0.3183,                 loss: nan
agent1:                 episode reward: -0.3183,                 loss: 0.3395
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8367s / 48.9164 s
agent0:                 episode reward: 0.3328,                 loss: nan
agent1:                 episode reward: -0.3328,                 loss: 0.3393
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8527s / 49.7691 s
agent0:                 episode reward: 0.6632,                 loss: nan
agent1:                 episode reward: -0.6632,                 loss: 0.3385
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8773s / 50.6464 s
agent0:                 episode reward: 0.3819,                 loss: nan
agent1:                 episode reward: -0.3819,                 loss: 0.3384
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8279s / 51.4743 s
agent0:                 episode reward: 0.5801,                 loss: nan
agent1:                 episode reward: -0.5801,                 loss: 0.3525
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8269s / 52.3012 s
agent0:                 episode reward: 0.0003,                 loss: nan
agent1:                 episode reward: -0.0003,                 loss: 0.3551
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8495s / 53.1507 s
agent0:                 episode reward: 1.0356,                 loss: nan
agent1:                 episode reward: -1.0356,                 loss: 0.3552
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8322s / 53.9829 s
agent0:                 episode reward: 0.8029,                 loss: nan
agent1:                 episode reward: -0.8029,                 loss: 0.3550
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8318s / 54.8147 s
agent0:                 episode reward: -0.3707,                 loss: nan
agent1:                 episode reward: 0.3707,                 loss: 0.3541
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8471s / 55.6617 s
agent0:                 episode reward: 0.2885,                 loss: nan
agent1:                 episode reward: -0.2885,                 loss: 0.3692
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8366s / 56.4983 s
agent0:                 episode reward: 0.0363,                 loss: nan
agent1:                 episode reward: -0.0363,                 loss: 0.3711
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8823s / 57.3806 s
agent0:                 episode reward: 1.1999,                 loss: nan
agent1:                 episode reward: -1.1999,                 loss: 0.3703
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8442s / 58.2248 s
agent0:                 episode reward: 0.1202,                 loss: nan
agent1:                 episode reward: -0.1202,                 loss: 0.3686
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8377s / 59.0625 s
agent0:                 episode reward: 1.0876,                 loss: nan
agent1:                 episode reward: -1.0876,                 loss: 0.3696
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8550s / 59.9175 s
agent0:                 episode reward: 0.5841,                 loss: nan
agent1:                 episode reward: -0.5841,                 loss: 0.3832
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9035s / 60.8210 s
agent0:                 episode reward: 0.2437,                 loss: nan
agent1:                 episode reward: -0.2437,                 loss: 0.3841
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8553s / 61.6763 s
agent0:                 episode reward: 0.6985,                 loss: nan
agent1:                 episode reward: -0.6985,                 loss: 0.3851
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8435s / 62.5198 s
agent0:                 episode reward: 1.0281,                 loss: nan
agent1:                 episode reward: -1.0281,                 loss: 0.3837
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8386s / 63.3584 s
agent0:                 episode reward: 0.8994,                 loss: nan
agent1:                 episode reward: -0.8994,                 loss: 0.3850
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8472s / 64.2056 s
agent0:                 episode reward: -0.1583,                 loss: nan
agent1:                 episode reward: 0.1583,                 loss: 0.3930
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8859s / 65.0915 s
agent0:                 episode reward: 0.7786,                 loss: nan
agent1:                 episode reward: -0.7786,                 loss: 0.3901
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8551s / 65.9467 s
agent0:                 episode reward: 0.2483,                 loss: nan
agent1:                 episode reward: -0.2483,                 loss: 0.3901
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8563s / 66.8029 s
agent0:                 episode reward: 0.6808,                 loss: nan
agent1:                 episode reward: -0.6808,                 loss: 0.3882
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8770s / 67.6799 s
agent0:                 episode reward: 0.5760,                 loss: nan
agent1:                 episode reward: -0.5760,                 loss: 0.3888
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8674s / 68.5473 s
agent0:                 episode reward: 0.7003,                 loss: nan
agent1:                 episode reward: -0.7003,                 loss: 0.3836
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8817s / 69.4290 s
agent0:                 episode reward: 0.2676,                 loss: nan
agent1:                 episode reward: -0.2676,                 loss: 0.3797
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9288s / 70.3578 s
agent0:                 episode reward: 0.1447,                 loss: nan
agent1:                 episode reward: -0.1447,                 loss: 0.3789
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9024s / 71.2602 s
agent0:                 episode reward: 0.5368,                 loss: nan
agent1:                 episode reward: -0.5368,                 loss: 0.3781
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8785s / 72.1387 s
agent0:                 episode reward: 0.4138,                 loss: nan
agent1:                 episode reward: -0.4138,                 loss: 0.3782
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8739s / 73.0126 s
agent0:                 episode reward: 0.3361,                 loss: nan
agent1:                 episode reward: -0.3361,                 loss: 0.3701
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9365s / 73.9491 s
agent0:                 episode reward: 0.2599,                 loss: nan
agent1:                 episode reward: -0.2599,                 loss: 0.3669
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8817s / 74.8308 s
agent0:                 episode reward: 0.9499,                 loss: nan
agent1:                 episode reward: -0.9499,                 loss: 0.3670
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8815s / 75.7123 s
agent0:                 episode reward: 0.1518,                 loss: nan
agent1:                 episode reward: -0.1518,                 loss: 0.3643
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8881s / 76.6004 s
agent0:                 episode reward: 0.9236,                 loss: nan
agent1:                 episode reward: -0.9236,                 loss: 0.3653
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8851s / 77.4855 s
agent0:                 episode reward: 1.0872,                 loss: nan
agent1:                 episode reward: -1.0872,                 loss: 0.3574
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8858s / 78.3713 s
agent0:                 episode reward: 1.0071,                 loss: nan
agent1:                 episode reward: -1.0071,                 loss: 0.3561
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8975s / 79.2688 s
agent0:                 episode reward: -0.0126,                 loss: nan
agent1:                 episode reward: 0.0126,                 loss: 0.3561
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9134s / 80.1822 s
agent0:                 episode reward: -0.2625,                 loss: nan
agent1:                 episode reward: 0.2625,                 loss: 0.3561
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9606s / 81.1428 s
agent0:                 episode reward: 0.4689,                 loss: nan
agent1:                 episode reward: -0.4689,                 loss: 0.3547
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9171s / 82.0599 s
agent0:                 episode reward: -0.0371,                 loss: nan
agent1:                 episode reward: 0.0371,                 loss: 0.3459
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9022s / 82.9621 s
agent0:                 episode reward: 0.6860,                 loss: nan
agent1:                 episode reward: -0.6860,                 loss: 0.3442
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8915s / 83.8536 s
agent0:                 episode reward: 0.1260,                 loss: nan
agent1:                 episode reward: -0.1260,                 loss: 0.3430
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9059s / 84.7595 s
agent0:                 episode reward: 0.3025,                 loss: nan
agent1:                 episode reward: -0.3025,                 loss: 0.3411
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9106s / 85.6701 s
agent0:                 episode reward: 0.3468,                 loss: nan
agent1:                 episode reward: -0.3468,                 loss: 0.3428
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9022s / 86.5723 s
agent0:                 episode reward: -0.2949,                 loss: nan
agent1:                 episode reward: 0.2949,                 loss: 0.3270
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9475s / 87.5198 s
agent0:                 episode reward: 0.5327,                 loss: nan
agent1:                 episode reward: -0.5327,                 loss: 0.3227
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9634s / 88.4832 s
agent0:                 episode reward: 0.4559,                 loss: nan
agent1:                 episode reward: -0.4559,                 loss: 0.3214
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9088s / 89.3920 s
agent0:                 episode reward: 0.7086,                 loss: nan
agent1:                 episode reward: -0.7086,                 loss: 0.3218
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9411s / 90.3331 s
agent0:                 episode reward: -0.1792,                 loss: nan
agent1:                 episode reward: 0.1792,                 loss: 0.3235
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9871s / 91.3202 s
agent0:                 episode reward: -0.0485,                 loss: nan
agent1:                 episode reward: 0.0485,                 loss: 0.3160
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9434s / 92.2635 s
agent0:                 episode reward: -0.0729,                 loss: nan
agent1:                 episode reward: 0.0729,                 loss: 0.3149
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9143s / 93.1779 s
agent0:                 episode reward: 0.2693,                 loss: nan
agent1:                 episode reward: -0.2693,                 loss: 0.3160
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9171s / 94.0949 s
agent0:                 episode reward: 0.0171,                 loss: nan
agent1:                 episode reward: -0.0171,                 loss: 0.3151
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9298s / 95.0247 s
agent0:                 episode reward: 0.3409,                 loss: nan
agent1:                 episode reward: -0.3409,                 loss: 0.3145
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9241s / 95.9488 s
agent0:                 episode reward: 0.2248,                 loss: nan
agent1:                 episode reward: -0.2248,                 loss: 0.3017
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9222s / 96.8710 s
agent0:                 episode reward: 0.1639,                 loss: nan
agent1:                 episode reward: -0.1639,                 loss: 0.2972
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9625s / 97.8335 s
agent0:                 episode reward: 0.1278,                 loss: nan
agent1:                 episode reward: -0.1278,                 loss: 0.2958
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9586s / 98.7921 s
agent0:                 episode reward: 0.4128,                 loss: nan
agent1:                 episode reward: -0.4128,                 loss: 0.2961
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9419s / 99.7340 s
agent0:                 episode reward: 0.3489,                 loss: nan
agent1:                 episode reward: -0.3489,                 loss: 0.2944
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9619s / 100.6959 s
agent0:                 episode reward: -0.6582,                 loss: nan
agent1:                 episode reward: 0.6582,                 loss: 0.2954
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0006s / 101.6965 s
agent0:                 episode reward: -0.0561,                 loss: nan
agent1:                 episode reward: 0.0561,                 loss: 0.2951
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9782s / 102.6747 s
agent0:                 episode reward: 0.4618,                 loss: nan
agent1:                 episode reward: -0.4618,                 loss: 0.2943
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9539s / 103.6286 s
agent0:                 episode reward: -0.6957,                 loss: nan
agent1:                 episode reward: 0.6957,                 loss: 0.2931
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9568s / 104.5853 s
agent0:                 episode reward: 0.1408,                 loss: nan
agent1:                 episode reward: -0.1408,                 loss: 0.2928
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9589s / 105.5442 s
agent0:                 episode reward: 0.2475,                 loss: nan
agent1:                 episode reward: -0.2475,                 loss: 0.2883
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9612s / 106.5054 s
agent0:                 episode reward: 1.1411,                 loss: nan
agent1:                 episode reward: -1.1411,                 loss: 0.2849
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9726s / 107.4779 s
agent0:                 episode reward: -0.6883,                 loss: nan
agent1:                 episode reward: 0.6883,                 loss: 0.2856
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9669s / 108.4448 s
agent0:                 episode reward: 0.4286,                 loss: nan
agent1:                 episode reward: -0.4286,                 loss: 0.2852
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9783s / 109.4231 s
agent0:                 episode reward: 0.3173,                 loss: nan
agent1:                 episode reward: -0.3173,                 loss: 0.2831
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9809s / 110.4040 s
agent0:                 episode reward: 0.5403,                 loss: nan
agent1:                 episode reward: -0.5403,                 loss: 0.2983
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0126s / 111.4166 s
agent0:                 episode reward: 0.7961,                 loss: nan
agent1:                 episode reward: -0.7961,                 loss: 0.2984
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9810s / 112.3976 s
agent0:                 episode reward: -0.0054,                 loss: nan
agent1:                 episode reward: 0.0054,                 loss: 0.2970
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9793s / 113.3768 s
agent0:                 episode reward: 0.3419,                 loss: nan
agent1:                 episode reward: -0.3419,                 loss: 0.2982
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9730s / 114.3498 s
agent0:                 episode reward: 0.2811,                 loss: nan
agent1:                 episode reward: -0.2811,                 loss: 0.2968
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9892s / 115.3390 s
agent0:                 episode reward: 0.0674,                 loss: nan
agent1:                 episode reward: -0.0674,                 loss: 0.3189
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9749s / 116.3138 s
agent0:                 episode reward: 0.4303,                 loss: nan
agent1:                 episode reward: -0.4303,                 loss: 0.3218
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9738s / 117.2876 s
agent0:                 episode reward: 0.0411,                 loss: nan
agent1:                 episode reward: -0.0411,                 loss: 0.3231
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9708s / 118.2584 s
agent0:                 episode reward: 0.8845,                 loss: nan
agent1:                 episode reward: -0.8845,                 loss: 0.3211
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9804s / 119.2388 s
agent0:                 episode reward: 0.7821,                 loss: nan
agent1:                 episode reward: -0.7821,                 loss: 0.3195
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9701s / 120.2089 s
agent0:                 episode reward: -0.0018,                 loss: nan
agent1:                 episode reward: 0.0018,                 loss: 0.3508
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9838s / 121.1927 s
agent0:                 episode reward: -0.4122,                 loss: nan
agent1:                 episode reward: 0.4122,                 loss: 0.3555
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0317s / 122.2244 s
agent0:                 episode reward: -0.0356,                 loss: nan
agent1:                 episode reward: 0.0356,                 loss: 0.3538
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9966s / 123.2210 s
agent0:                 episode reward: -0.2860,                 loss: nan
agent1:                 episode reward: 0.2860,                 loss: 0.3539
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9892s / 124.2102 s
agent0:                 episode reward: 0.5193,                 loss: nan
agent1:                 episode reward: -0.5193,                 loss: 0.3534
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0053s / 125.2155 s
agent0:                 episode reward: 0.0606,                 loss: nan
agent1:                 episode reward: -0.0606,                 loss: 0.3664
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9786s / 126.1942 s
agent0:                 episode reward: 0.4638,                 loss: nan
agent1:                 episode reward: -0.4638,                 loss: 0.3659
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9832s / 127.1774 s
agent0:                 episode reward: -0.0629,                 loss: nan
agent1:                 episode reward: 0.0629,                 loss: 0.3661
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9964s / 128.1738 s
agent0:                 episode reward: 0.5296,                 loss: nan
agent1:                 episode reward: -0.5296,                 loss: 0.3671
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9963s / 129.1701 s
agent0:                 episode reward: 0.1429,                 loss: nan
agent1:                 episode reward: -0.1429,                 loss: 0.3634
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9942s / 130.1643 s
agent0:                 episode reward: 0.5239,                 loss: nan
agent1:                 episode reward: -0.5239,                 loss: 0.3493
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0064s / 131.1707 s
agent0:                 episode reward: 0.0371,                 loss: nan
agent1:                 episode reward: -0.0371,                 loss: 0.3402
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0711s / 132.2418 s
agent0:                 episode reward: -0.7811,                 loss: nan
agent1:                 episode reward: 0.7811,                 loss: 0.3410
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0323s / 133.2741 s
agent0:                 episode reward: 0.1992,                 loss: nan
agent1:                 episode reward: -0.1992,                 loss: 0.3388
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0153s / 134.2894 s
agent0:                 episode reward: -0.2387,                 loss: nan
agent1:                 episode reward: 0.2387,                 loss: 0.3393
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0029s / 135.2923 s
agent0:                 episode reward: -0.4752,                 loss: nan
agent1:                 episode reward: 0.4752,                 loss: 0.2730
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0196s / 136.3119 s
agent0:                 episode reward: 0.2171,                 loss: nan
agent1:                 episode reward: -0.2171,                 loss: 0.2544
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0145s / 137.3264 s
agent0:                 episode reward: -0.4286,                 loss: nan
agent1:                 episode reward: 0.4286,                 loss: 0.2538
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0192s / 138.3455 s
agent0:                 episode reward: 0.4197,                 loss: nan
agent1:                 episode reward: -0.4197,                 loss: 0.2535
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0243s / 139.3698 s
agent0:                 episode reward: 0.2038,                 loss: nan
agent1:                 episode reward: -0.2038,                 loss: 0.2514
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0674s / 140.4373 s
agent0:                 episode reward: 0.1233,                 loss: nan
agent1:                 episode reward: -0.1233,                 loss: 0.2120
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0382s / 141.4755 s
agent0:                 episode reward: 0.3248,                 loss: nan
agent1:                 episode reward: -0.3248,                 loss: 0.1980
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0917s / 142.5671 s
agent0:                 episode reward: -0.1694,                 loss: nan
agent1:                 episode reward: 0.1694,                 loss: 0.1972
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0394s / 143.6066 s
agent0:                 episode reward: 0.9149,                 loss: nan
agent1:                 episode reward: -0.9149,                 loss: 0.1962
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0257s / 144.6322 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.1961
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0629s / 145.6951 s
agent0:                 episode reward: 0.0839,                 loss: nan
agent1:                 episode reward: -0.0839,                 loss: 0.2067
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0493s / 146.7445 s
agent0:                 episode reward: 0.0236,                 loss: nan
agent1:                 episode reward: -0.0236,                 loss: 0.2052
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0229s / 147.7674 s
agent0:                 episode reward: 0.3923,                 loss: nan
agent1:                 episode reward: -0.3923,                 loss: 0.2040
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0561s / 148.8235 s
agent0:                 episode reward: 0.6691,                 loss: nan
agent1:                 episode reward: -0.6691,                 loss: 0.2037
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0138s / 149.8373 s
agent0:                 episode reward: 0.2213,                 loss: nan
agent1:                 episode reward: -0.2213,                 loss: 0.2037
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0251s / 150.8624 s
agent0:                 episode reward: 0.4627,                 loss: nan
agent1:                 episode reward: -0.4627,                 loss: 0.2203
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0618s / 151.9242 s
agent0:                 episode reward: 0.0865,                 loss: nan
agent1:                 episode reward: -0.0865,                 loss: 0.2168
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0977s / 153.0219 s
agent0:                 episode reward: -0.3226,                 loss: nan
agent1:                 episode reward: 0.3226,                 loss: 0.2166
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0428s / 154.0647 s
agent0:                 episode reward: 0.5705,                 loss: nan
agent1:                 episode reward: -0.5705,                 loss: 0.2152
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0512s / 155.1159 s
agent0:                 episode reward: -0.3560,                 loss: nan
agent1:                 episode reward: 0.3560,                 loss: 0.2166
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0474s / 156.1633 s
agent0:                 episode reward: -0.0648,                 loss: nan
agent1:                 episode reward: 0.0648,                 loss: 0.2464
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0598s / 157.2231 s
agent0:                 episode reward: 0.5068,                 loss: nan
agent1:                 episode reward: -0.5068,                 loss: 0.2440
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0965s / 158.3195 s
agent0:                 episode reward: 0.8719,                 loss: nan
agent1:                 episode reward: -0.8719,                 loss: 0.2413
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0442s / 159.3638 s
agent0:                 episode reward: -0.3181,                 loss: nan
agent1:                 episode reward: 0.3181,                 loss: 0.2404
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0424s / 160.4061 s
agent0:                 episode reward: 0.3669,                 loss: nan
agent1:                 episode reward: -0.3669,                 loss: 0.2389
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0679s / 161.4741 s
agent0:                 episode reward: 0.0394,                 loss: nan
agent1:                 episode reward: -0.0394,                 loss: 0.2538
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1675s / 162.6416 s
agent0:                 episode reward: 0.2940,                 loss: nan
agent1:                 episode reward: -0.2940,                 loss: 0.2480
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0865s / 163.7281 s
agent0:                 episode reward: -0.7072,                 loss: nan
agent1:                 episode reward: 0.7072,                 loss: 0.2462
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1026s / 164.8307 s
agent0:                 episode reward: -0.1106,                 loss: nan
agent1:                 episode reward: 0.1106,                 loss: 0.2430
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0647s / 165.8954 s
agent0:                 episode reward: -0.5535,                 loss: nan
agent1:                 episode reward: 0.5535,                 loss: 0.2419
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0718s / 166.9673 s
agent0:                 episode reward: -0.1824,                 loss: nan
agent1:                 episode reward: 0.1824,                 loss: 0.2511
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0834s / 168.0507 s
agent0:                 episode reward: -0.0249,                 loss: nan
agent1:                 episode reward: 0.0249,                 loss: 0.2498
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0729s / 169.1236 s
agent0:                 episode reward: 0.0200,                 loss: nan
agent1:                 episode reward: -0.0200,                 loss: 0.2488
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0871s / 170.2107 s
agent0:                 episode reward: -0.0177,                 loss: nan
agent1:                 episode reward: 0.0177,                 loss: 0.2466
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0803s / 171.2910 s
agent0:                 episode reward: -0.1297,                 loss: nan
agent1:                 episode reward: 0.1297,                 loss: 0.2479
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0929s / 172.3839 s
agent0:                 episode reward: -0.4746,                 loss: nan
agent1:                 episode reward: 0.4746,                 loss: 0.2755
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1615s / 173.5454 s
agent0:                 episode reward: 0.3087,                 loss: nan
agent1:                 episode reward: -0.3087,                 loss: 0.2787
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0828s / 174.6282 s
agent0:                 episode reward: -0.4005,                 loss: nan
agent1:                 episode reward: 0.4005,                 loss: 0.2795
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0879s / 175.7161 s
agent0:                 episode reward: -0.1918,                 loss: nan
agent1:                 episode reward: 0.1918,                 loss: 0.2780
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0839s / 176.8000 s
agent0:                 episode reward: 0.4972,                 loss: nan
agent1:                 episode reward: -0.4972,                 loss: 0.2781
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0804s / 177.8803 s
agent0:                 episode reward: 0.4819,                 loss: nan
agent1:                 episode reward: -0.4819,                 loss: 0.3115
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1296s / 179.0099 s
agent0:                 episode reward: 0.6677,                 loss: nan
agent1:                 episode reward: -0.6677,                 loss: 0.3159
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0940s / 180.1039 s
agent0:                 episode reward: -0.3176,                 loss: nan
agent1:                 episode reward: 0.3176,                 loss: 0.3173
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1198s / 181.2237 s
agent0:                 episode reward: 0.2226,                 loss: nan
agent1:                 episode reward: -0.2226,                 loss: 0.3177
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1355s / 182.3591 s
agent0:                 episode reward: 0.3100,                 loss: nan
agent1:                 episode reward: -0.3100,                 loss: 0.3168
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1692s / 183.5284 s
agent0:                 episode reward: 0.1864,                 loss: nan
agent1:                 episode reward: -0.1864,                 loss: 0.3508
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1111s / 184.6395 s
agent0:                 episode reward: -0.4513,                 loss: nan
agent1:                 episode reward: 0.4513,                 loss: 0.3538
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1143s / 185.7538 s
agent0:                 episode reward: 0.2261,                 loss: nan
agent1:                 episode reward: -0.2261,                 loss: 0.3546
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1070s / 186.8608 s
agent0:                 episode reward: -0.3388,                 loss: nan
agent1:                 episode reward: 0.3388,                 loss: 0.3503
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1307s / 187.9915 s
agent0:                 episode reward: -0.8278,                 loss: nan
agent1:                 episode reward: 0.8278,                 loss: 0.3521
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1110s / 189.1025 s
agent0:                 episode reward: -0.2556,                 loss: nan
agent1:                 episode reward: 0.2556,                 loss: 0.3361
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1326s / 190.2351 s
agent0:                 episode reward: 0.5757,                 loss: nan
agent1:                 episode reward: -0.5757,                 loss: 0.3267
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1479s / 191.3830 s
agent0:                 episode reward: 0.7872,                 loss: nan
agent1:                 episode reward: -0.7872,                 loss: 0.3252
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1262s / 192.5092 s
agent0:                 episode reward: -0.3561,                 loss: nan
agent1:                 episode reward: 0.3561,                 loss: 0.3247
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1647s / 193.6739 s
agent0:                 episode reward: -0.6850,                 loss: nan
agent1:                 episode reward: 0.6850,                 loss: 0.3243
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1371s / 194.8110 s
agent0:                 episode reward: -0.2035,                 loss: nan
agent1:                 episode reward: 0.2035,                 loss: 0.2615
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1601s / 195.9711 s
agent0:                 episode reward: -0.5299,                 loss: nan
agent1:                 episode reward: 0.5299,                 loss: 0.2469
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1419s / 197.1129 s
agent0:                 episode reward: -0.0114,                 loss: nan
agent1:                 episode reward: 0.0114,                 loss: 0.2457
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1492s / 198.2621 s
agent0:                 episode reward: -0.4454,                 loss: nan
agent1:                 episode reward: 0.4454,                 loss: 0.2461
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1411s / 199.4032 s
agent0:                 episode reward: 0.0362,                 loss: nan
agent1:                 episode reward: -0.0362,                 loss: 0.2446
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1462s / 200.5494 s
agent0:                 episode reward: -0.0598,                 loss: nan
agent1:                 episode reward: 0.0598,                 loss: 0.2034
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1369s / 201.6863 s
agent0:                 episode reward: 0.3586,                 loss: nan
agent1:                 episode reward: -0.3586,                 loss: 0.1933
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2093s / 202.8956 s
agent0:                 episode reward: -0.7368,                 loss: nan
agent1:                 episode reward: 0.7368,                 loss: 0.1910
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1850s / 204.0807 s
agent0:                 episode reward: 0.3253,                 loss: nan
agent1:                 episode reward: -0.3253,                 loss: 0.1913
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1364s / 205.2171 s
agent0:                 episode reward: -0.7721,                 loss: nan
agent1:                 episode reward: 0.7721,                 loss: 0.1911
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1634s / 206.3805 s
agent0:                 episode reward: 0.0639,                 loss: nan
agent1:                 episode reward: -0.0639,                 loss: 0.2045
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1392s / 207.5197 s
agent0:                 episode reward: 0.2531,                 loss: nan
agent1:                 episode reward: -0.2531,                 loss: 0.2031
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1431s / 208.6628 s
agent0:                 episode reward: 0.4620,                 loss: nan
agent1:                 episode reward: -0.4620,                 loss: 0.2034
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1553s / 209.8181 s
agent0:                 episode reward: 0.0622,                 loss: nan
agent1:                 episode reward: -0.0622,                 loss: 0.2013
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1481s / 210.9662 s
agent0:                 episode reward: 0.0979,                 loss: nan
agent1:                 episode reward: -0.0979,                 loss: 0.2014
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1697s / 212.1360 s
agent0:                 episode reward: 0.2595,                 loss: nan
agent1:                 episode reward: -0.2595,                 loss: 0.2188
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1525s / 213.2885 s
agent0:                 episode reward: -0.3778,                 loss: nan
agent1:                 episode reward: 0.3778,                 loss: 0.2174
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2165s / 214.5050 s
agent0:                 episode reward: 0.3990,                 loss: nan
agent1:                 episode reward: -0.3990,                 loss: 0.2157
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1781s / 215.6831 s
agent0:                 episode reward: -0.0033,                 loss: nan
agent1:                 episode reward: 0.0033,                 loss: 0.2159
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1596s / 216.8427 s
agent0:                 episode reward: -0.0513,                 loss: nan
agent1:                 episode reward: 0.0513,                 loss: 0.2150
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1775s / 218.0202 s
agent0:                 episode reward: -0.2057,                 loss: nan
agent1:                 episode reward: 0.2057,                 loss: 0.2305
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1660s / 219.1862 s
agent0:                 episode reward: 0.0713,                 loss: nan
agent1:                 episode reward: -0.0713,                 loss: 0.2271
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1801s / 220.3663 s
agent0:                 episode reward: -0.0092,                 loss: nan
agent1:                 episode reward: 0.0092,                 loss: 0.2263
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1816s / 221.5480 s
agent0:                 episode reward: -0.0255,                 loss: nan
agent1:                 episode reward: 0.0255,                 loss: 0.2237
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1994s / 222.7474 s
agent0:                 episode reward: 0.1600,                 loss: nan
agent1:                 episode reward: -0.1600,                 loss: 0.2241
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1856s / 223.9330 s
agent0:                 episode reward: -0.2768,                 loss: nan
agent1:                 episode reward: 0.2768,                 loss: 0.2266
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2231s / 225.1560 s
agent0:                 episode reward: 0.1701,                 loss: nan
agent1:                 episode reward: -0.1701,                 loss: 0.2260
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1746s / 226.3306 s
agent0:                 episode reward: -0.0329,                 loss: nan
agent1:                 episode reward: 0.0329,                 loss: 0.2232
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1750s / 227.5056 s
agent0:                 episode reward: -0.1508,                 loss: nan
agent1:                 episode reward: 0.1508,                 loss: 0.2227
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1822s / 228.6877 s
agent0:                 episode reward: 0.2022,                 loss: nan
agent1:                 episode reward: -0.2022,                 loss: 0.2217
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1787s / 229.8664 s
agent0:                 episode reward: 0.2682,                 loss: nan
agent1:                 episode reward: -0.2682,                 loss: 0.2261
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2067s / 231.0730 s
agent0:                 episode reward: -0.2095,                 loss: nan
agent1:                 episode reward: 0.2095,                 loss: 0.2244
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2020s / 232.2750 s
agent0:                 episode reward: 0.2356,                 loss: nan
agent1:                 episode reward: -0.2356,                 loss: 0.2247
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2034s / 233.4784 s
agent0:                 episode reward: -1.0364,                 loss: nan
agent1:                 episode reward: 1.0364,                 loss: 0.2245
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2583s / 234.7367 s
agent0:                 episode reward: -0.3320,                 loss: nan
agent1:                 episode reward: 0.3320,                 loss: 0.2226
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2074s / 235.9441 s
agent0:                 episode reward: -0.0971,                 loss: nan
agent1:                 episode reward: 0.0971,                 loss: 0.2462
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2109s / 237.1550 s
agent0:                 episode reward: -1.5379,                 loss: nan
agent1:                 episode reward: 1.5379,                 loss: 0.2480
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1976s / 238.3526 s
agent0:                 episode reward: 0.1483,                 loss: nan
agent1:                 episode reward: -0.1483,                 loss: 0.2479
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2394s / 239.5920 s
agent0:                 episode reward: -0.1829,                 loss: nan
agent1:                 episode reward: 0.1829,                 loss: 0.2486
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2060s / 240.7980 s
agent0:                 episode reward: -0.2107,                 loss: nan
agent1:                 episode reward: 0.2107,                 loss: 0.2471
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2137s / 242.0118 s
agent0:                 episode reward: -0.1341,                 loss: nan
agent1:                 episode reward: 0.1341,                 loss: 0.2890
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2334s / 243.2452 s
agent0:                 episode reward: -0.1470,                 loss: nan
agent1:                 episode reward: 0.1470,                 loss: 0.2927
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2188s / 244.4640 s
agent0:                 episode reward: 0.3251,                 loss: nan
agent1:                 episode reward: -0.3251,                 loss: 0.2923
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2690s / 245.7329 s
agent0:                 episode reward: -0.9516,                 loss: nan
agent1:                 episode reward: 0.9516,                 loss: 0.2913
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2062s / 246.9392 s
agent0:                 episode reward: -0.8098,                 loss: nan
agent1:                 episode reward: 0.8098,                 loss: 0.2924
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2287s / 248.1678 s
agent0:                 episode reward: -0.1626,                 loss: nan
agent1:                 episode reward: 0.1626,                 loss: 0.3264
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2018s / 249.3697 s
agent0:                 episode reward: -1.0139,                 loss: nan
agent1:                 episode reward: 1.0139,                 loss: 0.3305
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2016s / 250.5713 s
agent0:                 episode reward: -0.7278,                 loss: nan
agent1:                 episode reward: 0.7278,                 loss: 0.3278
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2140s / 251.7853 s
agent0:                 episode reward: -0.6061,                 loss: nan
agent1:                 episode reward: 0.6061,                 loss: 0.3285
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2235s / 253.0089 s
agent0:                 episode reward: -0.4367,                 loss: nan
agent1:                 episode reward: 0.4367,                 loss: 0.3282
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2279s / 254.2367 s
agent0:                 episode reward: -0.0179,                 loss: nan
agent1:                 episode reward: 0.0179,                 loss: 0.3009
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2776s / 255.5144 s
agent0:                 episode reward: -0.7876,                 loss: nan
agent1:                 episode reward: 0.7876,                 loss: 0.2862
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2453s / 256.7597 s
agent0:                 episode reward: 0.0011,                 loss: nan
agent1:                 episode reward: -0.0011,                 loss: 0.2857
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2425s / 258.0022 s
agent0:                 episode reward: 0.0079,                 loss: nan
agent1:                 episode reward: -0.0079,                 loss: 0.2843
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2393s / 259.2415 s
agent0:                 episode reward: 0.2631,                 loss: nan
agent1:                 episode reward: -0.2631,                 loss: 0.2839
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2617s / 260.5032 s
agent0:                 episode reward: -0.4129,                 loss: nan
agent1:                 episode reward: 0.4129,                 loss: 0.2194
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2368s / 261.7401 s
agent0:                 episode reward: -0.0394,                 loss: nan
agent1:                 episode reward: 0.0394,                 loss: 0.2027
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2463s / 262.9864 s
agent0:                 episode reward: -1.0471,                 loss: nan
agent1:                 episode reward: 1.0471,                 loss: 0.1996
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2562s / 264.2426 s
agent0:                 episode reward: 0.1797,                 loss: nan
agent1:                 episode reward: -0.1797,                 loss: 0.1999
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3001s / 265.5427 s
agent0:                 episode reward: -0.2272,                 loss: nan
agent1:                 episode reward: 0.2272,                 loss: 0.1985
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2423s / 266.7850 s
agent0:                 episode reward: 0.2572,                 loss: nan
agent1:                 episode reward: -0.2572,                 loss: 0.1823
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2568s / 268.0418 s
agent0:                 episode reward: -0.5170,                 loss: nan
agent1:                 episode reward: 0.5170,                 loss: 0.1717
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2765s / 269.3183 s
agent0:                 episode reward: -0.5882,                 loss: nan
agent1:                 episode reward: 0.5882,                 loss: 0.1730
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2586s / 270.5769 s
agent0:                 episode reward: -0.3693,                 loss: nan
agent1:                 episode reward: 0.3693,                 loss: 0.1717
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2385s / 271.8154 s
agent0:                 episode reward: -0.7196,                 loss: nan
agent1:                 episode reward: 0.7196,                 loss: 0.1730
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2928s / 273.1082 s
agent0:                 episode reward: 0.6419,                 loss: nan
agent1:                 episode reward: -0.6419,                 loss: 0.1917
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2694s / 274.3776 s
agent0:                 episode reward: 0.1239,                 loss: nan
agent1:                 episode reward: -0.1239,                 loss: 0.1907
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3201s / 275.6978 s
agent0:                 episode reward: 0.1803,                 loss: nan
agent1:                 episode reward: -0.1803,                 loss: 0.1905
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2506s / 276.9484 s
agent0:                 episode reward: -0.1461,                 loss: nan
agent1:                 episode reward: 0.1461,                 loss: 0.1890
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2700s / 278.2184 s
agent0:                 episode reward: 0.2989,                 loss: nan
agent1:                 episode reward: -0.2989,                 loss: 0.1899
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2751s / 279.4935 s
agent0:                 episode reward: -0.1579,                 loss: nan
agent1:                 episode reward: 0.1579,                 loss: 0.2104
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2806s / 280.7741 s
agent0:                 episode reward: -0.1795,                 loss: nan
agent1:                 episode reward: 0.1795,                 loss: 0.2089
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2675s / 282.0416 s
agent0:                 episode reward: 0.0822,                 loss: nan
agent1:                 episode reward: -0.0822,                 loss: 0.2097
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2597s / 283.3014 s
agent0:                 episode reward: 0.5452,                 loss: nan
agent1:                 episode reward: -0.5452,                 loss: 0.2080
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2631s / 284.5645 s
agent0:                 episode reward: 0.1998,                 loss: nan
agent1:                 episode reward: -0.1998,                 loss: 0.2088
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3111s / 285.8756 s
agent0:                 episode reward: -0.3604,                 loss: nan
agent1:                 episode reward: 0.3604,                 loss: 0.2182
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2659s / 287.1414 s
agent0:                 episode reward: -0.2316,                 loss: nan
agent1:                 episode reward: 0.2316,                 loss: 0.2149
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2711s / 288.4126 s
agent0:                 episode reward: 0.1902,                 loss: nan
agent1:                 episode reward: -0.1902,                 loss: 0.2145
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2938s / 289.7063 s
agent0:                 episode reward: -0.4280,                 loss: nan
agent1:                 episode reward: 0.4280,                 loss: 0.2147
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2795s / 290.9858 s
agent0:                 episode reward: -0.1021,                 loss: nan
agent1:                 episode reward: 0.1021,                 loss: 0.2161
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2786s / 292.2645 s
agent0:                 episode reward: -0.5936,                 loss: nan
agent1:                 episode reward: 0.5936,                 loss: 0.2262
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3207s / 293.5851 s
agent0:                 episode reward: 0.0696,                 loss: nan
agent1:                 episode reward: -0.0696,                 loss: 0.2205
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2961s / 294.8812 s
agent0:                 episode reward: 0.0481,                 loss: nan
agent1:                 episode reward: -0.0481,                 loss: 0.2218
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3462s / 296.2274 s
agent0:                 episode reward: 0.4706,                 loss: nan
agent1:                 episode reward: -0.4706,                 loss: 0.2195
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3246s / 297.5520 s
agent0:                 episode reward: -0.1091,                 loss: nan
agent1:                 episode reward: 0.1091,                 loss: 0.2184
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2809s / 298.8329 s
agent0:                 episode reward: 0.3041,                 loss: nan
agent1:                 episode reward: -0.3041,                 loss: 0.2454
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2937s / 300.1265 s
agent0:                 episode reward: -0.5475,                 loss: nan
agent1:                 episode reward: 0.5475,                 loss: 0.2454
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2834s / 301.4099 s
agent0:                 episode reward: 0.2697,                 loss: nan
agent1:                 episode reward: -0.2697,                 loss: 0.2432
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3013s / 302.7112 s
agent0:                 episode reward: 0.0060,                 loss: nan
agent1:                 episode reward: -0.0060,                 loss: 0.2435
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3073s / 304.0185 s
agent0:                 episode reward: -0.1423,                 loss: nan
agent1:                 episode reward: 0.1423,                 loss: 0.2427
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2969s / 305.3154 s
agent0:                 episode reward: -0.0399,                 loss: nan
agent1:                 episode reward: 0.0399,                 loss: 0.2984
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3779s / 306.6933 s
agent0:                 episode reward: 0.2856,                 loss: nan
agent1:                 episode reward: -0.2856,                 loss: 0.3043
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.2955s / 307.9888 s
agent0:                 episode reward: -0.1246,                 loss: nan
agent1:                 episode reward: 0.1246,                 loss: 0.3048
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3003s / 309.2891 s
agent0:                 episode reward: -0.2163,                 loss: nan
agent1:                 episode reward: 0.2163,                 loss: 0.3055
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3127s / 310.6017 s
agent0:                 episode reward: 0.6009,                 loss: nan
agent1:                 episode reward: -0.6009,                 loss: 0.3052
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3141s / 311.9158 s
agent0:                 episode reward: -0.2972,                 loss: nan
agent1:                 episode reward: 0.2972,                 loss: 0.3271
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3158s / 313.2316 s
agent0:                 episode reward: -0.4371,                 loss: nan
agent1:                 episode reward: 0.4371,                 loss: 0.3254
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3372s / 314.5688 s
agent0:                 episode reward: 0.0828,                 loss: nan
agent1:                 episode reward: -0.0828,                 loss: 0.3249
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3299s / 315.8987 s
agent0:                 episode reward: -0.0651,                 loss: nan
agent1:                 episode reward: 0.0651,                 loss: 0.3234
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4166s / 317.3153 s
agent0:                 episode reward: -0.6780,                 loss: nan
agent1:                 episode reward: 0.6780,                 loss: 0.3245
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3402s / 318.6554 s
agent0:                 episode reward: -0.2086,                 loss: nan
agent1:                 episode reward: 0.2086,                 loss: 0.2731
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3834s / 320.0388 s
agent0:                 episode reward: 0.4879,                 loss: nan
agent1:                 episode reward: -0.4879,                 loss: 0.2593
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3463s / 321.3852 s
agent0:                 episode reward: 0.4629,                 loss: nan
agent1:                 episode reward: -0.4629,                 loss: 0.2574
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3953s / 322.7805 s
agent0:                 episode reward: 0.0300,                 loss: nan
agent1:                 episode reward: -0.0300,                 loss: 0.2583
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3465s / 324.1270 s
agent0:                 episode reward: 0.0690,                 loss: nan
agent1:                 episode reward: -0.0690,                 loss: 0.2567
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3499s / 325.4769 s
agent0:                 episode reward: -0.5148,                 loss: nan
agent1:                 episode reward: 0.5148,                 loss: 0.2035
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4161s / 326.8930 s
agent0:                 episode reward: -0.5052,                 loss: nan
agent1:                 episode reward: 0.5052,                 loss: 0.1862
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3414s / 328.2344 s
agent0:                 episode reward: -1.1725,                 loss: nan
agent1:                 episode reward: 1.1725,                 loss: 0.1867
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3494s / 329.5838 s
agent0:                 episode reward: 0.0144,                 loss: nan
agent1:                 episode reward: -0.0144,                 loss: 0.1858
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3597s / 330.9435 s
agent0:                 episode reward: -0.1922,                 loss: nan
agent1:                 episode reward: 0.1922,                 loss: 0.1852
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3527s / 332.2962 s
agent0:                 episode reward: -0.2816,                 loss: nan
agent1:                 episode reward: 0.2816,                 loss: 0.1880
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4028s / 333.6990 s
agent0:                 episode reward: 0.4119,                 loss: nan
agent1:                 episode reward: -0.4119,                 loss: 0.1828
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3812s / 335.0802 s
agent0:                 episode reward: -0.9807,                 loss: nan
agent1:                 episode reward: 0.9807,                 loss: 0.1819
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3940s / 336.4741 s
agent0:                 episode reward: -0.8952,                 loss: nan
agent1:                 episode reward: 0.8952,                 loss: 0.1806
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4228s / 337.8969 s
agent0:                 episode reward: 0.1688,                 loss: nan
agent1:                 episode reward: -0.1688,                 loss: 0.1806
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4311s / 339.3280 s
agent0:                 episode reward: -0.4810,                 loss: nan
agent1:                 episode reward: 0.4810,                 loss: 0.2051
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3957s / 340.7237 s
agent0:                 episode reward: -0.2567,                 loss: nan
agent1:                 episode reward: 0.2567,                 loss: 0.2001
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3803s / 342.1040 s
agent0:                 episode reward: -0.4247,                 loss: nan
agent1:                 episode reward: 0.4247,                 loss: 0.2009
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3740s / 343.4781 s
agent0:                 episode reward: -0.1066,                 loss: nan
agent1:                 episode reward: 0.1066,                 loss: 0.2025
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3932s / 344.8713 s
agent0:                 episode reward: -0.3813,                 loss: nan
agent1:                 episode reward: 0.3813,                 loss: 0.2020
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4174s / 346.2887 s
agent0:                 episode reward: -0.2845,                 loss: nan
agent1:                 episode reward: 0.2845,                 loss: 0.2294
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4558s / 347.7445 s
agent0:                 episode reward: -0.3327,                 loss: nan
agent1:                 episode reward: 0.3327,                 loss: 0.2295
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3865s / 349.1310 s
agent0:                 episode reward: 0.1166,                 loss: nan
agent1:                 episode reward: -0.1166,                 loss: 0.2284
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4314s / 350.5624 s
agent0:                 episode reward: -0.3333,                 loss: nan
agent1:                 episode reward: 0.3333,                 loss: 0.2282
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4090s / 351.9714 s
agent0:                 episode reward: -0.3443,                 loss: nan
agent1:                 episode reward: 0.3443,                 loss: 0.2269
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.3930s / 353.3645 s
agent0:                 episode reward: -0.6628,                 loss: nan
agent1:                 episode reward: 0.6628,                 loss: 0.2334
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4407s / 354.8051 s
agent0:                 episode reward: 0.2681,                 loss: nan
agent1:                 episode reward: -0.2681,                 loss: 0.2294
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4097s / 356.2148 s
agent0:                 episode reward: -0.3782,                 loss: nan
agent1:                 episode reward: 0.3782,                 loss: 0.2272
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4705s / 357.6853 s
agent0:                 episode reward: -0.5946,                 loss: nan
agent1:                 episode reward: 0.5946,                 loss: 0.2286
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4310s / 359.1163 s
agent0:                 episode reward: -0.1250,                 loss: nan
agent1:                 episode reward: 0.1250,                 loss: 0.2297
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4521s / 360.5685 s
agent0:                 episode reward: -0.5969,                 loss: nan
agent1:                 episode reward: 0.5969,                 loss: 0.2385
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4096s / 361.9781 s
agent0:                 episode reward: -0.8347,                 loss: nan
agent1:                 episode reward: 0.8347,                 loss: 0.2352
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4384s / 363.4165 s
agent0:                 episode reward: -0.4012,                 loss: nan
agent1:                 episode reward: 0.4012,                 loss: 0.2347
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4466s / 364.8631 s
agent0:                 episode reward: -0.2140,                 loss: nan
agent1:                 episode reward: 0.2140,                 loss: 0.2350
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4348s / 366.2979 s
agent0:                 episode reward: -0.2586,                 loss: nan
agent1:                 episode reward: 0.2586,                 loss: 0.2329
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4775s / 367.7754 s
agent0:                 episode reward: -0.5078,                 loss: nan
agent1:                 episode reward: 0.5078,                 loss: 0.2721
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4536s / 369.2290 s
agent0:                 episode reward: -0.1163,                 loss: nan
agent1:                 episode reward: 0.1163,                 loss: 0.2742
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4495s / 370.6784 s
agent0:                 episode reward: -0.8817,                 loss: nan
agent1:                 episode reward: 0.8817,                 loss: 0.2744
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4787s / 372.1571 s
agent0:                 episode reward: -0.5473,                 loss: nan
agent1:                 episode reward: 0.5473,                 loss: 0.2756
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4435s / 373.6007 s
agent0:                 episode reward: -0.7597,                 loss: nan
agent1:                 episode reward: 0.7597,                 loss: 0.2736
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4475s / 375.0481 s
agent0:                 episode reward: -0.5224,                 loss: nan
agent1:                 episode reward: 0.5224,                 loss: 0.3126
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4276s / 376.4757 s
agent0:                 episode reward: 0.8722,                 loss: nan
agent1:                 episode reward: -0.8722,                 loss: 0.3172
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5018s / 377.9775 s
agent0:                 episode reward: -0.5550,                 loss: nan
agent1:                 episode reward: 0.5550,                 loss: 0.3171
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4510s / 379.4285 s
agent0:                 episode reward: -0.6630,                 loss: nan
agent1:                 episode reward: 0.6630,                 loss: 0.3169
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4998s / 380.9282 s
agent0:                 episode reward: -0.3022,                 loss: nan
agent1:                 episode reward: 0.3022,                 loss: 0.3162
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4982s / 382.4264 s
agent0:                 episode reward: -0.6246,                 loss: nan
agent1:                 episode reward: 0.6246,                 loss: 0.2978
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4664s / 383.8928 s
agent0:                 episode reward: 0.3834,                 loss: nan
agent1:                 episode reward: -0.3834,                 loss: 0.2895
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4809s / 385.3738 s
agent0:                 episode reward: -0.1578,                 loss: nan
agent1:                 episode reward: 0.1578,                 loss: 0.2862
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4791s / 386.8528 s
agent0:                 episode reward: -0.6792,                 loss: nan
agent1:                 episode reward: 0.6792,                 loss: 0.2883
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5315s / 388.3843 s
agent0:                 episode reward: -0.3229,                 loss: nan
agent1:                 episode reward: 0.3229,                 loss: 0.2886
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5267s / 389.9109 s
agent0:                 episode reward: 0.2600,                 loss: nan
agent1:                 episode reward: -0.2600,                 loss: 0.2172
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4606s / 391.3715 s
agent0:                 episode reward: -0.6242,                 loss: nan
agent1:                 episode reward: 0.6242,                 loss: 0.2007
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5143s / 392.8858 s
agent0:                 episode reward: -0.3196,                 loss: nan
agent1:                 episode reward: 0.3196,                 loss: 0.1998
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5157s / 394.4016 s
agent0:                 episode reward: -0.6537,                 loss: nan
agent1:                 episode reward: 0.6537,                 loss: 0.1999
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4722s / 395.8738 s
agent0:                 episode reward: -0.5195,                 loss: nan
agent1:                 episode reward: 0.5195,                 loss: 0.2006
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4801s / 397.3539 s
agent0:                 episode reward: -0.2607,                 loss: nan
agent1:                 episode reward: 0.2607,                 loss: 0.1671
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5443s / 398.8982 s
agent0:                 episode reward: 0.0259,                 loss: nan
agent1:                 episode reward: -0.0259,                 loss: 0.1574
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.4853s / 400.3835 s
agent0:                 episode reward: -0.5286,                 loss: nan
agent1:                 episode reward: 0.5286,                 loss: 0.1569
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5217s / 401.9052 s
agent0:                 episode reward: -0.3007,                 loss: nan
agent1:                 episode reward: 0.3007,                 loss: 0.1570
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5308s / 403.4361 s
agent0:                 episode reward: -0.2274,                 loss: nan
agent1:                 episode reward: 0.2274,                 loss: 0.1541
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5164s / 404.9525 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: 0.1688
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5082s / 406.4608 s
agent0:                 episode reward: 0.1105,                 loss: nan
agent1:                 episode reward: -0.1105,                 loss: 0.1684
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5096s / 407.9703 s
agent0:                 episode reward: -0.1305,                 loss: nan
agent1:                 episode reward: 0.1305,                 loss: 0.1686
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5605s / 409.5308 s
agent0:                 episode reward: -0.5586,                 loss: nan
agent1:                 episode reward: 0.5586,                 loss: 0.1677
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5373s / 411.0681 s
agent0:                 episode reward: -0.3416,                 loss: nan
agent1:                 episode reward: 0.3416,                 loss: 0.1682
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5231s / 412.5912 s
agent0:                 episode reward: -0.0712,                 loss: nan
agent1:                 episode reward: 0.0712,                 loss: 0.1933
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5737s / 414.1649 s
agent0:                 episode reward: -0.4449,                 loss: nan
agent1:                 episode reward: 0.4449,                 loss: 0.1926
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5149s / 415.6798 s
agent0:                 episode reward: -0.4749,                 loss: nan
agent1:                 episode reward: 0.4749,                 loss: 0.1922
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5133s / 417.1931 s
agent0:                 episode reward: -0.1299,                 loss: nan
agent1:                 episode reward: 0.1299,                 loss: 0.1906
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5215s / 418.7146 s
agent0:                 episode reward: 0.0101,                 loss: nan
agent1:                 episode reward: -0.0101,                 loss: 0.1917
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5871s / 420.3017 s
agent0:                 episode reward: -0.3326,                 loss: nan
agent1:                 episode reward: 0.3326,                 loss: 0.2177
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5432s / 421.8449 s
agent0:                 episode reward: 0.0908,                 loss: nan
agent1:                 episode reward: -0.0908,                 loss: 0.2198
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5348s / 423.3798 s
agent0:                 episode reward: 0.0084,                 loss: nan
agent1:                 episode reward: -0.0084,                 loss: 0.2181
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5376s / 424.9174 s
agent0:                 episode reward: 0.4775,                 loss: nan
agent1:                 episode reward: -0.4775,                 loss: 0.2175
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5577s / 426.4751 s
agent0:                 episode reward: -0.1213,                 loss: nan
agent1:                 episode reward: 0.1213,                 loss: 0.2166
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5204s / 427.9955 s
agent0:                 episode reward: 0.0101,                 loss: nan
agent1:                 episode reward: -0.0101,                 loss: 0.2362
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5913s / 429.5869 s
agent0:                 episode reward: -0.0123,                 loss: nan
agent1:                 episode reward: 0.0123,                 loss: 0.2330
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5566s / 431.1435 s
agent0:                 episode reward: -0.8192,                 loss: nan
agent1:                 episode reward: 0.8192,                 loss: 0.2335
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5648s / 432.7083 s
agent0:                 episode reward: -0.0449,                 loss: nan
agent1:                 episode reward: 0.0449,                 loss: 0.2345
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5359s / 434.2442 s
agent0:                 episode reward: -0.3293,                 loss: nan
agent1:                 episode reward: 0.3293,                 loss: 0.2344
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5678s / 435.8120 s
agent0:                 episode reward: -0.7520,                 loss: nan
agent1:                 episode reward: 0.7520,                 loss: 0.2416
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5532s / 437.3652 s
agent0:                 episode reward: -0.2507,                 loss: nan
agent1:                 episode reward: 0.2507,                 loss: 0.2360
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5767s / 438.9419 s
agent0:                 episode reward: 0.0058,                 loss: nan
agent1:                 episode reward: -0.0058,                 loss: 0.2356
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6250s / 440.5669 s
agent0:                 episode reward: -0.2910,                 loss: nan
agent1:                 episode reward: 0.2910,                 loss: 0.2359
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5616s / 442.1285 s
agent0:                 episode reward: -0.4216,                 loss: nan
agent1:                 episode reward: 0.4216,                 loss: 0.2342
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5782s / 443.7067 s
agent0:                 episode reward: 0.3349,                 loss: nan
agent1:                 episode reward: -0.3349,                 loss: 0.2627
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5833s / 445.2899 s
agent0:                 episode reward: -0.0442,                 loss: nan
agent1:                 episode reward: 0.0442,                 loss: 0.2612
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5817s / 446.8716 s
agent0:                 episode reward: -0.4836,                 loss: nan
agent1:                 episode reward: 0.4836,                 loss: 0.2628
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6143s / 448.4859 s
agent0:                 episode reward: 0.0594,                 loss: nan
agent1:                 episode reward: -0.0594,                 loss: 0.2630
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6308s / 450.1166 s
agent0:                 episode reward: -0.6768,                 loss: nan
agent1:                 episode reward: 0.6768,                 loss: 0.2609
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5903s / 451.7070 s
agent0:                 episode reward: -0.2407,                 loss: nan
agent1:                 episode reward: 0.2407,                 loss: 0.2996
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5848s / 453.2917 s
agent0:                 episode reward: -0.8382,                 loss: nan
agent1:                 episode reward: 0.8382,                 loss: 0.2993
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5793s / 454.8711 s
agent0:                 episode reward: -0.4791,                 loss: nan
agent1:                 episode reward: 0.4791,                 loss: 0.3010
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6257s / 456.4968 s
agent0:                 episode reward: 0.0255,                 loss: nan
agent1:                 episode reward: -0.0255,                 loss: 0.2987
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.5804s / 458.0771 s
agent0:                 episode reward: 0.2994,                 loss: nan
agent1:                 episode reward: -0.2994,                 loss: 0.2990
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6016s / 459.6788 s
agent0:                 episode reward: -0.8535,                 loss: nan
agent1:                 episode reward: 0.8535,                 loss: 0.2924
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6795s / 461.3583 s
agent0:                 episode reward: -0.6221,                 loss: nan
agent1:                 episode reward: 0.6221,                 loss: 0.2800
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6192s / 462.9775 s
agent0:                 episode reward: -0.5092,                 loss: nan
agent1:                 episode reward: 0.5092,                 loss: 0.2815
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6187s / 464.5963 s
agent0:                 episode reward: -0.6829,                 loss: nan
agent1:                 episode reward: 0.6829,                 loss: 0.2793
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6090s / 466.2053 s
agent0:                 episode reward: -0.6397,                 loss: nan
agent1:                 episode reward: 0.6397,                 loss: 0.2790
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6040s / 467.8093 s
agent0:                 episode reward: -0.4601,                 loss: nan
agent1:                 episode reward: 0.4601,                 loss: 0.2015
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6074s / 469.4166 s
agent0:                 episode reward: -0.2606,                 loss: nan
agent1:                 episode reward: 0.2606,                 loss: 0.1808
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6816s / 471.0982 s
agent0:                 episode reward: -0.2070,                 loss: nan
agent1:                 episode reward: 0.2070,                 loss: 0.1801
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6345s / 472.7327 s
agent0:                 episode reward: -0.9074,                 loss: nan
agent1:                 episode reward: 0.9074,                 loss: 0.1795
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6233s / 474.3560 s
agent0:                 episode reward: -0.7164,                 loss: nan
agent1:                 episode reward: 0.7164,                 loss: 0.1762
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6510s / 476.0070 s
agent0:                 episode reward: -0.1655,                 loss: nan
agent1:                 episode reward: 0.1655,                 loss: 0.1768
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6483s / 477.6553 s
agent0:                 episode reward: 1.0166,                 loss: nan
agent1:                 episode reward: -1.0166,                 loss: 0.1685
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6586s / 479.3139 s
agent0:                 episode reward: 0.3246,                 loss: nan
agent1:                 episode reward: -0.3246,                 loss: 0.1702
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6896s / 481.0035 s
agent0:                 episode reward: -0.1616,                 loss: nan
agent1:                 episode reward: 0.1616,                 loss: 0.1665
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6317s / 482.6352 s
agent0:                 episode reward: -0.0550,                 loss: nan
agent1:                 episode reward: 0.0550,                 loss: 0.1682
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6428s / 484.2780 s
agent0:                 episode reward: -0.3772,                 loss: nan
agent1:                 episode reward: 0.3772,                 loss: 0.1959
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6845s / 485.9625 s
agent0:                 episode reward: -0.6117,                 loss: nan
agent1:                 episode reward: 0.6117,                 loss: 0.1974
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6577s / 487.6202 s
agent0:                 episode reward: -0.7840,                 loss: nan
agent1:                 episode reward: 0.7840,                 loss: 0.1959
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6810s / 489.3012 s
agent0:                 episode reward: -0.9084,                 loss: nan
agent1:                 episode reward: 0.9084,                 loss: 0.1967
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7143s / 491.0155 s
agent0:                 episode reward: -1.1127,                 loss: nan
agent1:                 episode reward: 1.1127,                 loss: 0.1968
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6941s / 492.7096 s
agent0:                 episode reward: -0.0059,                 loss: nan
agent1:                 episode reward: 0.0059,                 loss: 0.2160
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6506s / 494.3602 s
agent0:                 episode reward: 0.0015,                 loss: nan
agent1:                 episode reward: -0.0015,                 loss: 0.2165
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7192s / 496.0794 s
agent0:                 episode reward: -0.5299,                 loss: nan
agent1:                 episode reward: 0.5299,                 loss: 0.2148
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6829s / 497.7622 s
agent0:                 episode reward: 0.0210,                 loss: nan
agent1:                 episode reward: -0.0210,                 loss: 0.2159
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6863s / 499.4486 s
agent0:                 episode reward: 0.0679,                 loss: nan
agent1:                 episode reward: -0.0679,                 loss: 0.2146
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7185s / 501.1670 s
agent0:                 episode reward: -1.0292,                 loss: nan
agent1:                 episode reward: 1.0292,                 loss: 0.2295
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6888s / 502.8559 s
agent0:                 episode reward: 0.2897,                 loss: nan
agent1:                 episode reward: -0.2897,                 loss: 0.2287
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7228s / 504.5787 s
agent0:                 episode reward: -0.7490,                 loss: nan
agent1:                 episode reward: 0.7490,                 loss: 0.2280
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7152s / 506.2939 s
agent0:                 episode reward: 0.2137,                 loss: nan
agent1:                 episode reward: -0.2137,                 loss: 0.2282
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6957s / 507.9896 s
agent0:                 episode reward: -0.1834,                 loss: nan
agent1:                 episode reward: 0.1834,                 loss: 0.2280
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7015s / 509.6911 s
agent0:                 episode reward: -0.2852,                 loss: nan
agent1:                 episode reward: 0.2852,                 loss: 0.2291
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7523s / 511.4433 s
agent0:                 episode reward: -0.5675,                 loss: nan
agent1:                 episode reward: 0.5675,                 loss: 0.2233
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7191s / 513.1624 s
agent0:                 episode reward: 0.3040,                 loss: nan
agent1:                 episode reward: -0.3040,                 loss: 0.2247
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6994s / 514.8619 s
agent0:                 episode reward: -0.0314,                 loss: nan
agent1:                 episode reward: 0.0314,                 loss: 0.2250
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7089s / 516.5707 s
agent0:                 episode reward: -0.5521,                 loss: nan
agent1:                 episode reward: 0.5521,                 loss: 0.2232
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.6838s / 518.2545 s
agent0:                 episode reward: -0.0790,                 loss: nan
agent1:                 episode reward: 0.0790,                 loss: 0.2383
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7283s / 519.9828 s
agent0:                 episode reward: -0.2062,                 loss: nan
agent1:                 episode reward: 0.2062,                 loss: 0.2390
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7827s / 521.7655 s
agent0:                 episode reward: -0.7312,                 loss: nan
agent1:                 episode reward: 0.7312,                 loss: 0.2391
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7058s / 523.4713 s
agent0:                 episode reward: -0.0982,                 loss: nan
agent1:                 episode reward: 0.0982,                 loss: 0.2399
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7270s / 525.1983 s
agent0:                 episode reward: -0.4716,                 loss: nan
agent1:                 episode reward: 0.4716,                 loss: 0.2370
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7133s / 526.9116 s
agent0:                 episode reward: 0.1326,                 loss: nan
agent1:                 episode reward: -0.1326,                 loss: 0.2646
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7221s / 528.6337 s
agent0:                 episode reward: -0.6025,                 loss: nan
agent1:                 episode reward: 0.6025,                 loss: 0.2648
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7213s / 530.3550 s
agent0:                 episode reward: -0.4223,                 loss: nan
agent1:                 episode reward: 0.4223,                 loss: 0.2636
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7761s / 532.1311 s
agent0:                 episode reward: -0.5785,                 loss: nan
agent1:                 episode reward: 0.5785,                 loss: 0.2631
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7235s / 533.8546 s
agent0:                 episode reward: -0.0234,                 loss: nan
agent1:                 episode reward: 0.0234,                 loss: 0.2645
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7271s / 535.5817 s
agent0:                 episode reward: -0.5718,                 loss: nan
agent1:                 episode reward: 0.5718,                 loss: 0.2943
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7996s / 537.3813 s
agent0:                 episode reward: -0.1793,                 loss: nan
agent1:                 episode reward: 0.1793,                 loss: 0.2905
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7432s / 539.1245 s
agent0:                 episode reward: -0.6702,                 loss: nan
agent1:                 episode reward: 0.6702,                 loss: 0.2900
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7541s / 540.8786 s
agent0:                 episode reward: 0.1420,                 loss: nan
agent1:                 episode reward: -0.1420,                 loss: 0.2883
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7977s / 542.6763 s
agent0:                 episode reward: 0.1125,                 loss: nan
agent1:                 episode reward: -0.1125,                 loss: 0.2899
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7731s / 544.4494 s
agent0:                 episode reward: -0.6713,                 loss: nan
agent1:                 episode reward: 0.6713,                 loss: 0.2570
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8294s / 546.2788 s
agent0:                 episode reward: -0.6534,                 loss: nan
agent1:                 episode reward: 0.6534,                 loss: 0.2394
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7653s / 548.0441 s
agent0:                 episode reward: -1.2521,                 loss: nan
agent1:                 episode reward: 1.2521,                 loss: 0.2381
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7721s / 549.8161 s
agent0:                 episode reward: -0.2244,                 loss: nan
agent1:                 episode reward: 0.2244,                 loss: 0.2389
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7748s / 551.5909 s
agent0:                 episode reward: -0.6936,                 loss: nan
agent1:                 episode reward: 0.6936,                 loss: 0.2387
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8448s / 553.4358 s
agent0:                 episode reward: -0.8477,                 loss: nan
agent1:                 episode reward: 0.8477,                 loss: 0.1807
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7952s / 555.2309 s
agent0:                 episode reward: -0.9069,                 loss: nan
agent1:                 episode reward: 0.9069,                 loss: 0.1608
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7891s / 557.0200 s
agent0:                 episode reward: -0.1986,                 loss: nan
agent1:                 episode reward: 0.1986,                 loss: 0.1617
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7862s / 558.8061 s
agent0:                 episode reward: -0.4444,                 loss: nan
agent1:                 episode reward: 0.4444,                 loss: 0.1610
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7894s / 560.5956 s
agent0:                 episode reward: -0.8155,                 loss: nan
agent1:                 episode reward: 0.8155,                 loss: 0.1612
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8394s / 562.4350 s
agent0:                 episode reward: -0.5225,                 loss: nan
agent1:                 episode reward: 0.5225,                 loss: 0.1588
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8252s / 564.2603 s
agent0:                 episode reward: -0.7543,                 loss: nan
agent1:                 episode reward: 0.7543,                 loss: 0.1555
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.7790s / 566.0393 s
agent0:                 episode reward: -0.6511,                 loss: nan
agent1:                 episode reward: 0.6511,                 loss: 0.1578
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8074s / 567.8467 s
agent0:                 episode reward: 0.1985,                 loss: nan
agent1:                 episode reward: -0.1985,                 loss: 0.1570
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8097s / 569.6564 s
agent0:                 episode reward: -0.5787,                 loss: nan
agent1:                 episode reward: 0.5787,                 loss: 0.1576
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8413s / 571.4977 s
agent0:                 episode reward: -0.0643,                 loss: nan
agent1:                 episode reward: 0.0643,                 loss: 0.1879
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8572s / 573.3548 s
agent0:                 episode reward: -0.5279,                 loss: nan
agent1:                 episode reward: 0.5279,                 loss: 0.1879
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8171s / 575.1720 s
agent0:                 episode reward: -0.2830,                 loss: nan
agent1:                 episode reward: 0.2830,                 loss: 0.1878
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8318s / 577.0037 s
agent0:                 episode reward: -0.7574,                 loss: nan
agent1:                 episode reward: 0.7574,                 loss: 0.1862
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8010s / 578.8047 s
agent0:                 episode reward: -0.1630,                 loss: nan
agent1:                 episode reward: 0.1630,                 loss: 0.1871
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8611s / 580.6658 s
agent0:                 episode reward: -0.0063,                 loss: nan
agent1:                 episode reward: 0.0063,                 loss: 0.2142
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8214s / 582.4872 s
agent0:                 episode reward: -0.1356,                 loss: nan
agent1:                 episode reward: 0.1356,                 loss: 0.2157
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8573s / 584.3445 s
agent0:                 episode reward: 0.1756,                 loss: nan
agent1:                 episode reward: -0.1756,                 loss: 0.2147
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8424s / 586.1869 s
agent0:                 episode reward: -0.2777,                 loss: nan
agent1:                 episode reward: 0.2777,                 loss: 0.2144
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8521s / 588.0390 s
agent0:                 episode reward: -0.4430,                 loss: nan
agent1:                 episode reward: 0.4430,                 loss: 0.2139
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8206s / 589.8595 s
agent0:                 episode reward: -1.0026,                 loss: nan
agent1:                 episode reward: 1.0026,                 loss: 0.2240
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8387s / 591.6982 s
agent0:                 episode reward: -0.3663,                 loss: nan
agent1:                 episode reward: 0.3663,                 loss: 0.2229
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9035s / 593.6017 s
agent0:                 episode reward: -0.4506,                 loss: nan
agent1:                 episode reward: 0.4506,                 loss: 0.2231
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8707s / 595.4724 s
agent0:                 episode reward: -0.6825,                 loss: nan
agent1:                 episode reward: 0.6825,                 loss: 0.2227
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9220s / 597.3944 s
agent0:                 episode reward: -1.0488,                 loss: nan
agent1:                 episode reward: 1.0488,                 loss: 0.2209/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8713s / 599.2656 s
agent0:                 episode reward: -0.5335,                 loss: nan
agent1:                 episode reward: 0.5335,                 loss: 0.2394
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8518s / 601.1174 s
agent0:                 episode reward: -0.3236,                 loss: nan
agent1:                 episode reward: 0.3236,                 loss: 0.2369
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8661s / 602.9836 s
agent0:                 episode reward: 0.0156,                 loss: nan
agent1:                 episode reward: -0.0156,                 loss: 0.2360
Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9588s / 604.9424 s
agent0:                 episode reward: -0.3429,                 loss: nan
agent1:                 episode reward: 0.3429,                 loss: 0.2345
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8673s / 606.8097 s
agent0:                 episode reward: -0.4327,                 loss: nan
agent1:                 episode reward: 0.4327,                 loss: 0.2346
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8748s / 608.6844 s
agent0:                 episode reward: -0.7502,                 loss: nan
agent1:                 episode reward: 0.7502,                 loss: 0.2411
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8676s / 610.5520 s
agent0:                 episode reward: -0.8187,                 loss: nan
agent1:                 episode reward: 0.8187,                 loss: 0.2390
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.8655s / 612.4176 s
agent0:                 episode reward: -0.4345,                 loss: nan
agent1:                 episode reward: 0.4345,                 loss: 0.2393
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9538s / 614.3714 s
agent0:                 episode reward: -0.7897,                 loss: nan
agent1:                 episode reward: 0.7897,                 loss: 0.2377
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9125s / 616.2839 s
agent0:                 episode reward: -1.1587,                 loss: nan
agent1:                 episode reward: 1.1587,                 loss: 0.2382
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.9066s / 618.1904 s
agent0:                 episode reward: -0.5701,                 loss: nan
agent1:                 episode reward: 0.5701,                 loss: 0.2495
