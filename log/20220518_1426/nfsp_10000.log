pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fdda581ac50>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_10000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_10000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6818s / 0.6818 s
agent0:                 episode reward: -1.2083,                 loss: nan
agent1:                 episode reward: 1.2083,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 0.8869 s
agent0:                 episode reward: -0.0123,                 loss: nan
agent1:                 episode reward: 0.0123,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 1.0859 s
agent0:                 episode reward: 0.1490,                 loss: nan
agent1:                 episode reward: -0.1490,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 1.2884 s
agent0:                 episode reward: 0.3227,                 loss: nan
agent1:                 episode reward: -0.3227,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 1.4881 s
agent0:                 episode reward: 0.2189,                 loss: nan
agent1:                 episode reward: -0.2189,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 1.6869 s
agent0:                 episode reward: -0.0734,                 loss: nan
agent1:                 episode reward: 0.0734,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 1.8897 s
agent0:                 episode reward: 0.0411,                 loss: nan
agent1:                 episode reward: -0.0411,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 2.0896 s
agent0:                 episode reward: 0.3751,                 loss: nan
agent1:                 episode reward: -0.3751,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 2.2851 s
agent0:                 episode reward: 0.5353,                 loss: nan
agent1:                 episode reward: -0.5353,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 2.4839 s
agent0:                 episode reward: -0.1466,                 loss: nan
agent1:                 episode reward: 0.1466,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1926s / 2.6766 s
agent0:                 episode reward: 0.2395,                 loss: nan
agent1:                 episode reward: -0.2395,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1883s / 2.8648 s
agent0:                 episode reward: 0.3167,                 loss: nan
agent1:                 episode reward: -0.3167,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 3.0659 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 3.2618 s
agent0:                 episode reward: 0.1377,                 loss: nan
agent1:                 episode reward: -0.1377,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 3.4550 s
agent0:                 episode reward: -0.1980,                 loss: nan
agent1:                 episode reward: 0.1980,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 3.6551 s
agent0:                 episode reward: -0.1804,                 loss: nan
agent1:                 episode reward: 0.1804,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 3.8509 s
agent0:                 episode reward: 0.2639,                 loss: nan
agent1:                 episode reward: -0.2639,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 4.0473 s
agent0:                 episode reward: 0.2001,                 loss: nan
agent1:                 episode reward: -0.2001,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 4.2481 s
agent0:                 episode reward: 0.2932,                 loss: nan
agent1:                 episode reward: -0.2932,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 4.4478 s
agent0:                 episode reward: 0.4071,                 loss: nan
agent1:                 episode reward: -0.4071,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 4.6470 s
agent0:                 episode reward: -0.0613,                 loss: nan
agent1:                 episode reward: 0.0613,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 4.8462 s
agent0:                 episode reward: -0.0225,                 loss: nan
agent1:                 episode reward: 0.0225,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 5.0434 s
agent0:                 episode reward: 0.1917,                 loss: nan
agent1:                 episode reward: -0.1917,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 5.2423 s
agent0:                 episode reward: -0.2104,                 loss: nan
agent1:                 episode reward: 0.2104,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 5.4409 s
agent0:                 episode reward: 0.1686,                 loss: nan
agent1:                 episode reward: -0.1686,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 5.6392 s
agent0:                 episode reward: -0.1431,                 loss: nan
agent1:                 episode reward: 0.1431,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 5.8396 s
agent0:                 episode reward: 0.0711,                 loss: nan
agent1:                 episode reward: -0.0711,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 6.0413 s
agent0:                 episode reward: 0.2982,                 loss: nan
agent1:                 episode reward: -0.2982,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 6.2372 s
agent0:                 episode reward: -0.0164,                 loss: nan
agent1:                 episode reward: 0.0164,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 6.4330 s
agent0:                 episode reward: 0.1239,                 loss: nan
agent1:                 episode reward: -0.1239,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 6.6292 s
agent0:                 episode reward: 0.2904,                 loss: nan
agent1:                 episode reward: -0.2904,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 6.8240 s
agent0:                 episode reward: -0.0350,                 loss: nan
agent1:                 episode reward: 0.0350,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 7.0262 s
agent0:                 episode reward: 0.2863,                 loss: nan
agent1:                 episode reward: -0.2863,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 7.2240 s
agent0:                 episode reward: 0.2256,                 loss: nan
agent1:                 episode reward: -0.2256,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 7.4204 s
agent0:                 episode reward: 0.2175,                 loss: nan
agent1:                 episode reward: -0.2175,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 7.6195 s
agent0:                 episode reward: -0.3859,                 loss: nan
agent1:                 episode reward: 0.3859,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2048s / 7.8243 s
agent0:                 episode reward: 0.1922,                 loss: nan
agent1:                 episode reward: -0.1922,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 8.0264 s
agent0:                 episode reward: -0.1314,                 loss: nan
agent1:                 episode reward: 0.1314,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 8.2290 s
agent0:                 episode reward: 0.0182,                 loss: nan
agent1:                 episode reward: -0.0182,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 8.4285 s
agent0:                 episode reward: 0.1471,                 loss: nan
agent1:                 episode reward: -0.1471,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 8.6232 s
agent0:                 episode reward: 0.1695,                 loss: nan
agent1:                 episode reward: -0.1695,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 8.8232 s
agent0:                 episode reward: 0.1041,                 loss: nan
agent1:                 episode reward: -0.1041,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 9.0185 s
agent0:                 episode reward: 0.1262,                 loss: nan
agent1:                 episode reward: -0.1262,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 9.2180 s
agent0:                 episode reward: 0.1950,                 loss: nan
agent1:                 episode reward: -0.1950,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 9.4151 s
agent0:                 episode reward: 0.0845,                 loss: nan
agent1:                 episode reward: -0.0845,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 9.6118 s
agent0:                 episode reward: 0.2440,                 loss: nan
agent1:                 episode reward: -0.2440,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 9.8107 s
agent0:                 episode reward: -0.3225,                 loss: nan
agent1:                 episode reward: 0.3225,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 10.0127 s
agent0:                 episode reward: 0.4368,                 loss: nan
agent1:                 episode reward: -0.4368,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 10.2104 s
agent0:                 episode reward: -0.4345,                 loss: nan
agent1:                 episode reward: 0.4345,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 10.4063 s
agent0:                 episode reward: 0.0016,                 loss: nan
agent1:                 episode reward: -0.0016,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 10.6063 s
agent0:                 episode reward: 0.0719,                 loss: nan
agent1:                 episode reward: -0.0719,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 10.8078 s
agent0:                 episode reward: 0.3292,                 loss: nan
agent1:                 episode reward: -0.3292,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 11.0072 s
agent0:                 episode reward: 0.2737,                 loss: nan
agent1:                 episode reward: -0.2737,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 11.2102 s
agent0:                 episode reward: -0.1267,                 loss: nan
agent1:                 episode reward: 0.1267,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2105s / 11.4206 s
agent0:                 episode reward: 0.0973,                 loss: nan
agent1:                 episode reward: -0.0973,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 11.6168 s
agent0:                 episode reward: 0.0691,                 loss: nan
agent1:                 episode reward: -0.0691,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 11.8160 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 12.0103 s
agent0:                 episode reward: 0.2504,                 loss: nan
agent1:                 episode reward: -0.2504,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 12.2147 s
agent0:                 episode reward: 0.0552,                 loss: nan
agent1:                 episode reward: -0.0552,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 12.4144 s
agent0:                 episode reward: 0.0556,                 loss: nan
agent1:                 episode reward: -0.0556,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 12.6137 s
agent0:                 episode reward: -0.2059,                 loss: nan
agent1:                 episode reward: 0.2059,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 12.8135 s
agent0:                 episode reward: 0.0405,                 loss: nan
agent1:                 episode reward: -0.0405,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 13.0107 s
agent0:                 episode reward: 0.0064,                 loss: nan
agent1:                 episode reward: -0.0064,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 13.2077 s
agent0:                 episode reward: 0.2553,                 loss: nan
agent1:                 episode reward: -0.2553,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 13.4035 s
agent0:                 episode reward: 0.2107,                 loss: nan
agent1:                 episode reward: -0.2107,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 13.6006 s
agent0:                 episode reward: -0.1354,                 loss: nan
agent1:                 episode reward: 0.1354,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 13.7963 s
agent0:                 episode reward: -0.3053,                 loss: nan
agent1:                 episode reward: 0.3053,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 13.9904 s
agent0:                 episode reward: 0.4689,                 loss: nan
agent1:                 episode reward: -0.4689,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 14.1902 s
agent0:                 episode reward: 0.2130,                 loss: nan
agent1:                 episode reward: -0.2130,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 14.3871 s
agent0:                 episode reward: 0.1706,                 loss: nan
agent1:                 episode reward: -0.1706,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 14.5831 s
agent0:                 episode reward: -0.0928,                 loss: nan
agent1:                 episode reward: 0.0928,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 14.7766 s
agent0:                 episode reward: 0.1181,                 loss: nan
agent1:                 episode reward: -0.1181,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 14.9749 s
agent0:                 episode reward: 0.0504,                 loss: nan
agent1:                 episode reward: -0.0504,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 15.1774 s
agent0:                 episode reward: 0.0336,                 loss: nan
agent1:                 episode reward: -0.0336,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 15.3794 s
agent0:                 episode reward: 0.2838,                 loss: nan
agent1:                 episode reward: -0.2838,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 15.5777 s
agent0:                 episode reward: -0.0777,                 loss: nan
agent1:                 episode reward: 0.0777,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 15.7796 s
agent0:                 episode reward: 0.1355,                 loss: nan
agent1:                 episode reward: -0.1355,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 15.9781 s
agent0:                 episode reward: -0.3420,                 loss: nan
agent1:                 episode reward: 0.3420,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 16.1804 s
agent0:                 episode reward: 0.3876,                 loss: nan
agent1:                 episode reward: -0.3876,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 16.3746 s
agent0:                 episode reward: 0.4139,                 loss: nan
agent1:                 episode reward: -0.4139,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 16.5750 s
agent0:                 episode reward: 0.3313,                 loss: nan
agent1:                 episode reward: -0.3313,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 16.7783 s
agent0:                 episode reward: 0.1008,                 loss: nan
agent1:                 episode reward: -0.1008,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 16.9721 s
agent0:                 episode reward: 0.3856,                 loss: nan
agent1:                 episode reward: -0.3856,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 17.1731 s
agent0:                 episode reward: -0.1444,                 loss: nan
agent1:                 episode reward: 0.1444,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 17.3727 s
agent0:                 episode reward: 0.1423,                 loss: nan
agent1:                 episode reward: -0.1423,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 17.5735 s
agent0:                 episode reward: 0.2545,                 loss: nan
agent1:                 episode reward: -0.2545,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1946s / 17.7681 s
agent0:                 episode reward: 0.2806,                 loss: nan
agent1:                 episode reward: -0.2806,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 17.9703 s
agent0:                 episode reward: 0.1354,                 loss: nan
agent1:                 episode reward: -0.1354,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 18.1659 s
agent0:                 episode reward: 0.1181,                 loss: nan
agent1:                 episode reward: -0.1181,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 18.3638 s
agent0:                 episode reward: 0.4892,                 loss: nan
agent1:                 episode reward: -0.4892,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 18.5605 s
agent0:                 episode reward: -0.1925,                 loss: nan
agent1:                 episode reward: 0.1925,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 18.7578 s
agent0:                 episode reward: 0.2836,                 loss: nan
agent1:                 episode reward: -0.2836,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 18.9570 s
agent0:                 episode reward: -0.4218,                 loss: nan
agent1:                 episode reward: 0.4218,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 19.1553 s
agent0:                 episode reward: 0.4175,                 loss: nan
agent1:                 episode reward: -0.4175,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 19.3555 s
agent0:                 episode reward: 0.2485,                 loss: nan
agent1:                 episode reward: -0.2485,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 19.5540 s
agent0:                 episode reward: 0.0758,                 loss: nan
agent1:                 episode reward: -0.0758,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 19.7542 s
agent0:                 episode reward: 0.0078,                 loss: nan
agent1:                 episode reward: -0.0078,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 19.9538 s
agent0:                 episode reward: -0.0524,                 loss: nan
agent1:                 episode reward: 0.0524,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 20.1467 s
agent0:                 episode reward: 0.1013,                 loss: nan
agent1:                 episode reward: -0.1013,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 20.3436 s
agent0:                 episode reward: 0.2873,                 loss: nan
agent1:                 episode reward: -0.2873,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 20.5464 s
agent0:                 episode reward: 0.3118,                 loss: nan
agent1:                 episode reward: -0.3118,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2059s / 20.7523 s
agent0:                 episode reward: -0.0477,                 loss: nan
agent1:                 episode reward: 0.0477,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 20.9500 s
agent0:                 episode reward: -0.4819,                 loss: nan
agent1:                 episode reward: 0.4819,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 21.1439 s
agent0:                 episode reward: 0.0313,                 loss: nan
agent1:                 episode reward: -0.0313,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 21.3445 s
agent0:                 episode reward: 0.3227,                 loss: nan
agent1:                 episode reward: -0.3227,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 21.5404 s
agent0:                 episode reward: 0.0872,                 loss: nan
agent1:                 episode reward: -0.0872,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 21.7341 s
agent0:                 episode reward: 0.0169,                 loss: nan
agent1:                 episode reward: -0.0169,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 21.9338 s
agent0:                 episode reward: 0.0534,                 loss: nan
agent1:                 episode reward: -0.0534,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 22.1318 s
agent0:                 episode reward: 0.0106,                 loss: nan
agent1:                 episode reward: -0.0106,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 22.3318 s
agent0:                 episode reward: 0.0919,                 loss: nan
agent1:                 episode reward: -0.0919,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 22.5326 s
agent0:                 episode reward: -0.2282,                 loss: nan
agent1:                 episode reward: 0.2282,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 22.7309 s
agent0:                 episode reward: 0.0669,                 loss: nan
agent1:                 episode reward: -0.0669,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 22.9268 s
agent0:                 episode reward: 0.1999,                 loss: nan
agent1:                 episode reward: -0.1999,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 23.1257 s
agent0:                 episode reward: 0.1034,                 loss: nan
agent1:                 episode reward: -0.1034,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 23.3224 s
agent0:                 episode reward: 0.0960,                 loss: nan
agent1:                 episode reward: -0.0960,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 23.5207 s
agent0:                 episode reward: -0.0579,                 loss: nan
agent1:                 episode reward: 0.0579,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 23.7154 s
agent0:                 episode reward: 0.2229,                 loss: nan
agent1:                 episode reward: -0.2229,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 23.9119 s
agent0:                 episode reward: 0.3683,                 loss: nan
agent1:                 episode reward: -0.3683,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 24.1096 s
agent0:                 episode reward: -0.3260,                 loss: nan
agent1:                 episode reward: 0.3260,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 24.3076 s
agent0:                 episode reward: 0.1238,                 loss: nan
agent1:                 episode reward: -0.1238,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 24.5062 s
agent0:                 episode reward: 0.0167,                 loss: nan
agent1:                 episode reward: -0.0167,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 24.7080 s
agent0:                 episode reward: 0.0560,                 loss: nan
agent1:                 episode reward: -0.0560,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 24.9047 s
agent0:                 episode reward: -0.3359,                 loss: nan
agent1:                 episode reward: 0.3359,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 25.1023 s
agent0:                 episode reward: -0.4080,                 loss: nan
agent1:                 episode reward: 0.4080,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2032s / 25.3055 s
agent0:                 episode reward: -0.1089,                 loss: nan
agent1:                 episode reward: 0.1089,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 25.5041 s
agent0:                 episode reward: 0.0690,                 loss: nan
agent1:                 episode reward: -0.0690,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 25.6994 s
agent0:                 episode reward: 0.0075,                 loss: nan
agent1:                 episode reward: -0.0075,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 25.8967 s
agent0:                 episode reward: -0.0198,                 loss: nan
agent1:                 episode reward: 0.0198,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 26.0966 s
agent0:                 episode reward: 0.4070,                 loss: nan
agent1:                 episode reward: -0.4070,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 26.2979 s
agent0:                 episode reward: 0.0615,                 loss: nan
agent1:                 episode reward: -0.0615,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1921s / 26.4900 s
agent0:                 episode reward: -0.1672,                 loss: nan
agent1:                 episode reward: 0.1672,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 26.6888 s
agent0:                 episode reward: -0.0928,                 loss: nan
agent1:                 episode reward: 0.0928,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 26.8816 s
agent0:                 episode reward: 0.3427,                 loss: nan
agent1:                 episode reward: -0.3427,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1808s / 27.0624 s
agent0:                 episode reward: -0.1549,                 loss: nan
agent1:                 episode reward: 0.1549,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 27.2596 s
agent0:                 episode reward: 0.1418,                 loss: nan
agent1:                 episode reward: -0.1418,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 27.4594 s
agent0:                 episode reward: 0.2947,                 loss: nan
agent1:                 episode reward: -0.2947,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 27.6591 s
agent0:                 episode reward: 0.4498,                 loss: nan
agent1:                 episode reward: -0.4498,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 27.8544 s
agent0:                 episode reward: 0.1240,                 loss: nan
agent1:                 episode reward: -0.1240,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2354s / 28.0898 s
agent0:                 episode reward: -0.1347,                 loss: nan
agent1:                 episode reward: 0.1347,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 28.2929 s
agent0:                 episode reward: 0.3307,                 loss: nan
agent1:                 episode reward: -0.3307,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 28.4941 s
agent0:                 episode reward: 0.1198,                 loss: nan
agent1:                 episode reward: -0.1198,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 28.6927 s
agent0:                 episode reward: -0.4590,                 loss: nan
agent1:                 episode reward: 0.4590,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 28.8917 s
agent0:                 episode reward: -0.3828,                 loss: nan
agent1:                 episode reward: 0.3828,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 29.0891 s
agent0:                 episode reward: 0.2685,                 loss: nan
agent1:                 episode reward: -0.2685,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 29.2879 s
agent0:                 episode reward: 0.0991,                 loss: nan
agent1:                 episode reward: -0.0991,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 29.4858 s
agent0:                 episode reward: 0.1505,                 loss: nan
agent1:                 episode reward: -0.1505,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 29.6844 s
agent0:                 episode reward: -0.2449,                 loss: nan
agent1:                 episode reward: 0.2449,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 29.8788 s
agent0:                 episode reward: -0.1510,                 loss: nan
agent1:                 episode reward: 0.1510,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 30.0780 s
agent0:                 episode reward: 0.2882,                 loss: nan
agent1:                 episode reward: -0.2882,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 30.2756 s
agent0:                 episode reward: 0.4796,                 loss: nan
agent1:                 episode reward: -0.4796,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 30.4695 s
agent0:                 episode reward: 0.1579,                 loss: nan
agent1:                 episode reward: -0.1579,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 30.6686 s
agent0:                 episode reward: 0.3568,                 loss: nan
agent1:                 episode reward: -0.3568,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 30.8667 s
agent0:                 episode reward: 0.0810,                 loss: nan
agent1:                 episode reward: -0.0810,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 31.0658 s
agent0:                 episode reward: -0.2834,                 loss: nan
agent1:                 episode reward: 0.2834,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 31.2648 s
agent0:                 episode reward: 0.1839,                 loss: nan
agent1:                 episode reward: -0.1839,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 31.4608 s
agent0:                 episode reward: 0.2151,                 loss: nan
agent1:                 episode reward: -0.2151,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 31.6592 s
agent0:                 episode reward: 0.0525,                 loss: nan
agent1:                 episode reward: -0.0525,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 31.8580 s
agent0:                 episode reward: 0.1380,                 loss: nan
agent1:                 episode reward: -0.1380,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 32.0572 s
agent0:                 episode reward: 0.0152,                 loss: nan
agent1:                 episode reward: -0.0152,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 32.2532 s
agent0:                 episode reward: -0.0541,                 loss: nan
agent1:                 episode reward: 0.0541,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 32.4516 s
agent0:                 episode reward: 0.0610,                 loss: nan
agent1:                 episode reward: -0.0610,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 32.6448 s
agent0:                 episode reward: 0.0311,                 loss: nan
agent1:                 episode reward: -0.0311,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 32.8403 s
agent0:                 episode reward: -0.0416,                 loss: nan
agent1:                 episode reward: 0.0416,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1918s / 33.0321 s
agent0:                 episode reward: 0.1798,                 loss: nan
agent1:                 episode reward: -0.1798,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1927s / 33.2248 s
agent0:                 episode reward: -0.0778,                 loss: nan
agent1:                 episode reward: 0.0778,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 33.4176 s
agent0:                 episode reward: 0.1002,                 loss: nan
agent1:                 episode reward: -0.1002,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 33.6114 s
agent0:                 episode reward: 0.2652,                 loss: nan
agent1:                 episode reward: -0.2652,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3481s / 33.9595 s
agent0:                 episode reward: -0.0280,                 loss: nan
agent1:                 episode reward: 0.0280,                 loss: 0.4474
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 34.5395 s
agent0:                 episode reward: -0.2938,                 loss: nan
agent1:                 episode reward: 0.2938,                 loss: 0.4395
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 35.1246 s
agent0:                 episode reward: 0.4419,                 loss: nan
agent1:                 episode reward: -0.4419,                 loss: 0.4320
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 35.7112 s
agent0:                 episode reward: 0.0402,                 loss: nan
agent1:                 episode reward: -0.0402,                 loss: 0.4244
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 36.2966 s
agent0:                 episode reward: -0.0325,                 loss: nan
agent1:                 episode reward: 0.0325,                 loss: 0.4160
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5810s / 36.8776 s
agent0:                 episode reward: 0.0700,                 loss: nan
agent1:                 episode reward: -0.0700,                 loss: 0.4069
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 37.4565 s
agent0:                 episode reward: 0.0043,                 loss: nan
agent1:                 episode reward: -0.0043,                 loss: 0.3990
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5840s / 38.0406 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.3943
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5829s / 38.6235 s
agent0:                 episode reward: -0.0532,                 loss: nan
agent1:                 episode reward: 0.0532,                 loss: 0.3927
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5798s / 39.2033 s
agent0:                 episode reward: -0.3405,                 loss: nan
agent1:                 episode reward: 0.3405,                 loss: 0.3870
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 39.7864 s
agent0:                 episode reward: -0.0085,                 loss: nan
agent1:                 episode reward: 0.0085,                 loss: 0.3864
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5849s / 40.3713 s
agent0:                 episode reward: -0.1733,                 loss: nan
agent1:                 episode reward: 0.1733,                 loss: 0.3844
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 40.9519 s
agent0:                 episode reward: -0.3661,                 loss: nan
agent1:                 episode reward: 0.3661,                 loss: 0.3843
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 41.5377 s
agent0:                 episode reward: 0.1654,                 loss: nan
agent1:                 episode reward: -0.1654,                 loss: 0.3840
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 42.1168 s
agent0:                 episode reward: -0.4644,                 loss: nan
agent1:                 episode reward: 0.4644,                 loss: 0.3805
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 42.7099 s
agent0:                 episode reward: 0.2149,                 loss: nan
agent1:                 episode reward: -0.2149,                 loss: 0.3820
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 43.3040 s
agent0:                 episode reward: -0.0084,                 loss: nan
agent1:                 episode reward: 0.0084,                 loss: 0.3780
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 43.8934 s
agent0:                 episode reward: -0.1451,                 loss: nan
agent1:                 episode reward: 0.1451,                 loss: 0.3746
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 44.4821 s
agent0:                 episode reward: -0.3924,                 loss: nan
agent1:                 episode reward: 0.3924,                 loss: 0.3625
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 45.0709 s
agent0:                 episode reward: -0.5251,                 loss: nan
agent1:                 episode reward: 0.5251,                 loss: 0.3605
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 45.6526 s
agent0:                 episode reward: 0.1252,                 loss: nan
agent1:                 episode reward: -0.1252,                 loss: 0.3584
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 46.2385 s
agent0:                 episode reward: -0.5557,                 loss: nan
agent1:                 episode reward: 0.5557,                 loss: 0.3546
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 46.8216 s
agent0:                 episode reward: -0.1742,                 loss: nan
agent1:                 episode reward: 0.1742,                 loss: 0.3511
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5850s / 47.4066 s
agent0:                 episode reward: -0.5805,                 loss: nan
agent1:                 episode reward: 0.5805,                 loss: 0.3489
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 47.9926 s
agent0:                 episode reward: -0.6031,                 loss: nan
agent1:                 episode reward: 0.6031,                 loss: 0.3485
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 48.5804 s
agent0:                 episode reward: -0.5535,                 loss: nan
agent1:                 episode reward: 0.5535,                 loss: 0.3419
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 49.1668 s
agent0:                 episode reward: -0.7758,                 loss: nan
agent1:                 episode reward: 0.7758,                 loss: 0.3431
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5816s / 49.7484 s
agent0:                 episode reward: -0.6255,                 loss: nan
agent1:                 episode reward: 0.6255,                 loss: 0.3424
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 50.3342 s
agent0:                 episode reward: -0.3622,                 loss: nan
agent1:                 episode reward: 0.3622,                 loss: 0.3356
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5787s / 50.9129 s
agent0:                 episode reward: -0.5669,                 loss: nan
agent1:                 episode reward: 0.5669,                 loss: 0.3360
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 51.5006 s
agent0:                 episode reward: -0.9755,                 loss: nan
agent1:                 episode reward: 0.9755,                 loss: 0.3316
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 52.0900 s
agent0:                 episode reward: -0.9018,                 loss: nan
agent1:                 episode reward: 0.9018,                 loss: 0.3295
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 52.6736 s
agent0:                 episode reward: -0.1545,                 loss: nan
agent1:                 episode reward: 0.1545,                 loss: 0.3243
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 53.2655 s
agent0:                 episode reward: -0.4103,                 loss: nan
agent1:                 episode reward: 0.4103,                 loss: 0.3249
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 53.8609 s
agent0:                 episode reward: -0.5426,                 loss: nan
agent1:                 episode reward: 0.5426,                 loss: 0.3288
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 54.4522 s
agent0:                 episode reward: -0.4262,                 loss: nan
agent1:                 episode reward: 0.4262,                 loss: 0.3214
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 55.0381 s
agent0:                 episode reward: -0.1570,                 loss: nan
agent1:                 episode reward: 0.1570,                 loss: 0.3179
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 55.6274 s
agent0:                 episode reward: -0.8765,                 loss: nan
agent1:                 episode reward: 0.8765,                 loss: 0.3157
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 56.2107 s
agent0:                 episode reward: -0.8346,                 loss: nan
agent1:                 episode reward: 0.8346,                 loss: 0.3178
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 56.8008 s
agent0:                 episode reward: -0.4235,                 loss: nan
agent1:                 episode reward: 0.4235,                 loss: 0.3143
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5808s / 57.3816 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: 0.3120
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 57.9647 s
agent0:                 episode reward: -0.6680,                 loss: nan
agent1:                 episode reward: 0.6680,                 loss: 0.3104
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 58.5492 s
agent0:                 episode reward: -0.2960,                 loss: nan
agent1:                 episode reward: 0.2960,                 loss: 0.3157
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 59.1292 s
agent0:                 episode reward: -0.5892,                 loss: nan
agent1:                 episode reward: 0.5892,                 loss: 0.3103
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 59.7205 s
agent0:                 episode reward: -0.3318,                 loss: nan
agent1:                 episode reward: 0.3318,                 loss: 0.3081
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 60.3082 s
agent0:                 episode reward: -0.1656,                 loss: nan
agent1:                 episode reward: 0.1656,                 loss: 0.3084
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 60.9016 s
agent0:                 episode reward: -0.1494,                 loss: nan
agent1:                 episode reward: 0.1494,                 loss: 0.3071
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 61.4923 s
agent0:                 episode reward: -0.8827,                 loss: nan
agent1:                 episode reward: 0.8827,                 loss: 0.3089
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 62.0752 s
agent0:                 episode reward: -0.4078,                 loss: nan
agent1:                 episode reward: 0.4078,                 loss: 0.3114
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 62.6677 s
agent0:                 episode reward: -0.4291,                 loss: nan
agent1:                 episode reward: 0.4291,                 loss: 0.3062
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 63.2556 s
agent0:                 episode reward: -0.5283,                 loss: nan
agent1:                 episode reward: 0.5283,                 loss: 0.3057
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 63.8452 s
agent0:                 episode reward: -0.2090,                 loss: nan
agent1:                 episode reward: 0.2090,                 loss: 0.2808
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 64.4310 s
agent0:                 episode reward: -0.6994,                 loss: nan
agent1:                 episode reward: 0.6994,                 loss: 0.2815
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 65.0133 s
agent0:                 episode reward: -0.5343,                 loss: nan
agent1:                 episode reward: 0.5343,                 loss: 0.2828
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5818s / 65.5951 s
agent0:                 episode reward: -0.6759,                 loss: nan
agent1:                 episode reward: 0.6759,                 loss: 0.2799
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5783s / 66.1733 s
agent0:                 episode reward: -0.5815,                 loss: nan
agent1:                 episode reward: 0.5815,                 loss: 0.2827
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 66.7553 s
agent0:                 episode reward: -0.0872,                 loss: nan
agent1:                 episode reward: 0.0872,                 loss: 0.2810
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 67.3399 s
agent0:                 episode reward: -0.3360,                 loss: nan
agent1:                 episode reward: 0.3360,                 loss: 0.2794
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 67.9291 s
agent0:                 episode reward: -0.5437,                 loss: nan
agent1:                 episode reward: 0.5437,                 loss: 0.2792
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5810s / 68.5101 s
agent0:                 episode reward: -0.4994,                 loss: nan
agent1:                 episode reward: 0.4994,                 loss: 0.2819
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 69.0957 s
agent0:                 episode reward: -0.5750,                 loss: nan
agent1:                 episode reward: 0.5750,                 loss: 0.2813
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 69.6816 s
agent0:                 episode reward: -0.4447,                 loss: nan
agent1:                 episode reward: 0.4447,                 loss: 0.2797
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 70.2686 s
agent0:                 episode reward: -0.5215,                 loss: nan
agent1:                 episode reward: 0.5215,                 loss: 0.2778
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 70.8517 s
agent0:                 episode reward: -0.5934,                 loss: nan
agent1:                 episode reward: 0.5934,                 loss: 0.2790
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 71.4418 s
agent0:                 episode reward: -0.5470,                 loss: nan
agent1:                 episode reward: 0.5470,                 loss: 0.2783
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 72.0274 s
agent0:                 episode reward: -0.4320,                 loss: nan
agent1:                 episode reward: 0.4320,                 loss: 0.2792
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 72.6157 s
agent0:                 episode reward: -0.3139,                 loss: nan
agent1:                 episode reward: 0.3139,                 loss: 0.2800
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 73.2059 s
agent0:                 episode reward: -0.6847,                 loss: nan
agent1:                 episode reward: 0.6847,                 loss: 0.3050
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 73.7993 s
agent0:                 episode reward: -0.5597,                 loss: nan
agent1:                 episode reward: 0.5597,                 loss: 0.3092
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 74.3858 s
agent0:                 episode reward: -0.8006,                 loss: nan
agent1:                 episode reward: 0.8006,                 loss: 0.3095
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 74.9695 s
agent0:                 episode reward: -0.6723,                 loss: nan
agent1:                 episode reward: 0.6723,                 loss: 0.3102
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5814s / 75.5509 s
agent0:                 episode reward: -0.7376,                 loss: nan
agent1:                 episode reward: 0.7376,                 loss: 0.3122
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 76.1366 s
agent0:                 episode reward: -0.6259,                 loss: nan
agent1:                 episode reward: 0.6259,                 loss: 0.3098
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 76.7212 s
agent0:                 episode reward: -0.5645,                 loss: nan
agent1:                 episode reward: 0.5645,                 loss: 0.3107
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 77.3123 s
agent0:                 episode reward: -0.2660,                 loss: nan
agent1:                 episode reward: 0.2660,                 loss: 0.3086
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 77.8979 s
agent0:                 episode reward: -0.3756,                 loss: nan
agent1:                 episode reward: 0.3756,                 loss: 0.3105
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 78.4877 s
agent0:                 episode reward: -0.2930,                 loss: nan
agent1:                 episode reward: 0.2930,                 loss: 0.3117
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 79.0729 s
agent0:                 episode reward: -0.4613,                 loss: nan
agent1:                 episode reward: 0.4613,                 loss: 0.3125
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5827s / 79.6556 s
agent0:                 episode reward: -0.2308,                 loss: nan
agent1:                 episode reward: 0.2308,                 loss: 0.3121
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5804s / 80.2361 s
agent0:                 episode reward: -0.2879,                 loss: nan
agent1:                 episode reward: 0.2879,                 loss: 0.3116
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 80.8206 s
agent0:                 episode reward: -0.2524,                 loss: nan
agent1:                 episode reward: 0.2524,                 loss: 0.3101
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 81.4065 s
agent0:                 episode reward: -0.4089,                 loss: nan
agent1:                 episode reward: 0.4089,                 loss: 0.3113
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 81.9910 s
agent0:                 episode reward: -0.2677,                 loss: nan
agent1:                 episode reward: 0.2677,                 loss: 0.3099
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 82.5798 s
agent0:                 episode reward: -0.6663,                 loss: nan
agent1:                 episode reward: 0.6663,                 loss: 0.3072
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5884s / 83.1682 s
agent0:                 episode reward: -0.1797,                 loss: nan
agent1:                 episode reward: 0.1797,                 loss: 0.3052
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 83.7592 s
agent0:                 episode reward: -0.3974,                 loss: nan
agent1:                 episode reward: 0.3974,                 loss: 0.3051
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 84.3409 s
agent0:                 episode reward: -0.5266,                 loss: nan
agent1:                 episode reward: 0.5266,                 loss: 0.2999
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 84.9267 s
agent0:                 episode reward: -0.6005,                 loss: nan
agent1:                 episode reward: 0.6005,                 loss: 0.3043
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 85.5217 s
agent0:                 episode reward: -0.3407,                 loss: nan
agent1:                 episode reward: 0.3407,                 loss: 0.3082
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 86.1092 s
agent0:                 episode reward: -0.3881,                 loss: nan
agent1:                 episode reward: 0.3881,                 loss: 0.3038
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 86.7091 s
agent0:                 episode reward: -0.5895,                 loss: nan
agent1:                 episode reward: 0.5895,                 loss: 0.3080
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 87.2958 s
agent0:                 episode reward: -0.9673,                 loss: nan
agent1:                 episode reward: 0.9673,                 loss: 0.3080
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 87.8887 s
agent0:                 episode reward: -0.4199,                 loss: nan
agent1:                 episode reward: 0.4199,                 loss: 0.3061
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 88.4855 s
agent0:                 episode reward: -1.0222,                 loss: nan
agent1:                 episode reward: 1.0222,                 loss: 0.3086
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5802s / 89.0657 s
agent0:                 episode reward: -0.3815,                 loss: nan
agent1:                 episode reward: 0.3815,                 loss: 0.3060
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 89.6628 s
agent0:                 episode reward: -0.6715,                 loss: nan
agent1:                 episode reward: 0.6715,                 loss: 0.3070
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 90.2507 s
agent0:                 episode reward: -0.6244,                 loss: nan
agent1:                 episode reward: 0.6244,                 loss: 0.3058
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 90.8445 s
agent0:                 episode reward: -0.5644,                 loss: nan
agent1:                 episode reward: 0.5644,                 loss: 0.3062
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 91.4276 s
agent0:                 episode reward: -0.5855,                 loss: nan
agent1:                 episode reward: 0.5855,                 loss: 0.3059
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 92.0246 s
agent0:                 episode reward: -1.0593,                 loss: nan
agent1:                 episode reward: 1.0593,                 loss: 0.3074
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 92.6237 s
agent0:                 episode reward: -0.7313,                 loss: nan
agent1:                 episode reward: 0.7313,                 loss: 0.3010
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 93.2164 s
agent0:                 episode reward: -0.3413,                 loss: nan
agent1:                 episode reward: 0.3413,                 loss: 0.2943
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 93.8022 s
agent0:                 episode reward: -0.6951,                 loss: nan
agent1:                 episode reward: 0.6951,                 loss: 0.2962
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 94.3936 s
agent0:                 episode reward: -0.8209,                 loss: nan
agent1:                 episode reward: 0.8209,                 loss: 0.2986
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 94.9801 s
agent0:                 episode reward: -0.8302,                 loss: nan
agent1:                 episode reward: 0.8302,                 loss: 0.2957
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 95.5748 s
agent0:                 episode reward: -0.3470,                 loss: nan
agent1:                 episode reward: 0.3470,                 loss: 0.2968
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 96.1684 s
agent0:                 episode reward: -0.5384,                 loss: nan
agent1:                 episode reward: 0.5384,                 loss: 0.2938
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 96.7621 s
agent0:                 episode reward: -0.2588,                 loss: nan
agent1:                 episode reward: 0.2588,                 loss: 0.2982
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 97.3523 s
agent0:                 episode reward: -0.6081,                 loss: nan
agent1:                 episode reward: 0.6081,                 loss: 0.2940
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 97.9437 s
agent0:                 episode reward: -0.5668,                 loss: nan
agent1:                 episode reward: 0.5668,                 loss: 0.2960
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 98.5385 s
agent0:                 episode reward: -0.2070,                 loss: nan
agent1:                 episode reward: 0.2070,                 loss: 0.2980
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 99.1394 s
agent0:                 episode reward: -0.5524,                 loss: nan
agent1:                 episode reward: 0.5524,                 loss: 0.2952
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 99.7282 s
agent0:                 episode reward: -0.6148,                 loss: nan
agent1:                 episode reward: 0.6148,                 loss: 0.2930
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 100.3204 s
agent0:                 episode reward: -0.2911,                 loss: nan
agent1:                 episode reward: 0.2911,                 loss: 0.2983
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 100.9112 s
agent0:                 episode reward: -0.3339,                 loss: nan
agent1:                 episode reward: 0.3339,                 loss: 0.2924
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 101.5082 s
agent0:                 episode reward: -0.2081,                 loss: nan
agent1:                 episode reward: 0.2081,                 loss: 0.2958
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 102.0921 s
agent0:                 episode reward: -0.7402,                 loss: nan
agent1:                 episode reward: 0.7402,                 loss: 0.2961
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 102.6917 s
agent0:                 episode reward: -0.7180,                 loss: nan
agent1:                 episode reward: 0.7180,                 loss: 0.3013
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 103.2829 s
agent0:                 episode reward: -0.4758,                 loss: nan
agent1:                 episode reward: 0.4758,                 loss: 0.3066
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 103.8735 s
agent0:                 episode reward: -0.4500,                 loss: nan
agent1:                 episode reward: 0.4500,                 loss: 0.3086
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 104.4674 s
agent0:                 episode reward: -0.1930,                 loss: nan
agent1:                 episode reward: 0.1930,                 loss: 0.3074
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 105.0623 s
agent0:                 episode reward: -0.7557,                 loss: nan
agent1:                 episode reward: 0.7557,                 loss: 0.3076
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 105.6597 s
agent0:                 episode reward: -0.4206,                 loss: nan
agent1:                 episode reward: 0.4206,                 loss: 0.3063
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 106.2460 s
agent0:                 episode reward: -0.5443,                 loss: nan
agent1:                 episode reward: 0.5443,                 loss: 0.3087
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 106.8464 s
agent0:                 episode reward: -0.6998,                 loss: nan
agent1:                 episode reward: 0.6998,                 loss: 0.3075
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 107.4361 s
agent0:                 episode reward: -0.5769,                 loss: nan
agent1:                 episode reward: 0.5769,                 loss: 0.3068
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 108.0285 s
agent0:                 episode reward: -0.4836,                 loss: nan
agent1:                 episode reward: 0.4836,                 loss: 0.3076
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5873s / 108.6157 s
agent0:                 episode reward: -0.3609,                 loss: nan
agent1:                 episode reward: 0.3609,                 loss: 0.3080
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5855s / 109.2012 s
agent0:                 episode reward: -0.4750,                 loss: nan
agent1:                 episode reward: 0.4750,                 loss: 0.3092
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5789s / 109.7801 s
agent0:                 episode reward: -0.4385,                 loss: nan
agent1:                 episode reward: 0.4385,                 loss: 0.3104
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 110.3764 s
agent0:                 episode reward: -0.5785,                 loss: nan
agent1:                 episode reward: 0.5785,                 loss: 0.3054
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 110.9665 s
agent0:                 episode reward: -0.4403,                 loss: nan
agent1:                 episode reward: 0.4403,                 loss: 0.3112
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 111.5607 s
agent0:                 episode reward: -1.0579,                 loss: nan
agent1:                 episode reward: 1.0579,                 loss: 0.3092
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 112.1477 s
agent0:                 episode reward: -0.5646,                 loss: nan
agent1:                 episode reward: 0.5646,                 loss: 0.3057
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5950s / 112.7427 s
agent0:                 episode reward: -0.5120,                 loss: nan
agent1:                 episode reward: 0.5120,                 loss: 0.3037
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 113.3318 s
agent0:                 episode reward: -0.4109,                 loss: nan
agent1:                 episode reward: 0.4109,                 loss: 0.3064
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 113.9313 s
agent0:                 episode reward: -0.5381,                 loss: nan
agent1:                 episode reward: 0.5381,                 loss: 0.3076
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 114.5211 s
agent0:                 episode reward: -0.5403,                 loss: nan
agent1:                 episode reward: 0.5403,                 loss: 0.3066
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 115.1098 s
agent0:                 episode reward: -0.6099,                 loss: nan
agent1:                 episode reward: 0.6099,                 loss: 0.3056
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 115.7080 s
agent0:                 episode reward: -0.4910,                 loss: nan
agent1:                 episode reward: 0.4910,                 loss: 0.3092
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 116.3055 s
agent0:                 episode reward: -0.4769,                 loss: nan
agent1:                 episode reward: 0.4769,                 loss: 0.3063
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 116.8983 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.3071
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 117.4901 s
agent0:                 episode reward: -0.6757,                 loss: nan
agent1:                 episode reward: 0.6757,                 loss: 0.3046
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 118.0799 s
agent0:                 episode reward: -0.4347,                 loss: nan
agent1:                 episode reward: 0.4347,                 loss: 0.3067
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 118.6704 s
agent0:                 episode reward: -0.6830,                 loss: nan
agent1:                 episode reward: 0.6830,                 loss: 0.3067
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 119.2609 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.3052
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 119.8607 s
agent0:                 episode reward: -0.6541,                 loss: nan
agent1:                 episode reward: 0.6541,                 loss: 0.3017
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 120.4560 s
agent0:                 episode reward: -0.8463,                 loss: nan
agent1:                 episode reward: 0.8463,                 loss: 0.3045
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 121.0500 s
agent0:                 episode reward: -0.5543,                 loss: nan
agent1:                 episode reward: 0.5543,                 loss: 0.3044
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 121.6460 s
agent0:                 episode reward: -0.4290,                 loss: nan
agent1:                 episode reward: 0.4290,                 loss: 0.3038
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 122.2441 s
agent0:                 episode reward: -0.5484,                 loss: nan
agent1:                 episode reward: 0.5484,                 loss: 0.3065
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 122.8330 s
agent0:                 episode reward: -0.3141,                 loss: nan
agent1:                 episode reward: 0.3141,                 loss: 0.3066
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 123.4276 s
agent0:                 episode reward: -0.8729,                 loss: nan
agent1:                 episode reward: 0.8729,                 loss: 0.3043
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 124.0252 s
agent0:                 episode reward: -0.0410,                 loss: nan
agent1:                 episode reward: 0.0410,                 loss: 0.3035
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 124.6198 s
agent0:                 episode reward: -0.7448,                 loss: nan
agent1:                 episode reward: 0.7448,                 loss: 0.3046
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 125.2077 s
agent0:                 episode reward: -0.7520,                 loss: nan
agent1:                 episode reward: 0.7520,                 loss: 0.3044
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 125.8020 s
agent0:                 episode reward: -0.4901,                 loss: nan
agent1:                 episode reward: 0.4901,                 loss: 0.3040
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 126.4016 s
agent0:                 episode reward: -0.4335,                 loss: nan
agent1:                 episode reward: 0.4335,                 loss: 0.3038
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 126.9959 s
agent0:                 episode reward: -0.6350,                 loss: nan
agent1:                 episode reward: 0.6350,                 loss: 0.3070
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 127.5955 s
agent0:                 episode reward: -0.2994,                 loss: nan
agent1:                 episode reward: 0.2994,                 loss: 0.2996
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 128.1935 s
agent0:                 episode reward: -0.0860,                 loss: nan
agent1:                 episode reward: 0.0860,                 loss: 0.3044
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 128.7864 s
agent0:                 episode reward: -0.4427,                 loss: nan
agent1:                 episode reward: 0.4427,                 loss: 0.3061
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 129.3846 s
agent0:                 episode reward: -0.5846,                 loss: nan
agent1:                 episode reward: 0.5846,                 loss: 0.3018
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 129.9867 s
agent0:                 episode reward: -0.6132,                 loss: nan
agent1:                 episode reward: 0.6132,                 loss: 0.3033
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 130.5767 s
agent0:                 episode reward: -0.8974,                 loss: nan
agent1:                 episode reward: 0.8974,                 loss: 0.3031
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 131.1658 s
agent0:                 episode reward: -0.5015,                 loss: nan
agent1:                 episode reward: 0.5015,                 loss: 0.3059
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 131.7599 s
agent0:                 episode reward: -0.9292,                 loss: nan
agent1:                 episode reward: 0.9292,                 loss: 0.3066
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 132.3562 s
agent0:                 episode reward: -0.1677,                 loss: nan
agent1:                 episode reward: 0.1677,                 loss: 0.3033
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 132.9448 s
agent0:                 episode reward: -0.5012,                 loss: nan
agent1:                 episode reward: 0.5012,                 loss: 0.3010
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 133.5479 s
agent0:                 episode reward: -0.7579,                 loss: nan
agent1:                 episode reward: 0.7579,                 loss: 0.3041
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 134.1457 s
agent0:                 episode reward: -0.4324,                 loss: nan
agent1:                 episode reward: 0.4324,                 loss: 0.3026
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 134.7385 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.3064
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 135.3355 s
agent0:                 episode reward: -0.6064,                 loss: nan
agent1:                 episode reward: 0.6064,                 loss: 0.3043
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 135.9276 s
agent0:                 episode reward: -0.6261,                 loss: nan
agent1:                 episode reward: 0.6261,                 loss: 0.3052
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 136.5276 s
agent0:                 episode reward: -0.6090,                 loss: nan
agent1:                 episode reward: 0.6090,                 loss: 0.3048
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5993s / 137.1269 s
agent0:                 episode reward: -0.6998,                 loss: nan
agent1:                 episode reward: 0.6998,                 loss: 0.3042
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 137.7233 s
agent0:                 episode reward: -0.6215,                 loss: nan
agent1:                 episode reward: 0.6215,                 loss: 0.3012
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 138.3108 s
agent0:                 episode reward: -0.6665,                 loss: nan
agent1:                 episode reward: 0.6665,                 loss: 0.3053
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 138.9055 s
agent0:                 episode reward: -0.6321,                 loss: nan
agent1:                 episode reward: 0.6321,                 loss: 0.3057
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 139.5077 s
agent0:                 episode reward: -0.5864,                 loss: nan
agent1:                 episode reward: 0.5864,                 loss: 0.3030
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6143s / 140.1220 s
agent0:                 episode reward: -0.4942,                 loss: nan
agent1:                 episode reward: 0.4942,                 loss: 0.3043
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 140.7166 s
agent0:                 episode reward: -0.3203,                 loss: nan
agent1:                 episode reward: 0.3203,                 loss: 0.3037
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 141.3169 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.3034
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 141.9167 s
agent0:                 episode reward: -0.4076,                 loss: nan
agent1:                 episode reward: 0.4076,                 loss: 0.3040
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 142.5132 s
agent0:                 episode reward: -0.0123,                 loss: nan
agent1:                 episode reward: 0.0123,                 loss: 0.3016
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 143.1117 s
agent0:                 episode reward: -0.7599,                 loss: nan
agent1:                 episode reward: 0.7599,                 loss: 0.3022
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 143.7075 s
agent0:                 episode reward: -0.3826,                 loss: nan
agent1:                 episode reward: 0.3826,                 loss: 0.3031
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 144.3082 s
agent0:                 episode reward: -0.4222,                 loss: nan
agent1:                 episode reward: 0.4222,                 loss: 0.3036
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 144.9066 s
agent0:                 episode reward: -0.0877,                 loss: nan
agent1:                 episode reward: 0.0877,                 loss: 0.3024
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 145.5025 s
agent0:                 episode reward: -0.2295,                 loss: nan
agent1:                 episode reward: 0.2295,                 loss: 0.3006
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6111s / 146.1136 s
agent0:                 episode reward: -0.4131,                 loss: nan
agent1:                 episode reward: 0.4131,                 loss: 0.2998
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 146.7118 s
agent0:                 episode reward: -0.6794,                 loss: nan
agent1:                 episode reward: 0.6794,                 loss: 0.3027
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 147.3099 s
agent0:                 episode reward: -0.4121,                 loss: nan
agent1:                 episode reward: 0.4121,                 loss: 0.3010
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 147.9042 s
agent0:                 episode reward: -0.3324,                 loss: nan
agent1:                 episode reward: 0.3324,                 loss: 0.3027
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 148.5016 s
agent0:                 episode reward: -0.9402,                 loss: nan
agent1:                 episode reward: 0.9402,                 loss: 0.3039
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 149.0956 s
agent0:                 episode reward: -0.8399,                 loss: nan
agent1:                 episode reward: 0.8399,                 loss: 0.3039
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 149.6968 s
agent0:                 episode reward: -0.6760,                 loss: nan
agent1:                 episode reward: 0.6760,                 loss: 0.3045
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 150.2875 s
agent0:                 episode reward: -0.6289,                 loss: nan
agent1:                 episode reward: 0.6289,                 loss: 0.3020
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 150.8854 s
agent0:                 episode reward: -0.9991,                 loss: nan
agent1:                 episode reward: 0.9991,                 loss: 0.3036
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 151.4799 s
agent0:                 episode reward: -0.8391,                 loss: nan
agent1:                 episode reward: 0.8391,                 loss: 0.3014
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 152.0670 s
agent0:                 episode reward: -0.5778,                 loss: nan
agent1:                 episode reward: 0.5778,                 loss: 0.3078
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 152.6641 s
agent0:                 episode reward: -0.6670,                 loss: nan
agent1:                 episode reward: 0.6670,                 loss: 0.3089
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 153.2604 s
agent0:                 episode reward: -0.5022,                 loss: nan
agent1:                 episode reward: 0.5022,                 loss: 0.3163
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 153.8497 s
agent0:                 episode reward: -0.4369,                 loss: nan
agent1:                 episode reward: 0.4369,                 loss: 0.3115
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 154.4525 s
agent0:                 episode reward: -0.6806,                 loss: nan
agent1:                 episode reward: 0.6806,                 loss: 0.3096
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6063s / 155.0588 s
agent0:                 episode reward: -0.4326,                 loss: nan
agent1:                 episode reward: 0.4326,                 loss: 0.3111
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 155.6601 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.3099
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6102s / 156.2704 s
agent0:                 episode reward: -0.4397,                 loss: nan
agent1:                 episode reward: 0.4397,                 loss: 0.3121
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 156.8740 s
agent0:                 episode reward: -0.3256,                 loss: nan
agent1:                 episode reward: 0.3256,                 loss: 0.3129
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6014s / 157.4754 s
agent0:                 episode reward: -0.7085,                 loss: nan
agent1:                 episode reward: 0.7085,                 loss: 0.3117
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 158.0683 s
agent0:                 episode reward: -0.7597,                 loss: nan
agent1:                 episode reward: 0.7597,                 loss: 0.3108
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 158.6643 s
agent0:                 episode reward: -0.7623,                 loss: nan
agent1:                 episode reward: 0.7623,                 loss: 0.3112
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 159.2590 s
agent0:                 episode reward: -0.5653,                 loss: nan
agent1:                 episode reward: 0.5653,                 loss: 0.3141
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 159.8598 s
agent0:                 episode reward: -0.5090,                 loss: nan
agent1:                 episode reward: 0.5090,                 loss: 0.3096
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 160.4585 s
agent0:                 episode reward: -0.4772,                 loss: nan
agent1:                 episode reward: 0.4772,                 loss: 0.3084