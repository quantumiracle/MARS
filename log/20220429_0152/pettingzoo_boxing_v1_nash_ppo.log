pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [848, 636, 123, 151, 419]
<SubprocVectorEnv instance>
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'feature': {'hidden_dim_list': [128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'policy': {'hidden_dim_list': [128, 128], 'hidden_activation': False, 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220429_0152/pettingzoo_boxing_v1_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220429_0152/pettingzoo_boxing_v1_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 5.2958s / 5.2958 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0699
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 4.0000,                 loss: nan
env4_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 67.8842s / 73.1799 s
env0_first_0:                 episode reward: -1.7000,                 loss: -0.2911
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8925s / 151.0724 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.6005
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5576s / 227.6301 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4779
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0971s / 303.7272 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.3470
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 82.3946s / 386.1218 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.8439
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.3899s / 479.5117 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.5753
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 93.6795s / 573.1912 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8580
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 92.6269s / 665.8180 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4215
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 92.0119s / 757.8299 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.8902
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 91.6660s / 849.4960 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.6544
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.2266s / 939.7225 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0204
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.0801s / 1028.8026 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.1686
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.5647s / 1119.3673 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.5830
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.2656s / 1209.6330 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.7958
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.2992s / 1299.9322 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.7275
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.7996s / 1389.7318 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.5262
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.0662s / 1478.7980 s
env0_first_0:                 episode reward: -2.6000,                 loss: 1.0227
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -1.3000,                 loss: nan
env3_second_0:                 episode reward: 1.3000,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.7723s / 1567.5704 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.1713
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.1655s / 1656.7358 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.3223
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.8108s / 1745.5466 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.4401
env0_second_0:                 episode reward: -0.9000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.3543s / 1834.9009 s
env0_first_0:                 episode reward: 0.9500,                 loss: 1.3037
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.4584s / 1924.3593 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.6738
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.3213s / 2013.6806 s
env0_first_0:                 episode reward: -0.4500,                 loss: 1.0965
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -1.4000,                 loss: nan
env4_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 90.1463s / 2103.8269 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.1129
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.1830s / 2193.0099 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.1170
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.7344s / 2282.7443 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0970
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.3591s / 2372.1034 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9197
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.1229s / 2461.2262 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5468
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.0619s / 2550.2881 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3737
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.4238s / 2638.7119 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3417
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.5170s / 2728.2289 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3519
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.3656s / 2816.5946 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2602
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5815s / 2903.1761 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3823
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4491s / 2990.6251 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3466
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0477s / 3078.6728 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3240
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7972s / 3165.4700 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0667
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5288s / 3251.9988 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.4892
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4545s / 3338.4533 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2671
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5662s / 3425.0195 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1222
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.9801s / 3512.9995 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7736
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0337s / 3601.0332 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7897
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2860s / 3688.3193 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7142
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0609s / 3775.3802 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5722
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4137s / 3862.7939 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4512
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1197s / 3949.9136 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5202
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.1025s / 4038.0161 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3537
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6697s / 4125.6858 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4201
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4443s / 4213.1301 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5863
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.3555s / 4301.4856 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5606
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.4237s / 4389.9093 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6798
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.3180s / 4478.2273 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8021
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5633s / 4565.7906 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8647
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.4851s / 4654.2757 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9363
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5472s / 4741.8229 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.9289
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.1792s / 4830.0021 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.8590
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3373s / 4917.3394 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0148
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8814s / 5005.2208 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0428
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6096s / 5092.8304 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.8786
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2031s / 5180.0335 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.7610
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9299s / 5266.9634 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.5707
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8733s / 5353.8367 s
env0_first_0:                 episode reward: 0.0500,                 loss: -1.0920
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2728s / 5442.1096 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.1202
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0108s / 5530.1203 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0611
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.9399s / 5619.0602 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9242
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.9743s / 5707.0346 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7434
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.6308s / 5795.6654 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7600
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8936s / 5883.5590 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7730
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0507s / 5971.6097 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7774
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.4776s / 6060.0873 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7950
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8524s / 6147.9397 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9114
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8620s / 6234.8016 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9766
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.6629s / 6323.4645 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9327
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.9047s / 6411.3692 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9732
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2480s / 6499.6172 s
env0_first_0:                 episode reward: 0.0500,                 loss: -1.0235
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7615s / 6587.3787 s
env0_first_0:                 episode reward: 0.1500,                 loss: -1.0053
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.4563s / 6675.8351 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.0080
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3122s / 6762.1472 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.5273
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.1283s / 6848.2755 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4421
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 1.0000,                 loss: nan
env4_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4869s / 6935.7624 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.8176
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6307s / 7022.3931 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7230
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.2216s / 7108.6146 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6793
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1170s / 7195.7316 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7307
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.5627s / 7281.2943 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7059
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.8373s / 7367.1317 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7603
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.9492s / 7453.0809 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8110
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8009s / 7539.8818 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8741
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3258s / 7626.2076 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.8364
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4003s / 7712.6079 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.5575
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3869s / 7798.9948 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.6383
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.9809s / 7884.9757 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7303
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5864s / 7971.5622 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6778
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4473s / 8058.0095 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5660
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3642s / 8144.3737 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3839
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.4583s / 8229.8321 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1411
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3857s / 8316.2178 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1665
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0942s / 8402.3120 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3353
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.0028s / 8487.3148 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2720
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.9022s / 8573.2170 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1545
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.7917s / 8659.0087 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1028
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.0621s / 8744.0708 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1129
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.1521s / 8830.2230 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1582
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.6748s / 8915.8978 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1720
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7826s / 9002.6804 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2170
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.5221s / 9088.2024 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2282
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5801s / 9174.7825 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3412
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3317s / 9261.1143 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4490
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.2601s / 9347.3744 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4860
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7363s / 9434.1107 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5402
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2839s / 9521.3946 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5622
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3546s / 9608.7492 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5382
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5195s / 9696.2688 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5559
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.9504s / 9782.2192 s
env0_first_0:                 episode reward: -1.4000,                 loss: -0.1808
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4691s / 9869.6883 s
env0_first_0:                 episode reward: -9.0000,                 loss: 3.1144
env0_second_0:                 episode reward: 9.0000,                 loss: nan
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
env2_first_0:                 episode reward: -10.6500,                 loss: nan
env2_second_0:                 episode reward: 10.6500,                 loss: nan
env3_first_0:                 episode reward: -11.9000,                 loss: nan
env3_second_0:                 episode reward: 11.9000,                 loss: nan
env4_first_0:                 episode reward: -8.7500,                 loss: nan
env4_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0476s / 9955.7359 s
env0_first_0:                 episode reward: -9.8000,                 loss: 6.9731
env0_second_0:                 episode reward: 9.8000,                 loss: nan
env1_first_0:                 episode reward: -16.8500,                 loss: nan
env1_second_0:                 episode reward: 16.8500,                 loss: nan
env2_first_0:                 episode reward: -13.0500,                 loss: nan
env2_second_0:                 episode reward: 13.0500,                 loss: nan
env3_first_0:                 episode reward: -16.9000,                 loss: nan
env3_second_0:                 episode reward: 16.9000,                 loss: nan
env4_first_0:                 episode reward: -14.9500,                 loss: nan
env4_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2629s / 10043.9988 s
env0_first_0:                 episode reward: -16.7500,                 loss: 8.8613
env0_second_0:                 episode reward: 16.7500,                 loss: nan
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
env2_first_0:                 episode reward: -13.5500,                 loss: nan
env2_second_0:                 episode reward: 13.5500,                 loss: nan
env3_first_0:                 episode reward: -16.9500,                 loss: nan
env3_second_0:                 episode reward: 16.9500,                 loss: nan
env4_first_0:                 episode reward: -18.7500,                 loss: nan
env4_second_0:                 episode reward: 18.7500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8910s / 10130.8898 s
env0_first_0:                 episode reward: -29.1500,                 loss: 12.7885
env0_second_0:                 episode reward: 29.1500,                 loss: nan
env1_first_0:                 episode reward: -29.9500,                 loss: nan
env1_second_0:                 episode reward: 29.9500,                 loss: nan
env2_first_0:                 episode reward: -27.4000,                 loss: nan
env2_second_0:                 episode reward: 27.4000,                 loss: nan
env3_first_0:                 episode reward: -27.5500,                 loss: nan
env3_second_0:                 episode reward: 27.5500,                 loss: nan
env4_first_0:                 episode reward: -23.3500,                 loss: nan
env4_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5129s / 10217.4027 s
env0_first_0:                 episode reward: -40.8500,                 loss: 12.7932
env0_second_0:                 episode reward: 40.8500,                 loss: nan
env1_first_0:                 episode reward: -41.6000,                 loss: nan
env1_second_0:                 episode reward: 41.6000,                 loss: nan
env2_first_0:                 episode reward: -36.9000,                 loss: nan
env2_second_0:                 episode reward: 36.9000,                 loss: nan
env3_first_0:                 episode reward: -38.0000,                 loss: nan
env3_second_0:                 episode reward: 38.0000,                 loss: nan
env4_first_0:                 episode reward: -41.5000,                 loss: nan
env4_second_0:                 episode reward: 41.5000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.3461s / 10302.7488 s
env0_first_0:                 episode reward: -42.2000,                 loss: 15.5955
env0_second_0:                 episode reward: 42.2000,                 loss: nan
env1_first_0:                 episode reward: -50.1000,                 loss: nan
env1_second_0:                 episode reward: 50.1000,                 loss: nan
env2_first_0:                 episode reward: -46.3000,                 loss: nan
env2_second_0:                 episode reward: 46.3000,                 loss: nan
env3_first_0:                 episode reward: -46.7500,                 loss: nan
env3_second_0:                 episode reward: 46.7500,                 loss: nan
env4_first_0:                 episode reward: -49.7000,                 loss: nan
env4_second_0:                 episode reward: 49.7000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4784s / 10390.2272 s
env0_first_0:                 episode reward: -61.0500,                 loss: 16.1214
env0_second_0:                 episode reward: 61.0500,                 loss: nan
env1_first_0:                 episode reward: -59.3500,                 loss: nan
env1_second_0:                 episode reward: 59.3500,                 loss: nan
env2_first_0:                 episode reward: -60.1500,                 loss: nan
env2_second_0:                 episode reward: 60.1500,                 loss: nan
env3_first_0:                 episode reward: -60.5000,                 loss: nan
env3_second_0:                 episode reward: 60.5000,                 loss: nan
env4_first_0:                 episode reward: -57.8500,                 loss: nan
env4_second_0:                 episode reward: 57.8500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 298.8,                last time consumption/overall running time: 86.2382s / 10476.4654 s
env0_first_0:                 episode reward: -75.1500,                 loss: 21.7530
env0_second_0:                 episode reward: 75.1500,                 loss: nan
env1_first_0:                 episode reward: -75.3000,                 loss: nan
env1_second_0:                 episode reward: 75.3000,                 loss: nan
env2_first_0:                 episode reward: -75.1500,                 loss: nan
env2_second_0:                 episode reward: 75.1500,                 loss: nan
env3_first_0:                 episode reward: -72.0000,                 loss: nan
env3_second_0:                 episode reward: 72.0000,                 loss: nan
env4_first_0:                 episode reward: -73.0000,                 loss: nan
env4_second_0:                 episode reward: 73.0000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 289.3,                last time consumption/overall running time: 85.3870s / 10561.8524 s
env0_first_0:                 episode reward: -82.1000,                 loss: 41.7268
env0_second_0:                 episode reward: 82.1000,                 loss: nan
env1_first_0:                 episode reward: -81.2500,                 loss: nan
env1_second_0:                 episode reward: 81.2500,                 loss: nan
env2_first_0:                 episode reward: -83.6000,                 loss: nan
env2_second_0:                 episode reward: 83.6000,                 loss: nan
env3_first_0:                 episode reward: -80.3500,                 loss: nan
env3_second_0:                 episode reward: 80.3500,                 loss: nan
env4_first_0:                 episode reward: -81.6000,                 loss: nan
env4_second_0:                 episode reward: 81.6000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 278.95,                last time consumption/overall running time: 82.5466s / 10644.3990 s
env0_first_0:                 episode reward: -86.3000,                 loss: 66.2572
env0_second_0:                 episode reward: 86.3000,                 loss: nan
env1_first_0:                 episode reward: -86.3500,                 loss: nan
env1_second_0:                 episode reward: 86.3500,                 loss: nan
env2_first_0:                 episode reward: -84.7000,                 loss: nan
env2_second_0:                 episode reward: 84.7000,                 loss: nan
env3_first_0:                 episode reward: -83.0500,                 loss: nan
env3_second_0:                 episode reward: 83.0500,                 loss: nan
env4_first_0:                 episode reward: -87.6500,                 loss: nan
env4_second_0:                 episode reward: 87.6500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 269.0,                last time consumption/overall running time: 80.6425s / 10725.0415 s
env0_first_0:                 episode reward: -83.1000,                 loss: 65.7180
env0_second_0:                 episode reward: 83.1000,                 loss: nan
env1_first_0:                 episode reward: -84.6500,                 loss: nan
env1_second_0:                 episode reward: 84.6500,                 loss: nan
env2_first_0:                 episode reward: -89.4500,                 loss: nan
env2_second_0:                 episode reward: 89.4500,                 loss: nan
env3_first_0:                 episode reward: -73.6500,                 loss: nan
env3_second_0:                 episode reward: 73.6500,                 loss: nan
env4_first_0:                 episode reward: -87.1500,                 loss: nan
env4_second_0:                 episode reward: 87.1500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 268.5,                last time consumption/overall running time: 80.0592s / 10805.1007 s
env0_first_0:                 episode reward: -86.7000,                 loss: 63.5031
env0_second_0:                 episode reward: 86.7000,                 loss: nan
env1_first_0:                 episode reward: -82.7500,                 loss: nan
env1_second_0:                 episode reward: 82.7500,                 loss: nan
env2_first_0:                 episode reward: -85.4500,                 loss: nan
env2_second_0:                 episode reward: 85.4500,                 loss: nan
env3_first_0:                 episode reward: -85.0000,                 loss: nan
env3_second_0:                 episode reward: 85.0000,                 loss: nan
env4_first_0:                 episode reward: -84.6500,                 loss: nan
env4_second_0:                 episode reward: 84.6500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 269.55,                last time consumption/overall running time: 80.7037s / 10885.8044 s
env0_first_0:                 episode reward: -83.6000,                 loss: 59.5668
env0_second_0:                 episode reward: 83.6000,                 loss: nan
env1_first_0:                 episode reward: -74.8000,                 loss: nan
env1_second_0:                 episode reward: 74.8000,                 loss: nan
env2_first_0:                 episode reward: -80.3000,                 loss: nan
env2_second_0:                 episode reward: 80.3000,                 loss: nan
env3_first_0:                 episode reward: -82.1500,                 loss: nan
env3_second_0:                 episode reward: 82.1500,                 loss: nan
env4_first_0:                 episode reward: -86.0000,                 loss: nan
env4_second_0:                 episode reward: 86.0000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 282.85,                last time consumption/overall running time: 82.6477s / 10968.4522 s
env0_first_0:                 episode reward: -35.1500,                 loss: 31.2354
env0_second_0:                 episode reward: 35.1500,                 loss: nan
env1_first_0:                 episode reward: -31.0500,                 loss: nan
env1_second_0:                 episode reward: 31.0500,                 loss: nan
env2_first_0:                 episode reward: -26.9500,                 loss: nan
env2_second_0:                 episode reward: 26.9500,                 loss: nan
env3_first_0:                 episode reward: -28.1000,                 loss: nan
env3_second_0:                 episode reward: 28.1000,                 loss: nan
env4_first_0:                 episode reward: -27.0500,                 loss: nan
env4_second_0:                 episode reward: 27.0500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6975s / 11055.1497 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.2320
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.7465s / 11140.8962 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4116
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.7051s / 11226.6013 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4436
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0955s / 11312.6968 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5052
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5181s / 11400.2150 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.4583
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -3.5500,                 loss: nan
env4_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0630s / 11487.2780 s
env0_first_0:                 episode reward: -16.9500,                 loss: 8.1676
env0_second_0:                 episode reward: 16.9500,                 loss: nan
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
env2_first_0:                 episode reward: -15.2500,                 loss: nan
env2_second_0:                 episode reward: 15.2500,                 loss: nan
env3_first_0:                 episode reward: -19.0000,                 loss: nan
env3_second_0:                 episode reward: 19.0000,                 loss: nan
env4_first_0:                 episode reward: -20.5000,                 loss: nan
env4_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3611s / 11573.6392 s
env0_first_0:                 episode reward: -28.2000,                 loss: 12.6255
env0_second_0:                 episode reward: 28.2000,                 loss: nan
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
env2_first_0:                 episode reward: -25.1500,                 loss: nan
env2_second_0:                 episode reward: 25.1500,                 loss: nan
env3_first_0:                 episode reward: -17.9500,                 loss: nan
env3_second_0:                 episode reward: 17.9500,                 loss: nan
env4_first_0:                 episode reward: -23.2000,                 loss: nan
env4_second_0:                 episode reward: 23.2000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4228s / 11661.0620 s
env0_first_0:                 episode reward: -60.5000,                 loss: 20.2685
env0_second_0:                 episode reward: 60.5000,                 loss: nan
env1_first_0:                 episode reward: -60.3500,                 loss: nan
env1_second_0:                 episode reward: 60.3500,                 loss: nan
env2_first_0:                 episode reward: -61.6000,                 loss: nan
env2_second_0:                 episode reward: 61.6000,                 loss: nan
env3_first_0:                 episode reward: -60.5500,                 loss: nan
env3_second_0:                 episode reward: 60.5500,                 loss: nan
env4_first_0:                 episode reward: -61.7500,                 loss: nan
env4_second_0:                 episode reward: 61.7500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 282.9,                last time consumption/overall running time: 82.2528s / 11743.3148 s
env0_first_0:                 episode reward: -86.5000,                 loss: 51.3802
env0_second_0:                 episode reward: 86.5000,                 loss: nan
env1_first_0:                 episode reward: -85.8000,                 loss: nan
env1_second_0:                 episode reward: 85.8000,                 loss: nan
env2_first_0:                 episode reward: -83.2500,                 loss: nan
env2_second_0:                 episode reward: 83.2500,                 loss: nan
env3_first_0:                 episode reward: -88.0500,                 loss: nan
env3_second_0:                 episode reward: 88.0500,                 loss: nan
env4_first_0:                 episode reward: -89.6000,                 loss: nan
env4_second_0:                 episode reward: 89.6000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 270.1,                last time consumption/overall running time: 80.2067s / 11823.5215 s
env0_first_0:                 episode reward: -81.6000,                 loss: 58.1816
env0_second_0:                 episode reward: 81.6000,                 loss: nan
env1_first_0:                 episode reward: -87.4500,                 loss: nan
env1_second_0:                 episode reward: 87.4500,                 loss: nan
env2_first_0:                 episode reward: -88.8000,                 loss: nan
env2_second_0:                 episode reward: 88.8000,                 loss: nan
env3_first_0:                 episode reward: -88.7500,                 loss: nan
env3_second_0:                 episode reward: 88.7500,                 loss: nan
env4_first_0:                 episode reward: -85.7500,                 loss: nan
env4_second_0:                 episode reward: 85.7500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 273.8,                last time consumption/overall running time: 81.1380s / 11904.6595 s
env0_first_0:                 episode reward: -90.6500,                 loss: 56.8133
env0_second_0:                 episode reward: 90.6500,                 loss: nan
env1_first_0:                 episode reward: -81.9000,                 loss: nan
env1_second_0:                 episode reward: 81.9000,                 loss: nan
env2_first_0:                 episode reward: -87.0000,                 loss: nan
env2_second_0:                 episode reward: 87.0000,                 loss: nan
env3_first_0:                 episode reward: -86.4000,                 loss: nan
env3_second_0:                 episode reward: 86.4000,                 loss: nan
env4_first_0:                 episode reward: -84.1500,                 loss: nan
env4_second_0:                 episode reward: 84.1500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 262.35,                last time consumption/overall running time: 78.9555s / 11983.6150 s
env0_first_0:                 episode reward: -85.5500,                 loss: 68.0480
env0_second_0:                 episode reward: 85.5500,                 loss: nan
env1_first_0:                 episode reward: -76.3500,                 loss: nan
env1_second_0:                 episode reward: 76.3500,                 loss: nan
env2_first_0:                 episode reward: -86.8500,                 loss: nan
env2_second_0:                 episode reward: 86.8500,                 loss: nan
env3_first_0:                 episode reward: -87.5500,                 loss: nan
env3_second_0:                 episode reward: 87.5500,                 loss: nan
env4_first_0:                 episode reward: -84.0500,                 loss: nan
env4_second_0:                 episode reward: 84.0500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 279.25,                last time consumption/overall running time: 81.0815s / 12064.6964 s
env0_first_0:                 episode reward: -60.7500,                 loss: 67.0104
env0_second_0:                 episode reward: 60.7500,                 loss: nan
env1_first_0:                 episode reward: -58.3500,                 loss: nan
env1_second_0:                 episode reward: 58.3500,                 loss: nan
env2_first_0:                 episode reward: -56.3500,                 loss: nan
env2_second_0:                 episode reward: 56.3500,                 loss: nan
env3_first_0:                 episode reward: -69.5500,                 loss: nan
env3_second_0:                 episode reward: 69.5500,                 loss: nan
env4_first_0:                 episode reward: -64.3500,                 loss: nan
env4_second_0:                 episode reward: 64.3500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 254.7,                last time consumption/overall running time: 77.6102s / 12142.3067 s
env0_first_0:                 episode reward: -84.7000,                 loss: 75.9026
env0_second_0:                 episode reward: 84.7000,                 loss: nan
env1_first_0:                 episode reward: -89.6500,                 loss: nan
env1_second_0:                 episode reward: 89.6500,                 loss: nan
env2_first_0:                 episode reward: -86.8000,                 loss: nan
env2_second_0:                 episode reward: 86.8000,                 loss: nan
env3_first_0:                 episode reward: -92.3500,                 loss: nan
env3_second_0:                 episode reward: 92.3500,                 loss: nan
env4_first_0:                 episode reward: -86.7500,                 loss: nan
env4_second_0:                 episode reward: 86.7500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 255.45,                last time consumption/overall running time: 76.7413s / 12219.0479 s
env0_first_0:                 episode reward: -78.2000,                 loss: 77.2608
env0_second_0:                 episode reward: 78.2000,                 loss: nan
env1_first_0:                 episode reward: -89.7000,                 loss: nan
env1_second_0:                 episode reward: 89.7000,                 loss: nan
env2_first_0:                 episode reward: -79.9000,                 loss: nan
env2_second_0:                 episode reward: 79.9000,                 loss: nan
env3_first_0:                 episode reward: -80.5500,                 loss: nan
env3_second_0:                 episode reward: 80.5500,                 loss: nan
env4_first_0:                 episode reward: -82.1000,                 loss: nan
env4_second_0:                 episode reward: 82.1000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 249.3,                last time consumption/overall running time: 75.6797s / 12294.7276 s
env0_first_0:                 episode reward: -54.4500,                 loss: 111.7395
env0_second_0:                 episode reward: 54.4500,                 loss: nan
env1_first_0:                 episode reward: -66.2500,                 loss: nan
env1_second_0:                 episode reward: 66.2500,                 loss: nan
env2_first_0:                 episode reward: -80.9000,                 loss: nan
env2_second_0:                 episode reward: 80.9000,                 loss: nan
env3_first_0:                 episode reward: -62.4500,                 loss: nan
env3_second_0:                 episode reward: 62.4500,                 loss: nan
env4_first_0:                 episode reward: -71.3000,                 loss: nan
env4_second_0:                 episode reward: 71.3000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 286.8,                last time consumption/overall running time: 84.7994s / 12379.5270 s
env0_first_0:                 episode reward: -8.0000,                 loss: 52.4012
env0_second_0:                 episode reward: 8.0000,                 loss: nan
env1_first_0:                 episode reward: -27.9500,                 loss: nan
env1_second_0:                 episode reward: 27.9500,                 loss: nan
env2_first_0:                 episode reward: -26.6000,                 loss: nan
env2_second_0:                 episode reward: 26.6000,                 loss: nan
env3_first_0:                 episode reward: -30.3000,                 loss: nan
env3_second_0:                 episode reward: 30.3000,                 loss: nan
env4_first_0:                 episode reward: -23.0500,                 loss: nan
env4_second_0:                 episode reward: 23.0500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6651s / 12467.1921 s
env0_first_0:                 episode reward: -5.1000,                 loss: 9.4096
env0_second_0:                 episode reward: 5.1000,                 loss: nan
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: -3.1500,                 loss: nan
env3_second_0:                 episode reward: 3.1500,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.2071s / 12553.3992 s
env0_first_0:                 episode reward: -2.3000,                 loss: 10.4768
env0_second_0:                 episode reward: 2.3000,                 loss: nan
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
env2_first_0:                 episode reward: -2.9000,                 loss: nan
env2_second_0:                 episode reward: 2.9000,                 loss: nan
env3_first_0:                 episode reward: -3.7500,                 loss: nan
env3_second_0:                 episode reward: 3.7500,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0967s / 12640.4959 s
env0_first_0:                 episode reward: -7.9500,                 loss: 10.8490
env0_second_0:                 episode reward: 7.9500,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -5.2500,                 loss: nan
env2_second_0:                 episode reward: 5.2500,                 loss: nan
env3_first_0:                 episode reward: -5.7500,                 loss: nan
env3_second_0:                 episode reward: 5.7500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5859s / 12727.0818 s
env0_first_0:                 episode reward: -6.4000,                 loss: 17.3475
env0_second_0:                 episode reward: 6.4000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -5.3500,                 loss: nan
env2_second_0:                 episode reward: 5.3500,                 loss: nan
env3_first_0:                 episode reward: -9.8500,                 loss: nan
env3_second_0:                 episode reward: 9.8500,                 loss: nan
env4_first_0:                 episode reward: -9.7500,                 loss: nan
env4_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8952s / 12813.9771 s
env0_first_0:                 episode reward: -4.6000,                 loss: 12.0980
env0_second_0:                 episode reward: 4.6000,                 loss: nan
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
env2_first_0:                 episode reward: -2.8500,                 loss: nan
env2_second_0:                 episode reward: 2.8500,                 loss: nan
env3_first_0:                 episode reward: -5.5500,                 loss: nan
env3_second_0:                 episode reward: 5.5500,                 loss: nan
env4_first_0:                 episode reward: -6.5000,                 loss: nan
env4_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6598s / 12901.6369 s
env0_first_0:                 episode reward: -8.3000,                 loss: 13.0867
env0_second_0:                 episode reward: 8.3000,                 loss: nan
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
env2_first_0:                 episode reward: -8.1500,                 loss: nan
env2_second_0:                 episode reward: 8.1500,                 loss: nan
env3_first_0:                 episode reward: -8.6500,                 loss: nan
env3_second_0:                 episode reward: 8.6500,                 loss: nan
env4_first_0:                 episode reward: -6.5000,                 loss: nan
env4_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4993s / 12989.1362 s
env0_first_0:                 episode reward: -6.6000,                 loss: 7.9507
env0_second_0:                 episode reward: 6.6000,                 loss: nan
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
env2_first_0:                 episode reward: -7.1000,                 loss: nan
env2_second_0:                 episode reward: 7.1000,                 loss: nan
env3_first_0:                 episode reward: -8.6000,                 loss: nan
env3_second_0:                 episode reward: 8.6000,                 loss: nan
env4_first_0:                 episode reward: -6.7500,                 loss: nan
env4_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7054s / 13075.8417 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.8117
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.6734s / 13161.5151 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.5711
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.4394s / 13246.9545 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0177
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.1360s / 13333.0904 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0025
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.6422s / 13418.7326 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0168
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3834s / 13505.1160 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0351
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4197s / 13592.5357 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2207
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2770s / 13680.8126 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2773
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6826s / 13768.4952 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3600
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6071s / 13856.1024 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4514
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4001s / 13943.5024 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4823
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5264s / 14031.0289 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.0132
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -1.7000,                 loss: nan
env4_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7201s / 14117.7490 s
env0_first_0:                 episode reward: -4.1000,                 loss: 1.7785
env0_second_0:                 episode reward: 4.1000,                 loss: nan
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
env2_first_0:                 episode reward: -4.5000,                 loss: nan
env2_second_0:                 episode reward: 4.5000,                 loss: nan
env3_first_0:                 episode reward: -2.9000,                 loss: nan
env3_second_0:                 episode reward: 2.9000,                 loss: nan
env4_first_0:                 episode reward: -4.1500,                 loss: nan
env4_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2897s / 14205.0387 s
env0_first_0:                 episode reward: -2.6500,                 loss: 1.3865
env0_second_0:                 episode reward: 2.6500,                 loss: nan
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -5.2000,                 loss: nan
env2_second_0:                 episode reward: 5.2000,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4113s / 14292.4501 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3597
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.5777s / 14381.0278 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2715
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8551s / 14467.8829 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2407
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2946s / 14556.1775 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4389
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5888s / 14643.7663 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7576
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1636s / 14730.9300 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.3808
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4033s / 14818.3333 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.5476
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6692s / 14905.0025 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7800
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2065s / 14992.2090 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8113
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8403s / 15080.0494 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6094
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1275s / 15167.1768 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6623
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2955s / 15254.4723 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5805
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.5537s / 15343.0261 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5513
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4137s / 15430.4397 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5204
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.1234s / 15518.5632 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4320
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6260s / 15606.1892 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4555
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4891s / 15693.6783 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4913
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0540s / 15780.7323 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4947
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7506s / 15868.4830 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5649
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2562s / 15956.7392 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6395
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3850s / 16044.1241 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6840
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9211s / 16131.0452 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6182
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2512s / 16218.2964 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5575
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3768s / 16304.6732 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4748
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0455s / 16392.7187 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5010
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7804s / 16480.4991 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5159
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.0042s / 16569.5033 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4664
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2785s / 16656.7818 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4805
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5301s / 16744.3119 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5161
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8285s / 16832.1404 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5246
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0915s / 16919.2318 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5091
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4893s / 17006.7212 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5566
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.0246s / 17095.7458 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5657
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7979s / 17183.5437 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6029
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.4117s / 17271.9555 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5659
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3079s / 17359.2634 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5641
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0924s / 17446.3558 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6148
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.1975s / 17534.5533 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5864
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.1434s / 17622.6967 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5775
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4358s / 17710.1325 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5771
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2017s / 17798.3342 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5423
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4256s / 17885.7598 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5314
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1423s / 17972.9021 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5019
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.7719s / 18062.6739 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5615
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8424s / 18150.5163 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4981
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.0824s / 18239.5987 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5206
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6626s / 18327.2613 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6459
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.5701s / 18416.8314 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8098
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2180s / 18504.0494 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7997
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7053s / 18590.7547 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6818
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8888s / 18678.6434 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7080
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4377s / 18765.0812 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7395
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.9344s / 18855.0156 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6745
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1906s / 18942.2062 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6882
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4699s / 19028.6761 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8214
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3606s / 19116.0367 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8458
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5195s / 19203.5562 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8605
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7397s / 19290.2959 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8368
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2431s / 19378.5390 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8052
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.1000s / 19466.6391 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8334
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6815s / 19553.3206 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.7469
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1822s / 19640.5027 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0637
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -2.8500,                 loss: nan
env4_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7908s / 19727.2936 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0416
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0551s / 19814.3487 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.1856
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8499s / 19902.1986 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3458
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.8114s / 19991.0100 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.7311
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.2173s / 20080.2273 s
env0_first_0:                 episode reward: 0.0000,                 loss: -1.1028
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3580s / 20167.5853 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.6857
env0_second_0:                 episode reward: -0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8247s / 20254.4100 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.2384
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.8445s / 20343.2545 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.9420
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6374s / 20430.8919 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7076
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9644s / 20517.8563 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7480
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.3701s / 20607.2264 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7925
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7237s / 20693.9502 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8342
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1005s / 20781.0506 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8140
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9951s / 20868.0457 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7628
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0934s / 20955.1391 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7583
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.6383s / 21043.7774 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7679
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9236s / 21130.7010 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7553
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.1310s / 21218.8320 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7750
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.1588s / 21306.9908 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.8375
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1847s / 21394.1755 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.6880
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7833s / 21480.9588 s
env0_first_0:                 episode reward: 1.2000,                 loss: -0.0665
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.0000,                 loss: nan
env3_second_0:                 episode reward: -1.0000,                 loss: nan
env4_first_0:                 episode reward: 0.8000,                 loss: nan
env4_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0799s / 21568.0387 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.4158
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.8000,                 loss: nan
env4_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6421s / 21655.6808 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0684
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2308s / 21743.9116 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0912
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 0.8000,                 loss: nan
env4_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0075s / 21831.9192 s
env0_first_0:                 episode reward: 0.8000,                 loss: 1.4059
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 3.8000,                 loss: nan
env2_second_0:                 episode reward: -3.8000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5028s / 21919.4220 s
env0_first_0:                 episode reward: 1.9000,                 loss: 1.9453
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 3.1500,                 loss: nan
env4_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3226s / 22006.7446 s
env0_first_0:                 episode reward: -0.7000,                 loss: 1.9643
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0505s / 22094.7951 s
env0_first_0:                 episode reward: 0.0500,                 loss: 2.6305
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6139s / 22181.4091 s
env0_first_0:                 episode reward: -13.2500,                 loss: 10.2462
env0_second_0:                 episode reward: 13.2500,                 loss: nan
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
env2_first_0:                 episode reward: -7.4000,                 loss: nan
env2_second_0:                 episode reward: 7.4000,                 loss: nan
env3_first_0:                 episode reward: -6.7000,                 loss: nan
env3_second_0:                 episode reward: 6.7000,                 loss: nan
env4_first_0:                 episode reward: -7.6000,                 loss: nan
env4_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.1224s / 22270.5314 s
env0_first_0:                 episode reward: -7.0000,                 loss: 9.9970
env0_second_0:                 episode reward: 7.0000,                 loss: nan
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
env2_first_0:                 episode reward: -6.5500,                 loss: nan
env2_second_0:                 episode reward: 6.5500,                 loss: nan
env3_first_0:                 episode reward: -7.4500,                 loss: nan
env3_second_0:                 episode reward: 7.4500,                 loss: nan
env4_first_0:                 episode reward: -7.9000,                 loss: nan
env4_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9815s / 22357.5129 s
env0_first_0:                 episode reward: 1.9500,                 loss: 5.8165
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -3.1500,                 loss: nan
env3_second_0:                 episode reward: 3.1500,                 loss: nan
env4_first_0:                 episode reward: -3.3500,                 loss: nan
env4_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9412s / 22444.4541 s
env0_first_0:                 episode reward: -1.3000,                 loss: 3.6311
env0_second_0:                 episode reward: 1.3000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
env3_first_0:                 episode reward: -2.9500,                 loss: nan
env3_second_0:                 episode reward: 2.9500,                 loss: nan
env4_first_0:                 episode reward: -3.7500,                 loss: nan
env4_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0125s / 22532.4666 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.7846
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3488s / 22619.8154 s
env0_first_0:                 episode reward: -2.5000,                 loss: 2.8402
env0_second_0:                 episode reward: 2.5000,                 loss: nan
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -3.3000,                 loss: nan
env3_second_0:                 episode reward: 3.3000,                 loss: nan
env4_first_0:                 episode reward: -3.1500,                 loss: nan
env4_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8903s / 22706.7057 s
env0_first_0:                 episode reward: -3.3500,                 loss: 3.7325
env0_second_0:                 episode reward: 3.3500,                 loss: nan
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -3.0000,                 loss: nan
env2_second_0:                 episode reward: 3.0000,                 loss: nan
env3_first_0:                 episode reward: -5.0500,                 loss: nan
env3_second_0:                 episode reward: 5.0500,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.2668s / 22792.9725 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.7933
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -1.4000,                 loss: nan
env4_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7448s / 22880.7174 s
env0_first_0:                 episode reward: -2.2000,                 loss: 2.8636
env0_second_0:                 episode reward: 2.2000,                 loss: nan
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
env2_first_0:                 episode reward: -3.0500,                 loss: nan
env2_second_0:                 episode reward: 3.0500,                 loss: nan
env3_first_0:                 episode reward: -4.5500,                 loss: nan
env3_second_0:                 episode reward: 4.5500,                 loss: nan
env4_first_0:                 episode reward: -4.2500,                 loss: nan
env4_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.6691s / 22969.3865 s
env0_first_0:                 episode reward: -2.9500,                 loss: 5.7334
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
env2_first_0:                 episode reward: -8.0500,                 loss: nan
env2_second_0:                 episode reward: 8.0500,                 loss: nan
env3_first_0:                 episode reward: -5.3500,                 loss: nan
env3_second_0:                 episode reward: 5.3500,                 loss: nan
env4_first_0:                 episode reward: -7.4000,                 loss: nan
env4_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1339s / 23056.5203 s
env0_first_0:                 episode reward: -10.0000,                 loss: 11.5823
env0_second_0:                 episode reward: 10.0000,                 loss: nan
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
env2_first_0:                 episode reward: -14.5500,                 loss: nan
env2_second_0:                 episode reward: 14.5500,                 loss: nan
env3_first_0:                 episode reward: -13.0500,                 loss: nan
env3_second_0:                 episode reward: 13.0500,                 loss: nan
env4_first_0:                 episode reward: -9.0500,                 loss: nan
env4_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3277s / 23142.8480 s
env0_first_0:                 episode reward: -7.4000,                 loss: 11.2465
env0_second_0:                 episode reward: 7.4000,                 loss: nan
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
env2_first_0:                 episode reward: -11.5500,                 loss: nan
env2_second_0:                 episode reward: 11.5500,                 loss: nan
env3_first_0:                 episode reward: -8.8500,                 loss: nan
env3_second_0:                 episode reward: 8.8500,                 loss: nan
env4_first_0:                 episode reward: -11.2500,                 loss: nan
env4_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.3147s / 23228.1627 s
env0_first_0:                 episode reward: -13.5500,                 loss: 11.3749
env0_second_0:                 episode reward: 13.5500,                 loss: nan
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
env2_first_0:                 episode reward: -9.4000,                 loss: nan
env2_second_0:                 episode reward: 9.4000,                 loss: nan
env3_first_0:                 episode reward: -12.0000,                 loss: nan
env3_second_0:                 episode reward: 12.0000,                 loss: nan
env4_first_0:                 episode reward: -10.7500,                 loss: nan
env4_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.5957s / 23316.7584 s
env0_first_0:                 episode reward: -8.4000,                 loss: 11.3261
env0_second_0:                 episode reward: 8.4000,                 loss: nan
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
env2_first_0:                 episode reward: -9.5000,                 loss: nan
env2_second_0:                 episode reward: 9.5000,                 loss: nan
env3_first_0:                 episode reward: -8.0500,                 loss: nan
env3_second_0:                 episode reward: 8.0500,                 loss: nan
env4_first_0:                 episode reward: -11.7000,                 loss: nan
env4_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6476s / 23404.4061 s
env0_first_0:                 episode reward: -4.2500,                 loss: 5.4497
env0_second_0:                 episode reward: 4.2500,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -5.1000,                 loss: nan
env3_second_0:                 episode reward: 5.1000,                 loss: nan
env4_first_0:                 episode reward: -4.4000,                 loss: nan
env4_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8162s / 23491.2223 s
env0_first_0:                 episode reward: -1.9500,                 loss: 2.4876
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.8278s / 23580.0501 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2663
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -1.2500,                 loss: nan
env3_second_0:                 episode reward: 1.2500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0227s / 23668.0729 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3976
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.6134s / 23756.6862 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.8004
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.3052s / 23844.9915 s
env0_first_0:                 episode reward: -10.5500,                 loss: 11.5401
env0_second_0:                 episode reward: 10.5500,                 loss: nan
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
env2_first_0:                 episode reward: -14.3500,                 loss: nan
env2_second_0:                 episode reward: 14.3500,                 loss: nan
env3_first_0:                 episode reward: -8.6500,                 loss: nan
env3_second_0:                 episode reward: 8.6500,                 loss: nan
env4_first_0:                 episode reward: -9.3500,                 loss: nan
env4_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4455s / 23932.4370 s
env0_first_0:                 episode reward: -14.1000,                 loss: 15.5873
env0_second_0:                 episode reward: 14.1000,                 loss: nan
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
env2_first_0:                 episode reward: -11.0500,                 loss: nan
env2_second_0:                 episode reward: 11.0500,                 loss: nan
env3_first_0:                 episode reward: -14.7500,                 loss: nan
env3_second_0:                 episode reward: 14.7500,                 loss: nan
env4_first_0:                 episode reward: -11.7500,                 loss: nan
env4_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1980s / 24019.6350 s
env0_first_0:                 episode reward: -19.0500,                 loss: 15.3378
env0_second_0:                 episode reward: 19.0500,                 loss: nan
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
env2_first_0:                 episode reward: -17.1500,                 loss: nan
env2_second_0:                 episode reward: 17.1500,                 loss: nan
env3_first_0:                 episode reward: -14.2500,                 loss: nan
env3_second_0:                 episode reward: 14.2500,                 loss: nan
env4_first_0:                 episode reward: -21.0500,                 loss: nan
env4_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2826s / 24106.9176 s
env0_first_0:                 episode reward: -14.7500,                 loss: 14.0148
env0_second_0:                 episode reward: 14.7500,                 loss: nan
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
env2_first_0:                 episode reward: -15.5000,                 loss: nan
env2_second_0:                 episode reward: 15.5000,                 loss: nan
env3_first_0:                 episode reward: -15.6000,                 loss: nan
env3_second_0:                 episode reward: 15.6000,                 loss: nan
env4_first_0:                 episode reward: -14.0500,                 loss: nan
env4_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9954s / 24193.9130 s
env0_first_0:                 episode reward: -1.1500,                 loss: 1.4795
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -2.5500,                 loss: nan
env2_second_0:                 episode reward: 2.5500,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9920s / 24280.9050 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7558
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4520s / 24367.3570 s
env0_first_0:                 episode reward: -3.0000,                 loss: 1.6087
env0_second_0:                 episode reward: 3.0000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -2.0500,                 loss: nan
env3_second_0:                 episode reward: 2.0500,                 loss: nan
env4_first_0:                 episode reward: -0.3500,                 loss: nan
env4_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7323s / 24455.0894 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.9692
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -1.3500,                 loss: nan
env3_second_0:                 episode reward: 1.3500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9186s / 24542.0079 s
env0_first_0:                 episode reward: -1.4000,                 loss: 3.1650
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: -1.7000,                 loss: nan
env4_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.8014s / 24627.8094 s
env0_first_0:                 episode reward: -6.4500,                 loss: 7.6205
env0_second_0:                 episode reward: 6.4500,                 loss: nan
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
env2_first_0:                 episode reward: -4.4500,                 loss: nan
env2_second_0:                 episode reward: 4.4500,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -7.1000,                 loss: nan
env4_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.7899s / 24713.5993 s
env0_first_0:                 episode reward: -4.2500,                 loss: 6.0383
env0_second_0:                 episode reward: 4.2500,                 loss: nan
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
env2_first_0:                 episode reward: -4.5000,                 loss: nan
env2_second_0:                 episode reward: 4.5000,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9967s / 24800.5960 s
env0_first_0:                 episode reward: -4.2000,                 loss: 6.5362
env0_second_0:                 episode reward: 4.2000,                 loss: nan
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
env2_first_0:                 episode reward: -7.2500,                 loss: nan
env2_second_0:                 episode reward: 7.2500,                 loss: nan
env3_first_0:                 episode reward: -3.8000,                 loss: nan
env3_second_0:                 episode reward: 3.8000,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3248s / 24886.9208 s
env0_first_0:                 episode reward: -8.7500,                 loss: 11.9226
env0_second_0:                 episode reward: 8.7500,                 loss: nan
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
env2_first_0:                 episode reward: -11.2000,                 loss: nan
env2_second_0:                 episode reward: 11.2000,                 loss: nan
env3_first_0:                 episode reward: -9.7000,                 loss: nan
env3_second_0:                 episode reward: 9.7000,                 loss: nan
env4_first_0:                 episode reward: -7.8500,                 loss: nan
env4_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2959s / 24974.2167 s
env0_first_0:                 episode reward: -13.7500,                 loss: 14.4296
env0_second_0:                 episode reward: 13.7500,                 loss: nan
env1_first_0:                 episode reward: -17.0000,                 loss: nan
env1_second_0:                 episode reward: 17.0000,                 loss: nan
env2_first_0:                 episode reward: -13.1000,                 loss: nan
env2_second_0:                 episode reward: 13.1000,                 loss: nan
env3_first_0:                 episode reward: -16.3500,                 loss: nan
env3_second_0:                 episode reward: 16.3500,                 loss: nan
env4_first_0:                 episode reward: -13.5000,                 loss: nan
env4_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.9779s / 25060.1946 s
env0_first_0:                 episode reward: -11.9500,                 loss: 15.4171
env0_second_0:                 episode reward: 11.9500,                 loss: nan
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
env2_first_0:                 episode reward: -13.6000,                 loss: nan
env2_second_0:                 episode reward: 13.6000,                 loss: nan
env3_first_0:                 episode reward: -15.2000,                 loss: nan
env3_second_0:                 episode reward: 15.2000,                 loss: nan
env4_first_0:                 episode reward: -18.3000,                 loss: nan
env4_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1005s / 25147.2951 s
env0_first_0:                 episode reward: -19.0000,                 loss: 14.6015
env0_second_0:                 episode reward: 19.0000,                 loss: nan
env1_first_0:                 episode reward: -19.8500,                 loss: nan
env1_second_0:                 episode reward: 19.8500,                 loss: nan
env2_first_0:                 episode reward: -17.2500,                 loss: nan
env2_second_0:                 episode reward: 17.2500,                 loss: nan
env3_first_0:                 episode reward: -18.4000,                 loss: nan
env3_second_0:                 episode reward: 18.4000,                 loss: nan
env4_first_0:                 episode reward: -23.2000,                 loss: nan
env4_second_0:                 episode reward: 23.2000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0308s / 25233.3259 s
env0_first_0:                 episode reward: -18.2000,                 loss: 14.6499
env0_second_0:                 episode reward: 18.2000,                 loss: nan
env1_first_0:                 episode reward: -19.8500,                 loss: nan
env1_second_0:                 episode reward: 19.8500,                 loss: nan
env2_first_0:                 episode reward: -19.9000,                 loss: nan
env2_second_0:                 episode reward: 19.9000,                 loss: nan
env3_first_0:                 episode reward: -24.4500,                 loss: nan
env3_second_0:                 episode reward: 24.4500,                 loss: nan
env4_first_0:                 episode reward: -22.1500,                 loss: nan
env4_second_0:                 episode reward: 22.1500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0331s / 25319.3590 s
env0_first_0:                 episode reward: -29.4500,                 loss: 16.3069
env0_second_0:                 episode reward: 29.4500,                 loss: nan
env1_first_0:                 episode reward: -27.4500,                 loss: nan
env1_second_0:                 episode reward: 27.4500,                 loss: nan
env2_first_0:                 episode reward: -23.5000,                 loss: nan
env2_second_0:                 episode reward: 23.5000,                 loss: nan
env3_first_0:                 episode reward: -25.8500,                 loss: nan
env3_second_0:                 episode reward: 25.8500,                 loss: nan
env4_first_0:                 episode reward: -25.5000,                 loss: nan
env4_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.5141s / 25407.8732 s
env0_first_0:                 episode reward: -26.8500,                 loss: 17.1323
env0_second_0:                 episode reward: 26.8500,                 loss: nan
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
env2_first_0:                 episode reward: -21.9500,                 loss: nan
env2_second_0:                 episode reward: 21.9500,                 loss: nan
env3_first_0:                 episode reward: -27.8000,                 loss: nan
env3_second_0:                 episode reward: 27.8000,                 loss: nan
env4_first_0:                 episode reward: -25.9500,                 loss: nan
env4_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0801s / 25494.9533 s
env0_first_0:                 episode reward: -27.4000,                 loss: 15.0658
env0_second_0:                 episode reward: 27.4000,                 loss: nan
env1_first_0:                 episode reward: -30.3000,                 loss: nan
env1_second_0:                 episode reward: 30.3000,                 loss: nan
env2_first_0:                 episode reward: -27.1500,                 loss: nan
env2_second_0:                 episode reward: 27.1500,                 loss: nan
env3_first_0:                 episode reward: -25.1500,                 loss: nan
env3_second_0:                 episode reward: 25.1500,                 loss: nan
env4_first_0:                 episode reward: -26.0000,                 loss: nan
env4_second_0:                 episode reward: 26.0000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6330s / 25581.5862 s
env0_first_0:                 episode reward: -25.1000,                 loss: 15.9447
env0_second_0:                 episode reward: 25.1000,                 loss: nan
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
env2_first_0:                 episode reward: -21.5000,                 loss: nan
env2_second_0:                 episode reward: 21.5000,                 loss: nan
env3_first_0:                 episode reward: -25.8500,                 loss: nan
env3_second_0:                 episode reward: 25.8500,                 loss: nan
env4_first_0:                 episode reward: -28.1500,                 loss: nan
env4_second_0:                 episode reward: 28.1500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5182s / 25668.1044 s
env0_first_0:                 episode reward: -14.7000,                 loss: 19.4937
env0_second_0:                 episode reward: 14.7000,                 loss: nan
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
env2_first_0:                 episode reward: -12.8500,                 loss: nan
env2_second_0:                 episode reward: 12.8500,                 loss: nan
env3_first_0:                 episode reward: -15.2000,                 loss: nan
env3_second_0:                 episode reward: 15.2000,                 loss: nan
env4_first_0:                 episode reward: -15.2000,                 loss: nan
env4_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7927s / 25755.8971 s
env0_first_0:                 episode reward: -4.6000,                 loss: 10.4767
env0_second_0:                 episode reward: 4.6000,                 loss: nan
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
env2_first_0:                 episode reward: -4.7500,                 loss: nan
env2_second_0:                 episode reward: 4.7500,                 loss: nan
env3_first_0:                 episode reward: -6.0000,                 loss: nan
env3_second_0:                 episode reward: 6.0000,                 loss: nan
env4_first_0:                 episode reward: -5.0000,                 loss: nan
env4_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3483s / 25843.2454 s
env0_first_0:                 episode reward: -1.1500,                 loss: 4.6811
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
env2_first_0:                 episode reward: -4.4500,                 loss: nan
env2_second_0:                 episode reward: 4.4500,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.1271s / 25932.3725 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0430
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1967s / 26019.5691 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.5257
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9976s / 26106.5667 s
env0_first_0:                 episode reward: -2.8500,                 loss: 2.4455
env0_second_0:                 episode reward: 2.8500,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -3.3500,                 loss: nan
env2_second_0:                 episode reward: 3.3500,                 loss: nan
env3_first_0:                 episode reward: -1.8500,                 loss: nan
env3_second_0:                 episode reward: 1.8500,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0710s / 26193.6377 s
env0_first_0:                 episode reward: -3.2000,                 loss: 3.9309
env0_second_0:                 episode reward: 3.2000,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -3.2000,                 loss: nan
env3_second_0:                 episode reward: 3.2000,                 loss: nan
env4_first_0:                 episode reward: -4.8000,                 loss: nan
env4_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6032s / 26280.2409 s
env0_first_0:                 episode reward: -8.1500,                 loss: 8.5150
env0_second_0:                 episode reward: 8.1500,                 loss: nan
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
env2_first_0:                 episode reward: -9.3000,                 loss: nan
env2_second_0:                 episode reward: 9.3000,                 loss: nan
env3_first_0:                 episode reward: -9.0000,                 loss: nan
env3_second_0:                 episode reward: 9.0000,                 loss: nan
env4_first_0:                 episode reward: -8.5000,                 loss: nan
env4_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9117s / 26367.1526 s
env0_first_0:                 episode reward: -12.2500,                 loss: 10.2863
env0_second_0:                 episode reward: 12.2500,                 loss: nan
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
env2_first_0:                 episode reward: -13.6500,                 loss: nan
env2_second_0:                 episode reward: 13.6500,                 loss: nan
env3_first_0:                 episode reward: -14.5000,                 loss: nan
env3_second_0:                 episode reward: 14.5000,                 loss: nan
env4_first_0:                 episode reward: -6.3000,                 loss: nan
env4_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7841s / 26454.9367 s
env0_first_0:                 episode reward: -6.7000,                 loss: 12.5543
env0_second_0:                 episode reward: 6.7000,                 loss: nan
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
env2_first_0:                 episode reward: -12.9000,                 loss: nan
env2_second_0:                 episode reward: 12.9000,                 loss: nan
env3_first_0:                 episode reward: -10.3000,                 loss: nan
env3_second_0:                 episode reward: 10.3000,                 loss: nan
env4_first_0:                 episode reward: -11.7500,                 loss: nan
env4_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5809s / 26542.5176 s
env0_first_0:                 episode reward: -3.5500,                 loss: 13.5852
env0_second_0:                 episode reward: 3.5500,                 loss: nan
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
env2_first_0:                 episode reward: -5.1000,                 loss: nan
env2_second_0:                 episode reward: 5.1000,                 loss: nan
env3_first_0:                 episode reward: -7.4000,                 loss: nan
env3_second_0:                 episode reward: 7.4000,                 loss: nan
env4_first_0:                 episode reward: -5.2000,                 loss: nan
env4_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4376s / 26628.9552 s
env0_first_0:                 episode reward: -3.3000,                 loss: 6.3827
env0_second_0:                 episode reward: 3.3000,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -3.9000,                 loss: nan
env2_second_0:                 episode reward: 3.9000,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7638s / 26715.7190 s
env0_first_0:                 episode reward: -7.1000,                 loss: 10.4730
env0_second_0:                 episode reward: 7.1000,                 loss: nan
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
env2_first_0:                 episode reward: -10.5000,                 loss: nan
env2_second_0:                 episode reward: 10.5000,                 loss: nan
env3_first_0:                 episode reward: -8.7500,                 loss: nan
env3_second_0:                 episode reward: 8.7500,                 loss: nan
env4_first_0:                 episode reward: -11.3500,                 loss: nan
env4_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.7791s / 26801.4981 s
env0_first_0:                 episode reward: -11.3000,                 loss: 16.2984
env0_second_0:                 episode reward: 11.3000,                 loss: nan
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
env2_first_0:                 episode reward: -14.1500,                 loss: nan
env2_second_0:                 episode reward: 14.1500,                 loss: nan
env3_first_0:                 episode reward: -10.1500,                 loss: nan
env3_second_0:                 episode reward: 10.1500,                 loss: nan
env4_first_0:                 episode reward: -12.0000,                 loss: nan
env4_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3022s / 26887.8003 s
env0_first_0:                 episode reward: -14.9500,                 loss: 17.4305
env0_second_0:                 episode reward: 14.9500,                 loss: nan
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
env2_first_0:                 episode reward: -17.7000,                 loss: nan
env2_second_0:                 episode reward: 17.7000,                 loss: nan
env3_first_0:                 episode reward: -18.1500,                 loss: nan
env3_second_0:                 episode reward: 18.1500,                 loss: nan
env4_first_0:                 episode reward: -17.6000,                 loss: nan
env4_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6204s / 26974.4207 s
env0_first_0:                 episode reward: -12.3500,                 loss: 15.1813
env0_second_0:                 episode reward: 12.3500,                 loss: nan
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
env2_first_0:                 episode reward: -12.3500,                 loss: nan
env2_second_0:                 episode reward: 12.3500,                 loss: nan
env3_first_0:                 episode reward: -10.8500,                 loss: nan
env3_second_0:                 episode reward: 10.8500,                 loss: nan
env4_first_0:                 episode reward: -13.3000,                 loss: nan
env4_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4275s / 27061.8482 s
env0_first_0:                 episode reward: -11.4500,                 loss: 12.5056
env0_second_0:                 episode reward: 11.4500,                 loss: nan
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
env2_first_0:                 episode reward: -9.4500,                 loss: nan
env2_second_0:                 episode reward: 9.4500,                 loss: nan
env3_first_0:                 episode reward: -11.4000,                 loss: nan
env3_second_0:                 episode reward: 11.4000,                 loss: nan
env4_first_0:                 episode reward: -6.2500,                 loss: nan
env4_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.2775s / 27150.1258 s
env0_first_0:                 episode reward: -5.3000,                 loss: 12.7751
env0_second_0:                 episode reward: 5.3000,                 loss: nan
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
env2_first_0:                 episode reward: -8.4000,                 loss: nan
env2_second_0:                 episode reward: 8.4000,                 loss: nan
env3_first_0:                 episode reward: -9.3500,                 loss: nan
env3_second_0:                 episode reward: 9.3500,                 loss: nan
env4_first_0:                 episode reward: -12.3500,                 loss: nan
env4_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.6949s / 27235.8207 s
env0_first_0:                 episode reward: -4.7000,                 loss: 9.7672
env0_second_0:                 episode reward: 4.7000,                 loss: nan
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
env2_first_0:                 episode reward: -6.8000,                 loss: nan
env2_second_0:                 episode reward: 6.8000,                 loss: nan
env3_first_0:                 episode reward: -6.1500,                 loss: nan
env3_second_0:                 episode reward: 6.1500,                 loss: nan
env4_first_0:                 episode reward: -2.7000,                 loss: nan
env4_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2979s / 27323.1186 s
env0_first_0:                 episode reward: -4.1500,                 loss: 15.1759
env0_second_0:                 episode reward: 4.1500,                 loss: nan
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
env2_first_0:                 episode reward: -8.0000,                 loss: nan
env2_second_0:                 episode reward: 8.0000,                 loss: nan
env3_first_0:                 episode reward: -11.1500,                 loss: nan
env3_second_0:                 episode reward: 11.1500,                 loss: nan
env4_first_0:                 episode reward: -10.7500,                 loss: nan
env4_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.4704s / 27410.5890 s
env0_first_0:                 episode reward: -5.9500,                 loss: 8.8084
env0_second_0:                 episode reward: 5.9500,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -5.1500,                 loss: nan
env3_second_0:                 episode reward: 5.1500,                 loss: nan
env4_first_0:                 episode reward: -5.3000,                 loss: nan
env4_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9894s / 27497.5784 s
env0_first_0:                 episode reward: -2.0500,                 loss: 8.0745
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5418s / 27584.1202 s
env0_first_0:                 episode reward: -3.3500,                 loss: 8.4399
env0_second_0:                 episode reward: 3.3500,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: -3.0500,                 loss: nan
env2_second_0:                 episode reward: 3.0500,                 loss: nan
env3_first_0:                 episode reward: -2.5000,                 loss: nan
env3_second_0:                 episode reward: 2.5000,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5815s / 27671.7017 s
env0_first_0:                 episode reward: -8.3000,                 loss: 10.0303
env0_second_0:                 episode reward: 8.3000,                 loss: nan
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
env2_first_0:                 episode reward: -7.5000,                 loss: nan
env2_second_0:                 episode reward: 7.5000,                 loss: nan
env3_first_0:                 episode reward: -8.1000,                 loss: nan
env3_second_0:                 episode reward: 8.1000,                 loss: nan
env4_first_0:                 episode reward: -9.4000,                 loss: nan
env4_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8158s / 27758.5175 s
env0_first_0:                 episode reward: -2.5500,                 loss: 7.0143
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -5.2500,                 loss: nan
env2_second_0:                 episode reward: 5.2500,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -3.7000,                 loss: nan
env4_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7662s / 27846.2837 s
env0_first_0:                 episode reward: 1.3500,                 loss: 8.5522
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -3.0500,                 loss: nan
env2_second_0:                 episode reward: 3.0500,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.7350s / 27935.0187 s
env0_first_0:                 episode reward: -0.7500,                 loss: 9.1930
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -4.4500,                 loss: nan
env2_second_0:                 episode reward: 4.4500,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -5.5000,                 loss: nan
env4_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.9332s / 28023.9519 s
env0_first_0:                 episode reward: -3.2000,                 loss: 3.1396
env0_second_0:                 episode reward: 3.2000,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: -2.1500,                 loss: nan
env2_second_0:                 episode reward: 2.1500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0684s / 28111.0203 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3050
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.0661s / 28200.0863 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.6147
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.9865s / 28288.0728 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6430
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5766s / 28375.6494 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.6045
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4318s / 28462.0813 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5043
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.5497s / 28550.6309 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4669
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0653s / 28638.6962 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.5247
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4837s / 28725.1799 s
env0_first_0:                 episode reward: 0.9500,                 loss: 1.3348
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.2753s / 28811.4552 s
env0_first_0:                 episode reward: 1.1500,                 loss: 1.7105
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4649s / 28897.9201 s
env0_first_0:                 episode reward: -2.4500,                 loss: 5.2916
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9130s / 28984.8331 s
env0_first_0:                 episode reward: -7.3500,                 loss: 7.1654
env0_second_0:                 episode reward: 7.3500,                 loss: nan
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
env2_first_0:                 episode reward: -6.3000,                 loss: nan
env2_second_0:                 episode reward: 6.3000,                 loss: nan
env3_first_0:                 episode reward: -6.5000,                 loss: nan
env3_second_0:                 episode reward: 6.5000,                 loss: nan
env4_first_0:                 episode reward: -9.0000,                 loss: nan
env4_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.6644s / 29070.4975 s
env0_first_0:                 episode reward: -1.4500,                 loss: 5.5939
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -3.8000,                 loss: nan
env3_second_0:                 episode reward: 3.8000,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.2999s / 29156.7973 s
env0_first_0:                 episode reward: -2.0500,                 loss: 4.8079
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.9812s / 29242.7786 s
env0_first_0:                 episode reward: -6.6500,                 loss: 9.5866
env0_second_0:                 episode reward: 6.6500,                 loss: nan
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
env2_first_0:                 episode reward: -7.1000,                 loss: nan
env2_second_0:                 episode reward: 7.1000,                 loss: nan
env3_first_0:                 episode reward: -7.0000,                 loss: nan
env3_second_0:                 episode reward: 7.0000,                 loss: nan
env4_first_0:                 episode reward: -9.0000,                 loss: nan
env4_second_0:                 episode reward: 9.0000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0405s / 29328.8191 s
env0_first_0:                 episode reward: -5.8000,                 loss: 6.4724
env0_second_0:                 episode reward: 5.8000,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3115s / 29416.1306 s
env0_first_0:                 episode reward: -2.5000,                 loss: 8.7156
env0_second_0:                 episode reward: 2.5000,                 loss: nan
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
env2_first_0:                 episode reward: -4.7000,                 loss: nan
env2_second_0:                 episode reward: 4.7000,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -4.8000,                 loss: nan
env4_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0766s / 29502.2072 s
env0_first_0:                 episode reward: -0.9500,                 loss: 8.6841
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
env2_first_0:                 episode reward: -4.8000,                 loss: nan
env2_second_0:                 episode reward: 4.8000,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -5.6000,                 loss: nan
env4_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3196s / 29588.5268 s
env0_first_0:                 episode reward: -4.3500,                 loss: 7.7435
env0_second_0:                 episode reward: 4.3500,                 loss: nan
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5460s / 29675.0727 s
env0_first_0:                 episode reward: -3.6000,                 loss: 10.2392
env0_second_0:                 episode reward: 3.6000,                 loss: nan
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
env3_first_0:                 episode reward: -9.5000,                 loss: nan
env3_second_0:                 episode reward: 9.5000,                 loss: nan
env4_first_0:                 episode reward: -6.6500,                 loss: nan
env4_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.8701s / 29761.9428 s
env0_first_0:                 episode reward: -8.9500,                 loss: 10.1173
env0_second_0:                 episode reward: 8.9500,                 loss: nan
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
env2_first_0:                 episode reward: -9.7500,                 loss: nan
env2_second_0:                 episode reward: 9.7500,                 loss: nan
env3_first_0:                 episode reward: -8.0500,                 loss: nan
env3_second_0:                 episode reward: 8.0500,                 loss: nan
env4_first_0:                 episode reward: -7.0000,                 loss: nan
env4_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5581s / 29848.5009 s
env0_first_0:                 episode reward: -10.1000,                 loss: 14.0023
env0_second_0:                 episode reward: 10.1000,                 loss: nan
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
env2_first_0:                 episode reward: -9.2000,                 loss: nan
env2_second_0:                 episode reward: 9.2000,                 loss: nan
env3_first_0:                 episode reward: -10.4000,                 loss: nan
env3_second_0:                 episode reward: 10.4000,                 loss: nan
env4_first_0:                 episode reward: -7.1500,                 loss: nan
env4_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.1340s / 29933.6349 s
env0_first_0:                 episode reward: -8.9000,                 loss: 12.6635
env0_second_0:                 episode reward: 8.9000,                 loss: nan
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
env2_first_0:                 episode reward: -7.4500,                 loss: nan
env2_second_0:                 episode reward: 7.4500,                 loss: nan
env3_first_0:                 episode reward: -6.4500,                 loss: nan
env3_second_0:                 episode reward: 6.4500,                 loss: nan
env4_first_0:                 episode reward: -7.0000,                 loss: nan
env4_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9800s / 30020.6149 s
env0_first_0:                 episode reward: -5.9500,                 loss: 9.0002
env0_second_0:                 episode reward: 5.9500,                 loss: nan
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
env2_first_0:                 episode reward: -8.0500,                 loss: nan
env2_second_0:                 episode reward: 8.0500,                 loss: nan
env3_first_0:                 episode reward: -6.7000,                 loss: nan
env3_second_0:                 episode reward: 6.7000,                 loss: nan
env4_first_0:                 episode reward: -6.5500,                 loss: nan
env4_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3711s / 30106.9860 s
env0_first_0:                 episode reward: -6.4000,                 loss: 8.0287
env0_second_0:                 episode reward: 6.4000,                 loss: nan
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
env2_first_0:                 episode reward: -7.6500,                 loss: nan
env2_second_0:                 episode reward: 7.6500,                 loss: nan
env3_first_0:                 episode reward: -7.6000,                 loss: nan
env3_second_0:                 episode reward: 7.6000,                 loss: nan
env4_first_0:                 episode reward: -5.8500,                 loss: nan
env4_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.2600s / 30193.2460 s
env0_first_0:                 episode reward: -4.6000,                 loss: 8.3942
env0_second_0:                 episode reward: 4.6000,                 loss: nan
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
env2_first_0:                 episode reward: -12.1500,                 loss: nan
env2_second_0:                 episode reward: 12.1500,                 loss: nan
env3_first_0:                 episode reward: -3.9000,                 loss: nan
env3_second_0:                 episode reward: 3.9000,                 loss: nan
env4_first_0:                 episode reward: -5.3000,                 loss: nan
env4_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3071s / 30280.5531 s
env0_first_0:                 episode reward: -5.3000,                 loss: 8.5149
env0_second_0:                 episode reward: 5.3000,                 loss: nan
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
env2_first_0:                 episode reward: -5.3500,                 loss: nan
env2_second_0:                 episode reward: 5.3500,                 loss: nan
env3_first_0:                 episode reward: -5.9500,                 loss: nan
env3_second_0:                 episode reward: 5.9500,                 loss: nan
env4_first_0:                 episode reward: -8.7000,                 loss: nan
env4_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.9887s / 30366.5418 s
env0_first_0:                 episode reward: -4.0000,                 loss: 12.1343
env0_second_0:                 episode reward: 4.0000,                 loss: nan
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -7.6500,                 loss: nan
env3_second_0:                 episode reward: 7.6500,                 loss: nan
env4_first_0:                 episode reward: -2.2500,                 loss: nan
env4_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.1155s / 30452.6573 s
env0_first_0:                 episode reward: -4.8500,                 loss: 15.3120
env0_second_0:                 episode reward: 4.8500,                 loss: nan
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: -3.0000,                 loss: nan
env4_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6689s / 30540.3262 s
env0_first_0:                 episode reward: -4.4500,                 loss: 12.9035
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -6.9500,                 loss: nan
env2_second_0:                 episode reward: 6.9500,                 loss: nan
env3_first_0:                 episode reward: -6.4500,                 loss: nan
env3_second_0:                 episode reward: 6.4500,                 loss: nan
env4_first_0:                 episode reward: -3.7500,                 loss: nan
env4_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4356s / 30626.7619 s
env0_first_0:                 episode reward: -5.2000,                 loss: 12.1753
env0_second_0:                 episode reward: 5.2000,                 loss: nan
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -2.1000,                 loss: nan
env3_second_0:                 episode reward: 2.1000,                 loss: nan
env4_first_0:                 episode reward: -6.5000,                 loss: nan
env4_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6493s / 30713.4111 s
env0_first_0:                 episode reward: -5.2000,                 loss: 17.9272
env0_second_0:                 episode reward: 5.2000,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -5.5000,                 loss: nan
env2_second_0:                 episode reward: 5.5000,                 loss: nan
env3_first_0:                 episode reward: -10.5500,                 loss: nan
env3_second_0:                 episode reward: 10.5500,                 loss: nan
env4_first_0:                 episode reward: -10.0000,                 loss: nan
env4_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6146s / 30801.0258 s
env0_first_0:                 episode reward: -5.3500,                 loss: 12.5457
env0_second_0:                 episode reward: 5.3500,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -5.7500,                 loss: nan
env2_second_0:                 episode reward: 5.7500,                 loss: nan
env3_first_0:                 episode reward: -5.9500,                 loss: nan
env3_second_0:                 episode reward: 5.9500,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3154s / 30888.3412 s
env0_first_0:                 episode reward: -3.1000,                 loss: 10.4059
env0_second_0:                 episode reward: 3.1000,                 loss: nan
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
env2_first_0:                 episode reward: -6.0500,                 loss: nan
env2_second_0:                 episode reward: 6.0500,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -5.6000,                 loss: nan
env4_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.9423s / 30974.2836 s
env0_first_0:                 episode reward: -6.3500,                 loss: 11.2495
env0_second_0:                 episode reward: 6.3500,                 loss: nan
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
env2_first_0:                 episode reward: -6.9000,                 loss: nan
env2_second_0:                 episode reward: 6.9000,                 loss: nan
env3_first_0:                 episode reward: -6.5500,                 loss: nan
env3_second_0:                 episode reward: 6.5500,                 loss: nan
env4_first_0:                 episode reward: -3.7000,                 loss: nan
env4_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3659s / 31060.6494 s
env0_first_0:                 episode reward: -14.0000,                 loss: 15.6283
env0_second_0:                 episode reward: 14.0000,                 loss: nan
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
env2_first_0:                 episode reward: -9.7500,                 loss: nan
env2_second_0:                 episode reward: 9.7500,                 loss: nan
env3_first_0:                 episode reward: -7.2500,                 loss: nan
env3_second_0:                 episode reward: 7.2500,                 loss: nan
env4_first_0:                 episode reward: -7.6000,                 loss: nan
env4_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2960s / 31147.9454 s
env0_first_0:                 episode reward: -11.1000,                 loss: 17.2125
env0_second_0:                 episode reward: 11.1000,                 loss: nan
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
env2_first_0:                 episode reward: -13.6000,                 loss: nan
env2_second_0:                 episode reward: 13.6000,                 loss: nan
env3_first_0:                 episode reward: -14.2500,                 loss: nan
env3_second_0:                 episode reward: 14.2500,                 loss: nan
env4_first_0:                 episode reward: -11.5000,                 loss: nan
env4_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5510s / 31234.4964 s
env0_first_0:                 episode reward: -10.5000,                 loss: 16.5883
env0_second_0:                 episode reward: 10.5000,                 loss: nan
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
env2_first_0:                 episode reward: -11.4500,                 loss: nan
env2_second_0:                 episode reward: 11.4500,                 loss: nan
env3_first_0:                 episode reward: -4.8500,                 loss: nan
env3_second_0:                 episode reward: 4.8500,                 loss: nan
env4_first_0:                 episode reward: -11.0000,                 loss: nan
env4_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.5037s / 31320.0001 s
env0_first_0:                 episode reward: -6.0500,                 loss: 11.6324
env0_second_0:                 episode reward: 6.0500,                 loss: nan
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
env2_first_0:                 episode reward: -4.3500,                 loss: nan
env2_second_0:                 episode reward: 4.3500,                 loss: nan
env3_first_0:                 episode reward: -5.3500,                 loss: nan
env3_second_0:                 episode reward: 5.3500,                 loss: nan
env4_first_0:                 episode reward: -6.3500,                 loss: nan
env4_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0230s / 31408.0231 s
env0_first_0:                 episode reward: -2.4500,                 loss: 7.0415
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -3.9000,                 loss: nan
env3_second_0:                 episode reward: 3.9000,                 loss: nan
env4_first_0:                 episode reward: -3.2000,                 loss: nan
env4_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2980s / 31495.3211 s
env0_first_0:                 episode reward: -4.1000,                 loss: 4.5843
env0_second_0:                 episode reward: 4.1000,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -3.7500,                 loss: nan
env2_second_0:                 episode reward: 3.7500,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -4.1000,                 loss: nan
env4_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0919s / 31582.4130 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.9659
env0_second_0:                 episode reward: 1.9000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -2.0000,                 loss: nan
env3_second_0:                 episode reward: 2.0000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9947s / 31669.4077 s
env0_first_0:                 episode reward: -3.8500,                 loss: 9.1187
env0_second_0:                 episode reward: 3.8500,                 loss: nan
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
env2_first_0:                 episode reward: -6.0500,                 loss: nan
env2_second_0:                 episode reward: 6.0500,                 loss: nan
env3_first_0:                 episode reward: -6.5000,                 loss: nan
env3_second_0:                 episode reward: 6.5000,                 loss: nan
env4_first_0:                 episode reward: -8.2500,                 loss: nan
env4_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1144s / 31756.5221 s
env0_first_0:                 episode reward: -14.5000,                 loss: 16.3570
env0_second_0:                 episode reward: 14.5000,                 loss: nan
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
env2_first_0:                 episode reward: -7.7500,                 loss: nan
env2_second_0:                 episode reward: 7.7500,                 loss: nan
env3_first_0:                 episode reward: -5.1500,                 loss: nan
env3_second_0:                 episode reward: 5.1500,                 loss: nan
env4_first_0:                 episode reward: -10.7500,                 loss: nan
env4_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1377s / 31843.6598 s
env0_first_0:                 episode reward: -7.8000,                 loss: 16.4235
env0_second_0:                 episode reward: 7.8000,                 loss: nan
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
env2_first_0:                 episode reward: -11.5500,                 loss: nan
env2_second_0:                 episode reward: 11.5500,                 loss: nan
env3_first_0:                 episode reward: -9.9000,                 loss: nan
env3_second_0:                 episode reward: 9.9000,                 loss: nan
env4_first_0:                 episode reward: -11.3000,                 loss: nan
env4_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0201s / 31929.6798 s
env0_first_0:                 episode reward: -19.5500,                 loss: 23.2582
env0_second_0:                 episode reward: 19.5500,                 loss: nan
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
env2_first_0:                 episode reward: -15.7000,                 loss: nan
env2_second_0:                 episode reward: 15.7000,                 loss: nan
env3_first_0:                 episode reward: -11.2500,                 loss: nan
env3_second_0:                 episode reward: 11.2500,                 loss: nan
env4_first_0:                 episode reward: -17.6500,                 loss: nan
env4_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9606s / 32016.6404 s
env0_first_0:                 episode reward: -17.8500,                 loss: 26.1895
env0_second_0:                 episode reward: 17.8500,                 loss: nan
env1_first_0:                 episode reward: -16.3500,                 loss: nan
env1_second_0:                 episode reward: 16.3500,                 loss: nan
env2_first_0:                 episode reward: -17.2500,                 loss: nan
env2_second_0:                 episode reward: 17.2500,                 loss: nan
env3_first_0:                 episode reward: -17.4000,                 loss: nan
env3_second_0:                 episode reward: 17.4000,                 loss: nan
env4_first_0:                 episode reward: -25.3000,                 loss: nan
env4_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.2785s / 32101.9189 s
env0_first_0:                 episode reward: -20.5000,                 loss: 36.4144
env0_second_0:                 episode reward: 20.5000,                 loss: nan
env1_first_0:                 episode reward: -26.5500,                 loss: nan
env1_second_0:                 episode reward: 26.5500,                 loss: nan
env2_first_0:                 episode reward: -26.5000,                 loss: nan
env2_second_0:                 episode reward: 26.5000,                 loss: nan
env3_first_0:                 episode reward: -32.9500,                 loss: nan
env3_second_0:                 episode reward: 32.9500,                 loss: nan
env4_first_0:                 episode reward: -29.2000,                 loss: nan
env4_second_0:                 episode reward: 29.2000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3343s / 32188.2532 s
env0_first_0:                 episode reward: -21.8000,                 loss: 29.4404
env0_second_0:                 episode reward: 21.8000,                 loss: nan
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
env2_first_0:                 episode reward: -21.2000,                 loss: nan
env2_second_0:                 episode reward: 21.2000,                 loss: nan
env3_first_0:                 episode reward: -16.0000,                 loss: nan
env3_second_0:                 episode reward: 16.0000,                 loss: nan
env4_first_0:                 episode reward: -17.9000,                 loss: nan
env4_second_0:                 episode reward: 17.9000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6107s / 32274.8639 s
env0_first_0:                 episode reward: -19.2500,                 loss: 29.2536
env0_second_0:                 episode reward: 19.2500,                 loss: nan
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
env2_first_0:                 episode reward: -16.2000,                 loss: nan
env2_second_0:                 episode reward: 16.2000,                 loss: nan
env3_first_0:                 episode reward: -11.5500,                 loss: nan
env3_second_0:                 episode reward: 11.5500,                 loss: nan
env4_first_0:                 episode reward: -14.7000,                 loss: nan
env4_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5967s / 32361.4606 s
env0_first_0:                 episode reward: -7.6000,                 loss: 17.3333
env0_second_0:                 episode reward: 7.6000,                 loss: nan
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
env2_first_0:                 episode reward: -8.8500,                 loss: nan
env2_second_0:                 episode reward: 8.8500,                 loss: nan
env3_first_0:                 episode reward: -7.9500,                 loss: nan
env3_second_0:                 episode reward: 7.9500,                 loss: nan
env4_first_0:                 episode reward: -7.4500,                 loss: nan
env4_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9560s / 32448.4166 s
env0_first_0:                 episode reward: -14.9500,                 loss: 19.8717
env0_second_0:                 episode reward: 14.9500,                 loss: nan
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
env2_first_0:                 episode reward: -13.4500,                 loss: nan
env2_second_0:                 episode reward: 13.4500,                 loss: nan
env3_first_0:                 episode reward: -10.3500,                 loss: nan
env3_second_0:                 episode reward: 10.3500,                 loss: nan
env4_first_0:                 episode reward: -11.4500,                 loss: nan
env4_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1943s / 32535.6108 s
env0_first_0:                 episode reward: -12.4000,                 loss: 23.0285
env0_second_0:                 episode reward: 12.4000,                 loss: nan
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
env2_first_0:                 episode reward: -10.1000,                 loss: nan
env2_second_0:                 episode reward: 10.1000,                 loss: nan
env3_first_0:                 episode reward: -18.4000,                 loss: nan
env3_second_0:                 episode reward: 18.4000,                 loss: nan
env4_first_0:                 episode reward: -12.4000,                 loss: nan
env4_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3702s / 32622.9810 s
env0_first_0:                 episode reward: -33.6000,                 loss: 44.8928
env0_second_0:                 episode reward: 33.6000,                 loss: nan
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
env2_first_0:                 episode reward: -25.8500,                 loss: nan
env2_second_0:                 episode reward: 25.8500,                 loss: nan
env3_first_0:                 episode reward: -32.0500,                 loss: nan
env3_second_0:                 episode reward: 32.0500,                 loss: nan
env4_first_0:                 episode reward: -29.2000,                 loss: nan
env4_second_0:                 episode reward: 29.2000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 297.75,                last time consumption/overall running time: 85.8854s / 32708.8664 s
env0_first_0:                 episode reward: -55.8000,                 loss: 62.2251
env0_second_0:                 episode reward: 55.8000,                 loss: nan
env1_first_0:                 episode reward: -62.7000,                 loss: nan
env1_second_0:                 episode reward: 62.7000,                 loss: nan
env2_first_0:                 episode reward: -63.6500,                 loss: nan
env2_second_0:                 episode reward: 63.6500,                 loss: nan
env3_first_0:                 episode reward: -55.4500,                 loss: nan
env3_second_0:                 episode reward: 55.4500,                 loss: nan
env4_first_0:                 episode reward: -49.7000,                 loss: nan
env4_second_0:                 episode reward: 49.7000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 297.95,                last time consumption/overall running time: 87.0813s / 32795.9477 s
env0_first_0:                 episode reward: -48.6500,                 loss: 67.5532
env0_second_0:                 episode reward: 48.6500,                 loss: nan
env1_first_0:                 episode reward: -63.8000,                 loss: nan
env1_second_0:                 episode reward: 63.8000,                 loss: nan
env2_first_0:                 episode reward: -51.4500,                 loss: nan
env2_second_0:                 episode reward: 51.4500,                 loss: nan
env3_first_0:                 episode reward: -61.3000,                 loss: nan
env3_second_0:                 episode reward: 61.3000,                 loss: nan
env4_first_0:                 episode reward: -58.8000,                 loss: nan
env4_second_0:                 episode reward: 58.8000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 290.6,                last time consumption/overall running time: 84.2405s / 32880.1882 s
env0_first_0:                 episode reward: -64.1500,                 loss: 80.1051
env0_second_0:                 episode reward: 64.1500,                 loss: nan
env1_first_0:                 episode reward: -59.0000,                 loss: nan
env1_second_0:                 episode reward: 59.0000,                 loss: nan
env2_first_0:                 episode reward: -66.5000,                 loss: nan
env2_second_0:                 episode reward: 66.5000,                 loss: nan
env3_first_0:                 episode reward: -65.5000,                 loss: nan
env3_second_0:                 episode reward: 65.5000,                 loss: nan
env4_first_0:                 episode reward: -65.0000,                 loss: nan
env4_second_0:                 episode reward: 65.0000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 276.45,                last time consumption/overall running time: 81.4189s / 32961.6071 s
env0_first_0:                 episode reward: -61.9000,                 loss: 86.3131
env0_second_0:                 episode reward: 61.9000,                 loss: nan
env1_first_0:                 episode reward: -69.9000,                 loss: nan
env1_second_0:                 episode reward: 69.9000,                 loss: nan
env2_first_0:                 episode reward: -52.6500,                 loss: nan
env2_second_0:                 episode reward: 52.6500,                 loss: nan
env3_first_0:                 episode reward: -60.3000,                 loss: nan
env3_second_0:                 episode reward: 60.3000,                 loss: nan
env4_first_0:                 episode reward: -62.0500,                 loss: nan
env4_second_0:                 episode reward: 62.0500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 282.2,                last time consumption/overall running time: 82.3392s / 33043.9462 s
env0_first_0:                 episode reward: -63.1000,                 loss: 93.2476
env0_second_0:                 episode reward: 63.1000,                 loss: nan
env1_first_0:                 episode reward: -64.8500,                 loss: nan
env1_second_0:                 episode reward: 64.8500,                 loss: nan
env2_first_0:                 episode reward: -66.0000,                 loss: nan
env2_second_0:                 episode reward: 66.0000,                 loss: nan
env3_first_0:                 episode reward: -70.2000,                 loss: nan
env3_second_0:                 episode reward: 70.2000,                 loss: nan
env4_first_0:                 episode reward: -71.9000,                 loss: nan
env4_second_0:                 episode reward: 71.9000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 286.1,                last time consumption/overall running time: 83.9122s / 33127.8584 s
env0_first_0:                 episode reward: -50.0000,                 loss: 83.2809
env0_second_0:                 episode reward: 50.0000,                 loss: nan
env1_first_0:                 episode reward: -68.0000,                 loss: nan
env1_second_0:                 episode reward: 68.0000,                 loss: nan
env2_first_0:                 episode reward: -57.8500,                 loss: nan
env2_second_0:                 episode reward: 57.8500,                 loss: nan
env3_first_0:                 episode reward: -44.3000,                 loss: nan
env3_second_0:                 episode reward: 44.3000,                 loss: nan
env4_first_0:                 episode reward: -54.1000,                 loss: nan
env4_second_0:                 episode reward: 54.1000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 289.75,                last time consumption/overall running time: 85.2833s / 33213.1417 s
env0_first_0:                 episode reward: -30.7000,                 loss: 79.9264
env0_second_0:                 episode reward: 30.7000,                 loss: nan
env1_first_0:                 episode reward: -42.8000,                 loss: nan
env1_second_0:                 episode reward: 42.8000,                 loss: nan
env2_first_0:                 episode reward: -40.5000,                 loss: nan
env2_second_0:                 episode reward: 40.5000,                 loss: nan
env3_first_0:                 episode reward: -35.3500,                 loss: nan
env3_second_0:                 episode reward: 35.3500,                 loss: nan
env4_first_0:                 episode reward: -48.1000,                 loss: nan
env4_second_0:                 episode reward: 48.1000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.8413s / 33298.9830 s
env0_first_0:                 episode reward: 1.4500,                 loss: 18.8999
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -1.9500,                 loss: nan
env3_second_0:                 episode reward: 1.9500,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 84.7876s / 33383.7706 s
env0_first_0:                 episode reward: -2.2500,                 loss: 5.4112
env0_second_0:                 episode reward: 2.2500,                 loss: nan
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -5.3500,                 loss: nan
env3_second_0:                 episode reward: 5.3500,                 loss: nan
env4_first_0:                 episode reward: -2.9500,                 loss: nan
env4_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0853s / 33469.8558 s
env0_first_0:                 episode reward: -7.6500,                 loss: 16.9692
env0_second_0:                 episode reward: 7.6500,                 loss: nan
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
env2_first_0:                 episode reward: -9.1000,                 loss: nan
env2_second_0:                 episode reward: 9.1000,                 loss: nan
env3_first_0:                 episode reward: -6.0500,                 loss: nan
env3_second_0:                 episode reward: 6.0500,                 loss: nan
env4_first_0:                 episode reward: -4.6500,                 loss: nan
env4_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 295.1,                last time consumption/overall running time: 85.9164s / 33555.7722 s
env0_first_0:                 episode reward: -8.2000,                 loss: 20.9592
env0_second_0:                 episode reward: 8.2000,                 loss: nan
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
env3_first_0:                 episode reward: -5.0000,                 loss: nan
env3_second_0:                 episode reward: 5.0000,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.8679s / 33641.6401 s
env0_first_0:                 episode reward: -6.7500,                 loss: 10.9592
env0_second_0:                 episode reward: 6.7500,                 loss: nan
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
env2_first_0:                 episode reward: -3.3500,                 loss: nan
env2_second_0:                 episode reward: 3.3500,                 loss: nan
env3_first_0:                 episode reward: -4.1500,                 loss: nan
env3_second_0:                 episode reward: 4.1500,                 loss: nan
env4_first_0:                 episode reward: -4.7500,                 loss: nan
env4_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5938s / 33728.2339 s
env0_first_0:                 episode reward: -2.0000,                 loss: 4.4909
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -4.1500,                 loss: nan
env3_second_0:                 episode reward: 4.1500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5190s / 33814.7528 s
env0_first_0:                 episode reward: -1.5500,                 loss: 4.4128
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -4.9500,                 loss: nan
env3_second_0:                 episode reward: 4.9500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5837s / 33902.3366 s
env0_first_0:                 episode reward: -1.8500,                 loss: 1.7541
env0_second_0:                 episode reward: 1.8500,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0275s / 33989.3640 s
env0_first_0:                 episode reward: -11.3000,                 loss: 12.8121
env0_second_0:                 episode reward: 11.3000,                 loss: nan
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
env2_first_0:                 episode reward: -11.6000,                 loss: nan
env2_second_0:                 episode reward: 11.6000,                 loss: nan
env3_first_0:                 episode reward: -12.4000,                 loss: nan
env3_second_0:                 episode reward: 12.4000,                 loss: nan
env4_first_0:                 episode reward: -8.0000,                 loss: nan
env4_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2387s / 34076.6027 s
env0_first_0:                 episode reward: -30.3500,                 loss: 19.1397
env0_second_0:                 episode reward: 30.3500,                 loss: nan
env1_first_0:                 episode reward: -29.9000,                 loss: nan
env1_second_0:                 episode reward: 29.9000,                 loss: nan
env2_first_0:                 episode reward: -25.3500,                 loss: nan
env2_second_0:                 episode reward: 25.3500,                 loss: nan
env3_first_0:                 episode reward: -29.2000,                 loss: nan
env3_second_0:                 episode reward: 29.2000,                 loss: nan
env4_first_0:                 episode reward: -17.8500,                 loss: nan
env4_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3414s / 34162.9441 s
env0_first_0:                 episode reward: -32.3500,                 loss: 25.9114
env0_second_0:                 episode reward: 32.3500,                 loss: nan
env1_first_0:                 episode reward: -30.4500,                 loss: nan
env1_second_0:                 episode reward: 30.4500,                 loss: nan
env2_first_0:                 episode reward: -29.6500,                 loss: nan
env2_second_0:                 episode reward: 29.6500,                 loss: nan
env3_first_0:                 episode reward: -34.1000,                 loss: nan
env3_second_0:                 episode reward: 34.1000,                 loss: nan
env4_first_0:                 episode reward: -32.5000,                 loss: nan
env4_second_0:                 episode reward: 32.5000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7599s / 34249.7040 s
env0_first_0:                 episode reward: -38.9000,                 loss: 31.0067
env0_second_0:                 episode reward: 38.9000,                 loss: nan
env1_first_0:                 episode reward: -44.9500,                 loss: nan
env1_second_0:                 episode reward: 44.9500,                 loss: nan
env2_first_0:                 episode reward: -36.3500,                 loss: nan
env2_second_0:                 episode reward: 36.3500,                 loss: nan
env3_first_0:                 episode reward: -40.0000,                 loss: nan
env3_second_0:                 episode reward: 40.0000,                 loss: nan
env4_first_0:                 episode reward: -40.2000,                 loss: nan
env4_second_0:                 episode reward: 40.2000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.5607s / 34335.2648 s
env0_first_0:                 episode reward: -48.8500,                 loss: 39.2540
env0_second_0:                 episode reward: 48.8500,                 loss: nan
env1_first_0:                 episode reward: -48.0000,                 loss: nan
env1_second_0:                 episode reward: 48.0000,                 loss: nan
env2_first_0:                 episode reward: -48.8000,                 loss: nan
env2_second_0:                 episode reward: 48.8000,                 loss: nan
env3_first_0:                 episode reward: -46.1500,                 loss: nan
env3_second_0:                 episode reward: 46.1500,                 loss: nan
env4_first_0:                 episode reward: -39.0000,                 loss: nan
env4_second_0:                 episode reward: 39.0000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.1083s / 34421.3730 s
env0_first_0:                 episode reward: -45.2000,                 loss: 42.6346
env0_second_0:                 episode reward: 45.2000,                 loss: nan
env1_first_0:                 episode reward: -36.5500,                 loss: nan
env1_second_0:                 episode reward: 36.5500,                 loss: nan
env2_first_0:                 episode reward: -42.2500,                 loss: nan
env2_second_0:                 episode reward: 42.2500,                 loss: nan
env3_first_0:                 episode reward: -47.4500,                 loss: nan
env3_second_0:                 episode reward: 47.4500,                 loss: nan
env4_first_0:                 episode reward: -47.8500,                 loss: nan
env4_second_0:                 episode reward: 47.8500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 293.45,                last time consumption/overall running time: 83.6027s / 34504.9757 s
env0_first_0:                 episode reward: -45.9500,                 loss: 66.4369
env0_second_0:                 episode reward: 45.9500,                 loss: nan
env1_first_0:                 episode reward: -37.3500,                 loss: nan
env1_second_0:                 episode reward: 37.3500,                 loss: nan
env2_first_0:                 episode reward: -37.1500,                 loss: nan
env2_second_0:                 episode reward: 37.1500,                 loss: nan
env3_first_0:                 episode reward: -44.7500,                 loss: nan
env3_second_0:                 episode reward: 44.7500,                 loss: nan
env4_first_0:                 episode reward: -44.7500,                 loss: nan
env4_second_0:                 episode reward: 44.7500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 294.45,                last time consumption/overall running time: 85.8827s / 34590.8584 s
env0_first_0:                 episode reward: -38.5500,                 loss: 72.4136
env0_second_0:                 episode reward: 38.5500,                 loss: nan
env1_first_0:                 episode reward: -49.8000,                 loss: nan
env1_second_0:                 episode reward: 49.8000,                 loss: nan
env2_first_0:                 episode reward: -39.3500,                 loss: nan
env2_second_0:                 episode reward: 39.3500,                 loss: nan
env3_first_0:                 episode reward: -39.1500,                 loss: nan
env3_second_0:                 episode reward: 39.1500,                 loss: nan
env4_first_0:                 episode reward: -44.7500,                 loss: nan
env4_second_0:                 episode reward: 44.7500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 294.95,                last time consumption/overall running time: 83.9813s / 34674.8397 s
env0_first_0:                 episode reward: -46.0000,                 loss: 78.2745
env0_second_0:                 episode reward: 46.0000,                 loss: nan
env1_first_0:                 episode reward: -48.1500,                 loss: nan
env1_second_0:                 episode reward: 48.1500,                 loss: nan
env2_first_0:                 episode reward: -43.6500,                 loss: nan
env2_second_0:                 episode reward: 43.6500,                 loss: nan
env3_first_0:                 episode reward: -41.3000,                 loss: nan
env3_second_0:                 episode reward: 41.3000,                 loss: nan
env4_first_0:                 episode reward: -53.0000,                 loss: nan
env4_second_0:                 episode reward: 53.0000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2431s / 34762.0828 s
env0_first_0:                 episode reward: -40.0500,                 loss: 60.4096
env0_second_0:                 episode reward: 40.0500,                 loss: nan
env1_first_0:                 episode reward: -37.4500,                 loss: nan
env1_second_0:                 episode reward: 37.4500,                 loss: nan
env2_first_0:                 episode reward: -37.3000,                 loss: nan
env2_second_0:                 episode reward: 37.3000,                 loss: nan
env3_first_0:                 episode reward: -31.8000,                 loss: nan
env3_second_0:                 episode reward: 31.8000,                 loss: nan
env4_first_0:                 episode reward: -42.1000,                 loss: nan
env4_second_0:                 episode reward: 42.1000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 296.65,                last time consumption/overall running time: 85.9275s / 34848.0103 s
env0_first_0:                 episode reward: -48.7000,                 loss: 74.8835
env0_second_0:                 episode reward: 48.7000,                 loss: nan
env1_first_0:                 episode reward: -40.1500,                 loss: nan
env1_second_0:                 episode reward: 40.1500,                 loss: nan
env2_first_0:                 episode reward: -54.5000,                 loss: nan
env2_second_0:                 episode reward: 54.5000,                 loss: nan
env3_first_0:                 episode reward: -45.8500,                 loss: nan
env3_second_0:                 episode reward: 45.8500,                 loss: nan
env4_first_0:                 episode reward: -50.6000,                 loss: nan
env4_second_0:                 episode reward: 50.6000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 298.9,                last time consumption/overall running time: 86.5753s / 34934.5856 s
env0_first_0:                 episode reward: -51.7500,                 loss: 68.9713
env0_second_0:                 episode reward: 51.7500,                 loss: nan
env1_first_0:                 episode reward: -52.6500,                 loss: nan
env1_second_0:                 episode reward: 52.6500,                 loss: nan
env2_first_0:                 episode reward: -47.9500,                 loss: nan
env2_second_0:                 episode reward: 47.9500,                 loss: nan
env3_first_0:                 episode reward: -50.5500,                 loss: nan
env3_second_0:                 episode reward: 50.5500,                 loss: nan
env4_first_0:                 episode reward: -45.7000,                 loss: nan
env4_second_0:                 episode reward: 45.7000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 295.5,                last time consumption/overall running time: 86.0825s / 35020.6681 s
env0_first_0:                 episode reward: -47.7000,                 loss: 85.0206
env0_second_0:                 episode reward: 47.7000,                 loss: nan
env1_first_0:                 episode reward: -42.4500,                 loss: nan
env1_second_0:                 episode reward: 42.4500,                 loss: nan
env2_first_0:                 episode reward: -53.1500,                 loss: nan
env2_second_0:                 episode reward: 53.1500,                 loss: nan
env3_first_0:                 episode reward: -41.5000,                 loss: nan
env3_second_0:                 episode reward: 41.5000,                 loss: nan
env4_first_0:                 episode reward: -45.0500,                 loss: nan
env4_second_0:                 episode reward: 45.0500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 284.55,                last time consumption/overall running time: 84.5159s / 35105.1840 s
env0_first_0:                 episode reward: -51.5500,                 loss: 89.9823
env0_second_0:                 episode reward: 51.5500,                 loss: nan
env1_first_0:                 episode reward: -52.0000,                 loss: nan
env1_second_0:                 episode reward: 52.0000,                 loss: nan
env2_first_0:                 episode reward: -46.2500,                 loss: nan
env2_second_0:                 episode reward: 46.2500,                 loss: nan
env3_first_0:                 episode reward: -54.4500,                 loss: nan
env3_second_0:                 episode reward: 54.4500,                 loss: nan
env4_first_0:                 episode reward: -51.4000,                 loss: nan
env4_second_0:                 episode reward: 51.4000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 295.8,                last time consumption/overall running time: 85.9920s / 35191.1760 s
env0_first_0:                 episode reward: -55.1000,                 loss: 77.2593
env0_second_0:                 episode reward: 55.1000,                 loss: nan
env1_first_0:                 episode reward: -44.1000,                 loss: nan
env1_second_0:                 episode reward: 44.1000,                 loss: nan
env2_first_0:                 episode reward: -44.4000,                 loss: nan
env2_second_0:                 episode reward: 44.4000,                 loss: nan
env3_first_0:                 episode reward: -41.7000,                 loss: nan
env3_second_0:                 episode reward: 41.7000,                 loss: nan
env4_first_0:                 episode reward: -57.9000,                 loss: nan
env4_second_0:                 episode reward: 57.9000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 293.65,                last time consumption/overall running time: 85.3223s / 35276.4983 s
env0_first_0:                 episode reward: -37.6500,                 loss: 89.2989
env0_second_0:                 episode reward: 37.6500,                 loss: nan
env1_first_0:                 episode reward: -40.1500,                 loss: nan
env1_second_0:                 episode reward: 40.1500,                 loss: nan
env2_first_0:                 episode reward: -49.1000,                 loss: nan
env2_second_0:                 episode reward: 49.1000,                 loss: nan
env3_first_0:                 episode reward: -55.8500,                 loss: nan
env3_second_0:                 episode reward: 55.8500,                 loss: nan
env4_first_0:                 episode reward: -50.4000,                 loss: nan
env4_second_0:                 episode reward: 50.4000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 289.7,                last time consumption/overall running time: 83.7757s / 35360.2740 s
env0_first_0:                 episode reward: -61.5000,                 loss: 110.7994
env0_second_0:                 episode reward: 61.5000,                 loss: nan
env1_first_0:                 episode reward: -58.9000,                 loss: nan
env1_second_0:                 episode reward: 58.9000,                 loss: nan
env2_first_0:                 episode reward: -72.2500,                 loss: nan
env2_second_0:                 episode reward: 72.2500,                 loss: nan
env3_first_0:                 episode reward: -54.5000,                 loss: nan
env3_second_0:                 episode reward: 54.5000,                 loss: nan
env4_first_0:                 episode reward: -65.8000,                 loss: nan
env4_second_0:                 episode reward: 65.8000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 285.3,                last time consumption/overall running time: 83.8201s / 35444.0941 s
env0_first_0:                 episode reward: -53.5000,                 loss: 98.6326
env0_second_0:                 episode reward: 53.5000,                 loss: nan
env1_first_0:                 episode reward: -56.5000,                 loss: nan
env1_second_0:                 episode reward: 56.5000,                 loss: nan
env2_first_0:                 episode reward: -52.7000,                 loss: nan
env2_second_0:                 episode reward: 52.7000,                 loss: nan
env3_first_0:                 episode reward: -51.4500,                 loss: nan
env3_second_0:                 episode reward: 51.4500,                 loss: nan
env4_first_0:                 episode reward: -51.0500,                 loss: nan
env4_second_0:                 episode reward: 51.0500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 288.25,                last time consumption/overall running time: 84.3370s / 35528.4310 s
env0_first_0:                 episode reward: -36.0000,                 loss: 77.9967
env0_second_0:                 episode reward: 36.0000,                 loss: nan
env1_first_0:                 episode reward: -28.2500,                 loss: nan
env1_second_0:                 episode reward: 28.2500,                 loss: nan
env2_first_0:                 episode reward: -30.2000,                 loss: nan
env2_second_0:                 episode reward: 30.2000,                 loss: nan
env3_first_0:                 episode reward: -17.3000,                 loss: nan
env3_second_0:                 episode reward: 17.3000,                 loss: nan
env4_first_0:                 episode reward: -34.4500,                 loss: nan
env4_second_0:                 episode reward: 34.4500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1554s / 35615.5865 s
env0_first_0:                 episode reward: -9.4500,                 loss: 29.8090
env0_second_0:                 episode reward: 9.4500,                 loss: nan
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
env2_first_0:                 episode reward: -12.9000,                 loss: nan
env2_second_0:                 episode reward: 12.9000,                 loss: nan
env3_first_0:                 episode reward: -3.0000,                 loss: nan
env3_second_0:                 episode reward: 3.0000,                 loss: nan
env4_first_0:                 episode reward: -6.5000,                 loss: nan
env4_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 286.65,                last time consumption/overall running time: 83.1443s / 35698.7308 s
env0_first_0:                 episode reward: -16.1000,                 loss: 57.4188
env0_second_0:                 episode reward: 16.1000,                 loss: nan
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
env2_first_0:                 episode reward: -13.7000,                 loss: nan
env2_second_0:                 episode reward: 13.7000,                 loss: nan
env3_first_0:                 episode reward: -13.1000,                 loss: nan
env3_second_0:                 episode reward: 13.1000,                 loss: nan
env4_first_0:                 episode reward: -18.1500,                 loss: nan
env4_second_0:                 episode reward: 18.1500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 276.95,                last time consumption/overall running time: 81.9506s / 35780.6814 s
env0_first_0:                 episode reward: -60.7500,                 loss: 116.9394
env0_second_0:                 episode reward: 60.7500,                 loss: nan
env1_first_0:                 episode reward: -54.9500,                 loss: nan
env1_second_0:                 episode reward: 54.9500,                 loss: nan
env2_first_0:                 episode reward: -50.1500,                 loss: nan
env2_second_0:                 episode reward: 50.1500,                 loss: nan
env3_first_0:                 episode reward: -53.0500,                 loss: nan
env3_second_0:                 episode reward: 53.0500,                 loss: nan
env4_first_0:                 episode reward: -61.8000,                 loss: nan
env4_second_0:                 episode reward: 61.8000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 256.1,                last time consumption/overall running time: 77.2519s / 35857.9333 s
env0_first_0:                 episode reward: -67.0000,                 loss: 132.2650
env0_second_0:                 episode reward: 67.0000,                 loss: nan
env1_first_0:                 episode reward: -51.5000,                 loss: nan
env1_second_0:                 episode reward: 51.5000,                 loss: nan
env2_first_0:                 episode reward: -62.0000,                 loss: nan
env2_second_0:                 episode reward: 62.0000,                 loss: nan
env3_first_0:                 episode reward: -61.3000,                 loss: nan
env3_second_0:                 episode reward: 61.3000,                 loss: nan
env4_first_0:                 episode reward: -71.7500,                 loss: nan
env4_second_0:                 episode reward: 71.7500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 273.15,                last time consumption/overall running time: 79.4489s / 35937.3822 s
env0_first_0:                 episode reward: -43.6500,                 loss: 78.9026
env0_second_0:                 episode reward: 43.6500,                 loss: nan
env1_first_0:                 episode reward: -34.5500,                 loss: nan
env1_second_0:                 episode reward: 34.5500,                 loss: nan
env2_first_0:                 episode reward: -50.4000,                 loss: nan
env2_second_0:                 episode reward: 50.4000,                 loss: nan
env3_first_0:                 episode reward: -35.3500,                 loss: nan
env3_second_0:                 episode reward: 35.3500,                 loss: nan
env4_first_0:                 episode reward: -44.1000,                 loss: nan
env4_second_0:                 episode reward: 44.1000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.1716s / 36024.5537 s
env0_first_0:                 episode reward: -5.1500,                 loss: 11.9311
env0_second_0:                 episode reward: 5.1500,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -5.3500,                 loss: nan
env2_second_0:                 episode reward: 5.3500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -5.7000,                 loss: nan
env4_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 277.5,                last time consumption/overall running time: 81.2099s / 36105.7636 s
env0_first_0:                 episode reward: -34.7000,                 loss: 110.1187
env0_second_0:                 episode reward: 34.7000,                 loss: nan
env1_first_0:                 episode reward: -33.6500,                 loss: nan
env1_second_0:                 episode reward: 33.6500,                 loss: nan
env2_first_0:                 episode reward: -37.9500,                 loss: nan
env2_second_0:                 episode reward: 37.9500,                 loss: nan
env3_first_0:                 episode reward: -32.9000,                 loss: nan
env3_second_0:                 episode reward: 32.9000,                 loss: nan
env4_first_0:                 episode reward: -36.3000,                 loss: nan
env4_second_0:                 episode reward: 36.3000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 251.05,                last time consumption/overall running time: 75.6557s / 36181.4194 s
env0_first_0:                 episode reward: -71.9500,                 loss: 131.7498
env0_second_0:                 episode reward: 71.9500,                 loss: nan
env1_first_0:                 episode reward: -72.5000,                 loss: nan
env1_second_0:                 episode reward: 72.5000,                 loss: nan
env2_first_0:                 episode reward: -70.4500,                 loss: nan
env2_second_0:                 episode reward: 70.4500,                 loss: nan
env3_first_0:                 episode reward: -71.5000,                 loss: nan
env3_second_0:                 episode reward: 71.5000,                 loss: nan
env4_first_0:                 episode reward: -76.8000,                 loss: nan
env4_second_0:                 episode reward: 76.8000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 275.15,                last time consumption/overall running time: 81.3470s / 36262.7663 s
env0_first_0:                 episode reward: -49.3500,                 loss: 134.5609
env0_second_0:                 episode reward: 49.3500,                 loss: nan
env1_first_0:                 episode reward: -52.3500,                 loss: nan
env1_second_0:                 episode reward: 52.3500,                 loss: nan
env2_first_0:                 episode reward: -51.0000,                 loss: nan
env2_second_0:                 episode reward: 51.0000,                 loss: nan
env3_first_0:                 episode reward: -54.4500,                 loss: nan
env3_second_0:                 episode reward: 54.4500,                 loss: nan
env4_first_0:                 episode reward: -38.0000,                 loss: nan
env4_second_0:                 episode reward: 38.0000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 265.95,                last time consumption/overall running time: 80.0404s / 36342.8067 s
env0_first_0:                 episode reward: -42.0500,                 loss: 130.8641
env0_second_0:                 episode reward: 42.0500,                 loss: nan
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
env2_first_0:                 episode reward: -43.8000,                 loss: nan
env2_second_0:                 episode reward: 43.8000,                 loss: nan
env3_first_0:                 episode reward: -34.3000,                 loss: nan
env3_second_0:                 episode reward: 34.3000,                 loss: nan
env4_first_0:                 episode reward: -48.9500,                 loss: nan
env4_second_0:                 episode reward: 48.9500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.0928s / 36430.8995 s
env0_first_0:                 episode reward: 0.4500,                 loss: 2.6873
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -3.1000,                 loss: nan
env4_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5533s / 36518.4528 s
env0_first_0:                 episode reward: -3.6500,                 loss: 2.4834
env0_second_0:                 episode reward: 3.6500,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
env2_first_0:                 episode reward: -3.6500,                 loss: nan
env2_second_0:                 episode reward: 3.6500,                 loss: nan
env3_first_0:                 episode reward: -2.1000,                 loss: nan
env3_second_0:                 episode reward: 2.1000,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3570s / 36605.8098 s
env0_first_0:                 episode reward: -6.0000,                 loss: 6.5780
env0_second_0:                 episode reward: 6.0000,                 loss: nan
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
env2_first_0:                 episode reward: -5.9000,                 loss: nan
env2_second_0:                 episode reward: 5.9000,                 loss: nan
env3_first_0:                 episode reward: -5.5500,                 loss: nan
env3_second_0:                 episode reward: 5.5500,                 loss: nan
env4_first_0:                 episode reward: -5.1500,                 loss: nan
env4_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5823s / 36693.3921 s
env0_first_0:                 episode reward: -8.7000,                 loss: 27.7631
env0_second_0:                 episode reward: 8.7000,                 loss: nan
env1_first_0:                 episode reward: -26.1000,                 loss: nan
env1_second_0:                 episode reward: 26.1000,                 loss: nan
env2_first_0:                 episode reward: -29.1000,                 loss: nan
env2_second_0:                 episode reward: 29.1000,                 loss: nan
env3_first_0:                 episode reward: -21.6000,                 loss: nan
env3_second_0:                 episode reward: 21.6000,                 loss: nan
env4_first_0:                 episode reward: -17.1500,                 loss: nan
env4_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3793s / 36779.7714 s
env0_first_0:                 episode reward: -29.7500,                 loss: 38.1383
env0_second_0:                 episode reward: 29.7500,                 loss: nan
env1_first_0:                 episode reward: -30.8000,                 loss: nan
env1_second_0:                 episode reward: 30.8000,                 loss: nan
env2_first_0:                 episode reward: -28.7000,                 loss: nan
env2_second_0:                 episode reward: 28.7000,                 loss: nan
env3_first_0:                 episode reward: -30.0500,                 loss: nan
env3_second_0:                 episode reward: 30.0500,                 loss: nan
env4_first_0:                 episode reward: -30.8500,                 loss: nan
env4_second_0:                 episode reward: 30.8500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 293.9,                last time consumption/overall running time: 85.9988s / 36865.7702 s
env0_first_0:                 episode reward: -38.6500,                 loss: 48.0803
env0_second_0:                 episode reward: 38.6500,                 loss: nan
env1_first_0:                 episode reward: -33.9500,                 loss: nan
env1_second_0:                 episode reward: 33.9500,                 loss: nan
env2_first_0:                 episode reward: -41.9500,                 loss: nan
env2_second_0:                 episode reward: 41.9500,                 loss: nan
env3_first_0:                 episode reward: -33.3500,                 loss: nan
env3_second_0:                 episode reward: 33.3500,                 loss: nan
env4_first_0:                 episode reward: -41.3500,                 loss: nan
env4_second_0:                 episode reward: 41.3500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 282.7,                last time consumption/overall running time: 82.3368s / 36948.1070 s
env0_first_0:                 episode reward: -63.4000,                 loss: 62.6089
env0_second_0:                 episode reward: 63.4000,                 loss: nan
env1_first_0:                 episode reward: -55.5500,                 loss: nan
env1_second_0:                 episode reward: 55.5500,                 loss: nan
env2_first_0:                 episode reward: -48.9500,                 loss: nan
env2_second_0:                 episode reward: 48.9500,                 loss: nan
env3_first_0:                 episode reward: -51.6500,                 loss: nan
env3_second_0:                 episode reward: 51.6500,                 loss: nan
env4_first_0:                 episode reward: -62.1500,                 loss: nan
env4_second_0:                 episode reward: 62.1500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 297.2,                last time consumption/overall running time: 86.1129s / 37034.2200 s
env0_first_0:                 episode reward: -34.4500,                 loss: 35.4889
env0_second_0:                 episode reward: 34.4500,                 loss: nan
env1_first_0:                 episode reward: -35.1500,                 loss: nan
env1_second_0:                 episode reward: 35.1500,                 loss: nan
env2_first_0:                 episode reward: -37.0500,                 loss: nan
env2_second_0:                 episode reward: 37.0500,                 loss: nan
env3_first_0:                 episode reward: -36.2500,                 loss: nan
env3_second_0:                 episode reward: 36.2500,                 loss: nan
env4_first_0:                 episode reward: -28.7000,                 loss: nan
env4_second_0:                 episode reward: 28.7000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 297.9,                last time consumption/overall running time: 85.0344s / 37119.2544 s
env0_first_0:                 episode reward: -34.0000,                 loss: 37.8275
env0_second_0:                 episode reward: 34.0000,                 loss: nan
env1_first_0:                 episode reward: -43.9500,                 loss: nan
env1_second_0:                 episode reward: 43.9500,                 loss: nan
env2_first_0:                 episode reward: -36.5000,                 loss: nan
env2_second_0:                 episode reward: 36.5000,                 loss: nan
env3_first_0:                 episode reward: -44.3500,                 loss: nan
env3_second_0:                 episode reward: 44.3500,                 loss: nan
env4_first_0:                 episode reward: -45.4000,                 loss: nan
env4_second_0:                 episode reward: 45.4000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 295.3,                last time consumption/overall running time: 85.7977s / 37205.0521 s
env0_first_0:                 episode reward: -40.4500,                 loss: 40.9655
env0_second_0:                 episode reward: 40.4500,                 loss: nan
env1_first_0:                 episode reward: -36.6500,                 loss: nan
env1_second_0:                 episode reward: 36.6500,                 loss: nan
env2_first_0:                 episode reward: -38.5000,                 loss: nan
env2_second_0:                 episode reward: 38.5000,                 loss: nan
env3_first_0:                 episode reward: -42.8000,                 loss: nan
env3_second_0:                 episode reward: 42.8000,                 loss: nan
env4_first_0:                 episode reward: -40.3500,                 loss: nan
env4_second_0:                 episode reward: 40.3500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3384s / 37291.3905 s
env0_first_0:                 episode reward: -15.5500,                 loss: 17.5512
env0_second_0:                 episode reward: 15.5500,                 loss: nan
env1_first_0:                 episode reward: -21.3500,                 loss: nan
env1_second_0:                 episode reward: 21.3500,                 loss: nan
env2_first_0:                 episode reward: -14.0000,                 loss: nan
env2_second_0:                 episode reward: 14.0000,                 loss: nan
env3_first_0:                 episode reward: -14.4000,                 loss: nan
env3_second_0:                 episode reward: 14.4000,                 loss: nan
env4_first_0:                 episode reward: -16.9000,                 loss: nan
env4_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 289.5,                last time consumption/overall running time: 85.3220s / 37376.7125 s
env0_first_0:                 episode reward: -48.2000,                 loss: 57.5871
env0_second_0:                 episode reward: 48.2000,                 loss: nan
env1_first_0:                 episode reward: -52.4500,                 loss: nan
env1_second_0:                 episode reward: 52.4500,                 loss: nan
env2_first_0:                 episode reward: -50.1000,                 loss: nan
env2_second_0:                 episode reward: 50.1000,                 loss: nan
env3_first_0:                 episode reward: -53.1000,                 loss: nan
env3_second_0:                 episode reward: 53.1000,                 loss: nan
env4_first_0:                 episode reward: -48.7000,                 loss: nan
env4_second_0:                 episode reward: 48.7000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8432s / 37464.5557 s
env0_first_0:                 episode reward: -5.1500,                 loss: 7.5008
env0_second_0:                 episode reward: 5.1500,                 loss: nan
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
env2_first_0:                 episode reward: -4.2500,                 loss: nan
env2_second_0:                 episode reward: 4.2500,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -3.1500,                 loss: nan
env4_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.3602s / 37552.9158 s
env0_first_0:                 episode reward: -2.9500,                 loss: 2.5880
env0_second_0:                 episode reward: 2.9500,                 loss: nan
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
env3_first_0:                 episode reward: -1.0500,                 loss: nan
env3_second_0:                 episode reward: 1.0500,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9588s / 37639.8747 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1815
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3191s / 37727.1938 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1245
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.5236s / 37814.7174 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2083
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5874s / 37901.3048 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2369
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.9653s / 37989.2701 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2453
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7113s / 38076.9815 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2270
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.9783s / 38163.9598 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3025
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3633s / 38251.3231 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4412
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.7382s / 38340.0613 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4332
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.6163s / 38426.6775 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.3575
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.8949s / 38514.5724 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.5182
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0445s / 38601.6169 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.7366
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3101s / 38688.9270 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4046
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.6100s / 38777.5370 s
env0_first_0:                 episode reward: -3.6500,                 loss: 2.3594
env0_second_0:                 episode reward: 3.6500,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -5.0500,                 loss: nan
env3_second_0:                 episode reward: 5.0500,                 loss: nan
env4_first_0:                 episode reward: -1.8500,                 loss: nan
env4_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0625s / 38864.5995 s
env0_first_0:                 episode reward: -6.2500,                 loss: 4.0489
env0_second_0:                 episode reward: 6.2500,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -5.0500,                 loss: nan
env4_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.5364s / 38951.1359 s
env0_first_0:                 episode reward: -4.7500,                 loss: 8.2018
env0_second_0:                 episode reward: 4.7500,                 loss: nan
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
env2_first_0:                 episode reward: -7.2000,                 loss: nan
env2_second_0:                 episode reward: 7.2000,                 loss: nan
env3_first_0:                 episode reward: -5.6000,                 loss: nan
env3_second_0:                 episode reward: 5.6000,                 loss: nan
env4_first_0:                 episode reward: -4.5500,                 loss: nan
env4_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.3249s / 39039.4608 s
env0_first_0:                 episode reward: -11.9000,                 loss: 10.9943
env0_second_0:                 episode reward: 11.9000,                 loss: nan
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
env2_first_0:                 episode reward: -7.5500,                 loss: nan
env2_second_0:                 episode reward: 7.5500,                 loss: nan
env3_first_0:                 episode reward: -9.8500,                 loss: nan
env3_second_0:                 episode reward: 9.8500,                 loss: nan
env4_first_0:                 episode reward: -7.3500,                 loss: nan
env4_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0507s / 39125.5116 s
env0_first_0:                 episode reward: -26.3500,                 loss: 26.7410
env0_second_0:                 episode reward: 26.3500,                 loss: nan
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
env2_first_0:                 episode reward: -17.2000,                 loss: nan
env2_second_0:                 episode reward: 17.2000,                 loss: nan
env3_first_0:                 episode reward: -21.7000,                 loss: nan
env3_second_0:                 episode reward: 21.7000,                 loss: nan
env4_first_0:                 episode reward: -21.0000,                 loss: nan
env4_second_0:                 episode reward: 21.0000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 298.55,                last time consumption/overall running time: 85.5255s / 39211.0370 s
env0_first_0:                 episode reward: -18.1000,                 loss: 35.2812
env0_second_0:                 episode reward: 18.1000,                 loss: nan
env1_first_0:                 episode reward: -23.3000,                 loss: nan
env1_second_0:                 episode reward: 23.3000,                 loss: nan
env2_first_0:                 episode reward: -28.9500,                 loss: nan
env2_second_0:                 episode reward: 28.9500,                 loss: nan
env3_first_0:                 episode reward: -20.2000,                 loss: nan
env3_second_0:                 episode reward: 20.2000,                 loss: nan
env4_first_0:                 episode reward: -17.1500,                 loss: nan
env4_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.7098s / 39298.7468 s
env0_first_0:                 episode reward: -15.7000,                 loss: 21.1600
env0_second_0:                 episode reward: 15.7000,                 loss: nan
env1_first_0:                 episode reward: -22.1000,                 loss: nan
env1_second_0:                 episode reward: 22.1000,                 loss: nan
env2_first_0:                 episode reward: -14.4000,                 loss: nan
env2_second_0:                 episode reward: 14.4000,                 loss: nan
env3_first_0:                 episode reward: -18.0000,                 loss: nan
env3_second_0:                 episode reward: 18.0000,                 loss: nan
env4_first_0:                 episode reward: -17.1500,                 loss: nan
env4_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 84.6880s / 39383.4348 s
env0_first_0:                 episode reward: -18.2500,                 loss: 28.4349
env0_second_0:                 episode reward: 18.2500,                 loss: nan
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
env2_first_0:                 episode reward: -20.6000,                 loss: nan
env2_second_0:                 episode reward: 20.6000,                 loss: nan
env3_first_0:                 episode reward: -22.3500,                 loss: nan
env3_second_0:                 episode reward: 22.3500,                 loss: nan
env4_first_0:                 episode reward: -21.3500,                 loss: nan
env4_second_0:                 episode reward: 21.3500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 298.65,                last time consumption/overall running time: 84.9693s / 39468.4041 s
env0_first_0:                 episode reward: -8.2000,                 loss: 16.9995
env0_second_0:                 episode reward: 8.2000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -15.7000,                 loss: nan
env2_second_0:                 episode reward: 15.7000,                 loss: nan
env3_first_0:                 episode reward: -9.5000,                 loss: nan
env3_second_0:                 episode reward: 9.5000,                 loss: nan
env4_first_0:                 episode reward: -5.4500,                 loss: nan
env4_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 88.4156s / 39556.8198 s
env0_first_0:                 episode reward: -7.5500,                 loss: 19.8906
env0_second_0:                 episode reward: 7.5500,                 loss: nan
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
env2_first_0:                 episode reward: -13.7500,                 loss: nan
env2_second_0:                 episode reward: 13.7500,                 loss: nan
env3_first_0:                 episode reward: -5.3000,                 loss: nan
env3_second_0:                 episode reward: 5.3000,                 loss: nan
env4_first_0:                 episode reward: -5.5500,                 loss: nan
env4_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0377s / 39643.8575 s
env0_first_0:                 episode reward: -3.4000,                 loss: 15.8845
env0_second_0:                 episode reward: 3.4000,                 loss: nan
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
env2_first_0:                 episode reward: -9.3500,                 loss: nan
env2_second_0:                 episode reward: 9.3500,                 loss: nan
env3_first_0:                 episode reward: -6.2500,                 loss: nan
env3_second_0:                 episode reward: 6.2500,                 loss: nan
env4_first_0:                 episode reward: -5.0000,                 loss: nan
env4_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 89.2480s / 39733.1055 s
env0_first_0:                 episode reward: -8.7500,                 loss: 14.3214
env0_second_0:                 episode reward: 8.7500,                 loss: nan
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
env2_first_0:                 episode reward: -6.8500,                 loss: nan
env2_second_0:                 episode reward: 6.8500,                 loss: nan
env3_first_0:                 episode reward: -10.1000,                 loss: nan
env3_second_0:                 episode reward: 10.1000,                 loss: nan
env4_first_0:                 episode reward: -7.5500,                 loss: nan
env4_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3413s / 39819.4467 s
env0_first_0:                 episode reward: -52.1000,                 loss: 43.0709
env0_second_0:                 episode reward: 52.1000,                 loss: nan
env1_first_0:                 episode reward: -49.0500,                 loss: nan
env1_second_0:                 episode reward: 49.0500,                 loss: nan
env2_first_0:                 episode reward: -55.3000,                 loss: nan
env2_second_0:                 episode reward: 55.3000,                 loss: nan
env3_first_0:                 episode reward: -54.6000,                 loss: nan
env3_second_0:                 episode reward: 54.6000,                 loss: nan
env4_first_0:                 episode reward: -53.8000,                 loss: nan
env4_second_0:                 episode reward: 53.8000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 297.85,                last time consumption/overall running time: 86.5048s / 39905.9515 s
env0_first_0:                 episode reward: -67.8500,                 loss: 50.6388
env0_second_0:                 episode reward: 67.8500,                 loss: nan
env1_first_0:                 episode reward: -66.2000,                 loss: nan
env1_second_0:                 episode reward: 66.2000,                 loss: nan
env2_first_0:                 episode reward: -62.2500,                 loss: nan
env2_second_0:                 episode reward: 62.2500,                 loss: nan
env3_first_0:                 episode reward: -67.8000,                 loss: nan
env3_second_0:                 episode reward: 67.8000,                 loss: nan
env4_first_0:                 episode reward: -65.0000,                 loss: nan
env4_second_0:                 episode reward: 65.0000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 292.9,                last time consumption/overall running time: 83.6561s / 39989.6076 s
env0_first_0:                 episode reward: -68.0500,                 loss: 65.1625
env0_second_0:                 episode reward: 68.0500,                 loss: nan
env1_first_0:                 episode reward: -71.0500,                 loss: nan
env1_second_0:                 episode reward: 71.0500,                 loss: nan
env2_first_0:                 episode reward: -69.0500,                 loss: nan
env2_second_0:                 episode reward: 69.0500,                 loss: nan
env3_first_0:                 episode reward: -63.7500,                 loss: nan
env3_second_0:                 episode reward: 63.7500,                 loss: nan
env4_first_0:                 episode reward: -73.8000,                 loss: nan
env4_second_0:                 episode reward: 73.8000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 297.85,                last time consumption/overall running time: 86.5011s / 40076.1088 s
env0_first_0:                 episode reward: -65.4000,                 loss: 57.2074
env0_second_0:                 episode reward: 65.4000,                 loss: nan
env1_first_0:                 episode reward: -54.4000,                 loss: nan
env1_second_0:                 episode reward: 54.4000,                 loss: nan
env2_first_0:                 episode reward: -68.0000,                 loss: nan
env2_second_0:                 episode reward: 68.0000,                 loss: nan
env3_first_0:                 episode reward: -68.3500,                 loss: nan
env3_second_0:                 episode reward: 68.3500,                 loss: nan
env4_first_0:                 episode reward: -62.7500,                 loss: nan
env4_second_0:                 episode reward: 62.7500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 292.4,                last time consumption/overall running time: 85.2682s / 40161.3770 s
env0_first_0:                 episode reward: -55.9500,                 loss: 77.0029
env0_second_0:                 episode reward: 55.9500,                 loss: nan
env1_first_0:                 episode reward: -49.8000,                 loss: nan
env1_second_0:                 episode reward: 49.8000,                 loss: nan
env2_first_0:                 episode reward: -59.4000,                 loss: nan
env2_second_0:                 episode reward: 59.4000,                 loss: nan
env3_first_0:                 episode reward: -56.2500,                 loss: nan
env3_second_0:                 episode reward: 56.2500,                 loss: nan
env4_first_0:                 episode reward: -62.6000,                 loss: nan
env4_second_0:                 episode reward: 62.6000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 294.55,                last time consumption/overall running time: 85.5794s / 40246.9564 s
env0_first_0:                 episode reward: -58.6500,                 loss: 69.8944
env0_second_0:                 episode reward: 58.6500,                 loss: nan
env1_first_0:                 episode reward: -63.7000,                 loss: nan
env1_second_0:                 episode reward: 63.7000,                 loss: nan
env2_first_0:                 episode reward: -65.8500,                 loss: nan
env2_second_0:                 episode reward: 65.8500,                 loss: nan
env3_first_0:                 episode reward: -57.1000,                 loss: nan
env3_second_0:                 episode reward: 57.1000,                 loss: nan
env4_first_0:                 episode reward: -50.6500,                 loss: nan
env4_second_0:                 episode reward: 50.6500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 294.35,                last time consumption/overall running time: 85.2970s / 40332.2534 s
env0_first_0:                 episode reward: -41.8500,                 loss: 71.9486
env0_second_0:                 episode reward: 41.8500,                 loss: nan
env1_first_0:                 episode reward: -52.7000,                 loss: nan
env1_second_0:                 episode reward: 52.7000,                 loss: nan
env2_first_0:                 episode reward: -48.5000,                 loss: nan
env2_second_0:                 episode reward: 48.5000,                 loss: nan
env3_first_0:                 episode reward: -58.1000,                 loss: nan
env3_second_0:                 episode reward: 58.1000,                 loss: nan
env4_first_0:                 episode reward: -57.4000,                 loss: nan
env4_second_0:                 episode reward: 57.4000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 298.15,                last time consumption/overall running time: 85.4413s / 40417.6947 s
env0_first_0:                 episode reward: -50.3000,                 loss: 50.9571
env0_second_0:                 episode reward: 50.3000,                 loss: nan
env1_first_0:                 episode reward: -44.4500,                 loss: nan
env1_second_0:                 episode reward: 44.4500,                 loss: nan
env2_first_0:                 episode reward: -48.3500,                 loss: nan
env2_second_0:                 episode reward: 48.3500,                 loss: nan
env3_first_0:                 episode reward: -41.7000,                 loss: nan
env3_second_0:                 episode reward: 41.7000,                 loss: nan
env4_first_0:                 episode reward: -44.8500,                 loss: nan
env4_second_0:                 episode reward: 44.8500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 290.25,                last time consumption/overall running time: 85.4625s / 40503.1571 s
env0_first_0:                 episode reward: -59.9000,                 loss: 69.1256
env0_second_0:                 episode reward: 59.9000,                 loss: nan
env1_first_0:                 episode reward: -56.2000,                 loss: nan
env1_second_0:                 episode reward: 56.2000,                 loss: nan
env2_first_0:                 episode reward: -55.3000,                 loss: nan
env2_second_0:                 episode reward: 55.3000,                 loss: nan
env3_first_0:                 episode reward: -69.0500,                 loss: nan
env3_second_0:                 episode reward: 69.0500,                 loss: nan
env4_first_0:                 episode reward: -60.8000,                 loss: nan
env4_second_0:                 episode reward: 60.8000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 291.4,                last time consumption/overall running time: 84.5900s / 40587.7471 s
env0_first_0:                 episode reward: -34.2000,                 loss: 69.5770
env0_second_0:                 episode reward: 34.2000,                 loss: nan
env1_first_0:                 episode reward: -27.5000,                 loss: nan
env1_second_0:                 episode reward: 27.5000,                 loss: nan
env2_first_0:                 episode reward: -33.6000,                 loss: nan
env2_second_0:                 episode reward: 33.6000,                 loss: nan
env3_first_0:                 episode reward: -35.0500,                 loss: nan
env3_second_0:                 episode reward: 35.0500,                 loss: nan
env4_first_0:                 episode reward: -42.7500,                 loss: nan
env4_second_0:                 episode reward: 42.7500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4334s / 40674.1805 s
env0_first_0:                 episode reward: -3.2500,                 loss: 5.5076
env0_second_0:                 episode reward: 3.2500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -3.5000,                 loss: nan
env4_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.9750s / 40760.1555 s
env0_first_0:                 episode reward: -2.1500,                 loss: 2.1227
env0_second_0:                 episode reward: 2.1500,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.4074s / 40846.5629 s
env0_first_0:                 episode reward: -0.6500,                 loss: 3.2607
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -5.4000,                 loss: nan
env3_second_0:                 episode reward: 5.4000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.8025s / 40932.3654 s
env0_first_0:                 episode reward: -4.2000,                 loss: 6.7169
env0_second_0:                 episode reward: 4.2000,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -2.5000,                 loss: nan
env3_second_0:                 episode reward: 2.5000,                 loss: nan
env4_first_0:                 episode reward: -4.2500,                 loss: nan
env4_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7600s / 41019.1254 s
env0_first_0:                 episode reward: -8.5500,                 loss: 12.4726
env0_second_0:                 episode reward: 8.5500,                 loss: nan
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
env2_first_0:                 episode reward: -7.2000,                 loss: nan
env2_second_0:                 episode reward: 7.2000,                 loss: nan
env3_first_0:                 episode reward: -7.8000,                 loss: nan
env3_second_0:                 episode reward: 7.8000,                 loss: nan
env4_first_0:                 episode reward: -5.7000,                 loss: nan
env4_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.0087s / 41106.1341 s
env0_first_0:                 episode reward: -4.9500,                 loss: 9.1036
env0_second_0:                 episode reward: 4.9500,                 loss: nan
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
env2_first_0:                 episode reward: -6.2500,                 loss: nan
env2_second_0:                 episode reward: 6.2500,                 loss: nan
env3_first_0:                 episode reward: -3.9000,                 loss: nan
env3_second_0:                 episode reward: 3.9000,                 loss: nan
env4_first_0:                 episode reward: -7.9500,                 loss: nan
env4_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.3073s / 41193.4414 s
env0_first_0:                 episode reward: -4.0000,                 loss: 3.5479
env0_second_0:                 episode reward: 4.0000,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.7000s / 41280.1415 s
env0_first_0:                 episode reward: -0.2000,                 loss: 4.5862
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
env3_first_0:                 episode reward: -1.9500,                 loss: nan
env3_second_0:                 episode reward: 1.9500,                 loss: nan
env4_first_0:                 episode reward: -3.4000,                 loss: nan
env4_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.0337s / 41365.1752 s
env0_first_0:                 episode reward: -1.1500,                 loss: 2.4552
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3269s / 41451.5021 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0097
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.6125s / 41539.1146 s
env0_first_0:                 episode reward: -2.4500,                 loss: 3.2564
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -4.6500,                 loss: nan
env3_second_0:                 episode reward: 4.6500,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.3805s / 41625.4952 s
env0_first_0:                 episode reward: -6.8500,                 loss: 6.8837
env0_second_0:                 episode reward: 6.8500,                 loss: nan
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
env2_first_0:                 episode reward: -7.1500,                 loss: nan
env2_second_0:                 episode reward: 7.1500,                 loss: nan
env3_first_0:                 episode reward: -6.8000,                 loss: nan
env3_second_0:                 episode reward: 6.8000,                 loss: nan
env4_first_0:                 episode reward: -6.1500,                 loss: nan
env4_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 86.0949s / 41711.5901 s
env0_first_0:                 episode reward: -8.1000,                 loss: 7.9099
env0_second_0:                 episode reward: 8.1000,                 loss: nan
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
env2_first_0:                 episode reward: -8.1500,                 loss: nan
env2_second_0:                 episode reward: 8.1500,                 loss: nan
env3_first_0:                 episode reward: -8.3000,                 loss: nan
env3_second_0:                 episode reward: 8.3000,                 loss: nan
env4_first_0:                 episode reward: -11.0000,                 loss: nan
env4_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.1876s / 41796.7777 s
env0_first_0:                 episode reward: -30.8500,                 loss: 19.1036
env0_second_0:                 episode reward: 30.8500,                 loss: nan
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
env2_first_0:                 episode reward: -29.3500,                 loss: nan
env2_second_0:                 episode reward: 29.3500,                 loss: nan
env3_first_0:                 episode reward: -24.1500,                 loss: nan
env3_second_0:                 episode reward: 24.1500,                 loss: nan
env4_first_0:                 episode reward: -27.3000,                 loss: nan
env4_second_0:                 episode reward: 27.3000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 85.1526s / 41881.9304 s
env0_first_0:                 episode reward: -20.2500,                 loss: 19.3747
env0_second_0:                 episode reward: 20.2500,                 loss: nan
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
env2_first_0:                 episode reward: -23.8500,                 loss: nan
env2_second_0:                 episode reward: 23.8500,                 loss: nan
env3_first_0:                 episode reward: -21.8000,                 loss: nan
env3_second_0:                 episode reward: 21.8000,                 loss: nan
env4_first_0:                 episode reward: -20.6500,                 loss: nan
env4_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 87.2564s / 41969.1868 s
env0_first_0:                 episode reward: -9.4000,                 loss: 24.8056
env0_second_0:                 episode reward: 9.4000,                 loss: nan
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
env2_first_0:                 episode reward: -15.0500,                 loss: nan
env2_second_0:                 episode reward: 15.0500,                 loss: nan
env3_first_0:                 episode reward: -10.7500,                 loss: nan
env3_second_0:                 episode reward: 10.7500,                 loss: nan
env4_first_0:                 episode reward: -16.1500,                 loss: nan
env4_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 83.9657s / 42053.1524 s
env0_first_0:                 episode reward: -15.6000,                 loss: 43.7153
env0_second_0:                 episode reward: 15.6000,                 loss: nan
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
env2_first_0:                 episode reward: -17.3500,                 loss: nan
env2_second_0:                 episode reward: 17.3500,                 loss: nan
env3_first_0:                 episode reward: -16.3500,                 loss: nan
env3_second_0:                 episode reward: 16.3500,                 loss: nan
env4_first_0:                 episode reward: -11.7500,                 loss: nan
env4_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 84.0335s / 42137.1859 s
env0_first_0:                 episode reward: -2.5000,                 loss: 38.1250
env0_second_0:                 episode reward: 2.5000,                 loss: nan
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
env3_first_0:                 episode reward: -4.7000,                 loss: nan
env3_second_0:                 episode reward: 4.7000,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 84.2150s / 42221.4010 s
env0_first_0:                 episode reward: -31.4500,                 loss: 64.3194
env0_second_0:                 episode reward: 31.4500,                 loss: nan
env1_first_0:                 episode reward: -30.8500,                 loss: nan
env1_second_0:                 episode reward: 30.8500,                 loss: nan
env2_first_0:                 episode reward: -23.8500,                 loss: nan
env2_second_0:                 episode reward: 23.8500,                 loss: nan
env3_first_0:                 episode reward: -29.7000,                 loss: nan
env3_second_0:                 episode reward: 29.7000,                 loss: nan
env4_first_0:                 episode reward: -36.7000,                 loss: nan
env4_second_0:                 episode reward: 36.7000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 290.25,                last time consumption/overall running time: 81.4985s / 42302.8994 s
env0_first_0:                 episode reward: -63.6000,                 loss: 63.8016
env0_second_0:                 episode reward: 63.6000,                 loss: nan
env1_first_0:                 episode reward: -64.0000,                 loss: nan
env1_second_0:                 episode reward: 64.0000,                 loss: nan
env2_first_0:                 episode reward: -63.7000,                 loss: nan
env2_second_0:                 episode reward: 63.7000,                 loss: nan
env3_first_0:                 episode reward: -64.4500,                 loss: nan
env3_second_0:                 episode reward: 64.4500,                 loss: nan
env4_first_0:                 episode reward: -51.8500,                 loss: nan
env4_second_0:                 episode reward: 51.8500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 284.7,                last time consumption/overall running time: 81.2701s / 42384.1695 s
env0_first_0:                 episode reward: -58.7500,                 loss: 54.5194
env0_second_0:                 episode reward: 58.7500,                 loss: nan
env1_first_0:                 episode reward: -59.7500,                 loss: nan
env1_second_0:                 episode reward: 59.7500,                 loss: nan
env2_first_0:                 episode reward: -62.1500,                 loss: nan
env2_second_0:                 episode reward: 62.1500,                 loss: nan
env3_first_0:                 episode reward: -65.3000,                 loss: nan
env3_second_0:                 episode reward: 65.3000,                 loss: nan
env4_first_0:                 episode reward: -60.6000,                 loss: nan
env4_second_0:                 episode reward: 60.6000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 84.7908s / 42468.9603 s
env0_first_0:                 episode reward: -70.9500,                 loss: 10.6099
env0_second_0:                 episode reward: 70.9500,                 loss: nan
env1_first_0:                 episode reward: -69.2000,                 loss: nan
env1_second_0:                 episode reward: 69.2000,                 loss: nan
env2_first_0:                 episode reward: -74.4500,                 loss: nan
env2_second_0:                 episode reward: 74.4500,                 loss: nan
env3_first_0:                 episode reward: -73.6500,                 loss: nan
env3_second_0:                 episode reward: 73.6500,                 loss: nan
env4_first_0:                 episode reward: -72.5000,                 loss: nan
env4_second_0:                 episode reward: 72.5000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 82.3162s / 42551.2765 s
env0_first_0:                 episode reward: -82.7000,                 loss: 8.8024
env0_second_0:                 episode reward: 82.7000,                 loss: nan
env1_first_0:                 episode reward: -82.4000,                 loss: nan
env1_second_0:                 episode reward: 82.4000,                 loss: nan
env2_first_0:                 episode reward: -84.0500,                 loss: nan
env2_second_0:                 episode reward: 84.0500,                 loss: nan
env3_first_0:                 episode reward: -77.6000,                 loss: nan
env3_second_0:                 episode reward: 77.6000,                 loss: nan
env4_first_0:                 episode reward: -80.9000,                 loss: nan
env4_second_0:                 episode reward: 80.9000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.8225s / 42632.0990 s
env0_first_0:                 episode reward: -69.7000,                 loss: 19.8775
env0_second_0:                 episode reward: 69.7000,                 loss: nan
env1_first_0:                 episode reward: -73.9500,                 loss: nan
env1_second_0:                 episode reward: 73.9500,                 loss: nan
env2_first_0:                 episode reward: -71.6000,                 loss: nan
env2_second_0:                 episode reward: 71.6000,                 loss: nan
env3_first_0:                 episode reward: -66.1000,                 loss: nan
env3_second_0:                 episode reward: 66.1000,                 loss: nan
env4_first_0:                 episode reward: -75.3500,                 loss: nan
env4_second_0:                 episode reward: 75.3500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.1426s / 42712.2416 sLoad boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -57.0500,                 loss: 33.4843
env0_second_0:                 episode reward: 57.0500,                 loss: nan
env1_first_0:                 episode reward: -49.5000,                 loss: nan
env1_second_0:                 episode reward: 49.5000,                 loss: nan
env2_first_0:                 episode reward: -46.8500,                 loss: nan
env2_second_0:                 episode reward: 46.8500,                 loss: nan
env3_first_0:                 episode reward: -60.3000,                 loss: nan
env3_second_0:                 episode reward: 60.3000,                 loss: nan
env4_first_0:                 episode reward: -47.0000,                 loss: nan
env4_second_0:                 episode reward: 47.0000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 80.0249s / 42792.2665 s
env0_first_0:                 episode reward: -16.5500,                 loss: 33.6556
env0_second_0:                 episode reward: 16.5500,                 loss: nan
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
env2_first_0:                 episode reward: -25.9500,                 loss: nan
env2_second_0:                 episode reward: 25.9500,                 loss: nan
env3_first_0:                 episode reward: -15.3000,                 loss: nan
env3_second_0:                 episode reward: 15.3000,                 loss: nan
env4_first_0:                 episode reward: -17.9000,                 loss: nan
env4_second_0:                 episode reward: 17.9000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.8081s / 42872.0746 s
env0_first_0:                 episode reward: -29.1500,                 loss: 47.6980
env0_second_0:                 episode reward: 29.1500,                 loss: nan
env1_first_0:                 episode reward: -28.5500,                 loss: nan
env1_second_0:                 episode reward: 28.5500,                 loss: nan
env2_first_0:                 episode reward: -28.1500,                 loss: nan
env2_second_0:                 episode reward: 28.1500,                 loss: nan
env3_first_0:                 episode reward: -25.8000,                 loss: nan
env3_second_0:                 episode reward: 25.8000,                 loss: nan
env4_first_0:                 episode reward: -28.4500,                 loss: nan
env4_second_0:                 episode reward: 28.4500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.2126s / 42951.2872 s
env0_first_0:                 episode reward: -1.7000,                 loss: 3.9000
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -2.9500,                 loss: nan
env4_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8203s / 43027.1075 s
env0_first_0:                 episode reward: -2.3500,                 loss: 1.9060
env0_second_0:                 episode reward: 2.3500,                 loss: nan
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -1.9500,                 loss: nan
env3_second_0:                 episode reward: 1.9500,                 loss: nan
env4_first_0:                 episode reward: -2.1500,                 loss: nan
env4_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2993s / 43103.4068 s
env0_first_0:                 episode reward: -6.4500,                 loss: 5.5612
env0_second_0:                 episode reward: 6.4500,                 loss: nan
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
env2_first_0:                 episode reward: -6.0000,                 loss: nan
env2_second_0:                 episode reward: 6.0000,                 loss: nan
env3_first_0:                 episode reward: -5.2500,                 loss: nan
env3_second_0:                 episode reward: 5.2500,                 loss: nan
env4_first_0:                 episode reward: -6.1000,                 loss: nan
env4_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6577s / 43180.0645 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.3842
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
