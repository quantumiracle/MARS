2022-05-11 10:48:51.827182: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 10:48:51.827262: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 10:48:51.827268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 33.0, (1,), float32) action space: Discrete(3)
random seed: 712
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fee192ad668>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 8000, 'exploiter_update_itr': 1}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 10, 'log_interval': 10, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220510143601/mdp_arbitrary_mdp_nash_dqn_exploiter/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220510143601_exploit_10000/mdp_arbitrary_mdp_nash_dqn_exploiter. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220510143601_exploit_10000/mdp_arbitrary_mdp_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8847s / 0.8847 s
agent0:                 episode reward: -0.3468,                 loss: nan
agent1:                 episode reward: 0.3468,                 loss: nan
Episode: 11/10000 (0.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1225s / 1.0072 s
agent0:                 episode reward: 0.7962,                 loss: nan
agent1:                 episode reward: -0.7962,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1233s / 1.1306 s
agent0:                 episode reward: 0.8823,                 loss: nan
agent1:                 episode reward: -0.8823,                 loss: nan
Episode: 31/10000 (0.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1220s / 1.2526 s
agent0:                 episode reward: 0.2375,                 loss: nan
agent1:                 episode reward: -0.2375,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1254s / 1.3780 s
agent0:                 episode reward: 1.6341,                 loss: nan
agent1:                 episode reward: -1.6341,                 loss: nan
Episode: 51/10000 (0.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1207s / 1.4987 s
agent0:                 episode reward: 1.1132,                 loss: nan
agent1:                 episode reward: -1.1132,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.1251s / 1.6238 s
agent0:                 episode reward: 1.0647,                 loss: nan
agent1:                 episode reward: -1.0647,                 loss: nan
Episode: 71/10000 (0.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.3760s / 1.9998 s
agent0:                 episode reward: 1.6750,                 loss: nan
agent1:                 episode reward: -1.6750,                 loss: 0.5110
Episode: 81/10000 (0.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5036s / 2.5034 s
agent0:                 episode reward: 0.9528,                 loss: nan
agent1:                 episode reward: -0.9528,                 loss: 0.4582
Episode: 91/10000 (0.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4794s / 2.9828 s
agent0:                 episode reward: 0.6106,                 loss: nan
agent1:                 episode reward: -0.6106,                 loss: 0.4553
Episode: 101/10000 (1.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4767s / 3.4596 s
agent0:                 episode reward: 1.5745,                 loss: nan
agent1:                 episode reward: -1.5745,                 loss: 0.4540
Episode: 111/10000 (1.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4823s / 3.9419 s
agent0:                 episode reward: 1.7279,                 loss: nan
agent1:                 episode reward: -1.7279,                 loss: 0.4522
Episode: 121/10000 (1.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4825s / 4.4244 s
agent0:                 episode reward: 1.4344,                 loss: nan
agent1:                 episode reward: -1.4344,                 loss: 0.4498
Episode: 131/10000 (1.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4843s / 4.9087 s
agent0:                 episode reward: 0.5905,                 loss: nan
agent1:                 episode reward: -0.5905,                 loss: 0.4487
Episode: 141/10000 (1.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4965s / 5.4052 s
agent0:                 episode reward: 1.0083,                 loss: nan
agent1:                 episode reward: -1.0083,                 loss: 0.4455
Episode: 151/10000 (1.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4894s / 5.8945 s
agent0:                 episode reward: 0.2350,                 loss: nan
agent1:                 episode reward: -0.2350,                 loss: 0.4442
Episode: 161/10000 (1.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4931s / 6.3877 s
agent0:                 episode reward: 1.2750,                 loss: nan
agent1:                 episode reward: -1.2750,                 loss: 0.4436
Episode: 171/10000 (1.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5016s / 6.8893 s
agent0:                 episode reward: 1.1617,                 loss: nan
agent1:                 episode reward: -1.1617,                 loss: 0.4352
Episode: 181/10000 (1.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4963s / 7.3856 s
agent0:                 episode reward: -0.2504,                 loss: nan
agent1:                 episode reward: 0.2504,                 loss: 0.4293
Episode: 191/10000 (1.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4909s / 7.8764 s
agent0:                 episode reward: 1.4053,                 loss: nan
agent1:                 episode reward: -1.4053,                 loss: 0.4260
Episode: 201/10000 (2.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5305s / 8.4070 s
agent0:                 episode reward: 1.2575,                 loss: nan
agent1:                 episode reward: -1.2575,                 loss: 0.4288
Episode: 211/10000 (2.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4964s / 8.9034 s
agent0:                 episode reward: 0.8897,                 loss: nan
agent1:                 episode reward: -0.8897,                 loss: 0.4288
Episode: 221/10000 (2.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5156s / 9.4190 s
agent0:                 episode reward: -0.1434,                 loss: nan
agent1:                 episode reward: 0.1434,                 loss: 0.4275
Episode: 231/10000 (2.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4875s / 9.9065 s
agent0:                 episode reward: 0.5071,                 loss: nan
agent1:                 episode reward: -0.5071,                 loss: 0.4259
Episode: 241/10000 (2.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4948s / 10.4013 s
agent0:                 episode reward: 1.2425,                 loss: nan
agent1:                 episode reward: -1.2425,                 loss: 0.4270
Episode: 251/10000 (2.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5272s / 10.9285 s
agent0:                 episode reward: 1.2795,                 loss: nan
agent1:                 episode reward: -1.2795,                 loss: 0.4256
Episode: 261/10000 (2.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5067s / 11.4352 s
agent0:                 episode reward: -0.1944,                 loss: nan
agent1:                 episode reward: 0.1944,                 loss: 0.4267
Episode: 271/10000 (2.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4974s / 11.9327 s
agent0:                 episode reward: 0.5397,                 loss: nan
agent1:                 episode reward: -0.5397,                 loss: 0.3808
Episode: 281/10000 (2.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5027s / 12.4354 s
agent0:                 episode reward: 1.6137,                 loss: nan
agent1:                 episode reward: -1.6137,                 loss: 0.3538
Episode: 291/10000 (2.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.4989s / 12.9343 s
agent0:                 episode reward: 1.2923,                 loss: nan
agent1:                 episode reward: -1.2923,                 loss: 0.3481
Episode: 301/10000 (3.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5022s / 13.4365 s
agent0:                 episode reward: 1.5261,                 loss: nan
agent1:                 episode reward: -1.5261,                 loss: 0.3477
Episode: 311/10000 (3.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5003s / 13.9368 s
agent0:                 episode reward: 1.5015,                 loss: nan
agent1:                 episode reward: -1.5015,                 loss: 0.3401
Episode: 321/10000 (3.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5095s / 14.4462 s
agent0:                 episode reward: 0.1963,                 loss: nan
agent1:                 episode reward: -0.1963,                 loss: 0.3400
Episode: 331/10000 (3.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5383s / 14.9845 s
agent0:                 episode reward: 0.6099,                 loss: nan
agent1:                 episode reward: -0.6099,                 loss: 0.3393
Episode: 341/10000 (3.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5091s / 15.4936 s
agent0:                 episode reward: 1.1221,                 loss: nan
agent1:                 episode reward: -1.1221,                 loss: 0.3390
Episode: 351/10000 (3.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5074s / 16.0010 s
agent0:                 episode reward: 1.4246,                 loss: nan
agent1:                 episode reward: -1.4246,                 loss: 0.3390
Episode: 361/10000 (3.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5048s / 16.5058 s
agent0:                 episode reward: 0.0587,                 loss: nan
agent1:                 episode reward: -0.0587,                 loss: 0.3371
Episode: 371/10000 (3.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5472s / 17.0530 s
agent0:                 episode reward: 0.3270,                 loss: nan
agent1:                 episode reward: -0.3270,                 loss: 0.2931
Episode: 381/10000 (3.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5362s / 17.5893 s
agent0:                 episode reward: 0.1615,                 loss: nan
agent1:                 episode reward: -0.1615,                 loss: 0.2683
Episode: 391/10000 (3.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5158s / 18.1050 s
agent0:                 episode reward: 1.6286,                 loss: nan
agent1:                 episode reward: -1.6286,                 loss: 0.2632
Episode: 401/10000 (4.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5789s / 18.6840 s
agent0:                 episode reward: 0.5108,                 loss: nan
agent1:                 episode reward: -0.5108,                 loss: 0.2636
Episode: 411/10000 (4.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5368s / 19.2207 s
agent0:                 episode reward: 0.3878,                 loss: nan
agent1:                 episode reward: -0.3878,                 loss: 0.2632
Episode: 421/10000 (4.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5122s / 19.7330 s
agent0:                 episode reward: 0.7455,                 loss: nan
agent1:                 episode reward: -0.7455,                 loss: 0.2608
Episode: 431/10000 (4.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5106s / 20.2436 s
agent0:                 episode reward: 1.1080,                 loss: nan
agent1:                 episode reward: -1.1080,                 loss: 0.2570
Episode: 441/10000 (4.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5151s / 20.7587 s
agent0:                 episode reward: 0.9564,                 loss: nan
agent1:                 episode reward: -0.9564,                 loss: 0.2583
Episode: 451/10000 (4.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5177s / 21.2764 s
agent0:                 episode reward: 1.7470,                 loss: nan
agent1:                 episode reward: -1.7470,                 loss: 0.2599
Episode: 461/10000 (4.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5114s / 21.7878 s
agent0:                 episode reward: 1.1099,                 loss: nan
agent1:                 episode reward: -1.1099,                 loss: 0.2564
Episode: 471/10000 (4.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5152s / 22.3030 s
agent0:                 episode reward: 1.7004,                 loss: nan
agent1:                 episode reward: -1.7004,                 loss: 0.2473
Episode: 481/10000 (4.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5145s / 22.8175 s
agent0:                 episode reward: 0.7453,                 loss: nan
agent1:                 episode reward: -0.7453,                 loss: 0.2409
Episode: 491/10000 (4.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5223s / 23.3398 s
agent0:                 episode reward: 0.2523,                 loss: nan
agent1:                 episode reward: -0.2523,                 loss: 0.2376
Episode: 501/10000 (5.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5165s / 23.8564 s
agent0:                 episode reward: 0.4458,                 loss: nan
agent1:                 episode reward: -0.4458,                 loss: 0.2371
Episode: 511/10000 (5.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5132s / 24.3696 s
agent0:                 episode reward: 0.1650,                 loss: nan
agent1:                 episode reward: -0.1650,                 loss: 0.2318
Episode: 521/10000 (5.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5156s / 24.8852 s
agent0:                 episode reward: 0.9609,                 loss: nan
agent1:                 episode reward: -0.9609,                 loss: 0.2288
Episode: 531/10000 (5.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5240s / 25.4092 s
agent0:                 episode reward: 0.4988,                 loss: nan
agent1:                 episode reward: -0.4988,                 loss: 0.2303
Episode: 541/10000 (5.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5221s / 25.9313 s
agent0:                 episode reward: 0.2317,                 loss: nan
agent1:                 episode reward: -0.2317,                 loss: 0.2257
Episode: 551/10000 (5.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5358s / 26.4670 s
agent0:                 episode reward: 0.9301,                 loss: nan
agent1:                 episode reward: -0.9301,                 loss: 0.2242
Episode: 561/10000 (5.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5248s / 26.9918 s
agent0:                 episode reward: 0.9975,                 loss: nan
agent1:                 episode reward: -0.9975,                 loss: 0.2241
Episode: 571/10000 (5.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5656s / 27.5574 s
agent0:                 episode reward: 1.5723,                 loss: nan
agent1:                 episode reward: -1.5723,                 loss: 0.2385
Episode: 581/10000 (5.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5263s / 28.0837 s
agent0:                 episode reward: 1.3013,                 loss: nan
agent1:                 episode reward: -1.3013,                 loss: 0.2404
Episode: 591/10000 (5.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5258s / 28.6095 s
agent0:                 episode reward: 0.0313,                 loss: nan
agent1:                 episode reward: -0.0313,                 loss: 0.2382
Episode: 601/10000 (6.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5972s / 29.2067 s
agent0:                 episode reward: 0.2655,                 loss: nan
agent1:                 episode reward: -0.2655,                 loss: 0.2387
Episode: 611/10000 (6.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5351s / 29.7418 s
agent0:                 episode reward: -0.0006,                 loss: nan
agent1:                 episode reward: 0.0006,                 loss: 0.2360
Episode: 621/10000 (6.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5240s / 30.2658 s
agent0:                 episode reward: -0.4045,                 loss: nan
agent1:                 episode reward: 0.4045,                 loss: 0.2366
Episode: 631/10000 (6.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5260s / 30.7918 s
agent0:                 episode reward: 1.1149,                 loss: nan
agent1:                 episode reward: -1.1149,                 loss: 0.2322
Episode: 641/10000 (6.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5325s / 31.3243 s
agent0:                 episode reward: 0.5460,                 loss: nan
agent1:                 episode reward: -0.5460,                 loss: 0.2322
Episode: 651/10000 (6.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5325s / 31.8568 s
agent0:                 episode reward: 1.4725,                 loss: nan
agent1:                 episode reward: -1.4725,                 loss: 0.2325
Episode: 661/10000 (6.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5391s / 32.3959 s
agent0:                 episode reward: 0.1773,                 loss: nan
agent1:                 episode reward: -0.1773,                 loss: 0.2342
Episode: 671/10000 (6.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5312s / 32.9271 s
agent0:                 episode reward: 1.3211,                 loss: nan
agent1:                 episode reward: -1.3211,                 loss: 0.2526
Episode: 681/10000 (6.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5414s / 33.4685 s
agent0:                 episode reward: 1.1067,                 loss: nan
agent1:                 episode reward: -1.1067,                 loss: 0.2586
Episode: 691/10000 (6.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5348s / 34.0033 s
agent0:                 episode reward: 0.3529,                 loss: nan
agent1:                 episode reward: -0.3529,                 loss: 0.2591
Episode: 701/10000 (7.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5325s / 34.5359 s
agent0:                 episode reward: -0.1510,                 loss: nan
agent1:                 episode reward: 0.1510,                 loss: 0.2569
Episode: 711/10000 (7.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5305s / 35.0664 s
agent0:                 episode reward: 0.9158,                 loss: nan
agent1:                 episode reward: -0.9158,                 loss: 0.2611
Episode: 721/10000 (7.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5859s / 35.6523 s
agent0:                 episode reward: 0.3603,                 loss: nan
agent1:                 episode reward: -0.3603,                 loss: 0.2603
Episode: 731/10000 (7.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5335s / 36.1857 s
agent0:                 episode reward: -0.6268,                 loss: nan
agent1:                 episode reward: 0.6268,                 loss: 0.2584
Episode: 741/10000 (7.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5388s / 36.7245 s
agent0:                 episode reward: -0.4544,                 loss: nan
agent1:                 episode reward: 0.4544,                 loss: 0.2585
Episode: 751/10000 (7.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5369s / 37.2614 s
agent0:                 episode reward: 0.3583,                 loss: nan
agent1:                 episode reward: -0.3583,                 loss: 0.2600
Episode: 761/10000 (7.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5469s / 37.8083 s
agent0:                 episode reward: 0.5549,                 loss: nan
agent1:                 episode reward: -0.5549,                 loss: 0.2578
Episode: 771/10000 (7.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5416s / 38.3499 s
agent0:                 episode reward: 0.3324,                 loss: nan
agent1:                 episode reward: -0.3324,                 loss: 0.2833
Episode: 781/10000 (7.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5490s / 38.8989 s
agent0:                 episode reward: 1.4740,                 loss: nan
agent1:                 episode reward: -1.4740,                 loss: 0.2932
Episode: 791/10000 (7.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6064s / 39.5053 s
agent0:                 episode reward: 0.2569,                 loss: nan
agent1:                 episode reward: -0.2569,                 loss: 0.2912
Episode: 801/10000 (8.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5357s / 40.0409 s
agent0:                 episode reward: 0.6218,                 loss: nan
agent1:                 episode reward: -0.6218,                 loss: 0.2927
Episode: 811/10000 (8.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5388s / 40.5798 s
agent0:                 episode reward: -0.2442,                 loss: nan
agent1:                 episode reward: 0.2442,                 loss: 0.2943
Episode: 821/10000 (8.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5399s / 41.1197 s
agent0:                 episode reward: 0.6995,                 loss: nan
agent1:                 episode reward: -0.6995,                 loss: 0.2917
Episode: 831/10000 (8.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5458s / 41.6655 s
agent0:                 episode reward: 0.5200,                 loss: nan
agent1:                 episode reward: -0.5200,                 loss: 0.2919
Episode: 841/10000 (8.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5465s / 42.2120 s
agent0:                 episode reward: 0.9387,                 loss: nan
agent1:                 episode reward: -0.9387,                 loss: 0.2876
Episode: 851/10000 (8.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5420s / 42.7540 s
agent0:                 episode reward: 0.9981,                 loss: nan
agent1:                 episode reward: -0.9981,                 loss: 0.2912
Episode: 861/10000 (8.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5481s / 43.3020 s
agent0:                 episode reward: 0.0609,                 loss: nan
agent1:                 episode reward: -0.0609,                 loss: 0.2922
Episode: 871/10000 (8.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5618s / 43.8639 s
agent0:                 episode reward: 0.5898,                 loss: nan
agent1:                 episode reward: -0.5898,                 loss: 0.3119
Episode: 881/10000 (8.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5618s / 44.4257 s
agent0:                 episode reward: -0.6941,                 loss: nan
agent1:                 episode reward: 0.6941,                 loss: 0.3199
Episode: 891/10000 (8.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5463s / 44.9719 s
agent0:                 episode reward: -0.2495,                 loss: nan
agent1:                 episode reward: 0.2495,                 loss: 0.3198
Episode: 901/10000 (9.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5474s / 45.5193 s
agent0:                 episode reward: 0.6963,                 loss: nan
agent1:                 episode reward: -0.6963,                 loss: 0.3183
Episode: 911/10000 (9.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5538s / 46.0731 s
agent0:                 episode reward: -0.2722,                 loss: nan
agent1:                 episode reward: 0.2722,                 loss: 0.3183
Episode: 921/10000 (9.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5535s / 46.6265 s
agent0:                 episode reward: 0.4846,                 loss: nan
agent1:                 episode reward: -0.4846,                 loss: 0.3209
Episode: 931/10000 (9.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5654s / 47.1919 s
agent0:                 episode reward: 0.5176,                 loss: nan
agent1:                 episode reward: -0.5176,                 loss: 0.3200
Episode: 941/10000 (9.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5821s / 47.7740 s
agent0:                 episode reward: 0.2343,                 loss: nan
agent1:                 episode reward: -0.2343,                 loss: 0.3201
Episode: 951/10000 (9.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5579s / 48.3319 s
agent0:                 episode reward: 1.1421,                 loss: nan
agent1:                 episode reward: -1.1421,                 loss: 0.3190
Episode: 961/10000 (9.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5551s / 48.8870 s
agent0:                 episode reward: -0.0414,                 loss: nan
agent1:                 episode reward: 0.0414,                 loss: 0.3191
Episode: 971/10000 (9.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6051s / 49.4921 s
agent0:                 episode reward: 0.2319,                 loss: nan
agent1:                 episode reward: -0.2319,                 loss: 0.3327
Episode: 981/10000 (9.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5565s / 50.0486 s
agent0:                 episode reward: 0.2896,                 loss: nan
agent1:                 episode reward: -0.2896,                 loss: 0.3356
Episode: 991/10000 (9.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5704s / 50.6190 s
agent0:                 episode reward: 0.7745,                 loss: nan
agent1:                 episode reward: -0.7745,                 loss: 0.3343
Episode: 1001/10000 (10.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5622s / 51.1813 s
agent0:                 episode reward: 0.8647,                 loss: nan
agent1:                 episode reward: -0.8647,                 loss: 0.3380
Episode: 1011/10000 (10.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5593s / 51.7406 s
agent0:                 episode reward: 0.9160,                 loss: nan
agent1:                 episode reward: -0.9160,                 loss: 0.3360
Episode: 1021/10000 (10.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5947s / 52.3354 s
agent0:                 episode reward: 1.2278,                 loss: nan
agent1:                 episode reward: -1.2278,                 loss: 0.3374
Episode: 1031/10000 (10.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5629s / 52.8982 s
agent0:                 episode reward: 0.3476,                 loss: nan
agent1:                 episode reward: -0.3476,                 loss: 0.3363
Episode: 1041/10000 (10.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5658s / 53.4640 s
agent0:                 episode reward: -0.0887,                 loss: nan
agent1:                 episode reward: 0.0887,                 loss: 0.3337
Episode: 1051/10000 (10.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5675s / 54.0315 s
agent0:                 episode reward: 0.4322,                 loss: nan
agent1:                 episode reward: -0.4322,                 loss: 0.3347
Episode: 1061/10000 (10.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5652s / 54.5967 s
agent0:                 episode reward: 0.4105,                 loss: nan
agent1:                 episode reward: -0.4105,                 loss: 0.3365
Episode: 1071/10000 (10.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5586s / 55.1552 s
agent0:                 episode reward: 0.8067,                 loss: nan
agent1:                 episode reward: -0.8067,                 loss: 0.3441
Episode: 1081/10000 (10.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5599s / 55.7151 s
agent0:                 episode reward: -1.1831,                 loss: nan
agent1:                 episode reward: 1.1831,                 loss: 0.3450
Episode: 1091/10000 (10.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5626s / 56.2777 s
agent0:                 episode reward: -0.0064,                 loss: nan
agent1:                 episode reward: 0.0064,                 loss: 0.3439
Episode: 1101/10000 (11.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5888s / 56.8665 s
agent0:                 episode reward: 1.2518,                 loss: nan
agent1:                 episode reward: -1.2518,                 loss: 0.3437
Episode: 1111/10000 (11.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5593s / 57.4258 s
agent0:                 episode reward: 0.3405,                 loss: nan
agent1:                 episode reward: -0.3405,                 loss: 0.3467
Episode: 1121/10000 (11.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5711s / 57.9969 s
agent0:                 episode reward: 0.4291,                 loss: nan
agent1:                 episode reward: -0.4291,                 loss: 0.3413
Episode: 1131/10000 (11.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5719s / 58.5689 s
agent0:                 episode reward: 0.6541,                 loss: nan
agent1:                 episode reward: -0.6541,                 loss: 0.3435
Episode: 1141/10000 (11.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5667s / 59.1356 s
agent0:                 episode reward: -0.2573,                 loss: nan
agent1:                 episode reward: 0.2573,                 loss: 0.3421
Episode: 1151/10000 (11.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6519s / 59.7875 s
agent0:                 episode reward: 0.5933,                 loss: nan
agent1:                 episode reward: -0.5933,                 loss: 0.3444
Episode: 1161/10000 (11.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5729s / 60.3604 s
agent0:                 episode reward: 0.1594,                 loss: nan
agent1:                 episode reward: -0.1594,                 loss: 0.3436
Episode: 1171/10000 (11.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5838s / 60.9442 s
agent0:                 episode reward: 0.9389,                 loss: nan
agent1:                 episode reward: -0.9389,                 loss: 0.3540
Episode: 1181/10000 (11.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5684s / 61.5126 s
agent0:                 episode reward: 0.2732,                 loss: nan
agent1:                 episode reward: -0.2732,                 loss: 0.3544
Episode: 1191/10000 (11.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5734s / 62.0860 s
agent0:                 episode reward: 0.5275,                 loss: nan
agent1:                 episode reward: -0.5275,                 loss: 0.3548
Episode: 1201/10000 (12.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5833s / 62.6692 s
agent0:                 episode reward: -0.2023,                 loss: nan
agent1:                 episode reward: 0.2023,                 loss: 0.3541
Episode: 1211/10000 (12.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5728s / 63.2421 s
agent0:                 episode reward: 0.1190,                 loss: nan
agent1:                 episode reward: -0.1190,                 loss: 0.3518
Episode: 1221/10000 (12.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5737s / 63.8158 s
agent0:                 episode reward: -0.3875,                 loss: nan
agent1:                 episode reward: 0.3875,                 loss: 0.3545
Episode: 1231/10000 (12.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5752s / 64.3910 s
agent0:                 episode reward: 0.1652,                 loss: nan
agent1:                 episode reward: -0.1652,                 loss: 0.3536
Episode: 1241/10000 (12.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5768s / 64.9678 s
agent0:                 episode reward: 0.8754,                 loss: nan
agent1:                 episode reward: -0.8754,                 loss: 0.3521
Episode: 1251/10000 (12.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5769s / 65.5447 s
agent0:                 episode reward: 0.5584,                 loss: nan
agent1:                 episode reward: -0.5584,                 loss: 0.3534
Episode: 1261/10000 (12.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5832s / 66.1279 s
agent0:                 episode reward: -0.7022,                 loss: nan
agent1:                 episode reward: 0.7022,                 loss: 0.3534
Episode: 1271/10000 (12.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5748s / 66.7027 s
agent0:                 episode reward: -1.0666,                 loss: nan
agent1:                 episode reward: 1.0666,                 loss: 0.3615
Episode: 1281/10000 (12.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5747s / 67.2775 s
agent0:                 episode reward: 0.1705,                 loss: nan
agent1:                 episode reward: -0.1705,                 loss: 0.3663
Episode: 1291/10000 (12.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5791s / 67.8566 s
agent0:                 episode reward: 1.0258,                 loss: nan
agent1:                 episode reward: -1.0258,                 loss: 0.3666
Episode: 1301/10000 (13.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5683s / 68.4249 s
agent0:                 episode reward: -0.0879,                 loss: nan
agent1:                 episode reward: 0.0879,                 loss: 0.3651
Episode: 1311/10000 (13.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5887s / 69.0136 s
agent0:                 episode reward: -0.2598,                 loss: nan
agent1:                 episode reward: 0.2598,                 loss: 0.3651
Episode: 1321/10000 (13.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6064s / 69.6200 s
agent0:                 episode reward: 0.6941,                 loss: nan
agent1:                 episode reward: -0.6941,                 loss: 0.3652
Episode: 1331/10000 (13.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6496s / 70.2696 s
agent0:                 episode reward: 1.5518,                 loss: nan
agent1:                 episode reward: -1.5518,                 loss: 0.3631
Episode: 1341/10000 (13.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5931s / 70.8627 s
agent0:                 episode reward: 0.5016,                 loss: nan
agent1:                 episode reward: -0.5016,                 loss: 0.3633
Episode: 1351/10000 (13.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5822s / 71.4449 s
agent0:                 episode reward: 0.8193,                 loss: nan
agent1:                 episode reward: -0.8193,                 loss: 0.3641
Episode: 1361/10000 (13.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5853s / 72.0302 s
agent0:                 episode reward: 0.9270,                 loss: nan
agent1:                 episode reward: -0.9270,                 loss: 0.3640
Episode: 1371/10000 (13.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5777s / 72.6080 s
agent0:                 episode reward: -0.4203,                 loss: nan
agent1:                 episode reward: 0.4203,                 loss: 0.3776
Episode: 1381/10000 (13.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5794s / 73.1874 s
agent0:                 episode reward: 0.1114,                 loss: nan
agent1:                 episode reward: -0.1114,                 loss: 0.3833
Episode: 1391/10000 (13.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5894s / 73.7768 s
agent0:                 episode reward: -0.3544,                 loss: nan
agent1:                 episode reward: 0.3544,                 loss: 0.3832
Episode: 1401/10000 (14.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5875s / 74.3643 s
agent0:                 episode reward: -0.1576,                 loss: nan
agent1:                 episode reward: 0.1576,                 loss: 0.3820
Episode: 1411/10000 (14.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5901s / 74.9543 s
agent0:                 episode reward: 1.2011,                 loss: nan
agent1:                 episode reward: -1.2011,                 loss: 0.3821
Episode: 1421/10000 (14.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5879s / 75.5422 s
agent0:                 episode reward: -0.1799,                 loss: nan
agent1:                 episode reward: 0.1799,                 loss: 0.3831
Episode: 1431/10000 (14.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5856s / 76.1278 s
agent0:                 episode reward: 0.5972,                 loss: nan
agent1:                 episode reward: -0.5972,                 loss: 0.3839
Episode: 1441/10000 (14.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5943s / 76.7221 s
agent0:                 episode reward: 1.0936,                 loss: nan
agent1:                 episode reward: -1.0936,                 loss: 0.3850
Episode: 1451/10000 (14.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6795s / 77.4016 s
agent0:                 episode reward: 0.3072,                 loss: nan
agent1:                 episode reward: -0.3072,                 loss: 0.3835
Episode: 1461/10000 (14.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6192s / 78.0208 s
agent0:                 episode reward: 0.5075,                 loss: nan
agent1:                 episode reward: -0.5075,                 loss: 0.3832
Episode: 1471/10000 (14.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5822s / 78.6030 s
agent0:                 episode reward: -0.2109,                 loss: nan
agent1:                 episode reward: 0.2109,                 loss: 0.3959
Episode: 1481/10000 (14.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5884s / 79.1914 s
agent0:                 episode reward: -0.4197,                 loss: nan
agent1:                 episode reward: 0.4197,                 loss: 0.4007
Episode: 1491/10000 (14.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6093s / 79.8008 s
agent0:                 episode reward: 0.2014,                 loss: nan
agent1:                 episode reward: -0.2014,                 loss: 0.4001
Episode: 1501/10000 (15.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6461s / 80.4469 s
agent0:                 episode reward: 0.0435,                 loss: nan
agent1:                 episode reward: -0.0435,                 loss: 0.4009
Episode: 1511/10000 (15.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5922s / 81.0391 s
agent0:                 episode reward: 1.0825,                 loss: nan
agent1:                 episode reward: -1.0825,                 loss: 0.3998
Episode: 1521/10000 (15.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5960s / 81.6351 s
agent0:                 episode reward: 0.5419,                 loss: nan
agent1:                 episode reward: -0.5419,                 loss: 0.4017
Episode: 1531/10000 (15.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5970s / 82.2321 s
agent0:                 episode reward: 0.1042,                 loss: nan
agent1:                 episode reward: -0.1042,                 loss: 0.3993
Episode: 1541/10000 (15.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5946s / 82.8267 s
agent0:                 episode reward: 0.3214,                 loss: nan
agent1:                 episode reward: -0.3214,                 loss: 0.3994
Episode: 1551/10000 (15.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5924s / 83.4191 s
agent0:                 episode reward: -0.1410,                 loss: nan
agent1:                 episode reward: 0.1410,                 loss: 0.3994
Episode: 1561/10000 (15.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6009s / 84.0200 s
agent0:                 episode reward: 0.8728,                 loss: nan
agent1:                 episode reward: -0.8728,                 loss: 0.3995
Episode: 1571/10000 (15.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5922s / 84.6122 s
agent0:                 episode reward: -0.0228,                 loss: nan
agent1:                 episode reward: 0.0228,                 loss: 0.4072
Episode: 1581/10000 (15.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5965s / 85.2087 s
agent0:                 episode reward: 0.7890,                 loss: nan
agent1:                 episode reward: -0.7890,                 loss: 0.4103
Episode: 1591/10000 (15.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6037s / 85.8124 s
agent0:                 episode reward: 0.5856,                 loss: nan
agent1:                 episode reward: -0.5856,                 loss: 0.4105
Episode: 1601/10000 (16.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6080s / 86.4203 s
agent0:                 episode reward: 0.0165,                 loss: nan
agent1:                 episode reward: -0.0165,                 loss: 0.4100
Episode: 1611/10000 (16.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6020s / 87.0223 s
agent0:                 episode reward: 1.0826,                 loss: nan
agent1:                 episode reward: -1.0826,                 loss: 0.4116
Episode: 1621/10000 (16.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5995s / 87.6218 s
agent0:                 episode reward: 1.1751,                 loss: nan
agent1:                 episode reward: -1.1751,                 loss: 0.4095
Episode: 1631/10000 (16.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6045s / 88.2262 s
agent0:                 episode reward: 0.5900,                 loss: nan
agent1:                 episode reward: -0.5900,                 loss: 0.4105
Episode: 1641/10000 (16.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5986s / 88.8249 s
agent0:                 episode reward: 0.9629,                 loss: nan
agent1:                 episode reward: -0.9629,                 loss: 0.4093
Episode: 1651/10000 (16.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6120s / 89.4369 s
agent0:                 episode reward: 0.5558,                 loss: nan
agent1:                 episode reward: -0.5558,                 loss: 0.4086
Episode: 1661/10000 (16.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6009s / 90.0378 s
agent0:                 episode reward: 1.2637,                 loss: nan
agent1:                 episode reward: -1.2637,                 loss: 0.4113
Episode: 1671/10000 (16.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6552s / 90.6931 s
agent0:                 episode reward: -0.2966,                 loss: nan
agent1:                 episode reward: 0.2966,                 loss: 0.4148
Episode: 1681/10000 (16.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6013s / 91.2944 s
agent0:                 episode reward: -0.5627,                 loss: nan
agent1:                 episode reward: 0.5627,                 loss: 0.4179
Episode: 1691/10000 (16.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5980s / 91.8924 s
agent0:                 episode reward: 0.2870,                 loss: nan
agent1:                 episode reward: -0.2870,                 loss: 0.4163
Episode: 1701/10000 (17.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6000s / 92.4923 s
agent0:                 episode reward: -0.1211,                 loss: nan
agent1:                 episode reward: 0.1211,                 loss: 0.4162
Episode: 1711/10000 (17.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6083s / 93.1006 s
agent0:                 episode reward: -0.5163,                 loss: nan
agent1:                 episode reward: 0.5163,                 loss: 0.4175
Episode: 1721/10000 (17.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6184s / 93.7190 s
agent0:                 episode reward: 0.0387,                 loss: nan
agent1:                 episode reward: -0.0387,                 loss: 0.4173
Episode: 1731/10000 (17.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6110s / 94.3299 s
agent0:                 episode reward: 0.9037,                 loss: nan
agent1:                 episode reward: -0.9037,                 loss: 0.4176
Episode: 1741/10000 (17.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.5963s / 94.9263 s
agent0:                 episode reward: -0.0383,                 loss: nan
agent1:                 episode reward: 0.0383,                 loss: 0.4194
Episode: 1751/10000 (17.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6256s / 95.5519 s
agent0:                 episode reward: -0.2635,                 loss: nan
agent1:                 episode reward: 0.2635,                 loss: 0.4167
Episode: 1761/10000 (17.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6083s / 96.1602 s
agent0:                 episode reward: -0.1677,                 loss: nan
agent1:                 episode reward: 0.1677,                 loss: 0.4174
Episode: 1771/10000 (17.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6220s / 96.7822 s
agent0:                 episode reward: 0.0124,                 loss: nan
agent1:                 episode reward: -0.0124,                 loss: 0.4208
Episode: 1781/10000 (17.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6152s / 97.3973 s
agent0:                 episode reward: 0.1838,                 loss: nan
agent1:                 episode reward: -0.1838,                 loss: 0.4234
Episode: 1791/10000 (17.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6058s / 98.0032 s
agent0:                 episode reward: 0.2138,                 loss: nan
agent1:                 episode reward: -0.2138,                 loss: 0.4230
Episode: 1801/10000 (18.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6236s / 98.6268 s
agent0:                 episode reward: 0.3047,                 loss: nan
agent1:                 episode reward: -0.3047,                 loss: 0.4225
Episode: 1811/10000 (18.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6332s / 99.2599 s
agent0:                 episode reward: 0.1473,                 loss: nan
agent1:                 episode reward: -0.1473,                 loss: 0.4223
Episode: 1821/10000 (18.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6070s / 99.8669 s
agent0:                 episode reward: 0.1063,                 loss: nan
agent1:                 episode reward: -0.1063,                 loss: 0.4223
Episode: 1831/10000 (18.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6055s / 100.4724 s
agent0:                 episode reward: 0.8640,                 loss: nan
agent1:                 episode reward: -0.8640,                 loss: 0.4229
Episode: 1841/10000 (18.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6473s / 101.1197 s
agent0:                 episode reward: -0.0805,                 loss: nan
agent1:                 episode reward: 0.0805,                 loss: 0.4230
Episode: 1851/10000 (18.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6259s / 101.7456 s
agent0:                 episode reward: -0.4410,                 loss: nan
agent1:                 episode reward: 0.4410,                 loss: 0.4227
Episode: 1861/10000 (18.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6329s / 102.3785 s
agent0:                 episode reward: 1.0342,                 loss: nan
agent1:                 episode reward: -1.0342,                 loss: 0.4220
Episode: 1871/10000 (18.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6091s / 102.9876 s
agent0:                 episode reward: -0.1177,                 loss: nan
agent1:                 episode reward: 0.1177,                 loss: 0.4206
Episode: 1881/10000 (18.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6152s / 103.6028 s
agent0:                 episode reward: -0.6323,                 loss: nan
agent1:                 episode reward: 0.6323,                 loss: 0.4207
Episode: 1891/10000 (18.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6155s / 104.2183 s
agent0:                 episode reward: 0.5203,                 loss: nan
agent1:                 episode reward: -0.5203,                 loss: 0.4220
Episode: 1901/10000 (19.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6236s / 104.8420 s
agent0:                 episode reward: 1.1611,                 loss: nan
agent1:                 episode reward: -1.1611,                 loss: 0.4223
Episode: 1911/10000 (19.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6082s / 105.4502 s
agent0:                 episode reward: -0.2524,                 loss: nan
agent1:                 episode reward: 0.2524,                 loss: 0.4198
Episode: 1921/10000 (19.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6207s / 106.0709 s
agent0:                 episode reward: -0.3037,                 loss: nan
agent1:                 episode reward: 0.3037,                 loss: 0.4207
Episode: 1931/10000 (19.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6113s / 106.6821 s
agent0:                 episode reward: 0.2951,                 loss: nan
agent1:                 episode reward: -0.2951,                 loss: 0.4196
Episode: 1941/10000 (19.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6123s / 107.2945 s
agent0:                 episode reward: -0.0399,                 loss: nan
agent1:                 episode reward: 0.0399,                 loss: 0.4201
Episode: 1951/10000 (19.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6255s / 107.9199 s
agent0:                 episode reward: -0.0770,                 loss: nan
agent1:                 episode reward: 0.0770,                 loss: 0.4208
Episode: 1961/10000 (19.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6193s / 108.5393 s
agent0:                 episode reward: 0.0154,                 loss: nan
agent1:                 episode reward: -0.0154,                 loss: 0.4200
Episode: 1971/10000 (19.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6067s / 109.1460 s
agent0:                 episode reward: 0.2359,                 loss: nan
agent1:                 episode reward: -0.2359,                 loss: 0.4184
Episode: 1981/10000 (19.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6114s / 109.7573 s
agent0:                 episode reward: 0.0175,                 loss: nan
agent1:                 episode reward: -0.0175,                 loss: 0.4166
Episode: 1991/10000 (19.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6331s / 110.3904 s
agent0:                 episode reward: 0.6132,                 loss: nan
agent1:                 episode reward: -0.6132,                 loss: 0.4182
Episode: 2001/10000 (20.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6639s / 111.0543 s
agent0:                 episode reward: 0.5162,                 loss: nan
agent1:                 episode reward: -0.5162,                 loss: 0.4177
Episode: 2011/10000 (20.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6224s / 111.6767 s
agent0:                 episode reward: -0.0058,                 loss: nan
agent1:                 episode reward: 0.0058,                 loss: 0.4164
Episode: 2021/10000 (20.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6263s / 112.3030 s
agent0:                 episode reward: -0.2480,                 loss: nan
agent1:                 episode reward: 0.2480,                 loss: 0.4171
Episode: 2031/10000 (20.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6154s / 112.9184 s
agent0:                 episode reward: 0.2334,                 loss: nan
agent1:                 episode reward: -0.2334,                 loss: 0.4159
Episode: 2041/10000 (20.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6247s / 113.5431 s
agent0:                 episode reward: -0.1461,                 loss: nan
agent1:                 episode reward: 0.1461,                 loss: 0.4158
Episode: 2051/10000 (20.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6343s / 114.1773 s
agent0:                 episode reward: -0.2995,                 loss: nan
agent1:                 episode reward: 0.2995,                 loss: 0.4166
Episode: 2061/10000 (20.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6137s / 114.7910 s
agent0:                 episode reward: 0.4611,                 loss: nan
agent1:                 episode reward: -0.4611,                 loss: 0.4169
Episode: 2071/10000 (20.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6257s / 115.4168 s
agent0:                 episode reward: 0.6138,                 loss: nan
agent1:                 episode reward: -0.6138,                 loss: 0.4147
Episode: 2081/10000 (20.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6276s / 116.0444 s
agent0:                 episode reward: 0.1277,                 loss: nan
agent1:                 episode reward: -0.1277,                 loss: 0.4135
Episode: 2091/10000 (20.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6250s / 116.6694 s
agent0:                 episode reward: 0.3843,                 loss: nan
agent1:                 episode reward: -0.3843,                 loss: 0.4143
Episode: 2101/10000 (21.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6525s / 117.3220 s
agent0:                 episode reward: 0.8221,                 loss: nan
agent1:                 episode reward: -0.8221,                 loss: 0.4138
Episode: 2111/10000 (21.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6273s / 117.9493 s
agent0:                 episode reward: 0.2143,                 loss: nan
agent1:                 episode reward: -0.2143,                 loss: 0.4153
Episode: 2121/10000 (21.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6974s / 118.6467 s
agent0:                 episode reward: -0.1737,                 loss: nan
agent1:                 episode reward: 0.1737,                 loss: 0.4137
Episode: 2131/10000 (21.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6344s / 119.2811 s
agent0:                 episode reward: 0.3514,                 loss: nan
agent1:                 episode reward: -0.3514,                 loss: 0.4139
Episode: 2141/10000 (21.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6206s / 119.9017 s
agent0:                 episode reward: 0.3943,                 loss: nan
agent1:                 episode reward: -0.3943,                 loss: 0.4143
Episode: 2151/10000 (21.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6212s / 120.5229 s
agent0:                 episode reward: 0.8841,                 loss: nan
agent1:                 episode reward: -0.8841,                 loss: 0.4143
Episode: 2161/10000 (21.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6642s / 121.1872 s
agent0:                 episode reward: 0.4387,                 loss: nan
agent1:                 episode reward: -0.4387,                 loss: 0.4144
Episode: 2171/10000 (21.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6240s / 121.8112 s
agent0:                 episode reward: -0.2539,                 loss: nan
agent1:                 episode reward: 0.2539,                 loss: 0.4122
Episode: 2181/10000 (21.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6216s / 122.4328 s
agent0:                 episode reward: -0.2341,                 loss: nan
agent1:                 episode reward: 0.2341,                 loss: 0.4126
Episode: 2191/10000 (21.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6374s / 123.0702 s
agent0:                 episode reward: 0.6140,                 loss: nan
agent1:                 episode reward: -0.6140,                 loss: 0.4123
Episode: 2201/10000 (22.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6291s / 123.6993 s
agent0:                 episode reward: -0.2034,                 loss: nan
agent1:                 episode reward: 0.2034,                 loss: 0.4103
Episode: 2211/10000 (22.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6254s / 124.3246 s
agent0:                 episode reward: 0.3762,                 loss: nan
agent1:                 episode reward: -0.3762,                 loss: 0.4129
Episode: 2221/10000 (22.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6810s / 125.0057 s
agent0:                 episode reward: -0.0912,                 loss: nan
agent1:                 episode reward: 0.0912,                 loss: 0.4114
Episode: 2231/10000 (22.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6495s / 125.6551 s
agent0:                 episode reward: 0.4950,                 loss: nan
agent1:                 episode reward: -0.4950,                 loss: 0.4108
Episode: 2241/10000 (22.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6373s / 126.2924 s
agent0:                 episode reward: 0.8556,                 loss: nan
agent1:                 episode reward: -0.8556,                 loss: 0.4111
Episode: 2251/10000 (22.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6684s / 126.9608 s
agent0:                 episode reward: 0.3730,                 loss: nan
agent1:                 episode reward: -0.3730,                 loss: 0.4123
Episode: 2261/10000 (22.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6253s / 127.5862 s
agent0:                 episode reward: 0.7262,                 loss: nan
agent1:                 episode reward: -0.7262,                 loss: 0.4117
Episode: 2271/10000 (22.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6284s / 128.2146 s
agent0:                 episode reward: -0.2038,                 loss: nan
agent1:                 episode reward: 0.2038,                 loss: 0.4108
Episode: 2281/10000 (22.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6355s / 128.8501 s
agent0:                 episode reward: 0.5341,                 loss: nan
agent1:                 episode reward: -0.5341,                 loss: 0.4131
Episode: 2291/10000 (22.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6275s / 129.4776 s
agent0:                 episode reward: -0.8374,                 loss: nan
agent1:                 episode reward: 0.8374,                 loss: 0.4124
Episode: 2301/10000 (23.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6328s / 130.1103 s
agent0:                 episode reward: 1.0178,                 loss: nan
agent1:                 episode reward: -1.0178,                 loss: 0.4120
Episode: 2311/10000 (23.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6302s / 130.7405 s
agent0:                 episode reward: -0.4972,                 loss: nan
agent1:                 episode reward: 0.4972,                 loss: 0.4137
Episode: 2321/10000 (23.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6801s / 131.4206 s
agent0:                 episode reward: -0.4956,                 loss: nan
agent1:                 episode reward: 0.4956,                 loss: 0.4138
Episode: 2331/10000 (23.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6524s / 132.0730 s
agent0:                 episode reward: 0.9895,                 loss: nan
agent1:                 episode reward: -0.9895,                 loss: 0.4108
Episode: 2341/10000 (23.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6464s / 132.7194 s
agent0:                 episode reward: 0.4683,                 loss: nan
agent1:                 episode reward: -0.4683,                 loss: 0.4118
Episode: 2351/10000 (23.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6369s / 133.3563 s
agent0:                 episode reward: 0.7358,                 loss: nan
agent1:                 episode reward: -0.7358,                 loss: 0.4124
Episode: 2361/10000 (23.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6299s / 133.9862 s
agent0:                 episode reward: 0.3277,                 loss: nan
agent1:                 episode reward: -0.3277,                 loss: 0.4117
Episode: 2371/10000 (23.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6354s / 134.6216 s
agent0:                 episode reward: 0.8236,                 loss: nan
agent1:                 episode reward: -0.8236,                 loss: 0.4127
Episode: 2381/10000 (23.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6616s / 135.2832 s
agent0:                 episode reward: 0.8542,                 loss: nan
agent1:                 episode reward: -0.8542,                 loss: 0.4116
Episode: 2391/10000 (23.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6326s / 135.9158 s
agent0:                 episode reward: 0.2426,                 loss: nan
agent1:                 episode reward: -0.2426,                 loss: 0.4130
Episode: 2401/10000 (24.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6396s / 136.5553 s
agent0:                 episode reward: 0.6452,                 loss: nan
agent1:                 episode reward: -0.6452,                 loss: 0.4106
Episode: 2411/10000 (24.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6349s / 137.1902 s
agent0:                 episode reward: 0.4373,                 loss: nan
agent1:                 episode reward: -0.4373,                 loss: 0.4110
Episode: 2421/10000 (24.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6360s / 137.8262 s
agent0:                 episode reward: 1.0688,                 loss: nan
agent1:                 episode reward: -1.0688,                 loss: 0.4097
Episode: 2431/10000 (24.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6619s / 138.4881 s
agent0:                 episode reward: -0.2118,                 loss: nan
agent1:                 episode reward: 0.2118,                 loss: 0.4119
Episode: 2441/10000 (24.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6411s / 139.1292 s
agent0:                 episode reward: 0.4963,                 loss: nan
agent1:                 episode reward: -0.4963,                 loss: 0.4116
Episode: 2451/10000 (24.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6440s / 139.7732 s
agent0:                 episode reward: -0.1975,                 loss: nan
agent1:                 episode reward: 0.1975,                 loss: 0.4098
Episode: 2461/10000 (24.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6327s / 140.4059 s
agent0:                 episode reward: 0.3065,                 loss: nan
agent1:                 episode reward: -0.3065,                 loss: 0.4104
Episode: 2471/10000 (24.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6404s / 141.0463 s
agent0:                 episode reward: 0.4590,                 loss: nan
agent1:                 episode reward: -0.4590,                 loss: 0.4114
Episode: 2481/10000 (24.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6861s / 141.7324 s
agent0:                 episode reward: 0.3822,                 loss: nan
agent1:                 episode reward: -0.3822,                 loss: 0.4111
Episode: 2491/10000 (24.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6357s / 142.3681 s
agent0:                 episode reward: 0.6009,                 loss: nan
agent1:                 episode reward: -0.6009,                 loss: 0.4103
Episode: 2501/10000 (25.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6431s / 143.0112 s
agent0:                 episode reward: 0.0541,                 loss: nan
agent1:                 episode reward: -0.0541,                 loss: 0.4120
Episode: 2511/10000 (25.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6482s / 143.6594 s
agent0:                 episode reward: -0.0341,                 loss: nan
agent1:                 episode reward: 0.0341,                 loss: 0.4112
Episode: 2521/10000 (25.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6482s / 144.3076 s
agent0:                 episode reward: 0.2942,                 loss: nan
agent1:                 episode reward: -0.2942,                 loss: 0.4116
Episode: 2531/10000 (25.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6433s / 144.9509 s
agent0:                 episode reward: -0.0939,                 loss: nan
agent1:                 episode reward: 0.0939,                 loss: 0.4121
Episode: 2541/10000 (25.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6366s / 145.5875 s
agent0:                 episode reward: 0.3925,                 loss: nan
agent1:                 episode reward: -0.3925,                 loss: 0.4109
Episode: 2551/10000 (25.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6441s / 146.2315 s
agent0:                 episode reward: 0.5553,                 loss: nan
agent1:                 episode reward: -0.5553,                 loss: 0.4109
Episode: 2561/10000 (25.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6369s / 146.8684 s
agent0:                 episode reward: 0.1354,                 loss: nan
agent1:                 episode reward: -0.1354,                 loss: 0.4110
Episode: 2571/10000 (25.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6531s / 147.5215 s
agent0:                 episode reward: -0.3139,                 loss: nan
agent1:                 episode reward: 0.3139,                 loss: 0.4126
Episode: 2581/10000 (25.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6515s / 148.1730 s
agent0:                 episode reward: 0.4740,                 loss: nan
agent1:                 episode reward: -0.4740,                 loss: 0.4145
Episode: 2591/10000 (25.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6446s / 148.8175 s
agent0:                 episode reward: 0.9401,                 loss: nan
agent1:                 episode reward: -0.9401,                 loss: 0.4118
Episode: 2601/10000 (26.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6676s / 149.4851 s
agent0:                 episode reward: -0.3831,                 loss: nan
agent1:                 episode reward: 0.3831,                 loss: 0.4136
Episode: 2611/10000 (26.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6459s / 150.1311 s
agent0:                 episode reward: 0.2118,                 loss: nan
agent1:                 episode reward: -0.2118,                 loss: 0.4135
Episode: 2621/10000 (26.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6431s / 150.7741 s
agent0:                 episode reward: 0.3009,                 loss: nan
agent1:                 episode reward: -0.3009,                 loss: 0.4134
Episode: 2631/10000 (26.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6452s / 151.4193 s
agent0:                 episode reward: -0.2709,                 loss: nan
agent1:                 episode reward: 0.2709,                 loss: 0.4136
Episode: 2641/10000 (26.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6928s / 152.1121 s
agent0:                 episode reward: 0.5335,                 loss: nan
agent1:                 episode reward: -0.5335,                 loss: 0.4130
Episode: 2651/10000 (26.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6412s / 152.7533 s
agent0:                 episode reward: 0.8712,                 loss: nan
agent1:                 episode reward: -0.8712,                 loss: 0.4128
Episode: 2661/10000 (26.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6491s / 153.4025 s
agent0:                 episode reward: 0.2783,                 loss: nan
agent1:                 episode reward: -0.2783,                 loss: 0.4114
Episode: 2671/10000 (26.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6469s / 154.0493 s
agent0:                 episode reward: 0.1793,                 loss: nan
agent1:                 episode reward: -0.1793,                 loss: 0.4143
Episode: 2681/10000 (26.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6508s / 154.7001 s
agent0:                 episode reward: 0.4636,                 loss: nan
agent1:                 episode reward: -0.4636,                 loss: 0.4147
Episode: 2691/10000 (26.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6458s / 155.3459 s
agent0:                 episode reward: 0.7349,                 loss: nan
agent1:                 episode reward: -0.7349,                 loss: 0.4149
Episode: 2701/10000 (27.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6448s / 155.9907 s
agent0:                 episode reward: -0.1426,                 loss: nan
agent1:                 episode reward: 0.1426,                 loss: 0.4168
Episode: 2711/10000 (27.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6688s / 156.6596 s
agent0:                 episode reward: 0.0162,                 loss: nan
agent1:                 episode reward: -0.0162,                 loss: 0.4146
Episode: 2721/10000 (27.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6538s / 157.3134 s
agent0:                 episode reward: 0.5322,                 loss: nan
agent1:                 episode reward: -0.5322,                 loss: 0.4144
Episode: 2731/10000 (27.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6456s / 157.9590 s
agent0:                 episode reward: 0.2786,                 loss: nan
agent1:                 episode reward: -0.2786,                 loss: 0.4146
Episode: 2741/10000 (27.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6574s / 158.6163 s
agent0:                 episode reward: -0.2476,                 loss: nan
agent1:                 episode reward: 0.2476,                 loss: 0.4150
Episode: 2751/10000 (27.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6653s / 159.2817 s
agent0:                 episode reward: 1.0999,                 loss: nan
agent1:                 episode reward: -1.0999,                 loss: 0.4148
Episode: 2761/10000 (27.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6622s / 159.9439 s
agent0:                 episode reward: 0.4668,                 loss: nan
agent1:                 episode reward: -0.4668,                 loss: 0.4163
Episode: 2771/10000 (27.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6577s / 160.6016 s
agent0:                 episode reward: 0.5223,                 loss: nan
agent1:                 episode reward: -0.5223,                 loss: 0.4172
Episode: 2781/10000 (27.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6524s / 161.2540 s
agent0:                 episode reward: 0.3411,                 loss: nan
agent1:                 episode reward: -0.3411,                 loss: 0.4186
Episode: 2791/10000 (27.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6939s / 161.9479 s
agent0:                 episode reward: -0.2630,                 loss: nan
agent1:                 episode reward: 0.2630,                 loss: 0.4171
Episode: 2801/10000 (28.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6784s / 162.6263 s
agent0:                 episode reward: -0.0092,                 loss: nan
agent1:                 episode reward: 0.0092,                 loss: 0.4159
Episode: 2811/10000 (28.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6568s / 163.2831 s
agent0:                 episode reward: 0.6407,                 loss: nan
agent1:                 episode reward: -0.6407,                 loss: 0.4157
Episode: 2821/10000 (28.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6483s / 163.9313 s
agent0:                 episode reward: 1.2480,                 loss: nan
agent1:                 episode reward: -1.2480,                 loss: 0.4172
Episode: 2831/10000 (28.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6557s / 164.5871 s
agent0:                 episode reward: -0.4173,                 loss: nan
agent1:                 episode reward: 0.4173,                 loss: 0.4168
Episode: 2841/10000 (28.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6588s / 165.2459 s
agent0:                 episode reward: 0.6754,                 loss: nan
agent1:                 episode reward: -0.6754,                 loss: 0.4165
Episode: 2851/10000 (28.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6517s / 165.8976 s
agent0:                 episode reward: -0.6028,                 loss: nan
agent1:                 episode reward: 0.6028,                 loss: 0.4162
Episode: 2861/10000 (28.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6596s / 166.5572 s
agent0:                 episode reward: 0.9345,                 loss: nan
agent1:                 episode reward: -0.9345,                 loss: 0.4163
Episode: 2871/10000 (28.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6585s / 167.2157 s
agent0:                 episode reward: 0.4756,                 loss: nan
agent1:                 episode reward: -0.4756,                 loss: 0.4182
Episode: 2881/10000 (28.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6562s / 167.8719 s
agent0:                 episode reward: 0.7753,                 loss: nan
agent1:                 episode reward: -0.7753,                 loss: 0.4178
Episode: 2891/10000 (28.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6718s / 168.5436 s
agent0:                 episode reward: 0.1874,                 loss: nan
agent1:                 episode reward: -0.1874,                 loss: 0.4195
Episode: 2901/10000 (29.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6611s / 169.2047 s
agent0:                 episode reward: 0.6025,                 loss: nan
agent1:                 episode reward: -0.6025,                 loss: 0.4193
Episode: 2911/10000 (29.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6599s / 169.8646 s
agent0:                 episode reward: -0.2099,                 loss: nan
agent1:                 episode reward: 0.2099,                 loss: 0.4181
Episode: 2921/10000 (29.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6570s / 170.5216 s
agent0:                 episode reward: -1.5397,                 loss: nan
agent1:                 episode reward: 1.5397,                 loss: 0.4175
Episode: 2931/10000 (29.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6540s / 171.1756 s
agent0:                 episode reward: -0.2013,                 loss: nan
agent1:                 episode reward: 0.2013,                 loss: 0.4177
Episode: 2941/10000 (29.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6642s / 171.8399 s
agent0:                 episode reward: 0.5300,                 loss: nan
agent1:                 episode reward: -0.5300,                 loss: 0.4175
Episode: 2951/10000 (29.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7029s / 172.5428 s
agent0:                 episode reward: 0.7375,                 loss: nan
agent1:                 episode reward: -0.7375,                 loss: 0.4199
Episode: 2961/10000 (29.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6686s / 173.2114 s
agent0:                 episode reward: 0.2260,                 loss: nan
agent1:                 episode reward: -0.2260,                 loss: 0.4179
Episode: 2971/10000 (29.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6583s / 173.8697 s
agent0:                 episode reward: -0.3169,                 loss: nan
agent1:                 episode reward: 0.3169,                 loss: 0.4172
Episode: 2981/10000 (29.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6850s / 174.5547 s
agent0:                 episode reward: -0.0920,                 loss: nan
agent1:                 episode reward: 0.0920,                 loss: 0.4169
Episode: 2991/10000 (29.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6599s / 175.2146 s
agent0:                 episode reward: 0.4756,                 loss: nan
agent1:                 episode reward: -0.4756,                 loss: 0.4154
Episode: 3001/10000 (30.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6633s / 175.8779 s
agent0:                 episode reward: 0.6019,                 loss: nan
agent1:                 episode reward: -0.6019,                 loss: 0.4167
Episode: 3011/10000 (30.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7437s / 176.6215 s
agent0:                 episode reward: 0.4551,                 loss: nan
agent1:                 episode reward: -0.4551,                 loss: 0.4169
Episode: 3021/10000 (30.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6722s / 177.2937 s
agent0:                 episode reward: 0.3725,                 loss: nan
agent1:                 episode reward: -0.3725,                 loss: 0.4155
Episode: 3031/10000 (30.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6753s / 177.9690 s
agent0:                 episode reward: 0.2987,                 loss: nan
agent1:                 episode reward: -0.2987,                 loss: 0.4180
Episode: 3041/10000 (30.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6894s / 178.6585 s
agent0:                 episode reward: -0.5133,                 loss: nan
agent1:                 episode reward: 0.5133,                 loss: 0.4168
Episode: 3051/10000 (30.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6698s / 179.3283 s
agent0:                 episode reward: 0.0092,                 loss: nan
agent1:                 episode reward: -0.0092,                 loss: 0.4175
Episode: 3061/10000 (30.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6561s / 179.9844 s
agent0:                 episode reward: 0.1098,                 loss: nan
agent1:                 episode reward: -0.1098,                 loss: 0.4160
Episode: 3071/10000 (30.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6906s / 180.6750 s
agent0:                 episode reward: -0.8742,                 loss: nan
agent1:                 episode reward: 0.8742,                 loss: 0.4123
Episode: 3081/10000 (30.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6673s / 181.3423 s
agent0:                 episode reward: 0.4104,                 loss: nan
agent1:                 episode reward: -0.4104,                 loss: 0.4087
Episode: 3091/10000 (30.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6610s / 182.0033 s
agent0:                 episode reward: -0.2453,                 loss: nan
agent1:                 episode reward: 0.2453,                 loss: 0.4086
Episode: 3101/10000 (31.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7055s / 182.7087 s
agent0:                 episode reward: 0.7619,                 loss: nan
agent1:                 episode reward: -0.7619,                 loss: 0.4085
Episode: 3111/10000 (31.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6604s / 183.3691 s
agent0:                 episode reward: 0.3139,                 loss: nan
agent1:                 episode reward: -0.3139,                 loss: 0.4092
Episode: 3121/10000 (31.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6707s / 184.0398 s
agent0:                 episode reward: 0.1325,                 loss: nan
agent1:                 episode reward: -0.1325,                 loss: 0.4084
Episode: 3131/10000 (31.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6672s / 184.7070 s
agent0:                 episode reward: 0.4673,                 loss: nan
agent1:                 episode reward: -0.4673,                 loss: 0.4083
Episode: 3141/10000 (31.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6807s / 185.3877 s
agent0:                 episode reward: -0.1575,                 loss: nan
agent1:                 episode reward: 0.1575,                 loss: 0.4083
Episode: 3151/10000 (31.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6689s / 186.0566 s
agent0:                 episode reward: 0.7297,                 loss: nan
agent1:                 episode reward: -0.7297,                 loss: 0.4086
Episode: 3161/10000 (31.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6800s / 186.7366 s
agent0:                 episode reward: 0.3910,                 loss: nan
agent1:                 episode reward: -0.3910,                 loss: 0.4080
Episode: 3171/10000 (31.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6611s / 187.3977 s
agent0:                 episode reward: 0.1637,                 loss: nan
agent1:                 episode reward: -0.1637,                 loss: 0.3928
Episode: 3181/10000 (31.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6700s / 188.0676 s
agent0:                 episode reward: -0.1340,                 loss: nan
agent1:                 episode reward: 0.1340,                 loss: 0.3839
Episode: 3191/10000 (31.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6688s / 188.7365 s
agent0:                 episode reward: 0.0933,                 loss: nan
agent1:                 episode reward: -0.0933,                 loss: 0.3829
Episode: 3201/10000 (32.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6828s / 189.4193 s
agent0:                 episode reward: -0.3585,                 loss: nan
agent1:                 episode reward: 0.3585,                 loss: 0.3827
Episode: 3211/10000 (32.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6796s / 190.0989 s
agent0:                 episode reward: -0.0233,                 loss: nan
agent1:                 episode reward: 0.0233,                 loss: 0.3840
Episode: 3221/10000 (32.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6737s / 190.7727 s
agent0:                 episode reward: 0.4454,                 loss: nan
agent1:                 episode reward: -0.4454,                 loss: 0.3825
Episode: 3231/10000 (32.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6750s / 191.4477 s
agent0:                 episode reward: 0.3132,                 loss: nan
agent1:                 episode reward: -0.3132,                 loss: 0.3823
Episode: 3241/10000 (32.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7001s / 192.1478 s
agent0:                 episode reward: 0.2856,                 loss: nan
agent1:                 episode reward: -0.2856,                 loss: 0.3818
Episode: 3251/10000 (32.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7640s / 192.9118 s
agent0:                 episode reward: -0.2780,                 loss: nan
agent1:                 episode reward: 0.2780,                 loss: 0.3820
Episode: 3261/10000 (32.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7067s / 193.6185 s
agent0:                 episode reward: -0.1480,                 loss: nan
agent1:                 episode reward: 0.1480,                 loss: 0.3807
Episode: 3271/10000 (32.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6803s / 194.2988 s
agent0:                 episode reward: 0.3078,                 loss: nan
agent1:                 episode reward: -0.3078,                 loss: 0.3720
Episode: 3281/10000 (32.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6707s / 194.9696 s
agent0:                 episode reward: 0.2106,                 loss: nan
agent1:                 episode reward: -0.2106,                 loss: 0.3689
Episode: 3291/10000 (32.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6905s / 195.6601 s
agent0:                 episode reward: -0.2885,                 loss: nan
agent1:                 episode reward: 0.2885,                 loss: 0.3681
Episode: 3301/10000 (33.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6664s / 196.3265 s
agent0:                 episode reward: -0.1234,                 loss: nan
agent1:                 episode reward: 0.1234,                 loss: 0.3661
Episode: 3311/10000 (33.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6847s / 197.0112 s
agent0:                 episode reward: 0.2255,                 loss: nan
agent1:                 episode reward: -0.2255,                 loss: 0.3672
Episode: 3321/10000 (33.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6705s / 197.6816 s
agent0:                 episode reward: -0.1470,                 loss: nan
agent1:                 episode reward: 0.1470,                 loss: 0.3657
Episode: 3331/10000 (33.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6782s / 198.3598 s
agent0:                 episode reward: 0.7267,                 loss: nan
agent1:                 episode reward: -0.7267,                 loss: 0.3669
Episode: 3341/10000 (33.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6729s / 199.0327 s
agent0:                 episode reward: -0.3066,                 loss: nan
agent1:                 episode reward: 0.3066,                 loss: 0.3664
Episode: 3351/10000 (33.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6940s / 199.7267 s
agent0:                 episode reward: -0.3953,                 loss: nan
agent1:                 episode reward: 0.3953,                 loss: 0.3658
Episode: 3361/10000 (33.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6747s / 200.4015 s
agent0:                 episode reward: -0.5889,                 loss: nan
agent1:                 episode reward: 0.5889,                 loss: 0.3678
Episode: 3371/10000 (33.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6821s / 201.0836 s
agent0:                 episode reward: 0.7815,                 loss: nan
agent1:                 episode reward: -0.7815,                 loss: 0.3669
Episode: 3381/10000 (33.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7127s / 201.7963 s
agent0:                 episode reward: 0.3662,                 loss: nan
agent1:                 episode reward: -0.3662,                 loss: 0.3656
Episode: 3391/10000 (33.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6882s / 202.4845 s
agent0:                 episode reward: -1.2900,                 loss: nan
agent1:                 episode reward: 1.2900,                 loss: 0.3653
Episode: 3401/10000 (34.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7524s / 203.2369 s
agent0:                 episode reward: 1.1318,                 loss: nan
agent1:                 episode reward: -1.1318,                 loss: 0.3648
Episode: 3411/10000 (34.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6838s / 203.9207 s
agent0:                 episode reward: -0.1321,                 loss: nan
agent1:                 episode reward: 0.1321,                 loss: 0.3662
Episode: 3421/10000 (34.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6990s / 204.6197 s
agent0:                 episode reward: 0.4143,                 loss: nan
agent1:                 episode reward: -0.4143,                 loss: 0.3660
Episode: 3431/10000 (34.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6888s / 205.3086 s
agent0:                 episode reward: 0.1952,                 loss: nan
agent1:                 episode reward: -0.1952,                 loss: 0.3656
Episode: 3441/10000 (34.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6789s / 205.9875 s
agent0:                 episode reward: 0.4830,                 loss: nan
agent1:                 episode reward: -0.4830,                 loss: 0.3634
Episode: 3451/10000 (34.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6891s / 206.6766 s
agent0:                 episode reward: 0.7209,                 loss: nan
agent1:                 episode reward: -0.7209,                 loss: 0.3625
Episode: 3461/10000 (34.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6848s / 207.3614 s
agent0:                 episode reward: -0.2664,                 loss: nan
agent1:                 episode reward: 0.2664,                 loss: 0.3646
Episode: 3471/10000 (34.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6932s / 208.0546 s
agent0:                 episode reward: 0.5243,                 loss: nan
agent1:                 episode reward: -0.5243,                 loss: 0.3668
Episode: 3481/10000 (34.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6927s / 208.7473 s
agent0:                 episode reward: 0.2195,                 loss: nan
agent1:                 episode reward: -0.2195,                 loss: 0.3672
Episode: 3491/10000 (34.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6885s / 209.4358 s
agent0:                 episode reward: 0.7143,                 loss: nan
agent1:                 episode reward: -0.7143,                 loss: 0.3656
Episode: 3501/10000 (35.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7195s / 210.1553 s
agent0:                 episode reward: 0.1208,                 loss: nan
agent1:                 episode reward: -0.1208,                 loss: 0.3652
Episode: 3511/10000 (35.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7155s / 210.8708 s
agent0:                 episode reward: 0.8188,                 loss: nan
agent1:                 episode reward: -0.8188,                 loss: 0.3651
Episode: 3521/10000 (35.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6854s / 211.5562 s
agent0:                 episode reward: 0.8799,                 loss: nan
agent1:                 episode reward: -0.8799,                 loss: 0.3655
Episode: 3531/10000 (35.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6929s / 212.2491 s
agent0:                 episode reward: 0.0584,                 loss: nan
agent1:                 episode reward: -0.0584,                 loss: 0.3626
Episode: 3541/10000 (35.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6858s / 212.9349 s
agent0:                 episode reward: -0.3624,                 loss: nan
agent1:                 episode reward: 0.3624,                 loss: 0.3620
Episode: 3551/10000 (35.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7644s / 213.6993 s
agent0:                 episode reward: -0.0352,                 loss: nan
agent1:                 episode reward: 0.0352,                 loss: 0.3630
Episode: 3561/10000 (35.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7044s / 214.4037 s
agent0:                 episode reward: -0.1755,                 loss: nan
agent1:                 episode reward: 0.1755,                 loss: 0.3645
Episode: 3571/10000 (35.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6961s / 215.0997 s
agent0:                 episode reward: 0.0711,                 loss: nan
agent1:                 episode reward: -0.0711,                 loss: 0.3623
Episode: 3581/10000 (35.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6875s / 215.7872 s
agent0:                 episode reward: 0.1447,                 loss: nan
agent1:                 episode reward: -0.1447,                 loss: 0.3631
Episode: 3591/10000 (35.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6930s / 216.4802 s
agent0:                 episode reward: 0.3216,                 loss: nan
agent1:                 episode reward: -0.3216,                 loss: 0.3624
Episode: 3601/10000 (36.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7067s / 217.1869 s
agent0:                 episode reward: 0.6875,                 loss: nan
agent1:                 episode reward: -0.6875,                 loss: 0.3654
Episode: 3611/10000 (36.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6927s / 217.8796 s
agent0:                 episode reward: -0.8049,                 loss: nan
agent1:                 episode reward: 0.8049,                 loss: 0.3633
Episode: 3621/10000 (36.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7040s / 218.5836 s
agent0:                 episode reward: -0.4752,                 loss: nan
agent1:                 episode reward: 0.4752,                 loss: 0.3630
Episode: 3631/10000 (36.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7004s / 219.2839 s
agent0:                 episode reward: -0.5251,                 loss: nan
agent1:                 episode reward: 0.5251,                 loss: 0.3604
Episode: 3641/10000 (36.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6972s / 219.9811 s
agent0:                 episode reward: 0.5245,                 loss: nan
agent1:                 episode reward: -0.5245,                 loss: 0.3633
Episode: 3651/10000 (36.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6927s / 220.6739 s
agent0:                 episode reward: 0.1258,                 loss: nan
agent1:                 episode reward: -0.1258,                 loss: 0.3599
Episode: 3661/10000 (36.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6959s / 221.3698 s
agent0:                 episode reward: 0.7688,                 loss: nan
agent1:                 episode reward: -0.7688,                 loss: 0.3631
Episode: 3671/10000 (36.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7288s / 222.0987 s
agent0:                 episode reward: 0.6322,                 loss: nan
agent1:                 episode reward: -0.6322,                 loss: 0.3642
Episode: 3681/10000 (36.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7101s / 222.8088 s
agent0:                 episode reward: 1.0635,                 loss: nan
agent1:                 episode reward: -1.0635,                 loss: 0.3659
Episode: 3691/10000 (36.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7413s / 223.5500 s
agent0:                 episode reward: 0.0651,                 loss: nan
agent1:                 episode reward: -0.0651,                 loss: 0.3659
Episode: 3701/10000 (37.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7026s / 224.2526 s
agent0:                 episode reward: 0.4703,                 loss: nan
agent1:                 episode reward: -0.4703,                 loss: 0.3673
Episode: 3711/10000 (37.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6985s / 224.9512 s
agent0:                 episode reward: 0.9282,                 loss: nan
agent1:                 episode reward: -0.9282,                 loss: 0.3663
Episode: 3721/10000 (37.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7053s / 225.6565 s
agent0:                 episode reward: 0.8309,                 loss: nan
agent1:                 episode reward: -0.8309,                 loss: 0.3653
Episode: 3731/10000 (37.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7164s / 226.3729 s
agent0:                 episode reward: -0.1906,                 loss: nan
agent1:                 episode reward: 0.1906,                 loss: 0.3670
Episode: 3741/10000 (37.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7036s / 227.0765 s
agent0:                 episode reward: -0.4363,                 loss: nan
agent1:                 episode reward: 0.4363,                 loss: 0.3670
Episode: 3751/10000 (37.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6945s / 227.7710 s
agent0:                 episode reward: 0.6361,                 loss: nan
agent1:                 episode reward: -0.6361,                 loss: 0.3654
Episode: 3761/10000 (37.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7077s / 228.4787 s
agent0:                 episode reward: 0.5878,                 loss: nan
agent1:                 episode reward: -0.5878,                 loss: 0.3642
Episode: 3771/10000 (37.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7093s / 229.1880 s
agent0:                 episode reward: -0.2638,                 loss: nan
agent1:                 episode reward: 0.2638,                 loss: 0.3671
Episode: 3781/10000 (37.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7019s / 229.8898 s
agent0:                 episode reward: -0.3927,                 loss: nan
agent1:                 episode reward: 0.3927,                 loss: 0.3668
Episode: 3791/10000 (37.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7134s / 230.6033 s
agent0:                 episode reward: -0.7072,                 loss: nan
agent1:                 episode reward: 0.7072,                 loss: 0.3687
Episode: 3801/10000 (38.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7044s / 231.3077 s
agent0:                 episode reward: -0.3942,                 loss: nan
agent1:                 episode reward: 0.3942,                 loss: 0.3678
Episode: 3811/10000 (38.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7191s / 232.0268 s
agent0:                 episode reward: -0.7319,                 loss: nan
agent1:                 episode reward: 0.7319,                 loss: 0.3667
Episode: 3821/10000 (38.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.6990s / 232.7258 s
agent0:                 episode reward: 1.1890,                 loss: nan
agent1:                 episode reward: -1.1890,                 loss: 0.3672
Episode: 3831/10000 (38.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7054s / 233.4312 s
agent0:                 episode reward: 0.3856,                 loss: nan
agent1:                 episode reward: -0.3856,                 loss: 0.3677
Episode: 3841/10000 (38.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7464s / 234.1776 s
agent0:                 episode reward: 0.4387,                 loss: nan
agent1:                 episode reward: -0.4387,                 loss: 0.3676
Episode: 3851/10000 (38.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7257s / 234.9033 s
agent0:                 episode reward: 0.1959,                 loss: nan
agent1:                 episode reward: -0.1959,                 loss: 0.3657
Episode: 3861/10000 (38.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7015s / 235.6048 s
agent0:                 episode reward: 0.0169,                 loss: nan
agent1:                 episode reward: -0.0169,                 loss: 0.3658
Episode: 3871/10000 (38.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7116s / 236.3164 s
agent0:                 episode reward: 1.2416,                 loss: nan
agent1:                 episode reward: -1.2416,                 loss: 0.3768
Episode: 3881/10000 (38.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7093s / 237.0256 s
agent0:                 episode reward: 0.9040,                 loss: nan
agent1:                 episode reward: -0.9040,                 loss: 0.3789
Episode: 3891/10000 (38.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7291s / 237.7547 s
agent0:                 episode reward: -0.0045,                 loss: nan
agent1:                 episode reward: 0.0045,                 loss: 0.3790
Episode: 3901/10000 (39.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7053s / 238.4600 s
agent0:                 episode reward: -0.3418,                 loss: nan
agent1:                 episode reward: 0.3418,                 loss: 0.3794
Episode: 3911/10000 (39.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7121s / 239.1721 s
agent0:                 episode reward: 0.5097,                 loss: nan
agent1:                 episode reward: -0.5097,                 loss: 0.3796
Episode: 3921/10000 (39.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7136s / 239.8856 s
agent0:                 episode reward: -0.4898,                 loss: nan
agent1:                 episode reward: 0.4898,                 loss: 0.3784
Episode: 3931/10000 (39.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7229s / 240.6086 s
agent0:                 episode reward: -0.3727,                 loss: nan
agent1:                 episode reward: 0.3727,                 loss: 0.3798
Episode: 3941/10000 (39.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7124s / 241.3210 s
agent0:                 episode reward: 0.0283,                 loss: nan
agent1:                 episode reward: -0.0283,                 loss: 0.3797
Episode: 3951/10000 (39.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7143s / 242.0353 s
agent0:                 episode reward: 0.7941,                 loss: nan
agent1:                 episode reward: -0.7941,                 loss: 0.3798
Episode: 3961/10000 (39.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7155s / 242.7508 s
agent0:                 episode reward: 0.1317,                 loss: nan
agent1:                 episode reward: -0.1317,                 loss: 0.3770
Episode: 3971/10000 (39.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7333s / 243.4841 s
agent0:                 episode reward: 1.1158,                 loss: nan
agent1:                 episode reward: -1.1158,                 loss: 0.3909
Episode: 3981/10000 (39.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7548s / 244.2389 s
agent0:                 episode reward: -0.0587,                 loss: nan
agent1:                 episode reward: 0.0587,                 loss: 0.3981
Episode: 3991/10000 (39.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7070s / 244.9459 s
agent0:                 episode reward: 0.4015,                 loss: nan
agent1:                 episode reward: -0.4015,                 loss: 0.3957
Episode: 4001/10000 (40.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7164s / 245.6623 s
agent0:                 episode reward: 0.7875,                 loss: nan
agent1:                 episode reward: -0.7875,                 loss: 0.3962
Episode: 4011/10000 (40.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7074s / 246.3697 s
agent0:                 episode reward: 0.2214,                 loss: nan
agent1:                 episode reward: -0.2214,                 loss: 0.3948
Episode: 4021/10000 (40.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7196s / 247.0893 s
agent0:                 episode reward: -0.0311,                 loss: nan
agent1:                 episode reward: 0.0311,                 loss: 0.3956
Episode: 4031/10000 (40.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7207s / 247.8100 s
agent0:                 episode reward: 0.3218,                 loss: nan
agent1:                 episode reward: -0.3218,                 loss: 0.3953
Episode: 4041/10000 (40.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7103s / 248.5203 s
agent0:                 episode reward: 0.3537,                 loss: nan
agent1:                 episode reward: -0.3537,                 loss: 0.3950
Episode: 4051/10000 (40.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7174s / 249.2377 s
agent0:                 episode reward: 0.0208,                 loss: nan
agent1:                 episode reward: -0.0208,                 loss: 0.3955
Episode: 4061/10000 (40.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7233s / 249.9610 s
agent0:                 episode reward: -0.2061,                 loss: nan
agent1:                 episode reward: 0.2061,                 loss: 0.3962
Episode: 4071/10000 (40.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7240s / 250.6850 s
agent0:                 episode reward: -0.0798,                 loss: nan
agent1:                 episode reward: 0.0798,                 loss: 0.4037
Episode: 4081/10000 (40.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7325s / 251.4175 s
agent0:                 episode reward: 1.4380,                 loss: nan
agent1:                 episode reward: -1.4380,                 loss: 0.4055
Episode: 4091/10000 (40.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7522s / 252.1697 s
agent0:                 episode reward: 0.1454,                 loss: nan
agent1:                 episode reward: -0.1454,                 loss: 0.4073
Episode: 4101/10000 (41.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7273s / 252.8970 s
agent0:                 episode reward: 0.4968,                 loss: nan
agent1:                 episode reward: -0.4968,                 loss: 0.4060
Episode: 4111/10000 (41.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7161s / 253.6132 s
agent0:                 episode reward: 1.3478,                 loss: nan
agent1:                 episode reward: -1.3478,                 loss: 0.4059
Episode: 4121/10000 (41.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7818s / 254.3950 s
agent0:                 episode reward: 1.1677,                 loss: nan
agent1:                 episode reward: -1.1677,                 loss: 0.4062
Episode: 4131/10000 (41.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7545s / 255.1495 s
agent0:                 episode reward: 0.6516,                 loss: nan
agent1:                 episode reward: -0.6516,                 loss: 0.4055
Episode: 4141/10000 (41.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8154s / 255.9648 s
agent0:                 episode reward: 0.2701,                 loss: nan
agent1:                 episode reward: -0.2701,                 loss: 0.4056
Episode: 4151/10000 (41.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7141s / 256.6789 s
agent0:                 episode reward: 1.0377,                 loss: nan
agent1:                 episode reward: -1.0377,                 loss: 0.4036
Episode: 4161/10000 (41.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7140s / 257.3929 s
agent0:                 episode reward: 0.2697,                 loss: nan
agent1:                 episode reward: -0.2697,                 loss: 0.4047
Episode: 4171/10000 (41.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7162s / 258.1090 s
agent0:                 episode reward: 0.6835,                 loss: nan
agent1:                 episode reward: -0.6835,                 loss: 0.4070
Episode: 4181/10000 (41.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7301s / 258.8392 s
agent0:                 episode reward: 0.3547,                 loss: nan
agent1:                 episode reward: -0.3547,                 loss: 0.4040
Episode: 4191/10000 (41.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7521s / 259.5913 s
agent0:                 episode reward: -0.0736,                 loss: nan
agent1:                 episode reward: 0.0736,                 loss: 0.4049
Episode: 4201/10000 (42.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7641s / 260.3554 s
agent0:                 episode reward: 1.0927,                 loss: nan
agent1:                 episode reward: -1.0927,                 loss: 0.4023
Episode: 4211/10000 (42.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7305s / 261.0858 s
agent0:                 episode reward: 0.1642,                 loss: nan
agent1:                 episode reward: -0.1642,                 loss: 0.4033
Episode: 4221/10000 (42.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7329s / 261.8187 s
agent0:                 episode reward: 0.2980,                 loss: nan
agent1:                 episode reward: -0.2980,                 loss: 0.4019
Episode: 4231/10000 (42.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7417s / 262.5605 s
agent0:                 episode reward: 0.6195,                 loss: nan
agent1:                 episode reward: -0.6195,                 loss: 0.4007
Episode: 4241/10000 (42.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7317s / 263.2922 s
agent0:                 episode reward: -0.4920,                 loss: nan
agent1:                 episode reward: 0.4920,                 loss: 0.4009
Episode: 4251/10000 (42.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7297s / 264.0219 s
agent0:                 episode reward: 0.4816,                 loss: nan
agent1:                 episode reward: -0.4816,                 loss: 0.4004
Episode: 4261/10000 (42.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7726s / 264.7946 s
agent0:                 episode reward: 0.2448,                 loss: nan
agent1:                 episode reward: -0.2448,                 loss: 0.4003
Episode: 4271/10000 (42.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7737s / 265.5683 s
agent0:                 episode reward: 0.5670,                 loss: nan
agent1:                 episode reward: -0.5670,                 loss: 0.3840
Episode: 4281/10000 (42.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7315s / 266.2998 s
agent0:                 episode reward: -0.2513,                 loss: nan
agent1:                 episode reward: 0.2513,                 loss: 0.3733
Episode: 4291/10000 (42.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7239s / 267.0237 s
agent0:                 episode reward: 0.1076,                 loss: nan
agent1:                 episode reward: -0.1076,                 loss: 0.3723
Episode: 4301/10000 (43.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7305s / 267.7542 s
agent0:                 episode reward: 0.1431,                 loss: nan
agent1:                 episode reward: -0.1431,                 loss: 0.3732
Episode: 4311/10000 (43.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7485s / 268.5026 s
agent0:                 episode reward: 0.2604,                 loss: nan
agent1:                 episode reward: -0.2604,                 loss: 0.3703
Episode: 4321/10000 (43.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7526s / 269.2552 s
agent0:                 episode reward: -0.1971,                 loss: nan
agent1:                 episode reward: 0.1971,                 loss: 0.3697
Episode: 4331/10000 (43.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7213s / 269.9764 s
agent0:                 episode reward: 0.3143,                 loss: nan
agent1:                 episode reward: -0.3143,                 loss: 0.3709
Episode: 4341/10000 (43.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7357s / 270.7122 s
agent0:                 episode reward: -0.9395,                 loss: nan
agent1:                 episode reward: 0.9395,                 loss: 0.3712
Episode: 4351/10000 (43.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7445s / 271.4567 s
agent0:                 episode reward: 0.8015,                 loss: nan
agent1:                 episode reward: -0.8015,                 loss: 0.3708
Episode: 4361/10000 (43.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7409s / 272.1976 s
agent0:                 episode reward: 0.2494,                 loss: nan
agent1:                 episode reward: -0.2494,                 loss: 0.3700
Episode: 4371/10000 (43.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7284s / 272.9260 s
agent0:                 episode reward: 0.0664,                 loss: nan
agent1:                 episode reward: -0.0664,                 loss: 0.3369
Episode: 4381/10000 (43.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7392s / 273.6652 s
agent0:                 episode reward: -0.1976,                 loss: nan
agent1:                 episode reward: 0.1976,                 loss: 0.3182
Episode: 4391/10000 (43.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7509s / 274.4161 s
agent0:                 episode reward: 0.0329,                 loss: nan
agent1:                 episode reward: -0.0329,                 loss: 0.3176
Episode: 4401/10000 (44.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7891s / 275.2052 s
agent0:                 episode reward: 0.5344,                 loss: nan
agent1:                 episode reward: -0.5344,                 loss: 0.3190
Episode: 4411/10000 (44.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7330s / 275.9382 s
agent0:                 episode reward: 0.1195,                 loss: nan
agent1:                 episode reward: -0.1195,                 loss: 0.3151
Episode: 4421/10000 (44.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7512s / 276.6894 s
agent0:                 episode reward: -1.0714,                 loss: nan
agent1:                 episode reward: 1.0714,                 loss: 0.3167
Episode: 4431/10000 (44.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7439s / 277.4333 s
agent0:                 episode reward: -0.3362,                 loss: nan
agent1:                 episode reward: 0.3362,                 loss: 0.3154
Episode: 4441/10000 (44.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7404s / 278.1738 s
agent0:                 episode reward: -0.2359,                 loss: nan
agent1:                 episode reward: 0.2359,                 loss: 0.3144
Episode: 4451/10000 (44.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7465s / 278.9202 s
agent0:                 episode reward: 0.5712,                 loss: nan
agent1:                 episode reward: -0.5712,                 loss: 0.3164
Episode: 4461/10000 (44.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7387s / 279.6589 s
agent0:                 episode reward: 0.5049,                 loss: nan
agent1:                 episode reward: -0.5049,                 loss: 0.3172
Episode: 4471/10000 (44.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7564s / 280.4153 s
agent0:                 episode reward: -0.1839,                 loss: nan
agent1:                 episode reward: 0.1839,                 loss: 0.2985
Episode: 4481/10000 (44.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7496s / 281.1650 s
agent0:                 episode reward: -1.0925,                 loss: nan
agent1:                 episode reward: 1.0925,                 loss: 0.2913
Episode: 4491/10000 (44.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7451s / 281.9101 s
agent0:                 episode reward: 0.5346,                 loss: nan
agent1:                 episode reward: -0.5346,                 loss: 0.2891
Episode: 4501/10000 (45.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7627s / 282.6728 s
agent0:                 episode reward: -0.1026,                 loss: nan
agent1:                 episode reward: 0.1026,                 loss: 0.2906
Episode: 4511/10000 (45.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7456s / 283.4184 s
agent0:                 episode reward: 0.5953,                 loss: nan
agent1:                 episode reward: -0.5953,                 loss: 0.2892
Episode: 4521/10000 (45.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7614s / 284.1798 s
agent0:                 episode reward: 0.3018,                 loss: nan
agent1:                 episode reward: -0.3018,                 loss: 0.2878
Episode: 4531/10000 (45.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8207s / 285.0005 s
agent0:                 episode reward: -0.5004,                 loss: nan
agent1:                 episode reward: 0.5004,                 loss: 0.2854
Episode: 4541/10000 (45.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7654s / 285.7659 s
agent0:                 episode reward: -1.0032,                 loss: nan
agent1:                 episode reward: 1.0032,                 loss: 0.2860
Episode: 4551/10000 (45.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7528s / 286.5187 s
agent0:                 episode reward: 0.1222,                 loss: nan
agent1:                 episode reward: -0.1222,                 loss: 0.2892
Episode: 4561/10000 (45.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7483s / 287.2670 s
agent0:                 episode reward: 1.0883,                 loss: nan
agent1:                 episode reward: -1.0883,                 loss: 0.2871
Episode: 4571/10000 (45.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7506s / 288.0176 s
agent0:                 episode reward: 0.3726,                 loss: nan
agent1:                 episode reward: -0.3726,                 loss: 0.2991
Episode: 4581/10000 (45.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7481s / 288.7657 s
agent0:                 episode reward: 0.7432,                 loss: nan
agent1:                 episode reward: -0.7432,                 loss: 0.3074
Episode: 4591/10000 (45.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7483s / 289.5140 s
agent0:                 episode reward: 0.7533,                 loss: nan
agent1:                 episode reward: -0.7533,                 loss: 0.3063
Episode: 4601/10000 (46.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7663s / 290.2803 s
agent0:                 episode reward: 0.5076,                 loss: nan
agent1:                 episode reward: -0.5076,                 loss: 0.3053
Episode: 4611/10000 (46.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7574s / 291.0376 s
agent0:                 episode reward: 0.7156,                 loss: nan
agent1:                 episode reward: -0.7156,                 loss: 0.3032
Episode: 4621/10000 (46.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7486s / 291.7863 s
agent0:                 episode reward: 1.6616,                 loss: nan
agent1:                 episode reward: -1.6616,                 loss: 0.3024
Episode: 4631/10000 (46.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7667s / 292.5529 s
agent0:                 episode reward: 0.5828,                 loss: nan
agent1:                 episode reward: -0.5828,                 loss: 0.3008
Episode: 4641/10000 (46.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7646s / 293.3176 s
agent0:                 episode reward: -0.0623,                 loss: nan
agent1:                 episode reward: 0.0623,                 loss: 0.3055
Episode: 4651/10000 (46.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7526s / 294.0702 s
agent0:                 episode reward: -0.5405,                 loss: nan
agent1:                 episode reward: 0.5405,                 loss: 0.3033
Episode: 4661/10000 (46.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7486s / 294.8188 s
agent0:                 episode reward: 0.3573,                 loss: nan
agent1:                 episode reward: -0.3573,                 loss: 0.3008
Episode: 4671/10000 (46.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8182s / 295.6369 s
agent0:                 episode reward: 0.0709,                 loss: nan
agent1:                 episode reward: -0.0709,                 loss: 0.3184
Episode: 4681/10000 (46.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7529s / 296.3898 s
agent0:                 episode reward: 0.3900,                 loss: nan
agent1:                 episode reward: -0.3900,                 loss: 0.3189
Episode: 4691/10000 (46.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7528s / 297.1426 s
agent0:                 episode reward: 0.4722,                 loss: nan
agent1:                 episode reward: -0.4722,                 loss: 0.3195
Episode: 4701/10000 (47.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7481s / 297.8907 s
agent0:                 episode reward: 0.4551,                 loss: nan
agent1:                 episode reward: -0.4551,                 loss: 0.3212
Episode: 4711/10000 (47.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7579s / 298.6486 s
agent0:                 episode reward: -0.4224,                 loss: nan
agent1:                 episode reward: 0.4224,                 loss: 0.3194
Episode: 4721/10000 (47.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7479s / 299.3965 s
agent0:                 episode reward: 0.2890,                 loss: nan
agent1:                 episode reward: -0.2890,                 loss: 0.3196
Episode: 4731/10000 (47.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7502s / 300.1467 s
agent0:                 episode reward: 1.0720,                 loss: nan
agent1:                 episode reward: -1.0720,                 loss: 0.3202
Episode: 4741/10000 (47.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7816s / 300.9283 s
agent0:                 episode reward: -0.0259,                 loss: nan
agent1:                 episode reward: 0.0259,                 loss: 0.3151
Episode: 4751/10000 (47.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7759s / 301.7042 s
agent0:                 episode reward: -0.3280,                 loss: nan
agent1:                 episode reward: 0.3280,                 loss: 0.3188
Episode: 4761/10000 (47.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7652s / 302.4694 s
agent0:                 episode reward: -0.5710,                 loss: nan
agent1:                 episode reward: 0.5710,                 loss: 0.3165
Episode: 4771/10000 (47.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7610s / 303.2304 s
agent0:                 episode reward: -0.1683,                 loss: nan
agent1:                 episode reward: 0.1683,                 loss: 0.3291
Episode: 4781/10000 (47.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7605s / 303.9909 s
agent0:                 episode reward: -0.0894,                 loss: nan
agent1:                 episode reward: 0.0894,                 loss: 0.3331
Episode: 4791/10000 (47.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7587s / 304.7496 s
agent0:                 episode reward: 0.4657,                 loss: nan
agent1:                 episode reward: -0.4657,                 loss: 0.3323
Episode: 4801/10000 (48.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7988s / 305.5484 s
agent0:                 episode reward: -0.3482,                 loss: nan
agent1:                 episode reward: 0.3482,                 loss: 0.3321
Episode: 4811/10000 (48.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7636s / 306.3120 s
agent0:                 episode reward: -0.6117,                 loss: nan
agent1:                 episode reward: 0.6117,                 loss: 0.3314
Episode: 4821/10000 (48.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7606s / 307.0726 s
agent0:                 episode reward: -0.6742,                 loss: nan
agent1:                 episode reward: 0.6742,                 loss: 0.3281
Episode: 4831/10000 (48.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7807s / 307.8533 s
agent0:                 episode reward: 0.3401,                 loss: nan
agent1:                 episode reward: -0.3401,                 loss: 0.3311
Episode: 4841/10000 (48.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7618s / 308.6151 s
agent0:                 episode reward: 0.2951,                 loss: nan
agent1:                 episode reward: -0.2951,                 loss: 0.3314
Episode: 4851/10000 (48.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7844s / 309.3995 s
agent0:                 episode reward: -0.3941,                 loss: nan
agent1:                 episode reward: 0.3941,                 loss: 0.3314
Episode: 4861/10000 (48.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7646s / 310.1641 s
agent0:                 episode reward: -0.3426,                 loss: nan
agent1:                 episode reward: 0.3426,                 loss: 0.3303
Episode: 4871/10000 (48.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7628s / 310.9269 s
agent0:                 episode reward: -0.5744,                 loss: nan
agent1:                 episode reward: 0.5744,                 loss: 0.3349
Episode: 4881/10000 (48.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7769s / 311.7038 s
agent0:                 episode reward: -0.3263,                 loss: nan
agent1:                 episode reward: 0.3263,                 loss: 0.3364
Episode: 4891/10000 (48.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7552s / 312.4589 s
agent0:                 episode reward: -0.2757,                 loss: nan
agent1:                 episode reward: 0.2757,                 loss: 0.3338
Episode: 4901/10000 (49.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7632s / 313.2222 s
agent0:                 episode reward: -0.3514,                 loss: nan
agent1:                 episode reward: 0.3514,                 loss: 0.3353
Episode: 4911/10000 (49.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7799s / 314.0020 s
agent0:                 episode reward: 0.1569,                 loss: nan
agent1:                 episode reward: -0.1569,                 loss: 0.3353
Episode: 4921/10000 (49.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7687s / 314.7708 s
agent0:                 episode reward: 0.1696,                 loss: nan
agent1:                 episode reward: -0.1696,                 loss: 0.3320
Episode: 4931/10000 (49.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7701s / 315.5408 s
agent0:                 episode reward: -0.2481,                 loss: nan
agent1:                 episode reward: 0.2481,                 loss: 0.3311
Episode: 4941/10000 (49.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8341s / 316.3749 s
agent0:                 episode reward: 0.2978,                 loss: nan
agent1:                 episode reward: -0.2978,                 loss: 0.3322
Episode: 4951/10000 (49.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7812s / 317.1562 s
agent0:                 episode reward: -0.9107,                 loss: nan
agent1:                 episode reward: 0.9107,                 loss: 0.3340
Episode: 4961/10000 (49.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7861s / 317.9423 s
agent0:                 episode reward: -0.4509,                 loss: nan
agent1:                 episode reward: 0.4509,                 loss: 0.3342
Episode: 4971/10000 (49.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7641s / 318.7064 s
agent0:                 episode reward: -0.4345,                 loss: nan
agent1:                 episode reward: 0.4345,                 loss: 0.3447
Episode: 4981/10000 (49.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7743s / 319.4806 s
agent0:                 episode reward: -0.1448,                 loss: nan
agent1:                 episode reward: 0.1448,                 loss: 0.3463
Episode: 4991/10000 (49.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7705s / 320.2512 s
agent0:                 episode reward: -0.2093,                 loss: nan
agent1:                 episode reward: 0.2093,                 loss: 0.3465
Episode: 5001/10000 (50.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7620s / 321.0132 s
agent0:                 episode reward: 0.2936,                 loss: nan
agent1:                 episode reward: -0.2936,                 loss: 0.3448
Episode: 5011/10000 (50.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7736s / 321.7867 s
agent0:                 episode reward: -0.3534,                 loss: nan
agent1:                 episode reward: 0.3534,                 loss: 0.3450
Episode: 5021/10000 (50.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7732s / 322.5600 s
agent0:                 episode reward: 0.1638,                 loss: nan
agent1:                 episode reward: -0.1638,                 loss: 0.3446
Episode: 5031/10000 (50.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7689s / 323.3289 s
agent0:                 episode reward: 0.2280,                 loss: nan
agent1:                 episode reward: -0.2280,                 loss: 0.3451
Episode: 5041/10000 (50.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7698s / 324.0986 s
agent0:                 episode reward: 0.6623,                 loss: nan
agent1:                 episode reward: -0.6623,                 loss: 0.3419
Episode: 5051/10000 (50.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7775s / 324.8761 s
agent0:                 episode reward: 0.5444,                 loss: nan
agent1:                 episode reward: -0.5444,                 loss: 0.3435
Episode: 5061/10000 (50.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7745s / 325.6506 s
agent0:                 episode reward: -0.1862,                 loss: nan
agent1:                 episode reward: 0.1862,                 loss: 0.3447
Episode: 5071/10000 (50.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8329s / 326.4835 s
agent0:                 episode reward: 0.1750,                 loss: nan
agent1:                 episode reward: -0.1750,                 loss: 0.3625
Episode: 5081/10000 (50.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7849s / 327.2684 s
agent0:                 episode reward: 0.7133,                 loss: nan
agent1:                 episode reward: -0.7133,                 loss: 0.3679
Episode: 5091/10000 (50.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7671s / 328.0355 s
agent0:                 episode reward: -0.1930,                 loss: nan
agent1:                 episode reward: 0.1930,                 loss: 0.3679
Episode: 5101/10000 (51.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7849s / 328.8203 s
agent0:                 episode reward: 0.3645,                 loss: nan
agent1:                 episode reward: -0.3645,                 loss: 0.3677
Episode: 5111/10000 (51.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7692s / 329.5896 s
agent0:                 episode reward: 0.2751,                 loss: nan
agent1:                 episode reward: -0.2751,                 loss: 0.3687
Episode: 5121/10000 (51.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7726s / 330.3622 s
agent0:                 episode reward: -0.4017,                 loss: nan
agent1:                 episode reward: 0.4017,                 loss: 0.3670
Episode: 5131/10000 (51.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7692s / 331.1314 s
agent0:                 episode reward: -0.6135,                 loss: nan
agent1:                 episode reward: 0.6135,                 loss: 0.3661
Episode: 5141/10000 (51.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8069s / 331.9383 s
agent0:                 episode reward: -0.4510,                 loss: nan
agent1:                 episode reward: 0.4510,                 loss: 0.3652
Episode: 5151/10000 (51.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7760s / 332.7143 s
agent0:                 episode reward: 0.0555,                 loss: nan
agent1:                 episode reward: -0.0555,                 loss: 0.3658
Episode: 5161/10000 (51.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7706s / 333.4849 s
agent0:                 episode reward: -0.0967,                 loss: nan
agent1:                 episode reward: 0.0967,                 loss: 0.3649
Episode: 5171/10000 (51.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7861s / 334.2710 s
agent0:                 episode reward: 0.3785,                 loss: nan
agent1:                 episode reward: -0.3785,                 loss: 0.3807
Episode: 5181/10000 (51.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7696s / 335.0406 s
agent0:                 episode reward: -0.5804,                 loss: nan
agent1:                 episode reward: 0.5804,                 loss: 0.3865
Episode: 5191/10000 (51.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7759s / 335.8165 s
agent0:                 episode reward: -0.5840,                 loss: nan
agent1:                 episode reward: 0.5840,                 loss: 0.3852
Episode: 5201/10000 (52.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8065s / 336.6230 s
agent0:                 episode reward: 0.1714,                 loss: nan
agent1:                 episode reward: -0.1714,                 loss: 0.3854
Episode: 5211/10000 (52.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7818s / 337.4048 s
agent0:                 episode reward: -0.1867,                 loss: nan
agent1:                 episode reward: 0.1867,                 loss: 0.3848
Episode: 5221/10000 (52.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7764s / 338.1812 s
agent0:                 episode reward: 0.3148,                 loss: nan
agent1:                 episode reward: -0.3148,                 loss: 0.3830
Episode: 5231/10000 (52.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7764s / 338.9576 s
agent0:                 episode reward: -0.6564,                 loss: nan
agent1:                 episode reward: 0.6564,                 loss: 0.3835
Episode: 5241/10000 (52.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7855s / 339.7431 s
agent0:                 episode reward: 1.0294,                 loss: nan
agent1:                 episode reward: -1.0294,                 loss: 0.3815
Episode: 5251/10000 (52.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7862s / 340.5293 s
agent0:                 episode reward: 0.7429,                 loss: nan
agent1:                 episode reward: -0.7429,                 loss: 0.3818
Episode: 5261/10000 (52.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7754s / 341.3047 s
agent0:                 episode reward: -1.1079,                 loss: nan
agent1:                 episode reward: 1.1079,                 loss: 0.3804
Episode: 5271/10000 (52.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7795s / 342.0843 s
agent0:                 episode reward: 0.8006,                 loss: nan
agent1:                 episode reward: -0.8006,                 loss: 0.3690
Episode: 5281/10000 (52.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7854s / 342.8696 s
agent0:                 episode reward: 0.3644,                 loss: nan
agent1:                 episode reward: -0.3644,                 loss: 0.3583
Episode: 5291/10000 (52.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7883s / 343.6579 s
agent0:                 episode reward: 0.1361,                 loss: nan
agent1:                 episode reward: -0.1361,                 loss: 0.3564
Episode: 5301/10000 (53.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7768s / 344.4347 s
agent0:                 episode reward: 0.6949,                 loss: nan
agent1:                 episode reward: -0.6949,                 loss: 0.3535
Episode: 5311/10000 (53.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7797s / 345.2143 s
agent0:                 episode reward: -0.0131,                 loss: nan
agent1:                 episode reward: 0.0131,                 loss: 0.3537
Episode: 5321/10000 (53.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7839s / 345.9983 s
agent0:                 episode reward: -1.4784,                 loss: nan
agent1:                 episode reward: 1.4784,                 loss: 0.3550
Episode: 5331/10000 (53.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8392s / 346.8375 s
agent0:                 episode reward: -0.3034,                 loss: nan
agent1:                 episode reward: 0.3034,                 loss: 0.3543
Episode: 5341/10000 (53.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7912s / 347.6287 s
agent0:                 episode reward: -1.6093,                 loss: nan
agent1:                 episode reward: 1.6093,                 loss: 0.3547
Episode: 5351/10000 (53.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7924s / 348.4211 s
agent0:                 episode reward: -0.3093,                 loss: nan
agent1:                 episode reward: 0.3093,                 loss: 0.3525
Episode: 5361/10000 (53.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7878s / 349.2089 s
agent0:                 episode reward: 0.6209,                 loss: nan
agent1:                 episode reward: -0.6209,                 loss: 0.3557
Episode: 5371/10000 (53.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7949s / 350.0038 s
agent0:                 episode reward: 0.5817,                 loss: nan
agent1:                 episode reward: -0.5817,                 loss: 0.3157
Episode: 5381/10000 (53.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7864s / 350.7902 s
agent0:                 episode reward: 0.2073,                 loss: nan
agent1:                 episode reward: -0.2073,                 loss: 0.2930
Episode: 5391/10000 (53.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8022s / 351.5923 s
agent0:                 episode reward: 0.2456,                 loss: nan
agent1:                 episode reward: -0.2456,                 loss: 0.2911
Episode: 5401/10000 (54.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7837s / 352.3760 s
agent0:                 episode reward: 0.1763,                 loss: nan
agent1:                 episode reward: -0.1763,                 loss: 0.2919
Episode: 5411/10000 (54.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8048s / 353.1808 s
agent0:                 episode reward: 0.4404,                 loss: nan
agent1:                 episode reward: -0.4404,                 loss: 0.2921
Episode: 5421/10000 (54.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7849s / 353.9657 s
agent0:                 episode reward: -0.1560,                 loss: nan
agent1:                 episode reward: 0.1560,                 loss: 0.2901
Episode: 5431/10000 (54.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7910s / 354.7567 s
agent0:                 episode reward: 0.2494,                 loss: nan
agent1:                 episode reward: -0.2494,                 loss: 0.2915
Episode: 5441/10000 (54.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7866s / 355.5433 s
agent0:                 episode reward: 0.7747,                 loss: nan
agent1:                 episode reward: -0.7747,                 loss: 0.2914
Episode: 5451/10000 (54.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7959s / 356.3392 s
agent0:                 episode reward: -0.9834,                 loss: nan
agent1:                 episode reward: 0.9834,                 loss: 0.2913
Episode: 5461/10000 (54.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8467s / 357.1859 s
agent0:                 episode reward: 0.1858,                 loss: nan
agent1:                 episode reward: -0.1858,                 loss: 0.2886
Episode: 5471/10000 (54.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7945s / 357.9804 s
agent0:                 episode reward: 0.0926,                 loss: nan
agent1:                 episode reward: -0.0926,                 loss: 0.2735
Episode: 5481/10000 (54.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8015s / 358.7819 s
agent0:                 episode reward: 0.7797,                 loss: nan
agent1:                 episode reward: -0.7797,                 loss: 0.2611
Episode: 5491/10000 (54.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8021s / 359.5840 s
agent0:                 episode reward: 0.4182,                 loss: nan
agent1:                 episode reward: -0.4182,                 loss: 0.2629
Episode: 5501/10000 (55.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7978s / 360.3818 s
agent0:                 episode reward: 0.4007,                 loss: nan
agent1:                 episode reward: -0.4007,                 loss: 0.2629
Episode: 5511/10000 (55.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7903s / 361.1721 s
agent0:                 episode reward: 0.1313,                 loss: nan
agent1:                 episode reward: -0.1313,                 loss: 0.2638
Episode: 5521/10000 (55.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8027s / 361.9748 s
agent0:                 episode reward: 0.0468,                 loss: nan
agent1:                 episode reward: -0.0468,                 loss: 0.2613
Episode: 5531/10000 (55.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7895s / 362.7643 s
agent0:                 episode reward: 0.1516,                 loss: nan
agent1:                 episode reward: -0.1516,                 loss: 0.2585
Episode: 5541/10000 (55.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7944s / 363.5587 s
agent0:                 episode reward: 0.7074,                 loss: nan
agent1:                 episode reward: -0.7074,                 loss: 0.2603
Episode: 5551/10000 (55.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7885s / 364.3473 s
agent0:                 episode reward: 0.8348,                 loss: nan
agent1:                 episode reward: -0.8348,                 loss: 0.2589
Episode: 5561/10000 (55.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7961s / 365.1433 s
agent0:                 episode reward: 0.4358,                 loss: nan
agent1:                 episode reward: -0.4358,                 loss: 0.2604
Episode: 5571/10000 (55.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8039s / 365.9472 s
agent0:                 episode reward: 0.4455,                 loss: nan
agent1:                 episode reward: -0.4455,                 loss: 0.2762
Episode: 5581/10000 (55.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8029s / 366.7501 s
agent0:                 episode reward: 0.7192,                 loss: nan
agent1:                 episode reward: -0.7192,                 loss: 0.2769
Episode: 5591/10000 (55.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8639s / 367.6140 s
agent0:                 episode reward: 0.5949,                 loss: nan
agent1:                 episode reward: -0.5949,                 loss: 0.2756
Episode: 5601/10000 (56.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8071s / 368.4211 s
agent0:                 episode reward: -0.0250,                 loss: nan
agent1:                 episode reward: 0.0250,                 loss: 0.2773
Episode: 5611/10000 (56.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7942s / 369.2153 s
agent0:                 episode reward: 0.0177,                 loss: nan
agent1:                 episode reward: -0.0177,                 loss: 0.2769
Episode: 5621/10000 (56.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7984s / 370.0137 s
agent0:                 episode reward: -0.3008,                 loss: nan
agent1:                 episode reward: 0.3008,                 loss: 0.2756
Episode: 5631/10000 (56.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8297s / 370.8434 s
agent0:                 episode reward: 0.0059,                 loss: nan
agent1:                 episode reward: -0.0059,                 loss: 0.2726
Episode: 5641/10000 (56.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8226s / 371.6660 s
agent0:                 episode reward: 0.7972,                 loss: nan
agent1:                 episode reward: -0.7972,                 loss: 0.2758
Episode: 5651/10000 (56.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8096s / 372.4756 s
agent0:                 episode reward: -0.4593,                 loss: nan
agent1:                 episode reward: 0.4593,                 loss: 0.2758
Episode: 5661/10000 (56.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8165s / 373.2922 s
agent0:                 episode reward: 0.6594,                 loss: nan
agent1:                 episode reward: -0.6594,                 loss: 0.2743
Episode: 5671/10000 (56.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7994s / 374.0916 s
agent0:                 episode reward: -0.1860,                 loss: nan
agent1:                 episode reward: 0.1860,                 loss: 0.2991
Episode: 5681/10000 (56.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.7985s / 374.8901 s
agent0:                 episode reward: 0.9781,                 loss: nan
agent1:                 episode reward: -0.9781,                 loss: 0.3013
Episode: 5691/10000 (56.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8048s / 375.6949 s
agent0:                 episode reward: -0.3609,                 loss: nan
agent1:                 episode reward: 0.3609,                 loss: 0.3017
Episode: 5701/10000 (57.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8177s / 376.5126 s
agent0:                 episode reward: -0.4799,                 loss: nan
agent1:                 episode reward: 0.4799,                 loss: 0.2987
Episode: 5711/10000 (57.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8559s / 377.3685 s
agent0:                 episode reward: 0.1443,                 loss: nan
agent1:                 episode reward: -0.1443,                 loss: 0.3000
Episode: 5721/10000 (57.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8045s / 378.1731 s
agent0:                 episode reward: -0.1460,                 loss: nan
agent1:                 episode reward: 0.1460,                 loss: 0.3005
Episode: 5731/10000 (57.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8018s / 378.9748 s
agent0:                 episode reward: 0.7268,                 loss: nan
agent1:                 episode reward: -0.7268,                 loss: 0.3000
Episode: 5741/10000 (57.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8250s / 379.7999 s
agent0:                 episode reward: 0.1314,                 loss: nan
agent1:                 episode reward: -0.1314,                 loss: 0.3007
Episode: 5751/10000 (57.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8008s / 380.6007 s
agent0:                 episode reward: -0.8954,                 loss: nan
agent1:                 episode reward: 0.8954,                 loss: 0.2975
Episode: 5761/10000 (57.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8272s / 381.4279 s
agent0:                 episode reward: -0.2168,                 loss: nan
agent1:                 episode reward: 0.2168,                 loss: 0.2978
Episode: 5771/10000 (57.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8177s / 382.2456 s
agent0:                 episode reward: 1.1438,                 loss: nan
agent1:                 episode reward: -1.1438,                 loss: 0.3201
Episode: 5781/10000 (57.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8093s / 383.0549 s
agent0:                 episode reward: 0.5615,                 loss: nan
agent1:                 episode reward: -0.5615,                 loss: 0.3175
Episode: 5791/10000 (57.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8111s / 383.8660 s
agent0:                 episode reward: 0.2092,                 loss: nan
agent1:                 episode reward: -0.2092,                 loss: 0.3192
Episode: 5801/10000 (58.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8364s / 384.7025 s
agent0:                 episode reward: -0.3888,                 loss: nan
agent1:                 episode reward: 0.3888,                 loss: 0.3143
Episode: 5811/10000 (58.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8087s / 385.5111 s
agent0:                 episode reward: 0.1945,                 loss: nan
agent1:                 episode reward: -0.1945,                 loss: 0.3117
Episode: 5821/10000 (58.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8764s / 386.3876 s
agent0:                 episode reward: -0.3355,                 loss: nan
agent1:                 episode reward: 0.3355,                 loss: 0.3113
Episode: 5831/10000 (58.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8160s / 387.2036 s
agent0:                 episode reward: -0.0958,                 loss: nan
agent1:                 episode reward: 0.0958,                 loss: 0.3106
Episode: 5841/10000 (58.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8556s / 388.0592 s
agent0:                 episode reward: -0.5473,                 loss: nan
agent1:                 episode reward: 0.5473,                 loss: 0.3110
Episode: 5851/10000 (58.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8176s / 388.8768 s
agent0:                 episode reward: 0.4350,                 loss: nan
agent1:                 episode reward: -0.4350,                 loss: 0.3105
Episode: 5861/10000 (58.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8072s / 389.6840 s
agent0:                 episode reward: -0.0441,                 loss: nan
agent1:                 episode reward: 0.0441,                 loss: 0.3111
Episode: 5871/10000 (58.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8059s / 390.4899 s
agent0:                 episode reward: 0.0237,                 loss: nan
agent1:                 episode reward: -0.0237,                 loss: 0.3124
Episode: 5881/10000 (58.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8086s / 391.2985 s
agent0:                 episode reward: 0.6906,                 loss: nan
agent1:                 episode reward: -0.6906,                 loss: 0.3025
Episode: 5891/10000 (58.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8430s / 392.1415 s
agent0:                 episode reward: 0.9301,                 loss: nan
agent1:                 episode reward: -0.9301,                 loss: 0.2989
Episode: 5901/10000 (59.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8322s / 392.9737 s
agent0:                 episode reward: -0.1270,                 loss: nan
agent1:                 episode reward: 0.1270,                 loss: 0.2977
Episode: 5911/10000 (59.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8241s / 393.7978 s
agent0:                 episode reward: -0.5253,                 loss: nan
agent1:                 episode reward: 0.5253,                 loss: 0.2984
Episode: 5921/10000 (59.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8134s / 394.6112 s
agent0:                 episode reward: -0.0610,                 loss: nan
agent1:                 episode reward: 0.0610,                 loss: 0.2982
Episode: 5931/10000 (59.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8266s / 395.4378 s
agent0:                 episode reward: -0.0502,                 loss: nan
agent1:                 episode reward: 0.0502,                 loss: 0.2968
Episode: 5941/10000 (59.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8226s / 396.2604 s
agent0:                 episode reward: -0.4488,                 loss: nan
agent1:                 episode reward: 0.4488,                 loss: 0.2971
Episode: 5951/10000 (59.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8148s / 397.0752 s
agent0:                 episode reward: 0.8245,                 loss: nan
agent1:                 episode reward: -0.8245,                 loss: 0.2973
Episode: 5961/10000 (59.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8968s / 397.9720 s
agent0:                 episode reward: 0.4628,                 loss: nan
agent1:                 episode reward: -0.4628,                 loss: 0.2969
Episode: 5971/10000 (59.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8273s / 398.7993 s
agent0:                 episode reward: 1.0922,                 loss: nan
agent1:                 episode reward: -1.0922,                 loss: 0.3043
Episode: 5981/10000 (59.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8236s / 399.6229 s
agent0:                 episode reward: 0.1622,                 loss: nan
agent1:                 episode reward: -0.1622,                 loss: 0.3019
Episode: 5991/10000 (59.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8238s / 400.4467 s
agent0:                 episode reward: -0.5857,                 loss: nan
agent1:                 episode reward: 0.5857,                 loss: 0.3027
Episode: 6001/10000 (60.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8630s / 401.3097 s
agent0:                 episode reward: -0.2810,                 loss: nan
agent1:                 episode reward: 0.2810,                 loss: 0.3023
Episode: 6011/10000 (60.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8262s / 402.1359 s
agent0:                 episode reward: -0.1675,                 loss: nan
agent1:                 episode reward: 0.1675,                 loss: 0.2992
Episode: 6021/10000 (60.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8321s / 402.9680 s
agent0:                 episode reward: -0.6932,                 loss: nan
agent1:                 episode reward: 0.6932,                 loss: 0.3005
Episode: 6031/10000 (60.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8470s / 403.8150 s
agent0:                 episode reward: 0.0399,                 loss: nan
agent1:                 episode reward: -0.0399,                 loss: 0.3015
Episode: 6041/10000 (60.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8563s / 404.6713 s
agent0:                 episode reward: -0.3459,                 loss: nan
agent1:                 episode reward: 0.3459,                 loss: 0.2994
Episode: 6051/10000 (60.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8279s / 405.4993 s
agent0:                 episode reward: -0.4648,                 loss: nan
agent1:                 episode reward: 0.4648,                 loss: 0.2999
Episode: 6061/10000 (60.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8195s / 406.3187 s
agent0:                 episode reward: -0.1880,                 loss: nan
agent1:                 episode reward: 0.1880,                 loss: 0.3006
Episode: 6071/10000 (60.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8322s / 407.1509 s
agent0:                 episode reward: -0.0351,                 loss: nan
agent1:                 episode reward: 0.0351,                 loss: 0.3305
Episode: 6081/10000 (60.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8582s / 408.0091 s
agent0:                 episode reward: 0.2779,                 loss: nan
agent1:                 episode reward: -0.2779,                 loss: 0.3339
Episode: 6091/10000 (60.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8243s / 408.8334 s
agent0:                 episode reward: -0.2710,                 loss: nan
agent1:                 episode reward: 0.2710,                 loss: 0.3312
Episode: 6101/10000 (61.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8584s / 409.6918 s
agent0:                 episode reward: -0.2002,                 loss: nan
agent1:                 episode reward: 0.2002,                 loss: 0.3306
Episode: 6111/10000 (61.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8405s / 410.5323 s
agent0:                 episode reward: -0.4867,                 loss: nan
agent1:                 episode reward: 0.4867,                 loss: 0.3296
Episode: 6121/10000 (61.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8400s / 411.3723 s
agent0:                 episode reward: 0.7366,                 loss: nan
agent1:                 episode reward: -0.7366,                 loss: 0.3309
Episode: 6131/10000 (61.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8330s / 412.2053 s
agent0:                 episode reward: 0.4730,                 loss: nan
agent1:                 episode reward: -0.4730,                 loss: 0.3291
Episode: 6141/10000 (61.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8414s / 413.0467 s
agent0:                 episode reward: -0.6538,                 loss: nan
agent1:                 episode reward: 0.6538,                 loss: 0.3298
Episode: 6151/10000 (61.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8312s / 413.8779 s
agent0:                 episode reward: -0.6453,                 loss: nan
agent1:                 episode reward: 0.6453,                 loss: 0.3303
Episode: 6161/10000 (61.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8240s / 414.7020 s
agent0:                 episode reward: 0.5892,                 loss: nan
agent1:                 episode reward: -0.5892,                 loss: 0.3310
Episode: 6171/10000 (61.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8283s / 415.5303 s
agent0:                 episode reward: -0.0443,                 loss: nan
agent1:                 episode reward: 0.0443,                 loss: 0.3066
Episode: 6181/10000 (61.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8332s / 416.3635 s
agent0:                 episode reward: 0.6831,                 loss: nan
agent1:                 episode reward: -0.6831,                 loss: 0.2711
Episode: 6191/10000 (61.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8283s / 417.1918 s
agent0:                 episode reward: 0.4561,                 loss: nan
agent1:                 episode reward: -0.4561,                 loss: 0.2717
Episode: 6201/10000 (62.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8685s / 418.0603 s
agent0:                 episode reward: -0.2313,                 loss: nan
agent1:                 episode reward: 0.2313,                 loss: 0.2710
Episode: 6211/10000 (62.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8503s / 418.9106 s
agent0:                 episode reward: -0.0903,                 loss: nan
agent1:                 episode reward: 0.0903,                 loss: 0.2695
Episode: 6221/10000 (62.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8329s / 419.7436 s
agent0:                 episode reward: -0.5858,                 loss: nan
agent1:                 episode reward: 0.5858,                 loss: 0.2708
Episode: 6231/10000 (62.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8312s / 420.5748 s
agent0:                 episode reward: 0.1796,                 loss: nan
agent1:                 episode reward: -0.1796,                 loss: 0.2704
Episode: 6241/10000 (62.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8341s / 421.4089 s
agent0:                 episode reward: 0.0252,                 loss: nan
agent1:                 episode reward: -0.0252,                 loss: 0.2672
Episode: 6251/10000 (62.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8405s / 422.2494 s
agent0:                 episode reward: 0.7111,                 loss: nan
agent1:                 episode reward: -0.7111,                 loss: 0.2699
Episode: 6261/10000 (62.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8415s / 423.0909 s
agent0:                 episode reward: -1.0852,                 loss: nan
agent1:                 episode reward: 1.0852,                 loss: 0.2692
Episode: 6271/10000 (62.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8307s / 423.9216 s
agent0:                 episode reward: -0.6069,                 loss: nan
agent1:                 episode reward: 0.6069,                 loss: 0.2178
Episode: 6281/10000 (62.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8380s / 424.7596 s
agent0:                 episode reward: -0.6858,                 loss: nan
agent1:                 episode reward: 0.6858,                 loss: 0.1756
Episode: 6291/10000 (62.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8458s / 425.6054 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.1743
Episode: 6301/10000 (63.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8298s / 426.4352 s
agent0:                 episode reward: 0.2516,                 loss: nan
agent1:                 episode reward: -0.2516,                 loss: 0.1727
Episode: 6311/10000 (63.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8387s / 427.2738 s
agent0:                 episode reward: 0.2767,                 loss: nan
agent1:                 episode reward: -0.2767,                 loss: 0.1728
Episode: 6321/10000 (63.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8767s / 428.1505 s
agent0:                 episode reward: 1.3167,                 loss: nan
agent1:                 episode reward: -1.3167,                 loss: 0.1720
Episode: 6331/10000 (63.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8843s / 429.0348 s
agent0:                 episode reward: -0.4099,                 loss: nan
agent1:                 episode reward: 0.4099,                 loss: 0.1730
Episode: 6341/10000 (63.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8380s / 429.8728 s
agent0:                 episode reward: -0.5053,                 loss: nan
agent1:                 episode reward: 0.5053,                 loss: 0.1731
Episode: 6351/10000 (63.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8390s / 430.7118 s
agent0:                 episode reward: 0.3099,                 loss: nan
agent1:                 episode reward: -0.3099,                 loss: 0.1722
Episode: 6361/10000 (63.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8590s / 431.5709 s
agent0:                 episode reward: 0.7487,                 loss: nan
agent1:                 episode reward: -0.7487,                 loss: 0.1723
Episode: 6371/10000 (63.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9213s / 432.4922 s
agent0:                 episode reward: 0.0218,                 loss: nan
agent1:                 episode reward: -0.0218,                 loss: 0.1728
Episode: 6381/10000 (63.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8460s / 433.3382 s
agent0:                 episode reward: 0.4635,                 loss: nan
agent1:                 episode reward: -0.4635,                 loss: 0.1671
Episode: 6391/10000 (63.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8490s / 434.1871 s
agent0:                 episode reward: -0.6677,                 loss: nan
agent1:                 episode reward: 0.6677,                 loss: 0.1668
Episode: 6401/10000 (64.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8360s / 435.0231 s
agent0:                 episode reward: 0.0337,                 loss: nan
agent1:                 episode reward: -0.0337,                 loss: 0.1672
Episode: 6411/10000 (64.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8380s / 435.8612 s
agent0:                 episode reward: 0.5604,                 loss: nan
agent1:                 episode reward: -0.5604,                 loss: 0.1666
Episode: 6421/10000 (64.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8451s / 436.7063 s
agent0:                 episode reward: 0.1306,                 loss: nan
agent1:                 episode reward: -0.1306,                 loss: 0.1676
Episode: 6431/10000 (64.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8754s / 437.5817 s
agent0:                 episode reward: -0.2678,                 loss: nan
agent1:                 episode reward: 0.2678,                 loss: 0.1650
Episode: 6441/10000 (64.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8680s / 438.4496 s
agent0:                 episode reward: 0.5838,                 loss: nan
agent1:                 episode reward: -0.5838,                 loss: 0.1659
Episode: 6451/10000 (64.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8983s / 439.3479 s
agent0:                 episode reward: 0.7045,                 loss: nan
agent1:                 episode reward: -0.7045,                 loss: 0.1669
Episode: 6461/10000 (64.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8594s / 440.2073 s
agent0:                 episode reward: -0.2552,                 loss: nan
agent1:                 episode reward: 0.2552,                 loss: 0.1655
Episode: 6471/10000 (64.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8456s / 441.0529 s
agent0:                 episode reward: -0.0508,                 loss: nan
agent1:                 episode reward: 0.0508,                 loss: 0.2001
Episode: 6481/10000 (64.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8497s / 441.9026 s
agent0:                 episode reward: -0.2374,                 loss: nan
agent1:                 episode reward: 0.2374,                 loss: 0.2106
Episode: 6491/10000 (64.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8787s / 442.7813 s
agent0:                 episode reward: 0.4294,                 loss: nan
agent1:                 episode reward: -0.4294,                 loss: 0.2083
Episode: 6501/10000 (65.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8538s / 443.6352 s
agent0:                 episode reward: -0.0705,                 loss: nan
agent1:                 episode reward: 0.0705,                 loss: 0.2082
Episode: 6511/10000 (65.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8490s / 444.4841 s
agent0:                 episode reward: 1.2027,                 loss: nan
agent1:                 episode reward: -1.2027,                 loss: 0.2091
Episode: 6521/10000 (65.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8611s / 445.3453 s
agent0:                 episode reward: 0.5512,                 loss: nan
agent1:                 episode reward: -0.5512,                 loss: 0.2083
Episode: 6531/10000 (65.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8541s / 446.1994 s
agent0:                 episode reward: 0.7562,                 loss: nan
agent1:                 episode reward: -0.7562,                 loss: 0.2076
Episode: 6541/10000 (65.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8577s / 447.0571 s
agent0:                 episode reward: -0.0990,                 loss: nan
agent1:                 episode reward: 0.0990,                 loss: 0.2080
Episode: 6551/10000 (65.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8522s / 447.9092 s
agent0:                 episode reward: 0.0526,                 loss: nan
agent1:                 episode reward: -0.0526,                 loss: 0.2070
Episode: 6561/10000 (65.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8675s / 448.7767 s
agent0:                 episode reward: 0.0136,                 loss: nan
agent1:                 episode reward: -0.0136,                 loss: 0.2071
Episode: 6571/10000 (65.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9136s / 449.6903 s
agent0:                 episode reward: 0.2190,                 loss: nan
agent1:                 episode reward: -0.2190,                 loss: 0.2429
Episode: 6581/10000 (65.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8645s / 450.5548 s
agent0:                 episode reward: -0.2694,                 loss: nan
agent1:                 episode reward: 0.2694,                 loss: 0.2536
Episode: 6591/10000 (65.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8466s / 451.4014 s
agent0:                 episode reward: 0.2317,                 loss: nan
agent1:                 episode reward: -0.2317,                 loss: 0.2525
Episode: 6601/10000 (66.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8671s / 452.2685 s
agent0:                 episode reward: -0.1502,                 loss: nan
agent1:                 episode reward: 0.1502,                 loss: 0.2520
Episode: 6611/10000 (66.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8619s / 453.1305 s
agent0:                 episode reward: -0.1045,                 loss: nan
agent1:                 episode reward: 0.1045,                 loss: 0.2502
Episode: 6621/10000 (66.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8582s / 453.9887 s
agent0:                 episode reward: 0.3489,                 loss: nan
agent1:                 episode reward: -0.3489,                 loss: 0.2493
Episode: 6631/10000 (66.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8567s / 454.8453 s
agent0:                 episode reward: -0.1678,                 loss: nan
agent1:                 episode reward: 0.1678,                 loss: 0.2500
Episode: 6641/10000 (66.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8623s / 455.7076 s
agent0:                 episode reward: 0.1779,                 loss: nan
agent1:                 episode reward: -0.1779,                 loss: 0.2494
Episode: 6651/10000 (66.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8512s / 456.5588 s
agent0:                 episode reward: 0.3429,                 loss: nan
agent1:                 episode reward: -0.3429,                 loss: 0.2485
Episode: 6661/10000 (66.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8743s / 457.4331 s
agent0:                 episode reward: -0.0930,                 loss: nan
agent1:                 episode reward: 0.0930,                 loss: 0.2482
Episode: 6671/10000 (66.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8668s / 458.2998 s
agent0:                 episode reward: -0.0034,                 loss: nan
agent1:                 episode reward: 0.0034,                 loss: 0.2830
Episode: 6681/10000 (66.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9131s / 459.2130 s
agent0:                 episode reward: 0.7251,                 loss: nan
agent1:                 episode reward: -0.7251,                 loss: 0.2901
Episode: 6691/10000 (66.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8603s / 460.0733 s
agent0:                 episode reward: 0.2840,                 loss: nan
agent1:                 episode reward: -0.2840,                 loss: 0.2908
Episode: 6701/10000 (67.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8626s / 460.9359 s
agent0:                 episode reward: 0.8329,                 loss: nan
agent1:                 episode reward: -0.8329,                 loss: 0.2871
Episode: 6711/10000 (67.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8667s / 461.8026 s
agent0:                 episode reward: 0.6400,                 loss: nan
agent1:                 episode reward: -0.6400,                 loss: 0.2858
Episode: 6721/10000 (67.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8600s / 462.6626 s
agent0:                 episode reward: -0.1211,                 loss: nan
agent1:                 episode reward: 0.1211,                 loss: 0.2872
Episode: 6731/10000 (67.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8715s / 463.5341 s
agent0:                 episode reward: 0.3094,                 loss: nan
agent1:                 episode reward: -0.3094,                 loss: 0.2861
Episode: 6741/10000 (67.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8673s / 464.4014 s
agent0:                 episode reward: -0.0885,                 loss: nan
agent1:                 episode reward: 0.0885,                 loss: 0.2869
Episode: 6751/10000 (67.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8637s / 465.2651 s
agent0:                 episode reward: -1.0738,                 loss: nan
agent1:                 episode reward: 1.0738,                 loss: 0.2864
Episode: 6761/10000 (67.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8736s / 466.1387 s
agent0:                 episode reward: -0.1934,                 loss: nan
agent1:                 episode reward: 0.1934,                 loss: 0.2857
Episode: 6771/10000 (67.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8633s / 467.0020 s
agent0:                 episode reward: 0.6769,                 loss: nan
agent1:                 episode reward: -0.6769,                 loss: 0.3005
Episode: 6781/10000 (67.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8920s / 467.8939 s
agent0:                 episode reward: 1.0401,                 loss: nan
agent1:                 episode reward: -1.0401,                 loss: 0.2926
Episode: 6791/10000 (67.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8610s / 468.7550 s
agent0:                 episode reward: 0.8130,                 loss: nan
agent1:                 episode reward: -0.8130,                 loss: 0.2919
Episode: 6801/10000 (68.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9098s / 469.6648 s
agent0:                 episode reward: 0.9414,                 loss: nan
agent1:                 episode reward: -0.9414,                 loss: 0.2940
Episode: 6811/10000 (68.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8767s / 470.5415 s
agent0:                 episode reward: 0.1096,                 loss: nan
agent1:                 episode reward: -0.1096,                 loss: 0.2909
Episode: 6821/10000 (68.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8683s / 471.4098 s
agent0:                 episode reward: -0.1999,                 loss: nan
agent1:                 episode reward: 0.1999,                 loss: 0.2910
Episode: 6831/10000 (68.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8659s / 472.2756 s
agent0:                 episode reward: 0.2684,                 loss: nan
agent1:                 episode reward: -0.2684,                 loss: 0.2923
Episode: 6841/10000 (68.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8737s / 473.1494 s
agent0:                 episode reward: 0.1468,                 loss: nan
agent1:                 episode reward: -0.1468,                 loss: 0.2904
Episode: 6851/10000 (68.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8903s / 474.0396 s
agent0:                 episode reward: -0.2131,                 loss: nan
agent1:                 episode reward: 0.2131,                 loss: 0.2903
Episode: 6861/10000 (68.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8738s / 474.9134 s
agent0:                 episode reward: 1.1021,                 loss: nan
agent1:                 episode reward: -1.1021,                 loss: 0.2913
Episode: 6871/10000 (68.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8838s / 475.7972 s
agent0:                 episode reward: 0.2009,                 loss: nan
agent1:                 episode reward: -0.2009,                 loss: 0.2895
Episode: 6881/10000 (68.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8816s / 476.6788 s
agent0:                 episode reward: 1.0344,                 loss: nan
agent1:                 episode reward: -1.0344,                 loss: 0.2664
Episode: 6891/10000 (68.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8722s / 477.5510 s
agent0:                 episode reward: 0.0900,                 loss: nan
agent1:                 episode reward: -0.0900,                 loss: 0.2660
Episode: 6901/10000 (69.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8813s / 478.4323 s
agent0:                 episode reward: 0.2665,                 loss: nan
agent1:                 episode reward: -0.2665,                 loss: 0.2631
Episode: 6911/10000 (69.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8725s / 479.3048 s
agent0:                 episode reward: 0.5061,                 loss: nan
agent1:                 episode reward: -0.5061,                 loss: 0.2617
Episode: 6921/10000 (69.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9272s / 480.2320 s
agent0:                 episode reward: 0.2431,                 loss: nan
agent1:                 episode reward: -0.2431,                 loss: 0.2617
Episode: 6931/10000 (69.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8737s / 481.1056 s
agent0:                 episode reward: -0.3875,                 loss: nan
agent1:                 episode reward: 0.3875,                 loss: 0.2640
Episode: 6941/10000 (69.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8793s / 481.9849 s
agent0:                 episode reward: -0.2312,                 loss: nan
agent1:                 episode reward: 0.2312,                 loss: 0.2608
Episode: 6951/10000 (69.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8844s / 482.8693 s
agent0:                 episode reward: 0.6559,                 loss: nan
agent1:                 episode reward: -0.6559,                 loss: 0.2635
Episode: 6961/10000 (69.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9097s / 483.7790 s
agent0:                 episode reward: 0.0704,                 loss: nan
agent1:                 episode reward: -0.0704,                 loss: 0.2618
Episode: 6971/10000 (69.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8748s / 484.6538 s
agent0:                 episode reward: 0.1130,                 loss: nan
agent1:                 episode reward: -0.1130,                 loss: 0.2753
Episode: 6981/10000 (69.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8889s / 485.5427 s
agent0:                 episode reward: 0.0746,                 loss: nan
agent1:                 episode reward: -0.0746,                 loss: 0.2691
Episode: 6991/10000 (69.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8769s / 486.4196 s
agent0:                 episode reward: -0.0604,                 loss: nan
agent1:                 episode reward: 0.0604,                 loss: 0.2683
Episode: 7001/10000 (70.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8799s / 487.2994 s
agent0:                 episode reward: -0.4928,                 loss: nan
agent1:                 episode reward: 0.4928,                 loss: 0.2636
Episode: 7011/10000 (70.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8866s / 488.1860 s
agent0:                 episode reward: 0.0179,                 loss: nan
agent1:                 episode reward: -0.0179,                 loss: 0.2640
Episode: 7021/10000 (70.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8921s / 489.0780 s
agent0:                 episode reward: 0.8897,                 loss: nan
agent1:                 episode reward: -0.8897,                 loss: 0.2672
Episode: 7031/10000 (70.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9249s / 490.0029 s
agent0:                 episode reward: -0.5659,                 loss: nan
agent1:                 episode reward: 0.5659,                 loss: 0.2656
Episode: 7041/10000 (70.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9021s / 490.9050 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.2639
Episode: 7051/10000 (70.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9034s / 491.8084 s
agent0:                 episode reward: -0.4036,                 loss: nan
agent1:                 episode reward: 0.4036,                 loss: 0.2663
Episode: 7061/10000 (70.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8961s / 492.7045 s
agent0:                 episode reward: -0.9827,                 loss: nan
agent1:                 episode reward: 0.9827,                 loss: 0.2648
Episode: 7071/10000 (70.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8893s / 493.5938 s
agent0:                 episode reward: -0.6711,                 loss: nan
agent1:                 episode reward: 0.6711,                 loss: 0.2967
Episode: 7081/10000 (70.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9085s / 494.5023 s
agent0:                 episode reward: 0.6150,                 loss: nan
agent1:                 episode reward: -0.6150,                 loss: 0.2909
Episode: 7091/10000 (70.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8896s / 495.3918 s
agent0:                 episode reward: -0.4246,                 loss: nan
agent1:                 episode reward: 0.4246,                 loss: 0.2886
Episode: 7101/10000 (71.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8856s / 496.2775 s
agent0:                 episode reward: 0.0039,                 loss: nan
agent1:                 episode reward: -0.0039,                 loss: 0.2880
Episode: 7111/10000 (71.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8883s / 497.1658 s
agent0:                 episode reward: -0.3936,                 loss: nan
agent1:                 episode reward: 0.3936,                 loss: 0.2882
Episode: 7121/10000 (71.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8995s / 498.0653 s
agent0:                 episode reward: -0.4135,                 loss: nan
agent1:                 episode reward: 0.4135,                 loss: 0.2871
Episode: 7131/10000 (71.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8915s / 498.9569 s
agent0:                 episode reward: 0.4285,                 loss: nan
agent1:                 episode reward: -0.4285,                 loss: 0.2886
Episode: 7141/10000 (71.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8898s / 499.8467 s
agent0:                 episode reward: 0.1684,                 loss: nan
agent1:                 episode reward: -0.1684,                 loss: 0.2871
Episode: 7151/10000 (71.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9519s / 500.7986 s
agent0:                 episode reward: -0.2044,                 loss: nan
agent1:                 episode reward: 0.2044,                 loss: 0.2852
Episode: 7161/10000 (71.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9103s / 501.7089 s
agent0:                 episode reward: -0.3952,                 loss: nan
agent1:                 episode reward: 0.3952,                 loss: 0.2869
Episode: 7171/10000 (71.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8904s / 502.5993 s
agent0:                 episode reward: -0.0704,                 loss: nan
agent1:                 episode reward: 0.0704,                 loss: 0.2640
Episode: 7181/10000 (71.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9009s / 503.5002 s
agent0:                 episode reward: -0.7722,                 loss: nan
agent1:                 episode reward: 0.7722,                 loss: 0.2178
Episode: 7191/10000 (71.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9150s / 504.4152 s
agent0:                 episode reward: -0.5691,                 loss: nan
agent1:                 episode reward: 0.5691,                 loss: 0.2130
Episode: 7201/10000 (72.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8998s / 505.3149 s
agent0:                 episode reward: -0.4900,                 loss: nan
agent1:                 episode reward: 0.4900,                 loss: 0.2134
Episode: 7211/10000 (72.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9002s / 506.2151 s
agent0:                 episode reward: 0.2927,                 loss: nan
agent1:                 episode reward: -0.2927,                 loss: 0.2122
Episode: 7221/10000 (72.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9131s / 507.1282 s
agent0:                 episode reward: -0.2617,                 loss: nan
agent1:                 episode reward: 0.2617,                 loss: 0.2129
Episode: 7231/10000 (72.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9145s / 508.0427 s
agent0:                 episode reward: 0.1543,                 loss: nan
agent1:                 episode reward: -0.1543,                 loss: 0.2125
Episode: 7241/10000 (72.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9242s / 508.9668 s
agent0:                 episode reward: -0.4394,                 loss: nan
agent1:                 episode reward: 0.4394,                 loss: 0.2118
Episode: 7251/10000 (72.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9108s / 509.8777 s
agent0:                 episode reward: 0.0248,                 loss: nan
agent1:                 episode reward: -0.0248,                 loss: 0.2107
Episode: 7261/10000 (72.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9372s / 510.8149 s
agent0:                 episode reward: 0.0725,                 loss: nan
agent1:                 episode reward: -0.0725,                 loss: 0.2096
Episode: 7271/10000 (72.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8990s / 511.7140 s
agent0:                 episode reward: -0.4059,                 loss: nan
agent1:                 episode reward: 0.4059,                 loss: 0.1809
Episode: 7281/10000 (72.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9127s / 512.6266 s
agent0:                 episode reward: 0.2051,                 loss: nan
agent1:                 episode reward: -0.2051,                 loss: 0.1499
Episode: 7291/10000 (72.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9072s / 513.5338 s
agent0:                 episode reward: -0.4228,                 loss: nan
agent1:                 episode reward: 0.4228,                 loss: 0.1478
Episode: 7301/10000 (73.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9134s / 514.4472 s
agent0:                 episode reward: 0.0713,                 loss: nan
agent1:                 episode reward: -0.0713,                 loss: 0.1475
Episode: 7311/10000 (73.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9119s / 515.3591 s
agent0:                 episode reward: 0.2089,                 loss: nan
agent1:                 episode reward: -0.2089,                 loss: 0.1481
Episode: 7321/10000 (73.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9335s / 516.2926 s
agent0:                 episode reward: 0.9967,                 loss: nan
agent1:                 episode reward: -0.9967,                 loss: 0.1462
Episode: 7331/10000 (73.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9482s / 517.2408 s
agent0:                 episode reward: -0.1058,                 loss: nan
agent1:                 episode reward: 0.1058,                 loss: 0.1452
Episode: 7341/10000 (73.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.8982s / 518.1390 s
agent0:                 episode reward: 0.2889,                 loss: nan
agent1:                 episode reward: -0.2889,                 loss: 0.1487
Episode: 7351/10000 (73.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9101s / 519.0491 s
agent0:                 episode reward: -0.1964,                 loss: nan
agent1:                 episode reward: 0.1964,                 loss: 0.1464
Episode: 7361/10000 (73.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9055s / 519.9546 s
agent0:                 episode reward: -1.1851,                 loss: nan
agent1:                 episode reward: 1.1851,                 loss: 0.1454
Episode: 7371/10000 (73.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9426s / 520.8972 s
agent0:                 episode reward: 0.2542,                 loss: nan
agent1:                 episode reward: -0.2542,                 loss: 0.1667
Episode: 7381/10000 (73.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9220s / 521.8192 s
agent0:                 episode reward: -0.0273,                 loss: nan
agent1:                 episode reward: 0.0273,                 loss: 0.1668
Episode: 7391/10000 (73.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9111s / 522.7304 s
agent0:                 episode reward: -0.5784,                 loss: nan
agent1:                 episode reward: 0.5784,                 loss: 0.1655
Episode: 7401/10000 (74.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9103s / 523.6406 s
agent0:                 episode reward: 0.2612,                 loss: nan
agent1:                 episode reward: -0.2612,                 loss: 0.1670
Episode: 7411/10000 (74.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9183s / 524.5590 s
agent0:                 episode reward: 0.1385,                 loss: nan
agent1:                 episode reward: -0.1385,                 loss: 0.1677
Episode: 7421/10000 (74.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9588s / 525.5178 s
agent0:                 episode reward: 0.0029,                 loss: nan
agent1:                 episode reward: -0.0029,                 loss: 0.1668
Episode: 7431/10000 (74.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9109s / 526.4286 s
agent0:                 episode reward: -0.0064,                 loss: nan
agent1:                 episode reward: 0.0064,                 loss: 0.1674
Episode: 7441/10000 (74.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9111s / 527.3398 s
agent0:                 episode reward: 0.0683,                 loss: nan
agent1:                 episode reward: -0.0683,                 loss: 0.1649
Episode: 7451/10000 (74.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9323s / 528.2721 s
agent0:                 episode reward: 0.5939,                 loss: nan
agent1:                 episode reward: -0.5939,                 loss: 0.1670
Episode: 7461/10000 (74.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9156s / 529.1877 s
agent0:                 episode reward: -0.1956,                 loss: nan
agent1:                 episode reward: 0.1956,                 loss: 0.1639
Episode: 7471/10000 (74.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9188s / 530.1065 s
agent0:                 episode reward: -0.3183,                 loss: nan
agent1:                 episode reward: 0.3183,                 loss: 0.2017
Episode: 7481/10000 (74.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0023s / 531.1089 s
agent0:                 episode reward: -0.2150,                 loss: nan
agent1:                 episode reward: 0.2150,                 loss: 0.2077
Episode: 7491/10000 (74.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9275s / 532.0364 s
agent0:                 episode reward: 0.1868,                 loss: nan
agent1:                 episode reward: -0.1868,                 loss: 0.2061
Episode: 7501/10000 (75.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9184s / 532.9548 s
agent0:                 episode reward: 0.1773,                 loss: nan
agent1:                 episode reward: -0.1773,                 loss: 0.2059
Episode: 7511/10000 (75.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9481s / 533.9029 s
agent0:                 episode reward: -0.2325,                 loss: nan
agent1:                 episode reward: 0.2325,                 loss: 0.2070
Episode: 7521/10000 (75.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9541s / 534.8571 s
agent0:                 episode reward: -0.1455,                 loss: nan
agent1:                 episode reward: 0.1455,                 loss: 0.2058
Episode: 7531/10000 (75.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9230s / 535.7800 s
agent0:                 episode reward: 0.0458,                 loss: nan
agent1:                 episode reward: -0.0458,                 loss: 0.2055
Episode: 7541/10000 (75.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9296s / 536.7096 s
agent0:                 episode reward: 0.2523,                 loss: nan
agent1:                 episode reward: -0.2523,                 loss: 0.2037
Episode: 7551/10000 (75.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9381s / 537.6477 s
agent0:                 episode reward: -0.8160,                 loss: nan
agent1:                 episode reward: 0.8160,                 loss: 0.2049
Episode: 7561/10000 (75.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9213s / 538.5690 s
agent0:                 episode reward: -0.0401,                 loss: nan
agent1:                 episode reward: 0.0401,                 loss: 0.2059
Episode: 7571/10000 (75.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9253s / 539.4943 s
agent0:                 episode reward: 0.5563,                 loss: nan
agent1:                 episode reward: -0.5563,                 loss: 0.2404
Episode: 7581/10000 (75.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9218s / 540.4161 s
agent0:                 episode reward: 0.2738,                 loss: nan
agent1:                 episode reward: -0.2738,                 loss: 0.2482
Episode: 7591/10000 (75.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9806s / 541.3967 s
agent0:                 episode reward: 0.6510,                 loss: nan
agent1:                 episode reward: -0.6510,                 loss: 0.2480
Episode: 7601/10000 (76.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9383s / 542.3350 s
agent0:                 episode reward: 0.5640,                 loss: nan
agent1:                 episode reward: -0.5640,                 loss: 0.2484
Episode: 7611/10000 (76.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9368s / 543.2718 s
agent0:                 episode reward: -0.4158,                 loss: nan
agent1:                 episode reward: 0.4158,                 loss: 0.2476
Episode: 7621/10000 (76.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9452s / 544.2170 s
agent0:                 episode reward: -0.5400,                 loss: nan
agent1:                 episode reward: 0.5400,                 loss: 0.2469
Episode: 7631/10000 (76.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9347s / 545.1517 s
agent0:                 episode reward: -1.2035,                 loss: nan
agent1:                 episode reward: 1.2035,                 loss: 0.2487
Episode: 7641/10000 (76.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9443s / 546.0960 s
agent0:                 episode reward: 0.0966,                 loss: nan
agent1:                 episode reward: -0.0966,                 loss: 0.2463
Episode: 7651/10000 (76.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9300s / 547.0260 s
agent0:                 episode reward: 0.4356,                 loss: nan
agent1:                 episode reward: -0.4356,                 loss: 0.2476
Episode: 7661/10000 (76.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9296s / 547.9556 s
agent0:                 episode reward: -0.5069,                 loss: nan
agent1:                 episode reward: 0.5069,                 loss: 0.2468
Episode: 7671/10000 (76.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9370s / 548.8925 s
agent0:                 episode reward: -0.1915,                 loss: nan
agent1:                 episode reward: 0.1915,                 loss: 0.2757
Episode: 7681/10000 (76.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9593s / 549.8519 s
agent0:                 episode reward: -0.3291,                 loss: nan
agent1:                 episode reward: 0.3291,                 loss: 0.2792
Episode: 7691/10000 (76.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9380s / 550.7899 s
agent0:                 episode reward: -0.1601,                 loss: nan
agent1:                 episode reward: 0.1601,                 loss: 0.2795
Episode: 7701/10000 (77.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9772s / 551.7670 s
agent0:                 episode reward: -0.3791,                 loss: nan
agent1:                 episode reward: 0.3791,                 loss: 0.2799
Episode: 7711/10000 (77.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9609s / 552.7280 s
agent0:                 episode reward: -0.0424,                 loss: nan
agent1:                 episode reward: 0.0424,                 loss: 0.2790
Episode: 7721/10000 (77.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9388s / 553.6667 s
agent0:                 episode reward: -0.1052,                 loss: nan
agent1:                 episode reward: 0.1052,                 loss: 0.2808
Episode: 7731/10000 (77.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9606s / 554.6273 s
agent0:                 episode reward: -0.0125,                 loss: nan
agent1:                 episode reward: 0.0125,                 loss: 0.2790
Episode: 7741/10000 (77.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9451s / 555.5724 s
agent0:                 episode reward: -0.4741,                 loss: nan
agent1:                 episode reward: 0.4741,                 loss: 0.2795
Episode: 7751/10000 (77.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9362s / 556.5086 s
agent0:                 episode reward: -1.2115,                 loss: nan
agent1:                 episode reward: 1.2115,                 loss: 0.2792
Episode: 7761/10000 (77.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9379s / 557.4465 s
agent0:                 episode reward: -0.4779,                 loss: nan
agent1:                 episode reward: 0.4779,                 loss: 0.2785
Episode: 7771/10000 (77.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9788s / 558.4254 s
agent0:                 episode reward: -0.6488,                 loss: nan
agent1:                 episode reward: 0.6488,                 loss: 0.3063
Episode: 7781/10000 (77.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9652s / 559.3906 s
agent0:                 episode reward: 0.1721,                 loss: nan
agent1:                 episode reward: -0.1721,                 loss: 0.3042
Episode: 7791/10000 (77.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9721s / 560.3627 s
agent0:                 episode reward: 0.3196,                 loss: nan
agent1:                 episode reward: -0.3196,                 loss: 0.3050
Episode: 7801/10000 (78.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9418s / 561.3045 s
agent0:                 episode reward: -0.4486,                 loss: nan
agent1:                 episode reward: 0.4486,                 loss: 0.3014
Episode: 7811/10000 (78.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0014s / 562.3059 s
agent0:                 episode reward: 0.3945,                 loss: nan
agent1:                 episode reward: -0.3945,                 loss: 0.2999
Episode: 7821/10000 (78.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9473s / 563.2532 s
agent0:                 episode reward: -0.2300,                 loss: nan
agent1:                 episode reward: 0.2300,                 loss: 0.2992
Episode: 7831/10000 (78.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9481s / 564.2014 s
agent0:                 episode reward: 0.3702,                 loss: nan
agent1:                 episode reward: -0.3702,                 loss: 0.2984
Episode: 7841/10000 (78.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9580s / 565.1594 s
agent0:                 episode reward: -0.2346,                 loss: nan
agent1:                 episode reward: 0.2346,                 loss: 0.3004
Episode: 7851/10000 (78.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9408s / 566.1002 s
agent0:                 episode reward: -0.0634,                 loss: nan
agent1:                 episode reward: 0.0634,                 loss: 0.2987
Episode: 7861/10000 (78.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9694s / 567.0696 s
agent0:                 episode reward: 0.0528,                 loss: nan
agent1:                 episode reward: -0.0528,                 loss: 0.2986
Episode: 7871/10000 (78.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9479s / 568.0175 s
agent0:                 episode reward: -0.8669,                 loss: nan
agent1:                 episode reward: 0.8669,                 loss: 0.3060
Episode: 7881/10000 (78.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9771s / 568.9946 s
agent0:                 episode reward: 0.2309,                 loss: nan
agent1:                 episode reward: -0.2309,                 loss: 0.2900
Episode: 7891/10000 (78.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9584s / 569.9530 s
agent0:                 episode reward: -0.0985,                 loss: nan
agent1:                 episode reward: 0.0985,                 loss: 0.2899
Episode: 7901/10000 (79.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9523s / 570.9054 s
agent0:                 episode reward: 0.0656,                 loss: nan
agent1:                 episode reward: -0.0656,                 loss: 0.2903
Episode: 7911/10000 (79.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9888s / 571.8942 s
agent0:                 episode reward: -0.2287,                 loss: nan
agent1:                 episode reward: 0.2287,                 loss: 0.2874
Episode: 7921/10000 (79.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9597s / 572.8539 s
agent0:                 episode reward: 0.3971,                 loss: nan
agent1:                 episode reward: -0.3971,                 loss: 0.2880
Episode: 7931/10000 (79.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9706s / 573.8245 s
agent0:                 episode reward: 0.4890,                 loss: nan
agent1:                 episode reward: -0.4890,                 loss: 0.2871
Episode: 7941/10000 (79.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9729s / 574.7974 s
agent0:                 episode reward: 0.0943,                 loss: nan
agent1:                 episode reward: -0.0943,                 loss: 0.2865
Episode: 7951/10000 (79.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9593s / 575.7567 s
agent0:                 episode reward: 0.0767,                 loss: nan
agent1:                 episode reward: -0.0767,                 loss: 0.2880
Episode: 7961/10000 (79.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9554s / 576.7121 s
agent0:                 episode reward: 0.4082,                 loss: nan
agent1:                 episode reward: -0.4082,                 loss: 0.2877
Episode: 7971/10000 (79.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9830s / 577.6951 s
agent0:                 episode reward: 0.7795,                 loss: nan
agent1:                 episode reward: -0.7795,                 loss: 0.3011
Episode: 7981/10000 (79.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9741s / 578.6692 s
agent0:                 episode reward: 0.1728,                 loss: nan
agent1:                 episode reward: -0.1728,                 loss: 0.2936
Episode: 7991/10000 (79.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9631s / 579.6322 s
agent0:                 episode reward: -0.9866,                 loss: nan
agent1:                 episode reward: 0.9866,                 loss: 0.2943
Episode: 8001/10000 (80.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9615s / 580.5938 s
agent0:                 episode reward: 0.0753,                 loss: nan
agent1:                 episode reward: -0.0753,                 loss: 0.2926
Episode: 8011/10000 (80.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9620s / 581.5558 s
agent0:                 episode reward: -0.1588,                 loss: nan
agent1:                 episode reward: 0.1588,                 loss: 0.2902
Episode: 8021/10000 (80.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0096s / 582.5653 s
agent0:                 episode reward: 0.2054,                 loss: nan
agent1:                 episode reward: -0.2054,                 loss: 0.2918
Episode: 8031/10000 (80.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9750s / 583.5404 s
agent0:                 episode reward: 0.5100,                 loss: nan
agent1:                 episode reward: -0.5100,                 loss: 0.2892
Episode: 8041/10000 (80.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9753s / 584.5157 s
agent0:                 episode reward: 0.2475,                 loss: nan
agent1:                 episode reward: -0.2475,                 loss: 0.2902
Episode: 8051/10000 (80.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9915s / 585.5072 s
agent0:                 episode reward: 0.0184,                 loss: nan
agent1:                 episode reward: -0.0184,                 loss: 0.2918
Episode: 8061/10000 (80.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9591s / 586.4664 s
agent0:                 episode reward: -0.6537,                 loss: nan
agent1:                 episode reward: 0.6537,                 loss: 0.2901
Episode: 8071/10000 (80.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9643s / 587.4307 s
agent0:                 episode reward: -0.1750,                 loss: nan
agent1:                 episode reward: 0.1750,                 loss: 0.3260
Episode: 8081/10000 (80.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9702s / 588.4009 s
agent0:                 episode reward: -0.0538,                 loss: nan
agent1:                 episode reward: 0.0538,                 loss: 0.3134
Episode: 8091/10000 (80.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9607s / 589.3616 s
agent0:                 episode reward: -0.5685,                 loss: nan
agent1:                 episode reward: 0.5685,                 loss: 0.3110
Episode: 8101/10000 (81.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9657s / 590.3273 s
agent0:                 episode reward: -0.1124,                 loss: nan
agent1:                 episode reward: 0.1124,                 loss: 0.3107
Episode: 8111/10000 (81.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0231s / 591.3504 s
agent0:                 episode reward: 0.3206,                 loss: nan
agent1:                 episode reward: -0.3206,                 loss: 0.3095
Episode: 8121/10000 (81.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0173s / 592.3678 s
agent0:                 episode reward: 0.5731,                 loss: nan
agent1:                 episode reward: -0.5731,                 loss: 0.3102
Episode: 8131/10000 (81.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9994s / 593.3671 s
agent0:                 episode reward: -0.1228,                 loss: nan
agent1:                 episode reward: 0.1228,                 loss: 0.3112
Episode: 8141/10000 (81.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9893s / 594.3564 s
agent0:                 episode reward: -0.1099,                 loss: nan
agent1:                 episode reward: 0.1099,                 loss: 0.3083
Episode: 8151/10000 (81.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9830s / 595.3395 s
agent0:                 episode reward: 1.3636,                 loss: nan
agent1:                 episode reward: -1.3636,                 loss: 0.3075
Episode: 8161/10000 (81.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9887s / 596.3282 s
agent0:                 episode reward: 0.1739,                 loss: nan
agent1:                 episode reward: -0.1739,                 loss: 0.3089
Episode: 8171/10000 (81.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9753s / 597.3035 s
agent0:                 episode reward: -0.4749,                 loss: nan
agent1:                 episode reward: 0.4749,                 loss: 0.2679
Episode: 8181/10000 (81.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9766s / 598.2801 s
agent0:                 episode reward: 0.5579,                 loss: nan
agent1:                 episode reward: -0.5579,                 loss: 0.2202
Episode: 8191/10000 (81.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9713s / 599.2514 s
agent0:                 episode reward: 0.4717,                 loss: nan
agent1:                 episode reward: -0.4717,                 loss: 0.2186
Episode: 8201/10000 (82.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0028s / 600.2541 s
agent0:                 episode reward: 0.2694,                 loss: nan
agent1:                 episode reward: -0.2694,                 loss: 0.2152
Episode: 8211/10000 (82.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9787s / 601.2328 s
agent0:                 episode reward: 0.2020,                 loss: nan
agent1:                 episode reward: -0.2020,                 loss: 0.2136
Episode: 8221/10000 (82.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0182s / 602.2511 s
agent0:                 episode reward: 0.1970,                 loss: nan
agent1:                 episode reward: -0.1970,                 loss: 0.2136
Episode: 8231/10000 (82.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0275s / 603.2785 s
agent0:                 episode reward: -0.5051,                 loss: nan
agent1:                 episode reward: 0.5051,                 loss: 0.2130
Episode: 8241/10000 (82.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9838s / 604.2623 s
agent0:                 episode reward: -0.0676,                 loss: nan
agent1:                 episode reward: 0.0676,                 loss: 0.2118
Episode: 8251/10000 (82.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9813s / 605.2436 s
agent0:                 episode reward: 0.5698,                 loss: nan
agent1:                 episode reward: -0.5698,                 loss: 0.2131
Episode: 8261/10000 (82.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9916s / 606.2352 s
agent0:                 episode reward: -0.1829,                 loss: nan
agent1:                 episode reward: 0.1829,                 loss: 0.2130
Episode: 8271/10000 (82.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9909s / 607.2261 s
agent0:                 episode reward: 1.0298,                 loss: nan
agent1:                 episode reward: -1.0298,                 loss: 0.1963
Episode: 8281/10000 (82.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0046s / 608.2307 s
agent0:                 episode reward: -0.0582,                 loss: nan
agent1:                 episode reward: 0.0582,                 loss: 0.1823
Episode: 8291/10000 (82.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0164s / 609.2470 s
agent0:                 episode reward: 0.7971,                 loss: nan
agent1:                 episode reward: -0.7971,                 loss: 0.1821
Episode: 8301/10000 (83.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9993s / 610.2463 s
agent0:                 episode reward: 0.3869,                 loss: nan
agent1:                 episode reward: -0.3869,                 loss: 0.1811
Episode: 8311/10000 (83.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0121s / 611.2584 s
agent0:                 episode reward: -0.0205,                 loss: nan
agent1:                 episode reward: 0.0205,                 loss: 0.1792
Episode: 8321/10000 (83.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9987s / 612.2571 s
agent0:                 episode reward: -0.2001,                 loss: nan
agent1:                 episode reward: 0.2001,                 loss: 0.1798
Episode: 8331/10000 (83.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0140s / 613.2711 s
agent0:                 episode reward: -0.4819,                 loss: nan
agent1:                 episode reward: 0.4819,                 loss: 0.1802
Episode: 8341/10000 (83.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9925s / 614.2636 s
agent0:                 episode reward: 0.0036,                 loss: nan
agent1:                 episode reward: -0.0036,                 loss: 0.1798
Episode: 8351/10000 (83.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0228s / 615.2864 s
agent0:                 episode reward: -1.0731,                 loss: nan
agent1:                 episode reward: 1.0731,                 loss: 0.1795
Episode: 8361/10000 (83.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0181s / 616.3046 s
agent0:                 episode reward: -0.4680,                 loss: nan
agent1:                 episode reward: 0.4680,                 loss: 0.1758
Episode: 8371/10000 (83.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9887s / 617.2933 s
agent0:                 episode reward: 0.1803,                 loss: nan
agent1:                 episode reward: -0.1803,                 loss: 0.1997
Episode: 8381/10000 (83.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0213s / 618.3146 s
agent0:                 episode reward: -0.6617,                 loss: nan
agent1:                 episode reward: 0.6617,                 loss: 0.2065
Episode: 8391/10000 (83.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 0.9914s / 619.3060 s
agent0:                 episode reward: -0.0336,                 loss: nan
agent1:                 episode reward: 0.0336,                 loss: 0.2038
Episode: 8401/10000 (84.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0025s / 620.3084 s
agent0:                 episode reward: -0.1739,                 loss: nan
agent1:                 episode reward: 0.1739,                 loss: 0.2032
Episode: 8411/10000 (84.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0022s / 621.3106 s
agent0:                 episode reward: 0.0802,                 loss: nan
agent1:                 episode reward: -0.0802,                 loss: 0.2051
Episode: 8421/10000 (84.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0011s / 622.3117 s
agent0:                 episode reward: 0.6131,                 loss: nan
agent1:                 episode reward: -0.6131,                 loss: 0.2056
Episode: 8431/10000 (84.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0515s / 623.3632 s
agent0:                 episode reward: -0.2524,                 loss: nan
agent1:                 episode reward: 0.2524,                 loss: 0.2047
Episode: 8441/10000 (84.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0235s / 624.3867 s
agent0:                 episode reward: -0.1942,                 loss: nan
agent1:                 episode reward: 0.1942,                 loss: 0.2052
Episode: 8451/10000 (84.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0475s / 625.4342 s
agent0:                 episode reward: -0.0929,                 loss: nan
agent1:                 episode reward: 0.0929,                 loss: 0.2024
Episode: 8461/10000 (84.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0210s / 626.4551 s
agent0:                 episode reward: -0.1704,                 loss: nan
agent1:                 episode reward: 0.1704,                 loss: 0.2072
Episode: 8471/10000 (84.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0199s / 627.4751 s
agent0:                 episode reward: 0.3502,                 loss: nan
agent1:                 episode reward: -0.3502,                 loss: 0.2257
Episode: 8481/10000 (84.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0251s / 628.5002 s
agent0:                 episode reward: -0.4700,                 loss: nan
agent1:                 episode reward: 0.4700,                 loss: 0.2307
Episode: 8491/10000 (84.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0140s / 629.5142 s
agent0:                 episode reward: -0.3990,                 loss: nan
agent1:                 episode reward: 0.3990,                 loss: 0.2331
Episode: 8501/10000 (85.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0272s / 630.5414 s
agent0:                 episode reward: -0.2304,                 loss: nan
agent1:                 episode reward: 0.2304,                 loss: 0.2326
Episode: 8511/10000 (85.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0032s / 631.5445 s
agent0:                 episode reward: -0.1782,                 loss: nan
agent1:                 episode reward: 0.1782,                 loss: 0.2314
Episode: 8521/10000 (85.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0175s / 632.5620 s
agent0:                 episode reward: 0.5447,                 loss: nan
agent1:                 episode reward: -0.5447,                 loss: 0.2317
Episode: 8531/10000 (85.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0786s / 633.6406 s
agent0:                 episode reward: -0.5900,                 loss: nan
agent1:                 episode reward: 0.5900,                 loss: 0.2303
Episode: 8541/10000 (85.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0153s / 634.6558 s
agent0:                 episode reward: -0.6513,                 loss: nan
agent1:                 episode reward: 0.6513,                 loss: 0.2313
Episode: 8551/10000 (85.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0353s / 635.6911 s
agent0:                 episode reward: 0.3453,                 loss: nan
agent1:                 episode reward: -0.3453,                 loss: 0.2303
Episode: 8561/10000 (85.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0223s / 636.7134 s
agent0:                 episode reward: 0.3245,                 loss: nan
agent1:                 episode reward: -0.3245,                 loss: 0.2333
Episode: 8571/10000 (85.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0081s / 637.7216 s
agent0:                 episode reward: 0.7218,                 loss: nan
agent1:                 episode reward: -0.7218,                 loss: 0.2633
Episode: 8581/10000 (85.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0388s / 638.7603 s
agent0:                 episode reward: -0.6146,                 loss: nan
agent1:                 episode reward: 0.6146,                 loss: 0.2697
Episode: 8591/10000 (85.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0126s / 639.7729 s
agent0:                 episode reward: 0.2214,                 loss: nan
agent1:                 episode reward: -0.2214,                 loss: 0.2696
Episode: 8601/10000 (86.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0066s / 640.7795 s
agent0:                 episode reward: -0.6288,                 loss: nan
agent1:                 episode reward: 0.6288,                 loss: 0.2706
Episode: 8611/10000 (86.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0442s / 641.8238 s
agent0:                 episode reward: 0.3409,                 loss: nan
agent1:                 episode reward: -0.3409,                 loss: 0.2673
Episode: 8621/10000 (86.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0135s / 642.8373 s
agent0:                 episode reward: -0.3028,                 loss: nan
agent1:                 episode reward: 0.3028,                 loss: 0.2683
Episode: 8631/10000 (86.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0859s / 643.9232 s
agent0:                 episode reward: 0.0230,                 loss: nan
agent1:                 episode reward: -0.0230,                 loss: 0.2699
Episode: 8641/10000 (86.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0243s / 644.9475 s
agent0:                 episode reward: -0.0661,                 loss: nan
agent1:                 episode reward: 0.0661,                 loss: 0.2675
Episode: 8651/10000 (86.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0323s / 645.9798 s
agent0:                 episode reward: 0.4019,                 loss: nan
agent1:                 episode reward: -0.4019,                 loss: 0.2720
Episode: 8661/10000 (86.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0251s / 647.0049 s
agent0:                 episode reward: 0.1646,                 loss: nan
agent1:                 episode reward: -0.1646,                 loss: 0.2697
Episode: 8671/10000 (86.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0313s / 648.0362 s
agent0:                 episode reward: -1.0685,                 loss: nan
agent1:                 episode reward: 1.0685,                 loss: 0.2991
Episode: 8681/10000 (86.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0446s / 649.0808 s
agent0:                 episode reward: -1.2761,                 loss: nan
agent1:                 episode reward: 1.2761,                 loss: 0.3024
Episode: 8691/10000 (86.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0212s / 650.1020 s
agent0:                 episode reward: 0.8139,                 loss: nan
agent1:                 episode reward: -0.8139,                 loss: 0.3000
Episode: 8701/10000 (87.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0278s / 651.1298 s
agent0:                 episode reward: 0.1485,                 loss: nan
agent1:                 episode reward: -0.1485,                 loss: 0.3026
Episode: 8711/10000 (87.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0434s / 652.1732 s
agent0:                 episode reward: -0.1376,                 loss: nan
agent1:                 episode reward: 0.1376,                 loss: 0.3020
Episode: 8721/10000 (87.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0570s / 653.2301 s
agent0:                 episode reward: -0.6188,                 loss: nan
agent1:                 episode reward: 0.6188,                 loss: 0.2993
Episode: 8731/10000 (87.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0980s / 654.3281 s
agent0:                 episode reward: -0.2539,                 loss: nan
agent1:                 episode reward: 0.2539,                 loss: 0.3026
Episode: 8741/10000 (87.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0544s / 655.3825 s
agent0:                 episode reward: -1.2512,                 loss: nan
agent1:                 episode reward: 1.2512,                 loss: 0.3026
Episode: 8751/10000 (87.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0542s / 656.4367 s
agent0:                 episode reward: -0.4497,                 loss: nan
agent1:                 episode reward: 0.4497,                 loss: 0.3017
Episode: 8761/10000 (87.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0366s / 657.4732 s
agent0:                 episode reward: -0.2065,                 loss: nan
agent1:                 episode reward: 0.2065,                 loss: 0.2998
Episode: 8771/10000 (87.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0460s / 658.5193 s
agent0:                 episode reward: -0.0042,                 loss: nan
agent1:                 episode reward: 0.0042,                 loss: 0.3110
Episode: 8781/10000 (87.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0385s / 659.5577 s
agent0:                 episode reward: -1.4731,                 loss: nan
agent1:                 episode reward: 1.4731,                 loss: 0.3045
Episode: 8791/10000 (87.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0468s / 660.6045 s
agent0:                 episode reward: -0.0052,                 loss: nan
agent1:                 episode reward: 0.0052,                 loss: 0.3026
Episode: 8801/10000 (88.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0332s / 661.6378 s
agent0:                 episode reward: -0.5153,                 loss: nan
agent1:                 episode reward: 0.5153,                 loss: 0.3022
Episode: 8811/10000 (88.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0477s / 662.6855 s
agent0:                 episode reward: -0.0070,                 loss: nan
agent1:                 episode reward: 0.0070,                 loss: 0.3008
Episode: 8821/10000 (88.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0577s / 663.7432 s
agent0:                 episode reward: 0.0183,                 loss: nan
agent1:                 episode reward: -0.0183,                 loss: 0.2999
Episode: 8831/10000 (88.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0849s / 664.8281 s
agent0:                 episode reward: -1.2699,                 loss: nan
agent1:                 episode reward: 1.2699,                 loss: 0.3024
Episode: 8841/10000 (88.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0355s / 665.8636 s
agent0:                 episode reward: 0.1425,                 loss: nan
agent1:                 episode reward: -0.1425,                 loss: 0.3017
Episode: 8851/10000 (88.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0558s / 666.9194 s
agent0:                 episode reward: -0.2906,                 loss: nan
agent1:                 episode reward: 0.2906,                 loss: 0.3004
Episode: 8861/10000 (88.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0412s / 667.9606 s
agent0:                 episode reward: -0.4765,                 loss: nan
agent1:                 episode reward: 0.4765,                 loss: 0.2992
Episode: 8871/10000 (88.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0389s / 668.9995 s
agent0:                 episode reward: 0.5790,                 loss: nan
agent1:                 episode reward: -0.5790,                 loss: 0.2990
Episode: 8881/10000 (88.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0122s / 670.0117 s
agent0:                 episode reward: 0.3343,                 loss: nan
agent1:                 episode reward: -0.3343,                 loss: 0.2899
Episode: 8891/10000 (88.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0398s / 671.0515 s
agent0:                 episode reward: -0.1727,                 loss: nan
agent1:                 episode reward: 0.1727,                 loss: 0.2919
Episode: 8901/10000 (89.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0490s / 672.1006 s
agent0:                 episode reward: -0.3602,                 loss: nan
agent1:                 episode reward: 0.3602,                 loss: 0.2911
Episode: 8911/10000 (89.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0708s / 673.1714 s
agent0:                 episode reward: -0.4985,                 loss: nan
agent1:                 episode reward: 0.4985,                 loss: 0.2909
Episode: 8921/10000 (89.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0807s / 674.2521 s
agent0:                 episode reward: 0.1812,                 loss: nan
agent1:                 episode reward: -0.1812,                 loss: 0.2909
Episode: 8931/10000 (89.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0452s / 675.2973 s
agent0:                 episode reward: 0.1724,                 loss: nan
agent1:                 episode reward: -0.1724,                 loss: 0.2893
Episode: 8941/10000 (89.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0525s / 676.3498 s
agent0:                 episode reward: 0.1751,                 loss: nan
agent1:                 episode reward: -0.1751,                 loss: 0.2887
Episode: 8951/10000 (89.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0223s / 677.3721 s
agent0:                 episode reward: -0.4648,                 loss: nan
agent1:                 episode reward: 0.4648,                 loss: 0.2897
Episode: 8961/10000 (89.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0481s / 678.4201 s
agent0:                 episode reward: -0.6339,                 loss: nan
agent1:                 episode reward: 0.6339,                 loss: 0.2893
Episode: 8971/10000 (89.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0470s / 679.4671 s
agent0:                 episode reward: -0.2770,                 loss: nan
agent1:                 episode reward: 0.2770,                 loss: 0.3152
Episode: 8981/10000 (89.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0405s / 680.5076 s
agent0:                 episode reward: 0.2791,                 loss: nan
agent1:                 episode reward: -0.2791,                 loss: 0.3179
Episode: 8991/10000 (89.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0288s / 681.5365 s
agent0:                 episode reward: 0.3025,                 loss: nan
agent1:                 episode reward: -0.3025,                 loss: 0.3139
Episode: 9001/10000 (90.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0800s / 682.6165 s
agent0:                 episode reward: 0.0483,                 loss: nan
agent1:                 episode reward: -0.0483,                 loss: 0.3137
Episode: 9011/10000 (90.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0529s / 683.6694 s
agent0:                 episode reward: -0.3102,                 loss: nan
agent1:                 episode reward: 0.3102,                 loss: 0.3141
Episode: 9021/10000 (90.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1188s / 684.7883 s
agent0:                 episode reward: 0.8641,                 loss: nan
agent1:                 episode reward: -0.8641,                 loss: 0.3150
Episode: 9031/10000 (90.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0412s / 685.8295 s
agent0:                 episode reward: 0.3621,                 loss: nan
agent1:                 episode reward: -0.3621,                 loss: 0.3136
Episode: 9041/10000 (90.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0679s / 686.8974 s
agent0:                 episode reward: 0.3760,                 loss: nan
agent1:                 episode reward: -0.3760,                 loss: 0.3133
Episode: 9051/10000 (90.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0455s / 687.9429 s
agent0:                 episode reward: -0.4672,                 loss: nan
agent1:                 episode reward: 0.4672,                 loss: 0.3094
Episode: 9061/10000 (90.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0238s / 688.9668 s
agent0:                 episode reward: 0.3811,                 loss: nan
agent1:                 episode reward: -0.3811,                 loss: 0.3110
Episode: 9071/10000 (90.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0183s / 689.9851 s
agent0:                 episode reward: -0.7426,                 loss: nan
agent1:                 episode reward: 0.7426,                 loss: 0.3158
Episode: 9081/10000 (90.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0666s / 691.0516 s
agent0:                 episode reward: 0.1763,                 loss: nan
agent1:                 episode reward: -0.1763,                 loss: 0.2952
Episode: 9091/10000 (90.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0606s / 692.1123 s
agent0:                 episode reward: -0.1285,                 loss: nan
agent1:                 episode reward: 0.1285,                 loss: 0.2926
Episode: 9101/10000 (91.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0603s / 693.1726 s
agent0:                 episode reward: 0.5455,                 loss: nan
agent1:                 episode reward: -0.5455,                 loss: 0.2923
Episode: 9111/10000 (91.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0777s / 694.2503 s
agent0:                 episode reward: 0.0714,                 loss: nan
agent1:                 episode reward: -0.0714,                 loss: 0.2922
Episode: 9121/10000 (91.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0747s / 695.3250 s
agent0:                 episode reward: -0.1296,                 loss: nan
agent1:                 episode reward: 0.1296,                 loss: 0.2912
Episode: 9131/10000 (91.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0268s / 696.3518 s
agent0:                 episode reward: 0.1670,                 loss: nan
agent1:                 episode reward: -0.1670,                 loss: 0.2945
Episode: 9141/10000 (91.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0923s / 697.4442 s
agent0:                 episode reward: -0.5006,                 loss: nan
agent1:                 episode reward: 0.5006,                 loss: 0.2917
Episode: 9151/10000 (91.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0520s / 698.4962 s
agent0:                 episode reward: -0.2432,                 loss: nan
agent1:                 episode reward: 0.2432,                 loss: 0.2925
Episode: 9161/10000 (91.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1028s / 699.5990 s
agent0:                 episode reward: -0.3343,                 loss: nan
agent1:                 episode reward: 0.3343,                 loss: 0.2906
Episode: 9171/10000 (91.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0733s / 700.6722 s
agent0:                 episode reward: -0.7432,                 loss: nan
agent1:                 episode reward: 0.7432,                 loss: 0.2377
Episode: 9181/10000 (91.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1033s / 701.7755 s
agent0:                 episode reward: -0.5282,                 loss: nan
agent1:                 episode reward: 0.5282,                 loss: 0.1887
Episode: 9191/10000 (91.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0725s / 702.8480 s
agent0:                 episode reward: 0.4181,                 loss: nan
agent1:                 episode reward: -0.4181,                 loss: 0.1842
Episode: 9201/10000 (92.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0842s / 703.9322 s
agent0:                 episode reward: 0.0971,                 loss: nan
agent1:                 episode reward: -0.0971,                 loss: 0.1836
Episode: 9211/10000 (92.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1042s / 705.0364 s
agent0:                 episode reward: 0.0476,                 loss: nan
agent1:                 episode reward: -0.0476,                 loss: 0.1827
Episode: 9221/10000 (92.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0662s / 706.1026 s
agent0:                 episode reward: -0.1917,                 loss: nan
agent1:                 episode reward: 0.1917,                 loss: 0.1837
Episode: 9231/10000 (92.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0616s / 707.1642 s
agent0:                 episode reward: 0.4159,                 loss: nan
agent1:                 episode reward: -0.4159,                 loss: 0.1819
Episode: 9241/10000 (92.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0457s / 708.2099 s
agent0:                 episode reward: 0.2095,                 loss: nan
agent1:                 episode reward: -0.2095,                 loss: 0.1822
Episode: 9251/10000 (92.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0896s / 709.2995 s
agent0:                 episode reward: 0.2548,                 loss: nan
agent1:                 episode reward: -0.2548,                 loss: 0.1801
Episode: 9261/10000 (92.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0915s / 710.3911 s
agent0:                 episode reward: -0.6360,                 loss: nan
agent1:                 episode reward: 0.6360,                 loss: 0.1811
Episode: 9271/10000 (92.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0941s / 711.4852 s
agent0:                 episode reward: 0.0307,                 loss: nan
agent1:                 episode reward: -0.0307,                 loss: 0.1663
Episode: 9281/10000 (92.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0623s / 712.5475 s
agent0:                 episode reward: 0.2260,                 loss: nan
agent1:                 episode reward: -0.2260,                 loss: 0.1502
Episode: 9291/10000 (92.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0633s / 713.6108 s
agent0:                 episode reward: 0.6941,                 loss: nan
agent1:                 episode reward: -0.6941,                 loss: 0.1483
Episode: 9301/10000 (93.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0558s / 714.6666 s
agent0:                 episode reward: -0.3911,                 loss: nan
agent1:                 episode reward: 0.3911,                 loss: 0.1491
Episode: 9311/10000 (93.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1259s / 715.7926 s
agent0:                 episode reward: 0.3002,                 loss: nan
agent1:                 episode reward: -0.3002,                 loss: 0.1482
Episode: 9321/10000 (93.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0986s / 716.8912 s
agent0:                 episode reward: -0.1438,                 loss: nan
agent1:                 episode reward: 0.1438,                 loss: 0.1487
Episode: 9331/10000 (93.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0866s / 717.9778 s
agent0:                 episode reward: -0.6517,                 loss: nan
agent1:                 episode reward: 0.6517,                 loss: 0.1459
Episode: 9341/10000 (93.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0746s / 719.0523 s
agent0:                 episode reward: 0.7761,                 loss: nan
agent1:                 episode reward: -0.7761,                 loss: 0.1476
Episode: 9351/10000 (93.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0887s / 720.1410 s
agent0:                 episode reward: -0.0562,                 loss: nan
agent1:                 episode reward: 0.0562,                 loss: 0.1469
Episode: 9361/10000 (93.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0839s / 721.2249 s
agent0:                 episode reward: -0.1225,                 loss: nan
agent1:                 episode reward: 0.1225,                 loss: 0.1465
Episode: 9371/10000 (93.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0999s / 722.3248 s
agent0:                 episode reward: -0.3805,                 loss: nan
agent1:                 episode reward: 0.3805,                 loss: 0.1735
Episode: 9381/10000 (93.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0883s / 723.4131 s
agent0:                 episode reward: -0.3181,                 loss: nan
agent1:                 episode reward: 0.3181,                 loss: 0.1813
Episode: 9391/10000 (93.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1085s / 724.5216 s
agent0:                 episode reward: -0.3130,                 loss: nan
agent1:                 episode reward: 0.3130,                 loss: 0.1790
Episode: 9401/10000 (94.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1606s / 725.6822 s
agent0:                 episode reward: -0.2054,                 loss: nan
agent1:                 episode reward: 0.2054,                 loss: 0.1811
Episode: 9411/10000 (94.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0927s / 726.7749 s
agent0:                 episode reward: -0.5721,                 loss: nan
agent1:                 episode reward: 0.5721,                 loss: 0.1801
Episode: 9421/10000 (94.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0940s / 727.8690 s
agent0:                 episode reward: -0.6742,                 loss: nan
agent1:                 episode reward: 0.6742,                 loss: 0.1800
Episode: 9431/10000 (94.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0881s / 728.9571 s
agent0:                 episode reward: -0.4014,                 loss: nan
agent1:                 episode reward: 0.4014,                 loss: 0.1804
Episode: 9441/10000 (94.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0899s / 730.0470 s
agent0:                 episode reward: 0.0340,                 loss: nan
agent1:                 episode reward: -0.0340,                 loss: 0.1808
Episode: 9451/10000 (94.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1288s / 731.1758 s
agent0:                 episode reward: -0.5421,                 loss: nan
agent1:                 episode reward: 0.5421,                 loss: 0.1795
Episode: 9461/10000 (94.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1005s / 732.2763 s
agent0:                 episode reward: -0.4021,                 loss: nan
agent1:                 episode reward: 0.4021,                 loss: 0.1793
Episode: 9471/10000 (94.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1041s / 733.3804 s
agent0:                 episode reward: -0.2557,                 loss: nan
agent1:                 episode reward: 0.2557,                 loss: 0.2164
Episode: 9481/10000 (94.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0776s / 734.4579 s
agent0:                 episode reward: -0.1754,                 loss: nan
agent1:                 episode reward: 0.1754,                 loss: 0.2258
Episode: 9491/10000 (94.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1257s / 735.5836 s
agent0:                 episode reward: -0.0715,                 loss: nan
agent1:                 episode reward: 0.0715,                 loss: 0.2271
Episode: 9501/10000 (95.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1218s / 736.7054 s
agent0:                 episode reward: -0.4919,                 loss: nan
agent1:                 episode reward: 0.4919,                 loss: 0.2267
Episode: 9511/10000 (95.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0992s / 737.8046 s
agent0:                 episode reward: 0.1421,                 loss: nan
agent1:                 episode reward: -0.1421,                 loss: 0.2235
Episode: 9521/10000 (95.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1063s / 738.9109 s
agent0:                 episode reward: -0.9069,                 loss: nan
agent1:                 episode reward: 0.9069,                 loss: 0.2253
Episode: 9531/10000 (95.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0903s / 740.0012 s
agent0:                 episode reward: 0.6699,                 loss: nan
agent1:                 episode reward: -0.6699,                 loss: 0.2261
Episode: 9541/10000 (95.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1291s / 741.1303 s
agent0:                 episode reward: 0.3536,                 loss: nan
agent1:                 episode reward: -0.3536,                 loss: 0.2264
Episode: 9551/10000 (95.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0998s / 742.2301 s
agent0:                 episode reward: -0.2879,                 loss: nan
agent1:                 episode reward: 0.2879,                 loss: 0.2254
Episode: 9561/10000 (95.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1064s / 743.3365 s
agent0:                 episode reward: 0.0887,                 loss: nan
agent1:                 episode reward: -0.0887,                 loss: 0.2240
Episode: 9571/10000 (95.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0878s / 744.4243 s
agent0:                 episode reward: -0.1466,                 loss: nan
agent1:                 episode reward: 0.1466,                 loss: 0.2587
Episode: 9581/10000 (95.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1002s / 745.5245 s
agent0:                 episode reward: -0.5200,                 loss: nan
agent1:                 episode reward: 0.5200,                 loss: 0.2700
Episode: 9591/10000 (95.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1411s / 746.6656 s
agent0:                 episode reward: 0.2265,                 loss: nan
agent1:                 episode reward: -0.2265,                 loss: 0.2690
Episode: 9601/10000 (96.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1080s / 747.7736 s
agent0:                 episode reward: -0.4187,                 loss: nan
agent1:                 episode reward: 0.4187,                 loss: 0.2665
Episode: 9611/10000 (96.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1271s / 748.9007 s
agent0:                 episode reward: -0.2689,                 loss: nan
agent1:                 episode reward: 0.2689,                 loss: 0.2678
Episode: 9621/10000 (96.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1007s / 750.0014 s
agent0:                 episode reward: 0.2734,                 loss: nan
agent1:                 episode reward: -0.2734,                 loss: 0.2718
Episode: 9631/10000 (96.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1086s / 751.1100 s
agent0:                 episode reward: -0.2475,                 loss: nan
agent1:                 episode reward: 0.2475,                 loss: 0.2681
Episode: 9641/10000 (96.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1078s / 752.2178 s
agent0:                 episode reward: -0.3402,                 loss: nan
agent1:                 episode reward: 0.3402,                 loss: 0.2642
Episode: 9651/10000 (96.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.0995s / 753.3173 s
agent0:                 episode reward: -0.0254,                 loss: nan
agent1:                 episode reward: 0.0254,                 loss: 0.2649
Episode: 9661/10000 (96.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1127s / 754.4300 s
agent0:                 episode reward: 0.0919,                 loss: nan
agent1:                 episode reward: -0.0919,                 loss: 0.2660
Episode: 9671/10000 (96.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1169s / 755.5469 s
agent0:                 episode reward: -0.3064,                 loss: nan
agent1:                 episode reward: 0.3064,                 loss: 0.2949
Episode: 9681/10000 (96.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1492s / 756.6961 s
agent0:                 episode reward: -0.7406,                 loss: nan
agent1:                 episode reward: 0.7406,                 loss: 0.2994
Episode: 9691/10000 (96.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1395s / 757.8356 s
agent0:                 episode reward: 0.1065,                 loss: nan
agent1:                 episode reward: -0.1065,                 loss: 0.3001
Episode: 9701/10000 (97.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1163s / 758.9519 s
agent0:                 episode reward: 0.3709,                 loss: nan
agent1:                 episode reward: -0.3709,                 loss: 0.3010
Episode: 9711/10000 (97.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1082s / 760.0602 s
agent0:                 episode reward: 0.4247,                 loss: nan
agent1:                 episode reward: -0.4247,                 loss: 0.2992
Episode: 9721/10000 (97.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1304s / 761.1905 s
agent0:                 episode reward: 1.0082,                 loss: nan
agent1:                 episode reward: -1.0082,                 loss: 0.2972
Episode: 9731/10000 (97.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1146s / 762.3051 s
agent0:                 episode reward: -0.7374,                 loss: nan
agent1:                 episode reward: 0.7374,                 loss: 0.2976
Episode: 9741/10000 (97.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1099s / 763.4149 s
agent0:                 episode reward: 0.1180,                 loss: nan
agent1:                 episode reward: -0.1180,                 loss: 0.2964
Episode: 9751/10000 (97.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1048s / 764.5197 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.2953
Episode: 9761/10000 (97.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1197s / 765.6395 s
agent0:                 episode reward: -0.9290,                 loss: nan
agent1:                 episode reward: 0.9290,                 loss: 0.2968
Episode: 9771/10000 (97.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1493s / 766.7888 s
agent0:                 episode reward: -0.0655,                 loss: nan
agent1:                 episode reward: 0.0655,                 loss: 0.2936
Episode: 9781/10000 (97.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1215s / 767.9103 s
agent0:                 episode reward: -0.4042,                 loss: nan
agent1:                 episode reward: 0.4042,                 loss: 0.2892
Episode: 9791/10000 (97.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1058s / 769.0161 s
agent0:                 episode reward: -0.1581,                 loss: nan
agent1:                 episode reward: 0.1581,                 loss: 0.2841
Episode: 9801/10000 (98.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1253s / 770.1414 s
agent0:                 episode reward: 0.6255,                 loss: nan
agent1:                 episode reward: -0.6255,                 loss: 0.2870
Episode: 9811/10000 (98.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1119s / 771.2533 s
agent0:                 episode reward: 0.1321,                 loss: nan
agent1:                 episode reward: -0.1321,                 loss: 0.2842
Episode: 9821/10000 (98.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1124s / 772.3657 s
agent0:                 episode reward: -0.0186,                 loss: nan
agent1:                 episode reward: 0.0186,                 loss: 0.2829
Episode: 9831/10000 (98.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1211s / 773.4867 s
agent0:                 episode reward: -0.2812,                 loss: nan
agent1:                 episode reward: 0.2812,                 loss: 0.2837/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9841/10000 (98.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1211s / 774.6079 s
agent0:                 episode reward: -0.8358,                 loss: nan
agent1:                 episode reward: 0.8358,                 loss: 0.2823
Episode: 9851/10000 (98.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1194s / 775.7273 s
agent0:                 episode reward: -0.2015,                 loss: nan
agent1:                 episode reward: 0.2015,                 loss: 0.2825
Episode: 9861/10000 (98.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1524s / 776.8797 s
agent0:                 episode reward: -0.8592,                 loss: nan
agent1:                 episode reward: 0.8592,                 loss: 0.2791
Episode: 9871/10000 (98.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1257s / 778.0053 s
agent0:                 episode reward: -0.4407,                 loss: nan
agent1:                 episode reward: 0.4407,                 loss: 0.2851
Episode: 9881/10000 (98.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1215s / 779.1268 s
agent0:                 episode reward: 0.8129,                 loss: nan
agent1:                 episode reward: -0.8129,                 loss: 0.2775
Episode: 9891/10000 (98.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1191s / 780.2459 s
agent0:                 episode reward: 0.5309,                 loss: nan
agent1:                 episode reward: -0.5309,                 loss: 0.2762
Episode: 9901/10000 (99.0100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1130s / 781.3589 s
agent0:                 episode reward: -0.2383,                 loss: nan
agent1:                 episode reward: 0.2383,                 loss: 0.2765
Episode: 9911/10000 (99.1100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1384s / 782.4973 s
agent0:                 episode reward: -0.5532,                 loss: nan
agent1:                 episode reward: 0.5532,                 loss: 0.2769
Episode: 9921/10000 (99.2100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1386s / 783.6359 s
agent0:                 episode reward: -0.3134,                 loss: nan
agent1:                 episode reward: 0.3134,                 loss: 0.2742
Episode: 9931/10000 (99.3100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1381s / 784.7740 s
agent0:                 episode reward: -1.0112,                 loss: nan
agent1:                 episode reward: 1.0112,                 loss: 0.2727
Episode: 9941/10000 (99.4100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1497s / 785.9237 s
agent0:                 episode reward: 0.3366,                 loss: nan
agent1:                 episode reward: -0.3366,                 loss: 0.2746
Episode: 9951/10000 (99.5100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1685s / 787.0922 s
agent0:                 episode reward: -0.6861,                 loss: nan
agent1:                 episode reward: 0.6861,                 loss: 0.2740
Episode: 9961/10000 (99.6100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1371s / 788.2293 s
agent0:                 episode reward: 0.5184,                 loss: nan
agent1:                 episode reward: -0.5184,                 loss: 0.2717
Episode: 9971/10000 (99.7100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1283s / 789.3576 s
agent0:                 episode reward: -0.6469,                 loss: nan
agent1:                 episode reward: 0.6469,                 loss: 0.2817
Episode: 9981/10000 (99.8100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1454s / 790.5029 s
agent0:                 episode reward: -0.5413,                 loss: nan
agent1:                 episode reward: 0.5413,                 loss: 0.2784
Episode: 9991/10000 (99.9100%),                 avg. length: 9.0,                last time consumption/overall running time: 1.1295s / 791.6325 s
agent0:                 episode reward: -0.2549,                 loss: nan
agent1:                 episode reward: 0.2549,                 loss: 0.2755
