pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [71, 34]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220115_0159/pettingzoo_pong_v2_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220115_0159/pettingzoo_pong_v2_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 1409.0,                last time consumption/overall running time: 12.5772s / 12.5772 s
env0_first_0:                 episode reward: 8.0000,                 loss: 0.2979
env0_second_0:                 episode reward: -8.0000,                 loss: 0.2648
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1190.5,                last time consumption/overall running time: 185.5699s / 198.1472 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.3259
env0_second_0:                 episode reward: -1.5000,                 loss: 0.3312
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1265.9,                last time consumption/overall running time: 198.2688s / 396.4159 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.5879
env0_second_0:                 episode reward: -4.1500,                 loss: 0.5895
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1252.75,                last time consumption/overall running time: 195.8948s / 592.3107 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.6657
env0_second_0:                 episode reward: -0.6500,                 loss: 0.6416
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1135.55,                last time consumption/overall running time: 178.6518s / 770.9625 s
env0_first_0:                 episode reward: 7.4500,                 loss: 0.5907
env0_second_0:                 episode reward: -7.4500,                 loss: 0.5560
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1125.3,                last time consumption/overall running time: 176.1243s / 947.0868 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.6132
env0_second_0:                 episode reward: 0.4000,                 loss: 0.5725
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1134.5,                last time consumption/overall running time: 178.0972s / 1125.1840 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.6013
env0_second_0:                 episode reward: -1.4500,                 loss: 0.5630
env1_first_0:                 episode reward: 6.4000,                 loss: nan
env1_second_0:                 episode reward: -6.4000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1175.15,                last time consumption/overall running time: 183.0238s / 1308.2078 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.5677
env0_second_0:                 episode reward: -1.5500,                 loss: 0.5391
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1268.45,                last time consumption/overall running time: 196.9404s / 1505.1482 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.5716
env0_second_0:                 episode reward: -3.8000,                 loss: 0.5452
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1253.65,                last time consumption/overall running time: 198.3283s / 1703.4766 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.5691
env0_second_0:                 episode reward: -0.2500,                 loss: 0.5522
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1178.35,                last time consumption/overall running time: 183.9937s / 1887.4703 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.5577
env0_second_0:                 episode reward: -1.4000,                 loss: 0.5384
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1203.1,                last time consumption/overall running time: 189.3514s / 2076.8217 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.5209
env0_second_0:                 episode reward: -0.3500,                 loss: 0.5073
env1_first_0:                 episode reward: 6.4500,                 loss: nan
env1_second_0:                 episode reward: -6.4500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1176.1,                last time consumption/overall running time: 182.7468s / 2259.5684 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.4950
env0_second_0:                 episode reward: -0.6000,                 loss: 0.4775
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1196.1,                last time consumption/overall running time: 186.5023s / 2446.0708 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.4411
env0_second_0:                 episode reward: -0.9500,                 loss: 0.4231
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1163.1,                last time consumption/overall running time: 180.4189s / 2626.4896 s
env0_first_0:                 episode reward: 6.0000,                 loss: 0.4604
env0_second_0:                 episode reward: -6.0000,                 loss: 0.4547
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1226.0,                last time consumption/overall running time: 188.3440s / 2814.8337 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.4466
env0_second_0:                 episode reward: -3.8000,                 loss: 0.4442
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1200.15,                last time consumption/overall running time: 188.9994s / 3003.8331 s
env0_first_0:                 episode reward: 4.7000,                 loss: 0.4791
env0_second_0:                 episode reward: -4.7000,                 loss: 0.4690
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1259.0,                last time consumption/overall running time: 196.6815s / 3200.5145 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.4494
env0_second_0:                 episode reward: -3.5500,                 loss: 0.4485
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1102.9,                last time consumption/overall running time: 175.3084s / 3375.8230 s
env0_first_0:                 episode reward: 6.2000,                 loss: 0.4184
env0_second_0:                 episode reward: -6.2000,                 loss: 0.4112
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1231.25,                last time consumption/overall running time: 191.2333s / 3567.0563 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.4856
env0_second_0:                 episode reward: -1.4000,                 loss: 0.4530
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1147.35,                last time consumption/overall running time: 181.5561s / 3748.6123 s
env0_first_0:                 episode reward: 5.6000,                 loss: 0.4168
env0_second_0:                 episode reward: -5.6000,                 loss: 0.4087
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1210.8,                last time consumption/overall running time: 189.0555s / 3937.6679 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.4422
env0_second_0:                 episode reward: -3.3500,                 loss: 0.4333
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1233.0,                last time consumption/overall running time: 189.7341s / 4127.4020 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.4341
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4326
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1299.7,                last time consumption/overall running time: 200.6856s / 4328.0876 s
env0_first_0:                 episode reward: 5.4500,                 loss: 0.4028
env0_second_0:                 episode reward: -5.4500,                 loss: 0.4022
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1236.25,                last time consumption/overall running time: 189.8403s / 4517.9279 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.4124
env0_second_0:                 episode reward: -3.1500,                 loss: 0.4151
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1199.05,                last time consumption/overall running time: 185.2443s / 4703.1722 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.4641
env0_second_0:                 episode reward: -1.5000,                 loss: 0.4654
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1198.45,                last time consumption/overall running time: 186.2086s / 4889.3809 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.4642
env0_second_0:                 episode reward: -0.2000,                 loss: 0.4641
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1215.75,                last time consumption/overall running time: 188.2269s / 5077.6077 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.4439
env0_second_0:                 episode reward: -2.9500,                 loss: 0.4416
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1210.8,                last time consumption/overall running time: 186.2583s / 5263.8660 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.4120
env0_second_0:                 episode reward: -2.3500,                 loss: 0.4111
env1_first_0:                 episode reward: 7.2000,                 loss: nan
env1_second_0:                 episode reward: -7.2000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1218.4,                last time consumption/overall running time: 186.7754s / 5450.6414 s
env0_first_0:                 episode reward: 4.3500,                 loss: 0.4138
env0_second_0:                 episode reward: -4.3500,                 loss: 0.4157
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1173.85,                last time consumption/overall running time: 181.0631s / 5631.7045 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.4301
env0_second_0:                 episode reward: 4.8000,                 loss: 0.4224
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1233.5,                last time consumption/overall running time: 190.8077s / 5822.5122 s
env0_first_0:                 episode reward: 5.9500,                 loss: 0.4234
env0_second_0:                 episode reward: -5.9500,                 loss: 0.4165
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1263.65,                last time consumption/overall running time: 194.8941s / 6017.4063 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.3835
env0_second_0:                 episode reward: -4.1000,                 loss: 0.3825
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1235.1,                last time consumption/overall running time: 188.8908s / 6206.2971 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.4436
env0_second_0:                 episode reward: 2.2000,                 loss: 0.4499
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1150.25,                last time consumption/overall running time: 176.9584s / 6383.2555 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.4345
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4222
env1_first_0:                 episode reward: 5.6500,                 loss: nan
env1_second_0:                 episode reward: -5.6500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1254.7,                last time consumption/overall running time: 193.2109s / 6576.4663 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.4173
env0_second_0:                 episode reward: -3.2000,                 loss: 0.4182
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1231.9,                last time consumption/overall running time: 188.7067s / 6765.1730 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.4055
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3924
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1143.85,                last time consumption/overall running time: 175.4377s / 6940.6107 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.4209
env0_second_0:                 episode reward: -2.1500,                 loss: 0.4204
env1_first_0:                 episode reward: 4.0500,                 loss: nan
env1_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1207.15,                last time consumption/overall running time: 186.8195s / 7127.4302 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.4314
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4307
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1118.6,                last time consumption/overall running time: 174.6510s / 7302.0812 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.4327
env0_second_0:                 episode reward: -2.2000,                 loss: 0.4325
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1164.2,                last time consumption/overall running time: 180.0979s / 7482.1791 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3999
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4124
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1182.45,                last time consumption/overall running time: 184.1840s / 7666.3631 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.4568
env0_second_0:                 episode reward: -3.5000,                 loss: 0.4455
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1197.6,                last time consumption/overall running time: 184.8401s / 7851.2031 s
env0_first_0:                 episode reward: 4.9000,                 loss: 0.4268
env0_second_0:                 episode reward: -4.9000,                 loss: 0.4323
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1263.55,                last time consumption/overall running time: 193.8740s / 8045.0771 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.4005
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3989
env1_first_0:                 episode reward: 6.0000,                 loss: nan
env1_second_0:                 episode reward: -6.0000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1208.05,                last time consumption/overall running time: 188.6379s / 8233.7150 s
env0_first_0:                 episode reward: 6.2500,                 loss: 0.4023
env0_second_0:                 episode reward: -6.2500,                 loss: 0.4022
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1200.2,                last time consumption/overall running time: 184.6112s / 8418.3262 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.4097
env0_second_0:                 episode reward: -2.3500,                 loss: 0.4132
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1187.3,                last time consumption/overall running time: 182.3986s / 8600.7248 s
env0_first_0:                 episode reward: 5.0000,                 loss: 0.3800
env0_second_0:                 episode reward: -5.0000,                 loss: 0.3717
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1142.25,                last time consumption/overall running time: 175.8117s / 8776.5366 s
env0_first_0:                 episode reward: 6.0000,                 loss: 0.4144
env0_second_0:                 episode reward: -6.0000,                 loss: 0.4162
env1_first_0:                 episode reward: 4.4500,                 loss: nan
env1_second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1219.0,                last time consumption/overall running time: 187.4710s / 8964.0076 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.4440
env0_second_0:                 episode reward: -2.8500,                 loss: 0.4491
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1310.15,                last time consumption/overall running time: 200.6163s / 9164.6239 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.4028
env0_second_0:                 episode reward: 1.4000,                 loss: 0.4009
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1231.85,                last time consumption/overall running time: 190.8647s / 9355.4886 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.4071
env0_second_0:                 episode reward: -1.7500,                 loss: 0.4043
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1291.95,                last time consumption/overall running time: 198.9532s / 9554.4417 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.4263
env0_second_0:                 episode reward: -3.0000,                 loss: 0.4266
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1247.45,                last time consumption/overall running time: 191.4820s / 9745.9238 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.4196
env0_second_0:                 episode reward: -4.2500,                 loss: 0.4165
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1278.15,                last time consumption/overall running time: 196.1838s / 9942.1075 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.4081
env0_second_0:                 episode reward: 2.0500,                 loss: 0.4085
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1205.45,                last time consumption/overall running time: 183.8663s / 10125.9738 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3897
env0_second_0:                 episode reward: -1.2000,                 loss: 0.3894
env1_first_0:                 episode reward: 4.4500,                 loss: nan
env1_second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1153.8,                last time consumption/overall running time: 178.2800s / 10304.2538 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.4565
env0_second_0:                 episode reward: 2.4000,                 loss: 0.4544
env1_first_0:                 episode reward: 5.8500,                 loss: nan
env1_second_0:                 episode reward: -5.8500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1240.3,                last time consumption/overall running time: 190.9490s / 10495.2028 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.4226
env0_second_0:                 episode reward: -3.1500,                 loss: 0.4394
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1193.95,                last time consumption/overall running time: 183.0659s / 10678.2687 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.4201
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4267
env1_first_0:                 episode reward: 5.2000,                 loss: nan
env1_second_0:                 episode reward: -5.2000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1137.9,                last time consumption/overall running time: 175.1028s / 10853.3715 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.4270
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4166
env1_first_0:                 episode reward: 6.2500,                 loss: nan
env1_second_0:                 episode reward: -6.2500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1176.95,                last time consumption/overall running time: 181.4771s / 11034.8486 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.4322
env0_second_0:                 episode reward: -2.6000,                 loss: 0.4082
env1_first_0:                 episode reward: 6.3000,                 loss: nan
env1_second_0:                 episode reward: -6.3000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1163.0,                last time consumption/overall running time: 181.5202s / 11216.3688 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.4242
env0_second_0:                 episode reward: -2.1500,                 loss: 0.3904
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1220.85,                last time consumption/overall running time: 188.8548s / 11405.2236 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.4266
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4299
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1208.4,                last time consumption/overall running time: 186.0491s / 11591.2727 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.4588
env0_second_0:                 episode reward: -1.2500,                 loss: 0.4619
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1235.45,                last time consumption/overall running time: 188.9267s / 11780.1994 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.3969
env0_second_0:                 episode reward: -3.7500,                 loss: 0.3951
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1222.95,                last time consumption/overall running time: 187.2741s / 11967.4735 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.4861
env0_second_0:                 episode reward: 1.6500,                 loss: 0.4902
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1194.45,                last time consumption/overall running time: 186.1572s / 12153.6307 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.3979
env0_second_0:                 episode reward: -1.1500,                 loss: 0.3933
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1164.2,                last time consumption/overall running time: 182.3309s / 12335.9616 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.4203
env0_second_0:                 episode reward: -5.9000,                 loss: 0.4136
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1154.3,                last time consumption/overall running time: 176.9294s / 12512.8910 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.4022
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3957
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1262.9,                last time consumption/overall running time: 196.1508s / 12709.0418 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.4188
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4213
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1188.95,                last time consumption/overall running time: 182.2413s / 12891.2831 s
env0_first_0:                 episode reward: 6.0500,                 loss: 0.4434
env0_second_0:                 episode reward: -6.0500,                 loss: 0.4362
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1149.45,                last time consumption/overall running time: 178.9607s / 13070.2438 s
env0_first_0:                 episode reward: 5.7000,                 loss: 0.3923
env0_second_0:                 episode reward: -5.7000,                 loss: 0.3947
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1184.55,                last time consumption/overall running time: 185.0191s / 13255.2629 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.4175
env0_second_0:                 episode reward: -1.1500,                 loss: 0.4402
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1214.25,                last time consumption/overall running time: 189.0512s / 13444.3141 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3823
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3888
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1230.65,                last time consumption/overall running time: 190.7048s / 13635.0189 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.3958
env0_second_0:                 episode reward: -3.1000,                 loss: 0.3878
env1_first_0:                 episode reward: 5.1000,                 loss: nan
env1_second_0:                 episode reward: -5.1000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1249.25,                last time consumption/overall running time: 191.4125s / 13826.4315 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.4135
env0_second_0:                 episode reward: -2.1500,                 loss: 0.4223
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1237.15,                last time consumption/overall running time: 194.1480s / 14020.5795 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.3834
env0_second_0:                 episode reward: -2.5500,                 loss: 0.3811
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1181.75,                last time consumption/overall running time: 182.8221s / 14203.4015 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.3801
env0_second_0:                 episode reward: -1.5000,                 loss: 0.3833
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1190.05,                last time consumption/overall running time: 182.4982s / 14385.8997 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.4359
env0_second_0:                 episode reward: -3.2000,                 loss: 0.4423
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1220.25,                last time consumption/overall running time: 186.6407s / 14572.5404 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.3927
env0_second_0:                 episode reward: -3.5000,                 loss: 0.4018
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1224.4,                last time consumption/overall running time: 190.0040s / 14762.5443 s
env0_first_0:                 episode reward: 4.3000,                 loss: 0.4347
env0_second_0:                 episode reward: -4.3000,                 loss: 0.4316
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1237.05,                last time consumption/overall running time: 189.6520s / 14952.1963 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.3718
env0_second_0:                 episode reward: -3.9500,                 loss: 0.3730
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1278.35,                last time consumption/overall running time: 196.8268s / 15149.0232 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.4142
env0_second_0:                 episode reward: -3.0500,                 loss: 0.4076
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1261.9,                last time consumption/overall running time: 194.9950s / 15344.0181 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3741
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3914
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1201.05,                last time consumption/overall running time: 187.5976s / 15531.6157 s
env0_first_0:                 episode reward: 5.2500,                 loss: 0.4445
env0_second_0:                 episode reward: -5.2500,                 loss: 0.4370
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1233.1,                last time consumption/overall running time: 189.5872s / 15721.2029 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.3964
env0_second_0:                 episode reward: 2.7500,                 loss: 0.4049
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1126.0,                last time consumption/overall running time: 173.5487s / 15894.7516 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.4123
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4119
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1217.45,                last time consumption/overall running time: 187.4038s / 16082.1553 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3987
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4158
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1232.25,                last time consumption/overall running time: 190.1675s / 16272.3229 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3803
env0_second_0:                 episode reward: 0.3500,                 loss: 0.3947
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1217.3,                last time consumption/overall running time: 184.5544s / 16456.8773 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.4116
env0_second_0:                 episode reward: 3.0000,                 loss: 0.3977
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1164.85,                last time consumption/overall running time: 180.9030s / 16637.7803 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.3911
env0_second_0:                 episode reward: 2.5500,                 loss: 0.3998
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1261.45,                last time consumption/overall running time: 195.6036s / 16833.3838 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.3885
env0_second_0:                 episode reward: -3.0000,                 loss: 0.3892
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1256.95,                last time consumption/overall running time: 195.2233s / 17028.6072 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.3807
env0_second_0:                 episode reward: -4.1000,                 loss: 0.3841
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1284.75,                last time consumption/overall running time: 197.1257s / 17225.7329 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.4158
env0_second_0:                 episode reward: -2.8000,                 loss: 0.4109
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1194.95,                last time consumption/overall running time: 186.6727s / 17412.4056 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3876
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3959
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1219.6,                last time consumption/overall running time: 188.4406s / 17600.8463 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.4499
env0_second_0:                 episode reward: -1.4500,                 loss: 0.4476
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1222.75,                last time consumption/overall running time: 188.4337s / 17789.2799 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.4301
env0_second_0:                 episode reward: 1.0500,                 loss: 0.4256
env1_first_0:                 episode reward: 5.4500,                 loss: nan
env1_second_0:                 episode reward: -5.4500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1181.45,                last time consumption/overall running time: 181.0222s / 17970.3022 s
env0_first_0:                 episode reward: 5.4500,                 loss: 0.3871
env0_second_0:                 episode reward: -5.4500,                 loss: 0.4096
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1178.65,                last time consumption/overall running time: 180.7356s / 18151.0377 s
env0_first_0:                 episode reward: 5.0000,                 loss: 0.4339
env0_second_0:                 episode reward: -5.0000,                 loss: 0.4365
env1_first_0:                 episode reward: 5.3500,                 loss: nan
env1_second_0:                 episode reward: -5.3500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 1312.3,                last time consumption/overall running time: 201.8209s / 18352.8586 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3917
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4035
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1195.5,                last time consumption/overall running time: 183.4995s / 18536.3581 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.3774
env0_second_0:                 episode reward: -2.1500,                 loss: 0.3746
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1147.0,                last time consumption/overall running time: 177.6226s / 18713.9807 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.4213
env0_second_0:                 episode reward: -2.1500,                 loss: 0.4185
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1220.25,                last time consumption/overall running time: 186.6423s / 18900.6231 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.4585
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4606
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1208.8,                last time consumption/overall running time: 188.0328s / 19088.6558 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.3782
env0_second_0:                 episode reward: 1.5500,                 loss: 0.3873
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1231.5,                last time consumption/overall running time: 194.1924s / 19282.8482 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.4211
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4275
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1186.5,                last time consumption/overall running time: 185.8728s / 19468.7210 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3731
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3766
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1197.95,                last time consumption/overall running time: 186.3695s / 19655.0905 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3907
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3957
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1199.15,                last time consumption/overall running time: 185.2606s / 19840.3510 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3825
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3836
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 1160.95,                last time consumption/overall running time: 178.7614s / 20019.1124 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.4185
env0_second_0:                 episode reward: -1.4500,                 loss: 0.4116
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1337.3,                last time consumption/overall running time: 204.8258s / 20223.9383 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.4070
env0_second_0:                 episode reward: -1.3000,                 loss: 0.4095
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1195.55,                last time consumption/overall running time: 185.3734s / 20409.3116 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3818
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3871
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1170.55,                last time consumption/overall running time: 183.6156s / 20592.9273 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.4344
env0_second_0:                 episode reward: -1.5500,                 loss: 0.4355
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 1218.9,                last time consumption/overall running time: 189.0384s / 20781.9656 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.3832
env0_second_0:                 episode reward: -2.2500,                 loss: 0.3877
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 1226.15,                last time consumption/overall running time: 191.9883s / 20973.9539 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.3998
env0_second_0:                 episode reward: -1.4500,                 loss: 0.4010
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 1215.45,                last time consumption/overall running time: 190.0157s / 21163.9696 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.4148
env0_second_0:                 episode reward: -2.4500,                 loss: 0.4131
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 1217.6,                last time consumption/overall running time: 188.9345s / 21352.9041 s
env0_first_0:                 episode reward: 4.4500,                 loss: 0.3812
env0_second_0:                 episode reward: -4.4500,                 loss: 0.3819
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 1261.3,                last time consumption/overall running time: 194.8462s / 21547.7503 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.3888
env0_second_0:                 episode reward: -4.8500,                 loss: 0.3916
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1229.35,                last time consumption/overall running time: 189.9722s / 21737.7225 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.4220
env0_second_0:                 episode reward: -3.5000,                 loss: 0.4197
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1248.55,                last time consumption/overall running time: 191.7729s / 21929.4954 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.3943
env0_second_0:                 episode reward: -3.4500,                 loss: 0.3918
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1293.65,                last time consumption/overall running time: 200.8457s / 22130.3411 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3737
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3706
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1137.95,                last time consumption/overall running time: 175.9465s / 22306.2876 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.4052
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4082
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 1231.6,                last time consumption/overall running time: 189.7611s / 22496.0487 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.4093
env0_second_0:                 episode reward: -4.5500,                 loss: 0.4104
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1244.9,                last time consumption/overall running time: 191.4852s / 22687.5339 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.4261
env0_second_0:                 episode reward: -2.3500,                 loss: 0.4379
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1233.95,                last time consumption/overall running time: 190.0984s / 22877.6322 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.3585
env0_second_0:                 episode reward: -3.2500,                 loss: 0.3766
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1210.8,                last time consumption/overall running time: 185.3525s / 23062.9847 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.4043
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4020
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1161.6,                last time consumption/overall running time: 178.8344s / 23241.8191 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.4001
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4004
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1235.2,                last time consumption/overall running time: 188.7209s / 23430.5401 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.4448
env0_second_0:                 episode reward: -1.2500,                 loss: 0.4550
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 1137.15,                last time consumption/overall running time: 175.4715s / 23606.0115 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.3617
env0_second_0:                 episode reward: -3.1500,                 loss: 0.3603
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1304.8,                last time consumption/overall running time: 199.0375s / 23805.0490 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.4103
env0_second_0:                 episode reward: -1.0500,                 loss: 0.4186
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1283.45,                last time consumption/overall running time: 198.4648s / 24003.5138 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.3634
env0_second_0:                 episode reward: -3.4000,                 loss: 0.3612
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1152.5,                last time consumption/overall running time: 178.5432s / 24182.0571 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.3819
env0_second_0:                 episode reward: -2.4500,                 loss: 0.3922
env1_first_0:                 episode reward: 4.0500,                 loss: nan
env1_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1182.6,                last time consumption/overall running time: 183.2872s / 24365.3442 s
env0_first_0:                 episode reward: 7.5000,                 loss: 0.4178
env0_second_0:                 episode reward: -7.5000,                 loss: 0.4202
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1200.8,                last time consumption/overall running time: 184.3599s / 24549.7041 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.4021
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3977
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1159.15,                last time consumption/overall running time: 178.1788s / 24727.8829 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.4362
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4441
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 1175.0,                last time consumption/overall running time: 183.2493s / 24911.1322 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.3973
env0_second_0:                 episode reward: -2.6000,                 loss: 0.3936
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1309.55,                last time consumption/overall running time: 198.9797s / 25110.1119 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3889
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3844
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 1253.55,                last time consumption/overall running time: 192.8860s / 25302.9979 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.4302
env0_second_0:                 episode reward: -1.0500,                 loss: 0.4258
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1221.2,                last time consumption/overall running time: 189.0254s / 25492.0233 s
env0_first_0:                 episode reward: 5.6000,                 loss: 0.3903
env0_second_0:                 episode reward: -5.6000,                 loss: 0.3805
env1_first_0:                 episode reward: 4.0500,                 loss: nan
env1_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1173.2,                last time consumption/overall running time: 179.4102s / 25671.4335 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.4311
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4115
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 1265.65,                last time consumption/overall running time: 193.1314s / 25864.5650 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.3861
env0_second_0:                 episode reward: -3.2000,                 loss: 0.3787
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1286.1,                last time consumption/overall running time: 194.8231s / 26059.3880 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.3430
env0_second_0:                 episode reward: -3.4500,                 loss: 0.3387
env1_first_0:                 episode reward: 4.6000,                 loss: nan
env1_second_0:                 episode reward: -4.6000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1232.2,                last time consumption/overall running time: 190.2317s / 26249.6198 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.3911
env0_second_0:                 episode reward: -3.7500,                 loss: 0.3874
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1256.6,                last time consumption/overall running time: 192.9323s / 26442.5521 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.4085
env0_second_0:                 episode reward: 2.1500,                 loss: 0.4107
env1_first_0:                 episode reward: 5.8000,                 loss: nan
env1_second_0:                 episode reward: -5.8000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1200.95,                last time consumption/overall running time: 186.1738s / 26628.7259 s
env0_first_0:                 episode reward: 5.6000,                 loss: 0.4125
env0_second_0:                 episode reward: -5.6000,                 loss: 0.4009
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1194.25,                last time consumption/overall running time: 186.0645s / 26814.7904 s
env0_first_0:                 episode reward: 5.2000,                 loss: 0.3905
env0_second_0:                 episode reward: -5.2000,                 loss: 0.3985
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1241.4,                last time consumption/overall running time: 191.2719s / 27006.0622 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.4148
env0_second_0:                 episode reward: -3.3000,                 loss: 0.4211
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1192.25,                last time consumption/overall running time: 185.7734s / 27191.8356 s
env0_first_0:                 episode reward: 5.7000,                 loss: 0.4242
env0_second_0:                 episode reward: -5.7000,                 loss: 0.4180
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 1270.75,                last time consumption/overall running time: 195.6718s / 27387.5074 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.4062
env0_second_0:                 episode reward: -3.3000,                 loss: 0.3974
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1208.7,                last time consumption/overall running time: 186.0142s / 27573.5216 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.4161
env0_second_0:                 episode reward: -2.0000,                 loss: 0.4100
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 1181.15,                last time consumption/overall running time: 183.0185s / 27756.5401 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.3901
env0_second_0:                 episode reward: -1.9500,                 loss: 0.3944
env1_first_0:                 episode reward: 4.7500,                 loss: nan
env1_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1174.6,                last time consumption/overall running time: 182.7684s / 27939.3085 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.4528
env0_second_0:                 episode reward: -2.6000,                 loss: 0.4575
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1140.75,                last time consumption/overall running time: 176.2664s / 28115.5749 s
env0_first_0:                 episode reward: 6.9000,                 loss: 0.3956
env0_second_0:                 episode reward: -6.9000,                 loss: 0.4071
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1245.7,                last time consumption/overall running time: 192.0860s / 28307.6608 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.4146
env0_second_0:                 episode reward: -4.2000,                 loss: 0.4254
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1228.6,                last time consumption/overall running time: 190.5055s / 28498.1663 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.3712
env0_second_0:                 episode reward: -2.4500,                 loss: 0.3941
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1209.9,                last time consumption/overall running time: 186.8859s / 28685.0521 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.4479
env0_second_0:                 episode reward: -4.0000,                 loss: 0.4423
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1230.6,                last time consumption/overall running time: 186.9431s / 28871.9953 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3819
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3859
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1198.2,                last time consumption/overall running time: 186.3515s / 29058.3467 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.4292
env0_second_0:                 episode reward: -1.9000,                 loss: 0.4314
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1172.35,                last time consumption/overall running time: 181.3345s / 29239.6812 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.4253
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4139
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1085.7,                last time consumption/overall running time: 172.8088s / 29412.4900 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3925
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3952
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1144.65,                last time consumption/overall running time: 176.0829s / 29588.5729 s
env0_first_0:                 episode reward: 6.7000,                 loss: 0.3902
env0_second_0:                 episode reward: -6.7000,                 loss: 0.3863
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1238.6,                last time consumption/overall running time: 189.7999s / 29778.3727 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.3756
env0_second_0:                 episode reward: -0.7500,                 loss: 0.3742
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1202.4,                last time consumption/overall running time: 184.4624s / 29962.8351 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.4068
env0_second_0:                 episode reward: -1.4500,                 loss: 0.3940
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1233.0,                last time consumption/overall running time: 190.4473s / 30153.2824 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.4205
env0_second_0:                 episode reward: -2.4500,                 loss: 0.4244
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1156.4,                last time consumption/overall running time: 179.9837s / 30333.2660 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.3970
env0_second_0:                 episode reward: -1.2500,                 loss: 0.4099
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1289.35,                last time consumption/overall running time: 197.1678s / 30530.4338 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.4023
env0_second_0:                 episode reward: -1.2000,                 loss: 0.4122
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1180.15,                last time consumption/overall running time: 181.2396s / 30711.6735 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.4034
env0_second_0:                 episode reward: -1.8500,                 loss: 0.3974
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1265.15,                last time consumption/overall running time: 194.0895s / 30905.7630 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.4206
env0_second_0:                 episode reward: -1.0000,                 loss: 0.4204
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1247.55,                last time consumption/overall running time: 192.4639s / 31098.2268 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3810
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3970
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1160.1,                last time consumption/overall running time: 178.9328s / 31277.1596 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.4049
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4003
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1179.45,                last time consumption/overall running time: 182.7025s / 31459.8621 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.4158
env0_second_0:                 episode reward: -3.9500,                 loss: 0.4237
env1_first_0:                 episode reward: 7.4000,                 loss: nan
env1_second_0:                 episode reward: -7.4000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1215.35,                last time consumption/overall running time: 190.3293s / 31650.1915 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.4334
env0_second_0:                 episode reward: -1.8500,                 loss: 0.4164
env1_first_0:                 episode reward: 4.7500,                 loss: nan
env1_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1180.9,                last time consumption/overall running time: 183.2894s / 31833.4809 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.4019
env0_second_0:                 episode reward: -1.0500,                 loss: 0.4137
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1248.95,                last time consumption/overall running time: 192.1740s / 32025.6548 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.4226
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4229
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1253.45,                last time consumption/overall running time: 194.8475s / 32220.5023 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.4403
env0_second_0:                 episode reward: 2.5000,                 loss: 0.4259
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1226.85,                last time consumption/overall running time: 189.7472s / 32410.2495 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.4232
env0_second_0:                 episode reward: 2.2500,                 loss: 0.4195
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1172.7,                last time consumption/overall running time: 180.8339s / 32591.0834 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.4091
env0_second_0:                 episode reward: 1.8000,                 loss: 0.4074
env1_first_0:                 episode reward: 6.9500,                 loss: nan
env1_second_0:                 episode reward: -6.9500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1182.15,                last time consumption/overall running time: 181.1670s / 32772.2504 s
env0_first_0:                 episode reward: 5.2500,                 loss: 0.4358
env0_second_0:                 episode reward: -5.2500,                 loss: 0.4399
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1198.75,                last time consumption/overall running time: 184.3269s / 32956.5773 s
env0_first_0:                 episode reward: 5.8000,                 loss: 0.3753
env0_second_0:                 episode reward: -5.8000,                 loss: 0.3698
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 1146.65,                last time consumption/overall running time: 178.8990s / 33135.4763 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.4553
env0_second_0:                 episode reward: -3.7000,                 loss: 0.4444
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1157.0,                last time consumption/overall running time: 178.9459s / 33314.4222 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.4263
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4352
env1_first_0:                 episode reward: 5.3500,                 loss: nan
env1_second_0:                 episode reward: -5.3500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1226.65,                last time consumption/overall running time: 186.0574s / 33500.4797 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.3911
env0_second_0:                 episode reward: -2.0000,                 loss: 0.4149
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1217.85,                last time consumption/overall running time: 183.7744s / 33684.2541 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.4296
env0_second_0:                 episode reward: -2.1000,                 loss: 0.4255
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1225.65,                last time consumption/overall running time: 186.5710s / 33870.8251 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.4084
env0_second_0:                 episode reward: -5.3000,                 loss: 0.4020
env1_first_0:                 episode reward: 5.5500,                 loss: nan
env1_second_0:                 episode reward: -5.5500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1256.2,                last time consumption/overall running time: 191.3858s / 34062.2109 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.4005
env0_second_0:                 episode reward: 2.6500,                 loss: 0.3885
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1226.75,                last time consumption/overall running time: 189.5915s / 34251.8024 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.4058
env0_second_0:                 episode reward: -2.9000,                 loss: 0.4152
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1145.25,                last time consumption/overall running time: 174.7550s / 34426.5574 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.4033
env0_second_0:                 episode reward: -0.6500,                 loss: 0.4057
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1236.55,                last time consumption/overall running time: 190.7105s / 34617.2678 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3820
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3752
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1184.2,                last time consumption/overall running time: 181.4848s / 34798.7526 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.4074
env0_second_0:                 episode reward: -3.4500,                 loss: 0.4292
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1285.3,                last time consumption/overall running time: 196.1434s / 34994.8961 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.4120
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4027
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1156.3,                last time consumption/overall running time: 175.0803s / 35169.9764 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.4115
env0_second_0:                 episode reward: -2.4000,                 loss: 0.4220
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 1214.3,                last time consumption/overall running time: 166.6323s / 35336.6087 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.4145
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4234
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 1149.7,                last time consumption/overall running time: 157.2001s / 35493.8087 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.4086
env0_second_0:                 episode reward: -5.3000,                 loss: 0.4070
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1307.4,                last time consumption/overall running time: 181.0987s / 35674.9075 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.4025
env0_second_0:                 episode reward: 0.7000,                 loss: 0.4134
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1191.75,                last time consumption/overall running time: 161.8311s / 35836.7386 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.4101
env0_second_0:                 episode reward: -2.8000,                 loss: 0.4080
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 1232.15,                last time consumption/overall running time: 169.3896s / 36006.1282 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.4145
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4295
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1123.55,                last time consumption/overall running time: 153.8027s / 36159.9309 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.3999
env0_second_0:                 episode reward: -4.5500,                 loss: 0.3954
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1259.8,                last time consumption/overall running time: 173.9807s / 36333.9116 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.4067
env0_second_0:                 episode reward: -3.3500,                 loss: 0.4087
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1180.7,                last time consumption/overall running time: 165.0724s / 36498.9839 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.4166
env0_second_0:                 episode reward: -3.0000,                 loss: 0.4037
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1211.7,                last time consumption/overall running time: 168.6115s / 36667.5955 s
env0_first_0:                 episode reward: 5.7000,                 loss: 0.4331
env0_second_0:                 episode reward: -5.7000,                 loss: 0.4273
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1248.4,                last time consumption/overall running time: 171.8459s / 36839.4414 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.3927
env0_second_0:                 episode reward: -2.5500,                 loss: 0.3977
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1161.8,                last time consumption/overall running time: 162.9571s / 37002.3985 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.4134
env0_second_0:                 episode reward: -4.4000,                 loss: 0.3855
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1375.6,                last time consumption/overall running time: 191.0939s / 37193.4924 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.4033
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3933
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1208.9,                last time consumption/overall running time: 167.5890s / 37361.0813 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.4373
env0_second_0:                 episode reward: -2.9000,                 loss: 0.4463
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 1187.25,                last time consumption/overall running time: 165.7445s / 37526.8259 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.3828
env0_second_0:                 episode reward: 2.4000,                 loss: 0.3656
env1_first_0:                 episode reward: 4.6500,                 loss: nan
env1_second_0:                 episode reward: -4.6500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1209.4,                last time consumption/overall running time: 166.8613s / 37693.6872 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.3722
env0_second_0:                 episode reward: 3.6500,                 loss: 0.3798
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1175.75,                last time consumption/overall running time: 164.8273s / 37858.5145 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.4375
env0_second_0:                 episode reward: -4.4000,                 loss: 0.4444
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 1166.35,                last time consumption/overall running time: 162.2928s / 38020.8073 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.4400
env0_second_0:                 episode reward: -3.5000,                 loss: 0.4359
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 1226.0,                last time consumption/overall running time: 170.0530s / 38190.8603 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.3943
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4057
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 1147.3,                last time consumption/overall running time: 159.9665s / 38350.8267 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.4079
env0_second_0:                 episode reward: -3.7000,                 loss: 0.4211
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1023.55,                last time consumption/overall running time: 143.4420s / 38494.2687 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.4401
env0_second_0:                 episode reward: -4.4000,                 loss: 0.4574
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 1236.0,                last time consumption/overall running time: 170.9711s / 38665.2399 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.4108
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4104
env1_first_0:                 episode reward: 5.2000,                 loss: nan
env1_second_0:                 episode reward: -5.2000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1253.3,                last time consumption/overall running time: 173.5976s / 38838.8374 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.3693
env0_second_0:                 episode reward: -1.4000,                 loss: 0.3686
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 1241.15,                last time consumption/overall running time: 171.5824s / 39010.4199 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.3811
env0_second_0:                 episode reward: -1.4000,                 loss: 0.3954
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 1202.1,                last time consumption/overall running time: 165.5271s / 39175.9469 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.3988
env0_second_0:                 episode reward: -2.0500,                 loss: 0.4006
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 1285.05,                last time consumption/overall running time: 176.3425s / 39352.2894 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3736
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3866
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 1260.15,                last time consumption/overall running time: 169.4222s / 39521.7115 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.4147
env0_second_0:                 episode reward: -1.6500,                 loss: 0.4155
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 1265.8,                last time consumption/overall running time: 174.5571s / 39696.2686 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.3766
env0_second_0:                 episode reward: -2.5000,                 loss: 0.3777
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 1321.8,                last time consumption/overall running time: 183.9147s / 39880.1833 s
env0_first_0:                 episode reward: 6.7000,                 loss: 0.4190
env0_second_0:                 episode reward: -6.7000,                 loss: 0.4245
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 1207.0,                last time consumption/overall running time: 164.2759s / 40044.4593 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.3807
env0_second_0:                 episode reward: -1.4500,                 loss: 0.3793
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 1221.8,                last time consumption/overall running time: 166.2227s / 40210.6820 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.4009
env0_second_0:                 episode reward: -2.7000,                 loss: 0.4134
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 1221.0,                last time consumption/overall running time: 164.4567s / 40375.1387 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.4253
env0_second_0:                 episode reward: -1.3000,                 loss: 0.4230
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 1141.65,                last time consumption/overall running time: 157.3821s / 40532.5209 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.4102
env0_second_0:                 episode reward: -0.6000,                 loss: 0.4102
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1174.2,                last time consumption/overall running time: 158.2831s / 40690.8040 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.4154
env0_second_0:                 episode reward: 2.3500,                 loss: 0.4164
env1_first_0:                 episode reward: 6.2000,                 loss: nan
env1_second_0:                 episode reward: -6.2000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1258.25,                last time consumption/overall running time: 171.1273s / 40861.9313 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.4108
env0_second_0:                 episode reward: -3.2000,                 loss: 0.3900
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1254.75,                last time consumption/overall running time: 173.6284s / 41035.5598 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.4038
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3921
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 1129.55,                last time consumption/overall running time: 156.5096s / 41192.0694 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.3865
env0_second_0:                 episode reward: -4.0000,                 loss: 0.3816
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1339.55,                last time consumption/overall running time: 184.0664s / 41376.1357 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3786
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3849
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1267.1,                last time consumption/overall running time: 175.5100s / 41551.6458 s
env0_first_0:                 episode reward: 5.6000,                 loss: 0.3846
env0_second_0:                 episode reward: -5.6000,                 loss: 0.3702
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1194.85,                last time consumption/overall running time: 166.3862s / 41718.0320 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.3741
env0_second_0:                 episode reward: -2.6000,                 loss: 0.3818
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1194.05,                last time consumption/overall running time: 164.4330s / 41882.4650 s
env0_first_0:                 episode reward: 5.9500,                 loss: 0.4058
env0_second_0:                 episode reward: -5.9500,                 loss: 0.3944
env1_first_0:                 episode reward: 5.9000,                 loss: nan
env1_second_0:                 episode reward: -5.9000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1245.25,                last time consumption/overall running time: 171.1869s / 42053.6520 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.4166
env0_second_0:                 episode reward: -3.6500,                 loss: 0.4279
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1237.75,                last time consumption/overall running time: 169.5447s / 42223.1967 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.3890
env0_second_0:                 episode reward: -2.1000,                 loss: 0.3888
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1335.05,                last time consumption/overall running time: 186.6873s / 42409.8840 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.4237
env0_second_0:                 episode reward: 1.0500,                 loss: 0.4296
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1186.6,                last time consumption/overall running time: 164.2600s / 42574.1440 s
env0_first_0:                 episode reward: 8.7500,                 loss: 0.3585
env0_second_0:                 episode reward: -8.7500,                 loss: 0.3481
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1277.9,                last time consumption/overall running time: 179.8346s / 42753.9786 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.3989
env0_second_0:                 episode reward: -2.8500,                 loss: 0.3908
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1186.45,                last time consumption/overall running time: 164.0439s / 42918.0225 s
env0_first_0:                 episode reward: 5.5500,                 loss: 0.4436
env0_second_0:                 episode reward: -5.5500,                 loss: 0.4556
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1234.75,                last time consumption/overall running time: 166.9445s / 43084.9669 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3956
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3873
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1164.15,                last time consumption/overall running time: 160.5532s / 43245.5202 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.4218
env0_second_0:                 episode reward: -2.6000,                 loss: 0.4201
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1211.45,                last time consumption/overall running time: 167.0401s / 43412.5603 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.3821
env0_second_0:                 episode reward: -1.6500,                 loss: 0.3856
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1205.6,                last time consumption/overall running time: 164.2014s / 43576.7617 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.4293
env0_second_0:                 episode reward: -0.7500,                 loss: 0.4283
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1176.3,                last time consumption/overall running time: 164.0207s / 43740.7824 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.4150
env0_second_0:                 episode reward: -2.1000,                 loss: 0.4208
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1261.0,                last time consumption/overall running time: 172.5393s / 43913.3217 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.3904
env0_second_0:                 episode reward: 1.4500,                 loss: 0.3873
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1156.6,                last time consumption/overall running time: 164.2565s / 44077.5781 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.3815
env0_second_0:                 episode reward: 1.9500,                 loss: 0.3798
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1187.0,                last time consumption/overall running time: 164.1966s / 44241.7747 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.4125
env0_second_0:                 episode reward: -1.4000,                 loss: 0.4127
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1194.45,                last time consumption/overall running time: 164.9964s / 44406.7712 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.4074
env0_second_0:                 episode reward: -2.5000,                 loss: 0.4113
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1169.05,                last time consumption/overall running time: 164.7100s / 44571.4812 s
env0_first_0:                 episode reward: 4.7000,                 loss: 0.4013
env0_second_0:                 episode reward: -4.7000,                 loss: 0.3963
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1102.35,                last time consumption/overall running time: 150.6416s / 44722.1227 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.4279
env0_second_0:                 episode reward: -0.8500,                 loss: 0.4139
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1286.5,                last time consumption/overall running time: 178.2523s / 44900.3750 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.4436
env0_second_0:                 episode reward: -0.8000,                 loss: 0.4497
env1_first_0:                 episode reward: 4.7500,                 loss: nan
env1_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 1174.65,                last time consumption/overall running time: 165.7857s / 45066.1607 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.3563
env0_second_0:                 episode reward: -1.7000,                 loss: 0.3535
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1155.75,                last time consumption/overall running time: 161.8002s / 45227.9609 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.4620
env0_second_0:                 episode reward: -2.2000,                 loss: 0.4584
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1177.4,                last time consumption/overall running time: 166.4037s / 45394.3646 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.3764
env0_second_0:                 episode reward: -3.8500,                 loss: 0.3732
env1_first_0:                 episode reward: 6.4500,                 loss: nan
env1_second_0:                 episode reward: -6.4500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1231.1,                last time consumption/overall running time: 173.0483s / 45567.4129 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.4331
env0_second_0:                 episode reward: -2.4500,                 loss: 0.4407
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 1236.95,                last time consumption/overall running time: 174.7515s / 45742.1644 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3532
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3684
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1278.3,                last time consumption/overall running time: 175.1604s / 45917.3248 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.4229
env0_second_0:                 episode reward: -2.8000,                 loss: 0.4248
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1079.7,                last time consumption/overall running time: 152.5108s / 46069.8357 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.4631
env0_second_0:                 episode reward: 1.2500,                 loss: 0.4561
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 1311.0,                last time consumption/overall running time: 180.4359s / 46250.2716 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.3938
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3889
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1144.85,                last time consumption/overall running time: 159.3315s / 46409.6031 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.4041
env0_second_0:                 episode reward: -3.2000,                 loss: 0.3954
env1_first_0:                 episode reward: 6.8500,                 loss: nan
env1_second_0:                 episode reward: -6.8500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1166.65,                last time consumption/overall running time: 158.5647s / 46568.1678 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.4515
env0_second_0:                 episode reward: -1.2500,                 loss: 0.4584
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1260.85,                last time consumption/overall running time: 175.0364s / 46743.2042 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.4191
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4480
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 1306.15,                last time consumption/overall running time: 178.2014s / 46921.4056 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.3906
env0_second_0:                 episode reward: -1.6000,                 loss: 0.4034
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1116.4,                last time consumption/overall running time: 152.8892s / 47074.2949 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.4610
env0_second_0:                 episode reward: -4.2500,                 loss: 0.4489
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1147.05,                last time consumption/overall running time: 157.2229s / 47231.5178 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.3759
env0_second_0:                 episode reward: -2.0500,                 loss: 0.3852
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1321.0,                last time consumption/overall running time: 179.5056s / 47411.0234 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.3805
env0_second_0:                 episode reward: 2.3000,                 loss: 0.3852
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1165.8,                last time consumption/overall running time: 161.7133s / 47572.7366 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.4018
env0_second_0:                 episode reward: -2.0500,                 loss: 0.3956
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1200.95,                last time consumption/overall running time: 166.1007s / 47738.8374 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.4047
env0_second_0:                 episode reward: -2.8500,                 loss: 0.3954
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1171.4,                last time consumption/overall running time: 165.1884s / 47904.0257 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.4091
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4289
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1200.65,                last time consumption/overall running time: 167.2414s / 48071.2672 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.4244
env0_second_0:                 episode reward: -4.7500,                 loss: 0.4310
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1135.85,                last time consumption/overall running time: 158.6264s / 48229.8936 s
env0_first_0:                 episode reward: 4.9000,                 loss: 0.3894
env0_second_0:                 episode reward: -4.9000,                 loss: 0.4002
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1189.5,                last time consumption/overall running time: 165.8339s / 48395.7275 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.4180
env0_second_0:                 episode reward: -0.9000,                 loss: 0.4215
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1227.25,                last time consumption/overall running time: 168.9171s / 48564.6446 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.3813
env0_second_0:                 episode reward: -1.1500,                 loss: 0.3815
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1145.6,                last time consumption/overall running time: 159.1346s / 48723.7791 s
env0_first_0:                 episode reward: 5.1000,                 loss: 0.4221
env0_second_0:                 episode reward: -5.1000,                 loss: 0.4185
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 1177.0,                last time consumption/overall running time: 163.1890s / 48886.9681 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.4294
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4371
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 1175.8,                last time consumption/overall running time: 163.9549s / 49050.9230 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.3789
env0_second_0:                 episode reward: -1.3000,                 loss: 0.3890
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 1193.2,                last time consumption/overall running time: 163.5828s / 49214.5059 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.4185
env0_second_0:                 episode reward: -3.6000,                 loss: 0.4337
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 1284.5,                last time consumption/overall running time: 177.4885s / 49391.9944 s
env0_first_0:                 episode reward: 5.1500,                 loss: 0.3918
env0_second_0:                 episode reward: -5.1500,                 loss: 0.3838
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 1191.55,                last time consumption/overall running time: 165.7715s / 49557.7659 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.4134
env0_second_0:                 episode reward: -2.6000,                 loss: 0.4199
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 1213.45,                last time consumption/overall running time: 169.0360s / 49726.8019 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.3975
env0_second_0:                 episode reward: -2.0000,                 loss: 0.3989
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1253.7,                last time consumption/overall running time: 171.7784s / 49898.5803 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.4250
env0_second_0:                 episode reward: -1.2500,                 loss: 0.4066
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1278.85,                last time consumption/overall running time: 175.1318s / 50073.7120 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.4193
env0_second_0:                 episode reward: -0.9500,                 loss: 0.4014
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 1245.3,                last time consumption/overall running time: 172.0448s / 50245.7568 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3857
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3975
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1259.6,                last time consumption/overall running time: 178.2973s / 50424.0541 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.3807
env0_second_0:                 episode reward: -3.0500,                 loss: 0.3878
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 1229.45,                last time consumption/overall running time: 170.6119s / 50594.6660 s
env0_first_0:                 episode reward: 5.3500,                 loss: 0.4398
env0_second_0:                 episode reward: -5.3500,                 loss: 0.4366
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1192.3,                last time consumption/overall running time: 164.0724s / 50758.7384 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.3710
env0_second_0:                 episode reward: -1.7000,                 loss: 0.3942
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1228.05,                last time consumption/overall running time: 169.6140s / 50928.3524 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.4473
env0_second_0:                 episode reward: 0.1500,                 loss: 0.4433
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 1257.5,                last time consumption/overall running time: 176.1873s / 51104.5397 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.3776
env0_second_0:                 episode reward: -3.1500,                 loss: 0.3968
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 1186.0,                last time consumption/overall running time: 165.8790s / 51270.4187 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.4115
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4116
env1_first_0:                 episode reward: 4.7500,                 loss: nan
env1_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 1156.15,                last time consumption/overall running time: 161.4865s / 51431.9053 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.3918
env0_second_0:                 episode reward: -2.8500,                 loss: 0.3844
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 1181.55,                last time consumption/overall running time: 164.4540s / 51596.3593 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.3953
env0_second_0:                 episode reward: -5.9000,                 loss: 0.3984
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 1192.55,                last time consumption/overall running time: 164.5996s / 51760.9589 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.3693
env0_second_0:                 episode reward: -3.7500,                 loss: 0.3799
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 1157.35,                last time consumption/overall running time: 160.1341s / 51921.0930 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.3614
env0_second_0:                 episode reward: -4.1000,                 loss: 0.3763
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 1187.3,                last time consumption/overall running time: 166.9892s / 52088.0822 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.4055
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4008
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 1276.35,                last time consumption/overall running time: 176.7051s / 52264.7873 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.4173
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4223
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 1176.75,                last time consumption/overall running time: 162.5890s / 52427.3763 s
env0_first_0:                 episode reward: 4.5000,                 loss: 0.3892
env0_second_0:                 episode reward: -4.5000,                 loss: 0.3830
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 1107.5,                last time consumption/overall running time: 155.3083s / 52582.6846 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.3961
env0_second_0:                 episode reward: -3.6500,                 loss: 0.4083
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 1235.85,                last time consumption/overall running time: 169.5913s / 52752.2759 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.4341
env0_second_0:                 episode reward: -1.4500,                 loss: 0.4456
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 1219.25,                last time consumption/overall running time: 166.7791s / 52919.0550 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.4081
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4211
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 1148.6,                last time consumption/overall running time: 160.2823s / 53079.3373 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.4011
env0_second_0:                 episode reward: -2.4000,                 loss: 0.4057
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 1198.05,                last time consumption/overall running time: 165.4506s / 53244.7878 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.3876
env0_second_0:                 episode reward: -2.6500,                 loss: 0.4131
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 1144.7,                last time consumption/overall running time: 158.1931s / 53402.9810 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.4347
env0_second_0:                 episode reward: -1.5000,                 loss: 0.4341
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 1150.45,                last time consumption/overall running time: 161.3619s / 53564.3429 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.4232
env0_second_0:                 episode reward: -1.0500,                 loss: 0.4129
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 1238.1,                last time consumption/overall running time: 171.1136s / 53735.4565 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.4042
env0_second_0:                 episode reward: -2.8000,                 loss: 0.3951
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 1214.6,                last time consumption/overall running time: 168.7270s / 53904.1836 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.4369
env0_second_0:                 episode reward: 2.6000,                 loss: 0.4490
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 1106.25,                last time consumption/overall running time: 155.0938s / 54059.2773 s
env0_first_0:                 episode reward: 5.6500,                 loss: 0.3596
env0_second_0:                 episode reward: -5.6500,                 loss: 0.3642
env1_first_0:                 episode reward: 7.6000,                 loss: nan
env1_second_0:                 episode reward: -7.6000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 1297.65,                last time consumption/overall running time: 181.4089s / 54240.6862 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3642
env0_second_0:                 episode reward: -1.2000,                 loss: 0.3630
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1229.05,                last time consumption/overall running time: 174.0278s / 54414.7140 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.4257
env0_second_0:                 episode reward: -4.1000,                 loss: 0.4340
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 1180.0,                last time consumption/overall running time: 165.3611s / 54580.0750 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.4570
env0_second_0:                 episode reward: -1.9000,                 loss: 0.4389
env1_first_0:                 episode reward: 5.8000,                 loss: nan
env1_second_0:                 episode reward: -5.8000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 1255.35,                last time consumption/overall running time: 174.2736s / 54754.3486 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.4002
env0_second_0:                 episode reward: -4.8500,                 loss: 0.4060
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 1303.35,                last time consumption/overall running time: 181.9739s / 54936.3226 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.3552
env0_second_0:                 episode reward: -2.7000,                 loss: 0.3682
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 1137.5,                last time consumption/overall running time: 159.6528s / 55095.9753 s
env0_first_0:                 episode reward: 5.2500,                 loss: 0.4212
env0_second_0:                 episode reward: -5.2500,                 loss: 0.4314
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 1138.35,                last time consumption/overall running time: 160.6060s / 55256.5814 s
env0_first_0:                 episode reward: 5.3500,                 loss: 0.4176
env0_second_0:                 episode reward: -5.3500,                 loss: 0.4240
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 1251.15,                last time consumption/overall running time: 171.1436s / 55427.7250 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.4120
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4228
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 1228.15,                last time consumption/overall running time: 169.7388s / 55597.4637 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.3728
env0_second_0:                 episode reward: -4.2500,                 loss: 0.3695
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 1215.65,                last time consumption/overall running time: 167.7976s / 55765.2614 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.3167
env0_second_0:                 episode reward: -4.5500,                 loss: 0.3336
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 1322.4,                last time consumption/overall running time: 183.7970s / 55949.0584 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.4073
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4194
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 1151.85,                last time consumption/overall running time: 161.0283s / 56110.0867 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.4246
env0_second_0:                 episode reward: -0.6000,                 loss: 0.3956
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 1238.45,                last time consumption/overall running time: 173.6738s / 56283.7605 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.3880
env0_second_0:                 episode reward: -2.3500,                 loss: 0.4060
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 1234.95,                last time consumption/overall running time: 176.6007s / 56460.3612 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.3743
env0_second_0:                 episode reward: -4.1500,                 loss: 0.3986
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 1235.3,                last time consumption/overall running time: 172.7974s / 56633.1585 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.3960
env0_second_0:                 episode reward: -3.0000,                 loss: 0.3976
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 1208.35,                last time consumption/overall running time: 165.7048s / 56798.8633 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3961
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3850
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 1216.35,                last time consumption/overall running time: 170.6062s / 56969.4695 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3899
env0_second_0:                 episode reward: -1.0000,                 loss: 0.3828
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 1118.1,                last time consumption/overall running time: 156.0811s / 57125.5506 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3551
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3509
env1_first_0:                 episode reward: 5.8500,                 loss: nan
env1_second_0:                 episode reward: -5.8500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 1240.6,                last time consumption/overall running time: 169.5534s / 57295.1040 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.4086
env0_second_0:                 episode reward: -4.1000,                 loss: 0.3955
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 1210.95,                last time consumption/overall running time: 167.7184s / 57462.8223 s
env0_first_0:                 episode reward: 5.3500,                 loss: 0.4040
env0_second_0:                 episode reward: -5.3500,                 loss: 0.3864
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 1279.2,                last time consumption/overall running time: 176.3328s / 57639.1551 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.4375
env0_second_0:                 episode reward: -3.6000,                 loss: 0.4460
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 1216.9,                last time consumption/overall running time: 166.2291s / 57805.3843 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.4147
env0_second_0:                 episode reward: -1.0500,                 loss: 0.4129
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 1219.0,                last time consumption/overall running time: 169.1263s / 57974.5106 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.4117
env0_second_0:                 episode reward: -1.4000,                 loss: 0.4192
env1_first_0:                 episode reward: 4.0500,                 loss: nan
env1_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 1222.85,                last time consumption/overall running time: 168.1132s / 58142.6238 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3903
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4066
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 1282.3,                last time consumption/overall running time: 178.0676s / 58320.6914 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3895
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3812
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 1228.65,                last time consumption/overall running time: 175.8207s / 58496.5121 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.4283
env0_second_0:                 episode reward: -4.2500,                 loss: 0.4190
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 1267.15,                last time consumption/overall running time: 175.2790s / 58671.7911 s
env0_first_0:                 episode reward: 5.9500,                 loss: 0.3914
env0_second_0:                 episode reward: -5.9500,                 loss: 0.4106
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 1268.55,                last time consumption/overall running time: 171.9996s / 58843.7907 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.3890
env0_second_0:                 episode reward: -2.1500,                 loss: 0.3975
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 1148.2,                last time consumption/overall running time: 160.1838s / 59003.9745 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.4286
env0_second_0:                 episode reward: 1.4000,                 loss: 0.4631
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 1164.0,                last time consumption/overall running time: 161.4862s / 59165.4607 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.4182
env0_second_0:                 episode reward: -1.3000,                 loss: 0.4119
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 1126.0,                last time consumption/overall running time: 155.6372s / 59321.0978 s
env0_first_0:                 episode reward: 5.4000,                 loss: 0.3784
env0_second_0:                 episode reward: -5.4000,                 loss: 0.3777
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 1249.15,                last time consumption/overall running time: 171.9170s / 59493.0149 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.3871
env0_second_0:                 episode reward: -2.7500,                 loss: 0.4014
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 1323.45,                last time consumption/overall running time: 179.6873s / 59672.7021 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.3541
env0_second_0:                 episode reward: 2.5500,                 loss: 0.3594
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 1166.85,                last time consumption/overall running time: 159.6193s / 59832.3214 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.4239
env0_second_0:                 episode reward: -2.1500,                 loss: 0.4232
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 1258.1,                last time consumption/overall running time: 176.2492s / 60008.5707 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.3863
env0_second_0:                 episode reward: -1.3500,                 loss: 0.3661
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 1239.55,                last time consumption/overall running time: 171.5397s / 60180.1103 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3927
env0_second_0:                 episode reward: -1.2000,                 loss: 0.4100
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 1098.05,                last time consumption/overall running time: 153.3950s / 60333.5054 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.4017
env0_second_0:                 episode reward: 2.9500,                 loss: 0.3973
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 1248.8,                last time consumption/overall running time: 171.9592s / 60505.4646 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.4032
env0_second_0:                 episode reward: -1.2500,                 loss: 0.4291
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 1144.9,                last time consumption/overall running time: 161.3299s / 60666.7945 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.3907
env0_second_0:                 episode reward: 1.4500,                 loss: 0.3718
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 1247.6,                last time consumption/overall running time: 171.7138s / 60838.5083 s
env0_first_0:                 episode reward: 5.6000,                 loss: 0.3839
env0_second_0:                 episode reward: -5.6000,                 loss: 0.3902
env1_first_0:                 episode reward: 6.4000,                 loss: nan
env1_second_0:                 episode reward: -6.4000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 1297.7,                last time consumption/overall running time: 179.2134s / 61017.7217 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.4118
env0_second_0:                 episode reward: -2.7000,                 loss: 0.4162
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 1245.5,                last time consumption/overall running time: 172.9317s / 61190.6534 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.3758
env0_second_0:                 episode reward: 2.6500,                 loss: 0.3813
env1_first_0:                 episode reward: 5.3500,                 loss: nan
env1_second_0:                 episode reward: -5.3500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 1219.25,                last time consumption/overall running time: 170.0525s / 61360.7059 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3841
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3745
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1318.3,                last time consumption/overall running time: 184.9013s / 61545.6072 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.4003
env0_second_0:                 episode reward: -2.1000,                 loss: 0.4014
env1_first_0:                 episode reward: 4.0500,                 loss: nan
env1_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 1202.55,                last time consumption/overall running time: 167.7734s / 61713.3806 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.3922
env0_second_0:                 episode reward: -4.4000,                 loss: 0.3915
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 1182.4,                last time consumption/overall running time: 167.2191s / 61880.5998 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.4375
env0_second_0:                 episode reward: -2.8500,                 loss: 0.4320
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 1277.15,                last time consumption/overall running time: 178.5776s / 62059.1773 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3837
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3696
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 1213.45,                last time consumption/overall running time: 170.1690s / 62229.3463 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.3587
env0_second_0:                 episode reward: -4.5500,                 loss: 0.3683
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 1270.3,                last time consumption/overall running time: 176.6926s / 62406.0389 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.3766
env0_second_0:                 episode reward: 1.4000,                 loss: 0.3909
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 1209.75,                last time consumption/overall running time: 166.4855s / 62572.5244 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.3778
env0_second_0:                 episode reward: -2.7000,                 loss: 0.3773
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 1231.7,                last time consumption/overall running time: 170.2890s / 62742.8134 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.3830
env0_second_0:                 episode reward: -2.2000,                 loss: 0.3892
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 1203.6,                last time consumption/overall running time: 167.4987s / 62910.3120 s
env0_first_0:                 episode reward: 5.7500,                 loss: 0.3675
env0_second_0:                 episode reward: -5.7500,                 loss: 0.3789
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 1269.65,                last time consumption/overall running time: 176.6752s / 63086.9873 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.4129
env0_second_0:                 episode reward: -3.4500,                 loss: 0.4205
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 1280.4,                last time consumption/overall running time: 177.5824s / 63264.5697 s
env0_first_0:                 episode reward: 5.1500,                 loss: 0.4089
env0_second_0:                 episode reward: -5.1500,                 loss: 0.3961
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 1187.05,                last time consumption/overall running time: 164.6721s / 63429.2418 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3827
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3895
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 1192.4,                last time consumption/overall running time: 159.2670s / 63588.5087 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.4038
env0_second_0:                 episode reward: -2.9000,                 loss: 0.4053
env1_first_0:                 episode reward: 5.2500,                 loss: nan
env1_second_0:                 episode reward: -5.2500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 1185.05,                last time consumption/overall running time: 163.8242s / 63752.3329 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.3470
env0_second_0:                 episode reward: 0.3000,                 loss: 0.3605
env1_first_0:                 episode reward: 6.3000,                 loss: nan
env1_second_0:                 episode reward: -6.3000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 1108.75,                last time consumption/overall running time: 152.9401s / 63905.2730 s
env0_first_0:                 episode reward: 6.6000,                 loss: 0.3859
env0_second_0:                 episode reward: -6.6000,                 loss: 0.3883
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 1165.7,                last time consumption/overall running time: 159.6174s / 64064.8904 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.3883
env0_second_0:                 episode reward: -4.1000,                 loss: 0.4253
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 1223.6,                last time consumption/overall running time: 169.7005s / 64234.5909 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.4233
env0_second_0:                 episode reward: -3.6500,                 loss: 0.4253
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 1131.3,                last time consumption/overall running time: 159.0504s / 64393.6412 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.3817
env0_second_0:                 episode reward: -5.3000,                 loss: 0.3928
env1_first_0:                 episode reward: 6.7000,                 loss: nan
env1_second_0:                 episode reward: -6.7000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 1190.45,                last time consumption/overall running time: 166.0296s / 64559.6709 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.3992
env0_second_0:                 episode reward: -3.5000,                 loss: 0.3972
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 1200.15,                last time consumption/overall running time: 166.5566s / 64726.2275 s
env0_first_0:                 episode reward: 8.3500,                 loss: 0.3297
env0_second_0:                 episode reward: -8.3500,                 loss: 0.3272
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 1234.2,                last time consumption/overall running time: 173.4178s / 64899.6453 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.4143
env0_second_0:                 episode reward: 2.7500,                 loss: 0.4384
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 1230.6,                last time consumption/overall running time: 172.2613s / 65071.9066 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3541
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3765
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 1198.75,                last time consumption/overall running time: 164.4377s / 65236.3443 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.4184
env0_second_0:                 episode reward: -2.3000,                 loss: 0.4356
env1_first_0:                 episode reward: 5.9000,                 loss: nan
env1_second_0:                 episode reward: -5.9000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 1279.8,                last time consumption/overall running time: 175.6941s / 65412.0384 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.3842
env0_second_0:                 episode reward: -3.2000,                 loss: 0.3848
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 1247.75,                last time consumption/overall running time: 170.0819s / 65582.1203 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.3969
env0_second_0:                 episode reward: -2.4500,                 loss: 0.4106
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 1237.7,                last time consumption/overall running time: 172.8097s / 65754.9300 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.3752
env0_second_0:                 episode reward: -3.1500,                 loss: 0.3792
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 1258.45,                last time consumption/overall running time: 174.2651s / 65929.1951 s
env0_first_0:                 episode reward: 7.3500,                 loss: 0.4365
env0_second_0:                 episode reward: -7.3500,                 loss: 0.4484
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 1248.6,                last time consumption/overall running time: 173.1725s / 66102.3676 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.3978
env0_second_0:                 episode reward: 1.6000,                 loss: 0.4073
env1_first_0:                 episode reward: 5.5500,                 loss: nan
env1_second_0:                 episode reward: -5.5500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 1278.8,                last time consumption/overall running time: 175.0102s / 66277.3778 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.3642
env0_second_0:                 episode reward: -1.5000,                 loss: 0.3554
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 1229.8,                last time consumption/overall running time: 169.9839s / 66447.3617 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.3980
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4215
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 1180.2,                last time consumption/overall running time: 162.8515s / 66610.2131 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.4051
env0_second_0:                 episode reward: 2.9000,                 loss: 0.4030
env1_first_0:                 episode reward: 6.4000,                 loss: nan
env1_second_0:                 episode reward: -6.4000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 1127.6,                last time consumption/overall running time: 158.5950s / 66768.8081 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.4072
env0_second_0:                 episode reward: -3.0500,                 loss: 0.4151
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 1216.4,                last time consumption/overall running time: 166.5402s / 66935.3483 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.3603
env0_second_0:                 episode reward: 1.8000,                 loss: 0.3692
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 1241.5,                last time consumption/overall running time: 171.8056s / 67107.1538 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.4281
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4292
env1_first_0:                 episode reward: 7.1500,                 loss: nan
env1_second_0:                 episode reward: -7.1500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 1222.2,                last time consumption/overall running time: 166.6591s / 67273.8129 s
env0_first_0:                 episode reward: 5.1000,                 loss: 0.4020
env0_second_0:                 episode reward: -5.1000,                 loss: 0.4243
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 1202.0,                last time consumption/overall running time: 166.8103s / 67440.6232 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.3663
env0_second_0:                 episode reward: 1.0500,                 loss: 0.3609
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 1144.3,                last time consumption/overall running time: 160.6418s / 67601.2650 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.4166
env0_second_0:                 episode reward: -1.9000,                 loss: 0.4425
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 1258.5,                last time consumption/overall running time: 170.0422s / 67771.3072 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3953
env0_second_0:                 episode reward: -1.2000,                 loss: 0.4079
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 1231.4,                last time consumption/overall running time: 166.8529s / 67938.1602 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.4254
env0_second_0:                 episode reward: 2.7000,                 loss: 0.4231
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 1218.25,                last time consumption/overall running time: 167.3625s / 68105.5227 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.3650
env0_second_0:                 episode reward: -3.1000,                 loss: 0.3765
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 1189.35,                last time consumption/overall running time: 161.0117s / 68266.5344 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.4390
env0_second_0:                 episode reward: -2.7500,                 loss: 0.4351
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 1210.5,                last time consumption/overall running time: 165.3044s / 68431.8388 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3912
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4052
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 1165.15,                last time consumption/overall running time: 161.7792s / 68593.6180 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.4216
env0_second_0:                 episode reward: -2.8000,                 loss: 0.4228
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 1282.05,                last time consumption/overall running time: 180.1914s / 68773.8095 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.3682
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3837
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 1201.45,                last time consumption/overall running time: 166.5704s / 68940.3799 s
env0_first_0:                 episode reward: 4.9000,                 loss: 0.3580
env0_second_0:                 episode reward: -4.9000,                 loss: 0.3313
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 1280.35,                last time consumption/overall running time: 176.1047s / 69116.4845 s
env0_first_0:                 episode reward: 4.6500,                 loss: 0.3739
env0_second_0:                 episode reward: -4.6500,                 loss: 0.3857
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 1212.7,                last time consumption/overall running time: 162.1677s / 69278.6522 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.3741
env0_second_0:                 episode reward: -2.4000,                 loss: 0.3894
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 1273.9,                last time consumption/overall running time: 164.8882s / 69443.5404 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.4341
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4418
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 1181.0,                last time consumption/overall running time: 160.2396s / 69603.7800 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.4176
env0_second_0:                 episode reward: -4.8500,                 loss: 0.4075
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 1329.9,                last time consumption/overall running time: 191.0608s / 69794.8409 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.4319
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4186
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 1181.9,                last time consumption/overall running time: 156.6247s / 69951.4656 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.3323
env0_second_0:                 episode reward: -2.9500,                 loss: 0.3482
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 1249.7,                last time consumption/overall running time: 174.1105s / 70125.5761 s
env0_first_0:                 episode reward: 4.8000,                 loss: 0.4381
env0_second_0:                 episode reward: -4.8000,                 loss: 0.4352
env1_first_0:                 episode reward: 7.2500,                 loss: nan
env1_second_0:                 episode reward: -7.2500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 1154.75,                last time consumption/overall running time: 159.1285s / 70284.7045 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.3625
env0_second_0:                 episode reward: -4.2000,                 loss: 0.3590
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 1238.4,                last time consumption/overall running time: 168.7450s / 70453.4495 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.3849
env0_second_0:                 episode reward: -3.0500,                 loss: 0.3714
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 1152.7,                last time consumption/overall running time: 152.7559s / 70606.2055 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.4426
env0_second_0:                 episode reward: -1.2500,                 loss: 0.4556
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 1181.65,                last time consumption/overall running time: 163.5800s / 70769.7855 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.4041
env0_second_0:                 episode reward: -2.8000,                 loss: 0.4073
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 1214.5,                last time consumption/overall running time: 172.6923s / 70942.4778 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.3850
env0_second_0:                 episode reward: -2.5000,                 loss: 0.3710
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 1210.3,                last time consumption/overall running time: 164.3539s / 71106.8316 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.4115
env0_second_0:                 episode reward: -4.1000,                 loss: 0.4024
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 1196.05,                last time consumption/overall running time: 166.0536s / 71272.8852 s
env0_first_0:                 episode reward: 5.5000,                 loss: 0.3862
env0_second_0:                 episode reward: -5.5000,                 loss: 0.4025
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 1178.45,                last time consumption/overall running time: 159.6314s / 71432.5166 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.4122
env0_second_0:                 episode reward: -2.4000,                 loss: 0.4112
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 1299.9,                last time consumption/overall running time: 178.5775s / 71611.0941 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3845
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3856
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 1205.85,                last time consumption/overall running time: 162.4505s / 71773.5446 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.4106
env0_second_0:                 episode reward: 0.8500,                 loss: 0.3908
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 1237.4,                last time consumption/overall running time: 171.0531s / 71944.5977 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.3756
env0_second_0:                 episode reward: -3.4000,                 loss: 0.3714
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 1179.15,                last time consumption/overall running time: 160.8406s / 72105.4383 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.4320
env0_second_0:                 episode reward: 0.9000,                 loss: 0.4361
env1_first_0:                 episode reward: 5.5000,                 loss: nan
env1_second_0:                 episode reward: -5.5000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 1182.4,                last time consumption/overall running time: 161.1687s / 72266.6070 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.4525
env0_second_0:                 episode reward: -1.5500,                 loss: 0.4511
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 1178.35,                last time consumption/overall running time: 160.8136s / 72427.4206 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.4292
env0_second_0:                 episode reward: 1.3500,                 loss: 0.4178
env1_first_0:                 episode reward: 7.8000,                 loss: nan
env1_second_0:                 episode reward: -7.8000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 1211.4,                last time consumption/overall running time: 165.5091s / 72592.9297 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.3703
env0_second_0:                 episode reward: -2.1000,                 loss: 0.3636
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 1345.65,                last time consumption/overall running time: 187.0534s / 72779.9831 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.3685
env0_second_0:                 episode reward: -2.3000,                 loss: 0.3529
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 1249.55,                last time consumption/overall running time: 170.6053s / 72950.5884 s
env0_first_0:                 episode reward: 4.3500,                 loss: 0.3755
env0_second_0:                 episode reward: -4.3500,                 loss: 0.3722
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 1210.5,                last time consumption/overall running time: 165.2364s / 73115.8248 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.3655
env0_second_0:                 episode reward: -3.0500,                 loss: 0.3728
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 1157.7,                last time consumption/overall running time: 160.0259s / 73275.8507 s
env0_first_0:                 episode reward: 7.0000,                 loss: 0.3814
env0_second_0:                 episode reward: -7.0000,                 loss: 0.3826
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 1239.75,                last time consumption/overall running time: 172.1657s / 73448.0163 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.4081
env0_second_0:                 episode reward: -2.6500,                 loss: 0.4437
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 1191.0,                last time consumption/overall running time: 163.9945s / 73612.0109 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3862
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3772
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 1239.05,                last time consumption/overall running time: 173.7262s / 73785.7371 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.4223
env0_second_0:                 episode reward: -0.3500,                 loss: 0.4112
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 1177.25,                last time consumption/overall running time: 163.7568s / 73949.4939 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.4182
env0_second_0:                 episode reward: -1.9500,                 loss: 0.4081
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 1131.75,                last time consumption/overall running time: 158.3375s / 74107.8314 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.4009
env0_second_0:                 episode reward: -4.8500,                 loss: 0.4394
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 1220.7,                last time consumption/overall running time: 169.6185s / 74277.4499 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3854
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3817
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 1179.85,                last time consumption/overall running time: 164.9075s / 74442.3574 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.3790
env0_second_0:                 episode reward: -0.4000,                 loss: 0.3957
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 1262.95,                last time consumption/overall running time: 176.5820s / 74618.9394 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.4035
env0_second_0:                 episode reward: -1.1000,                 loss: 0.3975
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 1227.05,                last time consumption/overall running time: 170.7184s / 74789.6578 s
env0_first_0:                 episode reward: 5.4000,                 loss: 0.4006
env0_second_0:                 episode reward: -5.4000,                 loss: 0.3797
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 1293.0,                last time consumption/overall running time: 181.0075s / 74970.6653 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.3793
env0_second_0:                 episode reward: 2.4500,                 loss: 0.3613
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 1115.75,                last time consumption/overall running time: 159.1706s / 75129.8360 s
env0_first_0:                 episode reward: 4.9500,                 loss: 0.3652
env0_second_0:                 episode reward: -4.9500,                 loss: 0.3567
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 1210.4,                last time consumption/overall running time: 169.7448s / 75299.5807 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3752
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3862
env1_first_0:                 episode reward: 8.1500,                 loss: nan
env1_second_0:                 episode reward: -8.1500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 1137.3,                last time consumption/overall running time: 159.0292s / 75458.6100 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.3932
env0_second_0:                 episode reward: 1.8500,                 loss: 0.4016
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 1138.5,                last time consumption/overall running time: 158.5837s / 75617.1936 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.4031
env0_second_0:                 episode reward: -4.0000,                 loss: 0.3977
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 1112.3,                last time consumption/overall running time: 158.1058s / 75775.2994 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.4327
env0_second_0:                 episode reward: -0.5500,                 loss: 0.4356
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 1239.6,                last time consumption/overall running time: 168.8733s / 75944.1727 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3868
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4063
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 1327.9,                last time consumption/overall running time: 190.0406s / 76134.2133 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.3884
env0_second_0:                 episode reward: -2.3500,                 loss: 0.3827
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 1206.15,                last time consumption/overall running time: 175.3951s / 76309.6084 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.4246
env0_second_0:                 episode reward: -0.9500,                 loss: 0.4302
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 1216.4,                last time consumption/overall running time: 173.6247s / 76483.2330 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.4001
env0_second_0:                 episode reward: -2.1500,                 loss: 0.3995
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 1237.4,                last time consumption/overall running time: 172.7740s / 76656.0070 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.3643
env0_second_0:                 episode reward: -3.0000,                 loss: 0.3687
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 1127.15,                last time consumption/overall running time: 152.0800s / 76808.0870 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3914
env0_second_0:                 episode reward: 1.3500,                 loss: 0.3953
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 1177.85,                last time consumption/overall running time: 167.8428s / 76975.9298 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3801
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3810
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 1238.5,                last time consumption/overall running time: 173.2777s / 77149.2076 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.4122
env0_second_0:                 episode reward: -4.8500,                 loss: 0.3975
env1_first_0:                 episode reward: 6.7000,                 loss: nan
env1_second_0:                 episode reward: -6.7000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 1249.9,                last time consumption/overall running time: 175.2996s / 77324.5071 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3940
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3940
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 1206.05,                last time consumption/overall running time: 168.2247s / 77492.7319 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3801
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3774
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 1211.6,                last time consumption/overall running time: 171.5453s / 77664.2771 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.4185
env0_second_0:                 episode reward: 1.9500,                 loss: 0.4088
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 1254.2,                last time consumption/overall running time: 171.9340s / 77836.2112 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.4204
env0_second_0:                 episode reward: -3.5500,                 loss: 0.4109
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 1218.85,                last time consumption/overall running time: 167.9678s / 78004.1789 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.3481
env0_second_0:                 episode reward: 1.6500,                 loss: 0.3701
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 1272.25,                last time consumption/overall running time: 174.5690s / 78178.7479 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.4210
env0_second_0:                 episode reward: 1.5000,                 loss: 0.4402
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 1180.55,                last time consumption/overall running time: 159.4468s / 78338.1947 s
env0_first_0:                 episode reward: 5.8000,                 loss: 0.3903
env0_second_0:                 episode reward: -5.8000,                 loss: 0.3914
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 1227.45,                last time consumption/overall running time: 166.6210s / 78504.8157 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.3960
env0_second_0:                 episode reward: -2.1000,                 loss: 0.3854
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 1250.4,                last time consumption/overall running time: 172.1394s / 78676.9551 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.3787
env0_second_0:                 episode reward: -2.4000,                 loss: 0.3765
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 1202.5,                last time consumption/overall running time: 168.5249s / 78845.4800 s
env0_first_0:                 episode reward: 5.8500,                 loss: 0.3982
env0_second_0:                 episode reward: -5.8500,                 loss: 0.3960
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 1194.8,                last time consumption/overall running time: 169.4756s / 79014.9556 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.3969
env0_second_0:                 episode reward: -3.6500,                 loss: 0.3945
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 1282.85,                last time consumption/overall running time: 186.5598s / 79201.5154 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3816
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3715
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 1297.75,                last time consumption/overall running time: 180.0425s / 79381.5578 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.4152
env0_second_0:                 episode reward: -2.5000,                 loss: 0.4238
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 1213.0,                last time consumption/overall running time: 165.4574s / 79547.0152 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.3882
env0_second_0:                 episode reward: -3.6500,                 loss: 0.3987
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 1226.1,                last time consumption/overall running time: 167.4824s / 79714.4976 s
env0_first_0:                 episode reward: 4.7000,                 loss: 0.3970
env0_second_0:                 episode reward: -4.7000,                 loss: 0.3965
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 1244.25,                last time consumption/overall running time: 171.6375s / 79886.1351 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.3838
env0_second_0:                 episode reward: -2.4000,                 loss: 0.3848
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 1232.05,                last time consumption/overall running time: 172.4173s / 80058.5524 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.4347
env0_second_0:                 episode reward: 1.9500,                 loss: 0.4390
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 1265.75,                last time consumption/overall running time: 180.1124s / 80238.6648 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.3492
env0_second_0:                 episode reward: -3.8000,                 loss: 0.3616
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 1227.85,                last time consumption/overall running time: 172.6794s / 80411.3442 s
env0_first_0:                 episode reward: 5.4000,                 loss: 0.4104
env0_second_0:                 episode reward: -5.4000,                 loss: 0.4211
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 1183.8,                last time consumption/overall running time: 159.7833s / 80571.1275 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.4025
env0_second_0:                 episode reward: -1.9500,                 loss: 0.4174
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 1254.15,                last time consumption/overall running time: 174.9954s / 80746.1229 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3795
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3526
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 1225.15,                last time consumption/overall running time: 172.9270s / 80919.0500 s
env0_first_0:                 episode reward: 6.4000,                 loss: 0.4125
env0_second_0:                 episode reward: -6.4000,                 loss: 0.3980
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 1213.45,                last time consumption/overall running time: 163.8888s / 81082.9388 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3714
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3683
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 1139.1,                last time consumption/overall running time: 155.1697s / 81238.1085 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.4432
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4737
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 1205.75,                last time consumption/overall running time: 167.2033s / 81405.3118 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.3839
env0_second_0:                 episode reward: -4.8500,                 loss: 0.3852
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 1229.7,                last time consumption/overall running time: 169.7400s / 81575.0518 s
env0_first_0:                 episode reward: 5.7500,                 loss: 0.3988
env0_second_0:                 episode reward: -5.7500,                 loss: 0.3923
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 1245.1,                last time consumption/overall running time: 171.6142s / 81746.6660 s
env0_first_0:                 episode reward: 5.8000,                 loss: 0.4053
env0_second_0:                 episode reward: -5.8000,                 loss: 0.3966
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 1242.45,                last time consumption/overall running time: 164.5393s / 81911.2053 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.3591
env0_second_0:                 episode reward: -3.3000,                 loss: 0.3441
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 1199.4,                last time consumption/overall running time: 160.0676s / 82071.2729 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3703
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4005
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 1132.2,                last time consumption/overall running time: 159.2127s / 82230.4856 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.4218
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4228
env1_first_0:                 episode reward: 5.4000,                 loss: nan
env1_second_0:                 episode reward: -5.4000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 1247.25,                last time consumption/overall running time: 175.1789s / 82405.6646 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.4011
env0_second_0:                 episode reward: -3.0500,                 loss: 0.3933
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 1175.9,                last time consumption/overall running time: 167.7436s / 82573.4082 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.4010
env0_second_0:                 episode reward: -2.7000,                 loss: 0.4365
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 1212.6,                last time consumption/overall running time: 172.2801s / 82745.6883 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.3998
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4017
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 1203.1,                last time consumption/overall running time: 163.2241s / 82908.9124 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3643
env0_second_0:                 episode reward: -0.3500,                 loss: 0.3829
env1_first_0:                 episode reward: 6.2000,                 loss: nan
env1_second_0:                 episode reward: -6.2000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 1283.75,                last time consumption/overall running time: 177.3902s / 83086.3026 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.3984
env0_second_0:                 episode reward: -2.3500,                 loss: 0.3855
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 1237.6,                last time consumption/overall running time: 173.9060s / 83260.2087 s
env0_first_0:                 episode reward: 6.3000,                 loss: 0.3827
env0_second_0:                 episode reward: -6.3000,                 loss: 0.3771
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 1208.1,                last time consumption/overall running time: 168.0919s / 83428.3006 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.3656
env0_second_0:                 episode reward: 1.5500,                 loss: 0.3937
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 1318.85,                last time consumption/overall running time: 182.7850s / 83611.0855 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.3775
env0_second_0:                 episode reward: -2.6500,                 loss: 0.3792
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 1210.1,                last time consumption/overall running time: 168.3083s / 83779.3939 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.3995
env0_second_0:                 episode reward: -1.9500,                 loss: 0.4036
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 1227.4,                last time consumption/overall running time: 169.4214s / 83948.8153 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.3766
env0_second_0:                 episode reward: -1.3500,                 loss: 0.3888
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 1156.05,                last time consumption/overall running time: 163.6399s / 84112.4552 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.4206
env0_second_0:                 episode reward: -2.7500,                 loss: 0.4451
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 1224.85,                last time consumption/overall running time: 163.5439s / 84275.9991 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.3378
env0_second_0:                 episode reward: -2.1500,                 loss: 0.3542
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 1184.25,                last time consumption/overall running time: 161.2095s / 84437.2086 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.4421
env0_second_0:                 episode reward: -3.0000,                 loss: 0.4463
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 1267.2,                last time consumption/overall running time: 181.0339s / 84618.2425 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.3367
env0_second_0:                 episode reward: 0.1500,                 loss: 0.3563
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 1183.2,                last time consumption/overall running time: 168.5305s / 84786.7731 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.4228
env0_second_0:                 episode reward: -4.7500,                 loss: 0.4217
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 1173.55,                last time consumption/overall running time: 162.7763s / 84949.5494 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.4205
env0_second_0:                 episode reward: -3.0500,                 loss: 0.4216
env1_first_0:                 episode reward: 5.8000,                 loss: nan
env1_second_0:                 episode reward: -5.8000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 1277.9,                last time consumption/overall running time: 173.6495s / 85123.1989 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.3968
env0_second_0:                 episode reward: -2.0000,                 loss: 0.4184
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 1163.25,                last time consumption/overall running time: 162.4044s / 85285.6033 s
env0_first_0:                 episode reward: 6.5500,                 loss: 0.4126
env0_second_0:                 episode reward: -6.5500,                 loss: 0.4203
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 1168.9,                last time consumption/overall running time: 162.0194s / 85447.6227 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3804
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3910
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 1229.45,                last time consumption/overall running time: 168.2646s / 85615.8872 s
env0_first_0:                 episode reward: 8.0500,                 loss: 0.3891
env0_second_0:                 episode reward: -8.0500,                 loss: 0.4000
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 1271.3,                last time consumption/overall running time: 170.7169s / 85786.6041 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.3987
env0_second_0:                 episode reward: -3.5500,                 loss: 0.3902
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 1188.75,                last time consumption/overall running time: 162.6291s / 85949.2332 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.4001Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_second_0:                 episode reward: -1.6500,                 loss: 0.3963
env1_first_0:                 episode reward: 6.5000,                 loss: nan
env1_second_0:                 episode reward: -6.5000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 1204.2,                last time consumption/overall running time: 166.2413s / 86115.4744 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.4225
env0_second_0:                 episode reward: -2.6000,                 loss: 0.4209
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 1225.05,                last time consumption/overall running time: 171.4076s / 86286.8820 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.3843
env0_second_0:                 episode reward: -2.9500,                 loss: 0.4030
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 1196.35,                last time consumption/overall running time: 166.5201s / 86453.4022 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.4155
env0_second_0:                 episode reward: 0.7500,                 loss: 0.4070
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 1159.75,                last time consumption/overall running time: 164.9930s / 86618.3952 s
env0_first_0:                 episode reward: 7.0000,                 loss: 0.4522
env0_second_0:                 episode reward: -7.0000,                 loss: 0.4515
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 1235.75,                last time consumption/overall running time: 166.9795s / 86785.3747 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3714
env0_second_0:                 episode reward: -0.4500,                 loss: 0.3566
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 1263.35,                last time consumption/overall running time: 174.8713s / 86960.2460 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.4113
env0_second_0:                 episode reward: -2.3500,                 loss: 0.4032
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 1216.85,                last time consumption/overall running time: 166.2442s / 87126.4902 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.4513
env0_second_0:                 episode reward: 0.9500,                 loss: 0.4471
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 1206.4,                last time consumption/overall running time: 161.8481s / 87288.3383 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3634
env0_second_0:                 episode reward: 0.0500,                 loss: 0.3603
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 1225.8,                last time consumption/overall running time: 170.3698s / 87458.7081 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.4057
env0_second_0:                 episode reward: -2.4000,                 loss: 0.4040
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
