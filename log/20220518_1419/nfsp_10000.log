pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 42.0, (1,), float32) action space: Discrete(6)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fe4bb1c0dd8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518032943/mdp_arbitrary_mdp_nfsp/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518032943/mdp_arbitrary_mdp_nfsp/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518032943_exploit_10000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518032943_exploit_10000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 7.3894s / 7.3894 s
agent0:                 episode reward: -0.1677,                 loss: nan
agent1:                 episode reward: 0.1677,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3553s / 7.7447 s
agent0:                 episode reward: -0.1213,                 loss: nan
agent1:                 episode reward: 0.1213,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4004s / 8.1451 s
agent0:                 episode reward: -0.0867,                 loss: nan
agent1:                 episode reward: 0.0867,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3994s / 8.5446 s
agent0:                 episode reward: -0.5779,                 loss: nan
agent1:                 episode reward: 0.5779,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3973s / 8.9419 s
agent0:                 episode reward: 0.0549,                 loss: nan
agent1:                 episode reward: -0.0549,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3954s / 9.3373 s
agent0:                 episode reward: 0.2681,                 loss: nan
agent1:                 episode reward: -0.2681,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3990s / 9.7364 s
agent0:                 episode reward: 0.0234,                 loss: nan
agent1:                 episode reward: -0.0234,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4012s / 10.1376 s
agent0:                 episode reward: 0.1329,                 loss: nan
agent1:                 episode reward: -0.1329,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3980s / 10.5356 s
agent0:                 episode reward: 0.1950,                 loss: nan
agent1:                 episode reward: -0.1950,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3973s / 10.9329 s
agent0:                 episode reward: 0.8511,                 loss: nan
agent1:                 episode reward: -0.8511,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3925s / 11.3254 s
agent0:                 episode reward: 0.5352,                 loss: nan
agent1:                 episode reward: -0.5352,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3947s / 11.7201 s
agent0:                 episode reward: 0.3733,                 loss: nan
agent1:                 episode reward: -0.3733,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4006s / 12.1207 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3958s / 12.5164 s
agent0:                 episode reward: -0.2473,                 loss: nan
agent1:                 episode reward: 0.2473,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3905s / 12.9069 s
agent0:                 episode reward: -0.2168,                 loss: nan
agent1:                 episode reward: 0.2168,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3858s / 13.2927 s
agent0:                 episode reward: 0.0866,                 loss: nan
agent1:                 episode reward: -0.0866,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3913s / 13.6840 s
agent0:                 episode reward: 0.2022,                 loss: nan
agent1:                 episode reward: -0.2022,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3897s / 14.0737 s
agent0:                 episode reward: 0.3639,                 loss: nan
agent1:                 episode reward: -0.3639,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3886s / 14.4623 s
agent0:                 episode reward: -0.2188,                 loss: nan
agent1:                 episode reward: 0.2188,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3857s / 14.8479 s
agent0:                 episode reward: -0.5914,                 loss: nan
agent1:                 episode reward: 0.5914,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3892s / 15.2372 s
agent0:                 episode reward: 0.8431,                 loss: nan
agent1:                 episode reward: -0.8431,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3965s / 15.6337 s
agent0:                 episode reward: -0.3054,                 loss: nan
agent1:                 episode reward: 0.3054,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3962s / 16.0299 s
agent0:                 episode reward: 0.0966,                 loss: nan
agent1:                 episode reward: -0.0966,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3886s / 16.4185 s
agent0:                 episode reward: 0.2082,                 loss: nan
agent1:                 episode reward: -0.2082,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3883s / 16.8068 s
agent0:                 episode reward: 0.2020,                 loss: nan
agent1:                 episode reward: -0.2020,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3916s / 17.1984 s
agent0:                 episode reward: 0.5073,                 loss: nan
agent1:                 episode reward: -0.5073,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3973s / 17.5957 s
agent0:                 episode reward: 0.5652,                 loss: nan
agent1:                 episode reward: -0.5652,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3881s / 17.9839 s
agent0:                 episode reward: 0.4660,                 loss: nan
agent1:                 episode reward: -0.4660,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3831s / 18.3670 s
agent0:                 episode reward: -0.0000,                 loss: nan
agent1:                 episode reward: 0.0000,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3873s / 18.7544 s
agent0:                 episode reward: -0.2299,                 loss: nan
agent1:                 episode reward: 0.2299,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3950s / 19.1493 s
agent0:                 episode reward: -0.1295,                 loss: nan
agent1:                 episode reward: 0.1295,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3938s / 19.5432 s
agent0:                 episode reward: 0.1562,                 loss: nan
agent1:                 episode reward: -0.1562,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3879s / 19.9310 s
agent0:                 episode reward: 0.1148,                 loss: nan
agent1:                 episode reward: -0.1148,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3959s / 20.3269 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3939s / 20.7208 s
agent0:                 episode reward: -0.1129,                 loss: nan
agent1:                 episode reward: 0.1129,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3857s / 21.1065 s
agent0:                 episode reward: 0.2607,                 loss: nan
agent1:                 episode reward: -0.2607,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3984s / 21.5049 s
agent0:                 episode reward: -0.4547,                 loss: nan
agent1:                 episode reward: 0.4547,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3957s / 21.9006 s
agent0:                 episode reward: 0.4099,                 loss: nan
agent1:                 episode reward: -0.4099,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3953s / 22.2959 s
agent0:                 episode reward: -0.2744,                 loss: nan
agent1:                 episode reward: 0.2744,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3906s / 22.6865 s
agent0:                 episode reward: 0.0545,                 loss: nan
agent1:                 episode reward: -0.0545,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3914s / 23.0780 s
agent0:                 episode reward: -0.0613,                 loss: nan
agent1:                 episode reward: 0.0613,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3915s / 23.4694 s
agent0:                 episode reward: 0.4692,                 loss: nan
agent1:                 episode reward: -0.4692,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4002s / 23.8696 s
agent0:                 episode reward: 0.2104,                 loss: nan
agent1:                 episode reward: -0.2104,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3947s / 24.2643 s
agent0:                 episode reward: -0.0612,                 loss: nan
agent1:                 episode reward: 0.0612,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3919s / 24.6562 s
agent0:                 episode reward: -0.2896,                 loss: nan
agent1:                 episode reward: 0.2896,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3939s / 25.0501 s
agent0:                 episode reward: -0.1732,                 loss: nan
agent1:                 episode reward: 0.1732,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3940s / 25.4441 s
agent0:                 episode reward: 0.1015,                 loss: nan
agent1:                 episode reward: -0.1015,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3916s / 25.8358 s
agent0:                 episode reward: -0.0467,                 loss: nan
agent1:                 episode reward: 0.0467,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3951s / 26.2309 s
agent0:                 episode reward: -0.0894,                 loss: nan
agent1:                 episode reward: 0.0894,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3893s / 26.6202 s
agent0:                 episode reward: 0.0375,                 loss: nan
agent1:                 episode reward: -0.0375,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3923s / 27.0125 s
agent0:                 episode reward: 0.0032,                 loss: nan
agent1:                 episode reward: -0.0032,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3920s / 27.4045 s
agent0:                 episode reward: -0.0295,                 loss: nan
agent1:                 episode reward: 0.0295,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3857s / 27.7902 s
agent0:                 episode reward: -0.5216,                 loss: nan
agent1:                 episode reward: 0.5216,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3947s / 28.1849 s
agent0:                 episode reward: -0.5070,                 loss: nan
agent1:                 episode reward: 0.5070,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3844s / 28.5693 s
agent0:                 episode reward: -0.6511,                 loss: nan
agent1:                 episode reward: 0.6511,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3932s / 28.9626 s
agent0:                 episode reward: 0.3079,                 loss: nan
agent1:                 episode reward: -0.3079,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3896s / 29.3522 s
agent0:                 episode reward: 0.1351,                 loss: nan
agent1:                 episode reward: -0.1351,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3915s / 29.7437 s
agent0:                 episode reward: -0.3298,                 loss: nan
agent1:                 episode reward: 0.3298,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3890s / 30.1327 s
agent0:                 episode reward: 0.0656,                 loss: nan
agent1:                 episode reward: -0.0656,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3944s / 30.5271 s
agent0:                 episode reward: 0.0871,                 loss: nan
agent1:                 episode reward: -0.0871,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3929s / 30.9200 s
agent0:                 episode reward: 0.3258,                 loss: nan
agent1:                 episode reward: -0.3258,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3945s / 31.3145 s
agent0:                 episode reward: 0.0846,                 loss: nan
agent1:                 episode reward: -0.0846,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3944s / 31.7089 s
agent0:                 episode reward: 0.2176,                 loss: nan
agent1:                 episode reward: -0.2176,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3954s / 32.1043 s
agent0:                 episode reward: -0.2650,                 loss: nan
agent1:                 episode reward: 0.2650,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3888s / 32.4930 s
agent0:                 episode reward: 0.0281,                 loss: nan
agent1:                 episode reward: -0.0281,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3917s / 32.8847 s
agent0:                 episode reward: 0.0670,                 loss: nan
agent1:                 episode reward: -0.0670,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3890s / 33.2737 s
agent0:                 episode reward: -0.1708,                 loss: nan
agent1:                 episode reward: 0.1708,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3866s / 33.6603 s
agent0:                 episode reward: 0.2043,                 loss: nan
agent1:                 episode reward: -0.2043,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3868s / 34.0470 s
agent0:                 episode reward: 0.1683,                 loss: nan
agent1:                 episode reward: -0.1683,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3945s / 34.4415 s
agent0:                 episode reward: -0.1875,                 loss: nan
agent1:                 episode reward: 0.1875,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3938s / 34.8353 s
agent0:                 episode reward: -0.3183,                 loss: nan
agent1:                 episode reward: 0.3183,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3894s / 35.2248 s
agent0:                 episode reward: -0.0209,                 loss: nan
agent1:                 episode reward: 0.0209,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3967s / 35.6214 s
agent0:                 episode reward: -0.1305,                 loss: nan
agent1:                 episode reward: 0.1305,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3846s / 36.0061 s
agent0:                 episode reward: -0.1665,                 loss: nan
agent1:                 episode reward: 0.1665,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3937s / 36.3997 s
agent0:                 episode reward: 0.3212,                 loss: nan
agent1:                 episode reward: -0.3212,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3869s / 36.7867 s
agent0:                 episode reward: -0.0838,                 loss: nan
agent1:                 episode reward: 0.0838,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4404s / 37.2271 s
agent0:                 episode reward: 0.2579,                 loss: nan
agent1:                 episode reward: -0.2579,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3662s / 37.5932 s
agent0:                 episode reward: -0.0309,                 loss: nan
agent1:                 episode reward: 0.0309,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3922s / 37.9854 s
agent0:                 episode reward: -0.0718,                 loss: nan
agent1:                 episode reward: 0.0718,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3880s / 38.3734 s
agent0:                 episode reward: 0.3145,                 loss: nan
agent1:                 episode reward: -0.3145,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3865s / 38.7599 s
agent0:                 episode reward: -0.5486,                 loss: nan
agent1:                 episode reward: 0.5486,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3931s / 39.1530 s
agent0:                 episode reward: -0.0080,                 loss: nan
agent1:                 episode reward: 0.0080,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3982s / 39.5512 s
agent0:                 episode reward: -0.2697,                 loss: nan
agent1:                 episode reward: 0.2697,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3933s / 39.9445 s
agent0:                 episode reward: 0.1459,                 loss: nan
agent1:                 episode reward: -0.1459,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 2.2484s / 42.1929 s
agent0:                 episode reward: -0.0512,                 loss: nan
agent1:                 episode reward: 0.0512,                 loss: 0.4639
Episode: 1701/30000 (5.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1313s / 43.3242 s
agent0:                 episode reward: 0.0493,                 loss: nan
agent1:                 episode reward: -0.0493,                 loss: 0.4005
Episode: 1721/30000 (5.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1401s / 44.4643 s
agent0:                 episode reward: 0.4608,                 loss: nan
agent1:                 episode reward: -0.4608,                 loss: 0.3869
Episode: 1741/30000 (5.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1364s / 45.6007 s
agent0:                 episode reward: 0.0225,                 loss: nan
agent1:                 episode reward: -0.0225,                 loss: 0.3766
Episode: 1761/30000 (5.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1362s / 46.7369 s
agent0:                 episode reward: 0.3216,                 loss: nan
agent1:                 episode reward: -0.3216,                 loss: 0.3602
Episode: 1781/30000 (5.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1376s / 47.8745 s
agent0:                 episode reward: -0.0129,                 loss: nan
agent1:                 episode reward: 0.0129,                 loss: 0.3376
Episode: 1801/30000 (6.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1323s / 49.0068 s
agent0:                 episode reward: 0.1110,                 loss: nan
agent1:                 episode reward: -0.1110,                 loss: 0.3133
Episode: 1821/30000 (6.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1369s / 50.1437 s
agent0:                 episode reward: 0.1588,                 loss: nan
agent1:                 episode reward: -0.1588,                 loss: 0.2906
Episode: 1841/30000 (6.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1298s / 51.2735 s
agent0:                 episode reward: -0.2828,                 loss: nan
agent1:                 episode reward: 0.2828,                 loss: 0.3272
Episode: 1861/30000 (6.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1383s / 52.4118 s
agent0:                 episode reward: 0.1343,                 loss: nan
agent1:                 episode reward: -0.1343,                 loss: 0.3908
Episode: 1881/30000 (6.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1374s / 53.5492 s
agent0:                 episode reward: 0.1536,                 loss: nan
agent1:                 episode reward: -0.1536,                 loss: 0.3856
Episode: 1901/30000 (6.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1457s / 54.6949 s
agent0:                 episode reward: -0.1818,                 loss: nan
agent1:                 episode reward: 0.1818,                 loss: 0.3873
Episode: 1921/30000 (6.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1365s / 55.8314 s
agent0:                 episode reward: 0.2484,                 loss: nan
agent1:                 episode reward: -0.2484,                 loss: 0.3856
Episode: 1941/30000 (6.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1385s / 56.9699 s
agent0:                 episode reward: -0.1045,                 loss: nan
agent1:                 episode reward: 0.1045,                 loss: 0.3843
Episode: 1961/30000 (6.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1356s / 58.1054 s
agent0:                 episode reward: 0.2222,                 loss: nan
agent1:                 episode reward: -0.2222,                 loss: 0.3849
Episode: 1981/30000 (6.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1431s / 59.2485 s
agent0:                 episode reward: -0.2914,                 loss: nan
agent1:                 episode reward: 0.2914,                 loss: 0.3832
Episode: 2001/30000 (6.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1446s / 60.3932 s
agent0:                 episode reward: -0.1145,                 loss: nan
agent1:                 episode reward: 0.1145,                 loss: 0.3874
Episode: 2021/30000 (6.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1406s / 61.5338 s
agent0:                 episode reward: -0.2071,                 loss: nan
agent1:                 episode reward: 0.2071,                 loss: 0.4133
Episode: 2041/30000 (6.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1284s / 62.6621 s
agent0:                 episode reward: -0.1747,                 loss: nan
agent1:                 episode reward: 0.1747,                 loss: 0.4036
Episode: 2061/30000 (6.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1282s / 63.7903 s
agent0:                 episode reward: -0.2647,                 loss: nan
agent1:                 episode reward: 0.2647,                 loss: 0.3983
Episode: 2081/30000 (6.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1195s / 64.9098 s
agent0:                 episode reward: 0.0927,                 loss: nan
agent1:                 episode reward: -0.0927,                 loss: 0.3956
Episode: 2101/30000 (7.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1316s / 66.0413 s
agent0:                 episode reward: 0.0560,                 loss: nan
agent1:                 episode reward: -0.0560,                 loss: 0.3951
Episode: 2121/30000 (7.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1299s / 67.1712 s
agent0:                 episode reward: -0.0999,                 loss: nan
agent1:                 episode reward: 0.0999,                 loss: 0.3937
Episode: 2141/30000 (7.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1382s / 68.3094 s
agent0:                 episode reward: -0.3129,                 loss: nan
agent1:                 episode reward: 0.3129,                 loss: 0.3930
Episode: 2161/30000 (7.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1247s / 69.4341 s
agent0:                 episode reward: -0.4137,                 loss: nan
agent1:                 episode reward: 0.4137,                 loss: 0.3915
Episode: 2181/30000 (7.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1231s / 70.5572 s
agent0:                 episode reward: -0.2510,                 loss: nan
agent1:                 episode reward: 0.2510,                 loss: 0.3999
Episode: 2201/30000 (7.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1419s / 71.6991 s
agent0:                 episode reward: -0.2467,                 loss: nan
agent1:                 episode reward: 0.2467,                 loss: 0.4002
Episode: 2221/30000 (7.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1228s / 72.8219 s
agent0:                 episode reward: -0.1565,                 loss: nan
agent1:                 episode reward: 0.1565,                 loss: 0.3998
Episode: 2241/30000 (7.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1220s / 73.9439 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.3982
Episode: 2261/30000 (7.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1243s / 75.0682 s
agent0:                 episode reward: -0.6742,                 loss: nan
agent1:                 episode reward: 0.6742,                 loss: 0.3998
Episode: 2281/30000 (7.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1459s / 76.2141 s
agent0:                 episode reward: 0.0045,                 loss: nan
agent1:                 episode reward: -0.0045,                 loss: 0.3981
Episode: 2301/30000 (7.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1263s / 77.3404 s
agent0:                 episode reward: -0.2415,                 loss: nan
agent1:                 episode reward: 0.2415,                 loss: 0.3979
Episode: 2321/30000 (7.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1304s / 78.4709 s
agent0:                 episode reward: -0.9079,                 loss: nan
agent1:                 episode reward: 0.9079,                 loss: 0.3971
Episode: 2341/30000 (7.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1375s / 79.6084 s
agent0:                 episode reward: 0.4950,                 loss: nan
agent1:                 episode reward: -0.4950,                 loss: 0.4087
Episode: 2361/30000 (7.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1363s / 80.7447 s
agent0:                 episode reward: -0.3139,                 loss: nan
agent1:                 episode reward: 0.3139,                 loss: 0.4142
Episode: 2381/30000 (7.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1310s / 81.8757 s
agent0:                 episode reward: 0.2625,                 loss: nan
agent1:                 episode reward: -0.2625,                 loss: 0.4125
Episode: 2401/30000 (8.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1314s / 83.0072 s
agent0:                 episode reward: 0.2140,                 loss: nan
agent1:                 episode reward: -0.2140,                 loss: 0.4102
Episode: 2421/30000 (8.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1248s / 84.1320 s
agent0:                 episode reward: 0.6807,                 loss: nan
agent1:                 episode reward: -0.6807,                 loss: 0.4109
Episode: 2441/30000 (8.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1409s / 85.2729 s
agent0:                 episode reward: -0.1102,                 loss: nan
agent1:                 episode reward: 0.1102,                 loss: 0.4086
Episode: 2461/30000 (8.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1411s / 86.4140 s
agent0:                 episode reward: -0.4258,                 loss: nan
agent1:                 episode reward: 0.4258,                 loss: 0.4095
Episode: 2481/30000 (8.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1568s / 87.5707 s
agent0:                 episode reward: -0.3646,                 loss: nan
agent1:                 episode reward: 0.3646,                 loss: 0.4086
Episode: 2501/30000 (8.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1649s / 88.7356 s
agent0:                 episode reward: 0.2785,                 loss: nan
agent1:                 episode reward: -0.2785,                 loss: 0.4052
Episode: 2521/30000 (8.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1593s / 89.8949 s
agent0:                 episode reward: -0.0681,                 loss: nan
agent1:                 episode reward: 0.0681,                 loss: 0.3785
Episode: 2541/30000 (8.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1722s / 91.0672 s
agent0:                 episode reward: -0.3971,                 loss: nan
agent1:                 episode reward: 0.3971,                 loss: 0.3765
Episode: 2561/30000 (8.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1553s / 92.2224 s
agent0:                 episode reward: 0.0225,                 loss: nan
agent1:                 episode reward: -0.0225,                 loss: 0.3744
Episode: 2581/30000 (8.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1526s / 93.3750 s
agent0:                 episode reward: -0.4543,                 loss: nan
agent1:                 episode reward: 0.4543,                 loss: 0.3738
Episode: 2601/30000 (8.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1513s / 94.5263 s
agent0:                 episode reward: 0.1636,                 loss: nan
agent1:                 episode reward: -0.1636,                 loss: 0.3739
Episode: 2621/30000 (8.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1460s / 95.6722 s
agent0:                 episode reward: -0.1895,                 loss: nan
agent1:                 episode reward: 0.1895,                 loss: 0.3749
Episode: 2641/30000 (8.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1513s / 96.8235 s
agent0:                 episode reward: -0.2981,                 loss: nan
agent1:                 episode reward: 0.2981,                 loss: 0.3750
Episode: 2661/30000 (8.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1621s / 97.9856 s
agent0:                 episode reward: 0.1902,                 loss: nan
agent1:                 episode reward: -0.1902,                 loss: 0.3742
Episode: 2681/30000 (8.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1492s / 99.1348 s
agent0:                 episode reward: 0.1094,                 loss: nan
agent1:                 episode reward: -0.1094,                 loss: 0.3713
Episode: 2701/30000 (9.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1537s / 100.2885 s
agent0:                 episode reward: -0.4266,                 loss: nan
agent1:                 episode reward: 0.4266,                 loss: 0.3691
Episode: 2721/30000 (9.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1509s / 101.4394 s
agent0:                 episode reward: -0.2101,                 loss: nan
agent1:                 episode reward: 0.2101,                 loss: 0.3669
Episode: 2741/30000 (9.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1546s / 102.5939 s
agent0:                 episode reward: -0.2485,                 loss: nan
agent1:                 episode reward: 0.2485,                 loss: 0.3683
Episode: 2761/30000 (9.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1520s / 103.7459 s
agent0:                 episode reward: -0.4175,                 loss: nan
agent1:                 episode reward: 0.4175,                 loss: 0.3675
Episode: 2781/30000 (9.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1569s / 104.9028 s
agent0:                 episode reward: 0.0860,                 loss: nan
agent1:                 episode reward: -0.0860,                 loss: 0.3694
Episode: 2801/30000 (9.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1649s / 106.0677 s
agent0:                 episode reward: 0.2065,                 loss: nan
agent1:                 episode reward: -0.2065,                 loss: 0.3668
Episode: 2821/30000 (9.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1416s / 107.2093 s
agent0:                 episode reward: 0.2927,                 loss: nan
agent1:                 episode reward: -0.2927,                 loss: 0.3689
Episode: 2841/30000 (9.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1414s / 108.3507 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.3938
Episode: 2861/30000 (9.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1641s / 109.5147 s
agent0:                 episode reward: -0.3350,                 loss: nan
agent1:                 episode reward: 0.3350,                 loss: 0.4257
Episode: 2881/30000 (9.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1527s / 110.6674 s
agent0:                 episode reward: -0.1614,                 loss: nan
agent1:                 episode reward: 0.1614,                 loss: 0.4242
Episode: 2901/30000 (9.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1640s / 111.8314 s
agent0:                 episode reward: -0.0260,                 loss: nan
agent1:                 episode reward: 0.0260,                 loss: 0.4238
Episode: 2921/30000 (9.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1597s / 112.9912 s
agent0:                 episode reward: -0.9795,                 loss: nan
agent1:                 episode reward: 0.9795,                 loss: 0.4244
Episode: 2941/30000 (9.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1549s / 114.1460 s
agent0:                 episode reward: -0.0698,                 loss: nan
agent1:                 episode reward: 0.0698,                 loss: 0.4241
Episode: 2961/30000 (9.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1513s / 115.2974 s
agent0:                 episode reward: -0.4113,                 loss: nan
agent1:                 episode reward: 0.4113,                 loss: 0.4236
Episode: 2981/30000 (9.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1737s / 116.4711 s
agent0:                 episode reward: -0.2216,                 loss: nan
agent1:                 episode reward: 0.2216,                 loss: 0.4232
Episode: 3001/30000 (10.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1543s / 117.6253 s
agent0:                 episode reward: -0.8092,                 loss: nan
agent1:                 episode reward: 0.8092,                 loss: 0.4254
Episode: 3021/30000 (10.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1598s / 118.7851 s
agent0:                 episode reward: -0.0489,                 loss: nan
agent1:                 episode reward: 0.0489,                 loss: 0.4396
Episode: 3041/30000 (10.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1678s / 119.9529 s
agent0:                 episode reward: -0.3919,                 loss: nan
agent1:                 episode reward: 0.3919,                 loss: 0.4362
Episode: 3061/30000 (10.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1626s / 121.1155 s
agent0:                 episode reward: -0.5937,                 loss: nan
agent1:                 episode reward: 0.5937,                 loss: 0.4357
Episode: 3081/30000 (10.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1693s / 122.2848 s
agent0:                 episode reward: -0.3186,                 loss: nan
agent1:                 episode reward: 0.3186,                 loss: 0.4365
Episode: 3101/30000 (10.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1510s / 123.4358 s
agent0:                 episode reward: -0.0189,                 loss: nan
agent1:                 episode reward: 0.0189,                 loss: 0.4345
Episode: 3121/30000 (10.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1596s / 124.5954 s
agent0:                 episode reward: 0.0509,                 loss: nan
agent1:                 episode reward: -0.0509,                 loss: 0.4343
Episode: 3141/30000 (10.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1559s / 125.7513 s
agent0:                 episode reward: -0.6116,                 loss: nan
agent1:                 episode reward: 0.6116,                 loss: 0.4343
Episode: 3161/30000 (10.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1752s / 126.9265 s
agent0:                 episode reward: -0.9157,                 loss: nan
agent1:                 episode reward: 0.9157,                 loss: 0.4351
Episode: 3181/30000 (10.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1791s / 128.1056 s
agent0:                 episode reward: 0.3544,                 loss: nan
agent1:                 episode reward: -0.3544,                 loss: 0.4358
Episode: 3201/30000 (10.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1625s / 129.2681 s
agent0:                 episode reward: 0.0368,                 loss: nan
agent1:                 episode reward: -0.0368,                 loss: 0.4355
Episode: 3221/30000 (10.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1637s / 130.4318 s
agent0:                 episode reward: -0.2072,                 loss: nan
agent1:                 episode reward: 0.2072,                 loss: 0.4359
Episode: 3241/30000 (10.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1736s / 131.6053 s
agent0:                 episode reward: -0.5690,                 loss: nan
agent1:                 episode reward: 0.5690,                 loss: 0.4335
Episode: 3261/30000 (10.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1668s / 132.7722 s
agent0:                 episode reward: -0.6960,                 loss: nan
agent1:                 episode reward: 0.6960,                 loss: 0.4336
Episode: 3281/30000 (10.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1550s / 133.9272 s
agent0:                 episode reward: -0.3786,                 loss: nan
agent1:                 episode reward: 0.3786,                 loss: 0.4337
Episode: 3301/30000 (11.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1804s / 135.1076 s
agent0:                 episode reward: -0.3813,                 loss: nan
agent1:                 episode reward: 0.3813,                 loss: 0.4347
Episode: 3321/30000 (11.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1683s / 136.2759 s
agent0:                 episode reward: -0.1084,                 loss: nan
agent1:                 episode reward: 0.1084,                 loss: 0.4344
Episode: 3341/30000 (11.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1597s / 137.4357 s
agent0:                 episode reward: -0.4445,                 loss: nan
agent1:                 episode reward: 0.4445,                 loss: 0.4387
Episode: 3361/30000 (11.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1685s / 138.6041 s
agent0:                 episode reward: 0.1999,                 loss: nan
agent1:                 episode reward: -0.1999,                 loss: 0.4425
Episode: 3381/30000 (11.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1564s / 139.7606 s
agent0:                 episode reward: -0.2721,                 loss: nan
agent1:                 episode reward: 0.2721,                 loss: 0.4437
Episode: 3401/30000 (11.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1704s / 140.9309 s
agent0:                 episode reward: -0.3988,                 loss: nan
agent1:                 episode reward: 0.3988,                 loss: 0.4427
Episode: 3421/30000 (11.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1811s / 142.1120 s
agent0:                 episode reward: 0.1384,                 loss: nan
agent1:                 episode reward: -0.1384,                 loss: 0.4417
Episode: 3441/30000 (11.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1750s / 143.2870 s
agent0:                 episode reward: -0.5618,                 loss: nan
agent1:                 episode reward: 0.5618,                 loss: 0.4425
Episode: 3461/30000 (11.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1645s / 144.4515 s
agent0:                 episode reward: -0.1669,                 loss: nan
agent1:                 episode reward: 0.1669,                 loss: 0.4411
Episode: 3481/30000 (11.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1701s / 145.6216 s
agent0:                 episode reward: -0.2872,                 loss: nan
agent1:                 episode reward: 0.2872,                 loss: 0.4403
Episode: 3501/30000 (11.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1561s / 146.7777 s
agent0:                 episode reward: 0.1779,                 loss: nan
agent1:                 episode reward: -0.1779,                 loss: 0.4414
Episode: 3521/30000 (11.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1659s / 147.9436 s
agent0:                 episode reward: -0.2256,                 loss: nan
agent1:                 episode reward: 0.2256,                 loss: 0.4241
Episode: 3541/30000 (11.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1704s / 149.1140 s
agent0:                 episode reward: -0.5517,                 loss: nan
agent1:                 episode reward: 0.5517,                 loss: 0.4269
Episode: 3561/30000 (11.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1790s / 150.2931 s
agent0:                 episode reward: 0.0739,                 loss: nan
agent1:                 episode reward: -0.0739,                 loss: 0.4260
Episode: 3581/30000 (11.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1627s / 151.4558 s
agent0:                 episode reward: -1.4173,                 loss: nan
agent1:                 episode reward: 1.4173,                 loss: 0.4254
Episode: 3601/30000 (12.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1664s / 152.6222 s
agent0:                 episode reward: -0.5240,                 loss: nan
agent1:                 episode reward: 0.5240,                 loss: 0.4240
Episode: 3621/30000 (12.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1753s / 153.7976 s
agent0:                 episode reward: -0.0821,                 loss: nan
agent1:                 episode reward: 0.0821,                 loss: 0.4232
Episode: 3641/30000 (12.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1759s / 154.9735 s
agent0:                 episode reward: -0.2510,                 loss: nan
agent1:                 episode reward: 0.2510,                 loss: 0.4238
Episode: 3661/30000 (12.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1856s / 156.1591 s
agent0:                 episode reward: -0.6301,                 loss: nan
agent1:                 episode reward: 0.6301,                 loss: 0.4245
Episode: 3681/30000 (12.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1699s / 157.3290 s
agent0:                 episode reward: -0.5797,                 loss: nan
agent1:                 episode reward: 0.5797,                 loss: 0.4192
Episode: 3701/30000 (12.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1758s / 158.5048 s
agent0:                 episode reward: 0.0905,                 loss: nan
agent1:                 episode reward: -0.0905,                 loss: 0.4141
Episode: 3721/30000 (12.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1764s / 159.6812 s
agent0:                 episode reward: -0.1544,                 loss: nan
agent1:                 episode reward: 0.1544,                 loss: 0.4127
Episode: 3741/30000 (12.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1725s / 160.8536 s
agent0:                 episode reward: -0.5029,                 loss: nan
agent1:                 episode reward: 0.5029,                 loss: 0.4135
Episode: 3761/30000 (12.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1710s / 162.0246 s
agent0:                 episode reward: -0.4141,                 loss: nan
agent1:                 episode reward: 0.4141,                 loss: 0.4133
Episode: 3781/30000 (12.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1854s / 163.2101 s
agent0:                 episode reward: -0.3284,                 loss: nan
agent1:                 episode reward: 0.3284,                 loss: 0.4126
Episode: 3801/30000 (12.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1770s / 164.3870 s
agent0:                 episode reward: 0.0968,                 loss: nan
agent1:                 episode reward: -0.0968,                 loss: 0.4122
Episode: 3821/30000 (12.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1737s / 165.5607 s
agent0:                 episode reward: -0.1574,                 loss: nan
agent1:                 episode reward: 0.1574,                 loss: 0.4120
Episode: 3841/30000 (12.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1974s / 166.7581 s
agent0:                 episode reward: 0.0287,                 loss: nan
agent1:                 episode reward: -0.0287,                 loss: 0.4208
Episode: 3861/30000 (12.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1942s / 167.9523 s
agent0:                 episode reward: -0.5579,                 loss: nan
agent1:                 episode reward: 0.5579,                 loss: 0.4272
Episode: 3881/30000 (12.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1862s / 169.1385 s
agent0:                 episode reward: -0.0370,                 loss: nan
agent1:                 episode reward: 0.0370,                 loss: 0.4268
Episode: 3901/30000 (13.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1853s / 170.3238 s
agent0:                 episode reward: -0.8925,                 loss: nan
agent1:                 episode reward: 0.8925,                 loss: 0.4264
Episode: 3921/30000 (13.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1947s / 171.5186 s
agent0:                 episode reward: -0.3378,                 loss: nan
agent1:                 episode reward: 0.3378,                 loss: 0.4272
Episode: 3941/30000 (13.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1931s / 172.7117 s
agent0:                 episode reward: -0.4403,                 loss: nan
agent1:                 episode reward: 0.4403,                 loss: 0.4267
Episode: 3961/30000 (13.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1999s / 173.9116 s
agent0:                 episode reward: 0.0934,                 loss: nan
agent1:                 episode reward: -0.0934,                 loss: 0.4255
Episode: 3981/30000 (13.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1886s / 175.1002 s
agent0:                 episode reward: -0.5022,                 loss: nan
agent1:                 episode reward: 0.5022,                 loss: 0.4278
Episode: 4001/30000 (13.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1934s / 176.2935 s
agent0:                 episode reward: -0.5284,                 loss: nan
agent1:                 episode reward: 0.5284,                 loss: 0.4269
Episode: 4021/30000 (13.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1994s / 177.4929 s
agent0:                 episode reward: -0.6152,                 loss: nan
agent1:                 episode reward: 0.6152,                 loss: 0.4327
Episode: 4041/30000 (13.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1689s / 178.6618 s
agent0:                 episode reward: -0.1411,                 loss: nan
agent1:                 episode reward: 0.1411,                 loss: 0.4299
Episode: 4061/30000 (13.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1782s / 179.8400 s
agent0:                 episode reward: -0.7225,                 loss: nan
agent1:                 episode reward: 0.7225,                 loss: 0.4279
Episode: 4081/30000 (13.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1674s / 181.0074 s
agent0:                 episode reward: -0.1186,                 loss: nan
agent1:                 episode reward: 0.1186,                 loss: 0.4288
Episode: 4101/30000 (13.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1780s / 182.1854 s
agent0:                 episode reward: -0.2797,                 loss: nan
agent1:                 episode reward: 0.2797,                 loss: 0.4276
Episode: 4121/30000 (13.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1715s / 183.3569 s
agent0:                 episode reward: -0.3517,                 loss: nan
agent1:                 episode reward: 0.3517,                 loss: 0.4281
Episode: 4141/30000 (13.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1734s / 184.5304 s
agent0:                 episode reward: 0.0433,                 loss: nan
agent1:                 episode reward: -0.0433,                 loss: 0.4275
Episode: 4161/30000 (13.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1878s / 185.7182 s
agent0:                 episode reward: -0.3439,                 loss: nan
agent1:                 episode reward: 0.3439,                 loss: 0.4260
Episode: 4181/30000 (13.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2057s / 186.9238 s
agent0:                 episode reward: -0.7822,                 loss: nan
agent1:                 episode reward: 0.7822,                 loss: 0.4247
Episode: 4201/30000 (14.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1834s / 188.1072 s
agent0:                 episode reward: -0.3857,                 loss: nan
agent1:                 episode reward: 0.3857,                 loss: 0.4189
Episode: 4221/30000 (14.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1816s / 189.2888 s
agent0:                 episode reward: -0.4326,                 loss: nan
agent1:                 episode reward: 0.4326,                 loss: 0.4169
Episode: 4241/30000 (14.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1875s / 190.4764 s
agent0:                 episode reward: -0.4122,                 loss: nan
agent1:                 episode reward: 0.4122,                 loss: 0.4188
Episode: 4261/30000 (14.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1912s / 191.6676 s
agent0:                 episode reward: -0.1717,                 loss: nan
agent1:                 episode reward: 0.1717,                 loss: 0.4189
Episode: 4281/30000 (14.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1868s / 192.8544 s
agent0:                 episode reward: -0.5861,                 loss: nan
agent1:                 episode reward: 0.5861,                 loss: 0.4179
Episode: 4301/30000 (14.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1830s / 194.0374 s
agent0:                 episode reward: -0.4722,                 loss: nan
agent1:                 episode reward: 0.4722,                 loss: 0.4181
Episode: 4321/30000 (14.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1939s / 195.2313 s
agent0:                 episode reward: -0.4530,                 loss: nan
agent1:                 episode reward: 0.4530,                 loss: 0.4158
Episode: 4341/30000 (14.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1821s / 196.4134 s
agent0:                 episode reward: -0.3126,                 loss: nan
agent1:                 episode reward: 0.3126,                 loss: 0.4232
Episode: 4361/30000 (14.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2487s / 197.6621 s
agent0:                 episode reward: -0.4429,                 loss: nan
agent1:                 episode reward: 0.4429,                 loss: 0.4304
Episode: 4381/30000 (14.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1936s / 198.8557 s
agent0:                 episode reward: -0.3844,                 loss: nan
agent1:                 episode reward: 0.3844,                 loss: 0.4295
Episode: 4401/30000 (14.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1889s / 200.0447 s
agent0:                 episode reward: -0.3340,                 loss: nan
agent1:                 episode reward: 0.3340,                 loss: 0.4296
Episode: 4421/30000 (14.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1816s / 201.2263 s
agent0:                 episode reward: -0.2536,                 loss: nan
agent1:                 episode reward: 0.2536,                 loss: 0.4299
Episode: 4441/30000 (14.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1918s / 202.4181 s
agent0:                 episode reward: -0.6468,                 loss: nan
agent1:                 episode reward: 0.6468,                 loss: 0.4304
Episode: 4461/30000 (14.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1950s / 203.6131 s
agent0:                 episode reward: -0.5023,                 loss: nan
agent1:                 episode reward: 0.5023,                 loss: 0.4303
Episode: 4481/30000 (14.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1942s / 204.8073 s
agent0:                 episode reward: 0.2624,                 loss: nan
agent1:                 episode reward: -0.2624,                 loss: 0.4303
Episode: 4501/30000 (15.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1908s / 205.9981 s
agent0:                 episode reward: -0.2723,                 loss: nan
agent1:                 episode reward: 0.2723,                 loss: 0.4299
Episode: 4521/30000 (15.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1834s / 207.1814 s
agent0:                 episode reward: -0.4408,                 loss: nan
agent1:                 episode reward: 0.4408,                 loss: 0.4218
Episode: 4541/30000 (15.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2016s / 208.3830 s
agent0:                 episode reward: -0.3692,                 loss: nan
agent1:                 episode reward: 0.3692,                 loss: 0.4226
Episode: 4561/30000 (15.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1805s / 209.5635 s
agent0:                 episode reward: -0.4412,                 loss: nan
agent1:                 episode reward: 0.4412,                 loss: 0.4218
Episode: 4581/30000 (15.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1983s / 210.7618 s
agent0:                 episode reward: 0.0582,                 loss: nan
agent1:                 episode reward: -0.0582,                 loss: 0.4210
Episode: 4601/30000 (15.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1837s / 211.9455 s
agent0:                 episode reward: -0.7571,                 loss: nan
agent1:                 episode reward: 0.7571,                 loss: 0.4206
Episode: 4621/30000 (15.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1879s / 213.1335 s
agent0:                 episode reward: -0.3342,                 loss: nan
agent1:                 episode reward: 0.3342,                 loss: 0.4218
Episode: 4641/30000 (15.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1632s / 214.2967 s
agent0:                 episode reward: 0.2488,                 loss: nan
agent1:                 episode reward: -0.2488,                 loss: 0.4210
Episode: 4661/30000 (15.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1771s / 215.4738 s
agent0:                 episode reward: -0.2042,                 loss: nan
agent1:                 episode reward: 0.2042,                 loss: 0.4209
Episode: 4681/30000 (15.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1825s / 216.6563 s
agent0:                 episode reward: -0.1704,                 loss: nan
agent1:                 episode reward: 0.1704,                 loss: 0.4126
Episode: 4701/30000 (15.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2689s / 217.9252 s
agent0:                 episode reward: -0.2165,                 loss: nan
agent1:                 episode reward: 0.2165,                 loss: 0.4045
Episode: 4721/30000 (15.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1801s / 219.1053 s
agent0:                 episode reward: 0.2678,                 loss: nan
agent1:                 episode reward: -0.2678,                 loss: 0.4046
Episode: 4741/30000 (15.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1782s / 220.2834 s
agent0:                 episode reward: -0.0364,                 loss: nan
agent1:                 episode reward: 0.0364,                 loss: 0.4048
Episode: 4761/30000 (15.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1863s / 221.4698 s
agent0:                 episode reward: -0.0124,                 loss: nan
agent1:                 episode reward: 0.0124,                 loss: 0.4059
Episode: 4781/30000 (15.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1831s / 222.6529 s
agent0:                 episode reward: -0.3658,                 loss: nan
agent1:                 episode reward: 0.3658,                 loss: 0.4034
Episode: 4801/30000 (16.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1839s / 223.8368 s
agent0:                 episode reward: -0.4441,                 loss: nan
agent1:                 episode reward: 0.4441,                 loss: 0.4051
Episode: 4821/30000 (16.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1854s / 225.0221 s
agent0:                 episode reward: -0.2789,                 loss: nan
agent1:                 episode reward: 0.2789,                 loss: 0.4031
Episode: 4841/30000 (16.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1973s / 226.2195 s
agent0:                 episode reward: -0.8183,                 loss: nan
agent1:                 episode reward: 0.8183,                 loss: 0.4095
Episode: 4861/30000 (16.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2050s / 227.4245 s
agent0:                 episode reward: -0.6670,                 loss: nan
agent1:                 episode reward: 0.6670,                 loss: 0.4158
Episode: 4881/30000 (16.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1863s / 228.6108 s
agent0:                 episode reward: 0.2537,                 loss: nan
agent1:                 episode reward: -0.2537,                 loss: 0.4152
Episode: 4901/30000 (16.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1924s / 229.8032 s
agent0:                 episode reward: -0.2924,                 loss: nan
agent1:                 episode reward: 0.2924,                 loss: 0.4153
Episode: 4921/30000 (16.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1844s / 230.9876 s
agent0:                 episode reward: -0.7156,                 loss: nan
agent1:                 episode reward: 0.7156,                 loss: 0.4142
Episode: 4941/30000 (16.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1872s / 232.1749 s
agent0:                 episode reward: -1.3180,                 loss: nan
agent1:                 episode reward: 1.3180,                 loss: 0.4150
Episode: 4961/30000 (16.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1956s / 233.3705 s
agent0:                 episode reward: -0.1422,                 loss: nan
agent1:                 episode reward: 0.1422,                 loss: 0.4147
Episode: 4981/30000 (16.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1943s / 234.5647 s
agent0:                 episode reward: -0.5254,                 loss: nan
agent1:                 episode reward: 0.5254,                 loss: 0.4145
Episode: 5001/30000 (16.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1865s / 235.7512 s
agent0:                 episode reward: 0.1894,                 loss: nan
agent1:                 episode reward: -0.1894,                 loss: 0.4169
Episode: 5021/30000 (16.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2089s / 236.9601 s
agent0:                 episode reward: -0.5404,                 loss: nan
agent1:                 episode reward: 0.5404,                 loss: 0.4279
Episode: 5041/30000 (16.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1892s / 238.1493 s
agent0:                 episode reward: 0.6027,                 loss: nan
agent1:                 episode reward: -0.6027,                 loss: 0.4265
Episode: 5061/30000 (16.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1895s / 239.3388 s
agent0:                 episode reward: -0.7106,                 loss: nan
agent1:                 episode reward: 0.7106,                 loss: 0.4256
Episode: 5081/30000 (16.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2031s / 240.5418 s
agent0:                 episode reward: -0.7772,                 loss: nan
agent1:                 episode reward: 0.7772,                 loss: 0.4249
Episode: 5101/30000 (17.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1919s / 241.7337 s
agent0:                 episode reward: -0.7074,                 loss: nan
agent1:                 episode reward: 0.7074,                 loss: 0.4255
Episode: 5121/30000 (17.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1986s / 242.9323 s
agent0:                 episode reward: -0.4346,                 loss: nan
agent1:                 episode reward: 0.4346,                 loss: 0.4246
Episode: 5141/30000 (17.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1849s / 244.1171 s
agent0:                 episode reward: -0.0936,                 loss: nan
agent1:                 episode reward: 0.0936,                 loss: 0.4239
Episode: 5161/30000 (17.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2042s / 245.3213 s
agent0:                 episode reward: -0.5409,                 loss: nan
agent1:                 episode reward: 0.5409,                 loss: 0.4226
Episode: 5181/30000 (17.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1927s / 246.5140 s
agent0:                 episode reward: -0.2358,                 loss: nan
agent1:                 episode reward: 0.2358,                 loss: 0.4044
Episode: 5201/30000 (17.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1970s / 247.7110 s
agent0:                 episode reward: -0.6836,                 loss: nan
agent1:                 episode reward: 0.6836,                 loss: 0.3903
Episode: 5221/30000 (17.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2032s / 248.9142 s
agent0:                 episode reward: -0.2388,                 loss: nan
agent1:                 episode reward: 0.2388,                 loss: 0.3888
Episode: 5241/30000 (17.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2015s / 250.1157 s
agent0:                 episode reward: -0.2488,                 loss: nan
agent1:                 episode reward: 0.2488,                 loss: 0.3901
Episode: 5261/30000 (17.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1968s / 251.3125 s
agent0:                 episode reward: -0.7058,                 loss: nan
agent1:                 episode reward: 0.7058,                 loss: 0.3894
Episode: 5281/30000 (17.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1983s / 252.5108 s
agent0:                 episode reward: 0.0325,                 loss: nan
agent1:                 episode reward: -0.0325,                 loss: 0.3872
Episode: 5301/30000 (17.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1982s / 253.7090 s
agent0:                 episode reward: -0.5091,                 loss: nan
agent1:                 episode reward: 0.5091,                 loss: 0.3890
Episode: 5321/30000 (17.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1957s / 254.9047 s
agent0:                 episode reward: -0.2894,                 loss: nan
agent1:                 episode reward: 0.2894,                 loss: 0.3893
Episode: 5341/30000 (17.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1949s / 256.0997 s
agent0:                 episode reward: -1.2520,                 loss: nan
agent1:                 episode reward: 1.2520,                 loss: 0.4003
Episode: 5361/30000 (17.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1996s / 257.2993 s
agent0:                 episode reward: -0.9426,                 loss: nan
agent1:                 episode reward: 0.9426,                 loss: 0.4125
Episode: 5381/30000 (17.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2053s / 258.5046 s
agent0:                 episode reward: -0.1801,                 loss: nan
agent1:                 episode reward: 0.1801,                 loss: 0.4124
Episode: 5401/30000 (18.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1983s / 259.7029 s
agent0:                 episode reward: -0.4619,                 loss: nan
agent1:                 episode reward: 0.4619,                 loss: 0.4127
Episode: 5421/30000 (18.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1980s / 260.9010 s
agent0:                 episode reward: -0.3537,                 loss: nan
agent1:                 episode reward: 0.3537,                 loss: 0.4122
Episode: 5441/30000 (18.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2035s / 262.1045 s
agent0:                 episode reward: -0.5508,                 loss: nan
agent1:                 episode reward: 0.5508,                 loss: 0.4122
Episode: 5461/30000 (18.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2057s / 263.3102 s
agent0:                 episode reward: 0.5840,                 loss: nan
agent1:                 episode reward: -0.5840,                 loss: 0.4144
Episode: 5481/30000 (18.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2077s / 264.5179 s
agent0:                 episode reward: -0.4574,                 loss: nan
agent1:                 episode reward: 0.4574,                 loss: 0.4117
Episode: 5501/30000 (18.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2056s / 265.7234 s
agent0:                 episode reward: -0.3839,                 loss: nan
agent1:                 episode reward: 0.3839,                 loss: 0.4131
Episode: 5521/30000 (18.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2018s / 266.9253 s
agent0:                 episode reward: -0.5898,                 loss: nan
agent1:                 episode reward: 0.5898,                 loss: 0.4106
Episode: 5541/30000 (18.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1973s / 268.1225 s
agent0:                 episode reward: -0.7646,                 loss: nan
agent1:                 episode reward: 0.7646,                 loss: 0.4069
Episode: 5561/30000 (18.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1974s / 269.3200 s
agent0:                 episode reward: -0.6873,                 loss: nan
agent1:                 episode reward: 0.6873,                 loss: 0.4082
Episode: 5581/30000 (18.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1890s / 270.5090 s
agent0:                 episode reward: -0.7425,                 loss: nan
agent1:                 episode reward: 0.7425,                 loss: 0.4069
Episode: 5601/30000 (18.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2131s / 271.7220 s
agent0:                 episode reward: -0.2708,                 loss: nan
agent1:                 episode reward: 0.2708,                 loss: 0.4056
Episode: 5621/30000 (18.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2077s / 272.9297 s
agent0:                 episode reward: -0.5729,                 loss: nan
agent1:                 episode reward: 0.5729,                 loss: 0.4052
Episode: 5641/30000 (18.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2074s / 274.1371 s
agent0:                 episode reward: 0.1270,                 loss: nan
agent1:                 episode reward: -0.1270,                 loss: 0.4068
Episode: 5661/30000 (18.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2067s / 275.3438 s
agent0:                 episode reward: -0.3222,                 loss: nan
agent1:                 episode reward: 0.3222,                 loss: 0.4088
Episode: 5681/30000 (18.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2038s / 276.5476 s
agent0:                 episode reward: -0.6908,                 loss: nan
agent1:                 episode reward: 0.6908,                 loss: 0.3914
Episode: 5701/30000 (19.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2171s / 277.7647 s
agent0:                 episode reward: -0.3063,                 loss: nan
agent1:                 episode reward: 0.3063,                 loss: 0.3800
Episode: 5721/30000 (19.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2050s / 278.9697 s
agent0:                 episode reward: -0.5617,                 loss: nan
agent1:                 episode reward: 0.5617,                 loss: 0.3789
Episode: 5741/30000 (19.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2194s / 280.1891 s
agent0:                 episode reward: -0.0867,                 loss: nan
agent1:                 episode reward: 0.0867,                 loss: 0.3800
Episode: 5761/30000 (19.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2016s / 281.3907 s
agent0:                 episode reward: -0.4905,                 loss: nan
agent1:                 episode reward: 0.4905,                 loss: 0.3790
Episode: 5781/30000 (19.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2198s / 282.6105 s
agent0:                 episode reward: -0.3417,                 loss: nan
agent1:                 episode reward: 0.3417,                 loss: 0.3786
Episode: 5801/30000 (19.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2071s / 283.8177 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.3779
Episode: 5821/30000 (19.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2015s / 285.0192 s
agent0:                 episode reward: -0.0890,                 loss: nan
agent1:                 episode reward: 0.0890,                 loss: 0.3768
Episode: 5841/30000 (19.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2259s / 286.2452 s
agent0:                 episode reward: -0.2594,                 loss: nan
agent1:                 episode reward: 0.2594,                 loss: 0.3841
Episode: 5861/30000 (19.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2238s / 287.4690 s
agent0:                 episode reward: -0.0745,                 loss: nan
agent1:                 episode reward: 0.0745,                 loss: 0.3893
Episode: 5881/30000 (19.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2119s / 288.6809 s
agent0:                 episode reward: -0.1641,                 loss: nan
agent1:                 episode reward: 0.1641,                 loss: 0.3868
Episode: 5901/30000 (19.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2288s / 289.9097 s
agent0:                 episode reward: 0.1530,                 loss: nan
agent1:                 episode reward: -0.1530,                 loss: 0.3882
Episode: 5921/30000 (19.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2122s / 291.1220 s
agent0:                 episode reward: -0.1046,                 loss: nan
agent1:                 episode reward: 0.1046,                 loss: 0.3875
Episode: 5941/30000 (19.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2139s / 292.3359 s
agent0:                 episode reward: -0.1590,                 loss: nan
agent1:                 episode reward: 0.1590,                 loss: 0.3874
Episode: 5961/30000 (19.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2097s / 293.5456 s
agent0:                 episode reward: -1.0774,                 loss: nan
agent1:                 episode reward: 1.0774,                 loss: 0.3879
Episode: 5981/30000 (19.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2257s / 294.7713 s
agent0:                 episode reward: -0.3032,                 loss: nan
agent1:                 episode reward: 0.3032,                 loss: 0.3856
Episode: 6001/30000 (20.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2224s / 295.9937 s
agent0:                 episode reward: -0.4158,                 loss: nan
agent1:                 episode reward: 0.4158,                 loss: 0.3903
Episode: 6021/30000 (20.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2158s / 297.2095 s
agent0:                 episode reward: 0.4039,                 loss: nan
agent1:                 episode reward: -0.4039,                 loss: 0.4035
Episode: 6041/30000 (20.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2417s / 298.4512 s
agent0:                 episode reward: -0.4803,                 loss: nan
agent1:                 episode reward: 0.4803,                 loss: 0.3993
Episode: 6061/30000 (20.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2255s / 299.6767 s
agent0:                 episode reward: -0.3405,                 loss: nan
agent1:                 episode reward: 0.3405,                 loss: 0.3965
Episode: 6081/30000 (20.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2211s / 300.8977 s
agent0:                 episode reward: -0.5455,                 loss: nan
agent1:                 episode reward: 0.5455,                 loss: 0.3953
Episode: 6101/30000 (20.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2139s / 302.1117 s
agent0:                 episode reward: 0.2649,                 loss: nan
agent1:                 episode reward: -0.2649,                 loss: 0.3986
Episode: 6121/30000 (20.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2093s / 303.3209 s
agent0:                 episode reward: -0.0857,                 loss: nan
agent1:                 episode reward: 0.0857,                 loss: 0.3968
Episode: 6141/30000 (20.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2266s / 304.5476 s
agent0:                 episode reward: -0.9949,                 loss: nan
agent1:                 episode reward: 0.9949,                 loss: 0.3964
Episode: 6161/30000 (20.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2161s / 305.7636 s
agent0:                 episode reward: 0.3692,                 loss: nan
agent1:                 episode reward: -0.3692,                 loss: 0.3939
Episode: 6181/30000 (20.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2249s / 306.9885 s
agent0:                 episode reward: -0.3159,                 loss: nan
agent1:                 episode reward: 0.3159,                 loss: 0.3670
Episode: 6201/30000 (20.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2166s / 308.2051 s
agent0:                 episode reward: -0.5588,                 loss: nan
agent1:                 episode reward: 0.5588,                 loss: 0.3417
Episode: 6221/30000 (20.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2112s / 309.4163 s
agent0:                 episode reward: -0.0871,                 loss: nan
agent1:                 episode reward: 0.0871,                 loss: 0.3433
Episode: 6241/30000 (20.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2314s / 310.6477 s
agent0:                 episode reward: -0.2416,                 loss: nan
agent1:                 episode reward: 0.2416,                 loss: 0.3413
Episode: 6261/30000 (20.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2309s / 311.8786 s
agent0:                 episode reward: 0.0301,                 loss: nan
agent1:                 episode reward: -0.0301,                 loss: 0.3426
Episode: 6281/30000 (20.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3297s / 313.2082 s
agent0:                 episode reward: 0.0789,                 loss: nan
agent1:                 episode reward: -0.0789,                 loss: 0.3402
Episode: 6301/30000 (21.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3660s / 314.5742 s
agent0:                 episode reward: -0.4574,                 loss: nan
agent1:                 episode reward: 0.4574,                 loss: 0.3413
Episode: 6321/30000 (21.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2354s / 315.8096 s
agent0:                 episode reward: -0.1755,                 loss: nan
agent1:                 episode reward: 0.1755,                 loss: 0.3417
Episode: 6341/30000 (21.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2099s / 317.0195 s
agent0:                 episode reward: -0.1195,                 loss: nan
agent1:                 episode reward: 0.1195,                 loss: 0.3522
Episode: 6361/30000 (21.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2276s / 318.2471 s
agent0:                 episode reward: 0.1963,                 loss: nan
agent1:                 episode reward: -0.1963,                 loss: 0.3689
Episode: 6381/30000 (21.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2276s / 319.4748 s
agent0:                 episode reward: -0.2013,                 loss: nan
agent1:                 episode reward: 0.2013,                 loss: 0.3682
Episode: 6401/30000 (21.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2218s / 320.6965 s
agent0:                 episode reward: -0.3639,                 loss: nan
agent1:                 episode reward: 0.3639,                 loss: 0.3662
Episode: 6421/30000 (21.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2274s / 321.9240 s
agent0:                 episode reward: -0.5251,                 loss: nan
agent1:                 episode reward: 0.5251,                 loss: 0.3659
Episode: 6441/30000 (21.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2347s / 323.1586 s
agent0:                 episode reward: -0.2908,                 loss: nan
agent1:                 episode reward: 0.2908,                 loss: 0.3666
Episode: 6461/30000 (21.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2167s / 324.3753 s
agent0:                 episode reward: -0.1809,                 loss: nan
agent1:                 episode reward: 0.1809,                 loss: 0.3675
Episode: 6481/30000 (21.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2184s / 325.5937 s
agent0:                 episode reward: -0.3081,                 loss: nan
agent1:                 episode reward: 0.3081,                 loss: 0.3673
Episode: 6501/30000 (21.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3655s / 326.9592 s
agent0:                 episode reward: -0.2189,                 loss: nan
agent1:                 episode reward: 0.2189,                 loss: 0.3701
Episode: 6521/30000 (21.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2696s / 328.2289 s
agent0:                 episode reward: -0.3127,                 loss: nan
agent1:                 episode reward: 0.3127,                 loss: 0.3924
Episode: 6541/30000 (21.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2852s / 329.5141 s
agent0:                 episode reward: -0.0585,                 loss: nan
agent1:                 episode reward: 0.0585,                 loss: 0.3883
Episode: 6561/30000 (21.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2291s / 330.7432 s
agent0:                 episode reward: -0.6615,                 loss: nan
agent1:                 episode reward: 0.6615,                 loss: 0.3883
Episode: 6581/30000 (21.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2375s / 331.9807 s
agent0:                 episode reward: -0.2841,                 loss: nan
agent1:                 episode reward: 0.2841,                 loss: 0.3866
Episode: 6601/30000 (22.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2282s / 333.2089 s
agent0:                 episode reward: -0.5369,                 loss: nan
agent1:                 episode reward: 0.5369,                 loss: 0.3874
Episode: 6621/30000 (22.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2342s / 334.4431 s
agent0:                 episode reward: -0.0240,                 loss: nan
agent1:                 episode reward: 0.0240,                 loss: 0.3870
Episode: 6641/30000 (22.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2368s / 335.6799 s
agent0:                 episode reward: -0.1759,                 loss: nan
agent1:                 episode reward: 0.1759,                 loss: 0.3856
Episode: 6661/30000 (22.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2374s / 336.9173 s
agent0:                 episode reward: -0.6774,                 loss: nan
agent1:                 episode reward: 0.6774,                 loss: 0.3851
Episode: 6681/30000 (22.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2281s / 338.1454 s
agent0:                 episode reward: -0.5272,                 loss: nan
agent1:                 episode reward: 0.5272,                 loss: 0.3750
Episode: 6701/30000 (22.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2432s / 339.3886 s
agent0:                 episode reward: -0.2739,                 loss: nan
agent1:                 episode reward: 0.2739,                 loss: 0.3634
Episode: 6721/30000 (22.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2387s / 340.6274 s
agent0:                 episode reward: -0.1443,                 loss: nan
agent1:                 episode reward: 0.1443,                 loss: 0.3634
Episode: 6741/30000 (22.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2347s / 341.8621 s
agent0:                 episode reward: -0.2245,                 loss: nan
agent1:                 episode reward: 0.2245,                 loss: 0.3625
Episode: 6761/30000 (22.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2468s / 343.1089 s
agent0:                 episode reward: -0.6672,                 loss: nan
agent1:                 episode reward: 0.6672,                 loss: 0.3599
Episode: 6781/30000 (22.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2413s / 344.3502 s
agent0:                 episode reward: -0.2414,                 loss: nan
agent1:                 episode reward: 0.2414,                 loss: 0.3618
Episode: 6801/30000 (22.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2383s / 345.5885 s
agent0:                 episode reward: -0.2037,                 loss: nan
agent1:                 episode reward: 0.2037,                 loss: 0.3616
Episode: 6821/30000 (22.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2463s / 346.8348 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.3592
Episode: 6841/30000 (22.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2473s / 348.0822 s
agent0:                 episode reward: -0.1713,                 loss: nan
agent1:                 episode reward: 0.1713,                 loss: 0.3702
Episode: 6861/30000 (22.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2531s / 349.3352 s
agent0:                 episode reward: -0.3050,                 loss: nan
agent1:                 episode reward: 0.3050,                 loss: 0.3839
Episode: 6881/30000 (22.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2481s / 350.5833 s
agent0:                 episode reward: -0.9710,                 loss: nan
agent1:                 episode reward: 0.9710,                 loss: 0.3854
Episode: 6901/30000 (23.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2619s / 351.8452 s
agent0:                 episode reward: -0.4284,                 loss: nan
agent1:                 episode reward: 0.4284,                 loss: 0.3824
Episode: 6921/30000 (23.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2521s / 353.0974 s
agent0:                 episode reward: 0.0222,                 loss: nan
agent1:                 episode reward: -0.0222,                 loss: 0.3813
Episode: 6941/30000 (23.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2470s / 354.3444 s
agent0:                 episode reward: -0.6496,                 loss: nan
agent1:                 episode reward: 0.6496,                 loss: 0.3849
Episode: 6961/30000 (23.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2491s / 355.5934 s
agent0:                 episode reward: -0.8616,                 loss: nan
agent1:                 episode reward: 0.8616,                 loss: 0.3836
Episode: 6981/30000 (23.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2471s / 356.8405 s
agent0:                 episode reward: -0.8010,                 loss: nan
agent1:                 episode reward: 0.8010,                 loss: 0.3833
Episode: 7001/30000 (23.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2502s / 358.0907 s
agent0:                 episode reward: -0.4594,                 loss: nan
agent1:                 episode reward: 0.4594,                 loss: 0.3838
Episode: 7021/30000 (23.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2537s / 359.3444 s
agent0:                 episode reward: 0.2719,                 loss: nan
agent1:                 episode reward: -0.2719,                 loss: 0.4136
Episode: 7041/30000 (23.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2557s / 360.6001 s
agent0:                 episode reward: -0.4610,                 loss: nan
agent1:                 episode reward: 0.4610,                 loss: 0.4119
Episode: 7061/30000 (23.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2579s / 361.8580 s
agent0:                 episode reward: -0.8927,                 loss: nan
agent1:                 episode reward: 0.8927,                 loss: 0.4137
Episode: 7081/30000 (23.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2606s / 363.1186 s
agent0:                 episode reward: -0.6015,                 loss: nan
agent1:                 episode reward: 0.6015,                 loss: 0.4100
Episode: 7101/30000 (23.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2590s / 364.3776 s
agent0:                 episode reward: -0.6317,                 loss: nan
agent1:                 episode reward: 0.6317,                 loss: 0.4130
Episode: 7121/30000 (23.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2575s / 365.6351 s
agent0:                 episode reward: -0.7962,                 loss: nan
agent1:                 episode reward: 0.7962,                 loss: 0.4120
Episode: 7141/30000 (23.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2550s / 366.8902 s
agent0:                 episode reward: -0.4904,                 loss: nan
agent1:                 episode reward: 0.4904,                 loss: 0.4113
Episode: 7161/30000 (23.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2592s / 368.1494 s
agent0:                 episode reward: -0.4151,                 loss: nan
agent1:                 episode reward: 0.4151,                 loss: 0.4113
Episode: 7181/30000 (23.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2530s / 369.4023 s
agent0:                 episode reward: -0.0014,                 loss: nan
agent1:                 episode reward: 0.0014,                 loss: 0.4005
Episode: 7201/30000 (24.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2604s / 370.6628 s
agent0:                 episode reward: -0.2424,                 loss: nan
agent1:                 episode reward: 0.2424,                 loss: 0.3911
Episode: 7221/30000 (24.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2988s / 371.9616 s
agent0:                 episode reward: -0.9755,                 loss: nan
agent1:                 episode reward: 0.9755,                 loss: 0.3887
Episode: 7241/30000 (24.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2494s / 373.2110 s
agent0:                 episode reward: -0.1235,                 loss: nan
agent1:                 episode reward: 0.1235,                 loss: 0.3894
Episode: 7261/30000 (24.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2531s / 374.4641 s
agent0:                 episode reward: 0.5951,                 loss: nan
agent1:                 episode reward: -0.5951,                 loss: 0.3885
Episode: 7281/30000 (24.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2537s / 375.7179 s
agent0:                 episode reward: -0.0131,                 loss: nan
agent1:                 episode reward: 0.0131,                 loss: 0.3900
Episode: 7301/30000 (24.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2575s / 376.9754 s
agent0:                 episode reward: -0.3990,                 loss: nan
agent1:                 episode reward: 0.3990,                 loss: 0.3874
Episode: 7321/30000 (24.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2440s / 378.2194 s
agent0:                 episode reward: -0.9061,                 loss: nan
agent1:                 episode reward: 0.9061,                 loss: 0.3877
Episode: 7341/30000 (24.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2535s / 379.4729 s
agent0:                 episode reward: -0.9321,                 loss: nan
agent1:                 episode reward: 0.9321,                 loss: 0.3814
Episode: 7361/30000 (24.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2663s / 380.7392 s
agent0:                 episode reward: -0.0080,                 loss: nan
agent1:                 episode reward: 0.0080,                 loss: 0.3691
Episode: 7381/30000 (24.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2609s / 382.0001 s
agent0:                 episode reward: -0.2903,                 loss: nan
agent1:                 episode reward: 0.2903,                 loss: 0.3667
Episode: 7401/30000 (24.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2597s / 383.2598 s
agent0:                 episode reward: -0.4964,                 loss: nan
agent1:                 episode reward: 0.4964,                 loss: 0.3685
Episode: 7421/30000 (24.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2666s / 384.5264 s
agent0:                 episode reward: -0.3457,                 loss: nan
agent1:                 episode reward: 0.3457,                 loss: 0.3668
Episode: 7441/30000 (24.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2593s / 385.7857 s
agent0:                 episode reward: -0.3347,                 loss: nan
agent1:                 episode reward: 0.3347,                 loss: 0.3672
Episode: 7461/30000 (24.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2666s / 387.0523 s
agent0:                 episode reward: -0.4881,                 loss: nan
agent1:                 episode reward: 0.4881,                 loss: 0.3661
Episode: 7481/30000 (24.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2672s / 388.3195 s
agent0:                 episode reward: -0.8653,                 loss: nan
agent1:                 episode reward: 0.8653,                 loss: 0.3658
Episode: 7501/30000 (25.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2664s / 389.5859 s
agent0:                 episode reward: -0.3197,                 loss: nan
agent1:                 episode reward: 0.3197,                 loss: 0.3710
Episode: 7521/30000 (25.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2735s / 390.8594 s
agent0:                 episode reward: -0.4581,                 loss: nan
agent1:                 episode reward: 0.4581,                 loss: 0.3996
Episode: 7541/30000 (25.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2738s / 392.1331 s
agent0:                 episode reward: -0.5675,                 loss: nan
agent1:                 episode reward: 0.5675,                 loss: 0.3964
Episode: 7561/30000 (25.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2716s / 393.4047 s
agent0:                 episode reward: -0.1536,                 loss: nan
agent1:                 episode reward: 0.1536,                 loss: 0.3971
Episode: 7581/30000 (25.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2677s / 394.6725 s
agent0:                 episode reward: -0.2033,                 loss: nan
agent1:                 episode reward: 0.2033,                 loss: 0.3958
Episode: 7601/30000 (25.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2599s / 395.9323 s
agent0:                 episode reward: -0.1479,                 loss: nan
agent1:                 episode reward: 0.1479,                 loss: 0.3974
Episode: 7621/30000 (25.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2635s / 397.1958 s
agent0:                 episode reward: -0.7713,                 loss: nan
agent1:                 episode reward: 0.7713,                 loss: 0.3951
Episode: 7641/30000 (25.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2681s / 398.4640 s
agent0:                 episode reward: -0.2419,                 loss: nan
agent1:                 episode reward: 0.2419,                 loss: 0.3952
Episode: 7661/30000 (25.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2730s / 399.7369 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.3960
Episode: 7681/30000 (25.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2979s / 401.0348 s
agent0:                 episode reward: -0.5624,                 loss: nan
agent1:                 episode reward: 0.5624,                 loss: 0.4048
Episode: 7701/30000 (25.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2753s / 402.3102 s
agent0:                 episode reward: -0.7273,                 loss: nan
agent1:                 episode reward: 0.7273,                 loss: 0.4028
Episode: 7721/30000 (25.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2749s / 403.5851 s
agent0:                 episode reward: -0.4941,                 loss: nan
agent1:                 episode reward: 0.4941,                 loss: 0.4017
Episode: 7741/30000 (25.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2775s / 404.8627 s
agent0:                 episode reward: -0.3642,                 loss: nan
agent1:                 episode reward: 0.3642,                 loss: 0.3990
Episode: 7761/30000 (25.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2833s / 406.1459 s
agent0:                 episode reward: 0.2157,                 loss: nan
agent1:                 episode reward: -0.2157,                 loss: 0.4005
Episode: 7781/30000 (25.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2764s / 407.4223 s
agent0:                 episode reward: -0.6399,                 loss: nan
agent1:                 episode reward: 0.6399,                 loss: 0.4023
Episode: 7801/30000 (26.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2838s / 408.7061 s
agent0:                 episode reward: -0.6625,                 loss: nan
agent1:                 episode reward: 0.6625,                 loss: 0.4000
Episode: 7821/30000 (26.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2924s / 409.9985 s
agent0:                 episode reward: -0.2272,                 loss: nan
agent1:                 episode reward: 0.2272,                 loss: 0.4012
Episode: 7841/30000 (26.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3108s / 411.3093 s
agent0:                 episode reward: -0.4802,                 loss: nan
agent1:                 episode reward: 0.4802,                 loss: 0.4062
Episode: 7861/30000 (26.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3632s / 412.6725 s
agent0:                 episode reward: -0.7061,                 loss: nan
agent1:                 episode reward: 0.7061,                 loss: 0.4090
Episode: 7881/30000 (26.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3203s / 413.9927 s
agent0:                 episode reward: -0.6326,                 loss: nan
agent1:                 episode reward: 0.6326,                 loss: 0.4104
Episode: 7901/30000 (26.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3201s / 415.3129 s
agent0:                 episode reward: -0.2904,                 loss: nan
agent1:                 episode reward: 0.2904,                 loss: 0.4079
Episode: 7921/30000 (26.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3312s / 416.6440 s
agent0:                 episode reward: -0.9928,                 loss: nan
agent1:                 episode reward: 0.9928,                 loss: 0.4089
Episode: 7941/30000 (26.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3213s / 417.9653 s
agent0:                 episode reward: -0.1413,                 loss: nan
agent1:                 episode reward: 0.1413,                 loss: 0.4087
Episode: 7961/30000 (26.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3166s / 419.2820 s
agent0:                 episode reward: -0.3954,                 loss: nan
agent1:                 episode reward: 0.3954,                 loss: 0.4076
Episode: 7981/30000 (26.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3084s / 420.5904 s
agent0:                 episode reward: -0.4886,                 loss: nan
agent1:                 episode reward: 0.4886,                 loss: 0.4093
Episode: 8001/30000 (26.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.4822s / 422.0726 s
agent0:                 episode reward: -0.8773,                 loss: nan
agent1:                 episode reward: 0.8773,                 loss: 0.4073
Episode: 8021/30000 (26.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3429s / 423.4155 s
agent0:                 episode reward: -0.4678,                 loss: nan
agent1:                 episode reward: 0.4678,                 loss: 0.4294
Episode: 8041/30000 (26.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3062s / 424.7217 s
agent0:                 episode reward: 0.2979,                 loss: nan
agent1:                 episode reward: -0.2979,                 loss: 0.4252
Episode: 8061/30000 (26.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3047s / 426.0264 s
agent0:                 episode reward: -0.2870,                 loss: nan
agent1:                 episode reward: 0.2870,                 loss: 0.4267
Episode: 8081/30000 (26.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2799s / 427.3063 s
agent0:                 episode reward: -0.7965,                 loss: nan
agent1:                 episode reward: 0.7965,                 loss: 0.4263
Episode: 8101/30000 (27.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2880s / 428.5943 s
agent0:                 episode reward: 0.2487,                 loss: nan
agent1:                 episode reward: -0.2487,                 loss: 0.4269
Episode: 8121/30000 (27.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2875s / 429.8817 s
agent0:                 episode reward: -0.7079,                 loss: nan
agent1:                 episode reward: 0.7079,                 loss: 0.4261
Episode: 8141/30000 (27.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2888s / 431.1705 s
agent0:                 episode reward: -0.2468,                 loss: nan
agent1:                 episode reward: 0.2468,                 loss: 0.4241
Episode: 8161/30000 (27.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2931s / 432.4636 s
agent0:                 episode reward: -0.2235,                 loss: nan
agent1:                 episode reward: 0.2235,                 loss: 0.4269
Episode: 8181/30000 (27.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3002s / 433.7637 s
agent0:                 episode reward: -0.1983,                 loss: nan
agent1:                 episode reward: 0.1983,                 loss: 0.4180
Episode: 8201/30000 (27.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3004s / 435.0641 s
agent0:                 episode reward: 0.1909,                 loss: nan
agent1:                 episode reward: -0.1909,                 loss: 0.4121
Episode: 8221/30000 (27.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2944s / 436.3586 s
agent0:                 episode reward: 0.2095,                 loss: nan
agent1:                 episode reward: -0.2095,                 loss: 0.4113
Episode: 8241/30000 (27.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2965s / 437.6551 s
agent0:                 episode reward: -0.4697,                 loss: nan
agent1:                 episode reward: 0.4697,                 loss: 0.4101
Episode: 8261/30000 (27.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2963s / 438.9514 s
agent0:                 episode reward: -0.8648,                 loss: nan
agent1:                 episode reward: 0.8648,                 loss: 0.4112
Episode: 8281/30000 (27.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2902s / 440.2416 s
agent0:                 episode reward: -0.2999,                 loss: nan
agent1:                 episode reward: 0.2999,                 loss: 0.4108
Episode: 8301/30000 (27.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2982s / 441.5398 s
agent0:                 episode reward: -0.6730,                 loss: nan
agent1:                 episode reward: 0.6730,                 loss: 0.4102
Episode: 8321/30000 (27.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2980s / 442.8378 s
agent0:                 episode reward: -0.1414,                 loss: nan
agent1:                 episode reward: 0.1414,                 loss: 0.4102
Episode: 8341/30000 (27.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2944s / 444.1322 s
agent0:                 episode reward: -0.1974,                 loss: nan
agent1:                 episode reward: 0.1974,                 loss: 0.4069
Episode: 8361/30000 (27.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2956s / 445.4278 s
agent0:                 episode reward: -0.2110,                 loss: nan
agent1:                 episode reward: 0.2110,                 loss: 0.3966
Episode: 8381/30000 (27.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3888s / 446.8166 s
agent0:                 episode reward: -0.6015,                 loss: nan
agent1:                 episode reward: 0.6015,                 loss: 0.3964
Episode: 8401/30000 (28.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3719s / 448.1885 s
agent0:                 episode reward: -0.6009,                 loss: nan
agent1:                 episode reward: 0.6009,                 loss: 0.3955
Episode: 8421/30000 (28.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.2918s / 449.4803 s
agent0:                 episode reward: -0.0577,                 loss: nan
agent1:                 episode reward: 0.0577,                 loss: 0.3940
Episode: 8441/30000 (28.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3080s / 450.7883 s
agent0:                 episode reward: -0.9135,                 loss: nan
agent1:                 episode reward: 0.9135,                 loss: 0.3950
Episode: 8461/30000 (28.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3054s / 452.0937 s
agent0:                 episode reward: -0.4162,                 loss: nan
agent1:                 episode reward: 0.4162,                 loss: 0.3946
Episode: 8481/30000 (28.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3494s / 453.4431 s
agent0:                 episode reward: -0.8685,                 loss: nan
agent1:                 episode reward: 0.8685,                 loss: 0.3933
Episode: 8501/30000 (28.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3157s / 454.7588 s
agent0:                 episode reward: -0.0102,                 loss: nan
agent1:                 episode reward: 0.0102,                 loss: 0.3966
Episode: 8521/30000 (28.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3059s / 456.0647 s
agent0:                 episode reward: 0.0869,                 loss: nan
agent1:                 episode reward: -0.0869,                 loss: 0.4014
Episode: 8541/30000 (28.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3064s / 457.3711 s
agent0:                 episode reward: -0.1182,                 loss: nan
agent1:                 episode reward: 0.1182,                 loss: 0.3995
Episode: 8561/30000 (28.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3132s / 458.6843 s
agent0:                 episode reward: -0.4553,                 loss: nan
agent1:                 episode reward: 0.4553,                 loss: 0.4001
Episode: 8581/30000 (28.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3188s / 460.0031 s
agent0:                 episode reward: -0.1561,                 loss: nan
agent1:                 episode reward: 0.1561,                 loss: 0.3983
Episode: 8601/30000 (28.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3263s / 461.3294 s
agent0:                 episode reward: -0.6610,                 loss: nan
agent1:                 episode reward: 0.6610,                 loss: 0.3992
Episode: 8621/30000 (28.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3153s / 462.6447 s
agent0:                 episode reward: -0.6276,                 loss: nan
agent1:                 episode reward: 0.6276,                 loss: 0.4010
Episode: 8641/30000 (28.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3226s / 463.9673 s
agent0:                 episode reward: 0.1080,                 loss: nan
agent1:                 episode reward: -0.1080,                 loss: 0.3979
Episode: 8661/30000 (28.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3133s / 465.2806 s
agent0:                 episode reward: -1.2424,                 loss: nan
agent1:                 episode reward: 1.2424,                 loss: 0.3997
Episode: 8681/30000 (28.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3214s / 466.6019 s
agent0:                 episode reward: -1.0103,                 loss: nan
agent1:                 episode reward: 1.0103,                 loss: 0.4063
Episode: 8701/30000 (29.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3047s / 467.9066 s
agent0:                 episode reward: -0.4323,                 loss: nan
agent1:                 episode reward: 0.4323,                 loss: 0.3992
Episode: 8721/30000 (29.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.4011s / 469.3077 s
agent0:                 episode reward: -0.3245,                 loss: nan
agent1:                 episode reward: 0.3245,                 loss: 0.4022
Episode: 8741/30000 (29.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.4865s / 470.7941 s
agent0:                 episode reward: -0.5508,                 loss: nan
agent1:                 episode reward: 0.5508,                 loss: 0.4024
Episode: 8761/30000 (29.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3120s / 472.1061 s
agent0:                 episode reward: -0.3287,                 loss: nan
agent1:                 episode reward: 0.3287,                 loss: 0.4003
Episode: 8781/30000 (29.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3115s / 473.4176 s
agent0:                 episode reward: -0.5970,                 loss: nan
agent1:                 episode reward: 0.5970,                 loss: 0.4005
Episode: 8801/30000 (29.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3041s / 474.7217 s
agent0:                 episode reward: -1.0156,                 loss: nan
agent1:                 episode reward: 1.0156,                 loss: 0.4026
Episode: 8821/30000 (29.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3118s / 476.0335 s
agent0:                 episode reward: -0.2452,                 loss: nan
agent1:                 episode reward: 0.2452,                 loss: 0.4012
Episode: 8841/30000 (29.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3002s / 477.3337 s
agent0:                 episode reward: -0.1951,                 loss: nan
agent1:                 episode reward: 0.1951,                 loss: 0.3997
Episode: 8861/30000 (29.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3115s / 478.6452 s
agent0:                 episode reward: -0.5090,                 loss: nan
agent1:                 episode reward: 0.5090,                 loss: 0.3944
Episode: 8881/30000 (29.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3228s / 479.9680 s
agent0:                 episode reward: -0.7910,                 loss: nan
agent1:                 episode reward: 0.7910,                 loss: 0.3948
Episode: 8901/30000 (29.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3124s / 481.2804 s
agent0:                 episode reward: -0.8252,                 loss: nan
agent1:                 episode reward: 0.8252,                 loss: 0.3926
Episode: 8921/30000 (29.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3226s / 482.6030 s
agent0:                 episode reward: -0.3007,                 loss: nan
agent1:                 episode reward: 0.3007,                 loss: 0.3945
Episode: 8941/30000 (29.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3342s / 483.9372 s
agent0:                 episode reward: 0.0648,                 loss: nan
agent1:                 episode reward: -0.0648,                 loss: 0.3925
Episode: 8961/30000 (29.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3344s / 485.2716 s
agent0:                 episode reward: -0.2823,                 loss: nan
agent1:                 episode reward: 0.2823,                 loss: 0.3935
Episode: 8981/30000 (29.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3242s / 486.5958 s
agent0:                 episode reward: -0.2327,                 loss: nan
agent1:                 episode reward: 0.2327,                 loss: 0.3930
Episode: 9001/30000 (30.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3231s / 487.9189 s
agent0:                 episode reward: -0.8710,                 loss: nan
agent1:                 episode reward: 0.8710,                 loss: 0.3932
Episode: 9021/30000 (30.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3184s / 489.2373 s
agent0:                 episode reward: -0.1996,                 loss: nan
agent1:                 episode reward: 0.1996,                 loss: 0.4098
Episode: 9041/30000 (30.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3407s / 490.5780 s
agent0:                 episode reward: -0.3044,                 loss: nan
agent1:                 episode reward: 0.3044,                 loss: 0.4048
Episode: 9061/30000 (30.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3248s / 491.9027 s
agent0:                 episode reward: -0.2344,                 loss: nan
agent1:                 episode reward: 0.2344,                 loss: 0.4050
Episode: 9081/30000 (30.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3249s / 493.2276 s
agent0:                 episode reward: -0.4536,                 loss: nan
agent1:                 episode reward: 0.4536,                 loss: 0.4042
Episode: 9101/30000 (30.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3546s / 494.5823 s
agent0:                 episode reward: -0.7834,                 loss: nan
agent1:                 episode reward: 0.7834,                 loss: 0.4037
Episode: 9121/30000 (30.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3181s / 495.9004 s
agent0:                 episode reward: -0.5346,                 loss: nan
agent1:                 episode reward: 0.5346,                 loss: 0.4043
Episode: 9141/30000 (30.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3671s / 497.2674 s
agent0:                 episode reward: -0.1389,                 loss: nan
agent1:                 episode reward: 0.1389,                 loss: 0.4050
Episode: 9161/30000 (30.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3265s / 498.5939 s
agent0:                 episode reward: -0.4832,                 loss: nan
agent1:                 episode reward: 0.4832,                 loss: 0.4036
Episode: 9181/30000 (30.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3297s / 499.9236 s
agent0:                 episode reward: 0.1479,                 loss: nan
agent1:                 episode reward: -0.1479,                 loss: 0.3846
Episode: 9201/30000 (30.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3215s / 501.2451 s
agent0:                 episode reward: -0.0907,                 loss: nan
agent1:                 episode reward: 0.0907,                 loss: 0.3676
Episode: 9221/30000 (30.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3380s / 502.5832 s
agent0:                 episode reward: -0.4179,                 loss: nan
agent1:                 episode reward: 0.4179,                 loss: 0.3660
Episode: 9241/30000 (30.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3368s / 503.9200 s
agent0:                 episode reward: -0.1298,                 loss: nan
agent1:                 episode reward: 0.1298,                 loss: 0.3662
Episode: 9261/30000 (30.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.7104s / 505.6304 s
agent0:                 episode reward: -0.6449,                 loss: nan
agent1:                 episode reward: 0.6449,                 loss: 0.3670
Episode: 9281/30000 (30.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3937s / 507.0241 s
agent0:                 episode reward: -0.3875,                 loss: nan
agent1:                 episode reward: 0.3875,                 loss: 0.3648
Episode: 9301/30000 (31.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3273s / 508.3514 s
agent0:                 episode reward: -0.2040,                 loss: nan
agent1:                 episode reward: 0.2040,                 loss: 0.3658
Episode: 9321/30000 (31.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3296s / 509.6810 s
agent0:                 episode reward: -0.2909,                 loss: nan
agent1:                 episode reward: 0.2909,                 loss: 0.3645
Episode: 9341/30000 (31.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3560s / 511.0370 s
agent0:                 episode reward: -0.3535,                 loss: nan
agent1:                 episode reward: 0.3535,                 loss: 0.3517
Episode: 9361/30000 (31.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3223s / 512.3593 s
agent0:                 episode reward: -0.2585,                 loss: nan
agent1:                 episode reward: 0.2585,                 loss: 0.3122
Episode: 9381/30000 (31.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3470s / 513.7063 s
agent0:                 episode reward: -0.7720,                 loss: nan
agent1:                 episode reward: 0.7720,                 loss: 0.3116
Episode: 9401/30000 (31.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3466s / 515.0529 s
agent0:                 episode reward: -0.7814,                 loss: nan
agent1:                 episode reward: 0.7814,                 loss: 0.3115
Episode: 9421/30000 (31.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3420s / 516.3949 s
agent0:                 episode reward: -0.6980,                 loss: nan
agent1:                 episode reward: 0.6980,                 loss: 0.3114
Episode: 9441/30000 (31.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3332s / 517.7281 s
agent0:                 episode reward: -0.3161,                 loss: nan
agent1:                 episode reward: 0.3161,                 loss: 0.3109
Episode: 9461/30000 (31.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3561s / 519.0842 s
agent0:                 episode reward: -0.3234,                 loss: nan
agent1:                 episode reward: 0.3234,                 loss: 0.3127
Episode: 9481/30000 (31.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3589s / 520.4430 s
agent0:                 episode reward: -0.1188,                 loss: nan
agent1:                 episode reward: 0.1188,                 loss: 0.3090
Episode: 9501/30000 (31.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3517s / 521.7947 s
agent0:                 episode reward: -0.4130,                 loss: nan
agent1:                 episode reward: 0.4130,                 loss: 0.3168
Episode: 9521/30000 (31.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3583s / 523.1530 s
agent0:                 episode reward: -0.0621,                 loss: nan
agent1:                 episode reward: 0.0621,                 loss: 0.3921
Episode: 9541/30000 (31.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3499s / 524.5029 s
agent0:                 episode reward: -0.8159,                 loss: nan
agent1:                 episode reward: 0.8159,                 loss: 0.3890
Episode: 9561/30000 (31.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3451s / 525.8480 s
agent0:                 episode reward: -0.2911,                 loss: nan
agent1:                 episode reward: 0.2911,                 loss: 0.3883
Episode: 9581/30000 (31.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3570s / 527.2050 s
agent0:                 episode reward: -0.4071,                 loss: nan
agent1:                 episode reward: 0.4071,                 loss: 0.3893
Episode: 9601/30000 (32.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3452s / 528.5502 s
agent0:                 episode reward: -0.9531,                 loss: nan
agent1:                 episode reward: 0.9531,                 loss: 0.3888
Episode: 9621/30000 (32.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3484s / 529.8986 s
agent0:                 episode reward: -0.5160,                 loss: nan
agent1:                 episode reward: 0.5160,                 loss: 0.3902
Episode: 9641/30000 (32.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3457s / 531.2444 s
agent0:                 episode reward: -1.0037,                 loss: nan
agent1:                 episode reward: 1.0037,                 loss: 0.3873
Episode: 9661/30000 (32.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3502s / 532.5946 s
agent0:                 episode reward: -0.8267,                 loss: nan
agent1:                 episode reward: 0.8267,                 loss: 0.3884
Episode: 9681/30000 (32.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3501s / 533.9447 s
agent0:                 episode reward: -0.5714,                 loss: nan
agent1:                 episode reward: 0.5714,                 loss: 0.3903
Episode: 9701/30000 (32.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3605s / 535.3052 s
agent0:                 episode reward: -0.6756,                 loss: nan
agent1:                 episode reward: 0.6756,                 loss: 0.3799
Episode: 9721/30000 (32.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3421s / 536.6473 s
agent0:                 episode reward: 0.0425,                 loss: nan
agent1:                 episode reward: -0.0425,                 loss: 0.3798
Episode: 9741/30000 (32.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3442s / 537.9915 s
agent0:                 episode reward: -0.7430,                 loss: nan
agent1:                 episode reward: 0.7430,                 loss: 0.3785
Episode: 9761/30000 (32.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3571s / 539.3486 s
agent0:                 episode reward: -0.0379,                 loss: nan
agent1:                 episode reward: 0.0379,                 loss: 0.3795
Episode: 9781/30000 (32.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3451s / 540.6937 s
agent0:                 episode reward: -0.3530,                 loss: nan
agent1:                 episode reward: 0.3530,                 loss: 0.3771
Episode: 9801/30000 (32.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3555s / 542.0492 s
agent0:                 episode reward: -0.0287,                 loss: nan
agent1:                 episode reward: 0.0287,                 loss: 0.3785
Episode: 9821/30000 (32.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3487s / 543.3979 s
agent0:                 episode reward: -0.7354,                 loss: nan
agent1:                 episode reward: 0.7354,                 loss: 0.3799
Episode: 9841/30000 (32.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3570s / 544.7550 s
agent0:                 episode reward: -0.2329,                 loss: nan
agent1:                 episode reward: 0.2329,                 loss: 0.3816
Episode: 9861/30000 (32.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3587s / 546.1137 s
agent0:                 episode reward: -0.0121,                 loss: nan
agent1:                 episode reward: 0.0121,                 loss: 0.3804
Episode: 9881/30000 (32.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3543s / 547.4680 s
agent0:                 episode reward: 0.1621,                 loss: nan
agent1:                 episode reward: -0.1621,                 loss: 0.3794
Episode: 9901/30000 (33.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3657s / 548.8337 s
agent0:                 episode reward: -0.3288,                 loss: nan
agent1:                 episode reward: 0.3288,                 loss: 0.3786
Episode: 9921/30000 (33.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3799s / 550.2136 s
agent0:                 episode reward: -0.6573,                 loss: nan
agent1:                 episode reward: 0.6573,                 loss: 0.3794
Episode: 9941/30000 (33.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3831s / 551.5967 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.3786
Episode: 9961/30000 (33.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3515s / 552.9483 s
agent0:                 episode reward: -0.2863,                 loss: nan
agent1:                 episode reward: 0.2863,                 loss: 0.3805
Episode: 9981/30000 (33.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3589s / 554.3071 s
agent0:                 episode reward: -0.1880,                 loss: nan
agent1:                 episode reward: 0.1880,                 loss: 0.3784
Episode: 10001/30000 (33.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3678s / 555.6750 s
agent0:                 episode reward: -0.3527,                 loss: nan
agent1:                 episode reward: 0.3527,                 loss: 0.3826
Episode: 10021/30000 (33.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3610s / 557.0360 s
agent0:                 episode reward: -0.4136,                 loss: nan
agent1:                 episode reward: 0.4136,                 loss: 0.4017
Episode: 10041/30000 (33.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3681s / 558.4041 s
agent0:                 episode reward: -0.4584,                 loss: nan
agent1:                 episode reward: 0.4584,                 loss: 0.4004
Episode: 10061/30000 (33.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3800s / 559.7841 s
agent0:                 episode reward: -1.0534,                 loss: nan
agent1:                 episode reward: 1.0534,                 loss: 0.4002
Episode: 10081/30000 (33.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3717s / 561.1558 s
agent0:                 episode reward: -0.2652,                 loss: nan
agent1:                 episode reward: 0.2652,                 loss: 0.3975
Episode: 10101/30000 (33.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3734s / 562.5292 s
agent0:                 episode reward: -0.1080,                 loss: nan
agent1:                 episode reward: 0.1080,                 loss: 0.3985
Episode: 10121/30000 (33.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3728s / 563.9020 s
agent0:                 episode reward: -0.0629,                 loss: nan
agent1:                 episode reward: 0.0629,                 loss: 0.3973
Episode: 10141/30000 (33.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3663s / 565.2684 s
agent0:                 episode reward: -0.3155,                 loss: nan
agent1:                 episode reward: 0.3155,                 loss: 0.3974
Episode: 10161/30000 (33.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3727s / 566.6411 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.3970
Episode: 10181/30000 (33.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3783s / 568.0194 s
agent0:                 episode reward: -0.2466,                 loss: nan
agent1:                 episode reward: 0.2466,                 loss: 0.3697
Episode: 10201/30000 (34.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3845s / 569.4039 s
agent0:                 episode reward: -0.8454,                 loss: nan
agent1:                 episode reward: 0.8454,                 loss: 0.3497
Episode: 10221/30000 (34.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3748s / 570.7788 s
agent0:                 episode reward: -0.2541,                 loss: nan
agent1:                 episode reward: 0.2541,                 loss: 0.3477
Episode: 10241/30000 (34.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3884s / 572.1671 s
agent0:                 episode reward: -0.2952,                 loss: nan
agent1:                 episode reward: 0.2952,                 loss: 0.3459
Episode: 10261/30000 (34.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3835s / 573.5506 s
agent0:                 episode reward: -0.4665,                 loss: nan
agent1:                 episode reward: 0.4665,                 loss: 0.3464
Episode: 10281/30000 (34.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3847s / 574.9353 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.3453
Episode: 10301/30000 (34.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3843s / 576.3196 s
agent0:                 episode reward: -1.0464,                 loss: nan
agent1:                 episode reward: 1.0464,                 loss: 0.3455
Episode: 10321/30000 (34.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.3908s / 577.7104 s
agent0:                 episode reward: -0.5956,                 loss: nan
agent1:                 episode reward: 0.5956,                 loss: 0.3442