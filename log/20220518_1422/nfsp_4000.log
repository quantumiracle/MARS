pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fc3468013c8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/4000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/4000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_4000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_4000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7216s / 0.7216 s
agent0:                 episode reward: -0.8433,                 loss: nan
agent1:                 episode reward: 0.8433,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 0.9210 s
agent0:                 episode reward: -0.1617,                 loss: nan
agent1:                 episode reward: 0.1617,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 1.1220 s
agent0:                 episode reward: 0.1449,                 loss: nan
agent1:                 episode reward: -0.1449,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 1.3176 s
agent0:                 episode reward: 0.2106,                 loss: nan
agent1:                 episode reward: -0.2106,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 1.5151 s
agent0:                 episode reward: 0.0343,                 loss: nan
agent1:                 episode reward: -0.0343,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 1.7107 s
agent0:                 episode reward: -0.0694,                 loss: nan
agent1:                 episode reward: 0.0694,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 1.9075 s
agent0:                 episode reward: 0.0988,                 loss: nan
agent1:                 episode reward: -0.0988,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 2.1071 s
agent0:                 episode reward: 0.1087,                 loss: nan
agent1:                 episode reward: -0.1087,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 2.3066 s
agent0:                 episode reward: 0.5058,                 loss: nan
agent1:                 episode reward: -0.5058,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1949s / 2.5015 s
agent0:                 episode reward: -0.0516,                 loss: nan
agent1:                 episode reward: 0.0516,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 2.6996 s
agent0:                 episode reward: -0.0400,                 loss: nan
agent1:                 episode reward: 0.0400,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 2.8964 s
agent0:                 episode reward: 0.1837,                 loss: nan
agent1:                 episode reward: -0.1837,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 3.0940 s
agent0:                 episode reward: 0.0644,                 loss: nan
agent1:                 episode reward: -0.0644,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 3.2894 s
agent0:                 episode reward: -0.0375,                 loss: nan
agent1:                 episode reward: 0.0375,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 3.4888 s
agent0:                 episode reward: -0.2115,                 loss: nan
agent1:                 episode reward: 0.2115,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 3.6895 s
agent0:                 episode reward: -0.2680,                 loss: nan
agent1:                 episode reward: 0.2680,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 3.8902 s
agent0:                 episode reward: 0.2117,                 loss: nan
agent1:                 episode reward: -0.2117,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2046s / 4.0948 s
agent0:                 episode reward: 0.1396,                 loss: nan
agent1:                 episode reward: -0.1396,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1946s / 4.2894 s
agent0:                 episode reward: -0.3364,                 loss: nan
agent1:                 episode reward: 0.3364,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 4.4900 s
agent0:                 episode reward: 0.2208,                 loss: nan
agent1:                 episode reward: -0.2208,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 4.6867 s
agent0:                 episode reward: 0.1606,                 loss: nan
agent1:                 episode reward: -0.1606,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 4.8813 s
agent0:                 episode reward: -0.0256,                 loss: nan
agent1:                 episode reward: 0.0256,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 5.0828 s
agent0:                 episode reward: -0.0337,                 loss: nan
agent1:                 episode reward: 0.0337,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 5.2809 s
agent0:                 episode reward: -0.3116,                 loss: nan
agent1:                 episode reward: 0.3116,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 5.4822 s
agent0:                 episode reward: 0.2412,                 loss: nan
agent1:                 episode reward: -0.2412,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 5.6788 s
agent0:                 episode reward: -0.0916,                 loss: nan
agent1:                 episode reward: 0.0916,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 5.8805 s
agent0:                 episode reward: 0.1760,                 loss: nan
agent1:                 episode reward: -0.1760,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 6.0789 s
agent0:                 episode reward: 0.3082,                 loss: nan
agent1:                 episode reward: -0.3082,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 6.2767 s
agent0:                 episode reward: 0.2430,                 loss: nan
agent1:                 episode reward: -0.2430,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 6.4769 s
agent0:                 episode reward: 0.0494,                 loss: nan
agent1:                 episode reward: -0.0494,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 6.6780 s
agent0:                 episode reward: -0.2734,                 loss: nan
agent1:                 episode reward: 0.2734,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 6.8781 s
agent0:                 episode reward: -0.1483,                 loss: nan
agent1:                 episode reward: 0.1483,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 7.0736 s
agent0:                 episode reward: 0.4770,                 loss: nan
agent1:                 episode reward: -0.4770,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 7.2715 s
agent0:                 episode reward: 0.1286,                 loss: nan
agent1:                 episode reward: -0.1286,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 7.4716 s
agent0:                 episode reward: -0.3476,                 loss: nan
agent1:                 episode reward: 0.3476,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 7.6663 s
agent0:                 episode reward: -0.3590,                 loss: nan
agent1:                 episode reward: 0.3590,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 7.8675 s
agent0:                 episode reward: 0.1547,                 loss: nan
agent1:                 episode reward: -0.1547,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 8.0658 s
agent0:                 episode reward: 0.0411,                 loss: nan
agent1:                 episode reward: -0.0411,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 8.2620 s
agent0:                 episode reward: 0.0790,                 loss: nan
agent1:                 episode reward: -0.0790,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 8.4629 s
agent0:                 episode reward: 0.2271,                 loss: nan
agent1:                 episode reward: -0.2271,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1899s / 8.6528 s
agent0:                 episode reward: 0.0203,                 loss: nan
agent1:                 episode reward: -0.0203,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 8.8548 s
agent0:                 episode reward: -0.0009,                 loss: nan
agent1:                 episode reward: 0.0009,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 9.0556 s
agent0:                 episode reward: 0.2282,                 loss: nan
agent1:                 episode reward: -0.2282,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 9.2550 s
agent0:                 episode reward: 0.1350,                 loss: nan
agent1:                 episode reward: -0.1350,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 9.4559 s
agent0:                 episode reward: 0.0090,                 loss: nan
agent1:                 episode reward: -0.0090,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 9.6571 s
agent0:                 episode reward: 0.2126,                 loss: nan
agent1:                 episode reward: -0.2126,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 9.8549 s
agent0:                 episode reward: -0.3806,                 loss: nan
agent1:                 episode reward: 0.3806,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 10.0484 s
agent0:                 episode reward: 0.2203,                 loss: nan
agent1:                 episode reward: -0.2203,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 10.2462 s
agent0:                 episode reward: -0.2507,                 loss: nan
agent1:                 episode reward: 0.2507,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 10.4419 s
agent0:                 episode reward: 0.3234,                 loss: nan
agent1:                 episode reward: -0.3234,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 10.6423 s
agent0:                 episode reward: 0.1471,                 loss: nan
agent1:                 episode reward: -0.1471,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 10.8402 s
agent0:                 episode reward: 0.0770,                 loss: nan
agent1:                 episode reward: -0.0770,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 11.0377 s
agent0:                 episode reward: -0.0969,                 loss: nan
agent1:                 episode reward: 0.0969,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 11.2371 s
agent0:                 episode reward: 0.0734,                 loss: nan
agent1:                 episode reward: -0.0734,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 11.4392 s
agent0:                 episode reward: 0.5571,                 loss: nan
agent1:                 episode reward: -0.5571,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 11.6399 s
agent0:                 episode reward: 0.2383,                 loss: nan
agent1:                 episode reward: -0.2383,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 11.8397 s
agent0:                 episode reward: -0.0466,                 loss: nan
agent1:                 episode reward: 0.0466,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2050s / 12.0447 s
agent0:                 episode reward: 0.1422,                 loss: nan
agent1:                 episode reward: -0.1422,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 12.2430 s
agent0:                 episode reward: 0.0853,                 loss: nan
agent1:                 episode reward: -0.0853,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 12.4463 s
agent0:                 episode reward: -0.3667,                 loss: nan
agent1:                 episode reward: 0.3667,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 12.6469 s
agent0:                 episode reward: -0.0919,                 loss: nan
agent1:                 episode reward: 0.0919,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 12.8452 s
agent0:                 episode reward: 0.1874,                 loss: nan
agent1:                 episode reward: -0.1874,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 13.0502 s
agent0:                 episode reward: 0.0107,                 loss: nan
agent1:                 episode reward: -0.0107,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 13.2477 s
agent0:                 episode reward: 0.0683,                 loss: nan
agent1:                 episode reward: -0.0683,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 13.4492 s
agent0:                 episode reward: 0.0985,                 loss: nan
agent1:                 episode reward: -0.0985,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 13.6464 s
agent0:                 episode reward: -0.1138,                 loss: nan
agent1:                 episode reward: 0.1138,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 13.8444 s
agent0:                 episode reward: -0.3236,                 loss: nan
agent1:                 episode reward: 0.3236,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 14.0454 s
agent0:                 episode reward: 0.3245,                 loss: nan
agent1:                 episode reward: -0.3245,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 14.2444 s
agent0:                 episode reward: 0.1487,                 loss: nan
agent1:                 episode reward: -0.1487,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 14.4434 s
agent0:                 episode reward: 0.1355,                 loss: nan
agent1:                 episode reward: -0.1355,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 14.6445 s
agent0:                 episode reward: -0.0380,                 loss: nan
agent1:                 episode reward: 0.0380,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 14.8471 s
agent0:                 episode reward: 0.4063,                 loss: nan
agent1:                 episode reward: -0.4063,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 15.0469 s
agent0:                 episode reward: 0.0718,                 loss: nan
agent1:                 episode reward: -0.0718,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 15.2451 s
agent0:                 episode reward: -0.5023,                 loss: nan
agent1:                 episode reward: 0.5023,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 15.4391 s
agent0:                 episode reward: 0.2941,                 loss: nan
agent1:                 episode reward: -0.2941,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 15.6395 s
agent0:                 episode reward: -0.0621,                 loss: nan
agent1:                 episode reward: 0.0621,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 15.8379 s
agent0:                 episode reward: 0.1205,                 loss: nan
agent1:                 episode reward: -0.1205,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2054s / 16.0433 s
agent0:                 episode reward: -0.1308,                 loss: nan
agent1:                 episode reward: 0.1308,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 16.2377 s
agent0:                 episode reward: 0.5407,                 loss: nan
agent1:                 episode reward: -0.5407,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 16.4361 s
agent0:                 episode reward: -0.2996,                 loss: nan
agent1:                 episode reward: 0.2996,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 16.6325 s
agent0:                 episode reward: -0.1057,                 loss: nan
agent1:                 episode reward: 0.1057,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 16.8306 s
agent0:                 episode reward: 0.1511,                 loss: nan
agent1:                 episode reward: -0.1511,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 17.0301 s
agent0:                 episode reward: 0.4045,                 loss: nan
agent1:                 episode reward: -0.4045,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 17.2299 s
agent0:                 episode reward: 0.2085,                 loss: nan
agent1:                 episode reward: -0.2085,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 17.4269 s
agent0:                 episode reward: 0.1376,                 loss: nan
agent1:                 episode reward: -0.1376,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 17.6275 s
agent0:                 episode reward: 0.3852,                 loss: nan
agent1:                 episode reward: -0.3852,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 17.8237 s
agent0:                 episode reward: -0.0255,                 loss: nan
agent1:                 episode reward: 0.0255,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 18.0208 s
agent0:                 episode reward: 0.0784,                 loss: nan
agent1:                 episode reward: -0.0784,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 18.2211 s
agent0:                 episode reward: -0.2499,                 loss: nan
agent1:                 episode reward: 0.2499,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 18.4204 s
agent0:                 episode reward: 0.1737,                 loss: nan
agent1:                 episode reward: -0.1737,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 18.6191 s
agent0:                 episode reward: -0.2008,                 loss: nan
agent1:                 episode reward: 0.2008,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 18.8110 s
agent0:                 episode reward: 0.2942,                 loss: nan
agent1:                 episode reward: -0.2942,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 19.0110 s
agent0:                 episode reward: -0.6984,                 loss: nan
agent1:                 episode reward: 0.6984,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 19.2092 s
agent0:                 episode reward: 0.5178,                 loss: nan
agent1:                 episode reward: -0.5178,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 19.4067 s
agent0:                 episode reward: 0.2265,                 loss: nan
agent1:                 episode reward: -0.2265,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 19.6097 s
agent0:                 episode reward: 0.1648,                 loss: nan
agent1:                 episode reward: -0.1648,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 19.8096 s
agent0:                 episode reward: -0.0097,                 loss: nan
agent1:                 episode reward: 0.0097,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 20.0096 s
agent0:                 episode reward: 0.1659,                 loss: nan
agent1:                 episode reward: -0.1659,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 20.2076 s
agent0:                 episode reward: -0.1103,                 loss: nan
agent1:                 episode reward: 0.1103,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 20.4048 s
agent0:                 episode reward: 0.2339,                 loss: nan
agent1:                 episode reward: -0.2339,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 20.6013 s
agent0:                 episode reward: 0.0748,                 loss: nan
agent1:                 episode reward: -0.0748,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 20.8026 s
agent0:                 episode reward: 0.1020,                 loss: nan
agent1:                 episode reward: -0.1020,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 21.0052 s
agent0:                 episode reward: -0.5102,                 loss: nan
agent1:                 episode reward: 0.5102,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 21.2041 s
agent0:                 episode reward: 0.1786,                 loss: nan
agent1:                 episode reward: -0.1786,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 21.4049 s
agent0:                 episode reward: 0.2830,                 loss: nan
agent1:                 episode reward: -0.2830,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 21.5979 s
agent0:                 episode reward: -0.0159,                 loss: nan
agent1:                 episode reward: 0.0159,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 21.8020 s
agent0:                 episode reward: 0.0322,                 loss: nan
agent1:                 episode reward: -0.0322,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 21.9989 s
agent0:                 episode reward: 0.1819,                 loss: nan
agent1:                 episode reward: -0.1819,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 22.1993 s
agent0:                 episode reward: -0.0408,                 loss: nan
agent1:                 episode reward: 0.0408,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 22.4016 s
agent0:                 episode reward: -0.0111,                 loss: nan
agent1:                 episode reward: 0.0111,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 22.6030 s
agent0:                 episode reward: -0.1067,                 loss: nan
agent1:                 episode reward: 0.1067,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 22.8012 s
agent0:                 episode reward: -0.0307,                 loss: nan
agent1:                 episode reward: 0.0307,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 22.9931 s
agent0:                 episode reward: 0.2119,                 loss: nan
agent1:                 episode reward: -0.2119,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 23.1927 s
agent0:                 episode reward: -0.3134,                 loss: nan
agent1:                 episode reward: 0.3134,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 23.3945 s
agent0:                 episode reward: -0.1085,                 loss: nan
agent1:                 episode reward: 0.1085,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 23.5916 s
agent0:                 episode reward: 0.0824,                 loss: nan
agent1:                 episode reward: -0.0824,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 23.7894 s
agent0:                 episode reward: 0.2561,                 loss: nan
agent1:                 episode reward: -0.2561,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 23.9873 s
agent0:                 episode reward: 0.3228,                 loss: nan
agent1:                 episode reward: -0.3228,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1930s / 24.1803 s
agent0:                 episode reward: -0.0655,                 loss: nan
agent1:                 episode reward: 0.0655,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 24.3789 s
agent0:                 episode reward: -0.2198,                 loss: nan
agent1:                 episode reward: 0.2198,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 24.5763 s
agent0:                 episode reward: 0.0175,                 loss: nan
agent1:                 episode reward: -0.0175,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 24.7732 s
agent0:                 episode reward: 0.1184,                 loss: nan
agent1:                 episode reward: -0.1184,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 24.9740 s
agent0:                 episode reward: -0.4368,                 loss: nan
agent1:                 episode reward: 0.4368,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 25.1719 s
agent0:                 episode reward: -0.0048,                 loss: nan
agent1:                 episode reward: 0.0048,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 25.3723 s
agent0:                 episode reward: 0.0697,                 loss: nan
agent1:                 episode reward: -0.0697,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 25.5698 s
agent0:                 episode reward: 0.0534,                 loss: nan
agent1:                 episode reward: -0.0534,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 25.7679 s
agent0:                 episode reward: -0.0761,                 loss: nan
agent1:                 episode reward: 0.0761,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 25.9660 s
agent0:                 episode reward: -0.2148,                 loss: nan
agent1:                 episode reward: 0.2148,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 26.1627 s
agent0:                 episode reward: 0.0626,                 loss: nan
agent1:                 episode reward: -0.0626,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1890s / 26.3517 s
agent0:                 episode reward: 0.1047,                 loss: nan
agent1:                 episode reward: -0.1047,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 26.5478 s
agent0:                 episode reward: -0.2339,                 loss: nan
agent1:                 episode reward: 0.2339,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 26.7454 s
agent0:                 episode reward: -0.0297,                 loss: nan
agent1:                 episode reward: 0.0297,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 26.9430 s
agent0:                 episode reward: 0.0580,                 loss: nan
agent1:                 episode reward: -0.0580,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 27.1448 s
agent0:                 episode reward: -0.3471,                 loss: nan
agent1:                 episode reward: 0.3471,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 27.3474 s
agent0:                 episode reward: 0.0518,                 loss: nan
agent1:                 episode reward: -0.0518,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 27.5465 s
agent0:                 episode reward: 0.2120,                 loss: nan
agent1:                 episode reward: -0.2120,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1921s / 27.7386 s
agent0:                 episode reward: -0.0219,                 loss: nan
agent1:                 episode reward: 0.0219,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1721s / 27.9107 s
agent0:                 episode reward: 0.1515,                 loss: nan
agent1:                 episode reward: -0.1515,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2438s / 28.1545 s
agent0:                 episode reward: -0.2937,                 loss: nan
agent1:                 episode reward: 0.2937,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 28.3550 s
agent0:                 episode reward: 0.1679,                 loss: nan
agent1:                 episode reward: -0.1679,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 28.5542 s
agent0:                 episode reward: 0.0978,                 loss: nan
agent1:                 episode reward: -0.0978,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 28.7558 s
agent0:                 episode reward: -0.0035,                 loss: nan
agent1:                 episode reward: 0.0035,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 28.9522 s
agent0:                 episode reward: 0.0060,                 loss: nan
agent1:                 episode reward: -0.0060,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 29.1506 s
agent0:                 episode reward: 0.4185,                 loss: nan
agent1:                 episode reward: -0.4185,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 29.3511 s
agent0:                 episode reward: 0.1908,                 loss: nan
agent1:                 episode reward: -0.1908,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 29.5549 s
agent0:                 episode reward: 0.1008,                 loss: nan
agent1:                 episode reward: -0.1008,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 29.7519 s
agent0:                 episode reward: 0.1112,                 loss: nan
agent1:                 episode reward: -0.1112,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 29.9540 s
agent0:                 episode reward: -0.3826,                 loss: nan
agent1:                 episode reward: 0.3826,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 30.1543 s
agent0:                 episode reward: 0.0755,                 loss: nan
agent1:                 episode reward: -0.0755,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 30.3534 s
agent0:                 episode reward: 0.1328,                 loss: nan
agent1:                 episode reward: -0.1328,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 30.5507 s
agent0:                 episode reward: 0.0012,                 loss: nan
agent1:                 episode reward: -0.0012,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 30.7483 s
agent0:                 episode reward: 0.0106,                 loss: nan
agent1:                 episode reward: -0.0106,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 30.9466 s
agent0:                 episode reward: 0.4901,                 loss: nan
agent1:                 episode reward: -0.4901,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2039s / 31.1505 s
agent0:                 episode reward: -0.1382,                 loss: nan
agent1:                 episode reward: 0.1382,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 31.3513 s
agent0:                 episode reward: -0.0058,                 loss: nan
agent1:                 episode reward: 0.0058,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 31.5521 s
agent0:                 episode reward: 0.1637,                 loss: nan
agent1:                 episode reward: -0.1637,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 31.7530 s
agent0:                 episode reward: -0.0896,                 loss: nan
agent1:                 episode reward: 0.0896,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 31.9545 s
agent0:                 episode reward: -0.3577,                 loss: nan
agent1:                 episode reward: 0.3577,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 32.1545 s
agent0:                 episode reward: 0.2189,                 loss: nan
agent1:                 episode reward: -0.2189,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 32.3508 s
agent0:                 episode reward: -0.1707,                 loss: nan
agent1:                 episode reward: 0.1707,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 32.5445 s
agent0:                 episode reward: 0.1282,                 loss: nan
agent1:                 episode reward: -0.1282,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 32.7425 s
agent0:                 episode reward: 0.3011,                 loss: nan
agent1:                 episode reward: -0.3011,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 32.9382 s
agent0:                 episode reward: 0.3090,                 loss: nan
agent1:                 episode reward: -0.3090,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 33.1339 s
agent0:                 episode reward: 0.0170,                 loss: nan
agent1:                 episode reward: -0.0170,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 33.3272 s
agent0:                 episode reward: 0.0767,                 loss: nan
agent1:                 episode reward: -0.0767,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 33.5214 s
agent0:                 episode reward: 0.5729,                 loss: nan
agent1:                 episode reward: -0.5729,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1903s / 33.7117 s
agent0:                 episode reward: -0.1598,                 loss: nan
agent1:                 episode reward: 0.1598,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3438s / 34.0555 s
agent0:                 episode reward: -0.2525,                 loss: nan
agent1:                 episode reward: 0.2525,                 loss: 0.4449
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5778s / 34.6333 s
agent0:                 episode reward: -0.4046,                 loss: nan
agent1:                 episode reward: 0.4046,                 loss: 0.4348
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5834s / 35.2166 s
agent0:                 episode reward: -0.6893,                 loss: nan
agent1:                 episode reward: 0.6893,                 loss: 0.4312
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 35.7999 s
agent0:                 episode reward: -0.5107,                 loss: nan
agent1:                 episode reward: 0.5107,                 loss: 0.4308
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5773s / 36.3772 s
agent0:                 episode reward: -0.6170,                 loss: nan
agent1:                 episode reward: 0.6170,                 loss: 0.4275
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 36.9572 s
agent0:                 episode reward: -0.6327,                 loss: nan
agent1:                 episode reward: 0.6327,                 loss: 0.4229
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5841s / 37.5413 s
agent0:                 episode reward: -0.6608,                 loss: nan
agent1:                 episode reward: 0.6608,                 loss: 0.4191
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 38.1266 s
agent0:                 episode reward: -0.6079,                 loss: nan
agent1:                 episode reward: 0.6079,                 loss: 0.4121
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 38.7125 s
agent0:                 episode reward: -0.8595,                 loss: nan
agent1:                 episode reward: 0.8595,                 loss: 0.4062
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 39.2947 s
agent0:                 episode reward: -0.7203,                 loss: nan
agent1:                 episode reward: 0.7203,                 loss: 0.3977
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5855s / 39.8802 s
agent0:                 episode reward: -0.4526,                 loss: nan
agent1:                 episode reward: 0.4526,                 loss: 0.3895
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 40.4762 s
agent0:                 episode reward: -0.7604,                 loss: nan
agent1:                 episode reward: 0.7604,                 loss: 0.3781
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5804s / 41.0566 s
agent0:                 episode reward: -0.9319,                 loss: nan
agent1:                 episode reward: 0.9319,                 loss: 0.3693
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 41.6447 s
agent0:                 episode reward: -0.5506,                 loss: nan
agent1:                 episode reward: 0.5506,                 loss: 0.3614
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5786s / 42.2234 s
agent0:                 episode reward: -0.7259,                 loss: nan
agent1:                 episode reward: 0.7259,                 loss: 0.3546
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5798s / 42.8031 s
agent0:                 episode reward: -0.4165,                 loss: nan
agent1:                 episode reward: 0.4165,                 loss: 0.3468
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 43.4007 s
agent0:                 episode reward: -0.7235,                 loss: nan
agent1:                 episode reward: 0.7235,                 loss: 0.3417
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5794s / 43.9801 s
agent0:                 episode reward: -0.6417,                 loss: nan
agent1:                 episode reward: 0.6417,                 loss: 0.3095
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 44.5657 s
agent0:                 episode reward: -0.7037,                 loss: nan
agent1:                 episode reward: 0.7037,                 loss: 0.2971
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 45.1565 s
agent0:                 episode reward: -0.8463,                 loss: nan
agent1:                 episode reward: 0.8463,                 loss: 0.2909
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5814s / 45.7379 s
agent0:                 episode reward: -0.5850,                 loss: nan
agent1:                 episode reward: 0.5850,                 loss: 0.2893
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 46.3215 s
agent0:                 episode reward: -0.7435,                 loss: nan
agent1:                 episode reward: 0.7435,                 loss: 0.2840
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 46.9109 s
agent0:                 episode reward: -0.9949,                 loss: nan
agent1:                 episode reward: 0.9949,                 loss: 0.2833
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 47.4986 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.2813
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 48.0842 s
agent0:                 episode reward: -0.8105,                 loss: nan
agent1:                 episode reward: 0.8105,                 loss: 0.2795
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 48.6783 s
agent0:                 episode reward: -0.7172,                 loss: nan
agent1:                 episode reward: 0.7172,                 loss: 0.2764
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 49.2709 s
agent0:                 episode reward: -0.8504,                 loss: nan
agent1:                 episode reward: 0.8504,                 loss: 0.2763
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 49.8607 s
agent0:                 episode reward: -0.4660,                 loss: nan
agent1:                 episode reward: 0.4660,                 loss: 0.2718
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5873s / 50.4480 s
agent0:                 episode reward: -0.4800,                 loss: nan
agent1:                 episode reward: 0.4800,                 loss: 0.2712
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 51.0385 s
agent0:                 episode reward: -0.6434,                 loss: nan
agent1:                 episode reward: 0.6434,                 loss: 0.2695
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 51.6296 s
agent0:                 episode reward: -0.9442,                 loss: nan
agent1:                 episode reward: 0.9442,                 loss: 0.2633
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 52.2308 s
agent0:                 episode reward: -0.8419,                 loss: nan
agent1:                 episode reward: 0.8419,                 loss: 0.2689
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 52.8203 s
agent0:                 episode reward: -0.8146,                 loss: nan
agent1:                 episode reward: 0.8146,                 loss: 0.2633
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5826s / 53.4029 s
agent0:                 episode reward: -0.8359,                 loss: nan
agent1:                 episode reward: 0.8359,                 loss: 0.2709
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 53.9933 s
agent0:                 episode reward: -0.6406,                 loss: nan
agent1:                 episode reward: 0.6406,                 loss: 0.2838
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 54.5819 s
agent0:                 episode reward: -0.7631,                 loss: nan
agent1:                 episode reward: 0.7631,                 loss: 0.2712
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5884s / 55.1704 s
agent0:                 episode reward: -0.8606,                 loss: nan
agent1:                 episode reward: 0.8606,                 loss: 0.2695
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 55.7558 s
agent0:                 episode reward: -0.7259,                 loss: nan
agent1:                 episode reward: 0.7259,                 loss: 0.2664
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5849s / 56.3407 s
agent0:                 episode reward: -0.8373,                 loss: nan
agent1:                 episode reward: 0.8373,                 loss: 0.2681
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 56.9224 s
agent0:                 episode reward: -0.7917,                 loss: nan
agent1:                 episode reward: 0.7917,                 loss: 0.2652
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 57.5116 s
agent0:                 episode reward: -0.7508,                 loss: nan
agent1:                 episode reward: 0.7508,                 loss: 0.2648
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 58.0985 s
agent0:                 episode reward: -0.8688,                 loss: nan
agent1:                 episode reward: 0.8688,                 loss: 0.2629
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 58.6937 s
agent0:                 episode reward: -0.4858,                 loss: nan
agent1:                 episode reward: 0.4858,                 loss: 0.2632
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 59.2869 s
agent0:                 episode reward: -0.7259,                 loss: nan
agent1:                 episode reward: 0.7259,                 loss: 0.2606
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 59.8858 s
agent0:                 episode reward: -0.4524,                 loss: nan
agent1:                 episode reward: 0.4524,                 loss: 0.2626
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 60.4728 s
agent0:                 episode reward: -0.8169,                 loss: nan
agent1:                 episode reward: 0.8169,                 loss: 0.2617
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 61.0654 s
agent0:                 episode reward: -0.7377,                 loss: nan
agent1:                 episode reward: 0.7377,                 loss: 0.2579
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 61.6543 s
agent0:                 episode reward: -0.9686,                 loss: nan
agent1:                 episode reward: 0.9686,                 loss: 0.2614
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 62.2504 s
agent0:                 episode reward: -0.4836,                 loss: nan
agent1:                 episode reward: 0.4836,                 loss: 0.2604
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5873s / 62.8377 s
agent0:                 episode reward: -0.7331,                 loss: nan
agent1:                 episode reward: 0.7331,                 loss: 0.2600
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 63.4220 s
agent0:                 episode reward: -0.7010,                 loss: nan
agent1:                 episode reward: 0.7010,                 loss: 0.2783
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 64.0106 s
agent0:                 episode reward: -0.7839,                 loss: nan
agent1:                 episode reward: 0.7839,                 loss: 0.2898
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 64.5937 s
agent0:                 episode reward: -0.9380,                 loss: nan
agent1:                 episode reward: 0.9380,                 loss: 0.2874
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 65.1863 s
agent0:                 episode reward: -0.9903,                 loss: nan
agent1:                 episode reward: 0.9903,                 loss: 0.2903
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 65.7695 s
agent0:                 episode reward: -0.5844,                 loss: nan
agent1:                 episode reward: 0.5844,                 loss: 0.2884
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 66.3581 s
agent0:                 episode reward: -0.9804,                 loss: nan
agent1:                 episode reward: 0.9804,                 loss: 0.2896
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 66.9398 s
agent0:                 episode reward: -0.6043,                 loss: nan
agent1:                 episode reward: 0.6043,                 loss: 0.2872
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 67.5319 s
agent0:                 episode reward: -0.3312,                 loss: nan
agent1:                 episode reward: 0.3312,                 loss: 0.2871
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 68.1251 s
agent0:                 episode reward: -0.6185,                 loss: nan
agent1:                 episode reward: 0.6185,                 loss: 0.2860
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 68.7154 s
agent0:                 episode reward: -0.7937,                 loss: nan
agent1:                 episode reward: 0.7937,                 loss: 0.2897
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 69.3066 s
agent0:                 episode reward: -0.9466,                 loss: nan
agent1:                 episode reward: 0.9466,                 loss: 0.2859
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 69.8934 s
agent0:                 episode reward: -0.6670,                 loss: nan
agent1:                 episode reward: 0.6670,                 loss: 0.2843
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5827s / 70.4761 s
agent0:                 episode reward: -0.8058,                 loss: nan
agent1:                 episode reward: 0.8058,                 loss: 0.2882
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5873s / 71.0634 s
agent0:                 episode reward: -0.7024,                 loss: nan
agent1:                 episode reward: 0.7024,                 loss: 0.2838
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 71.6570 s
agent0:                 episode reward: -0.8119,                 loss: nan
agent1:                 episode reward: 0.8119,                 loss: 0.2862
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 72.2491 s
agent0:                 episode reward: -0.4970,                 loss: nan
agent1:                 episode reward: 0.4970,                 loss: 0.2866
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 72.8385 s
agent0:                 episode reward: -0.9693,                 loss: nan
agent1:                 episode reward: 0.9693,                 loss: 0.2859
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 73.4291 s
agent0:                 episode reward: -0.8852,                 loss: nan
agent1:                 episode reward: 0.8852,                 loss: 0.2648
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 74.0237 s
agent0:                 episode reward: -0.5733,                 loss: nan
agent1:                 episode reward: 0.5733,                 loss: 0.2542
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 74.6165 s
agent0:                 episode reward: -0.9104,                 loss: nan
agent1:                 episode reward: 0.9104,                 loss: 0.2552
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 75.2101 s
agent0:                 episode reward: -0.7793,                 loss: nan
agent1:                 episode reward: 0.7793,                 loss: 0.2548
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 75.7996 s
agent0:                 episode reward: -0.7541,                 loss: nan
agent1:                 episode reward: 0.7541,                 loss: 0.2566
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 76.3894 s
agent0:                 episode reward: -0.7079,                 loss: nan
agent1:                 episode reward: 0.7079,                 loss: 0.2549
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 76.9824 s
agent0:                 episode reward: -0.7458,                 loss: nan
agent1:                 episode reward: 0.7458,                 loss: 0.2562
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 77.5720 s
agent0:                 episode reward: -0.5214,                 loss: nan
agent1:                 episode reward: 0.5214,                 loss: 0.2533
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 78.1592 s
agent0:                 episode reward: -0.7704,                 loss: nan
agent1:                 episode reward: 0.7704,                 loss: 0.2553
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 78.7488 s
agent0:                 episode reward: -0.6564,                 loss: nan
agent1:                 episode reward: 0.6564,                 loss: 0.2567
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 79.3473 s
agent0:                 episode reward: -0.8602,                 loss: nan
agent1:                 episode reward: 0.8602,                 loss: 0.2532
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 79.9418 s
agent0:                 episode reward: -0.5023,                 loss: nan
agent1:                 episode reward: 0.5023,                 loss: 0.2547
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 80.5303 s
agent0:                 episode reward: -0.6589,                 loss: nan
agent1:                 episode reward: 0.6589,                 loss: 0.2558
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 81.1220 s
agent0:                 episode reward: -0.9923,                 loss: nan
agent1:                 episode reward: 0.9923,                 loss: 0.2561
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 81.7120 s
agent0:                 episode reward: -0.4132,                 loss: nan
agent1:                 episode reward: 0.4132,                 loss: 0.2543
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 82.3062 s
agent0:                 episode reward: -1.0050,                 loss: nan
agent1:                 episode reward: 1.0050,                 loss: 0.2534
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 82.9107 s
agent0:                 episode reward: -0.7931,                 loss: nan
agent1:                 episode reward: 0.7931,                 loss: 0.2562
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 83.5092 s
agent0:                 episode reward: -0.5707,                 loss: nan
agent1:                 episode reward: 0.5707,                 loss: 0.2499
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 84.1012 s
agent0:                 episode reward: -0.5957,                 loss: nan
agent1:                 episode reward: 0.5957,                 loss: 0.2417
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 84.6987 s
agent0:                 episode reward: -0.5434,                 loss: nan
agent1:                 episode reward: 0.5434,                 loss: 0.2378
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 85.2911 s
agent0:                 episode reward: -0.6946,                 loss: nan
agent1:                 episode reward: 0.6946,                 loss: 0.2425
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 85.8873 s
agent0:                 episode reward: -0.6929,                 loss: nan
agent1:                 episode reward: 0.6929,                 loss: 0.2433
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 86.4805 s
agent0:                 episode reward: -0.7922,                 loss: nan
agent1:                 episode reward: 0.7922,                 loss: 0.2399
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 87.0667 s
agent0:                 episode reward: -0.4388,                 loss: nan
agent1:                 episode reward: 0.4388,                 loss: 0.2425
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 87.6562 s
agent0:                 episode reward: -0.8088,                 loss: nan
agent1:                 episode reward: 0.8088,                 loss: 0.2421
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5826s / 88.2388 s
agent0:                 episode reward: -0.8209,                 loss: nan
agent1:                 episode reward: 0.8209,                 loss: 0.2432
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 88.8319 s
agent0:                 episode reward: -0.7858,                 loss: nan
agent1:                 episode reward: 0.7858,                 loss: 0.2405
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 89.4221 s
agent0:                 episode reward: -0.7371,                 loss: nan
agent1:                 episode reward: 0.7371,                 loss: 0.2400
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 90.0161 s
agent0:                 episode reward: -0.5265,                 loss: nan
agent1:                 episode reward: 0.5265,                 loss: 0.2408
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5992s / 90.6153 s
agent0:                 episode reward: -0.7958,                 loss: nan
agent1:                 episode reward: 0.7958,                 loss: 0.2451
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 91.2104 s
agent0:                 episode reward: -0.6645,                 loss: nan
agent1:                 episode reward: 0.6645,                 loss: 0.2426
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 91.8111 s
agent0:                 episode reward: -0.8882,                 loss: nan
agent1:                 episode reward: 0.8882,                 loss: 0.2431
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 92.3993 s
agent0:                 episode reward: -0.9656,                 loss: nan
agent1:                 episode reward: 0.9656,                 loss: 0.2453
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 92.9954 s
agent0:                 episode reward: -0.4919,                 loss: nan
agent1:                 episode reward: 0.4919,                 loss: 0.2687
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 93.5883 s
agent0:                 episode reward: -0.4734,                 loss: nan
agent1:                 episode reward: 0.4734,                 loss: 0.2877
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 94.1787 s
agent0:                 episode reward: -0.8694,                 loss: nan
agent1:                 episode reward: 0.8694,                 loss: 0.2874
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 94.7799 s
agent0:                 episode reward: -0.8519,                 loss: nan
agent1:                 episode reward: 0.8519,                 loss: 0.2847
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 95.3727 s
agent0:                 episode reward: -0.4808,                 loss: nan
agent1:                 episode reward: 0.4808,                 loss: 0.2858
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 95.9635 s
agent0:                 episode reward: -0.6662,                 loss: nan
agent1:                 episode reward: 0.6662,                 loss: 0.2839
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 96.5529 s
agent0:                 episode reward: -0.7648,                 loss: nan
agent1:                 episode reward: 0.7648,                 loss: 0.2853
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 97.1429 s
agent0:                 episode reward: -0.5564,                 loss: nan
agent1:                 episode reward: 0.5564,                 loss: 0.2863
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6030s / 97.7459 s
agent0:                 episode reward: -1.0088,                 loss: nan
agent1:                 episode reward: 1.0088,                 loss: 0.2841
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 98.3445 s
agent0:                 episode reward: -0.6839,                 loss: nan
agent1:                 episode reward: 0.6839,                 loss: 0.2852
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 98.9424 s
agent0:                 episode reward: -0.8133,                 loss: nan
agent1:                 episode reward: 0.8133,                 loss: 0.2848
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 99.5380 s
agent0:                 episode reward: -0.7118,                 loss: nan
agent1:                 episode reward: 0.7118,                 loss: 0.2821
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6114s / 100.1493 s
agent0:                 episode reward: -0.5611,                 loss: nan
agent1:                 episode reward: 0.5611,                 loss: 0.2807
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 100.7369 s
agent0:                 episode reward: -0.8438,                 loss: nan
agent1:                 episode reward: 0.8438,                 loss: 0.2885
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5933s / 101.3302 s
agent0:                 episode reward: -0.6292,                 loss: nan
agent1:                 episode reward: 0.6292,                 loss: 0.2820
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6014s / 101.9317 s
agent0:                 episode reward: -0.5296,                 loss: nan
agent1:                 episode reward: 0.5296,                 loss: 0.2860
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 102.5272 s
agent0:                 episode reward: -0.6745,                 loss: nan
agent1:                 episode reward: 0.6745,                 loss: 0.2834
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6102s / 103.1374 s
agent0:                 episode reward: -0.5716,                 loss: nan
agent1:                 episode reward: 0.5716,                 loss: 0.2689
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 103.7354 s
agent0:                 episode reward: -0.4036,                 loss: nan
agent1:                 episode reward: 0.4036,                 loss: 0.2571
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6055s / 104.3409 s
agent0:                 episode reward: -1.0166,                 loss: nan
agent1:                 episode reward: 1.0166,                 loss: 0.2606
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 104.9414 s
agent0:                 episode reward: -0.4382,                 loss: nan
agent1:                 episode reward: 0.4382,                 loss: 0.2579
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 105.5297 s
agent0:                 episode reward: -0.7411,                 loss: nan
agent1:                 episode reward: 0.7411,                 loss: 0.2546
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6061s / 106.1358 s
agent0:                 episode reward: -0.9671,                 loss: nan
agent1:                 episode reward: 0.9671,                 loss: 0.2577
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 106.7329 s
agent0:                 episode reward: -0.8181,                 loss: nan
agent1:                 episode reward: 0.8181,                 loss: 0.2570
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 107.3353 s
agent0:                 episode reward: -0.8000,                 loss: nan
agent1:                 episode reward: 0.8000,                 loss: 0.2582
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 107.9313 s
agent0:                 episode reward: -0.8905,                 loss: nan
agent1:                 episode reward: 0.8905,                 loss: 0.2573
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 108.5320 s
agent0:                 episode reward: -0.7355,                 loss: nan
agent1:                 episode reward: 0.7355,                 loss: 0.2603
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 109.1345 s
agent0:                 episode reward: -0.8244,                 loss: nan
agent1:                 episode reward: 0.8244,                 loss: 0.2574
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 109.7402 s
agent0:                 episode reward: -0.6973,                 loss: nan
agent1:                 episode reward: 0.6973,                 loss: 0.2598
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 110.3319 s
agent0:                 episode reward: -0.7433,                 loss: nan
agent1:                 episode reward: 0.7433,                 loss: 0.2573
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 110.9242 s
agent0:                 episode reward: -0.9306,                 loss: nan
agent1:                 episode reward: 0.9306,                 loss: 0.2562
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 111.5213 s
agent0:                 episode reward: -0.9422,                 loss: nan
agent1:                 episode reward: 0.9422,                 loss: 0.2587
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 112.1160 s
agent0:                 episode reward: -0.9605,                 loss: nan
agent1:                 episode reward: 0.9605,                 loss: 0.2588
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 112.7084 s
agent0:                 episode reward: -0.7718,                 loss: nan
agent1:                 episode reward: 0.7718,                 loss: 0.2607
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 113.3099 s
agent0:                 episode reward: -0.9052,                 loss: nan
agent1:                 episode reward: 0.9052,                 loss: 0.2516
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 113.9085 s
agent0:                 episode reward: -0.8092,                 loss: nan
agent1:                 episode reward: 0.8092,                 loss: 0.2427
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 114.5118 s
agent0:                 episode reward: -0.6705,                 loss: nan
agent1:                 episode reward: 0.6705,                 loss: 0.2410
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 115.1056 s
agent0:                 episode reward: -0.9308,                 loss: nan
agent1:                 episode reward: 0.9308,                 loss: 0.2415
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6001s / 115.7058 s
agent0:                 episode reward: -0.7752,                 loss: nan
agent1:                 episode reward: 0.7752,                 loss: 0.2385
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 116.3063 s
agent0:                 episode reward: -0.8643,                 loss: nan
agent1:                 episode reward: 0.8643,                 loss: 0.2400
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 116.9052 s
agent0:                 episode reward: -0.5513,                 loss: nan
agent1:                 episode reward: 0.5513,                 loss: 0.2402
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 117.5047 s
agent0:                 episode reward: -0.5195,                 loss: nan
agent1:                 episode reward: 0.5195,                 loss: 0.2394
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 118.0940 s
agent0:                 episode reward: -1.0213,                 loss: nan
agent1:                 episode reward: 1.0213,                 loss: 0.2383
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6035s / 118.6975 s
agent0:                 episode reward: -0.7282,                 loss: nan
agent1:                 episode reward: 0.7282,                 loss: 0.2398
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 119.2938 s
agent0:                 episode reward: -0.5227,                 loss: nan
agent1:                 episode reward: 0.5227,                 loss: 0.2381
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 119.8938 s
agent0:                 episode reward: -0.5351,                 loss: nan
agent1:                 episode reward: 0.5351,                 loss: 0.2411
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 120.4886 s
agent0:                 episode reward: -0.9803,                 loss: nan
agent1:                 episode reward: 0.9803,                 loss: 0.2407
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 121.0915 s
agent0:                 episode reward: -0.4703,                 loss: nan
agent1:                 episode reward: 0.4703,                 loss: 0.2383
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 121.6812 s
agent0:                 episode reward: -0.5391,                 loss: nan
agent1:                 episode reward: 0.5391,                 loss: 0.2420
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 122.2731 s
agent0:                 episode reward: -0.8208,                 loss: nan
agent1:                 episode reward: 0.8208,                 loss: 0.2402
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6032s / 122.8763 s
agent0:                 episode reward: -0.6886,                 loss: nan
agent1:                 episode reward: 0.6886,                 loss: 0.2791
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 123.4711 s
agent0:                 episode reward: -0.8684,                 loss: nan
agent1:                 episode reward: 0.8684,                 loss: 0.2868
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 124.0666 s
agent0:                 episode reward: -1.0275,                 loss: nan
agent1:                 episode reward: 1.0275,                 loss: 0.2821
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 124.6637 s
agent0:                 episode reward: -0.7983,                 loss: nan
agent1:                 episode reward: 0.7983,                 loss: 0.2832
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 125.2658 s
agent0:                 episode reward: -0.5011,                 loss: nan
agent1:                 episode reward: 0.5011,                 loss: 0.2827
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 125.8585 s
agent0:                 episode reward: -1.1160,                 loss: nan
agent1:                 episode reward: 1.1160,                 loss: 0.2839
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 126.4557 s
agent0:                 episode reward: -0.7259,                 loss: nan
agent1:                 episode reward: 0.7259,                 loss: 0.2823
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6032s / 127.0589 s
agent0:                 episode reward: -0.8509,                 loss: nan
agent1:                 episode reward: 0.8509,                 loss: 0.2831
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 127.6616 s
agent0:                 episode reward: -0.9803,                 loss: nan
agent1:                 episode reward: 0.9803,                 loss: 0.2855
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 128.2589 s
agent0:                 episode reward: -0.4710,                 loss: nan
agent1:                 episode reward: 0.4710,                 loss: 0.2831
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 128.8593 s
agent0:                 episode reward: -0.3850,                 loss: nan
agent1:                 episode reward: 0.3850,                 loss: 0.2831
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6078s / 129.4670 s
agent0:                 episode reward: -0.7773,                 loss: nan
agent1:                 episode reward: 0.7773,                 loss: 0.2826
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6045s / 130.0715 s
agent0:                 episode reward: -1.0927,                 loss: nan
agent1:                 episode reward: 1.0927,                 loss: 0.2824
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5983s / 130.6699 s
agent0:                 episode reward: -1.0216,                 loss: nan
agent1:                 episode reward: 1.0216,                 loss: 0.2820
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5957s / 131.2656 s
agent0:                 episode reward: -0.7850,                 loss: nan
agent1:                 episode reward: 0.7850,                 loss: 0.2834
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 131.8698 s
agent0:                 episode reward: -0.7702,                 loss: nan
agent1:                 episode reward: 0.7702,                 loss: 0.2823
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 132.4689 s
agent0:                 episode reward: -0.7235,                 loss: nan
agent1:                 episode reward: 0.7235,                 loss: 0.2851
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6087s / 133.0776 s
agent0:                 episode reward: -0.6963,                 loss: nan
agent1:                 episode reward: 0.6963,                 loss: 0.2760
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6192s / 133.6968 s
agent0:                 episode reward: -0.8060,                 loss: nan
agent1:                 episode reward: 0.8060,                 loss: 0.2630
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 134.2994 s
agent0:                 episode reward: -0.8889,                 loss: nan
agent1:                 episode reward: 0.8889,                 loss: 0.2607
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 134.9046 s
agent0:                 episode reward: -0.7977,                 loss: nan
agent1:                 episode reward: 0.7977,                 loss: 0.2642
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 135.5085 s
agent0:                 episode reward: -0.8090,                 loss: nan
agent1:                 episode reward: 0.8090,                 loss: 0.2636
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6138s / 136.1222 s
agent0:                 episode reward: -0.9326,                 loss: nan
agent1:                 episode reward: 0.9326,                 loss: 0.2634
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 136.7218 s
agent0:                 episode reward: -0.8740,                 loss: nan
agent1:                 episode reward: 0.8740,                 loss: 0.2607
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 137.3265 s
agent0:                 episode reward: -0.5725,                 loss: nan
agent1:                 episode reward: 0.5725,                 loss: 0.2611
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6065s / 137.9329 s
agent0:                 episode reward: -1.0407,                 loss: nan
agent1:                 episode reward: 1.0407,                 loss: 0.2625
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 138.5465 s
agent0:                 episode reward: -0.9357,                 loss: nan
agent1:                 episode reward: 0.9357,                 loss: 0.2601
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 139.1429 s
agent0:                 episode reward: -0.6460,                 loss: nan
agent1:                 episode reward: 0.6460,                 loss: 0.2629
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 139.7456 s
agent0:                 episode reward: -0.7039,                 loss: nan
agent1:                 episode reward: 0.7039,                 loss: 0.2618
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 140.3484 s
agent0:                 episode reward: -0.8134,                 loss: nan
agent1:                 episode reward: 0.8134,                 loss: 0.2621
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 140.9456 s
agent0:                 episode reward: -0.6699,                 loss: nan
agent1:                 episode reward: 0.6699,                 loss: 0.2611
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 141.5552 s
agent0:                 episode reward: -0.5798,                 loss: nan
agent1:                 episode reward: 0.5798,                 loss: 0.2623
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 142.1527 s
agent0:                 episode reward: -0.9783,                 loss: nan
agent1:                 episode reward: 0.9783,                 loss: 0.2622
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6087s / 142.7615 s
agent0:                 episode reward: -0.8159,                 loss: nan
agent1:                 episode reward: 0.8159,                 loss: 0.2660
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 143.3592 s
agent0:                 episode reward: -0.6473,                 loss: nan
agent1:                 episode reward: 0.6473,                 loss: 0.2538
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6121s / 143.9713 s
agent0:                 episode reward: -0.7478,                 loss: nan
agent1:                 episode reward: 0.7478,                 loss: 0.2392
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 144.5808 s
agent0:                 episode reward: -0.6353,                 loss: nan
agent1:                 episode reward: 0.6353,                 loss: 0.2391
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6112s / 145.1921 s
agent0:                 episode reward: -0.5439,                 loss: nan
agent1:                 episode reward: 0.5439,                 loss: 0.2393
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 145.7967 s
agent0:                 episode reward: -0.3600,                 loss: nan
agent1:                 episode reward: 0.3600,                 loss: 0.2408
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 146.3965 s
agent0:                 episode reward: -0.5667,                 loss: nan
agent1:                 episode reward: 0.5667,                 loss: 0.2362
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 146.9973 s
agent0:                 episode reward: -0.7355,                 loss: nan
agent1:                 episode reward: 0.7355,                 loss: 0.2356
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 147.5950 s
agent0:                 episode reward: -0.7412,                 loss: nan
agent1:                 episode reward: 0.7412,                 loss: 0.2379
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 148.1992 s
agent0:                 episode reward: -0.9445,                 loss: nan
agent1:                 episode reward: 0.9445,                 loss: 0.2370
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6096s / 148.8088 s
agent0:                 episode reward: -0.8515,                 loss: nan
agent1:                 episode reward: 0.8515,                 loss: 0.2382
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6069s / 149.4157 s
agent0:                 episode reward: -0.8603,                 loss: nan
agent1:                 episode reward: 0.8603,                 loss: 0.2408
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 150.0207 s
agent0:                 episode reward: -1.0122,                 loss: nan
agent1:                 episode reward: 1.0122,                 loss: 0.2371
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6091s / 150.6298 s
agent0:                 episode reward: -0.9294,                 loss: nan
agent1:                 episode reward: 0.9294,                 loss: 0.2436
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 151.2329 s
agent0:                 episode reward: -0.7519,                 loss: nan
agent1:                 episode reward: 0.7519,                 loss: 0.2395
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 151.8370 s
agent0:                 episode reward: -1.2708,                 loss: nan
agent1:                 episode reward: 1.2708,                 loss: 0.2385
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 152.4422 s
agent0:                 episode reward: -0.9601,                 loss: nan
agent1:                 episode reward: 0.9601,                 loss: 0.2389
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 153.0407 s
agent0:                 episode reward: -0.8197,                 loss: nan
agent1:                 episode reward: 0.8197,                 loss: 0.2825
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 153.6441 s
agent0:                 episode reward: -0.9034,                 loss: nan
agent1:                 episode reward: 0.9034,                 loss: 0.2796
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 154.2459 s
agent0:                 episode reward: -0.9348,                 loss: nan
agent1:                 episode reward: 0.9348,                 loss: 0.2779
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 154.8427 s
agent0:                 episode reward: -0.6120,                 loss: nan
agent1:                 episode reward: 0.6120,                 loss: 0.2743
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 155.4451 s
agent0:                 episode reward: -0.9310,                 loss: nan
agent1:                 episode reward: 0.9310,                 loss: 0.2753
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 156.0448 s
agent0:                 episode reward: -0.8909,                 loss: nan
agent1:                 episode reward: 0.8909,                 loss: 0.2756
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 156.6407 s
agent0:                 episode reward: -0.9195,                 loss: nan
agent1:                 episode reward: 0.9195,                 loss: 0.2757
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 157.2473 s
agent0:                 episode reward: -0.8763,                 loss: nan
agent1:                 episode reward: 0.8763,                 loss: 0.2793
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 157.8548 s
agent0:                 episode reward: -0.7547,                 loss: nan
agent1:                 episode reward: 0.7547,                 loss: 0.2781
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 158.4560 s
agent0:                 episode reward: -0.7827,                 loss: nan
agent1:                 episode reward: 0.7827,                 loss: 0.2763
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 159.0612 s
agent0:                 episode reward: -0.9905,                 loss: nan
agent1:                 episode reward: 0.9905,                 loss: 0.2781
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 159.6612 s
agent0:                 episode reward: -0.9149,                 loss: nan
agent1:                 episode reward: 0.9149,                 loss: 0.2787
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 160.2782 s
agent0:                 episode reward: -0.6142,                 loss: nan
agent1:                 episode reward: 0.6142,                 loss: 0.2794
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 160.8858 s
agent0:                 episode reward: -0.9280,                 loss: nan
agent1:                 episode reward: 0.9280,                 loss: 0.2787
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 161.4899 s
agent0:                 episode reward: -0.7856,                 loss: nan
agent1:                 episode reward: 0.7856,                 loss: 0.2755
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 162.0932 s
agent0:                 episode reward: -0.9021,                 loss: nan
agent1:                 episode reward: 0.9021,                 loss: 0.2784
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 162.6963 s
agent0:                 episode reward: -0.7609,                 loss: nan
agent1:                 episode reward: 0.7609,                 loss: 0.2800
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 163.2999 s
agent0:                 episode reward: -0.7503,                 loss: nan
agent1:                 episode reward: 0.7503,                 loss: 0.2711
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6103s / 163.9102 s
agent0:                 episode reward: -0.7121,                 loss: nan
agent1:                 episode reward: 0.7121,                 loss: 0.2496
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6179s / 164.5281 s
agent0:                 episode reward: -0.4108,                 loss: nan
agent1:                 episode reward: 0.4108,                 loss: 0.2454
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 165.1267 s
agent0:                 episode reward: -0.7186,                 loss: nan
agent1:                 episode reward: 0.7186,                 loss: 0.2457
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6135s / 165.7402 s
agent0:                 episode reward: -0.9962,                 loss: nan
agent1:                 episode reward: 0.9962,                 loss: 0.2479
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6125s / 166.3526 s
agent0:                 episode reward: -0.9645,                 loss: nan
agent1:                 episode reward: 0.9645,                 loss: 0.2444
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 166.9544 s
agent0:                 episode reward: -0.9982,                 loss: nan
agent1:                 episode reward: 0.9982,                 loss: 0.2464
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6080s / 167.5625 s
agent0:                 episode reward: -0.8609,                 loss: nan
agent1:                 episode reward: 0.8609,                 loss: 0.2475
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6101s / 168.1726 s
agent0:                 episode reward: -0.7728,                 loss: nan
agent1:                 episode reward: 0.7728,                 loss: 0.2468
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 168.7754 s
agent0:                 episode reward: -0.6536,                 loss: nan
agent1:                 episode reward: 0.6536,                 loss: 0.2469
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 169.3787 s
agent0:                 episode reward: -0.9069,                 loss: nan
agent1:                 episode reward: 0.9069,                 loss: 0.2463
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 169.9915 s
agent0:                 episode reward: -0.6599,                 loss: nan
agent1:                 episode reward: 0.6599,                 loss: 0.2469
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 170.6005 s
agent0:                 episode reward: -1.3695,                 loss: nan
agent1:                 episode reward: 1.3695,                 loss: 0.2476
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6110s / 171.2116 s
agent0:                 episode reward: -0.9215,                 loss: nan
agent1:                 episode reward: 0.9215,                 loss: 0.2478
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6085s / 171.8201 s
agent0:                 episode reward: -0.9820,                 loss: nan
agent1:                 episode reward: 0.9820,                 loss: 0.2456
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6059s / 172.4259 s
agent0:                 episode reward: -0.8945,                 loss: nan
agent1:                 episode reward: 0.8945,                 loss: 0.2467
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 173.0274 s
agent0:                 episode reward: -0.6269,                 loss: nan
agent1:                 episode reward: 0.6269,                 loss: 0.2495
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6081s / 173.6355 s
agent0:                 episode reward: -0.6228,                 loss: nan
agent1:                 episode reward: 0.6228,                 loss: 0.2456
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6049s / 174.2405 s
agent0:                 episode reward: -0.5981,                 loss: nan
agent1:                 episode reward: 0.5981,                 loss: 0.2213
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6045s / 174.8450 s
agent0:                 episode reward: -0.4738,                 loss: nan
agent1:                 episode reward: 0.4738,                 loss: 0.2163
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 175.4465 s
agent0:                 episode reward: -0.4456,                 loss: nan
agent1:                 episode reward: 0.4456,                 loss: 0.2178
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 176.0511 s
agent0:                 episode reward: -0.6525,                 loss: nan
agent1:                 episode reward: 0.6525,                 loss: 0.2162
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6222s / 176.6734 s
agent0:                 episode reward: -0.6575,                 loss: nan
agent1:                 episode reward: 0.6575,                 loss: 0.2178
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6116s / 177.2850 s
agent0:                 episode reward: -0.5486,                 loss: nan
agent1:                 episode reward: 0.5486,                 loss: 0.2220
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6147s / 177.8997 s
agent0:                 episode reward: -0.6839,                 loss: nan
agent1:                 episode reward: 0.6839,                 loss: 0.2185
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6214s / 178.5210 s
