env_args:
  env_name: Ant-v2
  env_type: gym
  num_envs: 2
  against_baseline: false
  ram: true
  adversarial: true
  seed: random
agent_args:
  algorithm: NashActorCritic
  algorithm_spec:
    dueling: false
    replay_buffer_size: 1e5
    gamma: 0.99
    multi_step: 1
    target_update_interval: 1000
    eps_start: 1.0
    eps_final: 0.001
    eps_decay: 1000000
train_args:
  batch_size: 128
  max_episodes: 50000
  max_steps_per_episode: 10000
  train_start_frame: 0
  optimizer: adam
  learning_rate: 1e-4
  device: gpu
  update_itr: 1
  log_avg_window: 20
  log_interval: 20
  multiprocess: false
  net_architecture:
    feature:
      hidden_dim_list:
      - 128
      - 128
      hidden_activation: Tanh
      output_activation: false
    policy:
      hidden_dim_list:
      - 128
      hidden_activation: Tanh
      output_activation: false
    value:
      hidden_dim_list:
      - 128
      hidden_activation: Tanh
      output_activation: false
  marl_spec:
    global_state: true
  marl_method: nash_actor_critic
