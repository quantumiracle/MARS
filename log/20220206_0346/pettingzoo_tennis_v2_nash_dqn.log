pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 5, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220206_0346/pettingzoo_tennis_v2_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220206_0346/pettingzoo_tennis_v2_nash_dqn.
Episode: 1/10000 (0.0100%),                 avg. length: 9299.0,                last time consumption/overall running time: 77.1818s / 77.1818 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0865
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0867
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9078.5,                last time consumption/overall running time: 2273.0482s / 2350.2300 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.0681
env0_second_0:                 episode reward: -5.3000,                 loss: 0.0743
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 8017.35,                last time consumption/overall running time: 2187.9251s / 4538.1551 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0716
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0637
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 6422.85,                last time consumption/overall running time: 1763.3587s / 6301.5138 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0569
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0574
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 6933.35,                last time consumption/overall running time: 1870.6929s / 8172.2067 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0592
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0629
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 3174.55,                last time consumption/overall running time: 842.5014s / 9014.7081 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0532
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0597
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 3756.45,                last time consumption/overall running time: 1006.3763s / 10021.0844 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0646
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0573
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 3412.3,                last time consumption/overall running time: 905.7276s / 10926.8121 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0598
env0_second_0:                 episode reward: 6.6000,                 loss: 0.0525
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 4080.5,                last time consumption/overall running time: 1104.4530s / 12031.2651 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0590
env0_second_0:                 episode reward: 4.5500,                 loss: 0.0554
env1_first_0:                 episode reward: 7.3500,                 loss: nan
env1_second_0:                 episode reward: -7.3500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 4151.4,                last time consumption/overall running time: 1114.0228s / 13145.2879 s
env0_first_0:                 episode reward: -5.5000,                 loss: 0.0562
env0_second_0:                 episode reward: 5.5000,                 loss: 0.0539
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 4215.0,                last time consumption/overall running time: 1149.1523s / 14294.4402 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0600
env0_second_0:                 episode reward: 6.3000,                 loss: 0.0563
env1_first_0:                 episode reward: 6.3000,                 loss: nan
env1_second_0:                 episode reward: -6.3000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 3443.2,                last time consumption/overall running time: 927.8510s / 15222.2912 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0626
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0585
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 3953.7,                last time consumption/overall running time: 1078.3556s / 16300.6468 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0565
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0544
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 3624.8,                last time consumption/overall running time: 983.9880s / 17284.6348 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0529
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0494
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 3956.0,                last time consumption/overall running time: 1079.5236s / 18364.1584 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0513
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0498
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 4124.8,                last time consumption/overall running time: 1115.9720s / 19480.1304 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0483
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0485
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 4298.6,                last time consumption/overall running time: 1180.0509s / 20660.1813 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0442
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0445
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 4808.7,                last time consumption/overall running time: 1307.3359s / 21967.5172 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0458
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0478
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 4333.15,                last time consumption/overall running time: 1181.1989s / 23148.7161 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0458
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0437
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 4376.95,                last time consumption/overall running time: 1190.7609s / 24339.4770 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0447
env0_second_0:                 episode reward: 5.3500,                 loss: 0.0415
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 4417.25,                last time consumption/overall running time: 1184.9689s / 25524.4460 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0416
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0450
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 5105.0,                last time consumption/overall running time: 1371.9842s / 26896.4302 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0433
env0_second_0:                 episode reward: -1.7500,                 loss: 0.0402
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 5034.4,                last time consumption/overall running time: 1343.1617s / 28239.5919 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0422
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0414
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 4743.6,                last time consumption/overall running time: 1259.3924s / 29498.9843 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0414
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0415
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 4834.8,                last time consumption/overall running time: 1285.9464s / 30784.9307 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0425
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0441
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 5074.65,                last time consumption/overall running time: 1362.1356s / 32147.0662 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0444
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0457
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 4542.95,                last time consumption/overall running time: 1203.4648s / 33350.5310 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0445
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0427
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 4933.55,                last time consumption/overall running time: 1323.9142s / 34674.4453 s
env0_first_0:                 episode reward: -8.1000,                 loss: 0.0444
env0_second_0:                 episode reward: 8.1000,                 loss: 0.0454
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 4815.95,                last time consumption/overall running time: 1292.2718s / 35966.7171 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0427
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0434
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 5499.05,                last time consumption/overall running time: 1467.8657s / 37434.5828 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0411
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0418
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 5172.0,                last time consumption/overall running time: 1395.9775s / 38830.5603 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0392
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0433
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 4538.15,                last time consumption/overall running time: 1223.9998s / 40054.5601 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0400
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0411
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 4436.0,                last time consumption/overall running time: 1222.0145s / 41276.5746 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0392
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0410
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 4784.65,                last time consumption/overall running time: 1313.5769s / 42590.1515 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0396
env0_second_0:                 episode reward: 4.5000,                 loss: 0.0401
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 4638.25,                last time consumption/overall running time: 1280.3927s / 43870.5442 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0400
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0415
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 4491.6,                last time consumption/overall running time: 1229.0116s / 45099.5558 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0403
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0416
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 4346.15,                last time consumption/overall running time: 1216.2084s / 46315.7642 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0413
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0430
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 4854.95,                last time consumption/overall running time: 1348.3336s / 47664.0978 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0427
env0_second_0:                 episode reward: 5.1000,                 loss: 0.0447
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 4850.6,                last time consumption/overall running time: 1339.4650s / 49003.5628 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0385
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0412
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 4761.65,                last time consumption/overall running time: 1318.5568s / 50322.1196 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0395
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0399
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 4770.35,                last time consumption/overall running time: 1321.7759s / 51643.8955 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0382
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0409
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 4643.3,                last time consumption/overall running time: 1256.6651s / 52900.5606 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0409
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0446
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 4289.4,                last time consumption/overall running time: 1181.5542s / 54082.1148 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0402
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0425
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 5004.95,                last time consumption/overall running time: 1415.5496s / 55497.6645 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0394
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0391
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 4920.55,                last time consumption/overall running time: 1329.2222s / 56826.8866 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0376
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0404
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 4792.2,                last time consumption/overall running time: 1345.7598s / 58172.6465 s
env0_first_0:                 episode reward: -6.2000,                 loss: 0.0444
env0_second_0:                 episode reward: 6.2000,                 loss: 0.0438
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 4742.65,                last time consumption/overall running time: 1312.6096s / 59485.2561 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0419
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0414
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 4238.35,                last time consumption/overall running time: 1168.2622s / 60653.5183 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0395
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0406
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 4776.1,                last time consumption/overall running time: 1341.4206s / 61994.9389 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0394
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0411
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 4824.45,                last time consumption/overall running time: 1322.6987s / 63317.6376 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0412
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0392
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 4781.4,                last time consumption/overall running time: 1333.3814s / 64651.0190 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0410
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0411
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 4697.8,                last time consumption/overall running time: 1286.2971s / 65937.3160 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0422
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0415
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 4817.75,                last time consumption/overall running time: 1336.1773s / 67273.4933 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0395
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0417
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 4775.45,                last time consumption/overall running time: 1307.3341s / 68580.8274 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0400
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0419
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 4812.75,                last time consumption/overall running time: 1334.1923s / 69915.0197 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0389
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0413
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 4776.65,                last time consumption/overall running time: 1304.1155s / 71219.1352 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0384
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0421
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 4720.45,                last time consumption/overall running time: 1294.6268s / 72513.7620 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0416
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0409
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 4992.85,                last time consumption/overall running time: 1392.9320s / 73906.6941 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0375
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0379
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 4619.8,                last time consumption/overall running time: 1254.7991s / 75161.4931 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0395
env0_second_0:                 episode reward: -2.8500,                 loss: 0.0386
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 4935.4,                last time consumption/overall running time: 1371.1735s / 76532.6666 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.0374
env0_second_0:                 episode reward: -3.9000,                 loss: 0.0389
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 5120.5,                last time consumption/overall running time: 1425.4500s / 77958.1166 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0382
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0391
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 4941.3,                last time consumption/overall running time: 1374.6080s / 79332.7246 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0382
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0401
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 4745.95,                last time consumption/overall running time: 1314.4241s / 80647.1487 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0375
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0392
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 5253.0,                last time consumption/overall running time: 1446.1423s / 82093.2910 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.0380
env0_second_0:                 episode reward: -3.4500,                 loss: 0.0394
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 4504.9,                last time consumption/overall running time: 1231.9758s / 83325.2668 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0369
env0_second_0:                 episode reward: -2.8500,                 loss: 0.0378
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 5445.9,                last time consumption/overall running time: 1495.9578s / 84821.2246 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0375
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0374
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 5012.4,                last time consumption/overall running time: 1379.6606s / 86200.8852 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0373
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0379
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 4847.1,                last time consumption/overall running time: 1317.7418s / 87518.6270 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0368
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0391
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 5243.5,                last time consumption/overall running time: 1454.0269s / 88972.6539 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0372
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0374
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 4591.35,                last time consumption/overall running time: 1272.1890s / 90244.8429 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0370
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0384
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 5545.5,                last time consumption/overall running time: 1528.2026s / 91773.0455 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0373
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0380
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 5232.3,                last time consumption/overall running time: 1428.5358s / 93201.5813 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0362
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0372
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 5148.95,                last time consumption/overall running time: 1418.3041s / 94619.8854 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0373
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0382
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 5012.3,                last time consumption/overall running time: 1376.1247s / 95996.0101 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0379
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0379
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 5155.45,                last time consumption/overall running time: 1427.2939s / 97423.3040 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0381
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0381
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 5387.35,                last time consumption/overall running time: 1521.7230s / 98945.0270 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0380
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0377
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 4892.6,                last time consumption/overall running time: 1349.6738s / 100294.7008 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0371
env0_second_0:                 episode reward: -2.5500,                 loss: 0.0378
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 4845.25,                last time consumption/overall running time: 1356.5310s / 101651.2318 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0377
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0369
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 4899.5,                last time consumption/overall running time: 1343.9713s / 102995.2030 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0368
env0_second_0:                 episode reward: -3.6000,                 loss: 0.0368
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 5457.1,                last time consumption/overall running time: 1490.0253s / 104485.2283 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0373
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0368
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 4988.3,                last time consumption/overall running time: 1366.8332s / 105852.0615 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0376
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0370
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 5675.4,                last time consumption/overall running time: 1560.5216s / 107412.5831 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0361
env0_second_0:                 episode reward: -3.6000,                 loss: 0.0369
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 4582.1,                last time consumption/overall running time: 1264.1522s / 108676.7353 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0359
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0356
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 5329.5,                last time consumption/overall running time: 1464.4935s / 110141.2288 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0355
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0371
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 5038.2,                last time consumption/overall running time: 1398.3692s / 111539.5980 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0353
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0367
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 4937.2,                last time consumption/overall running time: 1367.9708s / 112907.5689 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0355
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0389
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 5630.3,                last time consumption/overall running time: 1545.6914s / 114453.2602 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0364
env0_second_0:                 episode reward: -2.7500,                 loss: 0.0358
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 4774.7,                last time consumption/overall running time: 1317.5632s / 115770.8234 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0371
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0369
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 5122.4,                last time consumption/overall running time: 1430.3056s / 117201.1290 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0353
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0378
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 5225.9,                last time consumption/overall running time: 1445.9844s / 118647.1135 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0368
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0362
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 5824.85,                last time consumption/overall running time: 1568.2642s / 120215.3776 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0354
env0_second_0:                 episode reward: -1.9500,                 loss: 0.0361
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 5453.25,                last time consumption/overall running time: 1489.1370s / 121704.5146 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0362
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0355
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 5551.2,                last time consumption/overall running time: 1507.3930s / 123211.9076 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0368
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0365
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 4884.15,                last time consumption/overall running time: 1339.2582s / 124551.1658 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0364
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0369
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 5550.95,                last time consumption/overall running time: 1500.2607s / 126051.4265 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0358
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0359
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 5260.2,                last time consumption/overall running time: 1412.1446s / 127463.5711 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0360
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0369
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 5093.7,                last time consumption/overall running time: 1382.0434s / 128845.6146 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0354
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0358
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 5326.45,                last time consumption/overall running time: 1457.9396s / 130303.5541 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0353
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0366
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 4917.95,                last time consumption/overall running time: 1324.6132s / 131628.1673 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0359
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0369
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 5885.25,                last time consumption/overall running time: 1613.9691s / 133242.1364 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0348
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0352
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 5738.9,                last time consumption/overall running time: 1530.6961s / 134772.8325 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0349
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0348
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 5919.05,                last time consumption/overall running time: 1596.2399s / 136369.0724 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0352
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0356
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 5642.3,                last time consumption/overall running time: 1534.4118s / 137903.4843 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0347
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0356
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 5536.25,                last time consumption/overall running time: 1516.4867s / 139419.9709 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0359
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0358
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 5760.65,                last time consumption/overall running time: 1582.0081s / 141001.9791 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0344
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0355
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 5406.2,                last time consumption/overall running time: 1445.0490s / 142447.0281 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0349
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0345
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 5166.35,                last time consumption/overall running time: 1406.2618s / 143853.2899 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0359
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0363
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 5788.45,                last time consumption/overall running time: 1579.3670s / 145432.6569 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0351
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0346
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 5824.8,                last time consumption/overall running time: 1598.7523s / 147031.4092 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0339
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0358
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 5640.15,                last time consumption/overall running time: 1523.2378s / 148554.6470 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0348
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0357
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 5401.0,                last time consumption/overall running time: 1493.8591s / 150048.5060 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0346
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0355
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 5095.45,                last time consumption/overall running time: 1369.8444s / 151418.3504 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0357
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0358
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 5800.6,                last time consumption/overall running time: 1571.5539s / 152989.9044 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0347
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0353
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 5149.55,                last time consumption/overall running time: 1405.6056s / 154395.5100 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0349
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0355
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 5568.65,                last time consumption/overall running time: 1495.1527s / 155890.6627 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0348
env0_second_0:                 episode reward: 2.1000,                 loss: 0.0358
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 5152.3,                last time consumption/overall running time: 1385.5814s / 157276.2440 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0371
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0361
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 5133.6,                last time consumption/overall running time: 1410.2115s / 158686.4555 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0361
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0352
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 6071.2,                last time consumption/overall running time: 1678.3299s / 160364.7855 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0344
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0335
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 5109.6,                last time consumption/overall running time: 1376.2616s / 161741.0471 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0350
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0345
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 5141.8,                last time consumption/overall running time: 1380.9723s / 163122.0194 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0356
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0356
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 5086.8,                last time consumption/overall running time: 1377.4876s / 164499.5070 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0352
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0355
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 5544.1,                last time consumption/overall running time: 1506.0943s / 166005.6013 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0351
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0346
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 4899.05,                last time consumption/overall running time: 1301.3816s / 167306.9830 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0353
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0359
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 5202.0,                last time consumption/overall running time: 1461.7061s / 168768.6891 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0363
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0353
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 5227.05,                last time consumption/overall running time: 1409.9655s / 170178.6546 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0339
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0350
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 5000.75,                last time consumption/overall running time: 1387.7055s / 171566.3601 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0355
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0359
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 5404.3,                last time consumption/overall running time: 1437.9568s / 173004.3170 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0362
env0_second_0:                 episode reward: 4.5000,                 loss: 0.0358
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 5382.05,                last time consumption/overall running time: 1449.7646s / 174454.0815 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0338
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0357
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 5220.85,                last time consumption/overall running time: 1417.9595s / 175872.0410 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0349
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0361
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 4715.95,                last time consumption/overall running time: 1267.7393s / 177139.7803 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0355
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0361
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 5130.45,                last time consumption/overall running time: 1375.7372s / 178515.5176 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0361
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0367
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 5152.5,                last time consumption/overall running time: 1373.9973s / 179889.5148 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0343
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0345
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 5225.75,                last time consumption/overall running time: 1392.8691s / 181282.3839 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0336
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0350
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 5352.6,                last time consumption/overall running time: 1437.8210s / 182720.2049 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0344
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0353
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 5615.05,                last time consumption/overall running time: 1515.1967s / 184235.4015 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0351
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0361
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 5011.85,                last time consumption/overall running time: 1377.8236s / 185613.2252 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0340
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0334
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 5548.3,                last time consumption/overall running time: 1475.8195s / 187089.0446 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0355
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0340
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 4837.95,                last time consumption/overall running time: 1312.6677s / 188401.7123 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0343
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0353
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 5028.6,                last time consumption/overall running time: 1340.8662s / 189742.5786 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0367
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0355
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 5671.85,                last time consumption/overall running time: 1516.7992s / 191259.3778 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0347
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0355
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 5322.6,                last time consumption/overall running time: 1427.7766s / 192687.1544 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0345
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0342
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 5233.6,                last time consumption/overall running time: 1382.3305s / 194069.4849 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0343
env0_second_0:                 episode reward: 4.9500,                 loss: 0.0345
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 5184.3,                last time consumption/overall running time: 1373.6056s / 195443.0905 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.0346
env0_second_0:                 episode reward: 4.8000,                 loss: 0.0348
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 4641.75,                last time consumption/overall running time: 1245.5518s / 196688.6423 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0348
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0358
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 5451.9,                last time consumption/overall running time: 1453.8552s / 198142.4974 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0349
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0359
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 5198.55,                last time consumption/overall running time: 1409.0448s / 199551.5423 s
env0_first_0:                 episode reward: 5.2500,                 loss: 0.0345
env0_second_0:                 episode reward: -5.2500,                 loss: 0.0343
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 5083.6,                last time consumption/overall running time: 1387.4221s / 200938.9644 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0343
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0353
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 5675.7,                last time consumption/overall running time: 1529.7000s / 202468.6644 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0339
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0346
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 5270.3,                last time consumption/overall running time: 1429.0240s / 203897.6884 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0341
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0344
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 5618.5,                last time consumption/overall running time: 1504.0056s / 205401.6940 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0346
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0352
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 5288.9,                last time consumption/overall running time: 1400.5339s / 206802.2279 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0350
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0347
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 5244.95,                last time consumption/overall running time: 1425.8861s / 208228.1141 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0338
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0350
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 5287.05,                last time consumption/overall running time: 1431.3967s / 209659.5108 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0343
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0354
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 4965.55,                last time consumption/overall running time: 1327.0235s / 210986.5343 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0348
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0345
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 5517.8,                last time consumption/overall running time: 1469.9441s / 212456.4784 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0350
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0360
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 5467.1,                last time consumption/overall running time: 1469.0865s / 213925.5649 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0334
env0_second_0:                 episode reward: -2.6500,                 loss: 0.0351
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 5442.95,                last time consumption/overall running time: 1465.5559s / 215391.1209 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0338
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0350
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 5175.0,                last time consumption/overall running time: 1376.1471s / 216767.2680 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0335
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0343
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 5582.3,                last time consumption/overall running time: 1489.7852s / 218257.0532 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0336
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0348
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 5588.3,                last time consumption/overall running time: 1500.9702s / 219758.0234 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0340
env0_second_0:                 episode reward: -2.7500,                 loss: 0.0347
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 5577.95,                last time consumption/overall running time: 1509.1250s / 221267.1484 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.0332
env0_second_0:                 episode reward: 4.3500,                 loss: 0.0349
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 5860.0,                last time consumption/overall running time: 1581.4436s / 222848.5919 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0349
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0365
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 5029.75,                last time consumption/overall running time: 1340.2375s / 224188.8295 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0346
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0350
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 5706.65,                last time consumption/overall running time: 1540.2685s / 225729.0980 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0341
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0343
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 5040.15,                last time consumption/overall running time: 1350.5121s / 227079.6101 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0335
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0341
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 5234.6,                last time consumption/overall running time: 1387.2522s / 228466.8623 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0338
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0344
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 5713.2,                last time consumption/overall running time: 1515.7726s / 229982.6350 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0342
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0349
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 5570.65,                last time consumption/overall running time: 1488.0199s / 231470.6549 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0332
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0341
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 5149.15,                last time consumption/overall running time: 1409.9454s / 232880.6003 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0338
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0340
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 5229.0,                last time consumption/overall running time: 1428.1024s / 234308.7026 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0338
env0_second_0:                 episode reward: -2.2000,                 loss: 0.0341
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 5192.7,                last time consumption/overall running time: 1417.8796s / 235726.5823 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0344
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0353
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 5474.4,                last time consumption/overall running time: 1496.6948s / 237223.2771 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0350
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0359
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 5426.2,                last time consumption/overall running time: 1488.4442s / 238711.7213 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0344
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0342
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 4998.0,                last time consumption/overall running time: 1403.1319s / 240114.8532 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0331
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0347
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 5412.1,                last time consumption/overall running time: 1493.8826s / 241608.7358 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0350
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0353
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 5341.05,                last time consumption/overall running time: 1444.3938s / 243053.1296 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0347
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0354
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 4870.7,                last time consumption/overall running time: 1322.2336s / 244375.3631 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0333
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0336
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 5467.55,                last time consumption/overall running time: 1505.3971s / 245880.7603 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0341
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0340
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 5332.15,                last time consumption/overall running time: 1471.4992s / 247352.2595 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0337
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0346
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 5952.25,                last time consumption/overall running time: 1624.8745s / 248977.1340 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0343
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0351
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 5080.65,                last time consumption/overall running time: 1415.7393s / 250392.8733 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0332
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0357
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 5886.7,                last time consumption/overall running time: 1642.9081s / 252035.7814 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0344
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0353
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 4959.1,                last time consumption/overall running time: 1387.7478s / 253423.5292 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0343
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0357
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 5202.3,                last time consumption/overall running time: 1445.9081s / 254869.4372 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0349
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0342
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 5488.7,                last time consumption/overall running time: 1503.5745s / 256373.0118 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0343
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0340
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 5383.15,                last time consumption/overall running time: 1513.9895s / 257887.0013 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0330
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0342
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 4942.65,                last time consumption/overall running time: 1380.9405s / 259267.9418 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0329
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0337
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 5710.8,                last time consumption/overall running time: 1598.7978s / 260866.7396 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0338
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0349
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 5679.45,                last time consumption/overall running time: 1525.4344s / 262392.1740 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0336
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0354
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 5068.2,                last time consumption/overall running time: 1408.2148s / 263800.3889 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0345
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0354
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 5080.0,                last time consumption/overall running time: 1378.9190s / 265179.3078 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0347
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0346
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 5357.15,                last time consumption/overall running time: 1507.3692s / 266686.6770 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0351
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0364
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 4812.55,                last time consumption/overall running time: 1334.1929s / 268020.8699 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0344
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0351
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 5103.0,                last time consumption/overall running time: 1401.2454s / 269422.1153 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0352
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0353
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 5401.15,                last time consumption/overall running time: 1508.3365s / 270930.4518 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0346
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0352
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 5624.45,                last time consumption/overall running time: 1576.5835s / 272507.0353 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0343
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0340
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 5401.2,                last time consumption/overall running time: 1486.2253s / 273993.2607 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0336
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0346
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 4845.0,                last time consumption/overall running time: 1353.0658s / 275346.3265 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0345
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0337
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 5173.9,                last time consumption/overall running time: 1404.7139s / 276751.0404 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.0334
env0_second_0:                 episode reward: 6.1500,                 loss: 0.0343
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 5172.05,                last time consumption/overall running time: 1446.1022s / 278197.1427 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0339
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0340
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 5652.9,                last time consumption/overall running time: 1579.4091s / 279776.5518 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0338
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0345
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 5792.5,                last time consumption/overall running time: 1585.2392s / 281361.7910 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0340
env0_second_0:                 episode reward: -1.8000,                 loss: 0.0341
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 5260.0,                last time consumption/overall running time: 1505.1349s / 282866.9260 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0338
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0335
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 5118.6,                last time consumption/overall running time: 1450.5619s / 284317.4879 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0342
env0_second_0:                 episode reward: 5.1000,                 loss: 0.0331
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 5466.9,                last time consumption/overall running time: 1457.0783s / 285774.5662 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0337
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0338
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 4949.95,                last time consumption/overall running time: 1306.9146s / 287081.4808 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0338
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0342
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 5466.9,                last time consumption/overall running time: 1455.7634s / 288537.2442 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0332
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0335
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 5710.05,                last time consumption/overall running time: 1505.1992s / 290042.4434 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0334
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0341
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 5471.45,                last time consumption/overall running time: 1464.6516s / 291507.0950 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0339
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0346
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 5350.1,                last time consumption/overall running time: 1434.4535s / 292941.5486 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0343
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0335
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 5572.4,                last time consumption/overall running time: 1503.1787s / 294444.7273 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0342
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0349
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 5484.7,                last time consumption/overall running time: 1448.8046s / 295893.5319 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0336
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0338
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 4994.5,                last time consumption/overall running time: 1326.8037s / 297220.3356 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0343
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0351
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 5218.0,                last time consumption/overall running time: 1377.8663s / 298598.2019 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0352
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0346
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 5228.3,                last time consumption/overall running time: 1387.9496s / 299986.1515 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0331
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0342
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 5621.35,                last time consumption/overall running time: 1482.7076s / 301468.8591 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0345
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0349
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 5300.15,                last time consumption/overall running time: 1399.5035s / 302868.3627 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0342
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0340
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 4968.65,                last time consumption/overall running time: 1330.0478s / 304198.4105 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0350
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0356
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 5361.55,                last time consumption/overall running time: 1447.1751s / 305645.5856 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0350
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0350
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 5461.2,                last time consumption/overall running time: 1431.2548s / 307076.8403 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0331
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0335
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 4996.05,                last time consumption/overall running time: 1359.7667s / 308436.6071 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0343
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0348
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 4898.7,                last time consumption/overall running time: 1312.4901s / 309749.0972 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0352
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0346
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 5526.25,                last time consumption/overall running time: 1479.7144s / 311228.8116 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0341
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0345
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 5514.05,                last time consumption/overall running time: 1456.4887s / 312685.3003 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0343
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0346
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 6105.3,                last time consumption/overall running time: 1650.3910s / 314335.6913 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0334
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0342
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 4896.55,                last time consumption/overall running time: 1329.9282s / 315665.6195 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0340
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0353
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 5057.6,                last time consumption/overall running time: 1376.5878s / 317042.2073 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.0349
env0_second_0:                 episode reward: 4.9500,                 loss: 0.0339
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 5186.3,                last time consumption/overall running time: 1398.4899s / 318440.6971 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0333
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0339
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 5383.7,                last time consumption/overall running time: 1442.3676s / 319883.0647 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0334
env0_second_0:                 episode reward: -2.6000,                 loss: 0.0341
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 5668.35,                last time consumption/overall running time: 1507.4522s / 321390.5169 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0338
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0340
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 5184.75,                last time consumption/overall running time: 1368.4440s / 322758.9609 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0344
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0347
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 5044.75,                last time consumption/overall running time: 1326.4764s / 324085.4373 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0342
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0345
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 4902.85,                last time consumption/overall running time: 1273.3049s / 325358.7422 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0352
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0351
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 6169.3,                last time consumption/overall running time: 1601.6310s / 326960.3732 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0339
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0344
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 5216.75,                last time consumption/overall running time: 1425.1955s / 328385.5687 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0351
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0343
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 5369.9,                last time consumption/overall running time: 1445.5362s / 329831.1049 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0336
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0340
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 5236.5,                last time consumption/overall running time: 1403.2157s / 331234.3206 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0334
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0335
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 5880.1,                last time consumption/overall running time: 1561.2542s / 332795.5748 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0346
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0351
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 5423.85,                last time consumption/overall running time: 1446.7561s / 334242.3310 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0338
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0328
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 5239.55,                last time consumption/overall running time: 1361.5992s / 335603.9302 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0343
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0346
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 5062.75,                last time consumption/overall running time: 1360.4513s / 336964.3815 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0338
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0347
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 5009.05,                last time consumption/overall running time: 1368.7810s / 338333.1625 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0343
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0341
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 5404.15,                last time consumption/overall running time: 1457.1326s / 339790.2951 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0341
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0337
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 5248.75,                last time consumption/overall running time: 1399.8046s / 341190.0997 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0338
env0_second_0:                 episode reward: -3.3000,                 loss: 0.0343
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 5059.95,                last time consumption/overall running time: 1340.6173s / 342530.7170 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0332
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0338
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 5429.75,                last time consumption/overall running time: 1464.4930s / 343995.2100 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0355
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0345
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 5812.4,                last time consumption/overall running time: 1576.0925s / 345571.3025 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0334
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0344
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 5476.6,                last time consumption/overall running time: 1460.0380s / 347031.3405 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.0336
env0_second_0:                 episode reward: -2.2500,                 loss: 0.0336
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 5215.15,                last time consumption/overall running time: 1389.5028s / 348420.8432 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0340
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0341
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 5726.0,                last time consumption/overall running time: 1478.5696s / 349899.4128 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0343
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0339
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 5369.7,                last time consumption/overall running time: 1451.9734s / 351351.3862 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0349
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0348
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 4889.9,                last time consumption/overall running time: 1294.9819s / 352646.3681 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0345
env0_second_0:                 episode reward: -2.3000,                 loss: 0.0345
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 5750.65,                last time consumption/overall running time: 1532.3798s / 354178.7479 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0341
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0349
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 6106.5,                last time consumption/overall running time: 1662.5661s / 355841.3140 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0335
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0335
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 5247.5,                last time consumption/overall running time: 1425.2066s / 357266.5206 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0345
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0340
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 5764.1,                last time consumption/overall running time: 1565.8480s / 358832.3685 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0348
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0347
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 5712.7,                last time consumption/overall running time: 1512.9491s / 360345.3176 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0339
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0345
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 5556.6,                last time consumption/overall running time: 1493.2994s / 361838.6171 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0339
env0_second_0:                 episode reward: -2.2000,                 loss: 0.0353
env1_first_0:                 episode reward: 5.7000,                 loss: nan
env1_second_0:                 episode reward: -5.7000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 5511.2,                last time consumption/overall running time: 1474.3654s / 363312.9824 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0351
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0348
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 5212.55,                last time consumption/overall running time: 1404.7584s / 364717.7409 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0338
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0347
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 4628.6,                last time consumption/overall running time: 1243.0809s / 365960.8218 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0352
env0_second_0:                 episode reward: -2.9000,                 loss: 0.0347
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 5414.0,                last time consumption/overall running time: 1464.1921s / 367425.0139 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0341
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0350
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 5048.6,                last time consumption/overall running time: 1357.3230s / 368782.3369 s
env0_first_0:                 episode reward: -5.5000,                 loss: 0.0339
env0_second_0:                 episode reward: 5.5000,                 loss: 0.0346
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 6017.0,                last time consumption/overall running time: 1610.6021s / 370392.9390 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.0347
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0350
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 5115.8,                last time consumption/overall running time: 1381.5957s / 371774.5347 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0345
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0347
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 5249.5,                last time consumption/overall running time: 1435.8400s / 373210.3747 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0345
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0344
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 5727.2,                last time consumption/overall running time: 1545.6049s / 374755.9796 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0334
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0344
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 5850.35,                last time consumption/overall running time: 1568.6264s / 376324.6059 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0340
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0344
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 5712.85,                last time consumption/overall running time: 1524.6722s / 377849.2781 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0341
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0348
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 5725.95,                last time consumption/overall running time: 1527.3784s / 379376.6565 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0340
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0337
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 5280.9,                last time consumption/overall running time: 1412.9460s / 380789.6025 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0355
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0368
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 5603.15,                last time consumption/overall running time: 1495.5429s / 382285.1453 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0353
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0367
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 5565.7,                last time consumption/overall running time: 1511.1069s / 383796.2523 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0340
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0345
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 5279.85,                last time consumption/overall running time: 1428.2080s / 385224.4603 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0335
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0343
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 5332.9,                last time consumption/overall running time: 1438.4150s / 386662.8753 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0333
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0331
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 5346.25,                last time consumption/overall running time: 1436.7720s / 388099.6473 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0342
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0335
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 5485.8,                last time consumption/overall running time: 1488.8136s / 389588.4609 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0338
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0334
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 5086.05,                last time consumption/overall running time: 1371.2285s / 390959.6894 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0343
env0_second_0:                 episode reward: -2.1000,                 loss: 0.0345
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 5772.3,                last time consumption/overall running time: 1567.7969s / 392527.4864 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0347
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0346
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 4909.2,                last time consumption/overall running time: 1326.4726s / 393853.9590 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0344
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0342
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 5694.8,                last time consumption/overall running time: 1529.8896s / 395383.8486 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0342
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0349
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 5142.0,                last time consumption/overall running time: 1393.4556s / 396777.3042 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0333
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0346
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 5610.6,                last time consumption/overall running time: 1489.0541s / 398266.3583 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0333
env0_second_0:                 episode reward: -2.3500,                 loss: 0.0344
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 5127.4,                last time consumption/overall running time: 1390.5279s / 399656.8861 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0337
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0338
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 5602.8,                last time consumption/overall running time: 1509.7608s / 401166.6470 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0343
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0341
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 5440.45,                last time consumption/overall running time: 1448.8289s / 402615.4759 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0338
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0342
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 5327.9,                last time consumption/overall running time: 1394.9512s / 404010.4271 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0342
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0343
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 5070.9,                last time consumption/overall running time: 1339.4498s / 405349.8770 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0340
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0337
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 5953.8,                last time consumption/overall running time: 1585.1020s / 406934.9790 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0342
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0346
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 5914.1,                last time consumption/overall running time: 1600.6963s / 408535.6753 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0332
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0338
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 5553.0,                last time consumption/overall running time: 1510.6085s / 410046.2838 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0342
env0_second_0:                 episode reward: -3.5000,                 loss: 0.0341
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 5290.8,                last time consumption/overall running time: 1407.8314s / 411454.1152 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0337
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0343
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 5662.4,                last time consumption/overall running time: 1496.2543s / 412950.3695 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0348
env0_second_0:                 episode reward: -2.0500,                 loss: 0.0347
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 5461.0,                last time consumption/overall running time: 1453.2393s / 414403.6089 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0344
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0340
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 5014.2,                last time consumption/overall running time: 1330.0212s / 415733.6301 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0348
env0_second_0:                 episode reward: 1.8000,                 loss: 0.0344
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 5523.05,                last time consumption/overall running time: 1510.7987s / 417244.4288 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0345
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0346
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 5458.9,                last time consumption/overall running time: 1442.9150s / 418687.3437 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0341
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0340
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 5553.2,                last time consumption/overall running time: 1480.5453s / 420167.8890 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0331
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0335
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 5248.75,                last time consumption/overall running time: 1424.4452s / 421592.3342 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0344
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0346
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 5539.05,                last time consumption/overall running time: 1491.2578s / 423083.5921 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0344
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0339
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 5700.35,                last time consumption/overall running time: 1517.8959s / 424601.4880 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0356
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0347
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 5144.45,                last time consumption/overall running time: 1384.6865s / 425986.1745 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0347
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0355
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 5752.3,                last time consumption/overall running time: 1537.5701s / 427523.7446 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0344
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0353
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 5816.05,                last time consumption/overall running time: 1544.2251s / 429067.9697 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0344
env0_second_0:                 episode reward: 1.8000,                 loss: 0.0347
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 6050.9,                last time consumption/overall running time: 1623.1510s / 430691.1208 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0336
env0_second_0:                 episode reward: -3.0000,                 loss: 0.0333
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 5773.25,                last time consumption/overall running time: 1550.8331s / 432241.9538 s
env0_first_0:                 episode reward: 4.0500,                 loss: 0.0342
env0_second_0:                 episode reward: -4.0500,                 loss: 0.0352
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 5981.95,                last time consumption/overall running time: 1608.8234s / 433850.7772 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0343
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0343
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 5108.65,                last time consumption/overall running time: 1383.2690s / 435234.0462 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.0349
env0_second_0:                 episode reward: -3.8500,                 loss: 0.0350
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 5172.25,                last time consumption/overall running time: 1393.3674s / 436627.4137 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0349
env0_second_0:                 episode reward: -2.3500,                 loss: 0.0349
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 5860.3,                last time consumption/overall running time: 1586.2370s / 438213.6506 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0355
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0348
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 5613.65,                last time consumption/overall running time: 1512.9748s / 439726.6254 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0344
env0_second_0:                 episode reward: -2.3000,                 loss: 0.0333
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 5422.8,                last time consumption/overall running time: 1473.4081s / 441200.0335 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0335
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0340
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 5499.7,                last time consumption/overall running time: 1500.4535s / 442700.4870 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0347
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0344
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 5525.5,                last time consumption/overall running time: 1480.1725s / 444180.6595 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0356
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0343
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 5890.3,                last time consumption/overall running time: 1580.3785s / 445761.0380 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0351
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0338
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 5458.6,                last time consumption/overall running time: 1461.2762s / 447222.3142 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0349
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0344
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 5362.3,                last time consumption/overall running time: 1396.4330s / 448618.7472 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0342
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0342
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 4900.0,                last time consumption/overall running time: 1324.0396s / 449942.7869 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0352
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0351
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 5459.65,                last time consumption/overall running time: 1480.4815s / 451423.2684 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0334
env0_second_0:                 episode reward: -2.7500,                 loss: 0.0336
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 5115.35,                last time consumption/overall running time: 1362.6237s / 452785.8920 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0337
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0343
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 5430.35,                last time consumption/overall running time: 1468.6428s / 454254.5348 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0343
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0345
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 5335.35,                last time consumption/overall running time: 1447.3730s / 455701.9078 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0342
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0345
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 5314.75,                last time consumption/overall running time: 1426.8070s / 457128.7149 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0346
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0341
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 5541.65,                last time consumption/overall running time: 1497.0715s / 458625.7864 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0342
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0342
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 5982.7,                last time consumption/overall running time: 1631.3405s / 460257.1269 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0343
env0_second_0:                 episode reward: -2.7000,                 loss: 0.0333
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 5598.9,                last time consumption/overall running time: 1525.4731s / 461782.6001 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0334
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0333
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 5461.2,                last time consumption/overall running time: 1468.2258s / 463250.8259 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0338
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0337
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 6033.75,                last time consumption/overall running time: 1640.4322s / 464891.2581 s
env0_first_0:                 episode reward: 5.6500,                 loss: 0.0339
env0_second_0:                 episode reward: -5.6500,                 loss: 0.0341
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 5732.4,                last time consumption/overall running time: 1557.1355s / 466448.3936 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0336
env0_second_0:                 episode reward: -2.7500,                 loss: 0.0333
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 5422.8,                last time consumption/overall running time: 1456.4697s / 467904.8633 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0340
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0345
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 5021.45,                last time consumption/overall running time: 1359.8532s / 469264.7165 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0355
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0356
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 5730.5,                last time consumption/overall running time: 1558.3809s / 470823.0974 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0336
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0343
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 5686.1,                last time consumption/overall running time: 1538.6229s / 472361.7203 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0342
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0355
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 5379.1,                last time consumption/overall running time: 1462.9094s / 473824.6297 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0351
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0351
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 5469.9,                last time consumption/overall running time: 1475.5635s / 475300.1932 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0343
env0_second_0:                 episode reward: -2.2000,                 loss: 0.0334
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 5234.85,                last time consumption/overall running time: 1419.8721s / 476720.0653 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0349
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0346
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 4843.1,                last time consumption/overall running time: 1316.0286s / 478036.0939 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0349
env0_second_0:                 episode reward: -1.9500,                 loss: 0.0350
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 5720.85,                last time consumption/overall running time: 1554.7862s / 479590.8800 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0346
env0_second_0:                 episode reward: -2.3000,                 loss: 0.0347
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 5368.6,                last time consumption/overall running time: 1468.4949s / 481059.3750 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0358
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0344
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 5854.9,                last time consumption/overall running time: 1606.7050s / 482666.0800 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0340
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0332
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 5742.35,                last time consumption/overall running time: 1570.6848s / 484236.7647 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0340
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0345
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 5072.3,                last time consumption/overall running time: 1380.1579s / 485616.9227 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0346
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0346
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 5570.65,                last time consumption/overall running time: 1510.6596s / 487127.5822 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0338
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0352
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 4939.9,                last time consumption/overall running time: 1307.1035s / 488434.6857 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.0334
env0_second_0:                 episode reward: 4.7000,                 loss: 0.0338
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 4847.0,                last time consumption/overall running time: 1361.2966s / 489795.9823 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0345
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0347
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 5755.2,                last time consumption/overall running time: 1645.1441s / 491441.1263 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0338
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0334
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 5789.85,                last time consumption/overall running time: 1659.1276s / 493100.2539 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0335
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0345
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 5437.65,                last time consumption/overall running time: 1586.8924s / 494687.1463 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0348
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0345
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 5472.95,                last time consumption/overall running time: 1530.7695s / 496217.9158 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0343
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0347
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 5308.05,                last time consumption/overall running time: 1489.6859s / 497707.6017 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0342
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0337
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 5890.45,                last time consumption/overall running time: 1654.6894s / 499362.2911 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0339
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0334
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 4834.6,                last time consumption/overall running time: 1345.2353s / 500707.5264 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0333
env0_second_0:                 episode reward: -2.1000,                 loss: 0.0336
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 5751.55,                last time consumption/overall running time: 1611.8609s / 502319.3873 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0328
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0338
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 6157.4,                last time consumption/overall running time: 1737.7755s / 504057.1628 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0335
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0332
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 5985.05,                last time consumption/overall running time: 1682.3695s / 505739.5323 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0333
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0337
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 5580.25,                last time consumption/overall running time: 1579.1449s / 507318.6772 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0343
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0339
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 5381.1,                last time consumption/overall running time: 1500.0939s / 508818.7711 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0341
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0331
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 5093.05,                last time consumption/overall running time: 1446.9320s / 510265.7031 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0350
env0_second_0:                 episode reward: -2.4500,                 loss: 0.0345
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 5277.7,                last time consumption/overall running time: 1468.4695s / 511734.1726 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0349
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0349
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 5278.15,                last time consumption/overall running time: 1480.5977s / 513214.7703 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0341
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0348
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 5341.2,                last time consumption/overall running time: 1492.7084s / 514707.4787 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0342
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0348
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 6003.45,                last time consumption/overall running time: 1693.2603s / 516400.7389 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0345
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0334
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 5458.35,                last time consumption/overall running time: 1520.4462s / 517921.1852 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0342
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0344
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 5839.1,                last time consumption/overall running time: 1627.3502s / 519548.5354 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0338
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0340
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 5712.15,                last time consumption/overall running time: 1592.7825s / 521141.3179 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0337
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0338
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 4887.05,                last time consumption/overall running time: 1355.6234s / 522496.9413 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0342
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0338
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 5392.3,                last time consumption/overall running time: 1498.3489s / 523995.2902 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0340
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0341
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 5624.1,                last time consumption/overall running time: 1574.3455s / 525569.6358 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0338
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0328
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 5131.45,                last time consumption/overall running time: 1434.5264s / 527004.1622 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0339
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0341
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 5381.1,                last time consumption/overall running time: 1498.9086s / 528503.0708 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0352
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0350
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 5424.0,                last time consumption/overall running time: 1507.8714s / 530010.9422 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0336
env0_second_0:                 episode reward: -2.0500,                 loss: 0.0340
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 5573.95,                last time consumption/overall running time: 1552.2661s / 531563.2083 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0336
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0337
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 5673.55,                last time consumption/overall running time: 1582.6018s / 533145.8100 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0345
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0348
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 5001.4,                last time consumption/overall running time: 1395.5012s / 534541.3112 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0348
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0346
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 5454.4,                last time consumption/overall running time: 1525.2230s / 536066.5342 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0349
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0357
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 5199.35,                last time consumption/overall running time: 1448.5018s / 537515.0360 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0343
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0342
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 5655.25,                last time consumption/overall running time: 1584.0546s / 539099.0906 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0338
env0_second_0:                 episode reward: 1.8000,                 loss: 0.0332
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 4852.7,                last time consumption/overall running time: 1355.0752s / 540454.1658 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0340
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0346
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 5124.9,                last time consumption/overall running time: 1391.2395s / 541845.4053 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0344
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0353
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 5620.55,                last time consumption/overall running time: 1564.2058s / 543409.6111 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.0336
env0_second_0:                 episode reward: 5.1000,                 loss: 0.0343
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 5011.2,                last time consumption/overall running time: 1373.2491s / 544782.8601 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0335
env0_second_0:                 episode reward: -2.7000,                 loss: 0.0347
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 5757.6,                last time consumption/overall running time: 1566.3163s / 546349.1765 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0346
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0349
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 5176.0,                last time consumption/overall running time: 1407.9009s / 547757.0773 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0347
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0343
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 6192.45,                last time consumption/overall running time: 1712.5265s / 549469.6038 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0340
env0_second_0:                 episode reward: -2.3000,                 loss: 0.0333
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 5454.25,                last time consumption/overall running time: 1511.7064s / 550981.3103 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0343
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0341
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 5646.9,                last time consumption/overall running time: 1585.4257s / 552566.7359 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0349
env0_second_0:                 episode reward: 4.3000,                 loss: 0.0346
env1_first_0:                 episode reward: 6.9500,                 loss: nan
env1_second_0:                 episode reward: -6.9500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 5101.05,                last time consumption/overall running time: 1424.8700s / 553991.6059 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0367
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0366
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 5627.4,                last time consumption/overall running time: 1570.0045s / 555561.6105 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0345
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0335
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 5263.0,                last time consumption/overall running time: 1466.6595s / 557028.2700 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0352
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0359
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 5360.2,                last time consumption/overall running time: 1496.0109s / 558524.2809 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0351
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0344
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 5130.75,                last time consumption/overall running time: 1436.6527s / 559960.9336 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0340
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0343
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 4844.65,                last time consumption/overall running time: 1354.8244s / 561315.7580 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0354
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0348
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 4952.3,                last time consumption/overall running time: 1391.8964s / 562707.6545 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0335
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0339
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 5485.75,                last time consumption/overall running time: 1526.8576s / 564234.5121 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0342
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0354
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 5811.6,                last time consumption/overall running time: 1638.8537s / 565873.3658 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0339
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0342
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 5212.35,                last time consumption/overall running time: 1461.4396s / 567334.8054 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.0339
env0_second_0:                 episode reward: -4.2500,                 loss: 0.0347
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 4933.0,                last time consumption/overall running time: 1375.6011s / 568710.4065 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0342
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0349
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 5384.15,                last time consumption/overall running time: 1501.8586s / 570212.2651 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0339
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0345
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 5586.35,                last time consumption/overall running time: 1560.0788s / 571772.3439 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0331
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0335
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 5257.9,                last time consumption/overall running time: 1467.1408s / 573239.4847 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0343
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0336
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 5792.4,                last time consumption/overall running time: 1615.2565s / 574854.7412 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0346
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0347
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 5668.65,                last time consumption/overall running time: 1584.0698s / 576438.8110 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0342
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0351
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 5471.85,                last time consumption/overall running time: 1527.4012s / 577966.2122 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0341
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0339
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 5229.75,                last time consumption/overall running time: 1455.1132s / 579421.3254 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0335
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0341
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 5112.85,                last time consumption/overall running time: 1425.8518s / 580847.1772 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0347
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0342
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 5583.25,                last time consumption/overall running time: 1557.9277s / 582405.1049 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0352
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0353
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 5347.1,                last time consumption/overall running time: 1488.7831s / 583893.8880 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0347
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0358
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 5576.95,                last time consumption/overall running time: 1546.0361s / 585439.9241 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0351
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0340
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 5518.35,                last time consumption/overall running time: 1542.7753s / 586982.6994 s
env0_first_0:                 episode reward: 9.2000,                 loss: 0.0363
env0_second_0:                 episode reward: -9.2000,                 loss: 0.0362
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 4853.55,                last time consumption/overall running time: 1351.4723s / 588334.1717 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0342
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0343
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 5442.8,                last time consumption/overall running time: 1530.8350s / 589865.0067 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0356
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0352
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 5963.75,                last time consumption/overall running time: 1701.6161s / 591566.6228 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0339
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0342
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 5330.85,                last time consumption/overall running time: 1575.6508s / 593142.2737 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0331
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0330
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 5253.5,                last time consumption/overall running time: 1479.9597s / 594622.2334 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0353
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0355
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 4798.25,                last time consumption/overall running time: 1349.0017s / 595971.2351 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0347
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0342
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 5587.7,                last time consumption/overall running time: 1573.5697s / 597544.8048 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0348
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0345
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 5213.75,                last time consumption/overall running time: 1486.5019s / 599031.3067 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0341
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0346
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 5366.55,                last time consumption/overall running time: 1535.0315s / 600566.3382 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0345
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0341
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 5254.15,                last time consumption/overall running time: 1498.7572s / 602065.0954 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0351
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0350
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 5457.65,                last time consumption/overall running time: 1520.8552s / 603585.9506 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0351
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0346
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 5916.4,                last time consumption/overall running time: 1641.6507s / 605227.6013 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0337
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0342
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 5536.0,                last time consumption/overall running time: 1532.4085s / 606760.0098 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0341
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0341
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 5332.8,                last time consumption/overall running time: 1478.4210s / 608238.4308 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0337
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0342
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 5650.1,                last time consumption/overall running time: 1576.9374s / 609815.3682 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0346
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0356
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 5227.0,                last time consumption/overall running time: 1457.8572s / 611273.2254 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0338
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0346
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 5749.7,                last time consumption/overall running time: 1602.8056s / 612876.0309 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0342
env0_second_0:                 episode reward: -3.2000,                 loss: 0.0346
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 5287.7,                last time consumption/overall running time: 1487.7078s / 614363.7388 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0349
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0355
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 5245.5,                last time consumption/overall running time: 1465.7595s / 615829.4983 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0349
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0348
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 5161.65,                last time consumption/overall running time: 1443.1257s / 617272.6239 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0342
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0341
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 5453.25,                last time consumption/overall running time: 1516.7585s / 618789.3824 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0350
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0347
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 5406.55,                last time consumption/overall running time: 1495.1074s / 620284.4898 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0340
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0337
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 6298.5,                last time consumption/overall running time: 1748.7887s / 622033.2785 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0344
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0343
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 5960.55,                last time consumption/overall running time: 1659.4209s / 623692.6994 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.0343
env0_second_0:                 episode reward: 4.8000,                 loss: 0.0343
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 5203.4,                last time consumption/overall running time: 1459.4525s / 625152.1520 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0339
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0354
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 4814.0,                last time consumption/overall running time: 1343.0717s / 626495.2237 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0348
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0348
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 5628.2,                last time consumption/overall running time: 1580.0989s / 628075.3226 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0350
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0342
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 6318.7,                last time consumption/overall running time: 1757.8287s / 629833.1513 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0343
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0339
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 5190.55,                last time consumption/overall running time: 1455.1685s / 631288.3199 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0351