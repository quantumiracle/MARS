pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 5, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220206_0346/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220206_0346/pettingzoo_boxing_v1_nash_dqn.
Episode: 1/10000 (0.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 14.3539s / 14.3539 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.0648
env0_second_0:                 episode reward: 5.0000,                 loss: 0.0635
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 377.7327s / 392.0866 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0835
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0836
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 455.8157s / 847.9023 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0848
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0855
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 477.1831s / 1325.0854 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0866
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0862
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 512.1161s / 1837.2015 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0848
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0851
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 502.9240s / 2340.1255 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0863
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0839
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 503.8696s / 2843.9951 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0883
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0884
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 501.8476s / 3345.8426 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0958
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0985
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 507.4906s / 3853.3332 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0998
env0_second_0:                 episode reward: 3.7500,                 loss: 0.1007
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 511.0390s / 4364.3722 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0991
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0954
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 498.9378s / 4863.3100 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0973
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0967
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 504.6413s / 5367.9514 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0966
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0984
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 497.1859s / 5865.1372 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0997
env0_second_0:                 episode reward: 1.4500,                 loss: 0.1020
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 507.4740s / 6372.6112 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0988
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1003
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 519.2823s / 6891.8935 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.1039
env0_second_0:                 episode reward: 1.5500,                 loss: 0.1027
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 496.5685s / 7388.4620 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.1053
env0_second_0:                 episode reward: 6.3000,                 loss: 0.1056
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 501.6600s / 7890.1220 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1186
env0_second_0:                 episode reward: 4.0500,                 loss: 0.1200
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 501.8996s / 8392.0216 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.1331
env0_second_0:                 episode reward: 5.3000,                 loss: 0.1337
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 501.6457s / 8893.6674 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.1411
env0_second_0:                 episode reward: 4.1500,                 loss: 0.1425
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 523.8844s / 9417.5517 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.1418
env0_second_0:                 episode reward: 3.7000,                 loss: 0.1466
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 495.1707s / 9912.7224 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.1392
env0_second_0:                 episode reward: 2.5500,                 loss: 0.1480
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 503.2214s / 10415.9439 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.1348
env0_second_0:                 episode reward: 2.5000,                 loss: 0.1383
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 500.6787s / 10916.6226 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.1343
env0_second_0:                 episode reward: -0.4500,                 loss: 0.1399
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 503.9400s / 11420.5626 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.1420
env0_second_0:                 episode reward: 1.7500,                 loss: 0.1431
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 488.8253s / 11909.3879 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.1299
env0_second_0:                 episode reward: 3.2500,                 loss: 0.1463
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 512.2939s / 12421.6818 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.1331
env0_second_0:                 episode reward: 4.3500,                 loss: 0.1342
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 510.1441s / 12931.8260 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.1308
env0_second_0:                 episode reward: 1.1000,                 loss: 0.1348
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 514.4762s / 13446.3021 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.1342
env0_second_0:                 episode reward: 2.9000,                 loss: 0.1483
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 523.5685s / 13969.8706 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.1367
env0_second_0:                 episode reward: 2.9000,                 loss: 0.1414
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 512.8062s / 14482.6768 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.1626
env0_second_0:                 episode reward: 3.0500,                 loss: 0.1650
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 516.6506s / 14999.3274 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.1666
env0_second_0:                 episode reward: 3.0000,                 loss: 0.1734
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 504.1711s / 15503.4986 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.1771
env0_second_0:                 episode reward: 3.0500,                 loss: 0.1879
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 511.1266s / 16014.6252 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.1575
env0_second_0:                 episode reward: 3.3500,                 loss: 0.1727
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 502.7723s / 16517.3976 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.1518
env0_second_0:                 episode reward: 3.7500,                 loss: 0.1584
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 503.9788s / 17021.3763 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.1441
env0_second_0:                 episode reward: 2.2000,                 loss: 0.1603
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 495.1176s / 17516.4939 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.1420
env0_second_0:                 episode reward: 2.2500,                 loss: 0.1432
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 501.1662s / 18017.6601 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.1605
env0_second_0:                 episode reward: 4.8500,                 loss: 0.1618
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 519.1435s / 18536.8036 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.1652
env0_second_0:                 episode reward: 4.5500,                 loss: 0.1800
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 505.2376s / 19042.0412 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.1775
env0_second_0:                 episode reward: 3.1500,                 loss: 0.1906
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 493.6961s / 19535.7373 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.1781
env0_second_0:                 episode reward: 4.2000,                 loss: 0.1657
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 496.6047s / 20032.3420 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.1814
env0_second_0:                 episode reward: 6.0500,                 loss: 0.1849
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 494.8782s / 20527.2203 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.1959
env0_second_0:                 episode reward: 4.0500,                 loss: 0.1994
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 499.1431s / 21026.3634 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.1965
env0_second_0:                 episode reward: 5.0500,                 loss: 0.2282
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 517.5862s / 21543.9496 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.2094
env0_second_0:                 episode reward: 1.9500,                 loss: 0.2380
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 506.2581s / 22050.2078 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.1904
env0_second_0:                 episode reward: 4.4500,                 loss: 0.1862
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 503.5609s / 22553.7687 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.1564
env0_second_0:                 episode reward: 2.1500,                 loss: 0.1706
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 506.8897s / 23060.6584 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.1449
env0_second_0:                 episode reward: 3.6000,                 loss: 0.1535
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 502.9007s / 23563.5591 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.1506
env0_second_0:                 episode reward: 1.3000,                 loss: 0.1596
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 503.8276s / 24067.3866 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.1626
env0_second_0:                 episode reward: 3.8000,                 loss: 0.1644
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 505.2075s / 24572.5942 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2064
env0_second_0:                 episode reward: 1.2500,                 loss: 0.1909
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 504.5014s / 25077.0955 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.1979
env0_second_0:                 episode reward: 4.8500,                 loss: 0.2142
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 496.2927s / 25573.3883 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2118
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2264
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 506.6422s / 26080.0304 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.2105
env0_second_0:                 episode reward: 1.7000,                 loss: 0.2220
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 501.9012s / 26581.9316 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.1987
env0_second_0:                 episode reward: 3.1000,                 loss: 0.2379
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 492.9391s / 27074.8707 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.1976
env0_second_0:                 episode reward: 4.5000,                 loss: 0.2408
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 508.1342s / 27583.0049 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.2168
env0_second_0:                 episode reward: 3.0000,                 loss: 0.2287
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 500.8799s / 28083.8848 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.2185
env0_second_0:                 episode reward: 4.1500,                 loss: 0.2397
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 494.9958s / 28578.8806 s
env0_first_0:                 episode reward: -8.0000,                 loss: 0.2177
env0_second_0:                 episode reward: 8.0000,                 loss: 0.2466
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 507.6970s / 29086.5775 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.2593
env0_second_0:                 episode reward: 9.5500,                 loss: 0.2652
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 494.7219s / 29581.2994 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.2505
env0_second_0:                 episode reward: 10.1000,                 loss: 0.3081
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 511.9796s / 30093.2790 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.3061
env0_second_0:                 episode reward: 9.8000,                 loss: 0.3270
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 508.1420s / 30601.4210 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.3514
env0_second_0:                 episode reward: 8.6000,                 loss: 0.3572
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 502.9995s / 31104.4205 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.3562
env0_second_0:                 episode reward: 3.8000,                 loss: 0.4003
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 502.0799s / 31606.5004 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.3866
env0_second_0:                 episode reward: 4.9000,                 loss: 0.4080
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 513.9857s / 32120.4861 s
env0_first_0:                 episode reward: -5.6000,                 loss: 0.3368
env0_second_0:                 episode reward: 5.6000,                 loss: 0.3566
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 508.2659s / 32628.7520 s
env0_first_0:                 episode reward: -10.0500,                 loss: 0.3241
env0_second_0:                 episode reward: 10.0500,                 loss: 0.3163
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 506.5804s / 33135.3324 s
env0_first_0:                 episode reward: -9.2000,                 loss: 0.3037
env0_second_0:                 episode reward: 9.2000,                 loss: 0.3206
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 501.2425s / 33636.5748 s
env0_first_0:                 episode reward: -14.0500,                 loss: 0.3478
env0_second_0:                 episode reward: 14.0500,                 loss: 0.3803
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 499.4218s / 34135.9966 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.3618
env0_second_0:                 episode reward: 9.3500,                 loss: 0.3608
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1775.3,                last time consumption/overall running time: 502.9180s / 34638.9146 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.3968
env0_second_0:                 episode reward: 11.3000,                 loss: 0.3831
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 505.7027s / 35144.6173 s
env0_first_0:                 episode reward: -7.8000,                 loss: 0.4273
env0_second_0:                 episode reward: 7.8000,                 loss: 0.4175
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 498.2540s / 35642.8714 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.4431
env0_second_0:                 episode reward: 16.2000,                 loss: 0.4425
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 503.0471s / 36145.9185 s
env0_first_0:                 episode reward: -10.1500,                 loss: 0.4678
env0_second_0:                 episode reward: 10.1500,                 loss: 0.4588
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 506.9975s / 36652.9159 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.4589
env0_second_0:                 episode reward: 10.9000,                 loss: 0.4825
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1783.4,                last time consumption/overall running time: 497.4619s / 37150.3779 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.4663
env0_second_0:                 episode reward: 16.1000,                 loss: 0.4462
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1781.25,                last time consumption/overall running time: 504.9281s / 37655.3060 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.4674
env0_second_0:                 episode reward: 11.6500,                 loss: 0.4413
env1_first_0:                 episode reward: -16.7000,                 loss: nan
env1_second_0:                 episode reward: 16.7000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 515.7692s / 38171.0752 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.5059
env0_second_0:                 episode reward: 13.2000,                 loss: 0.4884
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1736.95,                last time consumption/overall running time: 497.4597s / 38668.5348 s
env0_first_0:                 episode reward: -17.0000,                 loss: 0.5234
env0_second_0:                 episode reward: 17.0000,                 loss: 0.5230
env1_first_0:                 episode reward: -31.4000,                 loss: nan
env1_second_0:                 episode reward: 31.4000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1750.8,                last time consumption/overall running time: 507.6086s / 39176.1435 s
env0_first_0:                 episode reward: -30.3000,                 loss: 0.5828
env0_second_0:                 episode reward: 30.3000,                 loss: 0.5642
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1717.05,                last time consumption/overall running time: 493.0046s / 39669.1480 s
env0_first_0:                 episode reward: -16.5500,                 loss: 0.6789
env0_second_0:                 episode reward: 16.5500,                 loss: 0.6212
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1744.9,                last time consumption/overall running time: 496.0662s / 40165.2142 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.7555
env0_second_0:                 episode reward: 15.9000,                 loss: 0.7320
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1729.5,                last time consumption/overall running time: 500.0579s / 40665.2721 s
env0_first_0:                 episode reward: -13.9000,                 loss: 0.6568
env0_second_0:                 episode reward: 13.9000,                 loss: 0.7333
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1765.3,                last time consumption/overall running time: 524.7413s / 41190.0134 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.6536
env0_second_0:                 episode reward: 16.0500,                 loss: 0.6957
env1_first_0:                 episode reward: -17.7000,                 loss: nan
env1_second_0:                 episode reward: 17.7000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1716.9,                last time consumption/overall running time: 505.5348s / 41695.5482 s
env0_first_0:                 episode reward: -19.3500,                 loss: 0.6166
env0_second_0:                 episode reward: 19.3500,                 loss: 0.6435
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1755.9,                last time consumption/overall running time: 516.5134s / 42212.0616 s
env0_first_0:                 episode reward: -17.0500,                 loss: 0.6388
env0_second_0:                 episode reward: 17.0500,                 loss: 0.6948
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1767.3,                last time consumption/overall running time: 524.4070s / 42736.4686 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.6167
env0_second_0:                 episode reward: 19.0500,                 loss: 0.6737
env1_first_0:                 episode reward: -17.9000,                 loss: nan
env1_second_0:                 episode reward: 17.9000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1741.75,                last time consumption/overall running time: 532.4216s / 43268.8902 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.7194
env0_second_0:                 episode reward: 17.8500,                 loss: 0.7221
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1726.55,                last time consumption/overall running time: 514.8511s / 43783.7413 s
env0_first_0:                 episode reward: -22.6000,                 loss: 0.7118
env0_second_0:                 episode reward: 22.6000,                 loss: 0.7276
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1664.0,                last time consumption/overall running time: 493.8157s / 44277.5570 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.7113
env0_second_0:                 episode reward: 24.5500,                 loss: 0.7212
env1_first_0:                 episode reward: -27.4500,                 loss: nan
env1_second_0:                 episode reward: 27.4500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1619.7,                last time consumption/overall running time: 474.8910s / 44752.4480 s
env0_first_0:                 episode reward: -18.6000,                 loss: 0.7828
env0_second_0:                 episode reward: 18.6000,                 loss: 0.8084
env1_first_0:                 episode reward: -36.8500,                 loss: nan
env1_second_0:                 episode reward: 36.8500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1677.6,                last time consumption/overall running time: 492.9509s / 45245.3989 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.8763
env0_second_0:                 episode reward: 14.2500,                 loss: 0.8716
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1654.05,                last time consumption/overall running time: 487.0413s / 45732.4402 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.8678
env0_second_0:                 episode reward: 24.9500,                 loss: 0.9619
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1694.75,                last time consumption/overall running time: 493.7348s / 46226.1750 s
env0_first_0:                 episode reward: -23.3000,                 loss: 0.9070
env0_second_0:                 episode reward: 23.3000,                 loss: 0.8664
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1590.1,                last time consumption/overall running time: 462.3807s / 46688.5557 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.9471
env0_second_0:                 episode reward: 24.3500,                 loss: 0.9455
env1_first_0:                 episode reward: -34.1000,                 loss: nan
env1_second_0:                 episode reward: 34.1000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1656.1,                last time consumption/overall running time: 475.0656s / 47163.6213 s
env0_first_0:                 episode reward: -30.5000,                 loss: 1.1397
env0_second_0:                 episode reward: 30.5000,                 loss: 1.0192
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1585.35,                last time consumption/overall running time: 460.6467s / 47624.2680 s
env0_first_0:                 episode reward: -29.2000,                 loss: 1.0812
env0_second_0:                 episode reward: 29.2000,                 loss: 1.0712
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1628.15,                last time consumption/overall running time: 473.9236s / 48098.1916 s
env0_first_0:                 episode reward: -28.4000,                 loss: 0.9667
env0_second_0:                 episode reward: 28.4000,                 loss: 1.1769
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1486.85,                last time consumption/overall running time: 430.7063s / 48528.8978 s
env0_first_0:                 episode reward: -23.2500,                 loss: 1.0813
env0_second_0:                 episode reward: 23.2500,                 loss: 1.1941
env1_first_0:                 episode reward: -35.8500,                 loss: nan
env1_second_0:                 episode reward: 35.8500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 1501.1,                last time consumption/overall running time: 427.1353s / 48956.0331 s
env0_first_0:                 episode reward: -33.4500,                 loss: 1.2987
env0_second_0:                 episode reward: 33.4500,                 loss: 1.2744
env1_first_0:                 episode reward: -39.7000,                 loss: nan
env1_second_0:                 episode reward: 39.7000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1518.15,                last time consumption/overall running time: 443.4438s / 49399.4769 s
env0_first_0:                 episode reward: -23.0500,                 loss: 1.3675
env0_second_0:                 episode reward: 23.0500,                 loss: 1.2965
env1_first_0:                 episode reward: -29.1000,                 loss: nan
env1_second_0:                 episode reward: 29.1000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1576.4,                last time consumption/overall running time: 466.4638s / 49865.9407 s
env0_first_0:                 episode reward: -28.1500,                 loss: 1.3990
env0_second_0:                 episode reward: 28.1500,                 loss: 1.4567
env1_first_0:                 episode reward: -29.2000,                 loss: nan
env1_second_0:                 episode reward: 29.2000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1656.6,                last time consumption/overall running time: 480.7416s / 50346.6824 s
env0_first_0:                 episode reward: -27.0000,                 loss: 1.3700
env0_second_0:                 episode reward: 27.0000,                 loss: 1.4244
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1611.3,                last time consumption/overall running time: 461.3385s / 50808.0209 s
env0_first_0:                 episode reward: -16.0500,                 loss: 1.2791
env0_second_0:                 episode reward: 16.0500,                 loss: 1.3926
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1604.4,                last time consumption/overall running time: 484.8871s / 51292.9080 s
env0_first_0:                 episode reward: -23.3500,                 loss: 1.1578
env0_second_0:                 episode reward: 23.3500,                 loss: 1.1593
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1586.75,                last time consumption/overall running time: 463.7814s / 51756.6894 s
env0_first_0:                 episode reward: -24.3500,                 loss: 1.0139
env0_second_0:                 episode reward: 24.3500,                 loss: 1.1361
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1423.45,                last time consumption/overall running time: 414.1619s / 52170.8513 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.9954
env0_second_0:                 episode reward: 25.1000,                 loss: 1.0339
env1_first_0:                 episode reward: -30.4000,                 loss: nan
env1_second_0:                 episode reward: 30.4000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1400.35,                last time consumption/overall running time: 395.8780s / 52566.7293 s
env0_first_0:                 episode reward: -30.9500,                 loss: 1.2650
env0_second_0:                 episode reward: 30.9500,                 loss: 1.3184
env1_first_0:                 episode reward: -28.2500,                 loss: nan
env1_second_0:                 episode reward: 28.2500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 1410.3,                last time consumption/overall running time: 401.3586s / 52968.0879 s
env0_first_0:                 episode reward: -20.1500,                 loss: 1.2433
env0_second_0:                 episode reward: 20.1500,                 loss: 1.3054
env1_first_0:                 episode reward: -30.7000,                 loss: nan
env1_second_0:                 episode reward: 30.7000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1409.25,                last time consumption/overall running time: 405.1847s / 53373.2725 s
env0_first_0:                 episode reward: -26.5500,                 loss: 1.3309
env0_second_0:                 episode reward: 26.5500,                 loss: 1.4895
env1_first_0:                 episode reward: -27.3000,                 loss: nan
env1_second_0:                 episode reward: 27.3000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1258.55,                last time consumption/overall running time: 357.4983s / 53730.7708 s
env0_first_0:                 episode reward: -35.4500,                 loss: 1.4405
env0_second_0:                 episode reward: 35.4500,                 loss: 1.5152
env1_first_0:                 episode reward: -41.6500,                 loss: nan
env1_second_0:                 episode reward: 41.6500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1222.25,                last time consumption/overall running time: 350.1077s / 54080.8786 s
env0_first_0:                 episode reward: -43.7500,                 loss: 1.4523
env0_second_0:                 episode reward: 43.7500,                 loss: 1.5692
env1_first_0:                 episode reward: -35.1500,                 loss: nan
env1_second_0:                 episode reward: 35.1500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 1181.25,                last time consumption/overall running time: 354.6084s / 54435.4870 s
env0_first_0:                 episode reward: -38.2500,                 loss: 1.6281
env0_second_0:                 episode reward: 38.2500,                 loss: 1.8268
env1_first_0:                 episode reward: -39.4000,                 loss: nan
env1_second_0:                 episode reward: 39.4000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 1338.1,                last time consumption/overall running time: 385.8440s / 54821.3310 s
env0_first_0:                 episode reward: -36.0000,                 loss: 1.7815
env0_second_0:                 episode reward: 36.0000,                 loss: 1.9991
env1_first_0:                 episode reward: -35.1500,                 loss: nan
env1_second_0:                 episode reward: 35.1500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 1302.45,                last time consumption/overall running time: 378.0214s / 55199.3525 s
env0_first_0:                 episode reward: -33.9000,                 loss: 1.9765
env0_second_0:                 episode reward: 33.9000,                 loss: 2.1557
env1_first_0:                 episode reward: -40.7000,                 loss: nan
env1_second_0:                 episode reward: 40.7000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 1329.65,                last time consumption/overall running time: 382.5627s / 55581.9152 s
env0_first_0:                 episode reward: -36.6500,                 loss: 1.9956
env0_second_0:                 episode reward: 36.6500,                 loss: 1.8577
env1_first_0:                 episode reward: -29.9000,                 loss: nan
env1_second_0:                 episode reward: 29.9000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 1352.6,                last time consumption/overall running time: 398.7190s / 55980.6341 s
env0_first_0:                 episode reward: -30.7500,                 loss: 1.9155
env0_second_0:                 episode reward: 30.7500,                 loss: 1.9254
env1_first_0:                 episode reward: -35.3500,                 loss: nan
env1_second_0:                 episode reward: 35.3500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1148.8,                last time consumption/overall running time: 348.0138s / 56328.6479 s
env0_first_0:                 episode reward: -44.4000,                 loss: 1.9484
env0_second_0:                 episode reward: 44.4000,                 loss: 1.9181
env1_first_0:                 episode reward: -44.6000,                 loss: nan
env1_second_0:                 episode reward: 44.6000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1235.2,                last time consumption/overall running time: 364.2241s / 56692.8720 s
env0_first_0:                 episode reward: -30.7000,                 loss: 2.1230
env0_second_0:                 episode reward: 30.7000,                 loss: 1.9957
env1_first_0:                 episode reward: -36.2000,                 loss: nan
env1_second_0:                 episode reward: 36.2000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1338.0,                last time consumption/overall running time: 375.8091s / 57068.6811 s
env0_first_0:                 episode reward: -32.5500,                 loss: 2.2155
env0_second_0:                 episode reward: 32.5500,                 loss: 2.0924
env1_first_0:                 episode reward: -34.6500,                 loss: nan
env1_second_0:                 episode reward: 34.6500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1220.05,                last time consumption/overall running time: 351.1327s / 57419.8137 s
env0_first_0:                 episode reward: -37.0500,                 loss: 2.1443
env0_second_0:                 episode reward: 37.0500,                 loss: 2.2163
env1_first_0:                 episode reward: -38.9000,                 loss: nan
env1_second_0:                 episode reward: 38.9000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 1213.15,                last time consumption/overall running time: 355.7549s / 57775.5686 s
env0_first_0:                 episode reward: -41.4000,                 loss: 1.9238
env0_second_0:                 episode reward: 41.4000,                 loss: 1.9781
env1_first_0:                 episode reward: -38.7000,                 loss: nan
env1_second_0:                 episode reward: 38.7000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1275.45,                last time consumption/overall running time: 392.2360s / 58167.8046 s
env0_first_0:                 episode reward: -33.2000,                 loss: 1.9125
env0_second_0:                 episode reward: 33.2000,                 loss: 2.0280
env1_first_0:                 episode reward: -30.3000,                 loss: nan
env1_second_0:                 episode reward: 30.3000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1225.95,                last time consumption/overall running time: 362.0502s / 58529.8548 s
env0_first_0:                 episode reward: -36.3500,                 loss: 1.9524
env0_second_0:                 episode reward: 36.3500,                 loss: 2.0839
env1_first_0:                 episode reward: -36.5500,                 loss: nan
env1_second_0:                 episode reward: 36.5500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1260.7,                last time consumption/overall running time: 358.3371s / 58888.1919 s
env0_first_0:                 episode reward: -35.7000,                 loss: 2.2110
env0_second_0:                 episode reward: 35.7000,                 loss: 1.9363
env1_first_0:                 episode reward: -35.5500,                 loss: nan
env1_second_0:                 episode reward: 35.5500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1191.7,                last time consumption/overall running time: 342.9860s / 59231.1779 s
env0_first_0:                 episode reward: -47.8500,                 loss: 2.1997
env0_second_0:                 episode reward: 47.8500,                 loss: 2.0142
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1253.2,                last time consumption/overall running time: 357.9641s / 59589.1420 s
env0_first_0:                 episode reward: -24.6000,                 loss: 2.1440
env0_second_0:                 episode reward: 24.6000,                 loss: 2.0865
env1_first_0:                 episode reward: -33.6000,                 loss: nan
env1_second_0:                 episode reward: 33.6000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 1390.55,                last time consumption/overall running time: 393.8917s / 59983.0337 s
env0_first_0:                 episode reward: -27.2500,                 loss: 2.1756
env0_second_0:                 episode reward: 27.2500,                 loss: 1.8466
env1_first_0:                 episode reward: -30.7500,                 loss: nan
env1_second_0:                 episode reward: 30.7500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1210.1,                last time consumption/overall running time: 355.4087s / 60338.4424 s
env0_first_0:                 episode reward: -34.9500,                 loss: 2.1459
env0_second_0:                 episode reward: 34.9500,                 loss: 1.8854
env1_first_0:                 episode reward: -35.9500,                 loss: nan
env1_second_0:                 episode reward: 35.9500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1324.4,                last time consumption/overall running time: 386.3997s / 60724.8421 s
env0_first_0:                 episode reward: -21.2000,                 loss: 2.1327
env0_second_0:                 episode reward: 21.2000,                 loss: 2.1394
env1_first_0:                 episode reward: -39.0000,                 loss: nan
env1_second_0:                 episode reward: 39.0000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1234.55,                last time consumption/overall running time: 363.0620s / 61087.9041 s
env0_first_0:                 episode reward: -45.3000,                 loss: 2.0807
env0_second_0:                 episode reward: 45.3000,                 loss: 2.0053
env1_first_0:                 episode reward: -20.6500,                 loss: nan
env1_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1138.65,                last time consumption/overall running time: 334.9973s / 61422.9014 s
env0_first_0:                 episode reward: -22.7500,                 loss: 2.0026
env0_second_0:                 episode reward: 22.7500,                 loss: 1.9867
env1_first_0:                 episode reward: -39.3500,                 loss: nan
env1_second_0:                 episode reward: 39.3500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1037.8,                last time consumption/overall running time: 305.8474s / 61728.7487 s
env0_first_0:                 episode reward: -45.9000,                 loss: 2.3869
env0_second_0:                 episode reward: 45.9000,                 loss: 2.0487
env1_first_0:                 episode reward: -39.3000,                 loss: nan
env1_second_0:                 episode reward: 39.3000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1131.5,                last time consumption/overall running time: 328.6330s / 62057.3817 s
env0_first_0:                 episode reward: -38.0500,                 loss: 2.6284
env0_second_0:                 episode reward: 38.0500,                 loss: 2.3583
env1_first_0:                 episode reward: -44.5500,                 loss: nan
env1_second_0:                 episode reward: 44.5500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 1234.65,                last time consumption/overall running time: 369.2100s / 62426.5917 s
env0_first_0:                 episode reward: -24.8000,                 loss: 2.2222
env0_second_0:                 episode reward: 24.8000,                 loss: 2.4125
env1_first_0:                 episode reward: -33.7000,                 loss: nan
env1_second_0:                 episode reward: 33.7000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1139.4,                last time consumption/overall running time: 333.5501s / 62760.1417 s
env0_first_0:                 episode reward: -38.4500,                 loss: 2.0378
env0_second_0:                 episode reward: 38.4500,                 loss: 2.2886
env1_first_0:                 episode reward: -34.9500,                 loss: nan
env1_second_0:                 episode reward: 34.9500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 1171.3,                last time consumption/overall running time: 349.6270s / 63109.7688 s
env0_first_0:                 episode reward: -39.8500,                 loss: 2.2786
env0_second_0:                 episode reward: 39.8500,                 loss: 2.2420
env1_first_0:                 episode reward: -44.3000,                 loss: nan
env1_second_0:                 episode reward: 44.3000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1241.5,                last time consumption/overall running time: 355.7343s / 63465.5030 s
env0_first_0:                 episode reward: -42.7500,                 loss: 2.2580
env0_second_0:                 episode reward: 42.7500,                 loss: 2.1896
env1_first_0:                 episode reward: -28.6500,                 loss: nan
env1_second_0:                 episode reward: 28.6500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1214.55,                last time consumption/overall running time: 349.0384s / 63814.5415 s
env0_first_0:                 episode reward: -31.0500,                 loss: 2.3494
env0_second_0:                 episode reward: 31.0500,                 loss: 2.1264
env1_first_0:                 episode reward: -33.4500,                 loss: nan
env1_second_0:                 episode reward: 33.4500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 1121.8,                last time consumption/overall running time: 328.3168s / 64142.8582 s
env0_first_0:                 episode reward: -38.4000,                 loss: 2.2949
env0_second_0:                 episode reward: 38.4000,                 loss: 2.1782
env1_first_0:                 episode reward: -43.6500,                 loss: nan
env1_second_0:                 episode reward: 43.6500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1123.85,                last time consumption/overall running time: 326.1565s / 64469.0147 s
env0_first_0:                 episode reward: -28.0500,                 loss: 2.2784
env0_second_0:                 episode reward: 28.0500,                 loss: 2.1160
env1_first_0:                 episode reward: -43.8500,                 loss: nan
env1_second_0:                 episode reward: 43.8500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1132.85,                last time consumption/overall running time: 336.3758s / 64805.3906 s
env0_first_0:                 episode reward: -41.6500,                 loss: 1.9766
env0_second_0:                 episode reward: 41.6500,                 loss: 2.2540
env1_first_0:                 episode reward: -40.6000,                 loss: nan
env1_second_0:                 episode reward: 40.6000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1082.0,                last time consumption/overall running time: 322.8066s / 65128.1971 s
env0_first_0:                 episode reward: -54.2500,                 loss: 2.2654
env0_second_0:                 episode reward: 54.2500,                 loss: 2.2830
env1_first_0:                 episode reward: -38.8000,                 loss: nan
env1_second_0:                 episode reward: 38.8000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1052.2,                last time consumption/overall running time: 312.2004s / 65440.3975 s
env0_first_0:                 episode reward: -39.6500,                 loss: 2.5716
env0_second_0:                 episode reward: 39.6500,                 loss: 2.5130
env1_first_0:                 episode reward: -43.8500,                 loss: nan
env1_second_0:                 episode reward: 43.8500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1184.35,                last time consumption/overall running time: 339.8878s / 65780.2853 s
env0_first_0:                 episode reward: -40.4500,                 loss: 2.5675
env0_second_0:                 episode reward: 40.4500,                 loss: 2.7026
env1_first_0:                 episode reward: -39.2000,                 loss: nan
env1_second_0:                 episode reward: 39.2000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1100.75,                last time consumption/overall running time: 310.8821s / 66091.1674 s
env0_first_0:                 episode reward: -37.6000,                 loss: 2.6011
env0_second_0:                 episode reward: 37.6000,                 loss: 2.8968
env1_first_0:                 episode reward: -39.9500,                 loss: nan
env1_second_0:                 episode reward: 39.9500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1216.1,                last time consumption/overall running time: 353.9270s / 66445.0944 s
env0_first_0:                 episode reward: -30.4000,                 loss: 2.5808
env0_second_0:                 episode reward: 30.4000,                 loss: 2.8083
env1_first_0:                 episode reward: -47.2000,                 loss: nan
env1_second_0:                 episode reward: 47.2000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 1035.0,                last time consumption/overall running time: 303.0391s / 66748.1336 s
env0_first_0:                 episode reward: -50.8500,                 loss: 2.6664
env0_second_0:                 episode reward: 50.8500,                 loss: 2.6727
env1_first_0:                 episode reward: -38.0500,                 loss: nan
env1_second_0:                 episode reward: 38.0500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1144.2,                last time consumption/overall running time: 333.4110s / 67081.5446 s
env0_first_0:                 episode reward: -30.4500,                 loss: 2.9024
env0_second_0:                 episode reward: 30.4500,                 loss: 2.6878
env1_first_0:                 episode reward: -43.0000,                 loss: nan
env1_second_0:                 episode reward: 43.0000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 980.6,                last time consumption/overall running time: 280.2154s / 67361.7600 s
env0_first_0:                 episode reward: -39.5500,                 loss: 2.8979
env0_second_0:                 episode reward: 39.5500,                 loss: 2.9547
env1_first_0:                 episode reward: -49.3500,                 loss: nan
env1_second_0:                 episode reward: 49.3500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1099.2,                last time consumption/overall running time: 326.5774s / 67688.3374 s
env0_first_0:                 episode reward: -43.5500,                 loss: 2.7875
env0_second_0:                 episode reward: 43.5500,                 loss: 2.9380
env1_first_0:                 episode reward: -33.4000,                 loss: nan
env1_second_0:                 episode reward: 33.4000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1060.7,                last time consumption/overall running time: 306.8436s / 67995.1810 s
env0_first_0:                 episode reward: -44.6000,                 loss: 2.7430
env0_second_0:                 episode reward: 44.6000,                 loss: 2.7723
env1_first_0:                 episode reward: -33.6000,                 loss: nan
env1_second_0:                 episode reward: 33.6000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1178.25,                last time consumption/overall running time: 334.9086s / 68330.0896 s
env0_first_0:                 episode reward: -34.5500,                 loss: 3.0044
env0_second_0:                 episode reward: 34.5500,                 loss: 2.7868
env1_first_0:                 episode reward: -31.2500,                 loss: nan
env1_second_0:                 episode reward: 31.2500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1055.65,                last time consumption/overall running time: 310.9401s / 68641.0297 s
env0_first_0:                 episode reward: -46.1000,                 loss: 2.8161
env0_second_0:                 episode reward: 46.1000,                 loss: 2.6095
env1_first_0:                 episode reward: -26.7000,                 loss: nan
env1_second_0:                 episode reward: 26.7000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1187.1,                last time consumption/overall running time: 347.6517s / 68988.6814 s
env0_first_0:                 episode reward: -35.6500,                 loss: 2.7478
env0_second_0:                 episode reward: 35.6500,                 loss: 2.7635
env1_first_0:                 episode reward: -34.6000,                 loss: nan
env1_second_0:                 episode reward: 34.6000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1217.65,                last time consumption/overall running time: 352.8080s / 69341.4894 s
env0_first_0:                 episode reward: -43.1000,                 loss: 2.5686
env0_second_0:                 episode reward: 43.1000,                 loss: 2.7821
env1_first_0:                 episode reward: -40.0500,                 loss: nan
env1_second_0:                 episode reward: 40.0500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1066.15,                last time consumption/overall running time: 310.1915s / 69651.6809 s
env0_first_0:                 episode reward: -49.1500,                 loss: 2.7314
env0_second_0:                 episode reward: 49.1500,                 loss: 2.8455
env1_first_0:                 episode reward: -33.6500,                 loss: nan
env1_second_0:                 episode reward: 33.6500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1037.0,                last time consumption/overall running time: 308.1032s / 69959.7841 s
env0_first_0:                 episode reward: -40.0000,                 loss: 3.0006
env0_second_0:                 episode reward: 40.0000,                 loss: 2.8068
env1_first_0:                 episode reward: -50.8000,                 loss: nan
env1_second_0:                 episode reward: 50.8000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1088.85,                last time consumption/overall running time: 314.8965s / 70274.6806 s
env0_first_0:                 episode reward: -32.2000,                 loss: 3.0850
env0_second_0:                 episode reward: 32.2000,                 loss: 3.0415
env1_first_0:                 episode reward: -46.1500,                 loss: nan
env1_second_0:                 episode reward: 46.1500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1177.15,                last time consumption/overall running time: 357.2286s / 70631.9092 s
env0_first_0:                 episode reward: -32.1000,                 loss: 3.0503
env0_second_0:                 episode reward: 32.1000,                 loss: 3.0673
env1_first_0:                 episode reward: -36.3000,                 loss: nan
env1_second_0:                 episode reward: 36.3000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1066.05,                last time consumption/overall running time: 307.6783s / 70939.5875 s
env0_first_0:                 episode reward: -35.5500,                 loss: 2.7551
env0_second_0:                 episode reward: 35.5500,                 loss: 2.9292
env1_first_0:                 episode reward: -39.6500,                 loss: nan
env1_second_0:                 episode reward: 39.6500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1094.9,                last time consumption/overall running time: 319.0775s / 71258.6650 s
env0_first_0:                 episode reward: -31.9000,                 loss: 2.7150
env0_second_0:                 episode reward: 31.9000,                 loss: 2.7971
env1_first_0:                 episode reward: -46.9000,                 loss: nan
env1_second_0:                 episode reward: 46.9000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1007.8,                last time consumption/overall running time: 287.5485s / 71546.2134 s
env0_first_0:                 episode reward: -31.1000,                 loss: 2.7580
env0_second_0:                 episode reward: 31.1000,                 loss: 3.1325
env1_first_0:                 episode reward: -53.3000,                 loss: nan
env1_second_0:                 episode reward: 53.3000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 928.2,                last time consumption/overall running time: 274.3959s / 71820.6094 s
env0_first_0:                 episode reward: -38.7500,                 loss: 2.8059
env0_second_0:                 episode reward: 38.7500,                 loss: 3.0136
env1_first_0:                 episode reward: -44.3000,                 loss: nan
env1_second_0:                 episode reward: 44.3000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1241.8,                last time consumption/overall running time: 376.1983s / 72196.8077 s
env0_first_0:                 episode reward: -43.6500,                 loss: 2.9272
env0_second_0:                 episode reward: 43.6500,                 loss: 2.6538
env1_first_0:                 episode reward: -27.2500,                 loss: nan
env1_second_0:                 episode reward: 27.2500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1208.3,                last time consumption/overall running time: 349.5516s / 72546.3593 s
env0_first_0:                 episode reward: -34.7500,                 loss: 3.1163
env0_second_0:                 episode reward: 34.7500,                 loss: 2.7566
env1_first_0:                 episode reward: -34.1000,                 loss: nan
env1_second_0:                 episode reward: 34.1000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1236.3,                last time consumption/overall running time: 355.2373s / 72901.5966 s
env0_first_0:                 episode reward: -35.8000,                 loss: 2.8124
env0_second_0:                 episode reward: 35.8000,                 loss: 2.8517
env1_first_0:                 episode reward: -31.1000,                 loss: nan
env1_second_0:                 episode reward: 31.1000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1200.15,                last time consumption/overall running time: 344.2977s / 73245.8943 s
env0_first_0:                 episode reward: -23.2500,                 loss: 2.9241
env0_second_0:                 episode reward: 23.2500,                 loss: 2.5192
env1_first_0:                 episode reward: -38.6500,                 loss: nan
env1_second_0:                 episode reward: 38.6500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1072.8,                last time consumption/overall running time: 320.5831s / 73566.4774 s
env0_first_0:                 episode reward: -42.4000,                 loss: 2.8178
env0_second_0:                 episode reward: 42.4000,                 loss: 2.6508
env1_first_0:                 episode reward: -43.3500,                 loss: nan
env1_second_0:                 episode reward: 43.3500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 905.65,                last time consumption/overall running time: 261.6809s / 73828.1583 s
env0_first_0:                 episode reward: -39.1000,                 loss: 2.5373
env0_second_0:                 episode reward: 39.1000,                 loss: 2.7172
env1_first_0:                 episode reward: -40.7000,                 loss: nan
env1_second_0:                 episode reward: 40.7000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1104.4,                last time consumption/overall running time: 320.1743s / 74148.3326 s
env0_first_0:                 episode reward: -36.5500,                 loss: 2.7103
env0_second_0:                 episode reward: 36.5500,                 loss: 2.7266
env1_first_0:                 episode reward: -44.6000,                 loss: nan
env1_second_0:                 episode reward: 44.6000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1008.35,                last time consumption/overall running time: 291.4384s / 74439.7710 s
env0_first_0:                 episode reward: -48.0500,                 loss: 2.7275
env0_second_0:                 episode reward: 48.0500,                 loss: 3.0668
env1_first_0:                 episode reward: -42.1500,                 loss: nan
env1_second_0:                 episode reward: 42.1500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1023.25,                last time consumption/overall running time: 300.5577s / 74740.3288 s
env0_first_0:                 episode reward: -42.3000,                 loss: 2.9047
env0_second_0:                 episode reward: 42.3000,                 loss: 3.1132
env1_first_0:                 episode reward: -47.1000,                 loss: nan
env1_second_0:                 episode reward: 47.1000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1051.4,                last time consumption/overall running time: 302.4600s / 75042.7887 s
env0_first_0:                 episode reward: -52.2000,                 loss: 3.0262
env0_second_0:                 episode reward: 52.2000,                 loss: 2.9811
env1_first_0:                 episode reward: -24.2000,                 loss: nan
env1_second_0:                 episode reward: 24.2000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 996.2,                last time consumption/overall running time: 283.1431s / 75325.9318 s
env0_first_0:                 episode reward: -46.2500,                 loss: 3.2455
env0_second_0:                 episode reward: 46.2500,                 loss: 2.8057
env1_first_0:                 episode reward: -41.9500,                 loss: nan
env1_second_0:                 episode reward: 41.9500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 998.55,                last time consumption/overall running time: 291.3030s / 75617.2348 s
env0_first_0:                 episode reward: -38.6500,                 loss: 2.9262
env0_second_0:                 episode reward: 38.6500,                 loss: 3.1069
env1_first_0:                 episode reward: -57.4500,                 loss: nan
env1_second_0:                 episode reward: 57.4500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1000.05,                last time consumption/overall running time: 293.5363s / 75910.7711 s
env0_first_0:                 episode reward: -47.8500,                 loss: 3.3124
env0_second_0:                 episode reward: 47.8500,                 loss: 3.0982
env1_first_0:                 episode reward: -42.8500,                 loss: nan
env1_second_0:                 episode reward: 42.8500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1001.65,                last time consumption/overall running time: 299.0847s / 76209.8558 s
env0_first_0:                 episode reward: -36.2500,                 loss: 3.5190
env0_second_0:                 episode reward: 36.2500,                 loss: 3.1226
env1_first_0:                 episode reward: -56.3500,                 loss: nan
env1_second_0:                 episode reward: 56.3500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 1114.35,                last time consumption/overall running time: 319.2455s / 76529.1012 s
env0_first_0:                 episode reward: -38.8500,                 loss: 3.2930
env0_second_0:                 episode reward: 38.8500,                 loss: 3.3428
env1_first_0:                 episode reward: -48.8500,                 loss: nan
env1_second_0:                 episode reward: 48.8500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1048.0,                last time consumption/overall running time: 303.4896s / 76832.5908 s
env0_first_0:                 episode reward: -49.8500,                 loss: 3.1287
env0_second_0:                 episode reward: 49.8500,                 loss: 3.1594
env1_first_0:                 episode reward: -29.0000,                 loss: nan
env1_second_0:                 episode reward: 29.0000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1018.8,                last time consumption/overall running time: 294.9139s / 77127.5047 s
env0_first_0:                 episode reward: -39.8000,                 loss: 3.1873
env0_second_0:                 episode reward: 39.8000,                 loss: 3.2152
env1_first_0:                 episode reward: -47.6500,                 loss: nan
env1_second_0:                 episode reward: 47.6500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1124.45,                last time consumption/overall running time: 323.3673s / 77450.8720 s
env0_first_0:                 episode reward: -44.6000,                 loss: 3.1160
env0_second_0:                 episode reward: 44.6000,                 loss: 3.0575
env1_first_0:                 episode reward: -33.5000,                 loss: nan
env1_second_0:                 episode reward: 33.5000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 925.1,                last time consumption/overall running time: 282.0146s / 77732.8866 s
env0_first_0:                 episode reward: -44.5500,                 loss: 3.2077
env0_second_0:                 episode reward: 44.5500,                 loss: 3.0550
env1_first_0:                 episode reward: -37.6500,                 loss: nan
env1_second_0:                 episode reward: 37.6500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1053.2,                last time consumption/overall running time: 302.9711s / 78035.8576 s
env0_first_0:                 episode reward: -41.6500,                 loss: 3.0631
env0_second_0:                 episode reward: 41.6500,                 loss: 2.7765
env1_first_0:                 episode reward: -36.1500,                 loss: nan
env1_second_0:                 episode reward: 36.1500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1054.35,                last time consumption/overall running time: 312.9051s / 78348.7627 s
env0_first_0:                 episode reward: -44.1500,                 loss: 2.9996
env0_second_0:                 episode reward: 44.1500,                 loss: 2.7689
env1_first_0:                 episode reward: -40.8500,                 loss: nan
env1_second_0:                 episode reward: 40.8500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1107.5,                last time consumption/overall running time: 339.8162s / 78688.5789 s
env0_first_0:                 episode reward: -38.8000,                 loss: 2.9390
env0_second_0:                 episode reward: 38.8000,                 loss: 2.8962
env1_first_0:                 episode reward: -34.0000,                 loss: nan
env1_second_0:                 episode reward: 34.0000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1128.45,                last time consumption/overall running time: 324.7631s / 79013.3420 s
env0_first_0:                 episode reward: -44.4500,                 loss: 3.3134
env0_second_0:                 episode reward: 44.4500,                 loss: 2.7048
env1_first_0:                 episode reward: -42.3500,                 loss: nan
env1_second_0:                 episode reward: 42.3500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1086.1,                last time consumption/overall running time: 310.0048s / 79323.3468 s
env0_first_0:                 episode reward: -37.9000,                 loss: 3.6810
env0_second_0:                 episode reward: 37.9000,                 loss: 2.9827
env1_first_0:                 episode reward: -38.9500,                 loss: nan
env1_second_0:                 episode reward: 38.9500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 968.05,                last time consumption/overall running time: 280.3436s / 79603.6904 s
env0_first_0:                 episode reward: -54.4000,                 loss: 3.3485
env0_second_0:                 episode reward: 54.4000,                 loss: 2.9123
env1_first_0:                 episode reward: -31.8500,                 loss: nan
env1_second_0:                 episode reward: 31.8500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1022.55,                last time consumption/overall running time: 298.5960s / 79902.2863 s
env0_first_0:                 episode reward: -35.2000,                 loss: 3.2394
env0_second_0:                 episode reward: 35.2000,                 loss: 3.0479
env1_first_0:                 episode reward: -50.0500,                 loss: nan
env1_second_0:                 episode reward: 50.0500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 1111.4,                last time consumption/overall running time: 324.6513s / 80226.9376 s
env0_first_0:                 episode reward: -42.3000,                 loss: 3.3693
env0_second_0:                 episode reward: 42.3000,                 loss: 2.9590
env1_first_0:                 episode reward: -46.5500,                 loss: nan
env1_second_0:                 episode reward: 46.5500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 933.6,                last time consumption/overall running time: 275.5573s / 80502.4949 s
env0_first_0:                 episode reward: -45.8000,                 loss: 3.3485
env0_second_0:                 episode reward: 45.8000,                 loss: 3.3017
env1_first_0:                 episode reward: -39.6000,                 loss: nan
env1_second_0:                 episode reward: 39.6000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1085.85,                last time consumption/overall running time: 318.2052s / 80820.7000 s
env0_first_0:                 episode reward: -44.4000,                 loss: 2.9720
env0_second_0:                 episode reward: 44.4000,                 loss: 3.3605
env1_first_0:                 episode reward: -34.5000,                 loss: nan
env1_second_0:                 episode reward: 34.5000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1176.05,                last time consumption/overall running time: 358.6487s / 81179.3487 s
env0_first_0:                 episode reward: -35.5000,                 loss: 3.2801
env0_second_0:                 episode reward: 35.5000,                 loss: 3.2633
env1_first_0:                 episode reward: -42.4500,                 loss: nan
env1_second_0:                 episode reward: 42.4500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 965.9,                last time consumption/overall running time: 284.1476s / 81463.4963 s
env0_first_0:                 episode reward: -40.1000,                 loss: 3.1684
env0_second_0:                 episode reward: 40.1000,                 loss: 2.9047
env1_first_0:                 episode reward: -42.3500,                 loss: nan
env1_second_0:                 episode reward: 42.3500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 910.3,                last time consumption/overall running time: 261.2657s / 81724.7620 s
env0_first_0:                 episode reward: -45.8000,                 loss: 3.0947
env0_second_0:                 episode reward: 45.8000,                 loss: 3.1931
env1_first_0:                 episode reward: -48.1000,                 loss: nan
env1_second_0:                 episode reward: 48.1000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 969.35,                last time consumption/overall running time: 277.8481s / 82002.6101 s
env0_first_0:                 episode reward: -50.1500,                 loss: 3.0643
env0_second_0:                 episode reward: 50.1500,                 loss: 3.2097
env1_first_0:                 episode reward: -54.8000,                 loss: nan
env1_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 905.9,                last time consumption/overall running time: 264.7909s / 82267.4010 s
env0_first_0:                 episode reward: -41.4500,                 loss: 3.0852
env0_second_0:                 episode reward: 41.4500,                 loss: 3.3620
env1_first_0:                 episode reward: -55.9000,                 loss: nan
env1_second_0:                 episode reward: 55.9000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 998.1,                last time consumption/overall running time: 294.9821s / 82562.3831 s
env0_first_0:                 episode reward: -39.2000,                 loss: 3.2712
env0_second_0:                 episode reward: 39.2000,                 loss: 3.1653
env1_first_0:                 episode reward: -51.9500,                 loss: nan
env1_second_0:                 episode reward: 51.9500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1096.75,                last time consumption/overall running time: 318.6174s / 82881.0005 s
env0_first_0:                 episode reward: -44.5500,                 loss: 3.3700
env0_second_0:                 episode reward: 44.5500,                 loss: 3.0468
env1_first_0:                 episode reward: -41.6000,                 loss: nan
env1_second_0:                 episode reward: 41.6000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1115.75,                last time consumption/overall running time: 321.4486s / 83202.4491 s
env0_first_0:                 episode reward: -41.5000,                 loss: 3.3694
env0_second_0:                 episode reward: 41.5000,                 loss: 2.9813
env1_first_0:                 episode reward: -42.5000,                 loss: nan
env1_second_0:                 episode reward: 42.5000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1130.75,                last time consumption/overall running time: 329.5063s / 83531.9554 s
env0_first_0:                 episode reward: -32.5500,                 loss: 3.1108
env0_second_0:                 episode reward: 32.5500,                 loss: 2.9417
env1_first_0:                 episode reward: -40.8500,                 loss: nan
env1_second_0:                 episode reward: 40.8500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1094.35,                last time consumption/overall running time: 322.8699s / 83854.8253 s
env0_first_0:                 episode reward: -33.0500,                 loss: 2.7764
env0_second_0:                 episode reward: 33.0500,                 loss: 2.6825
env1_first_0:                 episode reward: -41.4000,                 loss: nan
env1_second_0:                 episode reward: 41.4000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 1108.85,                last time consumption/overall running time: 325.3038s / 84180.1291 s
env0_first_0:                 episode reward: -17.9500,                 loss: 3.0770
env0_second_0:                 episode reward: 17.9500,                 loss: 2.5687
env1_first_0:                 episode reward: -42.1500,                 loss: nan
env1_second_0:                 episode reward: 42.1500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1192.9,                last time consumption/overall running time: 347.8721s / 84528.0012 s
env0_first_0:                 episode reward: -35.6500,                 loss: 2.9756
env0_second_0:                 episode reward: 35.6500,                 loss: 2.8102
env1_first_0:                 episode reward: -41.6500,                 loss: nan
env1_second_0:                 episode reward: 41.6500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1015.4,                last time consumption/overall running time: 299.0697s / 84827.0710 s
env0_first_0:                 episode reward: -51.3000,                 loss: 2.7912
env0_second_0:                 episode reward: 51.3000,                 loss: 2.8559
env1_first_0:                 episode reward: -40.1500,                 loss: nan
env1_second_0:                 episode reward: 40.1500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 964.85,                last time consumption/overall running time: 299.3035s / 85126.3744 s
env0_first_0:                 episode reward: -45.3000,                 loss: 2.7283
env0_second_0:                 episode reward: 45.3000,                 loss: 2.7167
env1_first_0:                 episode reward: -43.9000,                 loss: nan
env1_second_0:                 episode reward: 43.9000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 883.55,                last time consumption/overall running time: 257.1293s / 85383.5037 s
env0_first_0:                 episode reward: -42.1000,                 loss: 2.7323
env0_second_0:                 episode reward: 42.1000,                 loss: 2.9379
env1_first_0:                 episode reward: -68.4500,                 loss: nan
env1_second_0:                 episode reward: 68.4500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 870.7,                last time consumption/overall running time: 255.0067s / 85638.5104 s
env0_first_0:                 episode reward: -39.7500,                 loss: 3.0416
env0_second_0:                 episode reward: 39.7500,                 loss: 3.1061
env1_first_0:                 episode reward: -57.6000,                 loss: nan
env1_second_0:                 episode reward: 57.6000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1138.55,                last time consumption/overall running time: 331.7598s / 85970.2701 s
env0_first_0:                 episode reward: -41.7500,                 loss: 3.0344
env0_second_0:                 episode reward: 41.7500,                 loss: 3.4538
env1_first_0:                 episode reward: -44.6500,                 loss: nan
env1_second_0:                 episode reward: 44.6500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 848.15,                last time consumption/overall running time: 246.9992s / 86217.2693 s
env0_first_0:                 episode reward: -33.8000,                 loss: 3.3417
env0_second_0:                 episode reward: 33.8000,                 loss: 3.5589
env1_first_0:                 episode reward: -61.9000,                 loss: nan
env1_second_0:                 episode reward: 61.9000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1015.45,                last time consumption/overall running time: 300.7355s / 86518.0048 s
env0_first_0:                 episode reward: -37.3000,                 loss: 3.6736
env0_second_0:                 episode reward: 37.3000,                 loss: 3.5004
env1_first_0:                 episode reward: -44.5500,                 loss: nan
env1_second_0:                 episode reward: 44.5500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 978.85,                last time consumption/overall running time: 291.4070s / 86809.4117 s
env0_first_0:                 episode reward: -39.4000,                 loss: 3.5038
env0_second_0:                 episode reward: 39.4000,                 loss: 3.2154
env1_first_0:                 episode reward: -50.5000,                 loss: nan
env1_second_0:                 episode reward: 50.5000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 983.0,                last time consumption/overall running time: 281.5176s / 87090.9293 s
env0_first_0:                 episode reward: -48.2000,                 loss: 3.2659
env0_second_0:                 episode reward: 48.2000,                 loss: 3.2766
env1_first_0:                 episode reward: -44.6500,                 loss: nan
env1_second_0:                 episode reward: 44.6500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 851.6,                last time consumption/overall running time: 248.0095s / 87338.9388 s
env0_first_0:                 episode reward: -44.3500,                 loss: 3.4023
env0_second_0:                 episode reward: 44.3500,                 loss: 3.4434
env1_first_0:                 episode reward: -53.9500,                 loss: nan
env1_second_0:                 episode reward: 53.9500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 990.45,                last time consumption/overall running time: 293.5848s / 87632.5236 s
env0_first_0:                 episode reward: -52.9000,                 loss: 3.7627
env0_second_0:                 episode reward: 52.9000,                 loss: 3.6307
env1_first_0:                 episode reward: -37.3500,                 loss: nan
env1_second_0:                 episode reward: 37.3500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 960.05,                last time consumption/overall running time: 273.7064s / 87906.2299 s
env0_first_0:                 episode reward: -41.1500,                 loss: 3.4179
env0_second_0:                 episode reward: 41.1500,                 loss: 3.7342
env1_first_0:                 episode reward: -40.0500,                 loss: nan
env1_second_0:                 episode reward: 40.0500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 953.3,                last time consumption/overall running time: 280.4770s / 88186.7069 s
env0_first_0:                 episode reward: -33.5500,                 loss: 3.6972
env0_second_0:                 episode reward: 33.5500,                 loss: 3.8181
env1_first_0:                 episode reward: -53.4000,                 loss: nan
env1_second_0:                 episode reward: 53.4000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 937.25,                last time consumption/overall running time: 277.5647s / 88464.2717 s
env0_first_0:                 episode reward: -33.1500,                 loss: 3.6000
env0_second_0:                 episode reward: 33.1500,                 loss: 3.4931
env1_first_0:                 episode reward: -53.3000,                 loss: nan
env1_second_0:                 episode reward: 53.3000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 978.15,                last time consumption/overall running time: 283.0405s / 88747.3122 s
env0_first_0:                 episode reward: -46.4000,                 loss: 3.4428
env0_second_0:                 episode reward: 46.4000,                 loss: 3.3398
env1_first_0:                 episode reward: -45.3000,                 loss: nan
env1_second_0:                 episode reward: 45.3000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 1065.25,                last time consumption/overall running time: 318.7526s / 89066.0648 s
env0_first_0:                 episode reward: -43.8500,                 loss: 3.6083
env0_second_0:                 episode reward: 43.8500,                 loss: 3.3595
env1_first_0:                 episode reward: -53.2000,                 loss: nan
env1_second_0:                 episode reward: 53.2000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 975.7,                last time consumption/overall running time: 279.6635s / 89345.7282 s
env0_first_0:                 episode reward: -46.2500,                 loss: 3.2071
env0_second_0:                 episode reward: 46.2500,                 loss: 3.7299
env1_first_0:                 episode reward: -46.0500,                 loss: nan
env1_second_0:                 episode reward: 46.0500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1022.1,                last time consumption/overall running time: 294.3586s / 89640.0869 s
env0_first_0:                 episode reward: -45.5000,                 loss: 3.4579
env0_second_0:                 episode reward: 45.5000,                 loss: 3.4599
env1_first_0:                 episode reward: -41.7000,                 loss: nan
env1_second_0:                 episode reward: 41.7000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1163.6,                last time consumption/overall running time: 346.1200s / 89986.2069 s
env0_first_0:                 episode reward: -48.0000,                 loss: 3.7107
env0_second_0:                 episode reward: 48.0000,                 loss: 3.4144
env1_first_0:                 episode reward: -42.1000,                 loss: nan
env1_second_0:                 episode reward: 42.1000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1055.95,                last time consumption/overall running time: 308.5363s / 90294.7432 s
env0_first_0:                 episode reward: -37.4500,                 loss: 3.6566
env0_second_0:                 episode reward: 37.4500,                 loss: 3.0710
env1_first_0:                 episode reward: -49.9500,                 loss: nan
env1_second_0:                 episode reward: 49.9500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 998.45,                last time consumption/overall running time: 295.4228s / 90590.1660 s
env0_first_0:                 episode reward: -47.5500,                 loss: 3.1748
env0_second_0:                 episode reward: 47.5500,                 loss: 3.0985
env1_first_0:                 episode reward: -47.3500,                 loss: nan
env1_second_0:                 episode reward: 47.3500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1119.1,                last time consumption/overall running time: 320.7543s / 90910.9202 s
env0_first_0:                 episode reward: -39.8000,                 loss: 3.0038
env0_second_0:                 episode reward: 39.8000,                 loss: 3.2474
env1_first_0:                 episode reward: -33.8000,                 loss: nan
env1_second_0:                 episode reward: 33.8000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1070.35,                last time consumption/overall running time: 314.0605s / 91224.9807 s
env0_first_0:                 episode reward: -46.5500,                 loss: 2.9546
env0_second_0:                 episode reward: 46.5500,                 loss: 2.9380
env1_first_0:                 episode reward: -44.6500,                 loss: nan
env1_second_0:                 episode reward: 44.6500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 950.5,                last time consumption/overall running time: 277.7849s / 91502.7656 s
env0_first_0:                 episode reward: -41.7000,                 loss: 3.0813
env0_second_0:                 episode reward: 41.7000,                 loss: 2.9254
env1_first_0:                 episode reward: -49.4500,                 loss: nan
env1_second_0:                 episode reward: 49.4500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 880.75,                last time consumption/overall running time: 252.3796s / 91755.1452 s
env0_first_0:                 episode reward: -47.8000,                 loss: 3.5672
env0_second_0:                 episode reward: 47.8000,                 loss: 3.2930
env1_first_0:                 episode reward: -69.2000,                 loss: nan
env1_second_0:                 episode reward: 69.2000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1025.35,                last time consumption/overall running time: 291.4277s / 92046.5729 s
env0_first_0:                 episode reward: -37.0500,                 loss: 3.6908
env0_second_0:                 episode reward: 37.0500,                 loss: 3.3871
env1_first_0:                 episode reward: -50.1500,                 loss: nan
env1_second_0:                 episode reward: 50.1500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1113.05,                last time consumption/overall running time: 327.0359s / 92373.6089 s
env0_first_0:                 episode reward: -40.7000,                 loss: 3.4774
env0_second_0:                 episode reward: 40.7000,                 loss: 3.4385
env1_first_0:                 episode reward: -42.9500,                 loss: nan
env1_second_0:                 episode reward: 42.9500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1012.15,                last time consumption/overall running time: 292.1907s / 92665.7995 s
env0_first_0:                 episode reward: -42.3000,                 loss: 3.8094
env0_second_0:                 episode reward: 42.3000,                 loss: 3.7008
env1_first_0:                 episode reward: -36.0000,                 loss: nan
env1_second_0:                 episode reward: 36.0000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 945.8,                last time consumption/overall running time: 281.3008s / 92947.1004 s
env0_first_0:                 episode reward: -45.4500,                 loss: 3.6468
env0_second_0:                 episode reward: 45.4500,                 loss: 3.5357
env1_first_0:                 episode reward: -48.4000,                 loss: nan
env1_second_0:                 episode reward: 48.4000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 955.3,                last time consumption/overall running time: 286.8894s / 93233.9898 s
env0_first_0:                 episode reward: -45.8500,                 loss: 3.2564
env0_second_0:                 episode reward: 45.8500,                 loss: 3.3896
env1_first_0:                 episode reward: -53.3000,                 loss: nan
env1_second_0:                 episode reward: 53.3000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1012.4,                last time consumption/overall running time: 290.0525s / 93524.0423 s
env0_first_0:                 episode reward: -31.6000,                 loss: 3.1708
env0_second_0:                 episode reward: 31.6000,                 loss: 3.3213
env1_first_0:                 episode reward: -52.0000,                 loss: nan
env1_second_0:                 episode reward: 52.0000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 913.6,                last time consumption/overall running time: 264.4998s / 93788.5421 s
env0_first_0:                 episode reward: -38.8000,                 loss: 3.0028
env0_second_0:                 episode reward: 38.8000,                 loss: 3.2927
env1_first_0:                 episode reward: -57.7500,                 loss: nan
env1_second_0:                 episode reward: 57.7500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 895.35,                last time consumption/overall running time: 261.6877s / 94050.2299 s
env0_first_0:                 episode reward: -53.9000,                 loss: 3.2133
env0_second_0:                 episode reward: 53.9000,                 loss: 3.5473
env1_first_0:                 episode reward: -42.5500,                 loss: nan
env1_second_0:                 episode reward: 42.5500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 938.55,                last time consumption/overall running time: 269.8097s / 94320.0395 s
env0_first_0:                 episode reward: -48.2500,                 loss: 3.6137
env0_second_0:                 episode reward: 48.2500,                 loss: 3.7849
env1_first_0:                 episode reward: -59.2500,                 loss: nan
env1_second_0:                 episode reward: 59.2500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 844.8,                last time consumption/overall running time: 246.2495s / 94566.2891 s
env0_first_0:                 episode reward: -53.4500,                 loss: 3.7249
env0_second_0:                 episode reward: 53.4500,                 loss: 3.8904
env1_first_0:                 episode reward: -46.6000,                 loss: nan
env1_second_0:                 episode reward: 46.6000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 895.05,                last time consumption/overall running time: 257.3550s / 94823.6440 s
env0_first_0:                 episode reward: -56.1000,                 loss: 3.6155
env0_second_0:                 episode reward: 56.1000,                 loss: 3.7252
env1_first_0:                 episode reward: -50.6500,                 loss: nan
env1_second_0:                 episode reward: 50.6500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 907.9,                last time consumption/overall running time: 259.7377s / 95083.3817 s
env0_first_0:                 episode reward: -51.3500,                 loss: 3.7494
env0_second_0:                 episode reward: 51.3500,                 loss: 3.7364
env1_first_0:                 episode reward: -39.9500,                 loss: nan
env1_second_0:                 episode reward: 39.9500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 841.5,                last time consumption/overall running time: 241.5959s / 95324.9776 s
env0_first_0:                 episode reward: -32.6500,                 loss: 3.7409
env0_second_0:                 episode reward: 32.6500,                 loss: 3.9769
env1_first_0:                 episode reward: -59.1500,                 loss: nan
env1_second_0:                 episode reward: 59.1500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1022.55,                last time consumption/overall running time: 299.7225s / 95624.7001 s
env0_first_0:                 episode reward: -36.0000,                 loss: 3.7524
env0_second_0:                 episode reward: 36.0000,                 loss: 3.9253
env1_first_0:                 episode reward: -49.8500,                 loss: nan
env1_second_0:                 episode reward: 49.8500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 889.65,                last time consumption/overall running time: 260.1944s / 95884.8945 s
env0_first_0:                 episode reward: -38.2500,                 loss: 3.9597
env0_second_0:                 episode reward: 38.2500,                 loss: 3.7354
env1_first_0:                 episode reward: -57.0500,                 loss: nan
env1_second_0:                 episode reward: 57.0500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1043.35,                last time consumption/overall running time: 309.7151s / 96194.6096 s
env0_first_0:                 episode reward: -45.4500,                 loss: 4.2420
env0_second_0:                 episode reward: 45.4500,                 loss: 3.7759
env1_first_0:                 episode reward: -44.3500,                 loss: nan
env1_second_0:                 episode reward: 44.3500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1044.65,                last time consumption/overall running time: 307.2185s / 96501.8281 s
env0_first_0:                 episode reward: -39.7000,                 loss: 3.9262
env0_second_0:                 episode reward: 39.7000,                 loss: 3.6290
env1_first_0:                 episode reward: -44.6000,                 loss: nan
env1_second_0:                 episode reward: 44.6000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 912.45,                last time consumption/overall running time: 266.5023s / 96768.3303 s
env0_first_0:                 episode reward: -39.0500,                 loss: 3.8587
env0_second_0:                 episode reward: 39.0500,                 loss: 3.8040
env1_first_0:                 episode reward: -50.5500,                 loss: nan
env1_second_0:                 episode reward: 50.5500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 885.05,                last time consumption/overall running time: 258.8963s / 97027.2266 s
env0_first_0:                 episode reward: -46.1000,                 loss: 3.7373
env0_second_0:                 episode reward: 46.1000,                 loss: 3.6798
env1_first_0:                 episode reward: -58.8500,                 loss: nan
env1_second_0:                 episode reward: 58.8500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1020.5,                last time consumption/overall running time: 294.6198s / 97321.8464 s
env0_first_0:                 episode reward: -45.1000,                 loss: 3.4998
env0_second_0:                 episode reward: 45.1000,                 loss: 3.5022
env1_first_0:                 episode reward: -53.6500,                 loss: nan
env1_second_0:                 episode reward: 53.6500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 908.15,                last time consumption/overall running time: 267.1047s / 97588.9511 s
env0_first_0:                 episode reward: -44.5000,                 loss: 3.6598
env0_second_0:                 episode reward: 44.5000,                 loss: 3.8097
env1_first_0:                 episode reward: -52.2500,                 loss: nan
env1_second_0:                 episode reward: 52.2500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 829.3,                last time consumption/overall running time: 246.6485s / 97835.5996 s
env0_first_0:                 episode reward: -51.2500,                 loss: 3.6263
env0_second_0:                 episode reward: 51.2500,                 loss: 3.7725
env1_first_0:                 episode reward: -62.6500,                 loss: nan
env1_second_0:                 episode reward: 62.6500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 931.8,                last time consumption/overall running time: 270.1124s / 98105.7120 s
env0_first_0:                 episode reward: -44.1000,                 loss: 3.6066
env0_second_0:                 episode reward: 44.1000,                 loss: 4.0003
env1_first_0:                 episode reward: -47.7000,                 loss: nan
env1_second_0:                 episode reward: 47.7000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1027.1,                last time consumption/overall running time: 300.1352s / 98405.8472 s
env0_first_0:                 episode reward: -50.5000,                 loss: 3.8962
env0_second_0:                 episode reward: 50.5000,                 loss: 4.0619
env1_first_0:                 episode reward: -39.2500,                 loss: nan
env1_second_0:                 episode reward: 39.2500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 884.55,                last time consumption/overall running time: 256.8252s / 98662.6724 s
env0_first_0:                 episode reward: -55.7500,                 loss: 4.0175
env0_second_0:                 episode reward: 55.7500,                 loss: 3.7964
env1_first_0:                 episode reward: -35.0000,                 loss: nan
env1_second_0:                 episode reward: 35.0000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 940.85,                last time consumption/overall running time: 270.7826s / 98933.4550 s
env0_first_0:                 episode reward: -36.9000,                 loss: 4.0905
env0_second_0:                 episode reward: 36.9000,                 loss: 3.7384
env1_first_0:                 episode reward: -54.5000,                 loss: nan
env1_second_0:                 episode reward: 54.5000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 942.6,                last time consumption/overall running time: 274.9111s / 99208.3660 s
env0_first_0:                 episode reward: -55.0000,                 loss: 4.1974
env0_second_0:                 episode reward: 55.0000,                 loss: 3.7376
env1_first_0:                 episode reward: -40.4000,                 loss: nan
env1_second_0:                 episode reward: 40.4000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 812.45,                last time consumption/overall running time: 235.2445s / 99443.6105 s
env0_first_0:                 episode reward: -52.4000,                 loss: 3.8574
env0_second_0:                 episode reward: 52.4000,                 loss: 3.9614
env1_first_0:                 episode reward: -48.6000,                 loss: nan
env1_second_0:                 episode reward: 48.6000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1053.0,                last time consumption/overall running time: 306.8397s / 99750.4503 s
env0_first_0:                 episode reward: -39.2500,                 loss: 3.5720
env0_second_0:                 episode reward: 39.2500,                 loss: 4.0930
env1_first_0:                 episode reward: -47.7000,                 loss: nan
env1_second_0:                 episode reward: 47.7000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 871.4,                last time consumption/overall running time: 252.2974s / 100002.7477 s
env0_first_0:                 episode reward: -45.6500,                 loss: 3.7350
env0_second_0:                 episode reward: 45.6500,                 loss: 3.6944
env1_first_0:                 episode reward: -46.8500,                 loss: nan
env1_second_0:                 episode reward: 46.8500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1111.15,                last time consumption/overall running time: 322.8613s / 100325.6090 s
env0_first_0:                 episode reward: -53.9000,                 loss: 3.4953
env0_second_0:                 episode reward: 53.9000,                 loss: 3.4937
env1_first_0:                 episode reward: -35.5000,                 loss: nan
env1_second_0:                 episode reward: 35.5000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1005.0,                last time consumption/overall running time: 291.8689s / 100617.4779 s
env0_first_0:                 episode reward: -39.2500,                 loss: 3.4025
env0_second_0:                 episode reward: 39.2500,                 loss: 3.4005
env1_first_0:                 episode reward: -44.7000,                 loss: nan
env1_second_0:                 episode reward: 44.7000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1012.85,                last time consumption/overall running time: 288.6124s / 100906.0902 s
env0_first_0:                 episode reward: -56.6500,                 loss: 3.3459
env0_second_0:                 episode reward: 56.6500,                 loss: 3.3227
env1_first_0:                 episode reward: -29.8000,                 loss: nan
env1_second_0:                 episode reward: 29.8000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1091.75,                last time consumption/overall running time: 323.1300s / 101229.2202 s
env0_first_0:                 episode reward: -48.1500,                 loss: 3.5520
env0_second_0:                 episode reward: 48.1500,                 loss: 3.1947
env1_first_0:                 episode reward: -43.1500,                 loss: nan
env1_second_0:                 episode reward: 43.1500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1029.3,                last time consumption/overall running time: 299.0487s / 101528.2689 s
env0_first_0:                 episode reward: -42.2500,                 loss: 3.3034
env0_second_0:                 episode reward: 42.2500,                 loss: 3.3182
env1_first_0:                 episode reward: -30.2000,                 loss: nan
env1_second_0:                 episode reward: 30.2000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1079.75,                last time consumption/overall running time: 316.5376s / 101844.8065 s
env0_first_0:                 episode reward: -56.1500,                 loss: 3.2746
env0_second_0:                 episode reward: 56.1500,                 loss: 3.4196
env1_first_0:                 episode reward: -34.2500,                 loss: nan
env1_second_0:                 episode reward: 34.2500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 854.35,                last time consumption/overall running time: 251.9284s / 102096.7349 s
env0_first_0:                 episode reward: -49.0500,                 loss: 3.2921
env0_second_0:                 episode reward: 49.0500,                 loss: 3.5764
env1_first_0:                 episode reward: -47.4000,                 loss: nan
env1_second_0:                 episode reward: 47.4000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 817.35,                last time consumption/overall running time: 237.8363s / 102334.5712 s
env0_first_0:                 episode reward: -59.4500,                 loss: 3.3417
env0_second_0:                 episode reward: 59.4500,                 loss: 3.4481
env1_first_0:                 episode reward: -32.9000,                 loss: nan
env1_second_0:                 episode reward: 32.9000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 948.9,                last time consumption/overall running time: 274.0465s / 102608.6177 s
env0_first_0:                 episode reward: -48.1000,                 loss: 3.5808
env0_second_0:                 episode reward: 48.1000,                 loss: 3.5829
env1_first_0:                 episode reward: -52.1500,                 loss: nan
env1_second_0:                 episode reward: 52.1500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 855.25,                last time consumption/overall running time: 250.7865s / 102859.4042 s
env0_first_0:                 episode reward: -33.6000,                 loss: 3.5789
env0_second_0:                 episode reward: 33.6000,                 loss: 3.4843
env1_first_0:                 episode reward: -66.2000,                 loss: nan
env1_second_0:                 episode reward: 66.2000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 911.3,                last time consumption/overall running time: 257.4352s / 103116.8394 s
env0_first_0:                 episode reward: -55.0000,                 loss: 3.9001
env0_second_0:                 episode reward: 55.0000,                 loss: 3.6073
env1_first_0:                 episode reward: -37.7000,                 loss: nan
env1_second_0:                 episode reward: 37.7000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 888.95,                last time consumption/overall running time: 257.0186s / 103373.8580 s
env0_first_0:                 episode reward: -54.2000,                 loss: 3.4802
env0_second_0:                 episode reward: 54.2000,                 loss: 3.7020
env1_first_0:                 episode reward: -51.2500,                 loss: nan
env1_second_0:                 episode reward: 51.2500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 829.45,                last time consumption/overall running time: 238.1412s / 103611.9992 s
env0_first_0:                 episode reward: -60.5000,                 loss: 3.7389
env0_second_0:                 episode reward: 60.5000,                 loss: 3.7539
env1_first_0:                 episode reward: -35.8500,                 loss: nan
env1_second_0:                 episode reward: 35.8500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 934.6,                last time consumption/overall running time: 266.9478s / 103878.9470 s
env0_first_0:                 episode reward: -34.2000,                 loss: 4.0118
env0_second_0:                 episode reward: 34.2000,                 loss: 3.4961
env1_first_0:                 episode reward: -60.2000,                 loss: nan
env1_second_0:                 episode reward: 60.2000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 964.2,                last time consumption/overall running time: 272.6532s / 104151.6002 s
env0_first_0:                 episode reward: -50.7000,                 loss: 4.0273
env0_second_0:                 episode reward: 50.7000,                 loss: 3.4126
env1_first_0:                 episode reward: -38.6500,                 loss: nan
env1_second_0:                 episode reward: 38.6500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 1008.55,                last time consumption/overall running time: 283.0152s / 104434.6154 s
env0_first_0:                 episode reward: -53.2500,                 loss: 3.9467
env0_second_0:                 episode reward: 53.2500,                 loss: 3.5612
env1_first_0:                 episode reward: -45.1500,                 loss: nan
env1_second_0:                 episode reward: 45.1500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 967.25,                last time consumption/overall running time: 286.4033s / 104721.0187 s
env0_first_0:                 episode reward: -51.0500,                 loss: 3.7863
env0_second_0:                 episode reward: 51.0500,                 loss: 3.7229
env1_first_0:                 episode reward: -39.9500,                 loss: nan
env1_second_0:                 episode reward: 39.9500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1043.0,                last time consumption/overall running time: 308.5394s / 105029.5582 s
env0_first_0:                 episode reward: -35.6000,                 loss: 3.7538
env0_second_0:                 episode reward: 35.6000,                 loss: 3.7388
env1_first_0:                 episode reward: -40.3500,                 loss: nan
env1_second_0:                 episode reward: 40.3500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 896.6,                last time consumption/overall running time: 262.8218s / 105292.3800 s
env0_first_0:                 episode reward: -45.6500,                 loss: 3.7567
env0_second_0:                 episode reward: 45.6500,                 loss: 3.7349
env1_first_0:                 episode reward: -45.3500,                 loss: nan
env1_second_0:                 episode reward: 45.3500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 826.1,                last time consumption/overall running time: 242.1223s / 105534.5023 s
env0_first_0:                 episode reward: -48.8500,                 loss: 3.4613
env0_second_0:                 episode reward: 48.8500,                 loss: 3.3778
env1_first_0:                 episode reward: -58.7500,                 loss: nan
env1_second_0:                 episode reward: 58.7500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1004.95,                last time consumption/overall running time: 287.2336s / 105821.7359 s
env0_first_0:                 episode reward: -36.1500,                 loss: 3.8803
env0_second_0:                 episode reward: 36.1500,                 loss: 3.3602
env1_first_0:                 episode reward: -51.8500,                 loss: nan
env1_second_0:                 episode reward: 51.8500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 931.25,                last time consumption/overall running time: 275.2170s / 106096.9529 s
env0_first_0:                 episode reward: -50.0000,                 loss: 3.9670
env0_second_0:                 episode reward: 50.0000,                 loss: 3.7111
env1_first_0:                 episode reward: -39.3000,                 loss: nan
env1_second_0:                 episode reward: 39.3000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1017.05,                last time consumption/overall running time: 303.5739s / 106400.5268 s
env0_first_0:                 episode reward: -51.6500,                 loss: 3.8251
env0_second_0:                 episode reward: 51.6500,                 loss: 3.7256
env1_first_0:                 episode reward: -48.6000,                 loss: nan
env1_second_0:                 episode reward: 48.6000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1055.2,                last time consumption/overall running time: 308.1215s / 106708.6482 s
env0_first_0:                 episode reward: -35.5000,                 loss: 3.8012
env0_second_0:                 episode reward: 35.5000,                 loss: 3.9183
env1_first_0:                 episode reward: -51.0000,                 loss: nan
env1_second_0:                 episode reward: 51.0000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 918.45,                last time consumption/overall running time: 263.4282s / 106972.0764 s
env0_first_0:                 episode reward: -48.3000,                 loss: 3.9302
env0_second_0:                 episode reward: 48.3000,                 loss: 3.4711
env1_first_0:                 episode reward: -50.1000,                 loss: nan
env1_second_0:                 episode reward: 50.1000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 807.5,                last time consumption/overall running time: 230.6635s / 107202.7399 s
env0_first_0:                 episode reward: -56.8500,                 loss: 3.8177
env0_second_0:                 episode reward: 56.8500,                 loss: 3.4321
env1_first_0:                 episode reward: -46.8000,                 loss: nan
env1_second_0:                 episode reward: 46.8000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 951.6,                last time consumption/overall running time: 271.9825s / 107474.7224 s
env0_first_0:                 episode reward: -58.9500,                 loss: 3.7211
env0_second_0:                 episode reward: 58.9500,                 loss: 3.6498
env1_first_0:                 episode reward: -39.7000,                 loss: nan
env1_second_0:                 episode reward: 39.7000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 954.4,                last time consumption/overall running time: 278.2015s / 107752.9239 s
env0_first_0:                 episode reward: -53.7500,                 loss: 3.7488
env0_second_0:                 episode reward: 53.7500,                 loss: 4.0184
env1_first_0:                 episode reward: -49.6500,                 loss: nan
env1_second_0:                 episode reward: 49.6500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 879.0,                last time consumption/overall running time: 256.7693s / 108009.6932 s
env0_first_0:                 episode reward: -53.4000,                 loss: 4.1804
env0_second_0:                 episode reward: 53.4000,                 loss: 4.0157
env1_first_0:                 episode reward: -36.9000,                 loss: nan
env1_second_0:                 episode reward: 36.9000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 917.1,                last time consumption/overall running time: 269.7623s / 108279.4555 s
env0_first_0:                 episode reward: -51.8500,                 loss: 4.2858
env0_second_0:                 episode reward: 51.8500,                 loss: 4.1582
env1_first_0:                 episode reward: -44.0500,                 loss: nan
env1_second_0:                 episode reward: 44.0500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 956.9,                last time consumption/overall running time: 274.3027s / 108553.7582 s
env0_first_0:                 episode reward: -29.0500,                 loss: 4.7354
env0_second_0:                 episode reward: 29.0500,                 loss: 4.1432
env1_first_0:                 episode reward: -62.1500,                 loss: nan
env1_second_0:                 episode reward: 62.1500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 943.45,                last time consumption/overall running time: 278.3143s / 108832.0725 s
env0_first_0:                 episode reward: -44.1000,                 loss: 4.9300
env0_second_0:                 episode reward: 44.1000,                 loss: 4.2503
env1_first_0:                 episode reward: -54.4500,                 loss: nan
env1_second_0:                 episode reward: 54.4500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 949.05,                last time consumption/overall running time: 283.7905s / 109115.8630 s
env0_first_0:                 episode reward: -51.4500,                 loss: 4.5338
env0_second_0:                 episode reward: 51.4500,                 loss: 4.5177
env1_first_0:                 episode reward: -47.6500,                 loss: nan
env1_second_0:                 episode reward: 47.6500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 988.8,                last time consumption/overall running time: 287.5725s / 109403.4355 s
env0_first_0:                 episode reward: -42.1500,                 loss: 4.2228
env0_second_0:                 episode reward: 42.1500,                 loss: 4.2317
env1_first_0:                 episode reward: -51.5000,                 loss: nan
env1_second_0:                 episode reward: 51.5000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 1040.2,                last time consumption/overall running time: 305.7106s / 109709.1462 s
env0_first_0:                 episode reward: -34.3000,                 loss: 3.8999
env0_second_0:                 episode reward: 34.3000,                 loss: 4.0011
env1_first_0:                 episode reward: -54.8000,                 loss: nan
env1_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 906.1,                last time consumption/overall running time: 266.6323s / 109975.7785 s
env0_first_0:                 episode reward: -52.4500,                 loss: 3.6586
env0_second_0:                 episode reward: 52.4500,                 loss: 3.9112
env1_first_0:                 episode reward: -46.5000,                 loss: nan
env1_second_0:                 episode reward: 46.5000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 813.5,                last time consumption/overall running time: 231.7380s / 110207.5165 s
env0_first_0:                 episode reward: -47.5000,                 loss: 3.6283
env0_second_0:                 episode reward: 47.5000,                 loss: 3.9476
env1_first_0:                 episode reward: -60.1500,                 loss: nan
env1_second_0:                 episode reward: 60.1500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 964.1,                last time consumption/overall running time: 276.4022s / 110483.9187 s
env0_first_0:                 episode reward: -60.8500,                 loss: 3.8714
env0_second_0:                 episode reward: 60.8500,                 loss: 4.0669
env1_first_0:                 episode reward: -42.1500,                 loss: nan
env1_second_0:                 episode reward: 42.1500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 754.9,                last time consumption/overall running time: 214.2345s / 110698.1531 s
env0_first_0:                 episode reward: -48.3500,                 loss: 3.6949
env0_second_0:                 episode reward: 48.3500,                 loss: 4.0631
env1_first_0:                 episode reward: -56.7500,                 loss: nan
env1_second_0:                 episode reward: 56.7500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 799.65,                last time consumption/overall running time: 226.6908s / 110924.8440 s
env0_first_0:                 episode reward: -42.7500,                 loss: 3.6638
env0_second_0:                 episode reward: 42.7500,                 loss: 4.1054
env1_first_0:                 episode reward: -67.5500,                 loss: nan
env1_second_0:                 episode reward: 67.5500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 917.65,                last time consumption/overall running time: 262.5416s / 111187.3856 s
env0_first_0:                 episode reward: -31.6500,                 loss: 3.9641
env0_second_0:                 episode reward: 31.6500,                 loss: 4.3029
env1_first_0:                 episode reward: -58.5500,                 loss: nan
env1_second_0:                 episode reward: 58.5500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 804.9,                last time consumption/overall running time: 227.7948s / 111415.1804 s
env0_first_0:                 episode reward: -50.3000,                 loss: 4.2247
env0_second_0:                 episode reward: 50.3000,                 loss: 4.3478
env1_first_0:                 episode reward: -58.5000,                 loss: nan
env1_second_0:                 episode reward: 58.5000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 912.75,                last time consumption/overall running time: 255.6106s / 111670.7909 s
env0_first_0:                 episode reward: -46.8500,                 loss: 3.9416
env0_second_0:                 episode reward: 46.8500,                 loss: 4.0912
env1_first_0:                 episode reward: -47.9500,                 loss: nan
env1_second_0:                 episode reward: 47.9500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 942.8,                last time consumption/overall running time: 277.6346s / 111948.4256 s
env0_first_0:                 episode reward: -43.5500,                 loss: 4.1358
env0_second_0:                 episode reward: 43.5500,                 loss: 3.8636
env1_first_0:                 episode reward: -47.1000,                 loss: nan
env1_second_0:                 episode reward: 47.1000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1022.7,                last time consumption/overall running time: 290.3341s / 112238.7596 s
env0_first_0:                 episode reward: -32.1000,                 loss: 4.4756
env0_second_0:                 episode reward: 32.1000,                 loss: 3.8798
env1_first_0:                 episode reward: -56.4000,                 loss: nan
env1_second_0:                 episode reward: 56.4000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 1052.15,                last time consumption/overall running time: 298.1763s / 112536.9359 s
env0_first_0:                 episode reward: -49.2500,                 loss: 4.0068
env0_second_0:                 episode reward: 49.2500,                 loss: 3.7240
env1_first_0:                 episode reward: -32.3000,                 loss: nan
env1_second_0:                 episode reward: 32.3000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 1027.0,                last time consumption/overall running time: 296.1241s / 112833.0600 s
env0_first_0:                 episode reward: -57.2000,                 loss: 3.8696
env0_second_0:                 episode reward: 57.2000,                 loss: 3.6929
env1_first_0:                 episode reward: -34.4000,                 loss: nan
env1_second_0:                 episode reward: 34.4000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 1085.85,                last time consumption/overall running time: 298.9192s / 113131.9792 s
env0_first_0:                 episode reward: -44.5000,                 loss: 3.9299
env0_second_0:                 episode reward: 44.5000,                 loss: 3.5749
env1_first_0:                 episode reward: -33.1000,                 loss: nan
env1_second_0:                 episode reward: 33.1000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 950.7,                last time consumption/overall running time: 262.2508s / 113394.2300 s
env0_first_0:                 episode reward: -44.2500,                 loss: 3.7210
env0_second_0:                 episode reward: 44.2500,                 loss: 3.7064
env1_first_0:                 episode reward: -42.8000,                 loss: nan
env1_second_0:                 episode reward: 42.8000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 1016.1,                last time consumption/overall running time: 278.6466s / 113672.8766 s
env0_first_0:                 episode reward: -36.7500,                 loss: 3.8651
env0_second_0:                 episode reward: 36.7500,                 loss: 3.6807
env1_first_0:                 episode reward: -48.3500,                 loss: nan
env1_second_0:                 episode reward: 48.3500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 1073.95,                last time consumption/overall running time: 297.7919s / 113970.6685 s
env0_first_0:                 episode reward: -31.5000,                 loss: 3.8356
env0_second_0:                 episode reward: 31.5000,                 loss: 3.5459
env1_first_0:                 episode reward: -47.5500,                 loss: nan
env1_second_0:                 episode reward: 47.5500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 1015.55,                last time consumption/overall running time: 281.2992s / 114251.9677 s
env0_first_0:                 episode reward: -50.4000,                 loss: 3.4625
env0_second_0:                 episode reward: 50.4000,                 loss: 3.3110
env1_first_0:                 episode reward: -49.0000,                 loss: nan
env1_second_0:                 episode reward: 49.0000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 987.2,                last time consumption/overall running time: 284.4085s / 114536.3762 s
env0_first_0:                 episode reward: -53.1000,                 loss: 3.5227
env0_second_0:                 episode reward: 53.1000,                 loss: 3.3562
env1_first_0:                 episode reward: -45.9000,                 loss: nan
env1_second_0:                 episode reward: 45.9000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 1000.75,                last time consumption/overall running time: 294.7924s / 114831.1686 s
env0_first_0:                 episode reward: -47.8000,                 loss: 3.3833
env0_second_0:                 episode reward: 47.8000,                 loss: 3.4603
env1_first_0:                 episode reward: -49.9500,                 loss: nan
env1_second_0:                 episode reward: 49.9500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 974.9,                last time consumption/overall running time: 270.3005s / 115101.4691 s
env0_first_0:                 episode reward: -47.8500,                 loss: 3.5044
env0_second_0:                 episode reward: 47.8500,                 loss: 3.6999
env1_first_0:                 episode reward: -56.9500,                 loss: nan
env1_second_0:                 episode reward: 56.9500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 957.35,                last time consumption/overall running time: 272.2649s / 115373.7340 s
env0_first_0:                 episode reward: -54.0000,                 loss: 3.8463
env0_second_0:                 episode reward: 54.0000,                 loss: 3.8973
env1_first_0:                 episode reward: -41.1500,                 loss: nan
env1_second_0:                 episode reward: 41.1500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 863.65,                last time consumption/overall running time: 239.6986s / 115613.4326 s
env0_first_0:                 episode reward: -44.5500,                 loss: 3.7315
env0_second_0:                 episode reward: 44.5500,                 loss: 3.9078
env1_first_0:                 episode reward: -46.3500,                 loss: nan
env1_second_0:                 episode reward: 46.3500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 948.75,                last time consumption/overall running time: 262.2256s / 115875.6582 s
env0_first_0:                 episode reward: -28.7000,                 loss: 3.7351
env0_second_0:                 episode reward: 28.7000,                 loss: 3.8067
env1_first_0:                 episode reward: -61.8500,                 loss: nan
env1_second_0:                 episode reward: 61.8500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 789.95,                last time consumption/overall running time: 217.8927s / 116093.5509 s
env0_first_0:                 episode reward: -49.1000,                 loss: 3.8535
env0_second_0:                 episode reward: 49.1000,                 loss: 3.7928
env1_first_0:                 episode reward: -52.7000,                 loss: nan
env1_second_0:                 episode reward: 52.7000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 883.25,                last time consumption/overall running time: 243.9813s / 116337.5322 s
env0_first_0:                 episode reward: -57.4000,                 loss: 3.7510
env0_second_0:                 episode reward: 57.4000,                 loss: 4.1568
env1_first_0:                 episode reward: -42.0000,                 loss: nan
env1_second_0:                 episode reward: 42.0000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 770.4,                last time consumption/overall running time: 215.4524s / 116552.9846 s
env0_first_0:                 episode reward: -51.1000,                 loss: 3.8263
env0_second_0:                 episode reward: 51.1000,                 loss: 4.2467
env1_first_0:                 episode reward: -56.9000,                 loss: nan
env1_second_0:                 episode reward: 56.9000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 902.4,                last time consumption/overall running time: 258.0633s / 116811.0479 s
env0_first_0:                 episode reward: -34.8000,                 loss: 4.1091
env0_second_0:                 episode reward: 34.8000,                 loss: 4.1441
env1_first_0:                 episode reward: -59.2500,                 loss: nan
env1_second_0:                 episode reward: 59.2500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 1056.45,                last time consumption/overall running time: 302.3687s / 117113.4166 s
env0_first_0:                 episode reward: -40.6500,                 loss: 4.2296
env0_second_0:                 episode reward: 40.6500,                 loss: 3.9431
env1_first_0:                 episode reward: -42.6000,                 loss: nan
env1_second_0:                 episode reward: 42.6000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 969.95,                last time consumption/overall running time: 274.2005s / 117387.6171 s
env0_first_0:                 episode reward: -42.8000,                 loss: 4.2176
env0_second_0:                 episode reward: 42.8000,                 loss: 4.0164
env1_first_0:                 episode reward: -49.2000,                 loss: nan
env1_second_0:                 episode reward: 49.2000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 899.85,                last time consumption/overall running time: 255.6135s / 117643.2306 s
env0_first_0:                 episode reward: -48.4000,                 loss: 3.7709
env0_second_0:                 episode reward: 48.4000,                 loss: 3.9799
env1_first_0:                 episode reward: -44.2500,                 loss: nan
env1_second_0:                 episode reward: 44.2500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 929.4,                last time consumption/overall running time: 268.8728s / 117912.1034 s
env0_first_0:                 episode reward: -56.6000,                 loss: 3.5610
env0_second_0:                 episode reward: 56.6000,                 loss: 3.9931
env1_first_0:                 episode reward: -29.3500,                 loss: nan
env1_second_0:                 episode reward: 29.3500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 944.45,                last time consumption/overall running time: 265.8489s / 118177.9523 s
env0_first_0:                 episode reward: -46.4000,                 loss: 3.4063
env0_second_0:                 episode reward: 46.4000,                 loss: 4.0067
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 808.7,                last time consumption/overall running time: 226.1157s / 118404.0680 s
env0_first_0:                 episode reward: -67.1500,                 loss: 3.6464
env0_second_0:                 episode reward: 67.1500,                 loss: 3.7539
env1_first_0:                 episode reward: -45.4000,                 loss: nan
env1_second_0:                 episode reward: 45.4000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 808.9,                last time consumption/overall running time: 225.9857s / 118630.0538 s
env0_first_0:                 episode reward: -40.6500,                 loss: 3.9099
env0_second_0:                 episode reward: 40.6500,                 loss: 3.8913
env1_first_0:                 episode reward: -48.0000,                 loss: nan
env1_second_0:                 episode reward: 48.0000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 996.65,                last time consumption/overall running time: 277.6226s / 118907.6764 s
env0_first_0:                 episode reward: -47.9000,                 loss: 4.2159
env0_second_0:                 episode reward: 47.9000,                 loss: 3.8849
env1_first_0:                 episode reward: -50.3000,                 loss: nan
env1_second_0:                 episode reward: 50.3000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 959.1,                last time consumption/overall running time: 263.1880s / 119170.8643 s
env0_first_0:                 episode reward: -49.7000,                 loss: 4.2713
env0_second_0:                 episode reward: 49.7000,                 loss: 4.0275
env1_first_0:                 episode reward: -46.3500,                 loss: nan
env1_second_0:                 episode reward: 46.3500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 895.85,                last time consumption/overall running time: 247.4827s / 119418.3471 s
env0_first_0:                 episode reward: -40.9000,                 loss: 4.0528
env0_second_0:                 episode reward: 40.9000,                 loss: 4.1402
env1_first_0:                 episode reward: -51.0500,                 loss: nan
env1_second_0:                 episode reward: 51.0500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 963.1,                last time consumption/overall running time: 264.4253s / 119682.7723 s
env0_first_0:                 episode reward: -48.0000,                 loss: 3.6531
env0_second_0:                 episode reward: 48.0000,                 loss: 4.2076
env1_first_0:                 episode reward: -47.8000,                 loss: nan
env1_second_0:                 episode reward: 47.8000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 1094.6,                last time consumption/overall running time: 301.1383s / 119983.9106 s
env0_first_0:                 episode reward: -46.8500,                 loss: 3.9393
env0_second_0:                 episode reward: 46.8500,                 loss: 3.8800
env1_first_0:                 episode reward: -43.2000,                 loss: nan
env1_second_0:                 episode reward: 43.2000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 857.75,                last time consumption/overall running time: 238.1653s / 120222.0759 s
env0_first_0:                 episode reward: -38.1000,                 loss: 4.1635
env0_second_0:                 episode reward: 38.1000,                 loss: 3.5829
env1_first_0:                 episode reward: -58.4500,                 loss: nan
env1_second_0:                 episode reward: 58.4500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 1005.6,                last time consumption/overall running time: 280.2686s / 120502.3445 s
env0_first_0:                 episode reward: -32.9000,                 loss: 4.0853
env0_second_0:                 episode reward: 32.9000,                 loss: 3.4968
env1_first_0:                 episode reward: -56.7000,                 loss: nan
env1_second_0:                 episode reward: 56.7000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 972.95,                last time consumption/overall running time: 267.7505s / 120770.0950 s
env0_first_0:                 episode reward: -51.6500,                 loss: 3.8279
env0_second_0:                 episode reward: 51.6500,                 loss: 3.5722
env1_first_0:                 episode reward: -53.1000,                 loss: nan
env1_second_0:                 episode reward: 53.1000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 987.75,                last time consumption/overall running time: 271.7119s / 121041.8069 s
env0_first_0:                 episode reward: -40.1000,                 loss: 3.6969
env0_second_0:                 episode reward: 40.1000,                 loss: 3.3920
env1_first_0:                 episode reward: -47.4000,                 loss: nan
env1_second_0:                 episode reward: 47.4000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 1005.55,                last time consumption/overall running time: 277.8749s / 121319.6818 s
env0_first_0:                 episode reward: -44.9500,                 loss: 3.9311
env0_second_0:                 episode reward: 44.9500,                 loss: 3.7640
env1_first_0:                 episode reward: -49.1000,                 loss: nan
env1_second_0:                 episode reward: 49.1000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 866.1,                last time consumption/overall running time: 246.1943s / 121565.8761 s
env0_first_0:                 episode reward: -47.8000,                 loss: 3.9690
env0_second_0:                 episode reward: 47.8000,                 loss: 4.0536
env1_first_0:                 episode reward: -48.3500,                 loss: nan
env1_second_0:                 episode reward: 48.3500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 843.9,                last time consumption/overall running time: 236.3706s / 121802.2468 s
env0_first_0:                 episode reward: -55.7000,                 loss: 3.7976
env0_second_0:                 episode reward: 55.7000,                 loss: 3.6615
env1_first_0:                 episode reward: -28.7500,                 loss: nan
env1_second_0:                 episode reward: 28.7500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 888.15,                last time consumption/overall running time: 246.3754s / 122048.6222 s
env0_first_0:                 episode reward: -45.8500,                 loss: 3.9730
env0_second_0:                 episode reward: 45.8500,                 loss: 3.8498
env1_first_0:                 episode reward: -54.4500,                 loss: nan
env1_second_0:                 episode reward: 54.4500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 871.5,                last time consumption/overall running time: 240.8298s / 122289.4520 s
env0_first_0:                 episode reward: -60.2000,                 loss: 3.7268
env0_second_0:                 episode reward: 60.2000,                 loss: 3.7946
env1_first_0:                 episode reward: -39.6000,                 loss: nan
env1_second_0:                 episode reward: 39.6000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 939.55,                last time consumption/overall running time: 259.6102s / 122549.0622 s
env0_first_0:                 episode reward: -49.2500,                 loss: 4.2384
env0_second_0:                 episode reward: 49.2500,                 loss: 3.8947
env1_first_0:                 episode reward: -41.0500,                 loss: nan
env1_second_0:                 episode reward: 41.0500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 895.95,                last time consumption/overall running time: 248.8464s / 122797.9085 s
env0_first_0:                 episode reward: -58.1500,                 loss: 4.0921
env0_second_0:                 episode reward: 58.1500,                 loss: 4.0062
env1_first_0:                 episode reward: -42.0500,                 loss: nan
env1_second_0:                 episode reward: 42.0500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 1074.9,                last time consumption/overall running time: 302.0566s / 123099.9652 s
env0_first_0:                 episode reward: -48.3500,                 loss: 4.0567
env0_second_0:                 episode reward: 48.3500,                 loss: 4.1837
env1_first_0:                 episode reward: -43.1500,                 loss: nan
env1_second_0:                 episode reward: 43.1500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1034.15,                last time consumption/overall running time: 314.4607s / 123414.4259 s
env0_first_0:                 episode reward: -40.5500,                 loss: 4.3279
env0_second_0:                 episode reward: 40.5500,                 loss: 3.9415
env1_first_0:                 episode reward: -50.7500,                 loss: nan
env1_second_0:                 episode reward: 50.7500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 1002.9,                last time consumption/overall running time: 299.6034s / 123714.0293 s
env0_first_0:                 episode reward: -37.9500,                 loss: 4.4046
env0_second_0:                 episode reward: 37.9500,                 loss: 4.0667
env1_first_0:                 episode reward: -48.1500,                 loss: nan
env1_second_0:                 episode reward: 48.1500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 1046.2,                last time consumption/overall running time: 297.6167s / 124011.6460 s
env0_first_0:                 episode reward: -43.5000,                 loss: 4.5621
env0_second_0:                 episode reward: 43.5000,                 loss: 3.9189
env1_first_0:                 episode reward: -43.2500,                 loss: nan
env1_second_0:                 episode reward: 43.2500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 1078.6,                last time consumption/overall running time: 310.4337s / 124322.0797 s
env0_first_0:                 episode reward: -48.8000,                 loss: 3.7886
env0_second_0:                 episode reward: 48.8000,                 loss: 3.6762
env1_first_0:                 episode reward: -38.5500,                 loss: nan
env1_second_0:                 episode reward: 38.5500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 899.6,                last time consumption/overall running time: 256.3314s / 124578.4111 s
env0_first_0:                 episode reward: -43.4500,                 loss: 3.6179
env0_second_0:                 episode reward: 43.4500,                 loss: 3.7242
env1_first_0:                 episode reward: -61.4500,                 loss: nan
env1_second_0:                 episode reward: 61.4500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 1043.25,                last time consumption/overall running time: 290.6695s / 124869.0806 s
env0_first_0:                 episode reward: -45.6500,                 loss: 4.1192
env0_second_0:                 episode reward: 45.6500,                 loss: 3.1144
env1_first_0:                 episode reward: -44.3500,                 loss: nan
env1_second_0:                 episode reward: 44.3500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 876.05,                last time consumption/overall running time: 251.2214s / 125120.3020 s
env0_first_0:                 episode reward: -51.5000,                 loss: 4.0020
env0_second_0:                 episode reward: 51.5000,                 loss: 3.3172
env1_first_0:                 episode reward: -43.4500,                 loss: nan
env1_second_0:                 episode reward: 43.4500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 890.2,                last time consumption/overall running time: 255.7921s / 125376.0941 s
env0_first_0:                 episode reward: -62.1000,                 loss: 3.9293
env0_second_0:                 episode reward: 62.1000,                 loss: 3.3087
env1_first_0:                 episode reward: -33.5500,                 loss: nan
env1_second_0:                 episode reward: 33.5500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 884.95,                last time consumption/overall running time: 257.5554s / 125633.6495 s
env0_first_0:                 episode reward: -47.3000,                 loss: 3.8040
env0_second_0:                 episode reward: 47.3000,                 loss: 3.3705
env1_first_0:                 episode reward: -49.3500,                 loss: nan
env1_second_0:                 episode reward: 49.3500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 1060.5,                last time consumption/overall running time: 318.0583s / 125951.7078 s
env0_first_0:                 episode reward: -38.3000,                 loss: 3.9610
env0_second_0:                 episode reward: 38.3000,                 loss: 3.6101
env1_first_0:                 episode reward: -41.5500,                 loss: nan
env1_second_0:                 episode reward: 41.5500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 1071.3,                last time consumption/overall running time: 303.7561s / 126255.4639 s
env0_first_0:                 episode reward: -40.9500,                 loss: 3.8673
env0_second_0:                 episode reward: 40.9500,                 loss: 3.4868
env1_first_0:                 episode reward: -44.4500,                 loss: nan
env1_second_0:                 episode reward: 44.4500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 865.15,                last time consumption/overall running time: 240.9767s / 126496.4407 s
env0_first_0:                 episode reward: -44.9500,                 loss: 3.7816
env0_second_0:                 episode reward: 44.9500,                 loss: 3.5528
env1_first_0:                 episode reward: -53.5000,                 loss: nan
env1_second_0:                 episode reward: 53.5000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 960.95,                last time consumption/overall running time: 267.2312s / 126763.6718 s
env0_first_0:                 episode reward: -46.1500,                 loss: 3.9734
env0_second_0:                 episode reward: 46.1500,                 loss: 3.6037
env1_first_0:                 episode reward: -43.8000,                 loss: nan
env1_second_0:                 episode reward: 43.8000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 888.35,                last time consumption/overall running time: 251.8338s / 127015.5056 s
env0_first_0:                 episode reward: -50.0500,                 loss: 4.0195
env0_second_0:                 episode reward: 50.0500,                 loss: 3.7746
env1_first_0:                 episode reward: -46.2000,                 loss: nan
env1_second_0:                 episode reward: 46.2000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 941.4,                last time consumption/overall running time: 269.2054s / 127284.7110 s
env0_first_0:                 episode reward: -49.7000,                 loss: 4.0858
env0_second_0:                 episode reward: 49.7000,                 loss: 3.8491
env1_first_0:                 episode reward: -39.7500,                 loss: nan
env1_second_0:                 episode reward: 39.7500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 880.55,                last time consumption/overall running time: 255.4518s / 127540.1628 s
env0_first_0:                 episode reward: -53.7000,                 loss: 4.1655
env0_second_0:                 episode reward: 53.7000,                 loss: 3.6598
env1_first_0:                 episode reward: -41.9500,                 loss: nan
env1_second_0:                 episode reward: 41.9500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 952.15,                last time consumption/overall running time: 273.7259s / 127813.8887 s
env0_first_0:                 episode reward: -34.9000,                 loss: 4.1611
env0_second_0:                 episode reward: 34.9000,                 loss: 3.7339
env1_first_0:                 episode reward: -64.5000,                 loss: nan
env1_second_0:                 episode reward: 64.5000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 947.15,                last time consumption/overall running time: 269.1658s / 128083.0545 s
env0_first_0:                 episode reward: -50.5000,                 loss: 4.2455
env0_second_0:                 episode reward: 50.5000,                 loss: 3.6928
env1_first_0:                 episode reward: -56.0500,                 loss: nan
env1_second_0:                 episode reward: 56.0500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 988.65,                last time consumption/overall running time: 282.2867s / 128365.3412 s
env0_first_0:                 episode reward: -39.4500,                 loss: 3.7967
env0_second_0:                 episode reward: 39.4500,                 loss: 3.5371
env1_first_0:                 episode reward: -53.5500,                 loss: nan
env1_second_0:                 episode reward: 53.5500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 836.75,                last time consumption/overall running time: 240.0299s / 128605.3711 s
env0_first_0:                 episode reward: -49.3500,                 loss: 4.0052
env0_second_0:                 episode reward: 49.3500,                 loss: 3.2152
env1_first_0:                 episode reward: -48.3500,                 loss: nan
env1_second_0:                 episode reward: 48.3500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 1045.7,                last time consumption/overall running time: 302.3177s / 128907.6888 s
env0_first_0:                 episode reward: -41.1500,                 loss: 3.7582
env0_second_0:                 episode reward: 41.1500,                 loss: 3.6136
env1_first_0:                 episode reward: -51.3000,                 loss: nan
env1_second_0:                 episode reward: 51.3000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 1028.5,                last time consumption/overall running time: 284.9568s / 129192.6456 s
env0_first_0:                 episode reward: -50.5000,                 loss: 3.5677
env0_second_0:                 episode reward: 50.5000,                 loss: 3.5776
env1_first_0:                 episode reward: -32.1500,                 loss: nan
env1_second_0:                 episode reward: 32.1500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 1072.75,                last time consumption/overall running time: 301.2328s / 129493.8784 s
env0_first_0:                 episode reward: -39.3500,                 loss: 3.4544
env0_second_0:                 episode reward: 39.3500,                 loss: 3.3218
env1_first_0:                 episode reward: -48.5500,                 loss: nan
env1_second_0:                 episode reward: 48.5500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 1051.85,                last time consumption/overall running time: 293.7489s / 129787.6272 s
env0_first_0:                 episode reward: -40.4500,                 loss: 3.5439
env0_second_0:                 episode reward: 40.4500,                 loss: 3.0860
env1_first_0:                 episode reward: -49.7000,                 loss: nan
env1_second_0:                 episode reward: 49.7000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 967.95,                last time consumption/overall running time: 270.3185s / 130057.9458 s
env0_first_0:                 episode reward: -41.4500,                 loss: 3.3631
env0_second_0:                 episode reward: 41.4500,                 loss: 3.1643
env1_first_0:                 episode reward: -55.4500,                 loss: nan
env1_second_0:                 episode reward: 55.4500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 801.8,                last time consumption/overall running time: 224.6503s / 130282.5961 s
env0_first_0:                 episode reward: -54.1500,                 loss: 3.2627
env0_second_0:                 episode reward: 54.1500,                 loss: 3.2013
env1_first_0:                 episode reward: -52.3000,                 loss: nan
env1_second_0:                 episode reward: 52.3000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 1074.2,                last time consumption/overall running time: 302.8982s / 130585.4943 s
env0_first_0:                 episode reward: -36.7000,                 loss: 3.2924
env0_second_0:                 episode reward: 36.7000,                 loss: 3.3301
env1_first_0:                 episode reward: -43.8000,                 loss: nan
env1_second_0:                 episode reward: 43.8000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 976.35,                last time consumption/overall running time: 277.3814s / 130862.8757 s
env0_first_0:                 episode reward: -44.4000,                 loss: 3.2965
env0_second_0:                 episode reward: 44.4000,                 loss: 3.5158
env1_first_0:                 episode reward: -44.7500,                 loss: nan
env1_second_0:                 episode reward: 44.7500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 831.3,                last time consumption/overall running time: 231.7394s / 131094.6151 s
env0_first_0:                 episode reward: -58.0000,                 loss: 3.4688
env0_second_0:                 episode reward: 58.0000,                 loss: 3.7323
env1_first_0:                 episode reward: -35.6500,                 loss: nan
env1_second_0:                 episode reward: 35.6500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 904.4,                last time consumption/overall running time: 250.6691s / 131345.2842 s
env0_first_0:                 episode reward: -43.4000,                 loss: 3.8489
env0_second_0:                 episode reward: 43.4000,                 loss: 3.7955
env1_first_0:                 episode reward: -44.0000,                 loss: nan
env1_second_0:                 episode reward: 44.0000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 1050.7,                last time consumption/overall running time: 306.0186s / 131651.3028 s
env0_first_0:                 episode reward: -51.7500,                 loss: 3.8144
env0_second_0:                 episode reward: 51.7500,                 loss: 3.8021
env1_first_0:                 episode reward: -37.0500,                 loss: nan
env1_second_0:                 episode reward: 37.0500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 884.35,                last time consumption/overall running time: 250.5459s / 131901.8487 s
env0_first_0:                 episode reward: -49.8500,                 loss: 4.3521
env0_second_0:                 episode reward: 49.8500,                 loss: 4.0569
env1_first_0:                 episode reward: -48.8000,                 loss: nan
env1_second_0:                 episode reward: 48.8000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 1047.6,                last time consumption/overall running time: 295.9376s / 132197.7862 s
env0_first_0:                 episode reward: -40.0000,                 loss: 4.4501
env0_second_0:                 episode reward: 40.0000,                 loss: 3.8183
env1_first_0:                 episode reward: -40.2500,                 loss: nan
env1_second_0:                 episode reward: 40.2500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 921.85,                last time consumption/overall running time: 263.2606s / 132461.0469 s
env0_first_0:                 episode reward: -51.7000,                 loss: 4.0669
env0_second_0:                 episode reward: 51.7000,                 loss: 3.8362
env1_first_0:                 episode reward: -44.6500,                 loss: nan
env1_second_0:                 episode reward: 44.6500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 835.55,                last time consumption/overall running time: 236.2248s / 132697.2716 s
env0_first_0:                 episode reward: -44.2000,                 loss: 3.8781
env0_second_0:                 episode reward: 44.2000,                 loss: 3.9559
env1_first_0:                 episode reward: -63.4000,                 loss: nan
env1_second_0:                 episode reward: 63.4000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 1011.3,                last time consumption/overall running time: 284.9000s / 132982.1716 s
env0_first_0:                 episode reward: -42.7000,                 loss: 3.7182
env0_second_0:                 episode reward: 42.7000,                 loss: 3.8916
env1_first_0:                 episode reward: -43.8500,                 loss: nan
env1_second_0:                 episode reward: 43.8500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 956.65,                last time consumption/overall running time: 271.0703s / 133253.2420 s
env0_first_0:                 episode reward: -51.9500,                 loss: 3.8907
env0_second_0:                 episode reward: 51.9500,                 loss: 4.0271
env1_first_0:                 episode reward: -39.8000,                 loss: nan
env1_second_0:                 episode reward: 39.8000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 840.25,                last time consumption/overall running time: 240.3521s / 133493.5941 s
env0_first_0:                 episode reward: -48.9000,                 loss: 4.2707
env0_second_0:                 episode reward: 48.9000,                 loss: 4.2194
env1_first_0:                 episode reward: -45.4500,                 loss: nan
env1_second_0:                 episode reward: 45.4500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 1018.1,                last time consumption/overall running time: 291.6990s / 133785.2931 s
env0_first_0:                 episode reward: -40.4000,                 loss: 4.2260
env0_second_0:                 episode reward: 40.4000,                 loss: 3.8911
env1_first_0:                 episode reward: -50.8000,                 loss: nan
env1_second_0:                 episode reward: 50.8000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 851.3,                last time consumption/overall running time: 237.7949s / 134023.0880 s
env0_first_0:                 episode reward: -40.8000,                 loss: 4.2457
env0_second_0:                 episode reward: 40.8000,                 loss: 4.0295
env1_first_0:                 episode reward: -58.7500,                 loss: nan
env1_second_0:                 episode reward: 58.7500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 869.2,                last time consumption/overall running time: 245.7620s / 134268.8501 s
env0_first_0:                 episode reward: -54.0500,                 loss: 4.1187
env0_second_0:                 episode reward: 54.0500,                 loss: 4.0972
env1_first_0:                 episode reward: -42.6500,                 loss: nan
env1_second_0:                 episode reward: 42.6500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 782.2,                last time consumption/overall running time: 221.2374s / 134490.0874 s
env0_first_0:                 episode reward: -53.5000,                 loss: 4.0096
env0_second_0:                 episode reward: 53.5000,                 loss: 4.3468
env1_first_0:                 episode reward: -50.4500,                 loss: nan
env1_second_0:                 episode reward: 50.4500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 835.05,                last time consumption/overall running time: 233.6712s / 134723.7587 s
env0_first_0:                 episode reward: -62.9000,                 loss: 4.0507
env0_second_0:                 episode reward: 62.9000,                 loss: 4.2282
env1_first_0:                 episode reward: -38.3500,                 loss: nan
env1_second_0:                 episode reward: 38.3500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 946.9,                last time consumption/overall running time: 273.8118s / 134997.5704 s
env0_first_0:                 episode reward: -52.6500,                 loss: 4.3568
env0_second_0:                 episode reward: 52.6500,                 loss: 4.2512
env1_first_0:                 episode reward: -49.0000,                 loss: nan
env1_second_0:                 episode reward: 49.0000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 1147.8,                last time consumption/overall running time: 317.5270s / 135315.0974 s
env0_first_0:                 episode reward: -44.7000,                 loss: 4.4955
env0_second_0:                 episode reward: 44.7000,                 loss: 3.9144
env1_first_0:                 episode reward: -26.9500,                 loss: nan
env1_second_0:                 episode reward: 26.9500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 982.8,                last time consumption/overall running time: 269.1827s / 135584.2801 s
env0_first_0:                 episode reward: -48.4000,                 loss: 4.4692
env0_second_0:                 episode reward: 48.4000,                 loss: 3.8113
env1_first_0:                 episode reward: -55.2000,                 loss: nan
env1_second_0:                 episode reward: 55.2000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 1005.55,                last time consumption/overall running time: 276.7838s / 135861.0640 s
env0_first_0:                 episode reward: -41.7000,                 loss: 4.3535
env0_second_0:                 episode reward: 41.7000,                 loss: 3.6095
env1_first_0:                 episode reward: -46.9500,                 loss: nan
env1_second_0:                 episode reward: 46.9500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 718.3,                last time consumption/overall running time: 198.0230s / 136059.0870 s
env0_first_0:                 episode reward: -46.4500,                 loss: 4.0277
env0_second_0:                 episode reward: 46.4500,                 loss: 3.7699
env1_first_0:                 episode reward: -54.5500,                 loss: nan
env1_second_0:                 episode reward: 54.5500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 993.1,                last time consumption/overall running time: 273.6088s / 136332.6957 s
env0_first_0:                 episode reward: -50.9000,                 loss: 4.3228
env0_second_0:                 episode reward: 50.9000,                 loss: 3.9933
env1_first_0:                 episode reward: -45.1000,                 loss: nan
env1_second_0:                 episode reward: 45.1000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 1059.25,                last time consumption/overall running time: 293.2515s / 136625.9472 s
env0_first_0:                 episode reward: -51.4500,                 loss: 4.3231
env0_second_0:                 episode reward: 51.4500,                 loss: 3.7881
env1_first_0:                 episode reward: -45.0500,                 loss: nan
env1_second_0:                 episode reward: 45.0500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 1025.05,                last time consumption/overall running time: 287.5364s / 136913.4836 s
env0_first_0:                 episode reward: -44.9500,                 loss: 4.7071
env0_second_0:                 episode reward: 44.9500,                 loss: 4.1593
env1_first_0:                 episode reward: -52.8000,                 loss: nan
env1_second_0:                 episode reward: 52.8000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 897.2,                last time consumption/overall running time: 248.0577s / 137161.5413 s
env0_first_0:                 episode reward: -45.6500,                 loss: 4.6605
env0_second_0:                 episode reward: 45.6500,                 loss: 4.1266
env1_first_0:                 episode reward: -43.4500,                 loss: nan
env1_second_0:                 episode reward: 43.4500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 1048.85,                last time consumption/overall running time: 290.5374s / 137452.0786 s
env0_first_0:                 episode reward: -37.9500,                 loss: 4.4343
env0_second_0:                 episode reward: 37.9500,                 loss: 4.1339
env1_first_0:                 episode reward: -37.8500,                 loss: nan
env1_second_0:                 episode reward: 37.8500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 973.55,                last time consumption/overall running time: 270.9781s / 137723.0567 s
env0_first_0:                 episode reward: -48.5500,                 loss: 4.1345
env0_second_0:                 episode reward: 48.5500,                 loss: 3.8274
env1_first_0:                 episode reward: -42.1500,                 loss: nan
env1_second_0:                 episode reward: 42.1500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 908.6,                last time consumption/overall running time: 261.0043s / 137984.0610 s
env0_first_0:                 episode reward: -59.0500,                 loss: 4.1145
env0_second_0:                 episode reward: 59.0500,                 loss: 3.9856
env1_first_0:                 episode reward: -41.1000,                 loss: nan
env1_second_0:                 episode reward: 41.1000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 856.15,                last time consumption/overall running time: 241.4086s / 138225.4696 s
env0_first_0:                 episode reward: -48.7500,                 loss: 4.2377
env0_second_0:                 episode reward: 48.7500,                 loss: 4.0841
env1_first_0:                 episode reward: -46.8500,                 loss: nan
env1_second_0:                 episode reward: 46.8500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 889.1,                last time consumption/overall running time: 254.9315s / 138480.4011 s
env0_first_0:                 episode reward: -62.9500,                 loss: 4.3091
env0_second_0:                 episode reward: 62.9500,                 loss: 3.9462
env1_first_0:                 episode reward: -34.0500,                 loss: nan
env1_second_0:                 episode reward: 34.0500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 931.7,                last time consumption/overall running time: 261.3574s / 138741.7586 s
env0_first_0:                 episode reward: -41.2000,                 loss: 4.5113
env0_second_0:                 episode reward: 41.2000,                 loss: 3.8798
env1_first_0:                 episode reward: -55.7000,                 loss: nan
env1_second_0:                 episode reward: 55.7000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 919.9,                last time consumption/overall running time: 260.4217s / 139002.1802 s
env0_first_0:                 episode reward: -55.6500,                 loss: 4.4311
env0_second_0:                 episode reward: 55.6500,                 loss: 3.9462
env1_first_0:                 episode reward: -33.6500,                 loss: nan
env1_second_0:                 episode reward: 33.6500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 905.25,                last time consumption/overall running time: 253.1360s / 139255.3163 s
env0_first_0:                 episode reward: -59.4000,                 loss: 4.6218
env0_second_0:                 episode reward: 59.4000,                 loss: 3.8923
env1_first_0:                 episode reward: -33.2500,                 loss: nan
env1_second_0:                 episode reward: 33.2500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 1095.05,                last time consumption/overall running time: 314.8341s / 139570.1504 s
env0_first_0:                 episode reward: -36.1000,                 loss: 4.4640
env0_second_0:                 episode reward: 36.1000,                 loss: 3.9886
env1_first_0:                 episode reward: -47.1500,                 loss: nan
env1_second_0:                 episode reward: 47.1500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 884.8,                last time consumption/overall running time: 245.4564s / 139815.6068 s
env0_first_0:                 episode reward: -48.6000,                 loss: 3.8677
env0_second_0:                 episode reward: 48.6000,                 loss: 3.8600
env1_first_0:                 episode reward: -50.1000,                 loss: nan
env1_second_0:                 episode reward: 50.1000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 972.65,                last time consumption/overall running time: 277.0637s / 140092.6704 s
env0_first_0:                 episode reward: -35.6500,                 loss: 3.8134
env0_second_0:                 episode reward: 35.6500,                 loss: 3.7664
env1_first_0:                 episode reward: -59.1500,                 loss: nan
env1_second_0:                 episode reward: 59.1500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 840.25,                last time consumption/overall running time: 237.0748s / 140329.7453 s
env0_first_0:                 episode reward: -48.1000,                 loss: 3.9824
env0_second_0:                 episode reward: 48.1000,                 loss: 3.7852
env1_first_0:                 episode reward: -59.8000,                 loss: nan
env1_second_0:                 episode reward: 59.8000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 947.35,                last time consumption/overall running time: 271.1485s / 140600.8938 s
env0_first_0:                 episode reward: -45.9000,                 loss: 4.1879
env0_second_0:                 episode reward: 45.9000,                 loss: 3.9218
env1_first_0:                 episode reward: -43.8000,                 loss: nan
env1_second_0:                 episode reward: 43.8000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 896.35,                last time consumption/overall running time: 256.5340s / 140857.4278 s
env0_first_0:                 episode reward: -60.9000,                 loss: 4.2786
env0_second_0:                 episode reward: 60.9000,                 loss: 3.8487
env1_first_0:                 episode reward: -46.4000,                 loss: nan
env1_second_0:                 episode reward: 46.4000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 915.1,                last time consumption/overall running time: 262.7720s / 141120.1998 s
env0_first_0:                 episode reward: -39.4000,                 loss: 4.2782
env0_second_0:                 episode reward: 39.4000,                 loss: 4.1006
env1_first_0:                 episode reward: -43.5000,                 loss: nan
env1_second_0:                 episode reward: 43.5000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 963.8,                last time consumption/overall running time: 266.6472s / 141386.8470 s
env0_first_0:                 episode reward: -50.6500,                 loss: 4.0403
env0_second_0:                 episode reward: 50.6500,                 loss: 4.0886
env1_first_0:                 episode reward: -42.4000,                 loss: nan
env1_second_0:                 episode reward: 42.4000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 790.95,                last time consumption/overall running time: 216.8712s / 141603.7182 s
env0_first_0:                 episode reward: -49.7000,                 loss: 3.9941
env0_second_0:                 episode reward: 49.7000,                 loss: 4.1686
env1_first_0:                 episode reward: -42.4500,                 loss: nan
env1_second_0:                 episode reward: 42.4500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 1076.15,                last time consumption/overall running time: 295.5308s / 141899.2490 s
env0_first_0:                 episode reward: -52.1000,                 loss: 3.9183
env0_second_0:                 episode reward: 52.1000,                 loss: 3.8701
env1_first_0:                 episode reward: -39.3000,                 loss: nan
env1_second_0:                 episode reward: 39.3000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 958.15,                last time consumption/overall running time: 265.9786s / 142165.2276 s
env0_first_0:                 episode reward: -51.9000,                 loss: 4.2376
env0_second_0:                 episode reward: 51.9000,                 loss: 4.0651
env1_first_0:                 episode reward: -36.9000,                 loss: nan
env1_second_0:                 episode reward: 36.9000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 848.6,                last time consumption/overall running time: 238.4533s / 142403.6809 s
env0_first_0:                 episode reward: -41.1000,                 loss: 4.5178
env0_second_0:                 episode reward: 41.1000,                 loss: 4.0428
env1_first_0:                 episode reward: -53.0000,                 loss: nan
env1_second_0:                 episode reward: 53.0000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 898.4,                last time consumption/overall running time: 252.7576s / 142656.4385 s
env0_first_0:                 episode reward: -53.3000,                 loss: 4.3176
env0_second_0:                 episode reward: 53.3000,                 loss: 3.8693
env1_first_0:                 episode reward: -41.7500,                 loss: nan
env1_second_0:                 episode reward: 41.7500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 1105.45,                last time consumption/overall running time: 316.1376s / 142972.5761 s
env0_first_0:                 episode reward: -40.3500,                 loss: 4.1938
env0_second_0:                 episode reward: 40.3500,                 loss: 4.1476
env1_first_0:                 episode reward: -48.3500,                 loss: nan
env1_second_0:                 episode reward: 48.3500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 976.5,                last time consumption/overall running time: 281.4175s / 143253.9936 s
env0_first_0:                 episode reward: -50.1500,                 loss: 3.8748
env0_second_0:                 episode reward: 50.1500,                 loss: 3.8861
env1_first_0:                 episode reward: -58.8000,                 loss: nan
env1_second_0:                 episode reward: 58.8000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 973.1,                last time consumption/overall running time: 269.7197s / 143523.7133 s
env0_first_0:                 episode reward: -51.4500,                 loss: 4.0358
env0_second_0:                 episode reward: 51.4500,                 loss: 3.8915
env1_first_0:                 episode reward: -49.0500,                 loss: nan
env1_second_0:                 episode reward: 49.0500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 1006.6,                last time consumption/overall running time: 279.8594s / 143803.5726 s
env0_first_0:                 episode reward: -34.5000,                 loss: 3.8476
env0_second_0:                 episode reward: 34.5000,                 loss: 3.9434
env1_first_0:                 episode reward: -48.7000,                 loss: nan
env1_second_0:                 episode reward: 48.7000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 859.8,                last time consumption/overall running time: 239.7003s / 144043.2729 s
env0_first_0:                 episode reward: -51.1000,                 loss: 4.0913
env0_second_0:                 episode reward: 51.1000,                 loss: 3.9271
env1_first_0:                 episode reward: -50.5500,                 loss: nan
env1_second_0:                 episode reward: 50.5500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 913.25,                last time consumption/overall running time: 250.9574s / 144294.2304 s
env0_first_0:                 episode reward: -50.4000,                 loss: 4.4650
env0_second_0:                 episode reward: 50.4000,                 loss: 4.2317
env1_first_0:                 episode reward: -41.2000,                 loss: nan
env1_second_0:                 episode reward: 41.2000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 990.85,                last time consumption/overall running time: 271.2260s / 144565.4564 s
env0_first_0:                 episode reward: -29.9500,                 loss: 4.6059
env0_second_0:                 episode reward: 29.9500,                 loss: 4.2590
env1_first_0:                 episode reward: -48.2500,                 loss: nan
env1_second_0:                 episode reward: 48.2500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 1310.4,                last time consumption/overall running time: 355.7433s / 144921.1997 s
env0_first_0:                 episode reward: -38.7500,                 loss: 4.2044
env0_second_0:                 episode reward: 38.7500,                 loss: 3.8367
env1_first_0:                 episode reward: -34.6000,                 loss: nan
env1_second_0:                 episode reward: 34.6000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 1062.25,                last time consumption/overall running time: 288.1692s / 145209.3689 s
env0_first_0:                 episode reward: -40.4500,                 loss: 3.7402
env0_second_0:                 episode reward: 40.4500,                 loss: 3.5232
env1_first_0:                 episode reward: -36.1500,                 loss: nan
env1_second_0:                 episode reward: 36.1500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 1008.25,                last time consumption/overall running time: 274.9031s / 145484.2720 s
env0_first_0:                 episode reward: -40.9000,                 loss: 3.5976
env0_second_0:                 episode reward: 40.9000,                 loss: 3.3625
env1_first_0:                 episode reward: -39.7000,                 loss: nan
env1_second_0:                 episode reward: 39.7000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 1025.1,                last time consumption/overall running time: 293.2516s / 145777.5236 s
env0_first_0:                 episode reward: -46.0500,                 loss: 3.4455
env0_second_0:                 episode reward: 46.0500,                 loss: 3.4222
env1_first_0:                 episode reward: -50.0000,                 loss: nan
env1_second_0:                 episode reward: 50.0000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 873.95,                last time consumption/overall running time: 242.1073s / 146019.6309 s
env0_first_0:                 episode reward: -59.8500,                 loss: 3.6631
env0_second_0:                 episode reward: 59.8500,                 loss: 3.7371
env1_first_0:                 episode reward: -48.3500,                 loss: nan
env1_second_0:                 episode reward: 48.3500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 821.15,                last time consumption/overall running time: 231.2760s / 146250.9069 s
env0_first_0:                 episode reward: -41.3500,                 loss: 3.8374
env0_second_0:                 episode reward: 41.3500,                 loss: 4.0942
env1_first_0:                 episode reward: -62.2000,                 loss: nan
env1_second_0:                 episode reward: 62.2000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 876.45,                last time consumption/overall running time: 234.7695s / 146485.6763 s
env0_first_0:                 episode reward: -67.0500,                 loss: 4.0251
env0_second_0:                 episode reward: 67.0500,                 loss: 3.9834
env1_first_0:                 episode reward: -38.4000,                 loss: nan
env1_second_0:                 episode reward: 38.4000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 810.8,                last time consumption/overall running time: 217.2590s / 146702.9354 s
env0_first_0:                 episode reward: -54.4500,                 loss: 3.9910
env0_second_0:                 episode reward: 54.4500,                 loss: 4.0691
env1_first_0:                 episode reward: -60.2500,                 loss: nan
env1_second_0:                 episode reward: 60.2500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 839.15,                last time consumption/overall running time: 225.0785s / 146928.0138 s
env0_first_0:                 episode reward: -42.9500,                 loss: 4.2007
env0_second_0:                 episode reward: 42.9500,                 loss: 4.2976
env1_first_0:                 episode reward: -59.0500,                 loss: nan
env1_second_0:                 episode reward: 59.0500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 871.65,                last time consumption/overall running time: 232.8625s / 147160.8763 s
env0_first_0:                 episode reward: -51.3000,                 loss: 4.6938
env0_second_0:                 episode reward: 51.3000,                 loss: 4.2285
env1_first_0:                 episode reward: -44.0500,                 loss: nan
env1_second_0:                 episode reward: 44.0500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 838.1,                last time consumption/overall running time: 227.8379s / 147388.7142 s
env0_first_0:                 episode reward: -61.2500,                 loss: 4.5150
env0_second_0:                 episode reward: 61.2500,                 loss: 4.0639
env1_first_0:                 episode reward: -26.1000,                 loss: nan
env1_second_0:                 episode reward: 26.1000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 925.6,                last time consumption/overall running time: 250.5365s / 147639.2507 s
env0_first_0:                 episode reward: -37.2500,                 loss: 4.3697
env0_second_0:                 episode reward: 37.2500,                 loss: 4.2466
env1_first_0:                 episode reward: -65.8500,                 loss: nan
env1_second_0:                 episode reward: 65.8500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 1056.95,                last time consumption/overall running time: 286.0342s / 147925.2849 s
env0_first_0:                 episode reward: -47.8000,                 loss: 4.3439
env0_second_0:                 episode reward: 47.8000,                 loss: 3.9521
env1_first_0:                 episode reward: -41.2000,                 loss: nan
env1_second_0:                 episode reward: 41.2000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 1104.25,                last time consumption/overall running time: 305.2257s / 148230.5105 s
env0_first_0:                 episode reward: -39.1000,                 loss: 3.9918
env0_second_0:                 episode reward: 39.1000,                 loss: 3.7678
env1_first_0:                 episode reward: -35.8000,                 loss: nan
env1_second_0:                 episode reward: 35.8000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 1016.9,                last time consumption/overall running time: 291.6780s / 148522.1885 s
env0_first_0:                 episode reward: -48.2000,                 loss: 4.1599
env0_second_0:                 episode reward: 48.2000,                 loss: 3.4427
env1_first_0:                 episode reward: -40.1000,                 loss: nan
env1_second_0:                 episode reward: 40.1000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 977.7,                last time consumption/overall running time: 274.6017s / 148796.7902 s
env0_first_0:                 episode reward: -48.9500,                 loss: 3.8136
env0_second_0:                 episode reward: 48.9500,                 loss: 3.6477
env1_first_0:                 episode reward: -48.2000,                 loss: nan
env1_second_0:                 episode reward: 48.2000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 968.35,                last time consumption/overall running time: 262.5328s / 149059.3230 s
env0_first_0:                 episode reward: -50.5500,                 loss: 3.5804
env0_second_0:                 episode reward: 50.5500,                 loss: 3.6838
env1_first_0:                 episode reward: -38.0500,                 loss: nan
env1_second_0:                 episode reward: 38.0500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 932.5,                last time consumption/overall running time: 255.8235s / 149315.1464 s
env0_first_0:                 episode reward: -55.0000,                 loss: 3.6809
env0_second_0:                 episode reward: 55.0000,                 loss: 4.0999
env1_first_0:                 episode reward: -50.3000,                 loss: nan
env1_second_0:                 episode reward: 50.3000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 859.9,                last time consumption/overall running time: 233.2020s / 149548.3484 s
env0_first_0:                 episode reward: -64.4000,                 loss: 3.9959
env0_second_0:                 episode reward: 64.4000,                 loss: 4.0689
env1_first_0:                 episode reward: -46.0000,                 loss: nan
env1_second_0:                 episode reward: 46.0000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 976.1,                last time consumption/overall running time: 276.0768s / 149824.4252 s
env0_first_0:                 episode reward: -47.4500,                 loss: 4.0734
env0_second_0:                 episode reward: 47.4500,                 loss: 3.9153
env1_first_0:                 episode reward: -45.4500,                 loss: nan
env1_second_0:                 episode reward: 45.4500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 941.85,                last time consumption/overall running time: 266.9520s / 150091.3771 s
env0_first_0:                 episode reward: -44.4000,                 loss: 4.1712
env0_second_0:                 episode reward: 44.4000,                 loss: 3.8479
env1_first_0:                 episode reward: -49.3500,                 loss: nan
env1_second_0:                 episode reward: 49.3500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 958.15,                last time consumption/overall running time: 282.7903s / 150374.1674 s
env0_first_0:                 episode reward: -46.1500,                 loss: 3.9239
env0_second_0:                 episode reward: 46.1500,                 loss: 3.6345
env1_first_0:                 episode reward: -52.6500,                 loss: nan
env1_second_0:                 episode reward: 52.6500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 773.15,                last time consumption/overall running time: 210.5322s / 150584.6996 s
env0_first_0:                 episode reward: -31.3500,                 loss: 3.7297
env0_second_0:                 episode reward: 31.3500,                 loss: 3.6925
env1_first_0:                 episode reward: -55.0500,                 loss: nan
env1_second_0:                 episode reward: 55.0500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 956.15,                last time consumption/overall running time: 259.1028s / 150843.8024 s
env0_first_0:                 episode reward: -45.6500,                 loss: 4.0678
env0_second_0:                 episode reward: 45.6500,                 loss: 3.5521
env1_first_0:                 episode reward: -40.0500,                 loss: nan
env1_second_0:                 episode reward: 40.0500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 886.0,                last time consumption/overall running time: 240.5247s / 151084.3271 s
env0_first_0:                 episode reward: -43.7500,                 loss: 3.8792
env0_second_0:                 episode reward: 43.7500,                 loss: 3.7086
env1_first_0:                 episode reward: -45.4500,                 loss: nan
env1_second_0:                 episode reward: 45.4500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 835.85,                last time consumption/overall running time: 251.0488s / 151335.3759 s
env0_first_0:                 episode reward: -49.5500,                 loss: 3.6288
env0_second_0:                 episode reward: 49.5500,                 loss: 3.8986
env1_first_0:                 episode reward: -45.5500,                 loss: nan
env1_second_0:                 episode reward: 45.5500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 956.85,                last time consumption/overall running time: 269.1679s / 151604.5439 s
env0_first_0:                 episode reward: -39.0500,                 loss: 3.8239
env0_second_0:                 episode reward: 39.0500,                 loss: 3.8609
env1_first_0:                 episode reward: -50.9000,                 loss: nan
env1_second_0:                 episode reward: 50.9000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 1017.2,                last time consumption/overall running time: 286.3514s / 151890.8952 s
env0_first_0:                 episode reward: -40.9000,                 loss: 3.8440
env0_second_0:                 episode reward: 40.9000,                 loss: 3.7452
env1_first_0:                 episode reward: -48.8500,                 loss: nan
env1_second_0:                 episode reward: 48.8500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 980.2,                last time consumption/overall running time: 269.3297s / 152160.2249 s
env0_first_0:                 episode reward: -40.9500,                 loss: 3.9028
env0_second_0:                 episode reward: 40.9500,                 loss: 3.6588
env1_first_0:                 episode reward: -46.6000,                 loss: nan
env1_second_0:                 episode reward: 46.6000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 960.85,                last time consumption/overall running time: 262.2584s / 152422.4833 s
env0_first_0:                 episode reward: -47.0500,                 loss: 3.9836
env0_second_0:                 episode reward: 47.0500,                 loss: 3.6820
env1_first_0:                 episode reward: -36.6000,                 loss: nan
env1_second_0:                 episode reward: 36.6000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 961.65,                last time consumption/overall running time: 263.4439s / 152685.9272 s
env0_first_0:                 episode reward: -52.3000,                 loss: 3.7201
env0_second_0:                 episode reward: 52.3000,                 loss: 3.8545
env1_first_0:                 episode reward: -35.6500,                 loss: nan
env1_second_0:                 episode reward: 35.6500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 1048.55,                last time consumption/overall running time: 286.2015s / 152972.1287 s
env0_first_0:                 episode reward: -42.9500,                 loss: 3.8592
env0_second_0:                 episode reward: 42.9500,                 loss: 4.0876
env1_first_0:                 episode reward: -39.7000,                 loss: nan
env1_second_0:                 episode reward: 39.7000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 881.95,                last time consumption/overall running time: 241.1406s / 153213.2693 s
env0_first_0:                 episode reward: -43.1500,                 loss: 4.1982
env0_second_0:                 episode reward: 43.1500,                 loss: 3.8886
env1_first_0:                 episode reward: -50.4000,                 loss: nan
env1_second_0:                 episode reward: 50.4000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 1023.2,                last time consumption/overall running time: 284.6149s / 153497.8842 s
env0_first_0:                 episode reward: -37.7500,                 loss: 3.9186
env0_second_0:                 episode reward: 37.7500,                 loss: 3.8712
env1_first_0:                 episode reward: -62.0000,                 loss: nan
env1_second_0:                 episode reward: 62.0000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 893.25,                last time consumption/overall running time: 242.4985s / 153740.3827 s
env0_first_0:                 episode reward: -55.5000,                 loss: 4.0973
env0_second_0:                 episode reward: 55.5000,                 loss: 3.7621
env1_first_0:                 episode reward: -40.8000,                 loss: nan
env1_second_0:                 episode reward: 40.8000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 919.35,                last time consumption/overall running time: 266.2296s / 154006.6123 s
env0_first_0:                 episode reward: -38.4500,                 loss: 4.1189
env0_second_0:                 episode reward: 38.4500,                 loss: 3.8234
env1_first_0:                 episode reward: -44.0500,                 loss: nan
env1_second_0:                 episode reward: 44.0500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 848.35,                last time consumption/overall running time: 246.0107s / 154252.6230 s
env0_first_0:                 episode reward: -50.3500,                 loss: 3.9964
env0_second_0:                 episode reward: 50.3500,                 loss: 3.9286
env1_first_0:                 episode reward: -46.7500,                 loss: nan
env1_second_0:                 episode reward: 46.7500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 927.45,                last time consumption/overall running time: 263.1372s / 154515.7602 s
env0_first_0:                 episode reward: -47.6000,                 loss: 4.0875
env0_second_0:                 episode reward: 47.6000,                 loss: 4.0003
env1_first_0:                 episode reward: -48.7000,                 loss: nan
env1_second_0:                 episode reward: 48.7000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 1041.9,                last time consumption/overall running time: 293.6961s / 154809.4563 s
env0_first_0:                 episode reward: -51.9500,                 loss: 4.0774
env0_second_0:                 episode reward: 51.9500,                 loss: 4.3562
env1_first_0:                 episode reward: -36.8000,                 loss: nan
env1_second_0:                 episode reward: 36.8000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 1047.3,                last time consumption/overall running time: 286.8845s / 155096.3408 s
env0_first_0:                 episode reward: -50.7000,                 loss: 4.5858
env0_second_0:                 episode reward: 50.7000,                 loss: 4.0467
env1_first_0:                 episode reward: -40.5000,                 loss: nan
env1_second_0:                 episode reward: 40.5000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 949.5,                last time consumption/overall running time: 263.5474s / 155359.8883 s
env0_first_0:                 episode reward: -55.5000,                 loss: 4.4634
env0_second_0:                 episode reward: 55.5000,                 loss: 3.8707
env1_first_0:                 episode reward: -33.4000,                 loss: nan
env1_second_0:                 episode reward: 33.4000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 961.05,                last time consumption/overall running time: 270.9593s / 155630.8475 s
env0_first_0:                 episode reward: -50.5500,                 loss: 4.3246
env0_second_0:                 episode reward: 50.5500,                 loss: 4.0894
env1_first_0:                 episode reward: -43.9000,                 loss: nan
env1_second_0:                 episode reward: 43.9000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 864.5,                last time consumption/overall running time: 253.4145s / 155884.2620 s
env0_first_0:                 episode reward: -54.8500,                 loss: 4.0417
env0_second_0:                 episode reward: 54.8500,                 loss: 4.0169
env1_first_0:                 episode reward: -37.9000,                 loss: nan
env1_second_0:                 episode reward: 37.9000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 859.55,                last time consumption/overall running time: 242.3391s / 156126.6011 s
env0_first_0:                 episode reward: -53.6500,                 loss: 3.9820
env0_second_0:                 episode reward: 53.6500,                 loss: 4.0609
env1_first_0:                 episode reward: -52.0000,                 loss: nan
env1_second_0:                 episode reward: 52.0000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 830.65,                last time consumption/overall running time: 224.1746s / 156350.7757 s
env0_first_0:                 episode reward: -41.5000,                 loss: 4.1139
env0_second_0:                 episode reward: 41.5000,                 loss: 4.4347
env1_first_0:                 episode reward: -56.4000,                 loss: nan
env1_second_0:                 episode reward: 56.4000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 859.8,                last time consumption/overall running time: 234.0828s / 156584.8584 s
env0_first_0:                 episode reward: -53.3500,                 loss: 4.4712
env0_second_0:                 episode reward: 53.3500,                 loss: 4.5459
env1_first_0:                 episode reward: -45.4000,                 loss: nan
env1_second_0:                 episode reward: 45.4000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 945.85,                last time consumption/overall running time: 258.7060s / 156843.5645 s
env0_first_0:                 episode reward: -45.6000,                 loss: 4.3957
env0_second_0:                 episode reward: 45.6000,                 loss: 4.6055
env1_first_0:                 episode reward: -47.0500,                 loss: nan
env1_second_0:                 episode reward: 47.0500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 902.8,                last time consumption/overall running time: 256.2253s / 157099.7898 s
env0_first_0:                 episode reward: -46.6000,                 loss: 4.3723
env0_second_0:                 episode reward: 46.6000,                 loss: 4.7745
env1_first_0:                 episode reward: -51.5500,                 loss: nan
env1_second_0:                 episode reward: 51.5500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 891.1,                last time consumption/overall running time: 260.8183s / 157360.6081 s
env0_first_0:                 episode reward: -55.8000,                 loss: 4.3158
env0_second_0:                 episode reward: 55.8000,                 loss: 4.7267
env1_first_0:                 episode reward: -32.9500,                 loss: nan
env1_second_0:                 episode reward: 32.9500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 789.35,                last time consumption/overall running time: 221.2779s / 157581.8860 s
env0_first_0:                 episode reward: -51.0000,                 loss: 4.3150
env0_second_0:                 episode reward: 51.0000,                 loss: 4.5567
env1_first_0:                 episode reward: -46.1500,                 loss: nan
env1_second_0:                 episode reward: 46.1500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 975.9,                last time consumption/overall running time: 263.8021s / 157845.6881 s
env0_first_0:                 episode reward: -51.3500,                 loss: 4.3569
env0_second_0:                 episode reward: 51.3500,                 loss: 4.1841
env1_first_0:                 episode reward: -45.0000,                 loss: nan
env1_second_0:                 episode reward: 45.0000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 841.35,                last time consumption/overall running time: 237.1721s / 158082.8602 s
env0_first_0:                 episode reward: -54.0000,                 loss: 4.3039
env0_second_0:                 episode reward: 54.0000,                 loss: 4.2684
env1_first_0:                 episode reward: -46.7500,                 loss: nan
env1_second_0:                 episode reward: 46.7500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 882.65,                last time consumption/overall running time: 240.9876s / 158323.8478 s
env0_first_0:                 episode reward: -32.3000,                 loss: 4.3625
env0_second_0:                 episode reward: 32.3000,                 loss: 4.5330
env1_first_0:                 episode reward: -52.5500,                 loss: nan
env1_second_0:                 episode reward: 52.5500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 833.1,                last time consumption/overall running time: 241.9096s / 158565.7575 s
env0_first_0:                 episode reward: -43.2000,                 loss: 4.5967
env0_second_0:                 episode reward: 43.2000,                 loss: 4.4748
env1_first_0:                 episode reward: -57.0500,                 loss: nan
env1_second_0:                 episode reward: 57.0500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 970.05,                last time consumption/overall running time: 268.2540s / 158834.0115 s
env0_first_0:                 episode reward: -44.5500,                 loss: 4.6595
env0_second_0:                 episode reward: 44.5500,                 loss: 4.3951
env1_first_0:                 episode reward: -52.5500,                 loss: nan
env1_second_0:                 episode reward: 52.5500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 1065.3,                last time consumption/overall running time: 295.3994s / 159129.4109 s
env0_first_0:                 episode reward: -39.7500,                 loss: 4.3149
env0_second_0:                 episode reward: 39.7500,                 loss: 4.4417
env1_first_0:                 episode reward: -40.5000,                 loss: nan
env1_second_0:                 episode reward: 40.5000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 747.55,                last time consumption/overall running time: 213.0386s / 159342.4496 s
env0_first_0:                 episode reward: -55.8500,                 loss: 4.3888
env0_second_0:                 episode reward: 55.8500,                 loss: 4.3382
env1_first_0:                 episode reward: -53.8000,                 loss: nan
env1_second_0:                 episode reward: 53.8000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 922.3,                last time consumption/overall running time: 252.1531s / 159594.6027 s
env0_first_0:                 episode reward: -50.6500,                 loss: 4.7893
env0_second_0:                 episode reward: 50.6500,                 loss: 4.2353
env1_first_0:                 episode reward: -42.5500,                 loss: nan
env1_second_0:                 episode reward: 42.5500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 1047.9,                last time consumption/overall running time: 283.9678s / 159878.5705 s
env0_first_0:                 episode reward: -42.4000,                 loss: 4.5154
env0_second_0:                 episode reward: 42.4000,                 loss: 4.2318
env1_first_0:                 episode reward: -39.8000,                 loss: nan
env1_second_0:                 episode reward: 39.8000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 894.25,                last time consumption/overall running time: 248.2281s / 160126.7986 s
env0_first_0:                 episode reward: -38.2000,                 loss: 4.1852
env0_second_0:                 episode reward: 38.2000,                 loss: 4.2726
env1_first_0:                 episode reward: -44.1500,                 loss: nan
env1_second_0:                 episode reward: 44.1500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 1051.4,                last time consumption/overall running time: 289.3260s / 160416.1246 s
env0_first_0:                 episode reward: -42.1000,                 loss: 4.2410
env0_second_0:                 episode reward: 42.1000,                 loss: 4.4297
env1_first_0:                 episode reward: -36.1500,                 loss: nan
env1_second_0:                 episode reward: 36.1500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 1029.55,                last time consumption/overall running time: 285.6813s / 160701.8059 s
env0_first_0:                 episode reward: -38.3500,                 loss: 4.2492
env0_second_0:                 episode reward: 38.3500,                 loss: 4.5261
env1_first_0:                 episode reward: -36.7500,                 loss: nan
env1_second_0:                 episode reward: 36.7500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 1007.45,                last time consumption/overall running time: 271.9024s / 160973.7083 s
env0_first_0:                 episode reward: -49.3000,                 loss: 4.1222
env0_second_0:                 episode reward: 49.3000,                 loss: 4.3754
env1_first_0:                 episode reward: -38.1000,                 loss: nan
env1_second_0:                 episode reward: 38.1000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 1043.2,                last time consumption/overall running time: 287.8997s / 161261.6080 sLoad boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -44.6000,                 loss: 4.2352
env0_second_0:                 episode reward: 44.6000,                 loss: 4.0761
env1_first_0:                 episode reward: -45.2500,                 loss: nan
env1_second_0:                 episode reward: 45.2500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 924.05,                last time consumption/overall running time: 249.3876s / 161510.9956 s
env0_first_0:                 episode reward: -43.2000,                 loss: 4.1218
env0_second_0:                 episode reward: 43.2000,                 loss: 3.5845
env1_first_0:                 episode reward: -39.1000,                 loss: nan
env1_second_0:                 episode reward: 39.1000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 875.1,                last time consumption/overall running time: 235.6404s / 161746.6360 s
env0_first_0:                 episode reward: -45.7500,                 loss: 3.9556
env0_second_0:                 episode reward: 45.7500,                 loss: 3.6594
env1_first_0:                 episode reward: -50.5000,                 loss: nan
env1_second_0:                 episode reward: 50.5000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 865.45,                last time consumption/overall running time: 242.2900s / 161988.9260 s
env0_first_0:                 episode reward: -48.1500,                 loss: 4.1358
env0_second_0:                 episode reward: 48.1500,                 loss: 4.0485
env1_first_0:                 episode reward: -53.7000,                 loss: nan
env1_second_0:                 episode reward: 53.7000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 833.95,                last time consumption/overall running time: 226.5645s / 162215.4905 s
env0_first_0:                 episode reward: -55.6500,                 loss: 4.3449
env0_second_0:                 episode reward: 55.6500,                 loss: 4.2135
env1_first_0:                 episode reward: -57.0000,                 loss: nan
env1_second_0:                 episode reward: 57.0000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 791.0,                last time consumption/overall running time: 227.8828s / 162443.3733 s
env0_first_0:                 episode reward: -56.1500,                 loss: 4.4053
env0_second_0:                 episode reward: 56.1500,                 loss: 4.0623
env1_first_0:                 episode reward: -52.5000,                 loss: nan
env1_second_0:                 episode reward: 52.5000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 951.1,                last time consumption/overall running time: 259.3094s / 162702.6827 s
env0_first_0:                 episode reward: -56.5500,                 loss: 4.4902
env0_second_0:                 episode reward: 56.5500,                 loss: 4.5100
env1_first_0:                 episode reward: -44.6000,                 loss: nan
env1_second_0:                 episode reward: 44.6000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 991.65,                last time consumption/overall running time: 279.7535s / 162982.4362 s
env0_first_0:                 episode reward: -48.7000,                 loss: 4.8779
env0_second_0:                 episode reward: 48.7000,                 loss: 4.6950
env1_first_0:                 episode reward: -40.8000,                 loss: nan
env1_second_0:                 episode reward: 40.8000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 972.8,                last time consumption/overall running time: 271.2547s / 163253.6909 s
env0_first_0:                 episode reward: -41.5000,                 loss: 4.6643
env0_second_0:                 episode reward: 41.5000,                 loss: 4.4830
env1_first_0:                 episode reward: -44.4500,                 loss: nan
env1_second_0:                 episode reward: 44.4500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 900.9,                last time consumption/overall running time: 266.5789s / 163520.2698 s
env0_first_0:                 episode reward: -34.9000,                 loss: 4.5418
env0_second_0:                 episode reward: 34.9000,                 loss: 4.4768
env1_first_0:                 episode reward: -63.7500,                 loss: nan
env1_second_0:                 episode reward: 63.7500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 1039.35,                last time consumption/overall running time: 282.3069s / 163802.5767 s
env0_first_0:                 episode reward: -42.7000,                 loss: 4.1663
env0_second_0:                 episode reward: 42.7000,                 loss: 4.2500
env1_first_0:                 episode reward: -56.5000,                 loss: nan
env1_second_0:                 episode reward: 56.5000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 1015.6,                last time consumption/overall running time: 274.0506s / 164076.6273 s
env0_first_0:                 episode reward: -37.7000,                 loss: 4.1965
env0_second_0:                 episode reward: 37.7000,                 loss: 3.9711
env1_first_0:                 episode reward: -51.9500,                 loss: nan
env1_second_0:                 episode reward: 51.9500,                 loss: nan
