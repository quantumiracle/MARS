A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)
[Powered by Stella]
I0104 20:14:30.223002 140486757930816 test_pettingzoo.py:131] Environment: Pong
I0104 20:14:30.223340 140486757930816 test_pettingzoo.py:132] Action spec: 6
I0104 20:14:30.223392 140486757930816 test_pettingzoo.py:133] Observation spec: (1, 84, 84)
{'first_0': Box(0, 255, (1, 84, 84), uint8), 'second_0': Box(0, 255, (1, 84, 84), uint8)} {'first_0': Discrete(6), 'second_0': Discrete(6)}
learning agent args:  {'env_name': 'pong_v3', 'env_type': 'gym', 'num_envs': 1, 'ram': False, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 1000000}, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'num_process': 1, 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'net_architecture': {'hidden_dim_list': [512, 512], 'channel_list': [32, 64, 64], 'kernel_size_list': [8, 4, 3], 'stride_list': [4, 2, 1], 'hidden_activation': 'ReLU', 'output_activation': False}}
Episode 0 finished after 929 steps with reward -20.0, loss 0.8749963641166687.
Episode 50 finished after 1167 steps with reward -18.0, loss 0.18229776620864868.
Episode 100 finished after 846 steps with reward -19.0, loss 0.16065751016139984.
Episode 150 finished after 1382 steps with reward -15.0, loss 0.10756266117095947.
Episode 200 finished after 1056 steps with reward -19.0, loss 0.15849733352661133.
Episode 250 finished after 1003 steps with reward -20.0, loss 0.16482169926166534.
Episode 300 finished after 1184 steps with reward -15.0, loss 0.10595600306987762.
Episode 350 finished after 788 steps with reward -21.0, loss 0.2335614711046219.
Episode 400 finished after 818 steps with reward -21.0, loss 0.12347210943698883.
Episode 450 finished after 917 steps with reward -20.0, loss 0.09353967010974884.
Episode 500 finished after 1300 steps with reward -18.0, loss 0.03791287541389465.
Episode 550 finished after 1120 steps with reward -16.0, loss 0.17943516373634338.
Episode 600 finished after 1000 steps with reward -18.0, loss 0.23054139316082.
Episode 650 finished after 851 steps with reward -21.0, loss 0.2897045612335205.
Episode 700 finished after 1105 steps with reward -17.0, loss 0.20727282762527466.
Episode 750 finished after 848 steps with reward -21.0, loss 0.20400133728981018.
Episode 800 finished after 850 steps with reward -21.0, loss 0.22621120512485504.
Episode 850 finished after 975 steps with reward -19.0, loss 0.2501406967639923.
Episode 900 finished after 848 steps with reward -21.0, loss 0.16982224583625793.
Episode 950 finished after 944 steps with reward -20.0, loss 0.2161991000175476.
Episode 1000 finished after 788 steps with reward -21.0, loss 0.22373901307582855.
Episode 1050 finished after 868 steps with reward -20.0, loss 0.15216538310050964.
Episode 1100 finished after 870 steps with reward -20.0, loss 0.17167331278324127.
Episode 1150 finished after 1189 steps with reward -19.0, loss 0.3062312602996826.
Episode 1200 finished after 1173 steps with reward -17.0, loss 0.1586279571056366.
Episode 1250 finished after 1104 steps with reward -18.0, loss 0.18761056661605835.
Episode 1300 finished after 894 steps with reward -21.0, loss 0.29731059074401855.
Episode 1350 finished after 1072 steps with reward -16.0, loss 0.1660069227218628.
Episode 1400 finished after 972 steps with reward -18.0, loss 0.3584803342819214.
Episode 1450 finished after 990 steps with reward -20.0, loss 0.2594924569129944.
Episode 1500 finished after 773 steps with reward -21.0, loss 0.2521384358406067.
Episode 1550 finished after 881 steps with reward -21.0, loss 0.35310491919517517.
Episode 1600 finished after 1050 steps with reward -20.0, loss 0.27327191829681396.
Episode 1650 finished after 848 steps with reward -21.0, loss 0.5769360065460205.
Episode 1700 finished after 869 steps with reward -20.0, loss 0.48629993200302124.
Episode 1750 finished after 1058 steps with reward -21.0, loss 0.274793416261673.
Episode 1800 finished after 987 steps with reward -20.0, loss 0.24686592817306519.
Episode 1850 finished after 728 steps with reward -21.0, loss 0.416191965341568.
Episode 1900 finished after 773 steps with reward -21.0, loss 0.5540101528167725.
Episode 1950 finished after 1212 steps with reward -16.0, loss 0.3443059027194977.
Episode 2000 finished after 772 steps with reward -21.0, loss 0.34768402576446533.
Episode 2050 finished after 733 steps with reward -21.0, loss 0.4859757721424103.
Episode 2100 finished after 789 steps with reward -21.0, loss 0.4617947041988373.
Episode 2150 finished after 1138 steps with reward -18.0, loss 0.42538321018218994.
Episode 2200 finished after 728 steps with reward -21.0, loss 0.5049619674682617.
Episode 2250 finished after 984 steps with reward -20.0, loss 0.3154257535934448.
Episode 2300 finished after 886 steps with reward -20.0, loss 0.359882116317749.
Episode 2350 finished after 811 steps with reward -20.0, loss 0.29179269075393677.
Episode 2400 finished after 728 steps with reward -21.0, loss 0.4910256862640381.
Episode 2450 finished after 955 steps with reward -18.0, loss 0.49755457043647766.
Episode 2500 finished after 728 steps with reward -21.0, loss 0.4185267388820648.
Episode 2550 finished after 728 steps with reward -21.0, loss 0.5613164901733398.
Episode 2600 finished after 864 steps with reward -21.0, loss 0.6766883134841919.
Episode 2650 finished after 789 steps with reward -21.0, loss 0.598017692565918.
Episode 2700 finished after 728 steps with reward -21.0, loss 0.3916095793247223.
Episode 2750 finished after 728 steps with reward -21.0, loss 0.26331841945648193.
Episode 2800 finished after 728 steps with reward -21.0, loss 0.3315999507904053.
Episode 2850 finished after 728 steps with reward -21.0, loss 0.40519922971725464.
Episode 2900 finished after 836 steps with reward -20.0, loss 0.4170186519622803.
Episode 2950 finished after 788 steps with reward -21.0, loss 0.5417827367782593.
Episode 3000 finished after 728 steps with reward -21.0, loss 0.6202952861785889.
Episode 3050 finished after 824 steps with reward -20.0, loss 0.47410526871681213.
Episode 3100 finished after 788 steps with reward -21.0, loss 0.25992482900619507.
Episode 3150 finished after 834 steps with reward -21.0, loss 0.3567585349082947.
Episode 3200 finished after 728 steps with reward -21.0, loss 0.8519910573959351.
Episode 3250 finished after 952 steps with reward -20.0, loss 0.6890659928321838.
Episode 3300 finished after 729 steps with reward -21.0, loss 0.6790690422058105.
Episode 3350 finished after 728 steps with reward -21.0, loss 0.6273249387741089.
Episode 3400 finished after 908 steps with reward -21.0, loss 0.6292535066604614.
Episode 3450 finished after 729 steps with reward -21.0, loss 0.3491339683532715.
Episode 3500 finished after 854 steps with reward -21.0, loss 0.6739116907119751.
Episode 3550 finished after 728 steps with reward -21.0, loss 0.3330400586128235.
Episode 3600 finished after 774 steps with reward -21.0, loss 0.5001665353775024.
Episode 3650 finished after 827 steps with reward -20.0, loss 0.47172877192497253.
Episode 3700 finished after 729 steps with reward -21.0, loss 0.2864237427711487.
Episode 3750 finished after 728 steps with reward -21.0, loss 0.5211703777313232.
Episode 3800 finished after 789 steps with reward -21.0, loss 0.4170456528663635.
Episode 3850 finished after 775 steps with reward -21.0, loss 0.32714495062828064.
Episode 3900 finished after 772 steps with reward -21.0, loss 0.3293883800506592.
Episode 3950 finished after 788 steps with reward -21.0, loss 0.39046967029571533.
Episode 4000 finished after 949 steps with reward -19.0, loss 0.6229969263076782.
Episode 4050 finished after 858 steps with reward -19.0, loss 0.30951645970344543.
Episode 4100 finished after 772 steps with reward -21.0, loss 0.48564058542251587.
Episode 4150 finished after 728 steps with reward -21.0, loss 0.670069694519043.
Episode 4200 finished after 823 steps with reward -20.0, loss 0.5846189856529236.
Episode 4250 finished after 1132 steps with reward -20.0, loss 0.7523711919784546.
Episode 4300 finished after 1049 steps with reward -20.0, loss 0.5916561484336853.
Episode 4350 finished after 728 steps with reward -21.0, loss 0.5809357762336731.
Episode 4400 finished after 824 steps with reward -20.0, loss 0.19612909853458405./data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/wrappers/base_parallel.py:53: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:87: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:101: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."

Episode 4450 finished after 728 steps with reward -21.0, loss 0.5472986698150635.
Episode 4500 finished after 818 steps with reward -21.0, loss 0.35791364312171936.
Episode 4550 finished after 728 steps with reward -21.0, loss 0.31963294744491577.
Episode 4600 finished after 728 steps with reward -21.0, loss 0.34854212403297424.
Episode 4650 finished after 728 steps with reward -21.0, loss 0.295382559299469.
Episode 4700 finished after 788 steps with reward -21.0, loss 0.6299855709075928.
Episode 4750 finished after 728 steps with reward -21.0, loss 0.6178580522537231.
Episode 4800 finished after 728 steps with reward -21.0, loss 0.4279879927635193.
Episode 4850 finished after 728 steps with reward -21.0, loss 0.6070564985275269.
Episode 4900 finished after 788 steps with reward -21.0, loss 0.6968718767166138.
Episode 4950 finished after 789 steps with reward -21.0, loss 0.6608060002326965.
Episode 5000 finished after 1081 steps with reward -18.0, loss 0.6133629083633423.
Episode 5050 finished after 728 steps with reward -21.0, loss 0.7024534344673157.
Episode 5100 finished after 886 steps with reward -20.0, loss 0.5450958013534546.
Episode 5150 finished after 788 steps with reward -21.0, loss 0.6124959588050842.
Episode 5200 finished after 1054 steps with reward -22.0, loss 0.6514753103256226.
Episode 5250 finished after 788 steps with reward -21.0, loss 0.5021122694015503.
