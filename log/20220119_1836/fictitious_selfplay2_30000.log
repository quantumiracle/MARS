pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f6c346c5390>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.024 0.024 0.024 ... 0.024 0.024 0.024]
 [0.024 0.024 0.024 ... 0.024 0.024 0.024]]
Load checkpoints (policy family):  [['50' '5253' '7615' ... '26681' '26940' '28709']
 ['193' '5289' '7712' ... '26747' '26990' '28804']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_30000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220117153310_exploit_30000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220117153310_exploit_30000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0264s / 0.0264 s
agent0:                 episode reward: 2.0935,                 loss: nan
agent1:                 episode reward: -2.0935,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0646s / 0.0910 s
agent0:                 episode reward: 0.3456,                 loss: nan
agent1:                 episode reward: -0.3456,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0519s / 0.1429 s
agent0:                 episode reward: 0.1250,                 loss: nan
agent1:                 episode reward: -0.1250,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0530s / 0.1959 s
agent0:                 episode reward: 0.1149,                 loss: nan
agent1:                 episode reward: -0.1149,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0444s / 0.2404 s
agent0:                 episode reward: 0.2173,                 loss: nan
agent1:                 episode reward: -0.2173,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0418s / 0.2822 s
agent0:                 episode reward: 0.1661,                 loss: nan
agent1:                 episode reward: -0.1661,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0418s / 0.3239 s
agent0:                 episode reward: 0.3993,                 loss: nan
agent1:                 episode reward: -0.3993,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0498s / 0.3737 s
agent0:                 episode reward: 0.1507,                 loss: nan
agent1:                 episode reward: -0.1507,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0459s / 0.4196 s
agent0:                 episode reward: 0.1550,                 loss: nan
agent1:                 episode reward: -0.1550,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0477s / 0.4673 s
agent0:                 episode reward: 0.2181,                 loss: nan
agent1:                 episode reward: -0.2181,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0426s / 0.5098 s
agent0:                 episode reward: 0.2365,                 loss: nan
agent1:                 episode reward: -0.2365,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1196s / 0.6294 s
agent0:                 episode reward: 0.0782,                 loss: nan
agent1:                 episode reward: -0.0782,                 loss: 0.1767
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1686s / 0.7980 s
agent0:                 episode reward: 0.4044,                 loss: nan
agent1:                 episode reward: -0.4044,                 loss: 0.1700
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1683s / 0.9664 s
agent0:                 episode reward: -0.1098,                 loss: nan
agent1:                 episode reward: 0.1098,                 loss: 0.1645
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1747s / 1.1410 s
agent0:                 episode reward: -0.2153,                 loss: nan
agent1:                 episode reward: 0.2153,                 loss: 0.1605
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1795s / 1.3205 s
agent0:                 episode reward: 0.2377,                 loss: nan
agent1:                 episode reward: -0.2377,                 loss: 0.1558
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1734s / 1.4940 s
agent0:                 episode reward: 0.0433,                 loss: nan
agent1:                 episode reward: -0.0433,                 loss: 0.1510
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1633s / 1.6573 s
agent0:                 episode reward: 0.4366,                 loss: nan
agent1:                 episode reward: -0.4366,                 loss: 0.1471
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1640s / 1.8213 s
agent0:                 episode reward: 0.3096,                 loss: nan
agent1:                 episode reward: -0.3096,                 loss: 0.1440
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1597s / 1.9810 s
agent0:                 episode reward: -0.2807,                 loss: nan
agent1:                 episode reward: 0.2807,                 loss: 0.1414
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1838s / 2.1647 s
agent0:                 episode reward: 0.2398,                 loss: nan
agent1:                 episode reward: -0.2398,                 loss: 0.1403
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1577s / 2.3224 s
agent0:                 episode reward: 0.3952,                 loss: nan
agent1:                 episode reward: -0.3952,                 loss: 0.1376
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1579s / 2.4803 s
agent0:                 episode reward: -0.2154,                 loss: nan
agent1:                 episode reward: 0.2154,                 loss: 0.1382
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1572s / 2.6376 s
agent0:                 episode reward: 0.1667,                 loss: nan
agent1:                 episode reward: -0.1667,                 loss: 0.1392
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1582s / 2.7958 s
agent0:                 episode reward: 0.3228,                 loss: nan
agent1:                 episode reward: -0.3228,                 loss: 0.1371
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1595s / 2.9552 s
agent0:                 episode reward: 0.0344,                 loss: nan
agent1:                 episode reward: -0.0344,                 loss: 0.1362
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1601s / 3.1154 s
agent0:                 episode reward: 0.3538,                 loss: nan
agent1:                 episode reward: -0.3538,                 loss: 0.1382
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1682s / 3.2836 s
agent0:                 episode reward: 0.0876,                 loss: nan
agent1:                 episode reward: -0.0876,                 loss: 0.1370
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1619s / 3.4455 s
agent0:                 episode reward: 0.2182,                 loss: nan
agent1:                 episode reward: -0.2182,                 loss: 0.1337
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1555s / 3.6010 s
agent0:                 episode reward: 0.3847,                 loss: nan
agent1:                 episode reward: -0.3847,                 loss: 0.1318
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1553s / 3.7563 s
agent0:                 episode reward: -0.2300,                 loss: nan
agent1:                 episode reward: 0.2300,                 loss: 0.1316
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1612s / 3.9175 s
agent0:                 episode reward: -0.3054,                 loss: nan
agent1:                 episode reward: 0.3054,                 loss: 0.1306
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1600s / 4.0774 s
agent0:                 episode reward: 0.3669,                 loss: nan
agent1:                 episode reward: -0.3669,                 loss: 0.1291
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1588s / 4.2363 s
agent0:                 episode reward: 0.0260,                 loss: nan
agent1:                 episode reward: -0.0260,                 loss: 0.1298
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1584s / 4.3946 s
agent0:                 episode reward: 0.1180,                 loss: nan
agent1:                 episode reward: -0.1180,                 loss: 0.1303
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1579s / 4.5525 s
agent0:                 episode reward: 0.1607,                 loss: nan
agent1:                 episode reward: -0.1607,                 loss: 0.1312
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1553s / 4.7078 s
agent0:                 episode reward: -0.0603,                 loss: nan
agent1:                 episode reward: 0.0603,                 loss: 0.1316
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1590s / 4.8668 s
agent0:                 episode reward: 0.3607,                 loss: nan
agent1:                 episode reward: -0.3607,                 loss: 0.1303
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1588s / 5.0256 s
agent0:                 episode reward: 0.5497,                 loss: nan
agent1:                 episode reward: -0.5497,                 loss: 0.1284
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1584s / 5.1840 s
agent0:                 episode reward: 0.2168,                 loss: nan
agent1:                 episode reward: -0.2168,                 loss: 0.1290
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1546s / 5.3386 s
agent0:                 episode reward: -0.1709,                 loss: nan
agent1:                 episode reward: 0.1709,                 loss: 0.1285
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1578s / 5.4965 s
agent0:                 episode reward: -0.3182,                 loss: nan
agent1:                 episode reward: 0.3182,                 loss: 0.1279
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1622s / 5.6587 s
agent0:                 episode reward: 0.2315,                 loss: nan
agent1:                 episode reward: -0.2315,                 loss: 0.1278
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1622s / 5.8209 s
agent0:                 episode reward: -0.2122,                 loss: nan
agent1:                 episode reward: 0.2122,                 loss: 0.1280
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1622s / 5.9831 s
agent0:                 episode reward: -0.1321,                 loss: nan
agent1:                 episode reward: 0.1321,                 loss: 0.1276
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1607s / 6.1438 s
agent0:                 episode reward: -0.3298,                 loss: nan
agent1:                 episode reward: 0.3298,                 loss: 0.1304
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1711s / 6.3149 s
agent0:                 episode reward: -0.3721,                 loss: nan
agent1:                 episode reward: 0.3721,                 loss: 0.1284
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1696s / 6.4845 s
agent0:                 episode reward: 0.2189,                 loss: nan
agent1:                 episode reward: -0.2189,                 loss: 0.1297
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1641s / 6.6486 s
agent0:                 episode reward: 0.4842,                 loss: nan
agent1:                 episode reward: -0.4842,                 loss: 0.1270
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1611s / 6.8097 s
agent0:                 episode reward: 0.0662,                 loss: nan
agent1:                 episode reward: -0.0662,                 loss: 0.1273
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1707s / 6.9804 s
agent0:                 episode reward: 0.1401,                 loss: nan
agent1:                 episode reward: -0.1401,                 loss: 0.1278
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1603s / 7.1407 s
agent0:                 episode reward: 0.0256,                 loss: nan
agent1:                 episode reward: -0.0256,                 loss: 0.1280
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1642s / 7.3050 s
agent0:                 episode reward: 0.5702,                 loss: nan
agent1:                 episode reward: -0.5702,                 loss: 0.1272
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1606s / 7.4655 s
agent0:                 episode reward: -0.1445,                 loss: nan
agent1:                 episode reward: 0.1445,                 loss: 0.1273
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1550s / 7.6205 s
agent0:                 episode reward: 0.5184,                 loss: nan
agent1:                 episode reward: -0.5184,                 loss: 0.1301
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1618s / 7.7824 s
agent0:                 episode reward: 0.1810,                 loss: nan
agent1:                 episode reward: -0.1810,                 loss: 0.1276
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1581s / 7.9405 s
agent0:                 episode reward: 0.0456,                 loss: nan
agent1:                 episode reward: -0.0456,                 loss: 0.1280
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1587s / 8.0992 s
agent0:                 episode reward: -0.2037,                 loss: nan
agent1:                 episode reward: 0.2037,                 loss: 0.1280
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1551s / 8.2543 s
agent0:                 episode reward: 0.1220,                 loss: nan
agent1:                 episode reward: -0.1220,                 loss: 0.1262
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1532s / 8.4075 s
agent0:                 episode reward: -0.1435,                 loss: nan
agent1:                 episode reward: 0.1435,                 loss: 0.1273
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1571s / 8.5646 s
agent0:                 episode reward: -0.4024,                 loss: nan
agent1:                 episode reward: 0.4024,                 loss: 0.1271
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1608s / 8.7253 s
agent0:                 episode reward: 0.1815,                 loss: nan
agent1:                 episode reward: -0.1815,                 loss: 0.1270
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1630s / 8.8884 s
agent0:                 episode reward: -0.1500,                 loss: nan
agent1:                 episode reward: 0.1500,                 loss: 0.1268
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1621s / 9.0504 s
agent0:                 episode reward: 0.2418,                 loss: nan
agent1:                 episode reward: -0.2418,                 loss: 0.1263
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1630s / 9.2134 s
agent0:                 episode reward: -0.3133,                 loss: nan
agent1:                 episode reward: 0.3133,                 loss: 0.1251
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1729s / 9.3864 s
agent0:                 episode reward: 0.1294,                 loss: nan
agent1:                 episode reward: -0.1294,                 loss: 0.1262
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1687s / 9.5551 s
agent0:                 episode reward: 0.4265,                 loss: nan
agent1:                 episode reward: -0.4265,                 loss: 0.1255
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1629s / 9.7180 s
agent0:                 episode reward: -0.2681,                 loss: nan
agent1:                 episode reward: 0.2681,                 loss: 0.1260
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1634s / 9.8814 s
agent0:                 episode reward: 0.2968,                 loss: nan
agent1:                 episode reward: -0.2968,                 loss: 0.1263
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1656s / 10.0470 s
agent0:                 episode reward: 0.0161,                 loss: nan
agent1:                 episode reward: -0.0161,                 loss: 0.1262
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1647s / 10.2117 s
agent0:                 episode reward: 0.4487,                 loss: nan
agent1:                 episode reward: -0.4487,                 loss: 0.1265
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1664s / 10.3780 s
agent0:                 episode reward: -0.3648,                 loss: nan
agent1:                 episode reward: 0.3648,                 loss: 0.1257
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1663s / 10.5443 s
agent0:                 episode reward: 0.1704,                 loss: nan
agent1:                 episode reward: -0.1704,                 loss: 0.1258
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1624s / 10.7067 s
agent0:                 episode reward: 0.4903,                 loss: nan
agent1:                 episode reward: -0.4903,                 loss: 0.1254
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1637s / 10.8705 s
agent0:                 episode reward: 0.2329,                 loss: nan
agent1:                 episode reward: -0.2329,                 loss: 0.1253
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1646s / 11.0351 s
agent0:                 episode reward: 0.4015,                 loss: nan
agent1:                 episode reward: -0.4015,                 loss: 0.1245
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1690s / 11.2040 s
agent0:                 episode reward: 0.0576,                 loss: nan
agent1:                 episode reward: -0.0576,                 loss: 0.1239
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1738s / 11.3778 s
agent0:                 episode reward: -0.2870,                 loss: nan
agent1:                 episode reward: 0.2870,                 loss: 0.1237
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1715s / 11.5493 s
agent0:                 episode reward: 0.3566,                 loss: nan
agent1:                 episode reward: -0.3566,                 loss: 0.1239
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1707s / 11.7200 s
agent0:                 episode reward: -0.1666,                 loss: nan
agent1:                 episode reward: 0.1666,                 loss: 0.1256
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1727s / 11.8927 s
agent0:                 episode reward: 0.0345,                 loss: nan
agent1:                 episode reward: -0.0345,                 loss: 0.1237
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1700s / 12.0627 s
agent0:                 episode reward: 0.0539,                 loss: nan
agent1:                 episode reward: -0.0539,                 loss: 0.1253
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1707s / 12.2334 s
agent0:                 episode reward: 0.1987,                 loss: nan
agent1:                 episode reward: -0.1987,                 loss: 0.1244
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1750s / 12.4084 s
agent0:                 episode reward: -0.1920,                 loss: nan
agent1:                 episode reward: 0.1920,                 loss: 0.1241
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 12.6093 s
agent0:                 episode reward: -0.2155,                 loss: nan
agent1:                 episode reward: 0.2155,                 loss: 0.1233
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1772s / 12.7866 s
agent0:                 episode reward: -0.3986,                 loss: nan
agent1:                 episode reward: 0.3986,                 loss: 0.1241
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1696s / 12.9562 s
agent0:                 episode reward: 0.2501,                 loss: nan
agent1:                 episode reward: -0.2501,                 loss: 0.1245
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1692s / 13.1254 s
agent0:                 episode reward: 0.1824,                 loss: nan
agent1:                 episode reward: -0.1824,                 loss: 0.1238
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1829s / 13.3083 s
agent0:                 episode reward: 0.0769,                 loss: nan
agent1:                 episode reward: -0.0769,                 loss: 0.1244
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1630s / 13.4713 s
agent0:                 episode reward: 0.0938,                 loss: nan
agent1:                 episode reward: -0.0938,                 loss: 0.1230
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1616s / 13.6329 s
agent0:                 episode reward: -0.0706,                 loss: nan
agent1:                 episode reward: 0.0706,                 loss: 0.1245
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1635s / 13.7964 s
agent0:                 episode reward: -0.5454,                 loss: nan
agent1:                 episode reward: 0.5454,                 loss: 0.1237
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1612s / 13.9576 s
agent0:                 episode reward: -0.1473,                 loss: nan
agent1:                 episode reward: 0.1473,                 loss: 0.1232
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1745s / 14.1321 s
agent0:                 episode reward: 0.1438,                 loss: nan
agent1:                 episode reward: -0.1438,                 loss: 0.1232
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1728s / 14.3049 s
agent0:                 episode reward: -0.1785,                 loss: nan
agent1:                 episode reward: 0.1785,                 loss: 0.1229
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1743s / 14.4792 s
agent0:                 episode reward: -0.0580,                 loss: nan
agent1:                 episode reward: 0.0580,                 loss: 0.1242
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1659s / 14.6452 s
agent0:                 episode reward: 0.1054,                 loss: nan
agent1:                 episode reward: -0.1054,                 loss: 0.1243
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1703s / 14.8155 s
agent0:                 episode reward: -0.3355,                 loss: nan
agent1:                 episode reward: 0.3355,                 loss: 0.1225
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1725s / 14.9880 s
agent0:                 episode reward: 0.2456,                 loss: nan
agent1:                 episode reward: -0.2456,                 loss: 0.1234
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1759s / 15.1639 s
agent0:                 episode reward: 0.0235,                 loss: nan
agent1:                 episode reward: -0.0235,                 loss: 0.1224
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 15.3575 s
agent0:                 episode reward: 0.1119,                 loss: nan
agent1:                 episode reward: -0.1119,                 loss: 0.1226
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1891s / 15.5466 s
agent0:                 episode reward: 0.1163,                 loss: nan
agent1:                 episode reward: -0.1163,                 loss: 0.1232
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 15.7399 s
agent0:                 episode reward: 0.3528,                 loss: nan
agent1:                 episode reward: -0.3528,                 loss: 0.1231
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1746s / 15.9145 s
agent0:                 episode reward: -0.1775,                 loss: nan
agent1:                 episode reward: 0.1775,                 loss: 0.1234
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1722s / 16.0867 s
agent0:                 episode reward: -0.3599,                 loss: nan
agent1:                 episode reward: 0.3599,                 loss: 0.1236
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1721s / 16.2589 s
agent0:                 episode reward: 0.1311,                 loss: nan
agent1:                 episode reward: -0.1311,                 loss: 0.1240
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1653s / 16.4242 s
agent0:                 episode reward: 0.2089,                 loss: nan
agent1:                 episode reward: -0.2089,                 loss: 0.1222
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1645s / 16.5886 s
agent0:                 episode reward: 0.2489,                 loss: nan
agent1:                 episode reward: -0.2489,                 loss: 0.1223
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1693s / 16.7580 s
agent0:                 episode reward: -0.2336,                 loss: nan
agent1:                 episode reward: 0.2336,                 loss: 0.1235
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1653s / 16.9233 s
agent0:                 episode reward: -0.0633,                 loss: nan
agent1:                 episode reward: 0.0633,                 loss: 0.1231
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1644s / 17.0876 s
agent0:                 episode reward: 0.0845,                 loss: nan
agent1:                 episode reward: -0.0845,                 loss: 0.1233
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1649s / 17.2525 s
agent0:                 episode reward: -0.2399,                 loss: nan
agent1:                 episode reward: 0.2399,                 loss: 0.1230
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1648s / 17.4173 s
agent0:                 episode reward: -0.1629,                 loss: nan
agent1:                 episode reward: 0.1629,                 loss: 0.1245
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1687s / 17.5860 s
agent0:                 episode reward: -0.1942,                 loss: nan
agent1:                 episode reward: 0.1942,                 loss: 0.1234
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 17.7802 s
agent0:                 episode reward: -0.1455,                 loss: nan
agent1:                 episode reward: 0.1455,                 loss: 0.1227
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1719s / 17.9521 s
agent0:                 episode reward: -0.2773,                 loss: nan
agent1:                 episode reward: 0.2773,                 loss: 0.1233
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1696s / 18.1217 s
agent0:                 episode reward: 0.0903,                 loss: nan
agent1:                 episode reward: -0.0903,                 loss: 0.1228
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1694s / 18.2911 s
agent0:                 episode reward: 0.1308,                 loss: nan
agent1:                 episode reward: -0.1308,                 loss: 0.1234
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 18.4872 s
agent0:                 episode reward: -0.0615,                 loss: nan
agent1:                 episode reward: 0.0615,                 loss: 0.1231
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 18.6840 s
agent0:                 episode reward: -0.0991,                 loss: nan
agent1:                 episode reward: 0.0991,                 loss: 0.1246
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1773s / 18.8613 s
agent0:                 episode reward: -0.4393,                 loss: nan
agent1:                 episode reward: 0.4393,                 loss: 0.1244
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1715s / 19.0328 s
agent0:                 episode reward: -0.6099,                 loss: nan
agent1:                 episode reward: 0.6099,                 loss: 0.1238
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 19.2308 s
agent0:                 episode reward: -0.5910,                 loss: nan
agent1:                 episode reward: 0.5910,                 loss: 0.1222
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 19.4246 s
agent0:                 episode reward: 0.2080,                 loss: nan
agent1:                 episode reward: -0.2080,                 loss: 0.1222
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1749s / 19.5995 s
agent0:                 episode reward: -0.1153,                 loss: nan
agent1:                 episode reward: 0.1153,                 loss: 0.1241
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1792s / 19.7787 s
agent0:                 episode reward: -0.2761,                 loss: nan
agent1:                 episode reward: 0.2761,                 loss: 0.1234
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1788s / 19.9575 s
agent0:                 episode reward: -0.3605,                 loss: nan
agent1:                 episode reward: 0.3605,                 loss: 0.1239
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1791s / 20.1366 s
agent0:                 episode reward: -0.1593,                 loss: nan
agent1:                 episode reward: 0.1593,                 loss: 0.1245
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1797s / 20.3162 s
agent0:                 episode reward: -0.1490,                 loss: nan
agent1:                 episode reward: 0.1490,                 loss: 0.1248
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1759s / 20.4921 s
agent0:                 episode reward: -0.1264,                 loss: nan
agent1:                 episode reward: 0.1264,                 loss: 0.1245
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1782s / 20.6703 s
agent0:                 episode reward: -0.1152,                 loss: nan
agent1:                 episode reward: 0.1152,                 loss: 0.1255
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1802s / 20.8505 s
agent0:                 episode reward: 0.0463,                 loss: nan
agent1:                 episode reward: -0.0463,                 loss: 0.1256
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1726s / 21.0231 s
agent0:                 episode reward: 0.0312,                 loss: nan
agent1:                 episode reward: -0.0312,                 loss: 0.1249
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1728s / 21.1959 s
agent0:                 episode reward: -0.2240,                 loss: nan
agent1:                 episode reward: 0.2240,                 loss: 0.1258
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1686s / 21.3645 s
agent0:                 episode reward: -0.2021,                 loss: nan
agent1:                 episode reward: 0.2021,                 loss: 0.1247
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1775s / 21.5420 s
agent0:                 episode reward: -0.4153,                 loss: nan
agent1:                 episode reward: 0.4153,                 loss: 0.1249
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1906s / 21.7326 s
agent0:                 episode reward: -0.1814,                 loss: nan
agent1:                 episode reward: 0.1814,                 loss: 0.1240
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1869s / 21.9195 s
agent0:                 episode reward: -0.4553,                 loss: nan
agent1:                 episode reward: 0.4553,                 loss: 0.1239
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1749s / 22.0945 s
agent0:                 episode reward: 0.0512,                 loss: nan
agent1:                 episode reward: -0.0512,                 loss: 0.1240
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1723s / 22.2667 s
agent0:                 episode reward: -0.0337,                 loss: nan
agent1:                 episode reward: 0.0337,                 loss: 0.1242
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 22.4718 s
agent0:                 episode reward: 0.0757,                 loss: nan
agent1:                 episode reward: -0.0757,                 loss: 0.1240
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1768s / 22.6486 s
agent0:                 episode reward: 0.0756,                 loss: nan
agent1:                 episode reward: -0.0756,                 loss: 0.1241
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1755s / 22.8241 s
agent0:                 episode reward: -0.4189,                 loss: nan
agent1:                 episode reward: 0.4189,                 loss: 0.1244
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1766s / 23.0007 s
agent0:                 episode reward: 0.2117,                 loss: nan
agent1:                 episode reward: -0.2117,                 loss: 0.1241
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1789s / 23.1796 s
agent0:                 episode reward: -0.2451,                 loss: nan
agent1:                 episode reward: 0.2451,                 loss: 0.1240
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1803s / 23.3599 s
agent0:                 episode reward: -0.4621,                 loss: nan
agent1:                 episode reward: 0.4621,                 loss: 0.1243
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1758s / 23.5357 s
agent0:                 episode reward: -0.2282,                 loss: nan
agent1:                 episode reward: 0.2282,                 loss: 0.1255
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 23.7328 s
agent0:                 episode reward: 0.2634,                 loss: nan
agent1:                 episode reward: -0.2634,                 loss: 0.1245
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1787s / 23.9115 s
agent0:                 episode reward: -0.4787,                 loss: nan
agent1:                 episode reward: 0.4787,                 loss: 0.1239
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1799s / 24.0914 s
agent0:                 episode reward: -0.4867,                 loss: nan
agent1:                 episode reward: 0.4867,                 loss: 0.1246
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1819s / 24.2733 s
agent0:                 episode reward: -0.1408,                 loss: nan
agent1:                 episode reward: 0.1408,                 loss: 0.1251
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1849s / 24.4582 s
agent0:                 episode reward: -0.1204,                 loss: nan
agent1:                 episode reward: 0.1204,                 loss: 0.1237
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 24.6522 s
agent0:                 episode reward: -0.3215,                 loss: nan
agent1:                 episode reward: 0.3215,                 loss: 0.1228
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 24.8521 s
agent0:                 episode reward: -0.2008,                 loss: nan
agent1:                 episode reward: 0.2008,                 loss: 0.1241
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1862s / 25.0382 s
agent0:                 episode reward: -0.0723,                 loss: nan
agent1:                 episode reward: 0.0723,                 loss: 0.1237
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1781s / 25.2163 s
agent0:                 episode reward: -0.1140,                 loss: nan
agent1:                 episode reward: 0.1140,                 loss: 0.1227
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1798s / 25.3961 s
agent0:                 episode reward: -0.0398,                 loss: nan
agent1:                 episode reward: 0.0398,                 loss: 0.1241
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1767s / 25.5728 s
agent0:                 episode reward: -0.2774,                 loss: nan
agent1:                 episode reward: 0.2774,                 loss: 0.1222
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1847s / 25.7575 s
agent0:                 episode reward: -0.0700,                 loss: nan
agent1:                 episode reward: 0.0700,                 loss: 0.1227
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1766s / 25.9341 s
agent0:                 episode reward: -0.2138,                 loss: nan
agent1:                 episode reward: 0.2138,                 loss: 0.1238
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1750s / 26.1090 s
agent0:                 episode reward: -0.1502,                 loss: nan
agent1:                 episode reward: 0.1502,                 loss: 0.1243
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1785s / 26.2875 s
agent0:                 episode reward: -0.3497,                 loss: nan
agent1:                 episode reward: 0.3497,                 loss: 0.1227
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1730s / 26.4605 s
agent0:                 episode reward: 0.1201,                 loss: nan
agent1:                 episode reward: -0.1201,                 loss: 0.1242
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1729s / 26.6334 s
agent0:                 episode reward: 0.2677,                 loss: nan
agent1:                 episode reward: -0.2677,                 loss: 0.1236
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1761s / 26.8095 s
agent0:                 episode reward: -0.2665,                 loss: nan
agent1:                 episode reward: 0.2665,                 loss: 0.1232
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1794s / 26.9889 s
agent0:                 episode reward: -0.2936,                 loss: nan
agent1:                 episode reward: 0.2936,                 loss: 0.1221
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1733s / 27.1622 s
agent0:                 episode reward: -0.3143,                 loss: nan
agent1:                 episode reward: 0.3143,                 loss: 0.1214
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1758s / 27.3380 s
agent0:                 episode reward: -0.1710,                 loss: nan
agent1:                 episode reward: 0.1710,                 loss: 0.1214
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1732s / 27.5113 s
agent0:                 episode reward: -0.4947,                 loss: nan
agent1:                 episode reward: 0.4947,                 loss: 0.1244
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1790s / 27.6902 s
agent0:                 episode reward: -0.0598,                 loss: nan
agent1:                 episode reward: 0.0598,                 loss: 0.1232
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 27.8834 s
agent0:                 episode reward: 0.4710,                 loss: nan
agent1:                 episode reward: -0.4710,                 loss: 0.1241
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1863s / 28.0697 s
agent0:                 episode reward: -0.1885,                 loss: nan
agent1:                 episode reward: 0.1885,                 loss: 0.1218
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1742s / 28.2440 s
agent0:                 episode reward: -0.1135,                 loss: nan
agent1:                 episode reward: 0.1135,                 loss: 0.1214
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1744s / 28.4184 s
agent0:                 episode reward: -0.1976,                 loss: nan
agent1:                 episode reward: 0.1976,                 loss: 0.1236
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1726s / 28.5910 s
agent0:                 episode reward: -0.2739,                 loss: nan
agent1:                 episode reward: 0.2739,                 loss: 0.1228
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1729s / 28.7639 s
agent0:                 episode reward: -0.1523,                 loss: nan
agent1:                 episode reward: 0.1523,                 loss: 0.1229
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1709s / 28.9348 s
agent0:                 episode reward: -0.1822,                 loss: nan
agent1:                 episode reward: 0.1822,                 loss: 0.1211
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1738s / 29.1086 s
agent0:                 episode reward: 0.2460,                 loss: nan
agent1:                 episode reward: -0.2460,                 loss: 0.1233
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1810s / 29.2896 s
agent0:                 episode reward: -0.3558,                 loss: nan
agent1:                 episode reward: 0.3558,                 loss: 0.1239
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1826s / 29.4722 s
agent0:                 episode reward: -0.2921,                 loss: nan
agent1:                 episode reward: 0.2921,                 loss: 0.1250
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1833s / 29.6554 s
agent0:                 episode reward: -0.1953,                 loss: nan
agent1:                 episode reward: 0.1953,                 loss: 0.1251
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1825s / 29.8379 s
agent0:                 episode reward: -0.3712,                 loss: nan
agent1:                 episode reward: 0.3712,                 loss: 0.1254
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1806s / 30.0185 s
agent0:                 episode reward: -0.0423,                 loss: nan
agent1:                 episode reward: 0.0423,                 loss: 0.1253
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1838s / 30.2023 s
agent0:                 episode reward: 0.1122,                 loss: nan
agent1:                 episode reward: -0.1122,                 loss: 0.1239
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1840s / 30.3863 s
agent0:                 episode reward: -0.1755,                 loss: nan
agent1:                 episode reward: 0.1755,                 loss: 0.1242
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1888s / 30.5752 s
agent0:                 episode reward: -0.4936,                 loss: nan
agent1:                 episode reward: 0.4936,                 loss: 0.1244
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1772s / 30.7524 s
agent0:                 episode reward: -0.1181,                 loss: nan
agent1:                 episode reward: 0.1181,                 loss: 0.1250
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 30.9562 s
agent0:                 episode reward: -0.3394,                 loss: nan
agent1:                 episode reward: 0.3394,                 loss: 0.1230
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1847s / 31.1409 s
agent0:                 episode reward: -0.1316,                 loss: nan
agent1:                 episode reward: 0.1316,                 loss: 0.1248
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1768s / 31.3177 s
agent0:                 episode reward: -0.4164,                 loss: nan
agent1:                 episode reward: 0.4164,                 loss: 0.1228
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1746s / 31.4924 s
agent0:                 episode reward: -0.6638,                 loss: nan
agent1:                 episode reward: 0.6638,                 loss: 0.1224
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1748s / 31.6672 s
agent0:                 episode reward: -0.2045,                 loss: nan
agent1:                 episode reward: 0.2045,                 loss: 0.1222
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1835s / 31.8506 s
agent0:                 episode reward: -0.0999,                 loss: nan
agent1:                 episode reward: 0.0999,                 loss: 0.1232
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1922s / 32.0428 s
agent0:                 episode reward: 0.0018,                 loss: nan
agent1:                 episode reward: -0.0018,                 loss: 0.1227
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1791s / 32.2219 s
agent0:                 episode reward: -0.1111,                 loss: nan
agent1:                 episode reward: 0.1111,                 loss: 0.1234
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1755s / 32.3974 s
agent0:                 episode reward: -0.2022,                 loss: nan
agent1:                 episode reward: 0.2022,                 loss: 0.1242
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1741s / 32.5715 s
agent0:                 episode reward: -0.3111,                 loss: nan
agent1:                 episode reward: 0.3111,                 loss: 0.1239
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1779s / 32.7494 s
agent0:                 episode reward: -0.1598,                 loss: nan
agent1:                 episode reward: 0.1598,                 loss: 0.1223
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1709s / 32.9203 s
agent0:                 episode reward: -0.0958,                 loss: nan
agent1:                 episode reward: 0.0958,                 loss: 0.1232
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1732s / 33.0935 s
agent0:                 episode reward: 0.1274,                 loss: nan
agent1:                 episode reward: -0.1274,                 loss: 0.1226
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1778s / 33.2713 s
agent0:                 episode reward: 0.0202,                 loss: nan
agent1:                 episode reward: -0.0202,                 loss: 0.1221
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1715s / 33.4427 s
agent0:                 episode reward: -0.6586,                 loss: nan
agent1:                 episode reward: 0.6586,                 loss: 0.1230
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1763s / 33.6191 s
agent0:                 episode reward: 0.0615,                 loss: nan
agent1:                 episode reward: -0.0615,                 loss: 0.1231
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1805s / 33.7995 s
agent0:                 episode reward: 0.0481,                 loss: nan
agent1:                 episode reward: -0.0481,                 loss: 0.1251
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2145s / 34.0140 s
agent0:                 episode reward: -0.2352,                 loss: nan
agent1:                 episode reward: 0.2352,                 loss: 0.1234
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1909s / 34.2049 s
agent0:                 episode reward: -0.3585,                 loss: nan
agent1:                 episode reward: 0.3585,                 loss: 0.1238
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1799s / 34.3849 s
agent0:                 episode reward: -0.4257,                 loss: nan
agent1:                 episode reward: 0.4257,                 loss: 0.1232
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1895s / 34.5743 s
agent0:                 episode reward: -0.2888,                 loss: nan
agent1:                 episode reward: 0.2888,                 loss: 0.1221
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1864s / 34.7607 s
agent0:                 episode reward: -0.3123,                 loss: nan
agent1:                 episode reward: 0.3123,                 loss: 0.1227
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1860s / 34.9467 s
agent0:                 episode reward: -0.3682,                 loss: nan
agent1:                 episode reward: 0.3682,                 loss: 0.1228
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1890s / 35.1357 s
agent0:                 episode reward: -0.1978,                 loss: nan
agent1:                 episode reward: 0.1978,                 loss: 0.1234
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1909s / 35.3266 s
agent0:                 episode reward: -0.0605,                 loss: nan
agent1:                 episode reward: 0.0605,                 loss: 0.1224
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1808s / 35.5074 s
agent0:                 episode reward: -0.1924,                 loss: nan
agent1:                 episode reward: 0.1924,                 loss: 0.1248
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1822s / 35.6895 s
agent0:                 episode reward: 0.0428,                 loss: nan
agent1:                 episode reward: -0.0428,                 loss: 0.1236
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1886s / 35.8781 s
agent0:                 episode reward: -0.5659,                 loss: nan
agent1:                 episode reward: 0.5659,                 loss: 0.1231
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1827s / 36.0608 s
agent0:                 episode reward: -0.1783,                 loss: nan
agent1:                 episode reward: 0.1783,                 loss: 0.1244
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1832s / 36.2441 s
agent0:                 episode reward: -0.2613,                 loss: nan
agent1:                 episode reward: 0.2613,                 loss: 0.1237
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1831s / 36.4271 s
agent0:                 episode reward: -0.3393,                 loss: nan
agent1:                 episode reward: 0.3393,                 loss: 0.1242
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1857s / 36.6128 s
agent0:                 episode reward: -0.5112,                 loss: nan
agent1:                 episode reward: 0.5112,                 loss: 0.1239
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1883s / 36.8011 s
agent0:                 episode reward: -0.2148,                 loss: nan
agent1:                 episode reward: 0.2148,                 loss: 0.1239
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2035s / 37.0046 s
agent0:                 episode reward: -0.2414,                 loss: nan
agent1:                 episode reward: 0.2414,                 loss: 0.1225
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 37.2071 s
agent0:                 episode reward: 0.0083,                 loss: nan
agent1:                 episode reward: -0.0083,                 loss: 0.1225
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1885s / 37.3956 s
agent0:                 episode reward: 0.0167,                 loss: nan
agent1:                 episode reward: -0.0167,                 loss: 0.1236
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1839s / 37.5795 s
agent0:                 episode reward: -0.5100,                 loss: nan
agent1:                 episode reward: 0.5100,                 loss: 0.1228
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1887s / 37.7682 s
agent0:                 episode reward: -0.4208,                 loss: nan
agent1:                 episode reward: 0.4208,                 loss: 0.1228
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1881s / 37.9563 s
agent0:                 episode reward: 0.0073,                 loss: nan
agent1:                 episode reward: -0.0073,                 loss: 0.1235
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1869s / 38.1432 s
agent0:                 episode reward: -0.5660,                 loss: nan
agent1:                 episode reward: 0.5660,                 loss: 0.1241
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1901s / 38.3333 s
agent0:                 episode reward: -0.3802,                 loss: nan
agent1:                 episode reward: 0.3802,                 loss: 0.1231
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1853s / 38.5186 s
agent0:                 episode reward: -0.2672,                 loss: nan
agent1:                 episode reward: 0.2672,                 loss: 0.1247
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1865s / 38.7050 s
agent0:                 episode reward: -0.1477,                 loss: nan
agent1:                 episode reward: 0.1477,                 loss: 0.1225
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1896s / 38.8946 s
agent0:                 episode reward: -0.1445,                 loss: nan
agent1:                 episode reward: 0.1445,                 loss: 0.1218
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1835s / 39.0781 s
agent0:                 episode reward: -0.0152,                 loss: nan
agent1:                 episode reward: 0.0152,                 loss: 0.1224
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 39.2728 s
agent0:                 episode reward: 0.0096,                 loss: nan
agent1:                 episode reward: -0.0096,                 loss: 0.1233
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1874s / 39.4603 s
agent0:                 episode reward: -0.4132,                 loss: nan
agent1:                 episode reward: 0.4132,                 loss: 0.1232
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1844s / 39.6447 s
agent0:                 episode reward: -0.0349,                 loss: nan
agent1:                 episode reward: 0.0349,                 loss: 0.1227
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1865s / 39.8312 s
agent0:                 episode reward: -0.6528,                 loss: nan
agent1:                 episode reward: 0.6528,                 loss: 0.1237
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2060s / 40.0372 s
agent0:                 episode reward: 0.1860,                 loss: nan
agent1:                 episode reward: -0.1860,                 loss: 0.1226
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2152s / 40.2524 s
agent0:                 episode reward: -0.3649,                 loss: nan
agent1:                 episode reward: 0.3649,                 loss: 0.1242
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 40.4479 s
agent0:                 episode reward: -0.3156,                 loss: nan
agent1:                 episode reward: 0.3156,                 loss: 0.1235
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1861s / 40.6341 s
agent0:                 episode reward: -0.5119,                 loss: nan
agent1:                 episode reward: 0.5119,                 loss: 0.1242
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1842s / 40.8183 s
agent0:                 episode reward: -0.1556,                 loss: nan
agent1:                 episode reward: 0.1556,                 loss: 0.1224
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1853s / 41.0036 s
agent0:                 episode reward: -0.2929,                 loss: nan
agent1:                 episode reward: 0.2929,                 loss: 0.1220
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1830s / 41.1866 s
agent0:                 episode reward: -0.0274,                 loss: nan
agent1:                 episode reward: 0.0274,                 loss: 0.1218
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1903s / 41.3769 s
agent0:                 episode reward: -0.4319,                 loss: nan
agent1:                 episode reward: 0.4319,                 loss: 0.1228
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1782s / 41.5551 s
agent0:                 episode reward: -0.2967,                 loss: nan
agent1:                 episode reward: 0.2967,                 loss: 0.1218
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1794s / 41.7345 s
agent0:                 episode reward: -0.2611,                 loss: nan
agent1:                 episode reward: 0.2611,                 loss: 0.1246
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1796s / 41.9141 s
agent0:                 episode reward: -0.1252,                 loss: nan
agent1:                 episode reward: 0.1252,                 loss: 0.1241
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1807s / 42.0948 s
agent0:                 episode reward: -0.3119,                 loss: nan
agent1:                 episode reward: 0.3119,                 loss: 0.1252
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1838s / 42.2786 s
agent0:                 episode reward: -0.2234,                 loss: nan
agent1:                 episode reward: 0.2234,                 loss: 0.1244
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1820s / 42.4606 s
agent0:                 episode reward: -0.1549,                 loss: nan
agent1:                 episode reward: 0.1549,                 loss: 0.1235
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1824s / 42.6430 s
agent0:                 episode reward: -0.3898,                 loss: nan
agent1:                 episode reward: 0.3898,                 loss: 0.1244
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1874s / 42.8304 s
agent0:                 episode reward: -0.0844,                 loss: nan
agent1:                 episode reward: 0.0844,                 loss: 0.1261
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1860s / 43.0164 s
agent0:                 episode reward: -0.1272,                 loss: nan
agent1:                 episode reward: 0.1272,                 loss: 0.1237
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1852s / 43.2016 s
agent0:                 episode reward: -0.2295,                 loss: nan
agent1:                 episode reward: 0.2295,                 loss: 0.1245
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1872s / 43.3888 s
agent0:                 episode reward: -0.3966,                 loss: nan
agent1:                 episode reward: 0.3966,                 loss: 0.1254
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1848s / 43.5737 s
agent0:                 episode reward: -0.0932,                 loss: nan
agent1:                 episode reward: 0.0932,                 loss: 0.1237
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1833s / 43.7570 s
agent0:                 episode reward: -0.0882,                 loss: nan
agent1:                 episode reward: 0.0882,                 loss: 0.1237
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1886s / 43.9456 s
agent0:                 episode reward: 0.0529,                 loss: nan
agent1:                 episode reward: -0.0529,                 loss: 0.1254
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1874s / 44.1330 s
agent0:                 episode reward: -0.4340,                 loss: nan
agent1:                 episode reward: 0.4340,                 loss: 0.1241
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1930s / 44.3260 s
agent0:                 episode reward: 0.0919,                 loss: nan
agent1:                 episode reward: -0.0919,                 loss: 0.1251
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1903s / 44.5163 s
agent0:                 episode reward: 0.1986,                 loss: nan
agent1:                 episode reward: -0.1986,                 loss: 0.1248
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1861s / 44.7023 s
agent0:                 episode reward: -0.2032,                 loss: nan
agent1:                 episode reward: 0.2032,                 loss: 0.1240
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1870s / 44.8893 s
agent0:                 episode reward: -0.2361,                 loss: nan
agent1:                 episode reward: 0.2361,                 loss: 0.1209
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 45.0905 s
agent0:                 episode reward: -0.4863,                 loss: nan
agent1:                 episode reward: 0.4863,                 loss: 0.1216
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2034s / 45.2938 s
agent0:                 episode reward: -0.2718,                 loss: nan
agent1:                 episode reward: 0.2718,                 loss: 0.1213
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2040s / 45.4978 s
agent0:                 episode reward: -0.2994,                 loss: nan
agent1:                 episode reward: 0.2994,                 loss: 0.1224
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2032s / 45.7010 s
agent0:                 episode reward: 0.1891,                 loss: nan
agent1:                 episode reward: -0.1891,                 loss: 0.1211
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2445s / 45.9456 s
agent0:                 episode reward: -0.4087,                 loss: nan
agent1:                 episode reward: 0.4087,                 loss: 0.1225
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2171s / 46.1627 s
agent0:                 episode reward: 0.2321,                 loss: nan
agent1:                 episode reward: -0.2321,                 loss: 0.1228
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 46.3668 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.1205
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 46.5587 s
agent0:                 episode reward: -0.5606,                 loss: nan
agent1:                 episode reward: 0.5606,                 loss: 0.1217
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1924s / 46.7511 s
agent0:                 episode reward: -0.1930,                 loss: nan
agent1:                 episode reward: 0.1930,                 loss: 0.1223
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 46.9464 s
agent0:                 episode reward: -0.4178,                 loss: nan
agent1:                 episode reward: 0.4178,                 loss: 0.1204
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1871s / 47.1334 s
agent0:                 episode reward: -0.2039,                 loss: nan
agent1:                 episode reward: 0.2039,                 loss: 0.1205
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 47.3375 s
agent0:                 episode reward: -0.3716,                 loss: nan
agent1:                 episode reward: 0.3716,                 loss: 0.1203
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1847s / 47.5222 s
agent0:                 episode reward: -0.1481,                 loss: nan
agent1:                 episode reward: 0.1481,                 loss: 0.1217
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2232s / 47.7454 s
agent0:                 episode reward: -0.6798,                 loss: nan
agent1:                 episode reward: 0.6798,                 loss: 0.1219
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1887s / 47.9341 s
agent0:                 episode reward: -0.2350,                 loss: nan
agent1:                 episode reward: 0.2350,                 loss: 0.1205
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1914s / 48.1255 s
agent0:                 episode reward: -0.2059,                 loss: nan
agent1:                 episode reward: 0.2059,                 loss: 0.1223
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1890s / 48.3146 s
agent0:                 episode reward: -0.2205,                 loss: nan
agent1:                 episode reward: 0.2205,                 loss: 0.1207
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1863s / 48.5009 s
agent0:                 episode reward: 0.3727,                 loss: nan
agent1:                 episode reward: -0.3727,                 loss: 0.1209
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2103s / 48.7112 s
agent0:                 episode reward: -0.2398,                 loss: nan
agent1:                 episode reward: 0.2398,                 loss: 0.1211
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2214s / 48.9326 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.1222
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2177s / 49.1503 s
agent0:                 episode reward: -0.1675,                 loss: nan
agent1:                 episode reward: 0.1675,                 loss: 0.1218
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 49.3477 s
agent0:                 episode reward: -0.6456,                 loss: nan
agent1:                 episode reward: 0.6456,                 loss: 0.1220
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1909s / 49.5386 s
agent0:                 episode reward: -0.2748,                 loss: nan
agent1:                 episode reward: 0.2748,                 loss: 0.1210
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1921s / 49.7307 s
agent0:                 episode reward: -0.2543,                 loss: nan
agent1:                 episode reward: 0.2543,                 loss: 0.1217
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1909s / 49.9216 s
agent0:                 episode reward: -0.1840,                 loss: nan
agent1:                 episode reward: 0.1840,                 loss: 0.1226
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 50.1199 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.1221
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 50.3208 s
agent0:                 episode reward: -0.3591,                 loss: nan
agent1:                 episode reward: 0.3591,                 loss: 0.1216
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2076s / 50.5284 s
agent0:                 episode reward: -0.2831,                 loss: nan
agent1:                 episode reward: 0.2831,                 loss: 0.1221
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2062s / 50.7346 s
agent0:                 episode reward: -0.2654,                 loss: nan
agent1:                 episode reward: 0.2654,                 loss: 0.1221
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2039s / 50.9385 s
agent0:                 episode reward: -0.2468,                 loss: nan
agent1:                 episode reward: 0.2468,                 loss: 0.1233
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 51.1333 s
agent0:                 episode reward: -0.2182,                 loss: nan
agent1:                 episode reward: 0.2182,                 loss: 0.1198
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 51.3314 s
agent0:                 episode reward: -0.1930,                 loss: nan
agent1:                 episode reward: 0.1930,                 loss: 0.1214
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2061s / 51.5375 s
agent0:                 episode reward: -0.3305,                 loss: nan
agent1:                 episode reward: 0.3305,                 loss: 0.1228
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2093s / 51.7468 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.1219
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 51.9511 s
agent0:                 episode reward: -0.4342,                 loss: nan
agent1:                 episode reward: 0.4342,                 loss: 0.1221
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2084s / 52.1596 s
agent0:                 episode reward: 0.0606,                 loss: nan
agent1:                 episode reward: -0.0606,                 loss: 0.1214
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 52.3525 s
agent0:                 episode reward: -0.1232,                 loss: nan
agent1:                 episode reward: 0.1232,                 loss: 0.1220
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1902s / 52.5427 s
agent0:                 episode reward: -0.4214,                 loss: nan
agent1:                 episode reward: 0.4214,                 loss: 0.1234
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 52.7408 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.1221
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 52.9422 s
agent0:                 episode reward: -0.1807,                 loss: nan
agent1:                 episode reward: 0.1807,                 loss: 0.1220
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 53.1402 s
agent0:                 episode reward: -0.4477,                 loss: nan
agent1:                 episode reward: 0.4477,                 loss: 0.1232
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 53.3393 s
agent0:                 episode reward: 0.0453,                 loss: nan
agent1:                 episode reward: -0.0453,                 loss: 0.1238
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 53.5403 s
agent0:                 episode reward: 0.0923,                 loss: nan
agent1:                 episode reward: -0.0923,                 loss: 0.1233
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2055s / 53.7459 s
agent0:                 episode reward: -0.1460,                 loss: nan
agent1:                 episode reward: 0.1460,                 loss: 0.1219
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 53.9477 s
agent0:                 episode reward: -0.2126,                 loss: nan
agent1:                 episode reward: 0.2126,                 loss: 0.1227
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 54.1397 s
agent0:                 episode reward: -0.2896,                 loss: nan
agent1:                 episode reward: 0.2896,                 loss: 0.1232
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1922s / 54.3320 s
agent0:                 episode reward: -0.2221,                 loss: nan
agent1:                 episode reward: 0.2221,                 loss: 0.1228
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 54.5316 s
agent0:                 episode reward: -0.6541,                 loss: nan
agent1:                 episode reward: 0.6541,                 loss: 0.1213
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 54.7268 s
agent0:                 episode reward: 0.2481,                 loss: nan
agent1:                 episode reward: -0.2481,                 loss: 0.1217
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 54.9221 s
agent0:                 episode reward: 0.0246,                 loss: nan
agent1:                 episode reward: -0.0246,                 loss: 0.1222
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2270s / 55.1491 s
agent0:                 episode reward: -0.3038,                 loss: nan
agent1:                 episode reward: 0.3038,                 loss: 0.1218
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2147s / 55.3638 s
agent0:                 episode reward: 0.1685,                 loss: nan
agent1:                 episode reward: -0.1685,                 loss: 0.1209
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 55.5634 s
agent0:                 episode reward: -0.2578,                 loss: nan
agent1:                 episode reward: 0.2578,                 loss: 0.1217
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 55.7641 s
agent0:                 episode reward: -0.2509,                 loss: nan
agent1:                 episode reward: 0.2509,                 loss: 0.1212
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 55.9655 s
agent0:                 episode reward: -0.5111,                 loss: nan
agent1:                 episode reward: 0.5111,                 loss: 0.1211
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 56.1615 s
agent0:                 episode reward: -0.3706,                 loss: nan
agent1:                 episode reward: 0.3706,                 loss: 0.1222
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 56.3644 s
agent0:                 episode reward: -0.1841,                 loss: nan
agent1:                 episode reward: 0.1841,                 loss: 0.1208
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 56.5683 s
agent0:                 episode reward: -0.0600,                 loss: nan
agent1:                 episode reward: 0.0600,                 loss: 0.1204
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 56.7696 s
agent0:                 episode reward: -0.2301,                 loss: nan
agent1:                 episode reward: 0.2301,                 loss: 0.1191
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2199s / 56.9895 s
agent0:                 episode reward: -0.2611,                 loss: nan
agent1:                 episode reward: 0.2611,                 loss: 0.1206
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 57.1902 s
agent0:                 episode reward: -0.3377,                 loss: nan
agent1:                 episode reward: 0.3377,                 loss: 0.1227
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 57.3849 s
agent0:                 episode reward: -0.2804,                 loss: nan
agent1:                 episode reward: 0.2804,                 loss: 0.1223
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1911s / 57.5760 s
agent0:                 episode reward: -0.7117,                 loss: nan
agent1:                 episode reward: 0.7117,                 loss: 0.1205
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 57.7726 s
agent0:                 episode reward: -0.1267,                 loss: nan
agent1:                 episode reward: 0.1267,                 loss: 0.1212
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 57.9736 s
agent0:                 episode reward: -0.3212,                 loss: nan
agent1:                 episode reward: 0.3212,                 loss: 0.1204
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2153s / 58.1890 s
agent0:                 episode reward: -0.3080,                 loss: nan
agent1:                 episode reward: 0.3080,                 loss: 0.1196
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2084s / 58.3973 s
agent0:                 episode reward: 0.2749,                 loss: nan
agent1:                 episode reward: -0.2749,                 loss: 0.1198
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 58.5905 s
agent0:                 episode reward: 0.1657,                 loss: nan
agent1:                 episode reward: -0.1657,                 loss: 0.1209
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 58.7902 s
agent0:                 episode reward: 0.0347,                 loss: nan
agent1:                 episode reward: -0.0347,                 loss: 0.1199
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2059s / 58.9961 s
agent0:                 episode reward: -0.4672,                 loss: nan
agent1:                 episode reward: 0.4672,                 loss: 0.1201
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 59.1978 s
agent0:                 episode reward: -0.2103,                 loss: nan
agent1:                 episode reward: 0.2103,                 loss: 0.1196
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 59.3989 s
agent0:                 episode reward: -0.3912,                 loss: nan
agent1:                 episode reward: 0.3912,                 loss: 0.1185
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 59.6031 s
agent0:                 episode reward: -0.1042,                 loss: nan
agent1:                 episode reward: 0.1042,                 loss: 0.1184
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2058s / 59.8089 s
agent0:                 episode reward: -0.3953,                 loss: nan
agent1:                 episode reward: 0.3953,                 loss: 0.1200
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2119s / 60.0207 s
agent0:                 episode reward: -0.4792,                 loss: nan
agent1:                 episode reward: 0.4792,                 loss: 0.1190
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1921s / 60.2128 s
agent0:                 episode reward: -0.5370,                 loss: nan
agent1:                 episode reward: 0.5370,                 loss: 0.1191
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 60.4062 s
agent0:                 episode reward: -0.3564,                 loss: nan
agent1:                 episode reward: 0.3564,                 loss: 0.1200
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 60.6002 s
agent0:                 episode reward: -0.5856,                 loss: nan
agent1:                 episode reward: 0.5856,                 loss: 0.1196
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 60.7956 s
agent0:                 episode reward: -0.3407,                 loss: nan
agent1:                 episode reward: 0.3407,                 loss: 0.1189
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1927s / 60.9883 s
agent0:                 episode reward: -0.3967,                 loss: nan
agent1:                 episode reward: 0.3967,                 loss: 0.1197
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2178s / 61.2061 s
agent0:                 episode reward: -0.4185,                 loss: nan
agent1:                 episode reward: 0.4185,                 loss: 0.1189
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2157s / 61.4218 s
agent0:                 episode reward: -0.1531,                 loss: nan
agent1:                 episode reward: 0.1531,                 loss: 0.1200
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1917s / 61.6135 s
agent0:                 episode reward: -0.2752,                 loss: nan
agent1:                 episode reward: 0.2752,                 loss: 0.1199
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 61.8139 s
agent0:                 episode reward: -0.3541,                 loss: nan
agent1:                 episode reward: 0.3541,                 loss: 0.1212
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 62.0113 s
agent0:                 episode reward: -0.4002,                 loss: nan
agent1:                 episode reward: 0.4002,                 loss: 0.1209
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 62.2084 s
agent0:                 episode reward: -0.6597,                 loss: nan
agent1:                 episode reward: 0.6597,                 loss: 0.1199
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 62.4065 s
agent0:                 episode reward: -0.2293,                 loss: nan
agent1:                 episode reward: 0.2293,                 loss: 0.1199
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 62.6016 s
agent0:                 episode reward: -0.1396,                 loss: nan
agent1:                 episode reward: 0.1396,                 loss: 0.1196
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 62.7957 s
agent0:                 episode reward: 0.0034,                 loss: nan
agent1:                 episode reward: -0.0034,                 loss: 0.1202
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 62.9956 s
agent0:                 episode reward: -0.3653,                 loss: nan
agent1:                 episode reward: 0.3653,                 loss: 0.1193
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 63.1955 s
agent0:                 episode reward: -0.2092,                 loss: nan
agent1:                 episode reward: 0.2092,                 loss: 0.1201
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2045s / 63.4000 s
agent0:                 episode reward: -0.9621,                 loss: nan
agent1:                 episode reward: 0.9621,                 loss: 0.1194
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2072s / 63.6072 s
agent0:                 episode reward: -0.1316,                 loss: nan
agent1:                 episode reward: 0.1316,                 loss: 0.1196
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 63.8088 s
agent0:                 episode reward: 0.0296,                 loss: nan
agent1:                 episode reward: -0.0296,                 loss: 0.1197
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2062s / 64.0150 s
agent0:                 episode reward: -0.4445,                 loss: nan
agent1:                 episode reward: 0.4445,                 loss: 0.1213
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2274s / 64.2424 s
agent0:                 episode reward: -0.4543,                 loss: nan
agent1:                 episode reward: 0.4543,                 loss: 0.1198
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2274s / 64.4698 s
agent0:                 episode reward: -0.7551,                 loss: nan
agent1:                 episode reward: 0.7551,                 loss: 0.1207
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2046s / 64.6744 s
agent0:                 episode reward: -0.0365,                 loss: nan
agent1:                 episode reward: 0.0365,                 loss: 0.1212
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2032s / 64.8777 s
agent0:                 episode reward: -0.3491,                 loss: nan
agent1:                 episode reward: 0.3491,                 loss: 0.1201
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2079s / 65.0855 s
agent0:                 episode reward: -0.6796,                 loss: nan
agent1:                 episode reward: 0.6796,                 loss: 0.1191
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2199s / 65.3054 s
agent0:                 episode reward: -0.1970,                 loss: nan
agent1:                 episode reward: 0.1970,                 loss: 0.1202
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2143s / 65.5198 s
agent0:                 episode reward: 0.0449,                 loss: nan
agent1:                 episode reward: -0.0449,                 loss: 0.1196
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 65.7215 s
agent0:                 episode reward: -0.2974,                 loss: nan
agent1:                 episode reward: 0.2974,                 loss: 0.1195
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2077s / 65.9292 s
agent0:                 episode reward: -0.5021,                 loss: nan
agent1:                 episode reward: 0.5021,                 loss: 0.1188
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2043s / 66.1335 s
agent0:                 episode reward: -0.2470,                 loss: nan
agent1:                 episode reward: 0.2470,                 loss: 0.1196
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 66.3348 s
agent0:                 episode reward: -0.4116,                 loss: nan
agent1:                 episode reward: 0.4116,                 loss: 0.1183
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 66.5392 s
agent0:                 episode reward: -0.5367,                 loss: nan
agent1:                 episode reward: 0.5367,                 loss: 0.1193
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 66.7422 s
agent0:                 episode reward: -0.4890,                 loss: nan
agent1:                 episode reward: 0.4890,                 loss: 0.1181
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2057s / 66.9478 s
agent0:                 episode reward: -0.9338,                 loss: nan
agent1:                 episode reward: 0.9338,                 loss: 0.1186
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2049s / 67.1527 s
agent0:                 episode reward: -0.6220,                 loss: nan
agent1:                 episode reward: 0.6220,                 loss: 0.1194
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2317s / 67.3844 s
agent0:                 episode reward: -0.3690,                 loss: nan
agent1:                 episode reward: 0.3690,                 loss: 0.1168
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2131s / 67.5975 s
agent0:                 episode reward: -0.6393,                 loss: nan
agent1:                 episode reward: 0.6393,                 loss: 0.1177
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 67.7939 s
agent0:                 episode reward: -0.0362,                 loss: nan
agent1:                 episode reward: 0.0362,                 loss: 0.1182
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 67.9921 s
agent0:                 episode reward: -0.3189,                 loss: nan
agent1:                 episode reward: 0.3189,                 loss: 0.1181
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 68.1925 s
agent0:                 episode reward: -0.1965,                 loss: nan
agent1:                 episode reward: 0.1965,                 loss: 0.1192
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 68.3914 s
agent0:                 episode reward: -0.3915,                 loss: nan
agent1:                 episode reward: 0.3915,                 loss: 0.1185
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 68.5905 s
agent0:                 episode reward: 0.2451,                 loss: nan
agent1:                 episode reward: -0.2451,                 loss: 0.1202
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 68.7904 s
agent0:                 episode reward: -0.2389,                 loss: nan
agent1:                 episode reward: 0.2389,                 loss: 0.1198
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 68.9888 s
agent0:                 episode reward: -0.2350,                 loss: nan
agent1:                 episode reward: 0.2350,                 loss: 0.1183
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 69.1909 s
agent0:                 episode reward: 0.0231,                 loss: nan
agent1:                 episode reward: -0.0231,                 loss: 0.1197
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2073s / 69.3982 s
agent0:                 episode reward: -0.6840,                 loss: nan
agent1:                 episode reward: 0.6840,                 loss: 0.1215
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 69.5995 s
agent0:                 episode reward: 0.1443,                 loss: nan
agent1:                 episode reward: -0.1443,                 loss: 0.1199
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 69.8037 s
agent0:                 episode reward: -0.6456,                 loss: nan
agent1:                 episode reward: 0.6456,                 loss: 0.1197
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 70.0064 s
agent0:                 episode reward: -0.6385,                 loss: nan
agent1:                 episode reward: 0.6385,                 loss: 0.1184
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 70.2072 s
agent0:                 episode reward: -0.3422,                 loss: nan
agent1:                 episode reward: 0.3422,                 loss: 0.1209
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2346s / 70.4418 s
agent0:                 episode reward: -0.3751,                 loss: nan
agent1:                 episode reward: 0.3751,                 loss: 0.1181
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2130s / 70.6548 s
agent0:                 episode reward: -0.7779,                 loss: nan
agent1:                 episode reward: 0.7779,                 loss: 0.1181
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 70.8543 s
agent0:                 episode reward: -0.4755,                 loss: nan
agent1:                 episode reward: 0.4755,                 loss: 0.1180
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 71.0556 s
agent0:                 episode reward: -0.3019,                 loss: nan
agent1:                 episode reward: 0.3019,                 loss: 0.1182
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2045s / 71.2601 s
agent0:                 episode reward: -0.1625,                 loss: nan
agent1:                 episode reward: 0.1625,                 loss: 0.1196
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 71.4632 s
agent0:                 episode reward: -0.3928,                 loss: nan
agent1:                 episode reward: 0.3928,                 loss: 0.1205
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2079s / 71.6711 s
agent0:                 episode reward: -0.1228,                 loss: nan
agent1:                 episode reward: 0.1228,                 loss: 0.1192
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 71.8728 s
agent0:                 episode reward: -0.1614,                 loss: nan
agent1:                 episode reward: 0.1614,                 loss: 0.1175
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 72.0720 s
agent0:                 episode reward: -0.4780,                 loss: nan
agent1:                 episode reward: 0.4780,                 loss: 0.1192
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 72.2674 s
agent0:                 episode reward: -0.3858,                 loss: nan
agent1:                 episode reward: 0.3858,                 loss: 0.1183
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 72.4635 s
agent0:                 episode reward: -0.0294,                 loss: nan
agent1:                 episode reward: 0.0294,                 loss: 0.1154
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 72.6614 s
agent0:                 episode reward: -0.3413,                 loss: nan
agent1:                 episode reward: 0.3413,                 loss: 0.1180
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 72.8620 s
agent0:                 episode reward: -0.7155,                 loss: nan
agent1:                 episode reward: 0.7155,                 loss: 0.1191
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 73.0627 s
agent0:                 episode reward: -0.3671,                 loss: nan
agent1:                 episode reward: 0.3671,                 loss: 0.1191
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2090s / 73.2717 s
agent0:                 episode reward: -0.6044,                 loss: nan
agent1:                 episode reward: 0.6044,                 loss: 0.1198
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2420s / 73.5137 s
agent0:                 episode reward: -0.3156,                 loss: nan
agent1:                 episode reward: 0.3156,                 loss: 0.1181
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2437s / 73.7574 s
agent0:                 episode reward: -0.4110,                 loss: nan
agent1:                 episode reward: 0.4110,                 loss: 0.1161
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2109s / 73.9683 s
agent0:                 episode reward: -0.1607,                 loss: nan
agent1:                 episode reward: 0.1607,                 loss: 0.1170
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2171s / 74.1854 s
agent0:                 episode reward: -0.0516,                 loss: nan
agent1:                 episode reward: 0.0516,                 loss: 0.1171
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2139s / 74.3993 s
agent0:                 episode reward: -0.3570,                 loss: nan
agent1:                 episode reward: 0.3570,                 loss: 0.1180
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2112s / 74.6105 s
agent0:                 episode reward: -0.1126,                 loss: nan
agent1:                 episode reward: 0.1126,                 loss: 0.1177
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2163s / 74.8268 s
agent0:                 episode reward: -0.5668,                 loss: nan
agent1:                 episode reward: 0.5668,                 loss: 0.1166
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2070s / 75.0338 s
agent0:                 episode reward: -0.1556,                 loss: nan
agent1:                 episode reward: 0.1556,                 loss: 0.1175
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2074s / 75.2412 s
agent0:                 episode reward: -0.3947,                 loss: nan
agent1:                 episode reward: 0.3947,                 loss: 0.1188
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2078s / 75.4490 s
agent0:                 episode reward: -0.7494,                 loss: nan
agent1:                 episode reward: 0.7494,                 loss: 0.1196
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2068s / 75.6558 s
agent0:                 episode reward: -0.5149,                 loss: nan
agent1:                 episode reward: 0.5149,                 loss: 0.1182
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2126s / 75.8684 s
agent0:                 episode reward: -0.5290,                 loss: nan
agent1:                 episode reward: 0.5290,                 loss: 0.1183
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2114s / 76.0798 s
agent0:                 episode reward: -0.4292,                 loss: nan
agent1:                 episode reward: 0.4292,                 loss: 0.1176
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2094s / 76.2892 s
agent0:                 episode reward: -0.3605,                 loss: nan
agent1:                 episode reward: 0.3605,                 loss: 0.1186
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2344s / 76.5236 s
agent0:                 episode reward: -0.1763,                 loss: nan
agent1:                 episode reward: 0.1763,                 loss: 0.1191
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2215s / 76.7451 s
agent0:                 episode reward: -0.2942,                 loss: nan
agent1:                 episode reward: 0.2942,                 loss: 0.1200
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 76.9475 s
agent0:                 episode reward: -0.2482,                 loss: nan
agent1:                 episode reward: 0.2482,                 loss: 0.1188
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 77.1493 s
agent0:                 episode reward: -0.3403,                 loss: nan
agent1:                 episode reward: 0.3403,                 loss: 0.1182
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 77.3480 s
agent0:                 episode reward: -0.2935,                 loss: nan
agent1:                 episode reward: 0.2935,                 loss: 0.1196
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 77.5471 s
agent0:                 episode reward: -0.1519,                 loss: nan
agent1:                 episode reward: 0.1519,                 loss: 0.1197
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 77.7486 s
agent0:                 episode reward: -0.2333,                 loss: nan
agent1:                 episode reward: 0.2333,                 loss: 0.1194
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2408s / 77.9894 s
agent0:                 episode reward: -0.6512,                 loss: nan
agent1:                 episode reward: 0.6512,                 loss: 0.1185
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2112s / 78.2006 s
agent0:                 episode reward: -0.6774,                 loss: nan
agent1:                 episode reward: 0.6774,                 loss: 0.1176
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2090s / 78.4096 s
agent0:                 episode reward: -0.3507,                 loss: nan
agent1:                 episode reward: 0.3507,                 loss: 0.1177
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 78.6168 s
agent0:                 episode reward: 0.0969,                 loss: nan
agent1:                 episode reward: -0.0969,                 loss: 0.1183
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2092s / 78.8259 s
agent0:                 episode reward: -0.4589,                 loss: nan
agent1:                 episode reward: 0.4589,                 loss: 0.1205
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2056s / 79.0315 s
agent0:                 episode reward: -0.0647,                 loss: nan
agent1:                 episode reward: 0.0647,                 loss: 0.1178
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 79.2357 s
agent0:                 episode reward: -0.3638,                 loss: nan
agent1:                 episode reward: 0.3638,                 loss: 0.1186
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2190s / 79.4547 s
agent0:                 episode reward: -0.2587,                 loss: nan
agent1:                 episode reward: 0.2587,                 loss: 0.1168
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2441s / 79.6988 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.1172
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2156s / 79.9144 s
agent0:                 episode reward: -0.5245,                 loss: nan
agent1:                 episode reward: 0.5245,                 loss: 0.1171
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2176s / 80.1320 s
agent0:                 episode reward: -0.5581,                 loss: nan
agent1:                 episode reward: 0.5581,                 loss: 0.1171
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2101s / 80.3421 s
agent0:                 episode reward: -0.4734,                 loss: nan
agent1:                 episode reward: 0.4734,                 loss: 0.1179
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2117s / 80.5538 s
agent0:                 episode reward: -0.0838,                 loss: nan
agent1:                 episode reward: 0.0838,                 loss: 0.1177
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2110s / 80.7648 s
agent0:                 episode reward: -0.4846,                 loss: nan
agent1:                 episode reward: 0.4846,                 loss: 0.1153
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2128s / 80.9776 s
agent0:                 episode reward: -0.1778,                 loss: nan
agent1:                 episode reward: 0.1778,                 loss: 0.1163
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2119s / 81.1896 s
agent0:                 episode reward: -0.3063,                 loss: nan
agent1:                 episode reward: 0.3063,                 loss: 0.1173
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2181s / 81.4077 s
agent0:                 episode reward: -0.3535,                 loss: nan
agent1:                 episode reward: 0.3535,                 loss: 0.1176
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2150s / 81.6227 s
agent0:                 episode reward: -0.3492,                 loss: nan
agent1:                 episode reward: 0.3492,                 loss: 0.1170
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 81.8264 s
agent0:                 episode reward: -0.3145,                 loss: nan
agent1:                 episode reward: 0.3145,                 loss: 0.1172
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2281s / 82.0545 s
agent0:                 episode reward: -0.2866,                 loss: nan
agent1:                 episode reward: 0.2866,                 loss: 0.1174
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2137s / 82.2683 s
agent0:                 episode reward: -0.3156,                 loss: nan
agent1:                 episode reward: 0.3156,                 loss: 0.1174
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2191s / 82.4873 s
agent0:                 episode reward: -0.3899,                 loss: nan
agent1:                 episode reward: 0.3899,                 loss: 0.1168
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 82.7347 s
agent0:                 episode reward: -0.1030,                 loss: nan
agent1:                 episode reward: 0.1030,                 loss: 0.1178
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2235s / 82.9582 s
agent0:                 episode reward: -0.4591,                 loss: nan
agent1:                 episode reward: 0.4591,                 loss: 0.1175
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2220s / 83.1801 s
agent0:                 episode reward: -0.3304,                 loss: nan
agent1:                 episode reward: 0.3304,                 loss: 0.1188
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2148s / 83.3949 s
agent0:                 episode reward: -0.7420,                 loss: nan
agent1:                 episode reward: 0.7420,                 loss: 0.1180
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2061s / 83.6011 s
agent0:                 episode reward: -0.2111,                 loss: nan
agent1:                 episode reward: 0.2111,                 loss: 0.1180
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2083s / 83.8094 s
agent0:                 episode reward: -0.5566,                 loss: nan
agent1:                 episode reward: 0.5566,                 loss: 0.1169
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2080s / 84.0173 s
agent0:                 episode reward: -0.2425,                 loss: nan
agent1:                 episode reward: 0.2425,                 loss: 0.1172
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2064s / 84.2237 s
agent0:                 episode reward: -0.0959,                 loss: nan
agent1:                 episode reward: 0.0959,                 loss: 0.1177
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2107s / 84.4344 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.1157
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2129s / 84.6474 s
agent0:                 episode reward: -0.2757,                 loss: nan
agent1:                 episode reward: 0.2757,                 loss: 0.1178
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2058s / 84.8532 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: 0.1169
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2061s / 85.0593 s
agent0:                 episode reward: -0.3509,                 loss: nan
agent1:                 episode reward: 0.3509,                 loss: 0.1180
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2177s / 85.2770 s
agent0:                 episode reward: -0.5910,                 loss: nan
agent1:                 episode reward: 0.5910,                 loss: 0.1175
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2082s / 85.4852 s
agent0:                 episode reward: -0.1574,                 loss: nan
agent1:                 episode reward: 0.1574,                 loss: 0.1178
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2319s / 85.7171 s
agent0:                 episode reward: -0.2398,                 loss: nan
agent1:                 episode reward: 0.2398,                 loss: 0.1184
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2291s / 85.9463 s
agent0:                 episode reward: -0.4266,                 loss: nan
agent1:                 episode reward: 0.4266,                 loss: 0.1169
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2123s / 86.1586 s
agent0:                 episode reward: -0.3684,                 loss: nan
agent1:                 episode reward: 0.3684,                 loss: 0.1153
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2094s / 86.3680 s
agent0:                 episode reward: -0.4358,                 loss: nan
agent1:                 episode reward: 0.4358,                 loss: 0.1154
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2111s / 86.5791 s
agent0:                 episode reward: -0.5475,                 loss: nan
agent1:                 episode reward: 0.5475,                 loss: 0.1163
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2093s / 86.7884 s
agent0:                 episode reward: -0.2851,                 loss: nan
agent1:                 episode reward: 0.2851,                 loss: 0.1156
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2064s / 86.9948 s
agent0:                 episode reward: -0.3031,                 loss: nan
agent1:                 episode reward: 0.3031,                 loss: 0.1154
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2125s / 87.2073 s
agent0:                 episode reward: -0.2242,                 loss: nan
agent1:                 episode reward: 0.2242,                 loss: 0.1169
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 87.4144 s
agent0:                 episode reward: -0.4545,                 loss: nan
agent1:                 episode reward: 0.4545,                 loss: 0.1167
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2098s / 87.6243 s
agent0:                 episode reward: -0.3388,                 loss: nan
agent1:                 episode reward: 0.3388,                 loss: 0.1157
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2088s / 87.8331 s
agent0:                 episode reward: -0.7206,                 loss: nan
agent1:                 episode reward: 0.7206,                 loss: 0.1168
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2128s / 88.0458 s
agent0:                 episode reward: -0.5045,                 loss: nan
agent1:                 episode reward: 0.5045,                 loss: 0.1157
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2111s / 88.2569 s
agent0:                 episode reward: -0.3691,                 loss: nan
agent1:                 episode reward: 0.3691,                 loss: 0.1165
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2109s / 88.4678 s
agent0:                 episode reward: -0.4053,                 loss: nan
agent1:                 episode reward: 0.4053,                 loss: 0.1157
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2334s / 88.7012 s
agent0:                 episode reward: -0.2215,                 loss: nan
agent1:                 episode reward: 0.2215,                 loss: 0.1166
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2360s / 88.9371 s
agent0:                 episode reward: -0.2717,                 loss: nan
agent1:                 episode reward: 0.2717,                 loss: 0.1165
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2119s / 89.1491 s
agent0:                 episode reward: -0.1698,                 loss: nan
agent1:                 episode reward: 0.1698,                 loss: 0.1168
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2140s / 89.3631 s
agent0:                 episode reward: -0.5735,                 loss: nan
agent1:                 episode reward: 0.5735,                 loss: 0.1161
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2065s / 89.5696 s
agent0:                 episode reward: -0.3771,                 loss: nan
agent1:                 episode reward: 0.3771,                 loss: 0.1155
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2089s / 89.7785 s
agent0:                 episode reward: -0.6690,                 loss: nan
agent1:                 episode reward: 0.6690,                 loss: 0.1153
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2111s / 89.9896 s
agent0:                 episode reward: -0.4424,                 loss: nan
agent1:                 episode reward: 0.4424,                 loss: 0.1160
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2180s / 90.2076 s
agent0:                 episode reward: -0.5418,                 loss: nan
agent1:                 episode reward: 0.5418,                 loss: 0.1153
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2262s / 90.4338 s
agent0:                 episode reward: -0.2118,                 loss: nan
agent1:                 episode reward: 0.2118,                 loss: 0.1160
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2131s / 90.6468 s
agent0:                 episode reward: -0.4586,                 loss: nan
agent1:                 episode reward: 0.4586,                 loss: 0.1164
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2183s / 90.8651 s
agent0:                 episode reward: -0.5164,                 loss: nan
agent1:                 episode reward: 0.5164,                 loss: 0.1162
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2134s / 91.0785 s
agent0:                 episode reward: -0.3313,                 loss: nan
agent1:                 episode reward: 0.3313,                 loss: 0.1157
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2124s / 91.2909 s
agent0:                 episode reward: -0.7115,                 loss: nan
agent1:                 episode reward: 0.7115,                 loss: 0.1145
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2214s / 91.5123 s
agent0:                 episode reward: -0.4332,                 loss: nan
agent1:                 episode reward: 0.4332,                 loss: 0.1159
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2276s / 91.7398 s
agent0:                 episode reward: -0.5142,                 loss: nan
agent1:                 episode reward: 0.5142,                 loss: 0.1173
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2456s / 91.9854 s
agent0:                 episode reward: -0.5834,                 loss: nan
agent1:                 episode reward: 0.5834,                 loss: 0.1153
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2217s / 92.2071 s
agent0:                 episode reward: -0.2345,                 loss: nan
agent1:                 episode reward: 0.2345,                 loss: 0.1161
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2149s / 92.4221 s
agent0:                 episode reward: -0.1979,                 loss: nan
agent1:                 episode reward: 0.1979,                 loss: 0.1162
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2159s / 92.6379 s
agent0:                 episode reward: -0.2352,                 loss: nan
agent1:                 episode reward: 0.2352,                 loss: 0.1155
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2152s / 92.8531 s
agent0:                 episode reward: -0.5957,                 loss: nan
agent1:                 episode reward: 0.5957,                 loss: 0.1162
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2164s / 93.0696 s
agent0:                 episode reward: -0.1817,                 loss: nan
agent1:                 episode reward: 0.1817,                 loss: 0.1146
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2185s / 93.2880 s
agent0:                 episode reward: -0.8019,                 loss: nan
agent1:                 episode reward: 0.8019,                 loss: 0.1151
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2175s / 93.5055 s
agent0:                 episode reward: -0.4957,                 loss: nan
agent1:                 episode reward: 0.4957,                 loss: 0.1144
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2209s / 93.7264 s
agent0:                 episode reward: 0.0425,                 loss: nan
agent1:                 episode reward: -0.0425,                 loss: 0.1144
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2190s / 93.9453 s
agent0:                 episode reward: -0.3460,                 loss: nan
agent1:                 episode reward: 0.3460,                 loss: 0.1158
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2133s / 94.1586 s
agent0:                 episode reward: -0.1982,                 loss: nan
agent1:                 episode reward: 0.1982,                 loss: 0.1138
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2143s / 94.3729 s
agent0:                 episode reward: -0.2466,                 loss: nan
agent1:                 episode reward: 0.2466,                 loss: 0.1150
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2159s / 94.5888 s
agent0:                 episode reward: -0.7622,                 loss: nan
agent1:                 episode reward: 0.7622,                 loss: 0.1152
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2365s / 94.8253 s
agent0:                 episode reward: -0.4167,                 loss: nan
agent1:                 episode reward: 0.4167,                 loss: 0.1141
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2411s / 95.0664 s
agent0:                 episode reward: -0.4418,                 loss: nan
agent1:                 episode reward: 0.4418,                 loss: 0.1149
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2199s / 95.2863 s
agent0:                 episode reward: -0.5560,                 loss: nan
agent1:                 episode reward: 0.5560,                 loss: 0.1151
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2153s / 95.5016 s
agent0:                 episode reward: -0.5600,                 loss: nan
agent1:                 episode reward: 0.5600,                 loss: 0.1140
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2165s / 95.7181 s
agent0:                 episode reward: -0.5510,                 loss: nan
agent1:                 episode reward: 0.5510,                 loss: 0.1138
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2243s / 95.9424 s
agent0:                 episode reward: -0.2111,                 loss: nan
agent1:                 episode reward: 0.2111,                 loss: 0.1130
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2260s / 96.1684 s
agent0:                 episode reward: -0.2020,                 loss: nan
agent1:                 episode reward: 0.2020,                 loss: 0.1149
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2284s / 96.3969 s
agent0:                 episode reward: -0.2663,                 loss: nan
agent1:                 episode reward: 0.2663,                 loss: 0.1155
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2279s / 96.6247 s
agent0:                 episode reward: -0.4815,                 loss: nan
agent1:                 episode reward: 0.4815,                 loss: 0.1154
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2279s / 96.8526 s
agent0:                 episode reward: -0.2892,                 loss: nan
agent1:                 episode reward: 0.2892,                 loss: 0.1143
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2206s / 97.0732 s
agent0:                 episode reward: -0.5940,                 loss: nan
agent1:                 episode reward: 0.5940,                 loss: 0.1148
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2256s / 97.2988 s
agent0:                 episode reward: -0.2708,                 loss: nan
agent1:                 episode reward: 0.2708,                 loss: 0.1148
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2307s / 97.5295 s
agent0:                 episode reward: -0.3206,                 loss: nan
agent1:                 episode reward: 0.3206,                 loss: 0.1150
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2292s / 97.7587 s
agent0:                 episode reward: -0.7364,                 loss: nan
agent1:                 episode reward: 0.7364,                 loss: 0.1133
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2652s / 98.0239 s
agent0:                 episode reward: -0.5747,                 loss: nan
agent1:                 episode reward: 0.5747,                 loss: 0.1146
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2426s / 98.2665 s
agent0:                 episode reward: -0.3923,                 loss: nan
agent1:                 episode reward: 0.3923,                 loss: 0.1132
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2281s / 98.4946 s
agent0:                 episode reward: -0.6537,                 loss: nan
agent1:                 episode reward: 0.6537,                 loss: 0.1155
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2461s / 98.7407 s
agent0:                 episode reward: -0.5312,                 loss: nan
agent1:                 episode reward: 0.5312,                 loss: 0.1120
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2203s / 98.9610 s
agent0:                 episode reward: -0.4891,                 loss: nan
agent1:                 episode reward: 0.4891,                 loss: 0.1143
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2198s / 99.1808 s
agent0:                 episode reward: -0.5590,                 loss: nan
agent1:                 episode reward: 0.5590,                 loss: 0.1150
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2194s / 99.4002 s
agent0:                 episode reward: -0.4488,                 loss: nan
agent1:                 episode reward: 0.4488,                 loss: 0.1143
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2278s / 99.6280 s
agent0:                 episode reward: -0.1745,                 loss: nan
agent1:                 episode reward: 0.1745,                 loss: 0.1137
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2296s / 99.8575 s
agent0:                 episode reward: -0.5527,                 loss: nan
agent1:                 episode reward: 0.5527,                 loss: 0.1124
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2221s / 100.0796 s
agent0:                 episode reward: -0.5882,                 loss: nan
agent1:                 episode reward: 0.5882,                 loss: 0.1133
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2177s / 100.2973 s
agent0:                 episode reward: -0.4072,                 loss: nan
agent1:                 episode reward: 0.4072,                 loss: 0.1135
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2203s / 100.5177 s
agent0:                 episode reward: -0.4887,                 loss: nan
agent1:                 episode reward: 0.4887,                 loss: 0.1148
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2236s / 100.7412 s
agent0:                 episode reward: -0.5137,                 loss: nan
agent1:                 episode reward: 0.5137,                 loss: 0.1136
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2261s / 100.9673 s
agent0:                 episode reward: -0.4605,                 loss: nan
agent1:                 episode reward: 0.4605,                 loss: 0.1155
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2247s / 101.1920 s
agent0:                 episode reward: -0.2692,                 loss: nan
agent1:                 episode reward: 0.2692,                 loss: 0.1144
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2319s / 101.4239 s
agent0:                 episode reward: -0.3871,                 loss: nan
agent1:                 episode reward: 0.3871,                 loss: 0.1169
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2271s / 101.6510 s
agent0:                 episode reward: -0.5407,                 loss: nan
agent1:                 episode reward: 0.5407,                 loss: 0.1144
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2277s / 101.8787 s
agent0:                 episode reward: -0.4675,                 loss: nan
agent1:                 episode reward: 0.4675,                 loss: 0.1142
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2273s / 102.1061 s
agent0:                 episode reward: -0.3358,                 loss: nan
agent1:                 episode reward: 0.3358,                 loss: 0.1145
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2214s / 102.3275 s
agent0:                 episode reward: -0.2194,                 loss: nan
agent1:                 episode reward: 0.2194,                 loss: 0.1142
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2120s / 102.5395 s
agent0:                 episode reward: -0.6708,                 loss: nan
agent1:                 episode reward: 0.6708,                 loss: 0.1138
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2118s / 102.7513 s
agent0:                 episode reward: -0.3510,                 loss: nan
agent1:                 episode reward: 0.3510,                 loss: 0.1144
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2137s / 102.9650 s
agent0:                 episode reward: -0.6255,                 loss: nan
agent1:                 episode reward: 0.6255,                 loss: 0.1143
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2137s / 103.1786 s
agent0:                 episode reward: -0.4958,                 loss: nan
agent1:                 episode reward: 0.4958,                 loss: 0.1140
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2200s / 103.3986 s
agent0:                 episode reward: -0.1690,                 loss: nan
agent1:                 episode reward: 0.1690,                 loss: 0.1138
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2226s / 103.6213 s
agent0:                 episode reward: -0.3602,                 loss: nan
agent1:                 episode reward: 0.3602,                 loss: 0.1147
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2483s / 103.8696 s
agent0:                 episode reward: -0.5271,                 loss: nan
agent1:                 episode reward: 0.5271,                 loss: 0.1137
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2206s / 104.0901 s
agent0:                 episode reward: -0.3390,                 loss: nan
agent1:                 episode reward: 0.3390,                 loss: 0.1149
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2135s / 104.3036 s
agent0:                 episode reward: -0.4045,                 loss: nan
agent1:                 episode reward: 0.4045,                 loss: 0.1156
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2267s / 104.5303 s
agent0:                 episode reward: -0.6755,                 loss: nan
agent1:                 episode reward: 0.6755,                 loss: 0.1149
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2319s / 104.7622 s
agent0:                 episode reward: -0.4541,                 loss: nan
agent1:                 episode reward: 0.4541,                 loss: 0.1156
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2342s / 104.9964 s
agent0:                 episode reward: -0.5611,                 loss: nan
agent1:                 episode reward: 0.5611,                 loss: 0.1168
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2309s / 105.2272 s
agent0:                 episode reward: -0.5852,                 loss: nan
agent1:                 episode reward: 0.5852,                 loss: 0.1160
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2360s / 105.4633 s
agent0:                 episode reward: -0.2764,                 loss: nan
agent1:                 episode reward: 0.2764,                 loss: 0.1146
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2350s / 105.6983 s
agent0:                 episode reward: -0.5641,                 loss: nan
agent1:                 episode reward: 0.5641,                 loss: 0.1139
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2333s / 105.9316 s
agent0:                 episode reward: -0.2759,                 loss: nan
agent1:                 episode reward: 0.2759,                 loss: 0.1143
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2317s / 106.1633 s
agent0:                 episode reward: -0.3234,                 loss: nan
agent1:                 episode reward: 0.3234,                 loss: 0.1142
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2437s / 106.4071 s
agent0:                 episode reward: -0.5894,                 loss: nan
agent1:                 episode reward: 0.5894,                 loss: 0.1141
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2363s / 106.6434 s
agent0:                 episode reward: -0.4062,                 loss: nan
agent1:                 episode reward: 0.4062,                 loss: 0.1155
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 106.9066 s
agent0:                 episode reward: -0.3355,                 loss: nan
agent1:                 episode reward: 0.3355,                 loss: 0.1147
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2466s / 107.1532 s
agent0:                 episode reward: -0.3352,                 loss: nan
agent1:                 episode reward: 0.3352,                 loss: 0.1156
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2306s / 107.3837 s
agent0:                 episode reward: -0.8638,                 loss: nan
agent1:                 episode reward: 0.8638,                 loss: 0.1153
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2280s / 107.6117 s
agent0:                 episode reward: -0.6540,                 loss: nan
agent1:                 episode reward: 0.6540,                 loss: 0.1140
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2336s / 107.8453 s
agent0:                 episode reward: -0.1631,                 loss: nan
agent1:                 episode reward: 0.1631,                 loss: 0.1150
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2380s / 108.0833 s
agent0:                 episode reward: -0.2553,                 loss: nan
agent1:                 episode reward: 0.2553,                 loss: 0.1151
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2329s / 108.3162 s
agent0:                 episode reward: -0.5174,                 loss: nan
agent1:                 episode reward: 0.5174,                 loss: 0.1150
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2349s / 108.5510 s
agent0:                 episode reward: -0.6307,                 loss: nan
agent1:                 episode reward: 0.6307,                 loss: 0.1140
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2359s / 108.7870 s
agent0:                 episode reward: -0.5892,                 loss: nan
agent1:                 episode reward: 0.5892,                 loss: 0.1152
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2302s / 109.0171 s
agent0:                 episode reward: -0.3238,                 loss: nan
agent1:                 episode reward: 0.3238,                 loss: 0.1149
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2364s / 109.2535 s
agent0:                 episode reward: -0.3752,                 loss: nan
agent1:                 episode reward: 0.3752,                 loss: 0.1144
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2323s / 109.4858 s
agent0:                 episode reward: -0.4636,                 loss: nan
agent1:                 episode reward: 0.4636,                 loss: 0.1147
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2315s / 109.7173 s
agent0:                 episode reward: -0.3801,                 loss: nan
agent1:                 episode reward: 0.3801,                 loss: 0.1153
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2683s / 109.9857 s
agent0:                 episode reward: -0.5203,                 loss: nan
agent1:                 episode reward: 0.5203,                 loss: 0.1153
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2452s / 110.2309 s
agent0:                 episode reward: -0.8276,                 loss: nan
agent1:                 episode reward: 0.8276,                 loss: 0.1149
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2299s / 110.4607 s
agent0:                 episode reward: -0.5050,                 loss: nan
agent1:                 episode reward: 0.5050,                 loss: 0.1148
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2328s / 110.6935 s
agent0:                 episode reward: -0.2086,                 loss: nan
agent1:                 episode reward: 0.2086,                 loss: 0.1163
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2318s / 110.9253 s
agent0:                 episode reward: -0.6748,                 loss: nan
agent1:                 episode reward: 0.6748,                 loss: 0.1152
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2283s / 111.1536 s
agent0:                 episode reward: -0.3342,                 loss: nan
agent1:                 episode reward: 0.3342,                 loss: 0.1157
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2251s / 111.3787 s
agent0:                 episode reward: -0.3164,                 loss: nan
agent1:                 episode reward: 0.3164,                 loss: 0.1144
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2273s / 111.6060 s
agent0:                 episode reward: -0.7113,                 loss: nan
agent1:                 episode reward: 0.7113,                 loss: 0.1150
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2337s / 111.8397 s
agent0:                 episode reward: -0.4805,                 loss: nan
agent1:                 episode reward: 0.4805,                 loss: 0.1145
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2332s / 112.0729 s
agent0:                 episode reward: -0.8510,                 loss: nan
agent1:                 episode reward: 0.8510,                 loss: 0.1127
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2334s / 112.3063 s
agent0:                 episode reward: -0.1946,                 loss: nan
agent1:                 episode reward: 0.1946,                 loss: 0.1138
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2309s / 112.5372 s
agent0:                 episode reward: -0.6282,                 loss: nan
agent1:                 episode reward: 0.6282,                 loss: 0.1158
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2374s / 112.7747 s
agent0:                 episode reward: -0.6967,                 loss: nan
agent1:                 episode reward: 0.6967,                 loss: 0.1152
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2722s / 113.0469 s
agent0:                 episode reward: -0.7495,                 loss: nan
agent1:                 episode reward: 0.7495,                 loss: 0.1145
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 113.3067 s
agent0:                 episode reward: -0.7086,                 loss: nan
agent1:                 episode reward: 0.7086,                 loss: 0.1148
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2370s / 113.5437 s
agent0:                 episode reward: -0.4207,                 loss: nan
agent1:                 episode reward: 0.4207,                 loss: 0.1144
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2463s / 113.7900 s
agent0:                 episode reward: -0.5655,                 loss: nan
agent1:                 episode reward: 0.5655,                 loss: 0.1145
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2325s / 114.0226 s
agent0:                 episode reward: -0.4175,                 loss: nan
agent1:                 episode reward: 0.4175,                 loss: 0.1149
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2257s / 114.2482 s
agent0:                 episode reward: -0.8275,                 loss: nan
agent1:                 episode reward: 0.8275,                 loss: 0.1142
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2214s / 114.4696 s
agent0:                 episode reward: -0.3639,                 loss: nan
agent1:                 episode reward: 0.3639,                 loss: 0.1136
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2219s / 114.6914 s
agent0:                 episode reward: -0.9113,                 loss: nan
agent1:                 episode reward: 0.9113,                 loss: 0.1150
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2233s / 114.9147 s
agent0:                 episode reward: -0.7704,                 loss: nan
agent1:                 episode reward: 0.7704,                 loss: 0.1134
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2213s / 115.1360 s
agent0:                 episode reward: -0.4678,                 loss: nan
agent1:                 episode reward: 0.4678,                 loss: 0.1123
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2412s / 115.3772 s
agent0:                 episode reward: -0.6025,                 loss: nan
agent1:                 episode reward: 0.6025,                 loss: 0.1143
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2773s / 115.6546 s
agent0:                 episode reward: -0.5640,                 loss: nan
agent1:                 episode reward: 0.5640,                 loss: 0.1153
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2568s / 115.9114 s
agent0:                 episode reward: -0.0954,                 loss: nan
agent1:                 episode reward: 0.0954,                 loss: 0.1137
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2613s / 116.1727 s
agent0:                 episode reward: -0.3780,                 loss: nan
agent1:                 episode reward: 0.3780,                 loss: 0.1132
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2461s / 116.4188 s
agent0:                 episode reward: -0.5750,                 loss: nan
agent1:                 episode reward: 0.5750,                 loss: 0.1126
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2289s / 116.6477 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.1120
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2265s / 116.8741 s
agent0:                 episode reward: -0.6907,                 loss: nan
agent1:                 episode reward: 0.6907,                 loss: 0.1126
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2255s / 117.0997 s
agent0:                 episode reward: -0.3593,                 loss: nan
agent1:                 episode reward: 0.3593,                 loss: 0.1106
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2371s / 117.3367 s
agent0:                 episode reward: -0.5084,                 loss: nan
agent1:                 episode reward: 0.5084,                 loss: 0.1141
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2367s / 117.5734 s
agent0:                 episode reward: -0.6038,                 loss: nan
agent1:                 episode reward: 0.6038,                 loss: 0.1123
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2353s / 117.8087 s
agent0:                 episode reward: -0.4742,                 loss: nan
agent1:                 episode reward: 0.4742,                 loss: 0.1130
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2358s / 118.0445 s
agent0:                 episode reward: -0.3026,                 loss: nan
agent1:                 episode reward: 0.3026,                 loss: 0.1132
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2404s / 118.2849 s
agent0:                 episode reward: -0.4693,                 loss: nan
agent1:                 episode reward: 0.4693,                 loss: 0.1125
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2460s / 118.5309 s
agent0:                 episode reward: -0.3420,                 loss: nan
agent1:                 episode reward: 0.3420,                 loss: 0.1117
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2390s / 118.7699 s
agent0:                 episode reward: -0.5783,                 loss: nan
agent1:                 episode reward: 0.5783,                 loss: 0.1125
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2736s / 119.0435 s
agent0:                 episode reward: -0.7897,                 loss: nan
agent1:                 episode reward: 0.7897,                 loss: 0.1133
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2614s / 119.3049 s
agent0:                 episode reward: -0.3120,                 loss: nan
agent1:                 episode reward: 0.3120,                 loss: 0.1117
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2382s / 119.5431 s
agent0:                 episode reward: -0.7591,                 loss: nan
agent1:                 episode reward: 0.7591,                 loss: 0.1132
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2408s / 119.7839 s
agent0:                 episode reward: -0.5087,                 loss: nan
agent1:                 episode reward: 0.5087,                 loss: 0.1122
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2344s / 120.0183 s
agent0:                 episode reward: -0.4035,                 loss: nan
agent1:                 episode reward: 0.4035,                 loss: 0.1120
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2343s / 120.2526 s
agent0:                 episode reward: -0.3021,                 loss: nan
agent1:                 episode reward: 0.3021,                 loss: 0.1120
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2297s / 120.4823 s
agent0:                 episode reward: -0.6894,                 loss: nan
agent1:                 episode reward: 0.6894,                 loss: 0.1129
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2319s / 120.7141 s
agent0:                 episode reward: -0.4537,                 loss: nan
agent1:                 episode reward: 0.4537,                 loss: 0.1129
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2329s / 120.9471 s
agent0:                 episode reward: -0.9276,                 loss: nan
agent1:                 episode reward: 0.9276,                 loss: 0.1123
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2375s / 121.1845 s
agent0:                 episode reward: -0.4928,                 loss: nan
agent1:                 episode reward: 0.4928,                 loss: 0.1120
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2452s / 121.4298 s
agent0:                 episode reward: -0.4091,                 loss: nan
agent1:                 episode reward: 0.4091,                 loss: 0.1126
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2458s / 121.6756 s
agent0:                 episode reward: -0.4724,                 loss: nan
agent1:                 episode reward: 0.4724,                 loss: 0.1120
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2454s / 121.9210 s
agent0:                 episode reward: -0.7201,                 loss: nan
agent1:                 episode reward: 0.7201,                 loss: 0.1119
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 122.1808 s
agent0:                 episode reward: -0.5063,                 loss: nan
agent1:                 episode reward: 0.5063,                 loss: 0.1125
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2426s / 122.4234 s
agent0:                 episode reward: -0.3765,                 loss: nan
agent1:                 episode reward: 0.3765,                 loss: 0.1129
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2354s / 122.6588 s
agent0:                 episode reward: -0.3039,                 loss: nan
agent1:                 episode reward: 0.3039,                 loss: 0.1122
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2381s / 122.8969 s
agent0:                 episode reward: -0.4063,                 loss: nan
agent1:                 episode reward: 0.4063,                 loss: 0.1125
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2498s / 123.1466 s
agent0:                 episode reward: -0.9495,                 loss: nan
agent1:                 episode reward: 0.9495,                 loss: 0.1128
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2369s / 123.3836 s
agent0:                 episode reward: -0.1463,                 loss: nan
agent1:                 episode reward: 0.1463,                 loss: 0.1117
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2396s / 123.6232 s
agent0:                 episode reward: -0.5055,                 loss: nan
agent1:                 episode reward: 0.5055,                 loss: 0.1124
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2498s / 123.8729 s
agent0:                 episode reward: -0.1368,                 loss: nan
agent1:                 episode reward: 0.1368,                 loss: 0.1132
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2311s / 124.1040 s
agent0:                 episode reward: -0.0344,                 loss: nan
agent1:                 episode reward: 0.0344,                 loss: 0.1122
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2299s / 124.3339 s
agent0:                 episode reward: -0.3847,                 loss: nan
agent1:                 episode reward: 0.3847,                 loss: 0.1127
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2302s / 124.5641 s
agent0:                 episode reward: -0.3359,                 loss: nan
agent1:                 episode reward: 0.3359,                 loss: 0.1133
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2304s / 124.7946 s
agent0:                 episode reward: -0.3709,                 loss: nan
agent1:                 episode reward: 0.3709,                 loss: 0.1138
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2305s / 125.0250 s
agent0:                 episode reward: -0.6220,                 loss: nan
agent1:                 episode reward: 0.6220,                 loss: 0.1131
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2616s / 125.2866 s
agent0:                 episode reward: -0.6916,                 loss: nan
agent1:                 episode reward: 0.6916,                 loss: 0.1113
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2376s / 125.5242 s
agent0:                 episode reward: -0.6433,                 loss: nan
agent1:                 episode reward: 0.6433,                 loss: 0.1122
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2377s / 125.7619 s
agent0:                 episode reward: -0.2845,                 loss: nan
agent1:                 episode reward: 0.2845,                 loss: 0.1115
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2362s / 125.9980 s
agent0:                 episode reward: -0.8037,                 loss: nan
agent1:                 episode reward: 0.8037,                 loss: 0.1139
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2316s / 126.2296 s
agent0:                 episode reward: -0.6136,                 loss: nan
agent1:                 episode reward: 0.6136,                 loss: 0.1116
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2331s / 126.4628 s
agent0:                 episode reward: -0.5242,                 loss: nan
agent1:                 episode reward: 0.5242,                 loss: 0.1116
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2446s / 126.7074 s
agent0:                 episode reward: -0.3644,                 loss: nan
agent1:                 episode reward: 0.3644,                 loss: 0.1111
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2404s / 126.9478 s
agent0:                 episode reward: -0.4645,                 loss: nan
agent1:                 episode reward: 0.4645,                 loss: 0.1122
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2435s / 127.1913 s
agent0:                 episode reward: -0.4431,                 loss: nan
agent1:                 episode reward: 0.4431,                 loss: 0.1121
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2509s / 127.4422 s
agent0:                 episode reward: -0.5764,                 loss: nan
agent1:                 episode reward: 0.5764,                 loss: 0.1104
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2430s / 127.6852 s
agent0:                 episode reward: -0.2506,                 loss: nan
agent1:                 episode reward: 0.2506,                 loss: 0.1127
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2396s / 127.9249 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.1110
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2474s / 128.1722 s
agent0:                 episode reward: -0.5610,                 loss: nan
agent1:                 episode reward: 0.5610,                 loss: 0.1124
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 128.4303 s
agent0:                 episode reward: -0.6983,                 loss: nan
agent1:                 episode reward: 0.6983,                 loss: 0.1130
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2390s / 128.6693 s
agent0:                 episode reward: -0.6385,                 loss: nan
agent1:                 episode reward: 0.6385,                 loss: 0.1135
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2375s / 128.9068 s
agent0:                 episode reward: -0.5140,                 loss: nan
agent1:                 episode reward: 0.5140,                 loss: 0.1127
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2364s / 129.1432 s
agent0:                 episode reward: -0.6199,                 loss: nan
agent1:                 episode reward: 0.6199,                 loss: 0.1126
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2360s / 129.3793 s
agent0:                 episode reward: -0.6117,                 loss: nan
agent1:                 episode reward: 0.6117,                 loss: 0.1144
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2437s / 129.6229 s
agent0:                 episode reward: -0.4255,                 loss: nan
agent1:                 episode reward: 0.4255,                 loss: 0.1129
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2382s / 129.8611 s
agent0:                 episode reward: -0.3693,                 loss: nan
agent1:                 episode reward: 0.3693,                 loss: 0.1136
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2445s / 130.1056 s
agent0:                 episode reward: -0.4625,                 loss: nan
agent1:                 episode reward: 0.4625,                 loss: 0.1125
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2481s / 130.3537 s
agent0:                 episode reward: -0.6806,                 loss: nan
agent1:                 episode reward: 0.6806,                 loss: 0.1123
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2481s / 130.6018 s
agent0:                 episode reward: -0.5645,                 loss: nan
agent1:                 episode reward: 0.5645,                 loss: 0.1128
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2471s / 130.8489 s
agent0:                 episode reward: -0.4688,                 loss: nan
agent1:                 episode reward: 0.4688,                 loss: 0.1116
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2432s / 131.0921 s
agent0:                 episode reward: -0.4127,                 loss: nan
agent1:                 episode reward: 0.4127,                 loss: 0.1101
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2654s / 131.3574 s
agent0:                 episode reward: -0.1826,                 loss: nan
agent1:                 episode reward: 0.1826,                 loss: 0.1128
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 131.6163 s
agent0:                 episode reward: -0.2577,                 loss: nan
agent1:                 episode reward: 0.2577,                 loss: 0.1116
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2511s / 131.8675 s
agent0:                 episode reward: -0.8739,                 loss: nan
agent1:                 episode reward: 0.8739,                 loss: 0.1125
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2664s / 132.1339 s
agent0:                 episode reward: -0.4624,                 loss: nan
agent1:                 episode reward: 0.4624,                 loss: 0.1112
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2420s / 132.3759 s
agent0:                 episode reward: -0.5834,                 loss: nan
agent1:                 episode reward: 0.5834,                 loss: 0.1120
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2396s / 132.6155 s
agent0:                 episode reward: -0.7414,                 loss: nan
agent1:                 episode reward: 0.7414,                 loss: 0.1118
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2426s / 132.8581 s
agent0:                 episode reward: -0.4842,                 loss: nan
agent1:                 episode reward: 0.4842,                 loss: 0.1125
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2437s / 133.1018 s
agent0:                 episode reward: -0.3399,                 loss: nan
agent1:                 episode reward: 0.3399,                 loss: 0.1129
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2455s / 133.3473 s
agent0:                 episode reward: -0.7189,                 loss: nan
agent1:                 episode reward: 0.7189,                 loss: 0.1126
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2411s / 133.5884 s
agent0:                 episode reward: -0.3708,                 loss: nan
agent1:                 episode reward: 0.3708,                 loss: 0.1120
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2438s / 133.8322 s
agent0:                 episode reward: -0.3506,                 loss: nan
agent1:                 episode reward: 0.3506,                 loss: 0.1134
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2449s / 134.0771 s
agent0:                 episode reward: -0.9766,                 loss: nan
agent1:                 episode reward: 0.9766,                 loss: 0.1117
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2903s / 134.3674 s
agent0:                 episode reward: -0.3046,                 loss: nan
agent1:                 episode reward: 0.3046,                 loss: 0.1124
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2622s / 134.6296 s
agent0:                 episode reward: 0.0616,                 loss: nan
agent1:                 episode reward: -0.0616,                 loss: 0.1110
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2441s / 134.8737 s
agent0:                 episode reward: -0.7540,                 loss: nan
agent1:                 episode reward: 0.7540,                 loss: 0.1125
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2463s / 135.1200 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: 0.1128
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2427s / 135.3627 s
agent0:                 episode reward: -0.3974,                 loss: nan
agent1:                 episode reward: 0.3974,                 loss: 0.1131
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2543s / 135.6170 s
agent0:                 episode reward: -0.4944,                 loss: nan
agent1:                 episode reward: 0.4944,                 loss: 0.1119
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2444s / 135.8614 s
agent0:                 episode reward: -0.2722,                 loss: nan
agent1:                 episode reward: 0.2722,                 loss: 0.1119
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2392s / 136.1006 s
agent0:                 episode reward: -0.6527,                 loss: nan
agent1:                 episode reward: 0.6527,                 loss: 0.1120
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2350s / 136.3356 s
agent0:                 episode reward: -0.6819,                 loss: nan
agent1:                 episode reward: 0.6819,                 loss: 0.1126
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2439s / 136.5796 s
agent0:                 episode reward: -0.5409,                 loss: nan
agent1:                 episode reward: 0.5409,                 loss: 0.1118
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2401s / 136.8197 s
agent0:                 episode reward: -0.5554,                 loss: nan
agent1:                 episode reward: 0.5554,                 loss: 0.1101
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2499s / 137.0695 s
agent0:                 episode reward: -0.4561,                 loss: nan
agent1:                 episode reward: 0.4561,                 loss: 0.1120
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2612s / 137.3307 s
agent0:                 episode reward: 0.0104,                 loss: nan
agent1:                 episode reward: -0.0104,                 loss: 0.1129
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2592s / 137.5899 s
agent0:                 episode reward: -0.8179,                 loss: nan
agent1:                 episode reward: 0.8179,                 loss: 0.1117
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2421s / 137.8321 s
agent0:                 episode reward: -0.5242,                 loss: nan
agent1:                 episode reward: 0.5242,                 loss: 0.1119
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2440s / 138.0761 s
agent0:                 episode reward: -0.5004,                 loss: nan
agent1:                 episode reward: 0.5004,                 loss: 0.1125
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2336s / 138.3096 s
agent0:                 episode reward: -0.6711,                 loss: nan
agent1:                 episode reward: 0.6711,                 loss: 0.1115
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2321s / 138.5417 s
agent0:                 episode reward: -0.7085,                 loss: nan
agent1:                 episode reward: 0.7085,                 loss: 0.1101
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2360s / 138.7777 s
agent0:                 episode reward: -0.3933,                 loss: nan
agent1:                 episode reward: 0.3933,                 loss: 0.1129
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2333s / 139.0110 s
agent0:                 episode reward: -0.8079,                 loss: nan
agent1:                 episode reward: 0.8079,                 loss: 0.1112
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2385s / 139.2495 s
agent0:                 episode reward: -0.8336,                 loss: nan
agent1:                 episode reward: 0.8336,                 loss: 0.1108
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2459s / 139.4954 s
agent0:                 episode reward: -0.8494,                 loss: nan
agent1:                 episode reward: 0.8494,                 loss: 0.1116
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2506s / 139.7460 s
agent0:                 episode reward: -0.6328,                 loss: nan
agent1:                 episode reward: 0.6328,                 loss: 0.1118
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2535s / 139.9995 s
agent0:                 episode reward: -0.8888,                 loss: nan
agent1:                 episode reward: 0.8888,                 loss: 0.1127
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 140.2564 s
agent0:                 episode reward: -0.7135,                 loss: nan
agent1:                 episode reward: 0.7135,                 loss: 0.1104
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2894s / 140.5458 s
agent0:                 episode reward: -0.9938,                 loss: nan
agent1:                 episode reward: 0.9938,                 loss: 0.1128
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2402s / 140.7860 s
agent0:                 episode reward: -0.5150,                 loss: nan
agent1:                 episode reward: 0.5150,                 loss: 0.1113
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2315s / 141.0175 s
agent0:                 episode reward: -0.5472,                 loss: nan
agent1:                 episode reward: 0.5472,                 loss: 0.1137
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2324s / 141.2498 s
agent0:                 episode reward: -0.5551,                 loss: nan
agent1:                 episode reward: 0.5551,                 loss: 0.1118
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2419s / 141.4917 s
agent0:                 episode reward: -0.5845,                 loss: nan
agent1:                 episode reward: 0.5845,                 loss: 0.1131
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2449s / 141.7366 s
agent0:                 episode reward: -0.5591,                 loss: nan
agent1:                 episode reward: 0.5591,                 loss: 0.1126
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2533s / 141.9900 s
agent0:                 episode reward: -0.6611,                 loss: nan
agent1:                 episode reward: 0.6611,                 loss: 0.1133
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2524s / 142.2424 s
agent0:                 episode reward: -0.5415,                 loss: nan
agent1:                 episode reward: 0.5415,                 loss: 0.1136
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2535s / 142.4960 s
agent0:                 episode reward: -0.7522,                 loss: nan
agent1:                 episode reward: 0.7522,                 loss: 0.1112
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2549s / 142.7509 s
agent0:                 episode reward: -0.2833,                 loss: nan
agent1:                 episode reward: 0.2833,                 loss: 0.1125
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2478s / 142.9987 s
agent0:                 episode reward: -0.6980,                 loss: nan
agent1:                 episode reward: 0.6980,                 loss: 0.1131
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2375s / 143.2362 s
agent0:                 episode reward: -0.7199,                 loss: nan
agent1:                 episode reward: 0.7199,                 loss: 0.1126
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2538s / 143.4900 s
agent0:                 episode reward: -0.1747,                 loss: nan
agent1:                 episode reward: 0.1747,                 loss: 0.1120
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 143.7562 s
agent0:                 episode reward: -0.1400,                 loss: nan
agent1:                 episode reward: 0.1400,                 loss: 0.1098
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2472s / 144.0034 s
agent0:                 episode reward: -0.8513,                 loss: nan
agent1:                 episode reward: 0.8513,                 loss: 0.1120
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2450s / 144.2484 s
agent0:                 episode reward: -0.5747,                 loss: nan
agent1:                 episode reward: 0.5747,                 loss: 0.1130
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2496s / 144.4979 s
agent0:                 episode reward: -0.7635,                 loss: nan
agent1:                 episode reward: 0.7635,                 loss: 0.1116
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2513s / 144.7492 s
agent0:                 episode reward: -0.6742,                 loss: nan
agent1:                 episode reward: 0.6742,                 loss: 0.1114
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2657s / 145.0149 s
agent0:                 episode reward: -0.5647,                 loss: nan
agent1:                 episode reward: 0.5647,                 loss: 0.1122
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 145.2780 s
agent0:                 episode reward: -0.4864,                 loss: nan
agent1:                 episode reward: 0.4864,                 loss: 0.1126
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2643s / 145.5423 s
agent0:                 episode reward: -0.6874,                 loss: nan
agent1:                 episode reward: 0.6874,                 loss: 0.1138
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2624s / 145.8048 s
agent0:                 episode reward: -0.2903,                 loss: nan
agent1:                 episode reward: 0.2903,                 loss: 0.1129
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2647s / 146.0695 s
agent0:                 episode reward: -0.4783,                 loss: nan
agent1:                 episode reward: 0.4783,                 loss: 0.1117
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2746s / 146.3441 s
agent0:                 episode reward: -0.6424,                 loss: nan
agent1:                 episode reward: 0.6424,                 loss: 0.1116
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2652s / 146.6093 s
agent0:                 episode reward: -0.7626,                 loss: nan
agent1:                 episode reward: 0.7626,                 loss: 0.1132
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2470s / 146.8563 s
agent0:                 episode reward: -0.6282,                 loss: nan
agent1:                 episode reward: 0.6282,                 loss: 0.1106
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2426s / 147.0989 s
agent0:                 episode reward: -0.6549,                 loss: nan
agent1:                 episode reward: 0.6549,                 loss: 0.1125
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2518s / 147.3506 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.1112
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2496s / 147.6003 s
agent0:                 episode reward: -0.5940,                 loss: nan
agent1:                 episode reward: 0.5940,                 loss: 0.1131
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2536s / 147.8539 s
agent0:                 episode reward: -0.5183,                 loss: nan
agent1:                 episode reward: 0.5183,                 loss: 0.1126
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2542s / 148.1081 s
agent0:                 episode reward: -0.7118,                 loss: nan
agent1:                 episode reward: 0.7118,                 loss: 0.1118
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2517s / 148.3598 s
agent0:                 episode reward: -0.6573,                 loss: nan
agent1:                 episode reward: 0.6573,                 loss: 0.1113
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 148.6167 s
agent0:                 episode reward: -0.8319,                 loss: nan
agent1:                 episode reward: 0.8319,                 loss: 0.1120
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2630s / 148.8797 s
agent0:                 episode reward: -0.7251,                 loss: nan
agent1:                 episode reward: 0.7251,                 loss: 0.1121
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2438s / 149.1235 s
agent0:                 episode reward: -0.4148,                 loss: nan
agent1:                 episode reward: 0.4148,                 loss: 0.1109
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2725s / 149.3960 s
agent0:                 episode reward: -0.4288,                 loss: nan
agent1:                 episode reward: 0.4288,                 loss: 0.1110
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2654s / 149.6614 s
agent0:                 episode reward: -0.5254,                 loss: nan
agent1:                 episode reward: 0.5254,                 loss: 0.1126
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2566s / 149.9179 s
agent0:                 episode reward: -0.9204,                 loss: nan
agent1:                 episode reward: 0.9204,                 loss: 0.1107
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2540s / 150.1720 s
agent0:                 episode reward: -0.3441,                 loss: nan
agent1:                 episode reward: 0.3441,                 loss: 0.1098
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2550s / 150.4269 s
agent0:                 episode reward: -0.1144,                 loss: nan
agent1:                 episode reward: 0.1144,                 loss: 0.1113
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2528s / 150.6797 s
agent0:                 episode reward: -0.5703,                 loss: nan
agent1:                 episode reward: 0.5703,                 loss: 0.1115
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2497s / 150.9295 s
agent0:                 episode reward: -0.6501,                 loss: nan
agent1:                 episode reward: 0.6501,                 loss: 0.1107
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2524s / 151.1819 s
agent0:                 episode reward: -0.3764,                 loss: nan
agent1:                 episode reward: 0.3764,                 loss: 0.1110
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2559s / 151.4378 s
agent0:                 episode reward: -0.5601,                 loss: nan
agent1:                 episode reward: 0.5601,                 loss: 0.1102
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 151.6939 s
agent0:                 episode reward: -0.5090,                 loss: nan
agent1:                 episode reward: 0.5090,                 loss: 0.1104
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 151.9445 s
agent0:                 episode reward: -0.7518,                 loss: nan
agent1:                 episode reward: 0.7518,                 loss: 0.1116
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2371s / 152.1816 s
agent0:                 episode reward: -0.8543,                 loss: nan
agent1:                 episode reward: 0.8543,                 loss: 0.1119
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2655s / 152.4470 s
agent0:                 episode reward: -0.8854,                 loss: nan
agent1:                 episode reward: 0.8854,                 loss: 0.1122
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2863s / 152.7333 s
agent0:                 episode reward: -0.4136,                 loss: nan
agent1:                 episode reward: 0.4136,                 loss: 0.1112
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2597s / 152.9931 s
agent0:                 episode reward: -0.6172,                 loss: nan
agent1:                 episode reward: 0.6172,                 loss: 0.1111
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2696s / 153.2626 s
agent0:                 episode reward: -0.6112,                 loss: nan
agent1:                 episode reward: 0.6112,                 loss: 0.1113
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2753s / 153.5379 s
agent0:                 episode reward: -1.0010,                 loss: nan
agent1:                 episode reward: 1.0010,                 loss: 0.1105
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2655s / 153.8034 s
agent0:                 episode reward: -0.7841,                 loss: nan
agent1:                 episode reward: 0.7841,                 loss: 0.1106
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2625s / 154.0659 s
agent0:                 episode reward: -0.7034,                 loss: nan
agent1:                 episode reward: 0.7034,                 loss: 0.1104
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2612s / 154.3272 s
agent0:                 episode reward: -0.3893,                 loss: nan
agent1:                 episode reward: 0.3893,                 loss: 0.1108
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2576s / 154.5848 s
agent0:                 episode reward: -0.3894,                 loss: nan
agent1:                 episode reward: 0.3894,                 loss: 0.1102
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2650s / 154.8498 s
agent0:                 episode reward: -0.6568,                 loss: nan
agent1:                 episode reward: 0.6568,                 loss: 0.1122
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2605s / 155.1104 s
agent0:                 episode reward: -0.7023,                 loss: nan
agent1:                 episode reward: 0.7023,                 loss: 0.1106
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 155.3824 s
agent0:                 episode reward: -0.4714,                 loss: nan
agent1:                 episode reward: 0.4714,                 loss: 0.1105
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2666s / 155.6490 s
agent0:                 episode reward: -0.5153,                 loss: nan
agent1:                 episode reward: 0.5153,                 loss: 0.1106
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2555s / 155.9045 s
agent0:                 episode reward: -0.7538,                 loss: nan
agent1:                 episode reward: 0.7538,                 loss: 0.1112
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2512s / 156.1557 s
agent0:                 episode reward: -0.2989,                 loss: nan
agent1:                 episode reward: 0.2989,                 loss: 0.1115
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2645s / 156.4202 s
agent0:                 episode reward: -0.7979,                 loss: nan
agent1:                 episode reward: 0.7979,                 loss: 0.1118
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2592s / 156.6795 s
agent0:                 episode reward: -0.2895,                 loss: nan
agent1:                 episode reward: 0.2895,                 loss: 0.1097
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2588s / 156.9383 s
agent0:                 episode reward: -0.4949,                 loss: nan
agent1:                 episode reward: 0.4949,                 loss: 0.1115
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2792s / 157.2175 s
agent0:                 episode reward: -0.6476,                 loss: nan
agent1:                 episode reward: 0.6476,                 loss: 0.1095
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2675s / 157.4849 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.1108
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2587s / 157.7436 s
agent0:                 episode reward: -0.3326,                 loss: nan
agent1:                 episode reward: 0.3326,                 loss: 0.1107
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2551s / 157.9987 s
agent0:                 episode reward: -0.4834,                 loss: nan
agent1:                 episode reward: 0.4834,                 loss: 0.1101
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2547s / 158.2534 s
agent0:                 episode reward: -0.5940,                 loss: nan
agent1:                 episode reward: 0.5940,                 loss: 0.1103
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2647s / 158.5181 s
agent0:                 episode reward: -0.5152,                 loss: nan
agent1:                 episode reward: 0.5152,                 loss: 0.1091
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2683s / 158.7864 s
agent0:                 episode reward: -0.8206,                 loss: nan
agent1:                 episode reward: 0.8206,                 loss: 0.1117
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2506s / 159.0369 s
agent0:                 episode reward: -0.4218,                 loss: nan
agent1:                 episode reward: 0.4218,                 loss: 0.1096
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 159.2843 s
agent0:                 episode reward: -0.5754,                 loss: nan
agent1:                 episode reward: 0.5754,                 loss: 0.1101
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2562s / 159.5405 s
agent0:                 episode reward: -0.6693,                 loss: nan
agent1:                 episode reward: 0.6693,                 loss: 0.1127
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2626s / 159.8031 s
agent0:                 episode reward: -0.5849,                 loss: nan
agent1:                 episode reward: 0.5849,                 loss: 0.1100
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2517s / 160.0549 s
agent0:                 episode reward: -0.6997,                 loss: nan
agent1:                 episode reward: 0.6997,                 loss: 0.1098
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2461s / 160.3010 s
agent0:                 episode reward: -0.6733,                 loss: nan
agent1:                 episode reward: 0.6733,                 loss: 0.1106
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 160.5590 s
agent0:                 episode reward: -0.5277,                 loss: nan
agent1:                 episode reward: 0.5277,                 loss: 0.1109
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2529s / 160.8119 s
agent0:                 episode reward: -0.0208,                 loss: nan
agent1:                 episode reward: 0.0208,                 loss: 0.1110
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 161.0680 s
agent0:                 episode reward: -0.6905,                 loss: nan
agent1:                 episode reward: 0.6905,                 loss: 0.1121
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2427s / 161.3107 s
agent0:                 episode reward: -0.3535,                 loss: nan
agent1:                 episode reward: 0.3535,                 loss: 0.1118
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2583s / 161.5690 s
agent0:                 episode reward: -0.3983,                 loss: nan
agent1:                 episode reward: 0.3983,                 loss: 0.1111
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2644s / 161.8334 s
agent0:                 episode reward: -0.5520,                 loss: nan
agent1:                 episode reward: 0.5520,                 loss: 0.1103
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 162.0932 s
agent0:                 episode reward: -0.3126,                 loss: nan
agent1:                 episode reward: 0.3126,                 loss: 0.1118
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2630s / 162.3561 s
agent0:                 episode reward: -0.4749,                 loss: nan
agent1:                 episode reward: 0.4749,                 loss: 0.1119
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3040s / 162.6601 s
agent0:                 episode reward: -0.7863,                 loss: nan
agent1:                 episode reward: 0.7863,                 loss: 0.1127
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2622s / 162.9223 s
agent0:                 episode reward: -0.4423,                 loss: nan
agent1:                 episode reward: 0.4423,                 loss: 0.1123
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2685s / 163.1908 s
agent0:                 episode reward: -1.0307,                 loss: nan
agent1:                 episode reward: 1.0307,                 loss: 0.1107
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2880s / 163.4789 s
agent0:                 episode reward: -0.5502,                 loss: nan
agent1:                 episode reward: 0.5502,                 loss: 0.1124
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2778s / 163.7567 s
agent0:                 episode reward: -0.8196,                 loss: nan
agent1:                 episode reward: 0.8196,                 loss: 0.1114
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 164.0155 s
agent0:                 episode reward: -0.2153,                 loss: nan
agent1:                 episode reward: 0.2153,                 loss: 0.1105
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2567s / 164.2722 s
agent0:                 episode reward: 0.0129,                 loss: nan
agent1:                 episode reward: -0.0129,                 loss: 0.1113
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2463s / 164.5185 s
agent0:                 episode reward: -0.7774,                 loss: nan
agent1:                 episode reward: 0.7774,                 loss: 0.1121
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2705s / 164.7891 s
agent0:                 episode reward: -0.5775,                 loss: nan
agent1:                 episode reward: 0.5775,                 loss: 0.1109
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2540s / 165.0431 s
agent0:                 episode reward: -0.5348,                 loss: nan
agent1:                 episode reward: 0.5348,                 loss: 0.1114
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2442s / 165.2873 s
agent0:                 episode reward: -0.4598,                 loss: nan
agent1:                 episode reward: 0.4598,                 loss: 0.1124
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2679s / 165.5552 s
agent0:                 episode reward: -0.3443,                 loss: nan
agent1:                 episode reward: 0.3443,                 loss: 0.1127
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2728s / 165.8280 s
agent0:                 episode reward: -0.4001,                 loss: nan
agent1:                 episode reward: 0.4001,                 loss: 0.1121
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2719s / 166.0999 s
agent0:                 episode reward: -0.7172,                 loss: nan
agent1:                 episode reward: 0.7172,                 loss: 0.1105
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2533s / 166.3533 s
agent0:                 episode reward: -0.8150,                 loss: nan
agent1:                 episode reward: 0.8150,                 loss: 0.1109
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2594s / 166.6126 s
agent0:                 episode reward: -0.6086,                 loss: nan
agent1:                 episode reward: 0.6086,                 loss: 0.1101
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2623s / 166.8749 s
agent0:                 episode reward: -0.2533,                 loss: nan
agent1:                 episode reward: 0.2533,                 loss: 0.1110
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2560s / 167.1309 s
agent0:                 episode reward: -0.5995,                 loss: nan
agent1:                 episode reward: 0.5995,                 loss: 0.1101
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 167.3920 s
agent0:                 episode reward: -0.8889,                 loss: nan
agent1:                 episode reward: 0.8889,                 loss: 0.1111
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2685s / 167.6605 s
agent0:                 episode reward: -0.4730,                 loss: nan
agent1:                 episode reward: 0.4730,                 loss: 0.1092
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2713s / 167.9318 s
agent0:                 episode reward: -0.3478,                 loss: nan
agent1:                 episode reward: 0.3478,                 loss: 0.1110
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 168.1908 s
agent0:                 episode reward: -0.7812,                 loss: nan
agent1:                 episode reward: 0.7812,                 loss: 0.1117
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2551s / 168.4458 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.1104
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2540s / 168.6999 s
agent0:                 episode reward: -0.4078,                 loss: nan
agent1:                 episode reward: 0.4078,                 loss: 0.1113
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2665s / 168.9663 s
agent0:                 episode reward: -0.4793,                 loss: nan
agent1:                 episode reward: 0.4793,                 loss: 0.1112
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2628s / 169.2292 s
agent0:                 episode reward: -0.4426,                 loss: nan
agent1:                 episode reward: 0.4426,                 loss: 0.1101
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 169.4872 s
agent0:                 episode reward: -0.5412,                 loss: nan
agent1:                 episode reward: 0.5412,                 loss: 0.1104
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2573s / 169.7444 s
agent0:                 episode reward: -0.6238,                 loss: nan
agent1:                 episode reward: 0.6238,                 loss: 0.1105
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2557s / 170.0001 s
agent0:                 episode reward: -0.3924,                 loss: nan
agent1:                 episode reward: 0.3924,                 loss: 0.1101
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2602s / 170.2604 s
agent0:                 episode reward: -0.5963,                 loss: nan
agent1:                 episode reward: 0.5963,                 loss: 0.1110
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 170.5265 s
agent0:                 episode reward: -0.7595,                 loss: nan
agent1:                 episode reward: 0.7595,                 loss: 0.1103
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2830s / 170.8095 s
agent0:                 episode reward: -0.6022,                 loss: nan
agent1:                 episode reward: 0.6022,                 loss: 0.1100
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2794s / 171.0889 s
agent0:                 episode reward: -0.6117,                 loss: nan
agent1:                 episode reward: 0.6117,                 loss: 0.1108
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2620s / 171.3509 s
agent0:                 episode reward: -0.2671,                 loss: nan
agent1:                 episode reward: 0.2671,                 loss: 0.1109
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2664s / 171.6173 s
agent0:                 episode reward: -0.4469,                 loss: nan
agent1:                 episode reward: 0.4469,                 loss: 0.1090
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2666s / 171.8839 s
agent0:                 episode reward: -0.2101,                 loss: nan
agent1:                 episode reward: 0.2101,                 loss: 0.1098
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2694s / 172.1534 s
agent0:                 episode reward: -0.6676,                 loss: nan
agent1:                 episode reward: 0.6676,                 loss: 0.1104
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2724s / 172.4257 s
agent0:                 episode reward: -1.1065,                 loss: nan
agent1:                 episode reward: 1.1065,                 loss: 0.1115
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2608s / 172.6865 s
agent0:                 episode reward: -0.2440,                 loss: nan
agent1:                 episode reward: 0.2440,                 loss: 0.1096
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2678s / 172.9544 s
agent0:                 episode reward: -0.2887,                 loss: nan
agent1:                 episode reward: 0.2887,                 loss: 0.1113
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2630s / 173.2173 s
agent0:                 episode reward: -0.4834,                 loss: nan
agent1:                 episode reward: 0.4834,                 loss: 0.1107
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2609s / 173.4782 s
agent0:                 episode reward: -0.2387,                 loss: nan
agent1:                 episode reward: 0.2387,                 loss: 0.1110
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3012s / 173.7795 s
agent0:                 episode reward: -0.4731,                 loss: nan
agent1:                 episode reward: 0.4731,                 loss: 0.1104
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2723s / 174.0518 s
agent0:                 episode reward: -0.8156,                 loss: nan
agent1:                 episode reward: 0.8156,                 loss: 0.1098
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2503s / 174.3022 s
agent0:                 episode reward: -0.8693,                 loss: nan
agent1:                 episode reward: 0.8693,                 loss: 0.1110
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2490s / 174.5512 s
agent0:                 episode reward: -0.5421,                 loss: nan
agent1:                 episode reward: 0.5421,                 loss: 0.1099
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2525s / 174.8037 s
agent0:                 episode reward: -0.1266,                 loss: nan
agent1:                 episode reward: 0.1266,                 loss: 0.1106
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2508s / 175.0545 s
agent0:                 episode reward: -0.7328,                 loss: nan
agent1:                 episode reward: 0.7328,                 loss: 0.1095
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2545s / 175.3090 s
agent0:                 episode reward: -0.6316,                 loss: nan
agent1:                 episode reward: 0.6316,                 loss: 0.1097
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2592s / 175.5681 s
agent0:                 episode reward: -0.7685,                 loss: nan
agent1:                 episode reward: 0.7685,                 loss: 0.1081
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2600s / 175.8281 s
agent0:                 episode reward: -0.8815,                 loss: nan
agent1:                 episode reward: 0.8815,                 loss: 0.1088
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2564s / 176.0845 s
agent0:                 episode reward: -0.7313,                 loss: nan
agent1:                 episode reward: 0.7313,                 loss: 0.1087
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2582s / 176.3428 s
agent0:                 episode reward: -0.3951,                 loss: nan
agent1:                 episode reward: 0.3951,                 loss: 0.1093
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2648s / 176.6076 s
agent0:                 episode reward: -0.5504,                 loss: nan
agent1:                 episode reward: 0.5504,                 loss: 0.1106
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2832s / 176.8909 s
agent0:                 episode reward: -0.8491,                 loss: nan
agent1:                 episode reward: 0.8491,                 loss: 0.1103
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2791s / 177.1699 s
agent0:                 episode reward: -0.4557,                 loss: nan
agent1:                 episode reward: 0.4557,                 loss: 0.1093
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2659s / 177.4358 s
agent0:                 episode reward: -0.4627,                 loss: nan
agent1:                 episode reward: 0.4627,                 loss: 0.1102
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2633s / 177.6991 s
agent0:                 episode reward: -0.5682,                 loss: nan
agent1:                 episode reward: 0.5682,                 loss: 0.1100
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2637s / 177.9628 s
agent0:                 episode reward: -0.5595,                 loss: nan
agent1:                 episode reward: 0.5595,                 loss: 0.1092
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 178.2259 s
agent0:                 episode reward: -0.8116,                 loss: nan
agent1:                 episode reward: 0.8116,                 loss: 0.1093
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2664s / 178.4923 s
agent0:                 episode reward: -0.4849,                 loss: nan
agent1:                 episode reward: 0.4849,                 loss: 0.1102
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2791s / 178.7714 s
agent0:                 episode reward: -0.7137,                 loss: nan
agent1:                 episode reward: 0.7137,                 loss: 0.1101
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2793s / 179.0508 s
agent0:                 episode reward: -0.4294,                 loss: nan
agent1:                 episode reward: 0.4294,                 loss: 0.1108
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2745s / 179.3252 s
agent0:                 episode reward: -0.4539,                 loss: nan
agent1:                 episode reward: 0.4539,                 loss: 0.1096
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2739s / 179.5991 s
agent0:                 episode reward: -0.7711,                 loss: nan
agent1:                 episode reward: 0.7711,                 loss: 0.1107
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2753s / 179.8744 s
agent0:                 episode reward: -0.5155,                 loss: nan
agent1:                 episode reward: 0.5155,                 loss: 0.1094
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2921s / 180.1665 s
agent0:                 episode reward: -0.6009,                 loss: nan
agent1:                 episode reward: 0.6009,                 loss: 0.1094
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2680s / 180.4345 s
agent0:                 episode reward: -0.6830,                 loss: nan
agent1:                 episode reward: 0.6830,                 loss: 0.1117
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 180.7006 s
agent0:                 episode reward: -0.7066,                 loss: nan
agent1:                 episode reward: 0.7066,                 loss: 0.1076
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2651s / 180.9657 s
agent0:                 episode reward: -0.6460,                 loss: nan
agent1:                 episode reward: 0.6460,                 loss: 0.1096
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2660s / 181.2317 s
agent0:                 episode reward: -0.5476,                 loss: nan
agent1:                 episode reward: 0.5476,                 loss: 0.1082
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2665s / 181.4983 s
agent0:                 episode reward: -0.5851,                 loss: nan
agent1:                 episode reward: 0.5851,                 loss: 0.1069
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 181.7623 s
agent0:                 episode reward: -0.5301,                 loss: nan
agent1:                 episode reward: 0.5301,                 loss: 0.1089
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2683s / 182.0306 s
agent0:                 episode reward: -0.4700,                 loss: nan
agent1:                 episode reward: 0.4700,                 loss: 0.1088
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2902s / 182.3208 s
agent0:                 episode reward: -0.5386,                 loss: nan
agent1:                 episode reward: 0.5386,                 loss: 0.1089
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2669s / 182.5877 s
agent0:                 episode reward: -0.6497,                 loss: nan
agent1:                 episode reward: 0.6497,                 loss: 0.1089
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2656s / 182.8532 s
agent0:                 episode reward: -0.6113,                 loss: nan
agent1:                 episode reward: 0.6113,                 loss: 0.1092
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2905s / 183.1437 s
agent0:                 episode reward: -0.3968,                 loss: nan
agent1:                 episode reward: 0.3968,                 loss: 0.1084
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2735s / 183.4172 s
agent0:                 episode reward: -0.5704,                 loss: nan
agent1:                 episode reward: 0.5704,                 loss: 0.1079
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2733s / 183.6905 s
agent0:                 episode reward: -0.3981,                 loss: nan
agent1:                 episode reward: 0.3981,                 loss: 0.1085
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 183.9545 s
agent0:                 episode reward: -0.3065,                 loss: nan
agent1:                 episode reward: 0.3065,                 loss: 0.1088
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2696s / 184.2241 s
agent0:                 episode reward: -0.5234,                 loss: nan
agent1:                 episode reward: 0.5234,                 loss: 0.1088
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2761s / 184.5002 s
agent0:                 episode reward: -0.6905,                 loss: nan
agent1:                 episode reward: 0.6905,                 loss: 0.1084
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2939s / 184.7942 s
agent0:                 episode reward: -0.7289,                 loss: nan
agent1:                 episode reward: 0.7289,                 loss: 0.1090
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3001s / 185.0942 s
agent0:                 episode reward: -0.3561,                 loss: nan
agent1:                 episode reward: 0.3561,                 loss: 0.1094
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2576s / 185.3518 s
agent0:                 episode reward: -0.4873,                 loss: nan
agent1:                 episode reward: 0.4873,                 loss: 0.1085
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2641s / 185.6159 s
agent0:                 episode reward: -0.5080,                 loss: nan
agent1:                 episode reward: 0.5080,                 loss: 0.1079
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2559s / 185.8718 s
agent0:                 episode reward: -0.2220,                 loss: nan
agent1:                 episode reward: 0.2220,                 loss: 0.1084
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2836s / 186.1553 s
agent0:                 episode reward: -0.3379,                 loss: nan
agent1:                 episode reward: 0.3379,                 loss: 0.1092
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2753s / 186.4306 s
agent0:                 episode reward: -0.4896,                 loss: nan
agent1:                 episode reward: 0.4896,                 loss: 0.1081
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2658s / 186.6964 s
agent0:                 episode reward: -0.4785,                 loss: nan
agent1:                 episode reward: 0.4785,                 loss: 0.1082
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 186.9775 s
agent0:                 episode reward: -0.6603,                 loss: nan
agent1:                 episode reward: 0.6603,                 loss: 0.1090
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2622s / 187.2397 s
agent0:                 episode reward: -0.6560,                 loss: nan
agent1:                 episode reward: 0.6560,                 loss: 0.1095
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2563s / 187.4960 s
agent0:                 episode reward: -0.4100,                 loss: nan
agent1:                 episode reward: 0.4100,                 loss: 0.1086
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 187.7522 s
agent0:                 episode reward: -0.2571,                 loss: nan
agent1:                 episode reward: 0.2571,                 loss: 0.1092
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2679s / 188.0201 s
agent0:                 episode reward: -0.2883,                 loss: nan
agent1:                 episode reward: 0.2883,                 loss: 0.1096
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2730s / 188.2931 s
agent0:                 episode reward: -0.4019,                 loss: nan
agent1:                 episode reward: 0.4019,                 loss: 0.1076
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2708s / 188.5639 s
agent0:                 episode reward: -0.8929,                 loss: nan
agent1:                 episode reward: 0.8929,                 loss: 0.1088
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2733s / 188.8372 s
agent0:                 episode reward: -0.6805,                 loss: nan
agent1:                 episode reward: 0.6805,                 loss: 0.1104
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2793s / 189.1165 s
agent0:                 episode reward: -1.0200,                 loss: nan
agent1:                 episode reward: 1.0200,                 loss: 0.1079
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2998s / 189.4163 s
agent0:                 episode reward: -0.6205,                 loss: nan
agent1:                 episode reward: 0.6205,                 loss: 0.1115
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2742s / 189.6905 s
agent0:                 episode reward: -0.7116,                 loss: nan
agent1:                 episode reward: 0.7116,                 loss: 0.1093
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2634s / 189.9539 s
agent0:                 episode reward: -0.3501,                 loss: nan
agent1:                 episode reward: 0.3501,                 loss: 0.1091
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2636s / 190.2175 s
agent0:                 episode reward: -0.6058,                 loss: nan
agent1:                 episode reward: 0.6058,                 loss: 0.1093
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 190.5035 s
agent0:                 episode reward: -0.7259,                 loss: nan
agent1:                 episode reward: 0.7259,                 loss: 0.1099
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2701s / 190.7736 s
agent0:                 episode reward: -0.5657,                 loss: nan
agent1:                 episode reward: 0.5657,                 loss: 0.1095
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2573s / 191.0310 s
agent0:                 episode reward: -0.1856,                 loss: nan
agent1:                 episode reward: 0.1856,                 loss: 0.1079
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2608s / 191.2918 s
agent0:                 episode reward: -0.5492,                 loss: nan
agent1:                 episode reward: 0.5492,                 loss: 0.1085
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 191.5516 s
agent0:                 episode reward: -0.2628,                 loss: nan
agent1:                 episode reward: 0.2628,                 loss: 0.1090
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 191.8101 s
agent0:                 episode reward: -0.8371,                 loss: nan
agent1:                 episode reward: 0.8371,                 loss: 0.1096
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2623s / 192.0725 s
agent0:                 episode reward: -0.3955,                 loss: nan
agent1:                 episode reward: 0.3955,                 loss: 0.1088
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3044s / 192.3769 s
agent0:                 episode reward: -0.3164,                 loss: nan
agent1:                 episode reward: 0.3164,                 loss: 0.1094
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2714s / 192.6483 s
agent0:                 episode reward: -0.6051,                 loss: nan
agent1:                 episode reward: 0.6051,                 loss: 0.1069
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2638s / 192.9121 s
agent0:                 episode reward: -0.5456,                 loss: nan
agent1:                 episode reward: 0.5456,                 loss: 0.1088
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 193.1720 s
agent0:                 episode reward: -0.3145,                 loss: nan
agent1:                 episode reward: 0.3145,                 loss: 0.1085
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2621s / 193.4341 s
agent0:                 episode reward: -0.6309,                 loss: nan
agent1:                 episode reward: 0.6309,                 loss: 0.1089
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2597s / 193.6938 s
agent0:                 episode reward: -0.4004,                 loss: nan
agent1:                 episode reward: 0.4004,                 loss: 0.1084
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 193.9536 s
agent0:                 episode reward: -0.6240,                 loss: nan
agent1:                 episode reward: 0.6240,                 loss: 0.1090
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2594s / 194.2130 s
agent0:                 episode reward: -0.6241,                 loss: nan
agent1:                 episode reward: 0.6241,                 loss: 0.1088
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2595s / 194.4725 s
agent0:                 episode reward: -0.5852,                 loss: nan
agent1:                 episode reward: 0.5852,                 loss: 0.1093
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2640s / 194.7365 s
agent0:                 episode reward: -0.5839,                 loss: nan
agent1:                 episode reward: 0.5839,                 loss: 0.1091
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2679s / 195.0044 s
agent0:                 episode reward: -0.5273,                 loss: nan
agent1:                 episode reward: 0.5273,                 loss: 0.1080
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2842s / 195.2886 s
agent0:                 episode reward: -0.7021,                 loss: nan
agent1:                 episode reward: 0.7021,                 loss: 0.1109
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2844s / 195.5730 s
agent0:                 episode reward: -0.8658,                 loss: nan
agent1:                 episode reward: 0.8658,                 loss: 0.1077
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2609s / 195.8338 s
agent0:                 episode reward: -0.5858,                 loss: nan
agent1:                 episode reward: 0.5858,                 loss: 0.1093
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2606s / 196.0944 s
agent0:                 episode reward: -0.6140,                 loss: nan
agent1:                 episode reward: 0.6140,                 loss: 0.1081
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 196.3542 s
agent0:                 episode reward: -0.6289,                 loss: nan
agent1:                 episode reward: 0.6289,                 loss: 0.1078
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2608s / 196.6150 s
agent0:                 episode reward: -0.5614,                 loss: nan
agent1:                 episode reward: 0.5614,                 loss: 0.1081
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2655s / 196.8805 s
agent0:                 episode reward: -0.8533,                 loss: nan
agent1:                 episode reward: 0.8533,                 loss: 0.1092
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2620s / 197.1425 s
agent0:                 episode reward: -0.7945,                 loss: nan
agent1:                 episode reward: 0.7945,                 loss: 0.1076
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2604s / 197.4028 s
agent0:                 episode reward: -0.5602,                 loss: nan
agent1:                 episode reward: 0.5602,                 loss: 0.1089
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2597s / 197.6625 s
agent0:                 episode reward: -0.6747,                 loss: nan
agent1:                 episode reward: 0.6747,                 loss: 0.1091
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2641s / 197.9266 s
agent0:                 episode reward: -0.4898,                 loss: nan
agent1:                 episode reward: 0.4898,                 loss: 0.1087
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2628s / 198.1894 s
agent0:                 episode reward: -0.4456,                 loss: nan
agent1:                 episode reward: 0.4456,                 loss: 0.1098
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2977s / 198.4871 s
agent0:                 episode reward: -0.7073,                 loss: nan
agent1:                 episode reward: 0.7073,                 loss: 0.1080
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2913s / 198.7784 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.1078
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2753s / 199.0537 s
agent0:                 episode reward: -0.9362,                 loss: nan
agent1:                 episode reward: 0.9362,                 loss: 0.1090
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2849s / 199.3386 s
agent0:                 episode reward: -0.7674,                 loss: nan
agent1:                 episode reward: 0.7674,                 loss: 0.1096
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2760s / 199.6146 s
agent0:                 episode reward: -0.2763,                 loss: nan
agent1:                 episode reward: 0.2763,                 loss: 0.1087
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2742s / 199.8888 s
agent0:                 episode reward: -0.6311,                 loss: nan
agent1:                 episode reward: 0.6311,                 loss: 0.1092
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2750s / 200.1637 s
agent0:                 episode reward: -0.3520,                 loss: nan
agent1:                 episode reward: 0.3520,                 loss: 0.1094
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2778s / 200.4415 s
agent0:                 episode reward: -0.6566,                 loss: nan
agent1:                 episode reward: 0.6566,                 loss: 0.1102
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2708s / 200.7123 s
agent0:                 episode reward: -0.9959,                 loss: nan
agent1:                 episode reward: 0.9959,                 loss: 0.1087
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2726s / 200.9850 s
agent0:                 episode reward: -0.3399,                 loss: nan
agent1:                 episode reward: 0.3399,                 loss: 0.1093
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2738s / 201.2588 s
agent0:                 episode reward: -0.3091,                 loss: nan
agent1:                 episode reward: 0.3091,                 loss: 0.1098
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2991s / 201.5579 s
agent0:                 episode reward: -0.4082,                 loss: nan
agent1:                 episode reward: 0.4082,                 loss: 0.1086
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2775s / 201.8354 s
agent0:                 episode reward: -0.5411,                 loss: nan
agent1:                 episode reward: 0.5411,                 loss: 0.1092
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2731s / 202.1085 s
agent0:                 episode reward: -0.5763,                 loss: nan
agent1:                 episode reward: 0.5763,                 loss: 0.1084
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2764s / 202.3849 s
agent0:                 episode reward: -0.3589,                 loss: nan
agent1:                 episode reward: 0.3589,                 loss: 0.1083
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2762s / 202.6612 s
agent0:                 episode reward: -0.5120,                 loss: nan
agent1:                 episode reward: 0.5120,                 loss: 0.1083
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2834s / 202.9446 s
agent0:                 episode reward: -0.4526,                 loss: nan
agent1:                 episode reward: 0.4526,                 loss: 0.1085
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2747s / 203.2193 s
agent0:                 episode reward: -0.6288,                 loss: nan
agent1:                 episode reward: 0.6288,                 loss: 0.1091
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2776s / 203.4970 s
agent0:                 episode reward: -0.5929,                 loss: nan
agent1:                 episode reward: 0.5929,                 loss: 0.1077
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2978s / 203.7947 s
agent0:                 episode reward: -0.2314,                 loss: nan
agent1:                 episode reward: 0.2314,                 loss: 0.1090
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2706s / 204.0653 s
agent0:                 episode reward: -0.7285,                 loss: nan
agent1:                 episode reward: 0.7285,                 loss: 0.1086
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2682s / 204.3335 s
agent0:                 episode reward: -0.3771,                 loss: nan
agent1:                 episode reward: 0.3771,                 loss: 0.1079
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2900s / 204.6235 s
agent0:                 episode reward: -0.6544,                 loss: nan
agent1:                 episode reward: 0.6544,                 loss: 0.1092
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2736s / 204.8971 s
agent0:                 episode reward: -0.6137,                 loss: nan
agent1:                 episode reward: 0.6137,                 loss: 0.1089
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2617s / 205.1588 s
agent0:                 episode reward: -0.7758,                 loss: nan
agent1:                 episode reward: 0.7758,                 loss: 0.1080
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2629s / 205.4217 s
agent0:                 episode reward: -0.6422,                 loss: nan
agent1:                 episode reward: 0.6422,                 loss: 0.1092
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2681s / 205.6897 s
agent0:                 episode reward: -0.4386,                 loss: nan
agent1:                 episode reward: 0.4386,                 loss: 0.1091
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2696s / 205.9594 s
agent0:                 episode reward: -0.4736,                 loss: nan
agent1:                 episode reward: 0.4736,                 loss: 0.1079
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2879s / 206.2473 s
agent0:                 episode reward: -0.7520,                 loss: nan
agent1:                 episode reward: 0.7520,                 loss: 0.1091
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3062s / 206.5535 s
agent0:                 episode reward: -0.8458,                 loss: nan
agent1:                 episode reward: 0.8458,                 loss: 0.1085
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 206.8334 s
agent0:                 episode reward: -0.7570,                 loss: nan
agent1:                 episode reward: 0.7570,                 loss: 0.1085
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2938s / 207.1272 s
agent0:                 episode reward: -0.4637,                 loss: nan
agent1:                 episode reward: 0.4637,                 loss: 0.1093
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2786s / 207.4058 s
agent0:                 episode reward: -0.4501,                 loss: nan
agent1:                 episode reward: 0.4501,                 loss: 0.1084
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3233s / 207.7291 s
agent0:                 episode reward: -0.4462,                 loss: nan
agent1:                 episode reward: 0.4462,                 loss: 0.1081
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2874s / 208.0165 s
agent0:                 episode reward: -0.4891,                 loss: nan
agent1:                 episode reward: 0.4891,                 loss: 0.1086
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2818s / 208.2983 s
agent0:                 episode reward: -0.5145,                 loss: nan
agent1:                 episode reward: 0.5145,                 loss: 0.1077
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2646s / 208.5629 s
agent0:                 episode reward: -0.6901,                 loss: nan
agent1:                 episode reward: 0.6901,                 loss: 0.1088
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2676s / 208.8305 s
agent0:                 episode reward: -0.5255,                 loss: nan
agent1:                 episode reward: 0.5255,                 loss: 0.1080
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2687s / 209.0992 s
agent0:                 episode reward: -0.5493,                 loss: nan
agent1:                 episode reward: 0.5493,                 loss: 0.1093
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2691s / 209.3683 s
agent0:                 episode reward: -0.3176,                 loss: nan
agent1:                 episode reward: 0.3176,                 loss: 0.1085
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2675s / 209.6357 s
agent0:                 episode reward: -0.5117,                 loss: nan
agent1:                 episode reward: 0.5117,                 loss: 0.1066
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2676s / 209.9033 s
agent0:                 episode reward: -0.4932,                 loss: nan
agent1:                 episode reward: 0.4932,                 loss: 0.1099
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2727s / 210.1760 s
agent0:                 episode reward: -0.7873,                 loss: nan
agent1:                 episode reward: 0.7873,                 loss: 0.1093
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2692s / 210.4453 s
agent0:                 episode reward: -0.9873,                 loss: nan
agent1:                 episode reward: 0.9873,                 loss: 0.1096
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2985s / 210.7437 s
agent0:                 episode reward: -0.5876,                 loss: nan
agent1:                 episode reward: 0.5876,                 loss: 0.1075
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2817s / 211.0254 s
agent0:                 episode reward: -0.5990,                 loss: nan
agent1:                 episode reward: 0.5990,                 loss: 0.1073
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 211.3067 s
agent0:                 episode reward: -0.5866,                 loss: nan
agent1:                 episode reward: 0.5866,                 loss: 0.1091
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2915s / 211.5981 s
agent0:                 episode reward: -0.9842,                 loss: nan
agent1:                 episode reward: 0.9842,                 loss: 0.1079
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2905s / 211.8887 s
agent0:                 episode reward: -0.4913,                 loss: nan
agent1:                 episode reward: 0.4913,                 loss: 0.1074
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2858s / 212.1744 s
agent0:                 episode reward: -0.2867,                 loss: nan
agent1:                 episode reward: 0.2867,                 loss: 0.1089
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 212.4571 s
agent0:                 episode reward: -0.5682,                 loss: nan
agent1:                 episode reward: 0.5682,                 loss: 0.1078
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 212.7383 s
agent0:                 episode reward: -0.8480,                 loss: nan
agent1:                 episode reward: 0.8480,                 loss: 0.1085
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2805s / 213.0188 s
agent0:                 episode reward: -0.7947,                 loss: nan
agent1:                 episode reward: 0.7947,                 loss: 0.1078
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 213.3017 s
agent0:                 episode reward: -0.2431,                 loss: nan
agent1:                 episode reward: 0.2431,                 loss: 0.1084
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2915s / 213.5932 s
agent0:                 episode reward: -0.5119,                 loss: nan
agent1:                 episode reward: 0.5119,                 loss: 0.1072
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3022s / 213.8954 s
agent0:                 episode reward: -0.6476,                 loss: nan
agent1:                 episode reward: 0.6476,                 loss: 0.1079
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2994s / 214.1948 s
agent0:                 episode reward: -0.8364,                 loss: nan
agent1:                 episode reward: 0.8364,                 loss: 0.1074
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2816s / 214.4764 s
agent0:                 episode reward: -0.2009,                 loss: nan
agent1:                 episode reward: 0.2009,                 loss: 0.1078
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2804s / 214.7568 s
agent0:                 episode reward: -0.5924,                 loss: nan
agent1:                 episode reward: 0.5924,                 loss: 0.1070
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2797s / 215.0365 s
agent0:                 episode reward: -0.4028,                 loss: nan
agent1:                 episode reward: 0.4028,                 loss: 0.1083
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2770s / 215.3135 s
agent0:                 episode reward: -0.5841,                 loss: nan
agent1:                 episode reward: 0.5841,                 loss: 0.1080
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3009s / 215.6144 s
agent0:                 episode reward: -0.5726,                 loss: nan
agent1:                 episode reward: 0.5726,                 loss: 0.1082
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2840s / 215.8984 s
agent0:                 episode reward: -0.7010,                 loss: nan
agent1:                 episode reward: 0.7010,                 loss: 0.1087
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2805s / 216.1789 s
agent0:                 episode reward: -0.3787,                 loss: nan
agent1:                 episode reward: 0.3787,                 loss: 0.1077
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2776s / 216.4566 s
agent0:                 episode reward: -0.6949,                 loss: nan
agent1:                 episode reward: 0.6949,                 loss: 0.1070
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3098s / 216.7663 s
agent0:                 episode reward: -0.6633,                 loss: nan
agent1:                 episode reward: 0.6633,                 loss: 0.1064
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2931s / 217.0594 s
agent0:                 episode reward: -0.7366,                 loss: nan
agent1:                 episode reward: 0.7366,                 loss: 0.1072
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2685s / 217.3279 s
agent0:                 episode reward: -0.9515,                 loss: nan
agent1:                 episode reward: 0.9515,                 loss: 0.1079
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 217.5940 s
agent0:                 episode reward: -0.7130,                 loss: nan
agent1:                 episode reward: 0.7130,                 loss: 0.1064
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2638s / 217.8577 s
agent0:                 episode reward: -0.1762,                 loss: nan
agent1:                 episode reward: 0.1762,                 loss: 0.1062
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2682s / 218.1259 s
agent0:                 episode reward: -0.2734,                 loss: nan
agent1:                 episode reward: 0.2734,                 loss: 0.1072
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2740s / 218.3999 s
agent0:                 episode reward: -0.6159,                 loss: nan
agent1:                 episode reward: 0.6159,                 loss: 0.1070
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 218.6719 s
agent0:                 episode reward: -0.5882,                 loss: nan
agent1:                 episode reward: 0.5882,                 loss: 0.1090
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2772s / 218.9491 s
agent0:                 episode reward: -0.8948,                 loss: nan
agent1:                 episode reward: 0.8948,                 loss: 0.1073
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3256s / 219.2747 s
agent0:                 episode reward: -0.4052,                 loss: nan
agent1:                 episode reward: 0.4052,                 loss: 0.1069
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2814s / 219.5561 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.1088
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3073s / 219.8634 s
agent0:                 episode reward: -0.4529,                 loss: nan
agent1:                 episode reward: 0.4529,                 loss: 0.1070
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2933s / 220.1567 s
agent0:                 episode reward: -0.5624,                 loss: nan
agent1:                 episode reward: 0.5624,                 loss: 0.1070
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2835s / 220.4402 s
agent0:                 episode reward: -0.7325,                 loss: nan
agent1:                 episode reward: 0.7325,                 loss: 0.1069
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2824s / 220.7226 s
agent0:                 episode reward: -0.6448,                 loss: nan
agent1:                 episode reward: 0.6448,                 loss: 0.1063
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2820s / 221.0046 s
agent0:                 episode reward: -0.9091,                 loss: nan
agent1:                 episode reward: 0.9091,                 loss: 0.1073
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2828s / 221.2873 s
agent0:                 episode reward: -0.5164,                 loss: nan
agent1:                 episode reward: 0.5164,                 loss: 0.1076
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3089s / 221.5963 s
agent0:                 episode reward: -0.6337,                 loss: nan
agent1:                 episode reward: 0.6337,                 loss: 0.1073
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2897s / 221.8859 s
agent0:                 episode reward: -0.6391,                 loss: nan
agent1:                 episode reward: 0.6391,                 loss: 0.1067
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2846s / 222.1705 s
agent0:                 episode reward: -0.7794,                 loss: nan
agent1:                 episode reward: 0.7794,                 loss: 0.1063
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2833s / 222.4538 s
agent0:                 episode reward: -0.5634,                 loss: nan
agent1:                 episode reward: 0.5634,                 loss: 0.1076
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2885s / 222.7424 s
agent0:                 episode reward: -0.4964,                 loss: nan
agent1:                 episode reward: 0.4964,                 loss: 0.1077
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3166s / 223.0590 s
agent0:                 episode reward: -0.5164,                 loss: nan
agent1:                 episode reward: 0.5164,                 loss: 0.1081
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2915s / 223.3505 s
agent0:                 episode reward: -0.7416,                 loss: nan
agent1:                 episode reward: 0.7416,                 loss: 0.1087
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2836s / 223.6341 s
agent0:                 episode reward: -0.6637,                 loss: nan
agent1:                 episode reward: 0.6637,                 loss: 0.1071
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2887s / 223.9228 s
agent0:                 episode reward: -0.7825,                 loss: nan
agent1:                 episode reward: 0.7825,                 loss: 0.1072
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2707s / 224.1935 s
agent0:                 episode reward: -0.8172,                 loss: nan
agent1:                 episode reward: 0.8172,                 loss: 0.1062
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2743s / 224.4678 s
agent0:                 episode reward: -0.5939,                 loss: nan
agent1:                 episode reward: 0.5939,                 loss: 0.1087
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2791s / 224.7469 s
agent0:                 episode reward: -0.7607,                 loss: nan
agent1:                 episode reward: 0.7607,                 loss: 0.1073
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2724s / 225.0193 s
agent0:                 episode reward: -0.5038,                 loss: nan
agent1:                 episode reward: 0.5038,                 loss: 0.1094
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2684s / 225.2877 s
agent0:                 episode reward: -0.6899,                 loss: nan
agent1:                 episode reward: 0.6899,                 loss: 0.1064
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2741s / 225.5618 s
agent0:                 episode reward: -0.5357,                 loss: nan
agent1:                 episode reward: 0.5357,                 loss: 0.1065
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2758s / 225.8376 s
agent0:                 episode reward: -0.8246,                 loss: nan
agent1:                 episode reward: 0.8246,                 loss: 0.1067
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3022s / 226.1398 s
agent0:                 episode reward: -0.9126,                 loss: nan
agent1:                 episode reward: 0.9126,                 loss: 0.1063
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2785s / 226.4183 s
agent0:                 episode reward: -0.8083,                 loss: nan
agent1:                 episode reward: 0.8083,                 loss: 0.1066
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2794s / 226.6977 s
agent0:                 episode reward: -1.1485,                 loss: nan
agent1:                 episode reward: 1.1485,                 loss: 0.1060
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2822s / 226.9799 s
agent0:                 episode reward: -0.4942,                 loss: nan
agent1:                 episode reward: 0.4942,                 loss: 0.1076
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2772s / 227.2571 s
agent0:                 episode reward: -0.7791,                 loss: nan
agent1:                 episode reward: 0.7791,                 loss: 0.1067
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2767s / 227.5338 s
agent0:                 episode reward: -0.8331,                 loss: nan
agent1:                 episode reward: 0.8331,                 loss: 0.1067
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2704s / 227.8042 s
agent0:                 episode reward: -0.6350,                 loss: nan
agent1:                 episode reward: 0.6350,                 loss: 0.1076
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2737s / 228.0779 s
agent0:                 episode reward: -0.9216,                 loss: nan
agent1:                 episode reward: 0.9216,                 loss: 0.1063
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2848s / 228.3627 s
agent0:                 episode reward: -0.7536,                 loss: nan
agent1:                 episode reward: 0.7536,                 loss: 0.1074
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2703s / 228.6330 s
agent0:                 episode reward: -0.8024,                 loss: nan
agent1:                 episode reward: 0.8024,                 loss: 0.1064
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2880s / 228.9209 s
agent0:                 episode reward: -0.3157,                 loss: nan
agent1:                 episode reward: 0.3157,                 loss: 0.1061
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2880s / 229.2090 s
agent0:                 episode reward: -0.7719,                 loss: nan
agent1:                 episode reward: 0.7719,                 loss: 0.1064
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2705s / 229.4795 s
agent0:                 episode reward: -0.8545,                 loss: nan
agent1:                 episode reward: 0.8545,                 loss: 0.1081
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2718s / 229.7512 s
agent0:                 episode reward: -0.3777,                 loss: nan
agent1:                 episode reward: 0.3777,                 loss: 0.1056
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2741s / 230.0254 s
agent0:                 episode reward: -0.7410,                 loss: nan
agent1:                 episode reward: 0.7410,                 loss: 0.1074
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2774s / 230.3028 s
agent0:                 episode reward: -0.6707,                 loss: nan
agent1:                 episode reward: 0.6707,                 loss: 0.1075
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2813s / 230.5840 s
agent0:                 episode reward: -0.7514,                 loss: nan
agent1:                 episode reward: 0.7514,                 loss: 0.1074
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2748s / 230.8588 s
agent0:                 episode reward: -0.9193,                 loss: nan
agent1:                 episode reward: 0.9193,                 loss: 0.1070
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 231.1345 s
agent0:                 episode reward: -0.5958,                 loss: nan
agent1:                 episode reward: 0.5958,                 loss: 0.1061
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2782s / 231.4127 s
agent0:                 episode reward: -0.7146,                 loss: nan
agent1:                 episode reward: 0.7146,                 loss: 0.1068
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2912s / 231.7039 s
agent0:                 episode reward: -0.1979,                 loss: nan
agent1:                 episode reward: 0.1979,                 loss: 0.1072
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2931s / 231.9970 s
agent0:                 episode reward: -0.7085,                 loss: nan
agent1:                 episode reward: 0.7085,                 loss: 0.1073
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3124s / 232.3094 s
agent0:                 episode reward: -1.0271,                 loss: nan
agent1:                 episode reward: 1.0271,                 loss: 0.1076
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2791s / 232.5885 s
agent0:                 episode reward: -0.9675,                 loss: nan
agent1:                 episode reward: 0.9675,                 loss: 0.1064
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2738s / 232.8623 s
agent0:                 episode reward: -0.5347,                 loss: nan
agent1:                 episode reward: 0.5347,                 loss: 0.1075
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2725s / 233.1349 s
agent0:                 episode reward: -0.7057,                 loss: nan
agent1:                 episode reward: 0.7057,                 loss: 0.1075
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2740s / 233.4088 s
agent0:                 episode reward: -0.4578,                 loss: nan
agent1:                 episode reward: 0.4578,                 loss: 0.1065
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2785s / 233.6874 s
agent0:                 episode reward: -0.5117,                 loss: nan
agent1:                 episode reward: 0.5117,                 loss: 0.1071
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2930s / 233.9804 s
agent0:                 episode reward: -0.4782,                 loss: nan
agent1:                 episode reward: 0.4782,                 loss: 0.1057
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2907s / 234.2710 s
agent0:                 episode reward: -0.9532,                 loss: nan
agent1:                 episode reward: 0.9532,                 loss: 0.1059
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2910s / 234.5620 s
agent0:                 episode reward: -0.6939,                 loss: nan
agent1:                 episode reward: 0.6939,                 loss: 0.1063
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2951s / 234.8571 s
agent0:                 episode reward: -0.4943,                 loss: nan
agent1:                 episode reward: 0.4943,                 loss: 0.1065
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3305s / 235.1876 s
agent0:                 episode reward: -0.6960,                 loss: nan
agent1:                 episode reward: 0.6960,                 loss: 0.1064
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2993s / 235.4869 s
agent0:                 episode reward: -0.4833,                 loss: nan
agent1:                 episode reward: 0.4833,                 loss: 0.1052
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2887s / 235.7756 s
agent0:                 episode reward: -0.6089,                 loss: nan
agent1:                 episode reward: 0.6089,                 loss: 0.1057
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2905s / 236.0661 s
agent0:                 episode reward: -0.7142,                 loss: nan
agent1:                 episode reward: 0.7142,                 loss: 0.1057
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2934s / 236.3595 s
agent0:                 episode reward: -0.3528,                 loss: nan
agent1:                 episode reward: 0.3528,                 loss: 0.1057
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2927s / 236.6522 s
agent0:                 episode reward: -0.3912,                 loss: nan
agent1:                 episode reward: 0.3912,                 loss: 0.1055
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3009s / 236.9531 s
agent0:                 episode reward: -0.6570,                 loss: nan
agent1:                 episode reward: 0.6570,                 loss: 0.1070
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3034s / 237.2565 s
agent0:                 episode reward: -0.6386,                 loss: nan
agent1:                 episode reward: 0.6386,                 loss: 0.1059
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2994s / 237.5558 s
agent0:                 episode reward: -0.6829,                 loss: nan
agent1:                 episode reward: 0.6829,                 loss: 0.1068
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2962s / 237.8520 s
agent0:                 episode reward: -0.6250,                 loss: nan
agent1:                 episode reward: 0.6250,                 loss: 0.1057
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3200s / 238.1720 s
agent0:                 episode reward: -0.6350,                 loss: nan
agent1:                 episode reward: 0.6350,                 loss: 0.1056
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3167s / 238.4887 s
agent0:                 episode reward: -0.5713,                 loss: nan
agent1:                 episode reward: 0.5713,                 loss: 0.1066
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3026s / 238.7913 s
agent0:                 episode reward: -0.4952,                 loss: nan
agent1:                 episode reward: 0.4952,                 loss: 0.1061
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2987s / 239.0900 s
agent0:                 episode reward: -0.5926,                 loss: nan
agent1:                 episode reward: 0.5926,                 loss: 0.1057
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2999s / 239.3900 s
agent0:                 episode reward: -0.7837,                 loss: nan
agent1:                 episode reward: 0.7837,                 loss: 0.1071
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2967s / 239.6866 s
agent0:                 episode reward: -0.6995,                 loss: nan
agent1:                 episode reward: 0.6995,                 loss: 0.1071
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2959s / 239.9825 s
agent0:                 episode reward: -0.6720,                 loss: nan
agent1:                 episode reward: 0.6720,                 loss: 0.1054
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2913s / 240.2738 s
agent0:                 episode reward: -0.4568,                 loss: nan
agent1:                 episode reward: 0.4568,                 loss: 0.1055
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3036s / 240.5774 s
agent0:                 episode reward: -0.8720,                 loss: nan
agent1:                 episode reward: 0.8720,                 loss: 0.1058
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2752s / 240.8526 s
agent0:                 episode reward: -0.6573,                 loss: nan
agent1:                 episode reward: 0.6573,                 loss: 0.1068
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2765s / 241.1290 s
agent0:                 episode reward: -0.3164,                 loss: nan
agent1:                 episode reward: 0.3164,                 loss: 0.1058
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3090s / 241.4380 s
agent0:                 episode reward: -0.2489,                 loss: nan
agent1:                 episode reward: 0.2489,                 loss: 0.1071
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2983s / 241.7363 s
agent0:                 episode reward: -0.5262,                 loss: nan
agent1:                 episode reward: 0.5262,                 loss: 0.1060
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2929s / 242.0292 s
agent0:                 episode reward: -1.0335,                 loss: nan
agent1:                 episode reward: 1.0335,                 loss: 0.1056
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2995s / 242.3287 s
agent0:                 episode reward: -0.7173,                 loss: nan
agent1:                 episode reward: 0.7173,                 loss: 0.1080
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2939s / 242.6226 s
agent0:                 episode reward: -0.8501,                 loss: nan
agent1:                 episode reward: 0.8501,                 loss: 0.1056
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 242.9166 s
agent0:                 episode reward: -0.5819,                 loss: nan
agent1:                 episode reward: 0.5819,                 loss: 0.1070
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2980s / 243.2146 s
agent0:                 episode reward: -0.5473,                 loss: nan
agent1:                 episode reward: 0.5473,                 loss: 0.1062
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2988s / 243.5134 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.1055
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3011s / 243.8146 s
agent0:                 episode reward: -0.9900,                 loss: nan
agent1:                 episode reward: 0.9900,                 loss: 0.1067
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2984s / 244.1129 s
agent0:                 episode reward: -0.8020,                 loss: nan
agent1:                 episode reward: 0.8020,                 loss: 0.1070
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3347s / 244.4476 s
agent0:                 episode reward: -0.6782,                 loss: nan
agent1:                 episode reward: 0.6782,                 loss: 0.1068
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2974s / 244.7450 s
agent0:                 episode reward: -0.8697,                 loss: nan
agent1:                 episode reward: 0.8697,                 loss: 0.1062
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 245.0346 s
agent0:                 episode reward: -0.6784,                 loss: nan
agent1:                 episode reward: 0.6784,                 loss: 0.1062
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2893s / 245.3239 s
agent0:                 episode reward: -0.4860,                 loss: nan
agent1:                 episode reward: 0.4860,                 loss: 0.1057
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3045s / 245.6284 s
agent0:                 episode reward: -0.6624,                 loss: nan
agent1:                 episode reward: 0.6624,                 loss: 0.1081
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2995s / 245.9279 s
agent0:                 episode reward: -0.0953,                 loss: nan
agent1:                 episode reward: 0.0953,                 loss: 0.1077
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3134s / 246.2412 s
agent0:                 episode reward: -0.8593,                 loss: nan
agent1:                 episode reward: 0.8593,                 loss: 0.1068
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3089s / 246.5501 s
agent0:                 episode reward: -0.5370,                 loss: nan
agent1:                 episode reward: 0.5370,                 loss: 0.1057
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3089s / 246.8590 s
agent0:                 episode reward: -0.7657,                 loss: nan
agent1:                 episode reward: 0.7657,                 loss: 0.1062
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3005s / 247.1595 s
agent0:                 episode reward: -0.3171,                 loss: nan
agent1:                 episode reward: 0.3171,                 loss: 0.1064
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3223s / 247.4819 s
agent0:                 episode reward: -0.4024,                 loss: nan
agent1:                 episode reward: 0.4024,                 loss: 0.1067
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3040s / 247.7859 s
agent0:                 episode reward: -0.6727,                 loss: nan
agent1:                 episode reward: 0.6727,                 loss: 0.1068
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3008s / 248.0867 s
agent0:                 episode reward: -0.8470,                 loss: nan
agent1:                 episode reward: 0.8470,                 loss: 0.1073
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3051s / 248.3918 s
agent0:                 episode reward: -0.5314,                 loss: nan
agent1:                 episode reward: 0.5314,                 loss: 0.1057
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2985s / 248.6903 s
agent0:                 episode reward: -0.9695,                 loss: nan
agent1:                 episode reward: 0.9695,                 loss: 0.1075
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3229s / 249.0132 s
agent0:                 episode reward: -0.6700,                 loss: nan
agent1:                 episode reward: 0.6700,                 loss: 0.1066
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3029s / 249.3161 s
agent0:                 episode reward: -0.4504,                 loss: nan
agent1:                 episode reward: 0.4504,                 loss: 0.1060
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2975s / 249.6136 s
agent0:                 episode reward: -0.8947,                 loss: nan
agent1:                 episode reward: 0.8947,                 loss: 0.1073
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3033s / 249.9169 s
agent0:                 episode reward: -0.4238,                 loss: nan
agent1:                 episode reward: 0.4238,                 loss: 0.1064
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3046s / 250.2215 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.1061
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3103s / 250.5318 s
agent0:                 episode reward: -0.8620,                 loss: nan
agent1:                 episode reward: 0.8620,                 loss: 0.1068
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2996s / 250.8313 s
agent0:                 episode reward: -0.7719,                 loss: nan
agent1:                 episode reward: 0.7719,                 loss: 0.1059
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3083s / 251.1397 s
agent0:                 episode reward: -0.7407,                 loss: nan
agent1:                 episode reward: 0.7407,                 loss: 0.1077
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3118s / 251.4514 s
agent0:                 episode reward: -0.7455,                 loss: nan
agent1:                 episode reward: 0.7455,                 loss: 0.1074
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3089s / 251.7603 s
agent0:                 episode reward: -0.6796,                 loss: nan
agent1:                 episode reward: 0.6796,                 loss: 0.1064
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3284s / 252.0887 s
agent0:                 episode reward: -0.7305,                 loss: nan
agent1:                 episode reward: 0.7305,                 loss: 0.1065
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3382s / 252.4269 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.1057
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3176s / 252.7444 s
agent0:                 episode reward: -0.6999,                 loss: nan
agent1:                 episode reward: 0.6999,                 loss: 0.1071
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2963s / 253.0407 s
agent0:                 episode reward: -0.2961,                 loss: nan
agent1:                 episode reward: 0.2961,                 loss: 0.1061
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2948s / 253.3355 s
agent0:                 episode reward: -0.6015,                 loss: nan
agent1:                 episode reward: 0.6015,                 loss: 0.1067
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2935s / 253.6290 s
agent0:                 episode reward: -0.3321,                 loss: nan
agent1:                 episode reward: 0.3321,                 loss: 0.1059
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2992s / 253.9281 s
agent0:                 episode reward: -0.8706,                 loss: nan
agent1:                 episode reward: 0.8706,                 loss: 0.1062
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3033s / 254.2314 s
agent0:                 episode reward: -0.6686,                 loss: nan
agent1:                 episode reward: 0.6686,                 loss: 0.1053
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2966s / 254.5280 s
agent0:                 episode reward: -0.9541,                 loss: nan
agent1:                 episode reward: 0.9541,                 loss: 0.1070
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2979s / 254.8259 s
agent0:                 episode reward: -0.7793,                 loss: nan
agent1:                 episode reward: 0.7793,                 loss: 0.1062
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3031s / 255.1290 s
agent0:                 episode reward: -0.4136,                 loss: nan
agent1:                 episode reward: 0.4136,                 loss: 0.1060
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2991s / 255.4281 s
agent0:                 episode reward: -0.3251,                 loss: nan
agent1:                 episode reward: 0.3251,                 loss: 0.1068
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2989s / 255.7271 s
agent0:                 episode reward: -0.5453,                 loss: nan
agent1:                 episode reward: 0.5453,                 loss: 0.1058
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3069s / 256.0340 s
agent0:                 episode reward: -0.7777,                 loss: nan
agent1:                 episode reward: 0.7777,                 loss: 0.1067
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3172s / 256.3512 s
agent0:                 episode reward: -0.3531,                 loss: nan
agent1:                 episode reward: 0.3531,                 loss: 0.1065
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3037s / 256.6549 s
agent0:                 episode reward: -0.8365,                 loss: nan
agent1:                 episode reward: 0.8365,                 loss: 0.1054
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3043s / 256.9592 s
agent0:                 episode reward: -0.2845,                 loss: nan
agent1:                 episode reward: 0.2845,                 loss: 0.1062
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3252s / 257.2844 s
agent0:                 episode reward: -0.4540,                 loss: nan
agent1:                 episode reward: 0.4540,                 loss: 0.1069
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2990s / 257.5834 s
agent0:                 episode reward: -0.6358,                 loss: nan
agent1:                 episode reward: 0.6358,                 loss: 0.1044
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3001s / 257.8835 s
agent0:                 episode reward: -0.8808,                 loss: nan
agent1:                 episode reward: 0.8808,                 loss: 0.1068
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2967s / 258.1802 s
agent0:                 episode reward: -0.6606,                 loss: nan
agent1:                 episode reward: 0.6606,                 loss: 0.1059
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3031s / 258.4833 s
agent0:                 episode reward: -0.4990,                 loss: nan
agent1:                 episode reward: 0.4990,                 loss: 0.1057
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2995s / 258.7828 s
agent0:                 episode reward: -0.4339,                 loss: nan
agent1:                 episode reward: 0.4339,                 loss: 0.1054
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2944s / 259.0772 s
agent0:                 episode reward: -0.5319,                 loss: nan
agent1:                 episode reward: 0.5319,                 loss: 0.1064
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3269s / 259.4041 s
agent0:                 episode reward: -0.3590,                 loss: nan
agent1:                 episode reward: 0.3590,                 loss: 0.1067
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3033s / 259.7074 s
agent0:                 episode reward: -0.6860,                 loss: nan
agent1:                 episode reward: 0.6860,                 loss: 0.1050
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3015s / 260.0088 s
agent0:                 episode reward: -0.1775,                 loss: nan
agent1:                 episode reward: 0.1775,                 loss: 0.1065
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3032s / 260.3121 s
agent0:                 episode reward: -0.5660,                 loss: nan
agent1:                 episode reward: 0.5660,                 loss: 0.1061
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2976s / 260.6096 s
agent0:                 episode reward: -0.7455,                 loss: nan
agent1:                 episode reward: 0.7455,                 loss: 0.1071
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2960s / 260.9057 s
agent0:                 episode reward: -0.4647,                 loss: nan
agent1:                 episode reward: 0.4647,                 loss: 0.1076
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2964s / 261.2020 s
agent0:                 episode reward: -0.4954,                 loss: nan
agent1:                 episode reward: 0.4954,                 loss: 0.1068
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3022s / 261.5043 s
agent0:                 episode reward: -0.7869,                 loss: nan
agent1:                 episode reward: 0.7869,                 loss: 0.1066
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2937s / 261.7980 s
agent0:                 episode reward: -0.6421,                 loss: nan
agent1:                 episode reward: 0.6421,                 loss: 0.1062
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3012s / 262.0991 s
agent0:                 episode reward: -0.5468,                 loss: nan
agent1:                 episode reward: 0.5468,                 loss: 0.1066
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3246s / 262.4237 s
agent0:                 episode reward: -0.9047,                 loss: nan
agent1:                 episode reward: 0.9047,                 loss: 0.1057
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3174s / 262.7412 s
agent0:                 episode reward: -0.8216,                 loss: nan
agent1:                 episode reward: 0.8216,                 loss: 0.1072
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3023s / 263.0434 s
agent0:                 episode reward: -0.8444,                 loss: nan
agent1:                 episode reward: 0.8444,                 loss: 0.1068
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3056s / 263.3490 s
agent0:                 episode reward: -0.7068,                 loss: nan
agent1:                 episode reward: 0.7068,                 loss: 0.1058
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3095s / 263.6586 s
agent0:                 episode reward: -0.7897,                 loss: nan
agent1:                 episode reward: 0.7897,                 loss: 0.1071
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3037s / 263.9623 s
agent0:                 episode reward: -0.5349,                 loss: nan
agent1:                 episode reward: 0.5349,                 loss: 0.1067
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3029s / 264.2652 s
agent0:                 episode reward: -0.6497,                 loss: nan
agent1:                 episode reward: 0.6497,                 loss: 0.1062
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3035s / 264.5687 s
agent0:                 episode reward: -0.7320,                 loss: nan
agent1:                 episode reward: 0.7320,                 loss: 0.1066
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3059s / 264.8746 s
agent0:                 episode reward: -0.6751,                 loss: nan
agent1:                 episode reward: 0.6751,                 loss: 0.1057
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3046s / 265.1792 s
agent0:                 episode reward: -0.6172,                 loss: nan
agent1:                 episode reward: 0.6172,                 loss: 0.1065
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3662s / 265.5454 s
agent0:                 episode reward: -0.9572,                 loss: nan
agent1:                 episode reward: 0.9572,                 loss: 0.1068
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3039s / 265.8493 s
agent0:                 episode reward: -0.6415,                 loss: nan
agent1:                 episode reward: 0.6415,                 loss: 0.1051
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3058s / 266.1550 s
agent0:                 episode reward: -0.7526,                 loss: nan
agent1:                 episode reward: 0.7526,                 loss: 0.1057
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3047s / 266.4598 s
agent0:                 episode reward: -0.6499,                 loss: nan
agent1:                 episode reward: 0.6499,                 loss: 0.1065
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3002s / 266.7600 s
agent0:                 episode reward: -0.3968,                 loss: nan
agent1:                 episode reward: 0.3968,                 loss: 0.1062
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3050s / 267.0649 s
agent0:                 episode reward: -0.8441,                 loss: nan
agent1:                 episode reward: 0.8441,                 loss: 0.1055
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3037s / 267.3687 s
agent0:                 episode reward: -0.4869,                 loss: nan
agent1:                 episode reward: 0.4869,                 loss: 0.1058
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3057s / 267.6744 s
agent0:                 episode reward: -0.9600,                 loss: nan
agent1:                 episode reward: 0.9600,                 loss: 0.1054
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3070s / 267.9814 s
agent0:                 episode reward: -0.8619,                 loss: nan
agent1:                 episode reward: 0.8619,                 loss: 0.1046
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 268.2754 s
agent0:                 episode reward: -0.7348,                 loss: nan
agent1:                 episode reward: 0.7348,                 loss: 0.1040
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3283s / 268.6037 s
agent0:                 episode reward: -0.4888,                 loss: nan
agent1:                 episode reward: 0.4888,                 loss: 0.1045
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3131s / 268.9168 s
agent0:                 episode reward: -0.2382,                 loss: nan
agent1:                 episode reward: 0.2382,                 loss: 0.1052
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2985s / 269.2153 s
agent0:                 episode reward: -0.8708,                 loss: nan
agent1:                 episode reward: 0.8708,                 loss: 0.1058
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2964s / 269.5117 s
agent0:                 episode reward: -0.4530,                 loss: nan
agent1:                 episode reward: 0.4530,                 loss: 0.1046
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2925s / 269.8042 s
agent0:                 episode reward: -0.6952,                 loss: nan
agent1:                 episode reward: 0.6952,                 loss: 0.1050
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3079s / 270.1121 s
agent0:                 episode reward: -0.7790,                 loss: nan
agent1:                 episode reward: 0.7790,                 loss: 0.1047
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3098s / 270.4219 s
agent0:                 episode reward: -0.6966,                 loss: nan
agent1:                 episode reward: 0.6966,                 loss: 0.1066
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3062s / 270.7281 s
agent0:                 episode reward: -0.9736,                 loss: nan
agent1:                 episode reward: 0.9736,                 loss: 0.1054
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3101s / 271.0382 s
agent0:                 episode reward: -0.6259,                 loss: nan
agent1:                 episode reward: 0.6259,                 loss: 0.1048
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 271.3503 s
agent0:                 episode reward: -0.5361,                 loss: nan
agent1:                 episode reward: 0.5361,                 loss: 0.1049
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3283s / 271.6786 s
agent0:                 episode reward: -0.6964,                 loss: nan
agent1:                 episode reward: 0.6964,                 loss: 0.1066
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3092s / 271.9878 s
agent0:                 episode reward: -1.0433,                 loss: nan
agent1:                 episode reward: 1.0433,                 loss: 0.1058
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3111s / 272.2989 s
agent0:                 episode reward: -0.6269,                 loss: nan
agent1:                 episode reward: 0.6269,                 loss: 0.1057
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 272.6108 s
agent0:                 episode reward: -1.1301,                 loss: nan
agent1:                 episode reward: 1.1301,                 loss: 0.1048
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 272.9215 s
agent0:                 episode reward: -0.7133,                 loss: nan
agent1:                 episode reward: 0.7133,                 loss: 0.1040
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 273.2322 s
agent0:                 episode reward: -0.3419,                 loss: nan
agent1:                 episode reward: 0.3419,                 loss: 0.1049
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3108s / 273.5430 s
agent0:                 episode reward: -0.8933,                 loss: nan
agent1:                 episode reward: 0.8933,                 loss: 0.1047
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3180s / 273.8610 s
agent0:                 episode reward: -0.7236,                 loss: nan
agent1:                 episode reward: 0.7236,                 loss: 0.1064
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3112s / 274.1722 s
agent0:                 episode reward: -0.8406,                 loss: nan
agent1:                 episode reward: 0.8406,                 loss: 0.1051
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3091s / 274.4813 s
agent0:                 episode reward: -1.0240,                 loss: nan
agent1:                 episode reward: 1.0240,                 loss: 0.1063
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3487s / 274.8301 s
agent0:                 episode reward: -0.6702,                 loss: nan
agent1:                 episode reward: 0.6702,                 loss: 0.1056
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3071s / 275.1372 s
agent0:                 episode reward: -0.7215,                 loss: nan
agent1:                 episode reward: 0.7215,                 loss: 0.1056
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3097s / 275.4469 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.1043
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3102s / 275.7571 s
agent0:                 episode reward: -0.6669,                 loss: nan
agent1:                 episode reward: 0.6669,                 loss: 0.1063
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3098s / 276.0669 s
agent0:                 episode reward: -0.4990,                 loss: nan
agent1:                 episode reward: 0.4990,                 loss: 0.1047
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 276.3807 s
agent0:                 episode reward: -0.6207,                 loss: nan
agent1:                 episode reward: 0.6207,                 loss: 0.1064
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3145s / 276.6952 s
agent0:                 episode reward: -0.5456,                 loss: nan
agent1:                 episode reward: 0.5456,                 loss: 0.1059
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3105s / 277.0057 s
agent0:                 episode reward: -0.7370,                 loss: nan
agent1:                 episode reward: 0.7370,                 loss: 0.1070
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3082s / 277.3139 s
agent0:                 episode reward: -0.6986,                 loss: nan
agent1:                 episode reward: 0.6986,                 loss: 0.1046
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3173s / 277.6312 s
agent0:                 episode reward: -0.7046,                 loss: nan
agent1:                 episode reward: 0.7046,                 loss: 0.1054
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3283s / 277.9595 s
agent0:                 episode reward: -0.4504,                 loss: nan
agent1:                 episode reward: 0.4504,                 loss: 0.1035
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3070s / 278.2665 s
agent0:                 episode reward: -0.2970,                 loss: nan
agent1:                 episode reward: 0.2970,                 loss: 0.1047
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3102s / 278.5767 s
agent0:                 episode reward: -0.9427,                 loss: nan
agent1:                 episode reward: 0.9427,                 loss: 0.1049
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3127s / 278.8894 s
agent0:                 episode reward: -0.4076,                 loss: nan
agent1:                 episode reward: 0.4076,                 loss: 0.1061
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3085s / 279.1979 s
agent0:                 episode reward: -0.6906,                 loss: nan
agent1:                 episode reward: 0.6906,                 loss: 0.1069
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3097s / 279.5076 s
agent0:                 episode reward: -0.4977,                 loss: nan
agent1:                 episode reward: 0.4977,                 loss: 0.1052
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 279.8183 s
agent0:                 episode reward: -0.8376,                 loss: nan
agent1:                 episode reward: 0.8376,                 loss: 0.1065
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3129s / 280.1312 s
agent0:                 episode reward: -0.9161,                 loss: nan
agent1:                 episode reward: 0.9161,                 loss: 0.1046
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3116s / 280.4427 s
agent0:                 episode reward: -0.5262,                 loss: nan
agent1:                 episode reward: 0.5262,                 loss: 0.1061
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3261s / 280.7689 s
agent0:                 episode reward: -0.7426,                 loss: nan
agent1:                 episode reward: 0.7426,                 loss: 0.1046
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3183s / 281.0871 s
agent0:                 episode reward: -0.3161,                 loss: nan
agent1:                 episode reward: 0.3161,                 loss: 0.1052
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3144s / 281.4015 s
agent0:                 episode reward: -0.4677,                 loss: nan
agent1:                 episode reward: 0.4677,                 loss: 0.1059
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3136s / 281.7151 s
agent0:                 episode reward: -0.6905,                 loss: nan
agent1:                 episode reward: 0.6905,                 loss: 0.1058
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 282.0315 s
agent0:                 episode reward: -0.4797,                 loss: nan
agent1:                 episode reward: 0.4797,                 loss: 0.1059
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 282.3680 s
agent0:                 episode reward: -0.7243,                 loss: nan
agent1:                 episode reward: 0.7243,                 loss: 0.1050
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3097s / 282.6776 s
agent0:                 episode reward: -0.8352,                 loss: nan
agent1:                 episode reward: 0.8352,                 loss: 0.1043
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3318s / 283.0094 s
agent0:                 episode reward: -0.7746,                 loss: nan
agent1:                 episode reward: 0.7746,                 loss: 0.1047
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3078s / 283.3172 s
agent0:                 episode reward: -0.9029,                 loss: nan
agent1:                 episode reward: 0.9029,                 loss: 0.1060
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3066s / 283.6238 s
agent0:                 episode reward: -0.8648,                 loss: nan
agent1:                 episode reward: 0.8648,                 loss: 0.1077
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3513s / 283.9750 s
agent0:                 episode reward: -0.6141,                 loss: nan
agent1:                 episode reward: 0.6141,                 loss: 0.1055
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 284.2929 s
agent0:                 episode reward: -0.7416,                 loss: nan
agent1:                 episode reward: 0.7416,                 loss: 0.1046
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3060s / 284.5988 s
agent0:                 episode reward: -0.8074,                 loss: nan
agent1:                 episode reward: 0.8074,                 loss: 0.1063
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3104s / 284.9092 s
agent0:                 episode reward: -0.7343,                 loss: nan
agent1:                 episode reward: 0.7343,                 loss: 0.1061
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 285.2199 s
agent0:                 episode reward: -0.2382,                 loss: nan
agent1:                 episode reward: 0.2382,                 loss: 0.1056
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3106s / 285.5304 s
agent0:                 episode reward: -0.5258,                 loss: nan
agent1:                 episode reward: 0.5258,                 loss: 0.1059
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3112s / 285.8417 s
agent0:                 episode reward: -0.7552,                 loss: nan
agent1:                 episode reward: 0.7552,                 loss: 0.1053
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 286.1563 s
agent0:                 episode reward: -0.8331,                 loss: nan
agent1:                 episode reward: 0.8331,                 loss: 0.1041
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3188s / 286.4751 s
agent0:                 episode reward: -0.6317,                 loss: nan
agent1:                 episode reward: 0.6317,                 loss: 0.1052
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3292s / 286.8043 s
agent0:                 episode reward: -0.7210,                 loss: nan
agent1:                 episode reward: 0.7210,                 loss: 0.1046
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3296s / 287.1339 s
agent0:                 episode reward: -0.6195,                 loss: nan
agent1:                 episode reward: 0.6195,                 loss: 0.1049
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3152s / 287.4492 s
agent0:                 episode reward: -0.5110,                 loss: nan
agent1:                 episode reward: 0.5110,                 loss: 0.1049
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3043s / 287.7534 s
agent0:                 episode reward: -0.2559,                 loss: nan
agent1:                 episode reward: 0.2559,                 loss: 0.1052
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3119s / 288.0653 s
agent0:                 episode reward: -0.6393,                 loss: nan
agent1:                 episode reward: 0.6393,                 loss: 0.1045
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 288.3785 s
agent0:                 episode reward: -0.1444,                 loss: nan
agent1:                 episode reward: 0.1444,                 loss: 0.1034
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3112s / 288.6898 s
agent0:                 episode reward: -0.6690,                 loss: nan
agent1:                 episode reward: 0.6690,                 loss: 0.1049
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3043s / 288.9940 s
agent0:                 episode reward: -0.2303,                 loss: nan
agent1:                 episode reward: 0.2303,                 loss: 0.1053
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3656s / 289.3596 s
agent0:                 episode reward: -0.6868,                 loss: nan
agent1:                 episode reward: 0.6868,                 loss: 0.1049
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3154s / 289.6750 s
agent0:                 episode reward: -0.5824,                 loss: nan
agent1:                 episode reward: 0.5824,                 loss: 0.1038
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3368s / 290.0118 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.1049
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 290.3255 s
agent0:                 episode reward: -0.6124,                 loss: nan
agent1:                 episode reward: 0.6124,                 loss: 0.1034
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3380s / 290.6636 s
agent0:                 episode reward: -0.7700,                 loss: nan
agent1:                 episode reward: 0.7700,                 loss: 0.1051
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3156s / 290.9792 s
agent0:                 episode reward: -0.4280,                 loss: nan
agent1:                 episode reward: 0.4280,                 loss: 0.1040
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3144s / 291.2936 s
agent0:                 episode reward: -0.6687,                 loss: nan
agent1:                 episode reward: 0.6687,                 loss: 0.1041
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3152s / 291.6088 s
agent0:                 episode reward: -0.4496,                 loss: nan
agent1:                 episode reward: 0.4496,                 loss: 0.1037
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3156s / 291.9244 s
agent0:                 episode reward: -0.7139,                 loss: nan
agent1:                 episode reward: 0.7139,                 loss: 0.1057
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3139s / 292.2383 s
agent0:                 episode reward: -0.7286,                 loss: nan
agent1:                 episode reward: 0.7286,                 loss: 0.1043
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3130s / 292.5512 s
agent0:                 episode reward: -0.4177,                 loss: nan
agent1:                 episode reward: 0.4177,                 loss: 0.1037
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 292.8660 s
agent0:                 episode reward: -0.2663,                 loss: nan
agent1:                 episode reward: 0.2663,                 loss: 0.1063
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3247s / 293.1906 s
agent0:                 episode reward: -0.7336,                 loss: nan
agent1:                 episode reward: 0.7336,                 loss: 0.1056
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3095s / 293.5001 s
agent0:                 episode reward: -0.6755,                 loss: nan
agent1:                 episode reward: 0.6755,                 loss: 0.1049
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3044s / 293.8045 s
agent0:                 episode reward: -0.4702,                 loss: nan
agent1:                 episode reward: 0.4702,                 loss: 0.1041
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3073s / 294.1118 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.1065
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3040s / 294.4159 s
agent0:                 episode reward: -0.7665,                 loss: nan
agent1:                 episode reward: 0.7665,                 loss: 0.1051
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3066s / 294.7224 s
agent0:                 episode reward: -0.6724,                 loss: nan
agent1:                 episode reward: 0.6724,                 loss: 0.1049
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3250s / 295.0474 s
agent0:                 episode reward: -0.5217,                 loss: nan
agent1:                 episode reward: 0.5217,                 loss: 0.1045
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3028s / 295.3502 s
agent0:                 episode reward: -0.4028,                 loss: nan
agent1:                 episode reward: 0.4028,                 loss: 0.1047
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3014s / 295.6516 s
agent0:                 episode reward: -0.8538,                 loss: nan
agent1:                 episode reward: 0.8538,                 loss: 0.1040
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3053s / 295.9569 s
agent0:                 episode reward: -0.4421,                 loss: nan
agent1:                 episode reward: 0.4421,                 loss: 0.1048
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3037s / 296.2606 s
agent0:                 episode reward: -0.7381,                 loss: nan
agent1:                 episode reward: 0.7381,                 loss: 0.1037
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3095s / 296.5701 s
agent0:                 episode reward: -0.8687,                 loss: nan
agent1:                 episode reward: 0.8687,                 loss: 0.1059
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3200s / 296.8901 s
agent0:                 episode reward: -0.4723,                 loss: nan
agent1:                 episode reward: 0.4723,                 loss: 0.1041
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3209s / 297.2110 s
agent0:                 episode reward: -0.3653,                 loss: nan
agent1:                 episode reward: 0.3653,                 loss: 0.1045
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3162s / 297.5272 s
agent0:                 episode reward: -0.9598,                 loss: nan
agent1:                 episode reward: 0.9598,                 loss: 0.1049
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 297.8506 s
agent0:                 episode reward: -0.7283,                 loss: nan
agent1:                 episode reward: 0.7283,                 loss: 0.1048
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3194s / 298.1700 s
agent0:                 episode reward: -0.7327,                 loss: nan
agent1:                 episode reward: 0.7327,                 loss: 0.1033
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3172s / 298.4872 s
agent0:                 episode reward: -0.5088,                 loss: nan
agent1:                 episode reward: 0.5088,                 loss: 0.1043
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3463s / 298.8335 s
agent0:                 episode reward: -1.1275,                 loss: nan
agent1:                 episode reward: 1.1275,                 loss: 0.1052
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3341s / 299.1676 s
agent0:                 episode reward: -0.5810,                 loss: nan
agent1:                 episode reward: 0.5810,                 loss: 0.1057
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3244s / 299.4921 s
agent0:                 episode reward: -0.8042,                 loss: nan
agent1:                 episode reward: 0.8042,                 loss: 0.1038
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 299.8162 s
agent0:                 episode reward: -0.4710,                 loss: nan
agent1:                 episode reward: 0.4710,                 loss: 0.1042
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3238s / 300.1400 s
agent0:                 episode reward: -0.7789,                 loss: nan
agent1:                 episode reward: 0.7789,                 loss: 0.1047
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3156s / 300.4556 s
agent0:                 episode reward: -0.9040,                 loss: nan
agent1:                 episode reward: 0.9040,                 loss: 0.1063
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3205s / 300.7761 s
agent0:                 episode reward: -0.9011,                 loss: nan
agent1:                 episode reward: 0.9011,                 loss: 0.1049
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3173s / 301.0934 s
agent0:                 episode reward: -0.8642,                 loss: nan
agent1:                 episode reward: 0.8642,                 loss: 0.1043
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3132s / 301.4066 s
agent0:                 episode reward: -0.8350,                 loss: nan
agent1:                 episode reward: 0.8350,                 loss: 0.1057
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3140s / 301.7206 s
agent0:                 episode reward: -0.4895,                 loss: nan
agent1:                 episode reward: 0.4895,                 loss: 0.1039
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3481s / 302.0687 s
agent0:                 episode reward: -0.6866,                 loss: nan
agent1:                 episode reward: 0.6866,                 loss: 0.1040
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 302.3889 s
agent0:                 episode reward: -0.5762,                 loss: nan
agent1:                 episode reward: 0.5762,                 loss: 0.1034
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3119s / 302.7008 s
agent0:                 episode reward: -0.4803,                 loss: nan
agent1:                 episode reward: 0.4803,                 loss: 0.1056
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3152s / 303.0160 s
agent0:                 episode reward: -0.6629,                 loss: nan
agent1:                 episode reward: 0.6629,                 loss: 0.1059
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3136s / 303.3296 s
agent0:                 episode reward: -0.8160,                 loss: nan
agent1:                 episode reward: 0.8160,                 loss: 0.1036
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3125s / 303.6421 s
agent0:                 episode reward: -0.9939,                 loss: nan
agent1:                 episode reward: 0.9939,                 loss: 0.1040
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3222s / 303.9643 s
agent0:                 episode reward: -0.8438,                 loss: nan
agent1:                 episode reward: 0.8438,                 loss: 0.1039
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3142s / 304.2785 s
agent0:                 episode reward: -0.5930,                 loss: nan
agent1:                 episode reward: 0.5930,                 loss: 0.1042
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3116s / 304.5901 s
agent0:                 episode reward: -0.9631,                 loss: nan
agent1:                 episode reward: 0.9631,                 loss: 0.1054
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3243s / 304.9143 s
agent0:                 episode reward: -0.3688,                 loss: nan
agent1:                 episode reward: 0.3688,                 loss: 0.1031
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3380s / 305.2523 s
agent0:                 episode reward: -0.6349,                 loss: nan
agent1:                 episode reward: 0.6349,                 loss: 0.1037
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3146s / 305.5669 s
agent0:                 episode reward: -0.3803,                 loss: nan
agent1:                 episode reward: 0.3803,                 loss: 0.1027
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3193s / 305.8862 s
agent0:                 episode reward: -0.3795,                 loss: nan
agent1:                 episode reward: 0.3795,                 loss: 0.1040
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3153s / 306.2015 s
agent0:                 episode reward: -0.4510,                 loss: nan
agent1:                 episode reward: 0.4510,                 loss: 0.1042
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3176s / 306.5191 s
agent0:                 episode reward: -0.5621,                 loss: nan
agent1:                 episode reward: 0.5621,                 loss: 0.1031
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3221s / 306.8412 s
agent0:                 episode reward: -0.6877,                 loss: nan
agent1:                 episode reward: 0.6877,                 loss: 0.1030
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3288s / 307.1700 s
agent0:                 episode reward: -0.8144,                 loss: nan
agent1:                 episode reward: 0.8144,                 loss: 0.1035
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3169s / 307.4869 s
agent0:                 episode reward: -0.6216,                 loss: nan
agent1:                 episode reward: 0.6216,                 loss: 0.1042
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3214s / 307.8083 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.1052
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3416s / 308.1499 s
agent0:                 episode reward: -0.8062,                 loss: nan
agent1:                 episode reward: 0.8062,                 loss: 0.1036
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3134s / 308.4633 s
agent0:                 episode reward: -0.5523,                 loss: nan
agent1:                 episode reward: 0.5523,                 loss: 0.1054
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 308.7811 s
agent0:                 episode reward: -0.6822,                 loss: nan
agent1:                 episode reward: 0.6822,                 loss: 0.1038
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3188s / 309.0999 s
agent0:                 episode reward: -0.2915,                 loss: nan
agent1:                 episode reward: 0.2915,                 loss: 0.1047
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3233s / 309.4232 s
agent0:                 episode reward: -0.4354,                 loss: nan
agent1:                 episode reward: 0.4354,                 loss: 0.1039
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3181s / 309.7413 s
agent0:                 episode reward: -0.7537,                 loss: nan
agent1:                 episode reward: 0.7537,                 loss: 0.1044
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 310.0591 s
agent0:                 episode reward: -0.5034,                 loss: nan
agent1:                 episode reward: 0.5034,                 loss: 0.1043
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3161s / 310.3752 s
agent0:                 episode reward: -0.6044,                 loss: nan
agent1:                 episode reward: 0.6044,                 loss: 0.1051
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3185s / 310.6938 s
agent0:                 episode reward: -0.7922,                 loss: nan
agent1:                 episode reward: 0.7922,                 loss: 0.1033
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3318s / 311.0256 s
agent0:                 episode reward: -0.9970,                 loss: nan
agent1:                 episode reward: 0.9970,                 loss: 0.1038
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3370s / 311.3626 s
agent0:                 episode reward: -0.6968,                 loss: nan
agent1:                 episode reward: 0.6968,                 loss: 0.1044
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3163s / 311.6789 s
agent0:                 episode reward: -0.5894,                 loss: nan
agent1:                 episode reward: 0.5894,                 loss: 0.1036
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3239s / 312.0028 s
agent0:                 episode reward: -0.9857,                 loss: nan
agent1:                 episode reward: 0.9857,                 loss: 0.1039
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3128s / 312.3156 s
agent0:                 episode reward: -0.4627,                 loss: nan
agent1:                 episode reward: 0.4627,                 loss: 0.1039
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3261s / 312.6417 s
agent0:                 episode reward: -0.8122,                 loss: nan
agent1:                 episode reward: 0.8122,                 loss: 0.1041
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3284s / 312.9701 s
agent0:                 episode reward: -0.7977,                 loss: nan
agent1:                 episode reward: 0.7977,                 loss: 0.1022
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3335s / 313.3036 s
agent0:                 episode reward: -0.6041,                 loss: nan
agent1:                 episode reward: 0.6041,                 loss: 0.1052
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3366s / 313.6401 s
agent0:                 episode reward: -0.7131,                 loss: nan
agent1:                 episode reward: 0.7131,                 loss: 0.1067
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3288s / 313.9690 s
agent0:                 episode reward: -0.7223,                 loss: nan
agent1:                 episode reward: 0.7223,                 loss: 0.1052
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3504s / 314.3194 s
agent0:                 episode reward: -0.5833,                 loss: nan
agent1:                 episode reward: 0.5833,                 loss: 0.1066
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3259s / 314.6453 s
agent0:                 episode reward: -0.7069,                 loss: nan
agent1:                 episode reward: 0.7069,                 loss: 0.1039
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3232s / 314.9685 s
agent0:                 episode reward: -0.6444,                 loss: nan
agent1:                 episode reward: 0.6444,                 loss: 0.1058
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3244s / 315.2929 s
agent0:                 episode reward: -0.7286,                 loss: nan
agent1:                 episode reward: 0.7286,                 loss: 0.1062
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3570s / 315.6499 s
agent0:                 episode reward: -0.6125,                 loss: nan
agent1:                 episode reward: 0.6125,                 loss: 0.1058
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3338s / 315.9837 s
agent0:                 episode reward: -0.6370,                 loss: nan
agent1:                 episode reward: 0.6370,                 loss: 0.1054
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 316.3201 s
agent0:                 episode reward: -1.0283,                 loss: nan
agent1:                 episode reward: 1.0283,                 loss: 0.1044
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3345s / 316.6546 s
agent0:                 episode reward: -0.8120,                 loss: nan
agent1:                 episode reward: 0.8120,                 loss: 0.1052
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3401s / 316.9947 s
agent0:                 episode reward: -0.5584,                 loss: nan
agent1:                 episode reward: 0.5584,                 loss: 0.1055
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3568s / 317.3515 s
agent0:                 episode reward: -0.5386,                 loss: nan
agent1:                 episode reward: 0.5386,                 loss: 0.1044
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3286s / 317.6801 s
agent0:                 episode reward: -0.5177,                 loss: nan
agent1:                 episode reward: 0.5177,                 loss: 0.1046
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3228s / 318.0029 s
agent0:                 episode reward: -0.8534,                 loss: nan
agent1:                 episode reward: 0.8534,                 loss: 0.1069
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3262s / 318.3291 s
agent0:                 episode reward: -0.6890,                 loss: nan
agent1:                 episode reward: 0.6890,                 loss: 0.1044
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3306s / 318.6597 s
agent0:                 episode reward: -0.8484,                 loss: nan
agent1:                 episode reward: 0.8484,                 loss: 0.1051
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3205s / 318.9802 s
agent0:                 episode reward: -0.8009,                 loss: nan
agent1:                 episode reward: 0.8009,                 loss: 0.1061
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3207s / 319.3009 s
agent0:                 episode reward: -0.4118,                 loss: nan
agent1:                 episode reward: 0.4118,                 loss: 0.1041
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3131s / 319.6140 s
agent0:                 episode reward: -0.8465,                 loss: nan
agent1:                 episode reward: 0.8465,                 loss: 0.1054
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3136s / 319.9276 s
agent0:                 episode reward: -0.3177,                 loss: nan
agent1:                 episode reward: 0.3177,                 loss: 0.1050
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3344s / 320.2619 s
agent0:                 episode reward: -0.7042,                 loss: nan
agent1:                 episode reward: 0.7042,                 loss: 0.1045
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 320.5820 s
agent0:                 episode reward: -0.1526,                 loss: nan
agent1:                 episode reward: 0.1526,                 loss: 0.1045
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3167s / 320.8987 s
agent0:                 episode reward: -0.6477,                 loss: nan
agent1:                 episode reward: 0.6477,                 loss: 0.1060
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3149s / 321.2136 s
agent0:                 episode reward: -0.1547,                 loss: nan
agent1:                 episode reward: 0.1547,                 loss: 0.1048
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3154s / 321.5290 s
agent0:                 episode reward: -0.7352,                 loss: nan
agent1:                 episode reward: 0.7352,                 loss: 0.1051
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3087s / 321.8377 s
agent0:                 episode reward: -0.4062,                 loss: nan
agent1:                 episode reward: 0.4062,                 loss: 0.1047
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 322.1554 s
agent0:                 episode reward: -1.1011,                 loss: nan
agent1:                 episode reward: 1.1011,                 loss: 0.1045
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3112s / 322.4666 s
agent0:                 episode reward: -0.9436,                 loss: nan
agent1:                 episode reward: 0.9436,                 loss: 0.1059
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3092s / 322.7758 s
agent0:                 episode reward: -0.8482,                 loss: nan
agent1:                 episode reward: 0.8482,                 loss: 0.1045
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3115s / 323.0873 s
agent0:                 episode reward: -0.8150,                 loss: nan
agent1:                 episode reward: 0.8150,                 loss: 0.1061
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3528s / 323.4402 s
agent0:                 episode reward: -0.4776,                 loss: nan
agent1:                 episode reward: 0.4776,                 loss: 0.1051
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 323.7580 s
agent0:                 episode reward: -0.8279,                 loss: nan
agent1:                 episode reward: 0.8279,                 loss: 0.1042
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3358s / 324.0937 s
agent0:                 episode reward: -0.4421,                 loss: nan
agent1:                 episode reward: 0.4421,                 loss: 0.1050
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3215s / 324.4152 s
agent0:                 episode reward: -0.6528,                 loss: nan
agent1:                 episode reward: 0.6528,                 loss: 0.1058
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3575s / 324.7728 s
agent0:                 episode reward: -0.4835,                 loss: nan
agent1:                 episode reward: 0.4835,                 loss: 0.1052
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3637s / 325.1364 s
agent0:                 episode reward: -0.8007,                 loss: nan
agent1:                 episode reward: 0.8007,                 loss: 0.1040
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3428s / 325.4793 s
agent0:                 episode reward: -0.6839,                 loss: nan
agent1:                 episode reward: 0.6839,                 loss: 0.1045
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3243s / 325.8035 s
agent0:                 episode reward: -0.6087,                 loss: nan
agent1:                 episode reward: 0.6087,                 loss: 0.1050
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3280s / 326.1315 s
agent0:                 episode reward: -0.6224,                 loss: nan
agent1:                 episode reward: 0.6224,                 loss: 0.1040
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3592s / 326.4907 s
agent0:                 episode reward: -0.7518,                 loss: nan
agent1:                 episode reward: 0.7518,                 loss: 0.1059
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3092s / 326.7999 s
agent0:                 episode reward: -0.8098,                 loss: nan
agent1:                 episode reward: 0.8098,                 loss: 0.1065
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3186s / 327.1185 s
agent0:                 episode reward: -0.9042,                 loss: nan
agent1:                 episode reward: 0.9042,                 loss: 0.1040
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3325s / 327.4509 s
agent0:                 episode reward: -0.8561,                 loss: nan
agent1:                 episode reward: 0.8561,                 loss: 0.1042
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 327.7873 s
agent0:                 episode reward: -0.5924,                 loss: nan
agent1:                 episode reward: 0.5924,                 loss: 0.1051
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3306s / 328.1180 s
agent0:                 episode reward: -0.3850,                 loss: nan
agent1:                 episode reward: 0.3850,                 loss: 0.1047
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3277s / 328.4457 s
agent0:                 episode reward: -0.9451,                 loss: nan
agent1:                 episode reward: 0.9451,                 loss: 0.1053
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3309s / 328.7765 s
agent0:                 episode reward: -0.6608,                 loss: nan
agent1:                 episode reward: 0.6608,                 loss: 0.1044
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3281s / 329.1046 s
agent0:                 episode reward: -0.8006,                 loss: nan
agent1:                 episode reward: 0.8006,                 loss: 0.1062
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3572s / 329.4618 s
agent0:                 episode reward: -0.6503,                 loss: nan
agent1:                 episode reward: 0.6503,                 loss: 0.1044
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3498s / 329.8116 s
agent0:                 episode reward: -0.4749,                 loss: nan
agent1:                 episode reward: 0.4749,                 loss: 0.1044
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 330.1432 s
agent0:                 episode reward: -0.5319,                 loss: nan
agent1:                 episode reward: 0.5319,                 loss: 0.1050
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3282s / 330.4714 s
agent0:                 episode reward: -0.8508,                 loss: nan
agent1:                 episode reward: 0.8508,                 loss: 0.1041
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3259s / 330.7973 s
agent0:                 episode reward: -0.6689,                 loss: nan
agent1:                 episode reward: 0.6689,                 loss: 0.1037
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3166s / 331.1140 s
agent0:                 episode reward: -0.7101,                 loss: nan
agent1:                 episode reward: 0.7101,                 loss: 0.1032
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3216s / 331.4356 s
agent0:                 episode reward: -0.3191,                 loss: nan
agent1:                 episode reward: 0.3191,                 loss: 0.1030
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3223s / 331.7579 s
agent0:                 episode reward: -0.8026,                 loss: nan
agent1:                 episode reward: 0.8026,                 loss: 0.1021
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3247s / 332.0826 s
agent0:                 episode reward: -0.3919,                 loss: nan
agent1:                 episode reward: 0.3919,                 loss: 0.1027
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3386s / 332.4211 s
agent0:                 episode reward: -0.6885,                 loss: nan
agent1:                 episode reward: 0.6885,                 loss: 0.1023
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3620s / 332.7831 s
agent0:                 episode reward: -0.4886,                 loss: nan
agent1:                 episode reward: 0.4886,                 loss: 0.1045
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3328s / 333.1159 s
agent0:                 episode reward: -0.6812,                 loss: nan
agent1:                 episode reward: 0.6812,                 loss: 0.1036
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3346s / 333.4505 s
agent0:                 episode reward: -0.7567,                 loss: nan
agent1:                 episode reward: 0.7567,                 loss: 0.1037
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3342s / 333.7848 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: 0.1048
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3297s / 334.1144 s
agent0:                 episode reward: -0.5458,                 loss: nan
agent1:                 episode reward: 0.5458,                 loss: 0.1031
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3310s / 334.4455 s
agent0:                 episode reward: -0.7035,                 loss: nan
agent1:                 episode reward: 0.7035,                 loss: 0.1038
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3366s / 334.7821 s
agent0:                 episode reward: -0.5329,                 loss: nan
agent1:                 episode reward: 0.5329,                 loss: 0.1036
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3458s / 335.1279 s
agent0:                 episode reward: -0.2500,                 loss: nan
agent1:                 episode reward: 0.2500,                 loss: 0.1048
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3395s / 335.4674 s
agent0:                 episode reward: -0.3516,                 loss: nan
agent1:                 episode reward: 0.3516,                 loss: 0.1043
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3522s / 335.8196 s
agent0:                 episode reward: -0.4233,                 loss: nan
agent1:                 episode reward: 0.4233,                 loss: 0.1041
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3310s / 336.1506 s
agent0:                 episode reward: -0.4804,                 loss: nan
agent1:                 episode reward: 0.4804,                 loss: 0.1051
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3365s / 336.4872 s
agent0:                 episode reward: -0.5808,                 loss: nan
agent1:                 episode reward: 0.5808,                 loss: 0.1051
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3363s / 336.8235 s
agent0:                 episode reward: -0.4598,                 loss: nan
agent1:                 episode reward: 0.4598,                 loss: 0.1037
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3348s / 337.1582 s
agent0:                 episode reward: -0.5925,                 loss: nan
agent1:                 episode reward: 0.5925,                 loss: 0.1054
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3338s / 337.4921 s
agent0:                 episode reward: -0.5618,                 loss: nan
agent1:                 episode reward: 0.5618,                 loss: 0.1044
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3320s / 337.8240 s
agent0:                 episode reward: -0.7842,                 loss: nan
agent1:                 episode reward: 0.7842,                 loss: 0.1028
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3185s / 338.1425 s
agent0:                 episode reward: -0.6997,                 loss: nan
agent1:                 episode reward: 0.6997,                 loss: 0.1057
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 338.4659 s
agent0:                 episode reward: -0.6138,                 loss: nan
agent1:                 episode reward: 0.6138,                 loss: 0.1033
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3584s / 338.8243 s
agent0:                 episode reward: -1.1061,                 loss: nan
agent1:                 episode reward: 1.1061,                 loss: 0.1040
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3363s / 339.1606 s
agent0:                 episode reward: -0.6967,                 loss: nan
agent1:                 episode reward: 0.6967,                 loss: 0.1029
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 339.4939 s
agent0:                 episode reward: -0.6868,                 loss: nan
agent1:                 episode reward: 0.6868,                 loss: 0.1027
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3358s / 339.8297 s
agent0:                 episode reward: -0.8346,                 loss: nan
agent1:                 episode reward: 0.8346,                 loss: 0.1046
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3365s / 340.1662 s
agent0:                 episode reward: -0.7833,                 loss: nan
agent1:                 episode reward: 0.7833,                 loss: 0.1039
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3510s / 340.5172 s
agent0:                 episode reward: -0.8554,                 loss: nan
agent1:                 episode reward: 0.8554,                 loss: 0.1050
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3266s / 340.8437 s
agent0:                 episode reward: -0.2299,                 loss: nan
agent1:                 episode reward: 0.2299,                 loss: 0.1040
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3264s / 341.1702 s
agent0:                 episode reward: -0.7387,                 loss: nan
agent1:                 episode reward: 0.7387,                 loss: 0.1044
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3274s / 341.4976 s
agent0:                 episode reward: -0.9234,                 loss: nan
agent1:                 episode reward: 0.9234,                 loss: 0.1028
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3622s / 341.8598 s
agent0:                 episode reward: -0.6170,                 loss: nan
agent1:                 episode reward: 0.6170,                 loss: 0.1041
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3428s / 342.2026 s
agent0:                 episode reward: -0.7618,                 loss: nan
agent1:                 episode reward: 0.7618,                 loss: 0.1036
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3268s / 342.5295 s
agent0:                 episode reward: -0.9966,                 loss: nan
agent1:                 episode reward: 0.9966,                 loss: 0.1039
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3369s / 342.8664 s
agent0:                 episode reward: -0.8830,                 loss: nan
agent1:                 episode reward: 0.8830,                 loss: 0.1037
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3350s / 343.2014 s
agent0:                 episode reward: -0.2796,                 loss: nan
agent1:                 episode reward: 0.2796,                 loss: 0.1026
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3322s / 343.5336 s
agent0:                 episode reward: -0.5658,                 loss: nan
agent1:                 episode reward: 0.5658,                 loss: 0.1033
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3309s / 343.8645 s
agent0:                 episode reward: -0.5897,                 loss: nan
agent1:                 episode reward: 0.5897,                 loss: 0.1033
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 344.2009 s
agent0:                 episode reward: -0.5272,                 loss: nan
agent1:                 episode reward: 0.5272,                 loss: 0.1026
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3413s / 344.5422 s
agent0:                 episode reward: -0.5354,                 loss: nan
agent1:                 episode reward: 0.5354,                 loss: 0.1040
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 344.8786 s
agent0:                 episode reward: -0.4743,                 loss: nan
agent1:                 episode reward: 0.4743,                 loss: 0.1038
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3369s / 345.2156 s
agent0:                 episode reward: -0.7559,                 loss: nan
agent1:                 episode reward: 0.7559,                 loss: 0.1029
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3360s / 345.5516 s
agent0:                 episode reward: -0.8129,                 loss: nan
agent1:                 episode reward: 0.8129,                 loss: 0.1032
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3405s / 345.8921 s
agent0:                 episode reward: -0.6855,                 loss: nan
agent1:                 episode reward: 0.6855,                 loss: 0.1026
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3422s / 346.2343 s
agent0:                 episode reward: -0.8246,                 loss: nan
agent1:                 episode reward: 0.8246,                 loss: 0.1037
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3365s / 346.5708 s
agent0:                 episode reward: -0.4700,                 loss: nan
agent1:                 episode reward: 0.4700,                 loss: 0.1032
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3367s / 346.9075 s
agent0:                 episode reward: -0.7691,                 loss: nan
agent1:                 episode reward: 0.7691,                 loss: 0.1040
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3378s / 347.2453 s
agent0:                 episode reward: -0.2083,                 loss: nan
agent1:                 episode reward: 0.2083,                 loss: 0.1034
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3419s / 347.5872 s
agent0:                 episode reward: -0.8162,                 loss: nan
agent1:                 episode reward: 0.8162,                 loss: 0.1024
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3374s / 347.9246 s
agent0:                 episode reward: -0.9571,                 loss: nan
agent1:                 episode reward: 0.9571,                 loss: 0.1030
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3393s / 348.2639 s
agent0:                 episode reward: -0.6196,                 loss: nan
agent1:                 episode reward: 0.6196,                 loss: 0.1035
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3356s / 348.5995 s
agent0:                 episode reward: -0.4186,                 loss: nan
agent1:                 episode reward: 0.4186,                 loss: 0.1030
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3488s / 348.9483 s
agent0:                 episode reward: -0.6212,                 loss: nan
agent1:                 episode reward: 0.6212,                 loss: 0.1038
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3431s / 349.2914 s
agent0:                 episode reward: -0.4347,                 loss: nan
agent1:                 episode reward: 0.4347,                 loss: 0.1050
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3381s / 349.6294 s
agent0:                 episode reward: -0.7014,                 loss: nan
agent1:                 episode reward: 0.7014,                 loss: 0.1025
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3397s / 349.9691 s
agent0:                 episode reward: -0.5845,                 loss: nan
agent1:                 episode reward: 0.5845,                 loss: 0.1036
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3371s / 350.3062 s
agent0:                 episode reward: -0.7524,                 loss: nan
agent1:                 episode reward: 0.7524,                 loss: 0.1032
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3554s / 350.6616 s
agent0:                 episode reward: -0.9828,                 loss: nan
agent1:                 episode reward: 0.9828,                 loss: 0.1035
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3337s / 350.9953 s
agent0:                 episode reward: -0.7076,                 loss: nan
agent1:                 episode reward: 0.7076,                 loss: 0.1039
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3392s / 351.3345 s
agent0:                 episode reward: -0.4944,                 loss: nan
agent1:                 episode reward: 0.4944,                 loss: 0.1029
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3418s / 351.6763 s
agent0:                 episode reward: -1.0969,                 loss: nan
agent1:                 episode reward: 1.0969,                 loss: 0.1032
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3273s / 352.0036 s
agent0:                 episode reward: -1.0421,                 loss: nan
agent1:                 episode reward: 1.0421,                 loss: 0.1031
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3233s / 352.3269 s
agent0:                 episode reward: -0.4070,                 loss: nan
agent1:                 episode reward: 0.4070,                 loss: 0.1036
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3228s / 352.6497 s
agent0:                 episode reward: -0.7001,                 loss: nan
agent1:                 episode reward: 0.7001,                 loss: 0.1045
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 352.9731 s
agent0:                 episode reward: -0.9451,                 loss: nan
agent1:                 episode reward: 0.9451,                 loss: 0.1049
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3266s / 353.2997 s
agent0:                 episode reward: -0.7202,                 loss: nan
agent1:                 episode reward: 0.7202,                 loss: 0.1039
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3497s / 353.6495 s
agent0:                 episode reward: -0.4462,                 loss: nan
agent1:                 episode reward: 0.4462,                 loss: 0.1043
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3277s / 353.9771 s
agent0:                 episode reward: -0.4512,                 loss: nan
agent1:                 episode reward: 0.4512,                 loss: 0.1023
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3254s / 354.3025 s
agent0:                 episode reward: -0.6568,                 loss: nan
agent1:                 episode reward: 0.6568,                 loss: 0.1041
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3238s / 354.6263 s
agent0:                 episode reward: -0.7264,                 loss: nan
agent1:                 episode reward: 0.7264,                 loss: 0.1061
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3246s / 354.9509 s
agent0:                 episode reward: -0.6514,                 loss: nan
agent1:                 episode reward: 0.6514,                 loss: 0.1040
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3286s / 355.2794 s
agent0:                 episode reward: -0.3462,                 loss: nan
agent1:                 episode reward: 0.3462,                 loss: 0.1046
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3256s / 355.6051 s
agent0:                 episode reward: -0.8136,                 loss: nan
agent1:                 episode reward: 0.8136,                 loss: 0.1040
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3258s / 355.9308 s
agent0:                 episode reward: -0.6641,                 loss: nan
agent1:                 episode reward: 0.6641,                 loss: 0.1026
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 356.2573 s
agent0:                 episode reward: -1.0271,                 loss: nan
agent1:                 episode reward: 1.0271,                 loss: 0.1046
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3479s / 356.6053 s
agent0:                 episode reward: -0.7845,                 loss: nan
agent1:                 episode reward: 0.7845,                 loss: 0.1025
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3310s / 356.9363 s
agent0:                 episode reward: -0.6825,                 loss: nan
agent1:                 episode reward: 0.6825,                 loss: 0.1036
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3513s / 357.2876 s
agent0:                 episode reward: -0.3164,                 loss: nan
agent1:                 episode reward: 0.3164,                 loss: 0.1036
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3349s / 357.6225 s
agent0:                 episode reward: -0.4427,                 loss: nan
agent1:                 episode reward: 0.4427,                 loss: 0.1046
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3339s / 357.9564 s
agent0:                 episode reward: -0.8414,                 loss: nan
agent1:                 episode reward: 0.8414,                 loss: 0.1046
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3394s / 358.2958 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.1036
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3320s / 358.6278 s
agent0:                 episode reward: -0.7129,                 loss: nan
agent1:                 episode reward: 0.7129,                 loss: 0.1033
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3378s / 358.9656 s
agent0:                 episode reward: -0.8551,                 loss: nan
agent1:                 episode reward: 0.8551,                 loss: 0.1036
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3414s / 359.3070 s
agent0:                 episode reward: -0.4182,                 loss: nan
agent1:                 episode reward: 0.4182,                 loss: 0.1050
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3513s / 359.6583 s
agent0:                 episode reward: -0.7089,                 loss: nan
agent1:                 episode reward: 0.7089,                 loss: 0.1027
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3411s / 359.9993 s
agent0:                 episode reward: -0.5070,                 loss: nan
agent1:                 episode reward: 0.5070,                 loss: 0.1036
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3586s / 360.3579 s
agent0:                 episode reward: -0.6773,                 loss: nan
agent1:                 episode reward: 0.6773,                 loss: 0.1027
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3383s / 360.6963 s
agent0:                 episode reward: -0.9212,                 loss: nan
agent1:                 episode reward: 0.9212,                 loss: 0.1041
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3367s / 361.0329 s
agent0:                 episode reward: -0.8387,                 loss: nan
agent1:                 episode reward: 0.8387,                 loss: 0.1034
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3455s / 361.3784 s
agent0:                 episode reward: -0.9692,                 loss: nan
agent1:                 episode reward: 0.9692,                 loss: 0.1047
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3486s / 361.7270 s
agent0:                 episode reward: -0.5344,                 loss: nan
agent1:                 episode reward: 0.5344,                 loss: 0.1044
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3496s / 362.0766 s
agent0:                 episode reward: -0.7594,                 loss: nan
agent1:                 episode reward: 0.7594,                 loss: 0.1039
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3515s / 362.4281 s
agent0:                 episode reward: -0.8265,                 loss: nan
agent1:                 episode reward: 0.8265,                 loss: 0.1036
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3853s / 362.8134 s
agent0:                 episode reward: -0.8771,                 loss: nan
agent1:                 episode reward: 0.8771,                 loss: 0.1045
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3500s / 363.1635 s
agent0:                 episode reward: -0.6181,                 loss: nan
agent1:                 episode reward: 0.6181,                 loss: 0.1022
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3450s / 363.5085 s
agent0:                 episode reward: -1.0070,                 loss: nan
agent1:                 episode reward: 1.0070,                 loss: 0.1028
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3463s / 363.8548 s
agent0:                 episode reward: -0.7227,                 loss: nan
agent1:                 episode reward: 0.7227,                 loss: 0.1039
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3374s / 364.1923 s
agent0:                 episode reward: -0.6380,                 loss: nan
agent1:                 episode reward: 0.6380,                 loss: 0.1036
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3348s / 364.5271 s
agent0:                 episode reward: -0.3938,                 loss: nan
agent1:                 episode reward: 0.3938,                 loss: 0.1048
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3426s / 364.8696 s
agent0:                 episode reward: -0.6284,                 loss: nan
agent1:                 episode reward: 0.6284,                 loss: 0.1033
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3417s / 365.2113 s
agent0:                 episode reward: -0.7517,                 loss: nan
agent1:                 episode reward: 0.7517,                 loss: 0.1024
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3556s / 365.5669 s
agent0:                 episode reward: -0.6541,                 loss: nan
agent1:                 episode reward: 0.6541,                 loss: 0.1027
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3722s / 365.9391 s
agent0:                 episode reward: -0.9772,                 loss: nan
agent1:                 episode reward: 0.9772,                 loss: 0.1040
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3447s / 366.2838 s
agent0:                 episode reward: -0.7838,                 loss: nan
agent1:                 episode reward: 0.7838,                 loss: 0.1036
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3438s / 366.6276 s
agent0:                 episode reward: -0.5187,                 loss: nan
agent1:                 episode reward: 0.5187,                 loss: 0.1029
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3410s / 366.9686 s
agent0:                 episode reward: -0.7541,                 loss: nan
agent1:                 episode reward: 0.7541,                 loss: 0.1040
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3438s / 367.3124 s
agent0:                 episode reward: -0.5926,                 loss: nan
agent1:                 episode reward: 0.5926,                 loss: 0.1042
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3403s / 367.6527 s
agent0:                 episode reward: -0.5245,                 loss: nan
agent1:                 episode reward: 0.5245,                 loss: 0.1030
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3464s / 367.9991 s
agent0:                 episode reward: -0.3655,                 loss: nan
agent1:                 episode reward: 0.3655,                 loss: 0.1028
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3453s / 368.3443 s
agent0:                 episode reward: -0.6304,                 loss: nan
agent1:                 episode reward: 0.6304,                 loss: 0.1039
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3450s / 368.6893 s
agent0:                 episode reward: -0.6567,                 loss: nan
agent1:                 episode reward: 0.6567,                 loss: 0.1030
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3624s / 369.0517 s
agent0:                 episode reward: -0.4314,                 loss: nan
agent1:                 episode reward: 0.4314,                 loss: 0.1029
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3419s / 369.3936 s
agent0:                 episode reward: -0.7450,                 loss: nan
agent1:                 episode reward: 0.7450,                 loss: 0.1042
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3505s / 369.7442 s
agent0:                 episode reward: -0.6085,                 loss: nan
agent1:                 episode reward: 0.6085,                 loss: 0.1035
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3459s / 370.0901 s
agent0:                 episode reward: -0.7029,                 loss: nan
agent1:                 episode reward: 0.7029,                 loss: 0.1057
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3517s / 370.4418 s
agent0:                 episode reward: -0.8695,                 loss: nan
agent1:                 episode reward: 0.8695,                 loss: 0.1033
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3380s / 370.7798 s
agent0:                 episode reward: -0.8604,                 loss: nan
agent1:                 episode reward: 0.8604,                 loss: 0.1036
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3350s / 371.1148 s
agent0:                 episode reward: -0.7282,                 loss: nan
agent1:                 episode reward: 0.7282,                 loss: 0.1037
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3310s / 371.4458 s
agent0:                 episode reward: -0.7245,                 loss: nan
agent1:                 episode reward: 0.7245,                 loss: 0.1038
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3399s / 371.7857 s
agent0:                 episode reward: -0.7156,                 loss: nan
agent1:                 episode reward: 0.7156,                 loss: 0.1044
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3486s / 372.1342 s
agent0:                 episode reward: -0.6496,                 loss: nan
agent1:                 episode reward: 0.6496,                 loss: 0.1036
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 372.4658 s
agent0:                 episode reward: -0.7399,                 loss: nan
agent1:                 episode reward: 0.7399,                 loss: 0.1034
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3332s / 372.7990 s
agent0:                 episode reward: -0.7238,                 loss: nan
agent1:                 episode reward: 0.7238,                 loss: 0.1042
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3324s / 373.1315 s
agent0:                 episode reward: -0.8389,                 loss: nan
agent1:                 episode reward: 0.8389,                 loss: 0.1043
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3334s / 373.4649 s
agent0:                 episode reward: -0.6439,                 loss: nan
agent1:                 episode reward: 0.6439,                 loss: 0.1038
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3494s / 373.8143 s
agent0:                 episode reward: -0.3771,                 loss: nan
agent1:                 episode reward: 0.3771,                 loss: 0.1041
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3434s / 374.1577 s
agent0:                 episode reward: -0.6846,                 loss: nan
agent1:                 episode reward: 0.6846,                 loss: 0.1051
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3432s / 374.5008 s
agent0:                 episode reward: -0.9682,                 loss: nan
agent1:                 episode reward: 0.9682,                 loss: 0.1027
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3591s / 374.8600 s
agent0:                 episode reward: -0.7057,                 loss: nan
agent1:                 episode reward: 0.7057,                 loss: 0.1054
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3716s / 375.2316 s
agent0:                 episode reward: -0.7608,                 loss: nan
agent1:                 episode reward: 0.7608,                 loss: 0.1034
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4146s / 375.6462 s
agent0:                 episode reward: -0.9035,                 loss: nan
agent1:                 episode reward: 0.9035,                 loss: 0.1037
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3555s / 376.0017 s
agent0:                 episode reward: -0.7048,                 loss: nan
agent1:                 episode reward: 0.7048,                 loss: 0.1044
Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3509s / 376.3526 s
agent0:                 episode reward: -0.6435,                 loss: nan
agent1:                 episode reward: 0.6435,                 loss: 0.1041
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3421s / 376.6947 s
agent0:                 episode reward: -0.3284,                 loss: nan
agent1:                 episode reward: 0.3284,                 loss: 0.1031
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3332s / 377.0278 s/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

agent0:                 episode reward: -1.0326,                 loss: nan
agent1:                 episode reward: 1.0326,                 loss: 0.1052
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3303s / 377.3581 s
agent0:                 episode reward: -0.9053,                 loss: nan
agent1:                 episode reward: 0.9053,                 loss: 0.1043
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3317s / 377.6898 s
agent0:                 episode reward: -0.6935,                 loss: nan
agent1:                 episode reward: 0.6935,                 loss: 0.1036
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3722s / 378.0620 s
agent0:                 episode reward: -0.7588,                 loss: nan
agent1:                 episode reward: 0.7588,                 loss: 0.1050
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3457s / 378.4077 s
agent0:                 episode reward: -0.6198,                 loss: nan
agent1:                 episode reward: 0.6198,                 loss: 0.1045
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3423s / 378.7500 s
agent0:                 episode reward: -0.4327,                 loss: nan
agent1:                 episode reward: 0.4327,                 loss: 0.1036
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3461s / 379.0961 s
agent0:                 episode reward: -1.0692,                 loss: nan
agent1:                 episode reward: 1.0692,                 loss: 0.1041
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3485s / 379.4447 s
agent0:                 episode reward: -0.5108,                 loss: nan
agent1:                 episode reward: 0.5108,                 loss: 0.1040
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3533s / 379.7979 s
agent0:                 episode reward: -0.7009,                 loss: nan
agent1:                 episode reward: 0.7009,                 loss: 0.1048
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3455s / 380.1435 s
agent0:                 episode reward: -0.6805,                 loss: nan
agent1:                 episode reward: 0.6805,                 loss: 0.1042
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3572s / 380.5007 s
agent0:                 episode reward: -0.5579,                 loss: nan
agent1:                 episode reward: 0.5579,                 loss: 0.1038
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3484s / 380.8491 s
agent0:                 episode reward: -0.8162,                 loss: nan
agent1:                 episode reward: 0.8162,                 loss: 0.1036
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3818s / 381.2309 s
agent0:                 episode reward: -0.5782,                 loss: nan
agent1:                 episode reward: 0.5782,                 loss: 0.1033
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3511s / 381.5820 s
agent0:                 episode reward: -0.5076,                 loss: nan
agent1:                 episode reward: 0.5076,                 loss: 0.1026
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3496s / 381.9316 s
agent0:                 episode reward: -0.5601,                 loss: nan
agent1:                 episode reward: 0.5601,                 loss: 0.1015
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3631s / 382.2947 s
agent0:                 episode reward: -0.8173,                 loss: nan
agent1:                 episode reward: 0.8173,                 loss: 0.1042
