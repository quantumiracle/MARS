pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
random seed: 91
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f8e844645d0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.224 0.093 0.114 ... 0.    0.    0.   ]
 [0.072 0.011 0.062 ... 0.    0.    0.   ]]
Load checkpoints (policy family):  [['83' '5753' '6419' ... '78946' '79127' '79375']
 ['121' '6342' '6627' ... '78967' '79225' '79437']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220116204408/epi_80000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220116204408_exploit_80000/mdp_arbitrary_mdp_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116204408_exploit_80000/mdp_arbitrary_mdp_nxdo2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.2623s / 1.2623 s
agent0:                 episode reward: -0.8110,                 loss: nan
agent1:                 episode reward: 0.8110,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0958s / 1.3581 s
agent0:                 episode reward: -0.2403,                 loss: nan
agent1:                 episode reward: 0.2403,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0920s / 1.4500 s
agent0:                 episode reward: 0.0023,                 loss: nan
agent1:                 episode reward: -0.0023,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0802s / 1.5303 s
agent0:                 episode reward: 0.0403,                 loss: nan
agent1:                 episode reward: -0.0403,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2734s / 1.8037 s
agent0:                 episode reward: -0.0268,                 loss: nan
agent1:                 episode reward: 0.0268,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3429s / 2.1465 s
agent0:                 episode reward: -0.2879,                 loss: nan
agent1:                 episode reward: 0.2879,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1608s / 2.3073 s
agent0:                 episode reward: 0.6034,                 loss: nan
agent1:                 episode reward: -0.6034,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4378s / 2.7451 s
agent0:                 episode reward: 0.0402,                 loss: nan
agent1:                 episode reward: -0.0402,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1665s / 2.9116 s
agent0:                 episode reward: -0.1931,                 loss: nan
agent1:                 episode reward: 0.1931,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0840s / 2.9956 s
agent0:                 episode reward: -0.1548,                 loss: nan
agent1:                 episode reward: 0.1548,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0793s / 3.0749 s
agent0:                 episode reward: 0.0755,                 loss: nan
agent1:                 episode reward: -0.0755,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 32.7350s / 35.8099 s
agent0:                 episode reward: 0.1891,                 loss: nan
agent1:                 episode reward: -0.1891,                 loss: 0.2633
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 101.3912s / 137.2011 s
agent0:                 episode reward: -0.1234,                 loss: nan
agent1:                 episode reward: 0.1234,                 loss: 0.2258
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.9232s / 237.1243 s
agent0:                 episode reward: 0.2509,                 loss: nan
agent1:                 episode reward: -0.2509,                 loss: 0.1905
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.1993s / 335.3236 s
agent0:                 episode reward: -0.2298,                 loss: nan
agent1:                 episode reward: 0.2298,                 loss: 0.1797
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 99.8120s / 435.1356 s
agent0:                 episode reward: -0.1772,                 loss: nan
agent1:                 episode reward: 0.1772,                 loss: 0.1756
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 100.5754s / 535.7110 s
agent0:                 episode reward: -0.1029,                 loss: nan
agent1:                 episode reward: 0.1029,                 loss: 0.1745
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.8732s / 633.5843 s
agent0:                 episode reward: 0.2432,                 loss: nan
agent1:                 episode reward: -0.2432,                 loss: 0.1711
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 100.9615s / 734.5457 s
agent0:                 episode reward: 0.2357,                 loss: nan
agent1:                 episode reward: -0.2357,                 loss: 0.1685
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 103.6364s / 838.1822 s
agent0:                 episode reward: -0.2723,                 loss: nan
agent1:                 episode reward: 0.2723,                 loss: 0.1663
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.6174s / 937.7996 s
agent0:                 episode reward: 0.1019,                 loss: nan
agent1:                 episode reward: -0.1019,                 loss: 0.1687
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 99.3439s / 1037.1434 s
agent0:                 episode reward: -0.4457,                 loss: nan
agent1:                 episode reward: 0.4457,                 loss: 0.1682
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 100.0481s / 1137.1915 s
agent0:                 episode reward: -0.0023,                 loss: nan
agent1:                 episode reward: 0.0023,                 loss: 0.1677
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 101.7134s / 1238.9049 s
agent0:                 episode reward: 0.1139,                 loss: nan
agent1:                 episode reward: -0.1139,                 loss: 0.1692
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.8079s / 1337.7127 s
agent0:                 episode reward: -0.2678,                 loss: nan
agent1:                 episode reward: 0.2678,                 loss: 0.1650
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 100.4384s / 1438.1512 s
agent0:                 episode reward: 0.0707,                 loss: nan
agent1:                 episode reward: -0.0707,                 loss: 0.1641
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.8230s / 1536.9742 s
agent0:                 episode reward: -0.0090,                 loss: nan
agent1:                 episode reward: 0.0090,                 loss: 0.1642
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 102.9633s / 1639.9374 s
agent0:                 episode reward: -0.3463,                 loss: nan
agent1:                 episode reward: 0.3463,                 loss: 0.1636
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.6860s / 1739.6234 s
agent0:                 episode reward: 0.4656,                 loss: nan
agent1:                 episode reward: -0.4656,                 loss: 0.1778
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 102.8332s / 1842.4566 s
agent0:                 episode reward: -0.0611,                 loss: nan
agent1:                 episode reward: 0.0611,                 loss: 0.1648
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.4545s / 1940.9111 s
agent0:                 episode reward: -0.3047,                 loss: nan
agent1:                 episode reward: 0.3047,                 loss: 0.1608
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 98.4809s / 2039.3920 s
agent0:                 episode reward: -0.3637,                 loss: nan
agent1:                 episode reward: 0.3637,                 loss: 0.1617
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.3158s / 2138.7078 s
agent0:                 episode reward: 0.0405,                 loss: nan
agent1:                 episode reward: -0.0405,                 loss: 0.1609
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 97.6552s / 2236.3631 s
agent0:                 episode reward: 0.3003,                 loss: nan
agent1:                 episode reward: -0.3003,                 loss: 0.1603
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 100.9149s / 2337.2779 s
agent0:                 episode reward: -0.0979,                 loss: nan
agent1:                 episode reward: 0.0979,                 loss: 0.1586
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.3500s / 2436.6279 s
agent0:                 episode reward: 0.2024,                 loss: nan
agent1:                 episode reward: -0.2024,                 loss: 0.1589
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 99.2194s / 2535.8474 s
agent0:                 episode reward: 0.0461,                 loss: nan
agent1:                 episode reward: -0.0461,                 loss: 0.1588
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 102.2639s / 2638.1113 s
agent0:                 episode reward: 0.0255,                 loss: nan
agent1:                 episode reward: -0.0255,                 loss: 0.1580
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 107.0498s / 2745.1611 s
agent0:                 episode reward: -0.3496,                 loss: nan
agent1:                 episode reward: 0.3496,                 loss: 0.1600
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1200s / 2877.2811 s
agent0:                 episode reward: 0.0164,                 loss: nan
agent1:                 episode reward: -0.0164,                 loss: 0.1587
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1643s / 3014.4454 s
agent0:                 episode reward: -0.0705,                 loss: nan
agent1:                 episode reward: 0.0705,                 loss: 0.1591
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7636s / 3155.2090 s
agent0:                 episode reward: 0.4471,                 loss: nan
agent1:                 episode reward: -0.4471,                 loss: 0.1574
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1283s / 3291.3373 s
agent0:                 episode reward: 0.2113,                 loss: nan
agent1:                 episode reward: -0.2113,                 loss: 0.1577
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9270s / 3427.2643 s
agent0:                 episode reward: 0.1748,                 loss: nan
agent1:                 episode reward: -0.1748,                 loss: 0.1591
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4231s / 3564.6874 s
agent0:                 episode reward: 0.6433,                 loss: nan
agent1:                 episode reward: -0.6433,                 loss: 0.1601
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8231s / 3700.5105 s
agent0:                 episode reward: -0.0522,                 loss: nan
agent1:                 episode reward: 0.0522,                 loss: 0.1575
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0739s / 3838.5844 s
agent0:                 episode reward: 0.2151,                 loss: nan
agent1:                 episode reward: -0.2151,                 loss: 0.1554
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2312s / 3974.8156 s
agent0:                 episode reward: 0.0566,                 loss: nan
agent1:                 episode reward: -0.0566,                 loss: 0.1553
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0916s / 4112.9072 s
agent0:                 episode reward: 0.1705,                 loss: nan
agent1:                 episode reward: -0.1705,                 loss: 0.1547
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9753s / 4248.8826 s
agent0:                 episode reward: 0.3714,                 loss: nan
agent1:                 episode reward: -0.3714,                 loss: 0.1556
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9638s / 4383.8464 s
agent0:                 episode reward: 0.0200,                 loss: nan
agent1:                 episode reward: -0.0200,                 loss: 0.1551
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1799s / 4524.0263 s
agent0:                 episode reward: -0.1849,                 loss: nan
agent1:                 episode reward: 0.1849,                 loss: 0.1550
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5223s / 4660.5485 s
agent0:                 episode reward: -0.3219,                 loss: nan
agent1:                 episode reward: 0.3219,                 loss: 0.1547
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9011s / 4801.4496 s
agent0:                 episode reward: 0.0735,                 loss: nan
agent1:                 episode reward: -0.0735,                 loss: 0.1566
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4467s / 4941.8963 s
agent0:                 episode reward: 0.2577,                 loss: nan
agent1:                 episode reward: -0.2577,                 loss: 0.1557
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8400s / 5084.7364 s
agent0:                 episode reward: 0.2590,                 loss: nan
agent1:                 episode reward: -0.2590,                 loss: 0.1538
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8344s / 5222.5708 s
agent0:                 episode reward: -0.3514,                 loss: nan
agent1:                 episode reward: 0.3514,                 loss: 0.1553
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3605s / 5363.9313 s
agent0:                 episode reward: 0.0925,                 loss: nan
agent1:                 episode reward: -0.0925,                 loss: 0.1550
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6210s / 5503.5523 s
agent0:                 episode reward: -0.0872,                 loss: nan
agent1:                 episode reward: 0.0872,                 loss: 0.1555
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1853s / 5643.7377 s
agent0:                 episode reward: 0.3472,                 loss: nan
agent1:                 episode reward: -0.3472,                 loss: 0.1552
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1376s / 5779.8753 s
agent0:                 episode reward: 0.0258,                 loss: nan
agent1:                 episode reward: -0.0258,                 loss: 0.1543
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2087s / 5921.0840 s
agent0:                 episode reward: 0.5104,                 loss: nan
agent1:                 episode reward: -0.5104,                 loss: 0.1550
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1914s / 6062.2753 s
agent0:                 episode reward: -0.1925,                 loss: nan
agent1:                 episode reward: 0.1925,                 loss: 0.1582
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2215s / 6203.4969 s
agent0:                 episode reward: -0.3069,                 loss: nan
agent1:                 episode reward: 0.3069,                 loss: 0.1587
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2150s / 6344.7118 s
agent0:                 episode reward: -0.0112,                 loss: nan
agent1:                 episode reward: 0.0112,                 loss: 0.1577
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8406s / 6479.5524 s
agent0:                 episode reward: 0.2824,                 loss: nan
agent1:                 episode reward: -0.2824,                 loss: 0.1571
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4638s / 6617.0163 s
agent0:                 episode reward: -0.3693,                 loss: nan
agent1:                 episode reward: 0.3693,                 loss: 0.1584
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2967s / 6753.3130 s
agent0:                 episode reward: -0.0148,                 loss: nan
agent1:                 episode reward: 0.0148,                 loss: 0.1569
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9106s / 6889.2236 s
agent0:                 episode reward: 0.0676,                 loss: nan
agent1:                 episode reward: -0.0676,                 loss: 0.1561
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7665s / 7028.9901 s
agent0:                 episode reward: 0.3831,                 loss: nan
agent1:                 episode reward: -0.3831,                 loss: 0.1551
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8583s / 7167.8484 s
agent0:                 episode reward: -0.0937,                 loss: nan
agent1:                 episode reward: 0.0937,                 loss: 0.1566
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5423s / 7306.3907 s
agent0:                 episode reward: 0.5515,                 loss: nan
agent1:                 episode reward: -0.5515,                 loss: 0.1563
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4207s / 7446.8114 s
agent0:                 episode reward: -0.0675,                 loss: nan
agent1:                 episode reward: 0.0675,                 loss: 0.1554
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9848s / 7586.7963 s
agent0:                 episode reward: 0.1032,                 loss: nan
agent1:                 episode reward: -0.1032,                 loss: 0.1555
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9227s / 7724.7190 s
agent0:                 episode reward: -0.1184,                 loss: nan
agent1:                 episode reward: 0.1184,                 loss: 0.1544
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7916s / 7864.5106 s
agent0:                 episode reward: -0.2449,                 loss: nan
agent1:                 episode reward: 0.2449,                 loss: 0.1564
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3128s / 8002.8234 s
agent0:                 episode reward: -0.0158,                 loss: nan
agent1:                 episode reward: 0.0158,                 loss: 0.1558
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7066s / 8141.5300 s
agent0:                 episode reward: 0.1401,                 loss: nan
agent1:                 episode reward: -0.1401,                 loss: 0.1553
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5208s / 8279.0509 s
agent0:                 episode reward: -0.4139,                 loss: nan
agent1:                 episode reward: 0.4139,                 loss: 0.1541
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3755s / 8418.4263 s
agent0:                 episode reward: -0.0588,                 loss: nan
agent1:                 episode reward: 0.0588,                 loss: 0.1550
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4209s / 8557.8472 s
agent0:                 episode reward: 0.2396,                 loss: nan
agent1:                 episode reward: -0.2396,                 loss: 0.1529
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2754s / 8698.1226 s
agent0:                 episode reward: 0.3384,                 loss: nan
agent1:                 episode reward: -0.3384,                 loss: 0.1554
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1241s / 8838.2467 s
agent0:                 episode reward: 0.0784,                 loss: nan
agent1:                 episode reward: -0.0784,                 loss: 0.1558
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6978s / 8976.9445 s
agent0:                 episode reward: -0.3902,                 loss: nan
agent1:                 episode reward: 0.3902,                 loss: 0.1547
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8373s / 9115.7818 s
agent0:                 episode reward: -0.0904,                 loss: nan
agent1:                 episode reward: 0.0904,                 loss: 0.1549
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6970s / 9255.4789 s
agent0:                 episode reward: 0.1272,                 loss: nan
agent1:                 episode reward: -0.1272,                 loss: 0.1552
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2494s / 9395.7283 s
agent0:                 episode reward: 0.5316,                 loss: nan
agent1:                 episode reward: -0.5316,                 loss: 0.1545
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5246s / 9536.2529 s
agent0:                 episode reward: -0.1989,                 loss: nan
agent1:                 episode reward: 0.1989,                 loss: 0.1545
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9415s / 9672.1944 s
agent0:                 episode reward: 0.2394,                 loss: nan
agent1:                 episode reward: -0.2394,                 loss: 0.1548
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8307s / 9812.0250 s
agent0:                 episode reward: -0.2134,                 loss: nan
agent1:                 episode reward: 0.2134,                 loss: 0.1526
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9565s / 9950.9815 s
agent0:                 episode reward: -0.0984,                 loss: nan
agent1:                 episode reward: 0.0984,                 loss: 0.1535
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5987s / 10086.5802 s
agent0:                 episode reward: 0.3813,                 loss: nan
agent1:                 episode reward: -0.3813,                 loss: 0.1540
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9523s / 10227.5325 s
agent0:                 episode reward: -0.3066,                 loss: nan
agent1:                 episode reward: 0.3066,                 loss: 0.1542
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0073s / 10364.5398 s
agent0:                 episode reward: -0.0718,                 loss: nan
agent1:                 episode reward: 0.0718,                 loss: 0.1548
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3929s / 10504.9328 s
agent0:                 episode reward: 0.1701,                 loss: nan
agent1:                 episode reward: -0.1701,                 loss: 0.1542
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5801s / 10643.5128 s
agent0:                 episode reward: -0.1960,                 loss: nan
agent1:                 episode reward: 0.1960,                 loss: 0.1575
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7147s / 10786.2275 s
agent0:                 episode reward: -0.1049,                 loss: nan
agent1:                 episode reward: 0.1049,                 loss: 0.1556
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1971s / 10921.4246 s
agent0:                 episode reward: 0.0181,                 loss: nan
agent1:                 episode reward: -0.0181,                 loss: 0.1559
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9869s / 11061.4115 s
agent0:                 episode reward: -0.2236,                 loss: nan
agent1:                 episode reward: 0.2236,                 loss: 0.1553
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4067s / 11202.8182 s
agent0:                 episode reward: 0.0879,                 loss: nan
agent1:                 episode reward: -0.0879,                 loss: 0.1554
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8600s / 11340.6782 s
agent0:                 episode reward: 0.2026,                 loss: nan
agent1:                 episode reward: -0.2026,                 loss: 0.1566
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2734s / 11476.9516 s
agent0:                 episode reward: 0.0273,                 loss: nan
agent1:                 episode reward: -0.0273,                 loss: 0.1555
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0386s / 11615.9902 s
agent0:                 episode reward: 0.0375,                 loss: nan
agent1:                 episode reward: -0.0375,                 loss: 0.1551
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2825s / 11754.2727 s
agent0:                 episode reward: -0.2787,                 loss: nan
agent1:                 episode reward: 0.2787,                 loss: 0.1554
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8666s / 11894.1394 s
agent0:                 episode reward: -0.1035,                 loss: nan
agent1:                 episode reward: 0.1035,                 loss: 0.1557
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0211s / 12031.1605 s
agent0:                 episode reward: 0.1471,                 loss: nan
agent1:                 episode reward: -0.1471,                 loss: 0.1552
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1912s / 12169.3517 s
agent0:                 episode reward: 0.4215,                 loss: nan
agent1:                 episode reward: -0.4215,                 loss: 0.1562
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.5664s / 12313.9181 s
agent0:                 episode reward: 0.1878,                 loss: nan
agent1:                 episode reward: -0.1878,                 loss: 0.1538
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1062s / 12456.0243 s
agent0:                 episode reward: -0.2748,                 loss: nan
agent1:                 episode reward: 0.2748,                 loss: 0.1566
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1807s / 12597.2051 s
agent0:                 episode reward: -0.0084,                 loss: nan
agent1:                 episode reward: 0.0084,                 loss: 0.1550
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4865s / 12740.6915 s
agent0:                 episode reward: -0.1482,                 loss: nan
agent1:                 episode reward: 0.1482,                 loss: 0.1549
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.8800s / 12885.5716 s
agent0:                 episode reward: 0.0521,                 loss: nan
agent1:                 episode reward: -0.0521,                 loss: 0.1546
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6468s / 13026.2183 s
agent0:                 episode reward: -0.1179,                 loss: nan
agent1:                 episode reward: 0.1179,                 loss: 0.1552
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.7570s / 13170.9753 s
agent0:                 episode reward: 0.1989,                 loss: nan
agent1:                 episode reward: -0.1989,                 loss: 0.1565
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3191s / 13310.2944 s
agent0:                 episode reward: 0.1515,                 loss: nan
agent1:                 episode reward: -0.1515,                 loss: 0.1566
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7910s / 13451.0854 s
agent0:                 episode reward: -0.3844,                 loss: nan
agent1:                 episode reward: 0.3844,                 loss: 0.1558
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.6087s / 13594.6941 s
agent0:                 episode reward: -0.1693,                 loss: nan
agent1:                 episode reward: 0.1693,                 loss: 0.1546
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.2350s / 13736.9291 s
agent0:                 episode reward: 0.0628,                 loss: nan
agent1:                 episode reward: -0.0628,                 loss: 0.1548
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8072s / 13877.7364 s
agent0:                 episode reward: 0.1088,                 loss: nan
agent1:                 episode reward: -0.1088,                 loss: 0.1565
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6253s / 14019.3616 s
agent0:                 episode reward: -0.1725,                 loss: nan
agent1:                 episode reward: 0.1725,                 loss: 0.1561
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5895s / 14162.9511 s
agent0:                 episode reward: -0.0365,                 loss: nan
agent1:                 episode reward: 0.0365,                 loss: 0.1536
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3600s / 14302.3110 s
agent0:                 episode reward: -0.2536,                 loss: nan
agent1:                 episode reward: 0.2536,                 loss: 0.1540
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2825s / 14441.5936 s
agent0:                 episode reward: 0.2520,                 loss: nan
agent1:                 episode reward: -0.2520,                 loss: 0.1554
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5353s / 14584.1289 s
agent0:                 episode reward: -0.1002,                 loss: nan
agent1:                 episode reward: 0.1002,                 loss: 0.1548
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8744s / 14725.0033 s
agent0:                 episode reward: 0.1881,                 loss: nan
agent1:                 episode reward: -0.1881,                 loss: 0.1557
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8738s / 14866.8772 s
agent0:                 episode reward: -0.1822,                 loss: nan
agent1:                 episode reward: 0.1822,                 loss: 0.1565
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8436s / 15009.7208 s
agent0:                 episode reward: -0.1718,                 loss: nan
agent1:                 episode reward: 0.1718,                 loss: 0.1554
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9270s / 15150.6477 s
agent0:                 episode reward: -0.1398,                 loss: nan
agent1:                 episode reward: 0.1398,                 loss: 0.1569
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5589s / 15291.2067 s
agent0:                 episode reward: -0.3986,                 loss: nan
agent1:                 episode reward: 0.3986,                 loss: 0.1530
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7033s / 15431.9100 s
agent0:                 episode reward: -0.0739,                 loss: nan
agent1:                 episode reward: 0.0739,                 loss: 0.1537
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6905s / 15573.6005 s
agent0:                 episode reward: -0.0488,                 loss: nan
agent1:                 episode reward: 0.0488,                 loss: 0.1545
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.3699s / 15718.9704 s
agent0:                 episode reward: 0.4547,                 loss: nan
agent1:                 episode reward: -0.4547,                 loss: 0.1524
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.0470s / 15860.0174 s
agent0:                 episode reward: -0.1557,                 loss: nan
agent1:                 episode reward: 0.1557,                 loss: 0.1515
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5550s / 16002.5724 s
agent0:                 episode reward: -0.1095,                 loss: nan
agent1:                 episode reward: 0.1095,                 loss: 0.1530
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5780s / 16146.1505 s
agent0:                 episode reward: -0.2231,                 loss: nan
agent1:                 episode reward: 0.2231,                 loss: 0.1510
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1661s / 16288.3165 s
agent0:                 episode reward: 0.2604,                 loss: nan
agent1:                 episode reward: -0.2604,                 loss: 0.1537
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2542s / 16431.5707 s
agent0:                 episode reward: 0.0966,                 loss: nan
agent1:                 episode reward: -0.0966,                 loss: 0.1506
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2951s / 16574.8659 s
agent0:                 episode reward: 0.2478,                 loss: nan
agent1:                 episode reward: -0.2478,                 loss: 0.1542
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0984s / 16711.9642 s
agent0:                 episode reward: -0.0864,                 loss: nan
agent1:                 episode reward: 0.0864,                 loss: 0.1528
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.6383s / 16855.6025 s
agent0:                 episode reward: -0.5659,                 loss: nan
agent1:                 episode reward: 0.5659,                 loss: 0.1528
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3476s / 16993.9501 s
agent0:                 episode reward: 0.0114,                 loss: nan
agent1:                 episode reward: -0.0114,                 loss: 0.1519
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6321s / 17133.5822 s
agent0:                 episode reward: 0.0581,                 loss: nan
agent1:                 episode reward: -0.0581,                 loss: 0.1528
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3004s / 17272.8826 s
agent0:                 episode reward: -0.5344,                 loss: nan
agent1:                 episode reward: 0.5344,                 loss: 0.1517
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2090s / 17413.0916 s
agent0:                 episode reward: -0.2071,                 loss: nan
agent1:                 episode reward: 0.2071,                 loss: 0.1531
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5455s / 17555.6372 s
agent0:                 episode reward: 0.1977,                 loss: nan
agent1:                 episode reward: -0.1977,                 loss: 0.1538
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6764s / 17694.3136 s
agent0:                 episode reward: -0.2791,                 loss: nan
agent1:                 episode reward: 0.2791,                 loss: 0.1542
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.0932s / 17836.4068 s
agent0:                 episode reward: -0.1453,                 loss: nan
agent1:                 episode reward: 0.1453,                 loss: 0.1526
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4097s / 17975.8165 s
agent0:                 episode reward: 0.4605,                 loss: nan
agent1:                 episode reward: -0.4605,                 loss: 0.1540
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8637s / 18114.6802 s
agent0:                 episode reward: 0.3426,                 loss: nan
agent1:                 episode reward: -0.3426,                 loss: 0.1530
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2822s / 18254.9624 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: 0.1532
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.2006s / 18397.1629 s
agent0:                 episode reward: 0.3596,                 loss: nan
agent1:                 episode reward: -0.3596,                 loss: 0.1544
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0707s / 18537.2337 s
agent0:                 episode reward: 0.3981,                 loss: nan
agent1:                 episode reward: -0.3981,                 loss: 0.1519
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9886s / 18676.2223 s
agent0:                 episode reward: 0.1323,                 loss: nan
agent1:                 episode reward: -0.1323,                 loss: 0.1543
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 147.2140s / 18823.4363 s
agent0:                 episode reward: -0.0940,                 loss: nan
agent1:                 episode reward: 0.0940,                 loss: 0.1529
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2581s / 18964.6944 s
agent0:                 episode reward: -0.0283,                 loss: nan
agent1:                 episode reward: 0.0283,                 loss: 0.1529
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3487s / 19104.0430 s
agent0:                 episode reward: -0.1975,                 loss: nan
agent1:                 episode reward: 0.1975,                 loss: 0.1547
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6247s / 19244.6678 s
agent0:                 episode reward: -0.7658,                 loss: nan
agent1:                 episode reward: 0.7658,                 loss: 0.1536
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.5696s / 19389.2374 s
agent0:                 episode reward: 0.0728,                 loss: nan
agent1:                 episode reward: -0.0728,                 loss: 0.1542
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1318s / 19529.3692 s
agent0:                 episode reward: -0.0876,                 loss: nan
agent1:                 episode reward: 0.0876,                 loss: 0.1543
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.5299s / 19673.8991 s
agent0:                 episode reward: -0.2988,                 loss: nan
agent1:                 episode reward: 0.2988,                 loss: 0.1522
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5972s / 19816.4964 s
agent0:                 episode reward: -0.0957,                 loss: nan
agent1:                 episode reward: 0.0957,                 loss: 0.1536
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2774s / 19956.7737 s
agent0:                 episode reward: -0.0138,                 loss: nan
agent1:                 episode reward: 0.0138,                 loss: 0.1530
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0188s / 20096.7925 s
agent0:                 episode reward: 0.0174,                 loss: nan
agent1:                 episode reward: -0.0174,                 loss: 0.1556
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4351s / 20236.2276 s
agent0:                 episode reward: -0.1115,                 loss: nan
agent1:                 episode reward: 0.1115,                 loss: 0.1564
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.8285s / 20381.0561 s
agent0:                 episode reward: -0.2089,                 loss: nan
agent1:                 episode reward: 0.2089,                 loss: 0.1553
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9058s / 20520.9619 s
agent0:                 episode reward: -0.4510,                 loss: nan
agent1:                 episode reward: 0.4510,                 loss: 0.1559
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1910s / 20662.1529 s
agent0:                 episode reward: -0.5163,                 loss: nan
agent1:                 episode reward: 0.5163,                 loss: 0.1576
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9220s / 20801.0749 s
agent0:                 episode reward: 0.0469,                 loss: nan
agent1:                 episode reward: -0.0469,                 loss: 0.1547
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3532s / 20936.4281 s
agent0:                 episode reward: 0.0597,                 loss: nan
agent1:                 episode reward: -0.0597,                 loss: 0.1573
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 130.6765s / 21067.1045 s
agent0:                 episode reward: -0.3752,                 loss: nan
agent1:                 episode reward: 0.3752,                 loss: 0.1548
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7665s / 21200.8710 s
agent0:                 episode reward: -0.4775,                 loss: nan
agent1:                 episode reward: 0.4775,                 loss: 0.1571
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.5666s / 21345.4376 s
agent0:                 episode reward: -0.2830,                 loss: nan
agent1:                 episode reward: 0.2830,                 loss: 0.1552
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0069s / 21488.4445 s
agent0:                 episode reward: -0.2042,                 loss: nan
agent1:                 episode reward: 0.2042,                 loss: 0.1543
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 146.1310s / 21634.5755 s
agent0:                 episode reward: -0.0703,                 loss: nan
agent1:                 episode reward: 0.0703,                 loss: 0.1555
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4316s / 21778.0071 s
agent0:                 episode reward: -0.3398,                 loss: nan
agent1:                 episode reward: 0.3398,                 loss: 0.1568
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.6072s / 21922.6142 s
agent0:                 episode reward: 0.1756,                 loss: nan
agent1:                 episode reward: -0.1756,                 loss: 0.1554
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6748s / 22063.2891 s
agent0:                 episode reward: -0.1871,                 loss: nan
agent1:                 episode reward: 0.1871,                 loss: 0.1562
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8234s / 22204.1125 s
agent0:                 episode reward: -0.5028,                 loss: nan
agent1:                 episode reward: 0.5028,                 loss: 0.1566
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8040s / 22347.9165 s
agent0:                 episode reward: -0.1026,                 loss: nan
agent1:                 episode reward: 0.1026,                 loss: 0.1574
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.6061s / 22491.5226 s
agent0:                 episode reward: -0.1655,                 loss: nan
agent1:                 episode reward: 0.1655,                 loss: 0.1583
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8470s / 22634.3697 s
agent0:                 episode reward: -0.0583,                 loss: nan
agent1:                 episode reward: 0.0583,                 loss: 0.1568
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8764s / 22777.2461 s
agent0:                 episode reward: 0.1357,                 loss: nan
agent1:                 episode reward: -0.1357,                 loss: 0.1577
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.1614s / 22921.4075 s
agent0:                 episode reward: 0.4716,                 loss: nan
agent1:                 episode reward: -0.4716,                 loss: 0.1571
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 145.0769s / 23066.4844 s
agent0:                 episode reward: 0.1056,                 loss: nan
agent1:                 episode reward: -0.1056,                 loss: 0.1570
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.9845s / 23209.4689 s
agent0:                 episode reward: 0.4068,                 loss: nan
agent1:                 episode reward: -0.4068,                 loss: 0.1576
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8004s / 23349.2693 s
agent0:                 episode reward: 0.1175,                 loss: nan
agent1:                 episode reward: -0.1175,                 loss: 0.1583
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5478s / 23491.8171 s
agent0:                 episode reward: -0.4338,                 loss: nan
agent1:                 episode reward: 0.4338,                 loss: 0.1575
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9720s / 23633.7892 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.1589
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4011s / 23777.1903 s
agent0:                 episode reward: -0.0153,                 loss: nan
agent1:                 episode reward: 0.0153,                 loss: 0.1568
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.0966s / 23919.2870 s
agent0:                 episode reward: -0.0020,                 loss: nan
agent1:                 episode reward: 0.0020,                 loss: 0.1585
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.9136s / 24062.2006 s
agent0:                 episode reward: -0.4824,                 loss: nan
agent1:                 episode reward: 0.4824,                 loss: 0.1574
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4382s / 24204.6388 s
agent0:                 episode reward: -0.1735,                 loss: nan
agent1:                 episode reward: 0.1735,                 loss: 0.1562
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1604s / 24346.7992 s
agent0:                 episode reward: 0.1106,                 loss: nan
agent1:                 episode reward: -0.1106,                 loss: 0.1577
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8162s / 24487.6154 s
agent0:                 episode reward: -0.0186,                 loss: nan
agent1:                 episode reward: 0.0186,                 loss: 0.1560
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5864s / 24631.2018 s
agent0:                 episode reward: -0.1971,                 loss: nan
agent1:                 episode reward: 0.1971,                 loss: 0.1569
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7447s / 24772.9464 s
agent0:                 episode reward: -0.2854,                 loss: nan
agent1:                 episode reward: 0.2854,                 loss: 0.1560
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 145.8094s / 24918.7558 s
agent0:                 episode reward: 0.3018,                 loss: nan
agent1:                 episode reward: -0.3018,                 loss: 0.1574
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.0270s / 25062.7828 s
agent0:                 episode reward: -0.0327,                 loss: nan
agent1:                 episode reward: 0.0327,                 loss: 0.1575
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.9003s / 25205.6831 s
agent0:                 episode reward: -0.1529,                 loss: nan
agent1:                 episode reward: 0.1529,                 loss: 0.1572
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1142s / 25347.7973 s
agent0:                 episode reward: -0.0178,                 loss: nan
agent1:                 episode reward: 0.0178,                 loss: 0.1586
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4353s / 25491.2326 s
agent0:                 episode reward: -0.4616,                 loss: nan
agent1:                 episode reward: 0.4616,                 loss: 0.1559
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 146.2899s / 25637.5225 s
agent0:                 episode reward: 0.1973,                 loss: nan
agent1:                 episode reward: -0.1973,                 loss: 0.1577
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.2532s / 25779.7757 s
agent0:                 episode reward: -0.4371,                 loss: nan
agent1:                 episode reward: 0.4371,                 loss: 0.1558
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.8711s / 25925.6468 s
agent0:                 episode reward: -0.3373,                 loss: nan
agent1:                 episode reward: 0.3373,                 loss: 0.1567
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5241s / 26068.1709 s
agent0:                 episode reward: -0.0729,                 loss: nan
agent1:                 episode reward: 0.0729,                 loss: 0.1575
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2432s / 26209.4141 s
agent0:                 episode reward: 0.3473,                 loss: nan
agent1:                 episode reward: -0.3473,                 loss: 0.1559
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5720s / 26349.9861 s
agent0:                 episode reward: 0.2484,                 loss: nan
agent1:                 episode reward: -0.2484,                 loss: 0.1553
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 145.7558s / 26495.7419 s
agent0:                 episode reward: 0.1840,                 loss: nan
agent1:                 episode reward: -0.1840,                 loss: 0.1543
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 145.6492s / 26641.3911 s
agent0:                 episode reward: 0.0794,                 loss: nan
agent1:                 episode reward: -0.0794,                 loss: 0.1570
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8450s / 26785.2361 s
agent0:                 episode reward: -0.0924,                 loss: nan
agent1:                 episode reward: 0.0924,                 loss: 0.1566
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 147.8342s / 26933.0703 s
agent0:                 episode reward: -0.4006,                 loss: nan
agent1:                 episode reward: 0.4006,                 loss: 0.1571
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6806s / 27074.7509 s
agent0:                 episode reward: -0.4478,                 loss: nan
agent1:                 episode reward: 0.4478,                 loss: 0.1561
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.4789s / 27220.2298 s
agent0:                 episode reward: -0.3994,                 loss: nan
agent1:                 episode reward: 0.3994,                 loss: 0.1556
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2823s / 27360.5121 s
agent0:                 episode reward: -0.0862,                 loss: nan
agent1:                 episode reward: 0.0862,                 loss: 0.1540
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3462s / 27494.8582 s
agent0:                 episode reward: -0.2141,                 loss: nan
agent1:                 episode reward: 0.2141,                 loss: 0.1561
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5566s / 27628.4148 s
agent0:                 episode reward: 0.1787,                 loss: nan
agent1:                 episode reward: -0.1787,                 loss: 0.1544
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0665s / 27763.4813 s
agent0:                 episode reward: 0.2100,                 loss: nan
agent1:                 episode reward: -0.2100,                 loss: 0.1555
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3180s / 27898.7992 s
agent0:                 episode reward: 0.0074,                 loss: nan
agent1:                 episode reward: -0.0074,                 loss: 0.1542
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7305s / 28034.5298 s
agent0:                 episode reward: -0.0511,                 loss: nan
agent1:                 episode reward: 0.0511,                 loss: 0.1559
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5930s / 28168.1227 s
agent0:                 episode reward: -0.5074,                 loss: nan
agent1:                 episode reward: 0.5074,                 loss: 0.1560
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2153s / 28301.3380 s
agent0:                 episode reward: 0.0396,                 loss: nan
agent1:                 episode reward: -0.0396,                 loss: 0.1522
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7178s / 28435.0558 s
agent0:                 episode reward: -0.1910,                 loss: nan
agent1:                 episode reward: 0.1910,                 loss: 0.1543
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0274s / 28573.0832 s
agent0:                 episode reward: -0.1239,                 loss: nan
agent1:                 episode reward: 0.1239,                 loss: 0.1537
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2355s / 28708.3187 s
agent0:                 episode reward: -0.0591,                 loss: nan
agent1:                 episode reward: 0.0591,                 loss: 0.1554
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5136s / 28842.8323 s
agent0:                 episode reward: 0.5511,                 loss: nan
agent1:                 episode reward: -0.5511,                 loss: 0.1540
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4620s / 28976.2943 s
agent0:                 episode reward: -0.0764,                 loss: nan
agent1:                 episode reward: 0.0764,                 loss: 0.1551
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3661s / 29110.6604 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.1562
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0016s / 29242.6620 s
agent0:                 episode reward: -0.1867,                 loss: nan
agent1:                 episode reward: 0.1867,                 loss: 0.1558
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8531s / 29380.5151 s
agent0:                 episode reward: -0.1258,                 loss: nan
agent1:                 episode reward: 0.1258,                 loss: 0.1584
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2188s / 29519.7339 s
agent0:                 episode reward: -0.2313,                 loss: nan
agent1:                 episode reward: 0.2313,                 loss: 0.1564
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0913s / 29652.8252 s
agent0:                 episode reward: -0.0153,                 loss: nan
agent1:                 episode reward: 0.0153,                 loss: 0.1597
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7249s / 29789.5501 s
agent0:                 episode reward: -0.1019,                 loss: nan
agent1:                 episode reward: 0.1019,                 loss: 0.1580
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1360s / 29923.6862 s
agent0:                 episode reward: -0.1738,                 loss: nan
agent1:                 episode reward: 0.1738,                 loss: 0.1581
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2156s / 30057.9017 s
agent0:                 episode reward: -0.1142,                 loss: nan
agent1:                 episode reward: 0.1142,                 loss: 0.1587
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8831s / 30192.7848 s
agent0:                 episode reward: -0.1321,                 loss: nan
agent1:                 episode reward: 0.1321,                 loss: 0.1575
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2610s / 30326.0458 s
agent0:                 episode reward: -0.5736,                 loss: nan
agent1:                 episode reward: 0.5736,                 loss: 0.1586
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3638s / 30460.4096 s
agent0:                 episode reward: -0.7414,                 loss: nan
agent1:                 episode reward: 0.7414,                 loss: 0.1577
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7144s / 30593.1240 s
agent0:                 episode reward: 0.0361,                 loss: nan
agent1:                 episode reward: -0.0361,                 loss: 0.1581
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0026s / 30726.1266 s
agent0:                 episode reward: 0.0643,                 loss: nan
agent1:                 episode reward: -0.0643,                 loss: 0.1592
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9666s / 30861.0933 s
agent0:                 episode reward: -0.0671,                 loss: nan
agent1:                 episode reward: 0.0671,                 loss: 0.1576
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8064s / 30993.8997 s
agent0:                 episode reward: -0.1234,                 loss: nan
agent1:                 episode reward: 0.1234,                 loss: 0.1584
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8261s / 31126.7258 s
agent0:                 episode reward: 0.1168,                 loss: nan
agent1:                 episode reward: -0.1168,                 loss: 0.1570
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2688s / 31262.9946 s
agent0:                 episode reward: -0.1359,                 loss: nan
agent1:                 episode reward: 0.1359,                 loss: 0.1570
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0389s / 31399.0335 s
agent0:                 episode reward: -0.4873,                 loss: nan
agent1:                 episode reward: 0.4873,                 loss: 0.1574
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2008s / 31537.2344 s
agent0:                 episode reward: -0.0717,                 loss: nan
agent1:                 episode reward: 0.0717,                 loss: 0.1590
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4320s / 31673.6664 s
agent0:                 episode reward: -0.3784,                 loss: nan
agent1:                 episode reward: 0.3784,                 loss: 0.1560
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4154s / 31806.0818 s
agent0:                 episode reward: -0.6031,                 loss: nan
agent1:                 episode reward: 0.6031,                 loss: 0.1560
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9921s / 31938.0739 s
agent0:                 episode reward: -0.5399,                 loss: nan
agent1:                 episode reward: 0.5399,                 loss: 0.1546
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.2359s / 32068.3098 s
agent0:                 episode reward: -0.0728,                 loss: nan
agent1:                 episode reward: 0.0728,                 loss: 0.1568
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9407s / 32201.2505 s
agent0:                 episode reward: -0.3488,                 loss: nan
agent1:                 episode reward: 0.3488,                 loss: 0.1555
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7477s / 32338.9982 s
agent0:                 episode reward: 0.0222,                 loss: nan
agent1:                 episode reward: -0.0222,                 loss: 0.1550
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6300s / 32474.6282 s
agent0:                 episode reward: -0.0554,                 loss: nan
agent1:                 episode reward: 0.0554,                 loss: 0.1564
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8576s / 32609.4858 s
agent0:                 episode reward: -0.2390,                 loss: nan
agent1:                 episode reward: 0.2390,                 loss: 0.1567
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6061s / 32745.0919 s
agent0:                 episode reward: -0.5228,                 loss: nan
agent1:                 episode reward: 0.5228,                 loss: 0.1552
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7888s / 32876.8807 s
agent0:                 episode reward: -0.5354,                 loss: nan
agent1:                 episode reward: 0.5354,                 loss: 0.1563
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5162s / 33010.3969 s
agent0:                 episode reward: -0.4845,                 loss: nan
agent1:                 episode reward: 0.4845,                 loss: 0.1555
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6971s / 33145.0940 s
agent0:                 episode reward: -0.1136,                 loss: nan
agent1:                 episode reward: 0.1136,                 loss: 0.1557
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5549s / 33280.6490 s
agent0:                 episode reward: -0.2472,                 loss: nan
agent1:                 episode reward: 0.2472,                 loss: 0.1557
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 130.7836s / 33411.4326 s
agent0:                 episode reward: 0.0514,                 loss: nan
agent1:                 episode reward: -0.0514,                 loss: 0.1548
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6354s / 33548.0680 s
agent0:                 episode reward: 0.3306,                 loss: nan
agent1:                 episode reward: -0.3306,                 loss: 0.1550
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0136s / 33683.0816 s
agent0:                 episode reward: -0.1193,                 loss: nan
agent1:                 episode reward: 0.1193,                 loss: 0.1567
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9641s / 33816.0457 s
agent0:                 episode reward: -0.5204,                 loss: nan
agent1:                 episode reward: 0.5204,                 loss: 0.1544
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6984s / 33950.7441 s
agent0:                 episode reward: -0.1093,                 loss: nan
agent1:                 episode reward: 0.1093,                 loss: 0.1534
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0900s / 34087.8341 s
agent0:                 episode reward: -0.0093,                 loss: nan
agent1:                 episode reward: 0.0093,                 loss: 0.1543
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8564s / 34224.6905 s
agent0:                 episode reward: 0.0915,                 loss: nan
agent1:                 episode reward: -0.0915,                 loss: 0.1539
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4072s / 34359.0976 s
agent0:                 episode reward: 0.0311,                 loss: nan
agent1:                 episode reward: -0.0311,                 loss: 0.1533
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1473s / 34491.2450 s
agent0:                 episode reward: -0.2336,                 loss: nan
agent1:                 episode reward: 0.2336,                 loss: 0.1556
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8737s / 34624.1186 s
agent0:                 episode reward: -0.3032,                 loss: nan
agent1:                 episode reward: 0.3032,                 loss: 0.1546
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8875s / 34757.0061 s
agent0:                 episode reward: 0.1004,                 loss: nan
agent1:                 episode reward: -0.1004,                 loss: 0.1555
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9223s / 34891.9284 s
agent0:                 episode reward: -0.1156,                 loss: nan
agent1:                 episode reward: 0.1156,                 loss: 0.1528
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0273s / 35027.9557 s
agent0:                 episode reward: -0.2967,                 loss: nan
agent1:                 episode reward: 0.2967,                 loss: 0.1548
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0993s / 35160.0550 s
agent0:                 episode reward: -0.1738,                 loss: nan
agent1:                 episode reward: 0.1738,                 loss: 0.1545
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6834s / 35297.7384 s
agent0:                 episode reward: 0.4282,                 loss: nan
agent1:                 episode reward: -0.4282,                 loss: 0.1550
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7530s / 35432.4914 s
agent0:                 episode reward: -0.0892,                 loss: nan
agent1:                 episode reward: 0.0892,                 loss: 0.1567
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4628s / 35569.9542 s
agent0:                 episode reward: -0.0060,                 loss: nan
agent1:                 episode reward: 0.0060,                 loss: 0.1545
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9369s / 35703.8911 s
agent0:                 episode reward: 0.1701,                 loss: nan
agent1:                 episode reward: -0.1701,                 loss: 0.1542
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 130.6682s / 35834.5593 s
agent0:                 episode reward: -0.3341,                 loss: nan
agent1:                 episode reward: 0.3341,                 loss: 0.1548
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7542s / 35969.3135 s
agent0:                 episode reward: -0.5502,                 loss: nan
agent1:                 episode reward: 0.5502,                 loss: 0.1546
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5092s / 36103.8227 s
agent0:                 episode reward: -0.5363,                 loss: nan
agent1:                 episode reward: 0.5363,                 loss: 0.1569
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.5122s / 36235.3349 s
agent0:                 episode reward: -0.2377,                 loss: nan
agent1:                 episode reward: 0.2377,                 loss: 0.1600
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4867s / 36370.8215 s
agent0:                 episode reward: -0.0793,                 loss: nan
agent1:                 episode reward: 0.0793,                 loss: 0.1592
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3378s / 36506.1593 s
agent0:                 episode reward: 0.0985,                 loss: nan
agent1:                 episode reward: -0.0985,                 loss: 0.1591
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8666s / 36641.0259 s
agent0:                 episode reward: -0.2748,                 loss: nan
agent1:                 episode reward: 0.2748,                 loss: 0.1604
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5132s / 36774.5391 s
agent0:                 episode reward: -0.4354,                 loss: nan
agent1:                 episode reward: 0.4354,                 loss: 0.1608
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4901s / 36912.0293 s
agent0:                 episode reward: -0.6005,                 loss: nan
agent1:                 episode reward: 0.6005,                 loss: 0.1597
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8739s / 37046.9032 s
agent0:                 episode reward: -0.4634,                 loss: nan
agent1:                 episode reward: 0.4634,                 loss: 0.1613
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3641s / 37182.2673 s
agent0:                 episode reward: 0.0652,                 loss: nan
agent1:                 episode reward: -0.0652,                 loss: 0.1605
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9300s / 37316.1973 s
agent0:                 episode reward: -0.0205,                 loss: nan
agent1:                 episode reward: 0.0205,                 loss: 0.1577
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4599s / 37452.6572 s
agent0:                 episode reward: -0.2302,                 loss: nan
agent1:                 episode reward: 0.2302,                 loss: 0.1589
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3699s / 37589.0271 s
agent0:                 episode reward: -0.1867,                 loss: nan
agent1:                 episode reward: 0.1867,                 loss: 0.1590
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4577s / 37724.4848 s
agent0:                 episode reward: -0.1131,                 loss: nan
agent1:                 episode reward: 0.1131,                 loss: 0.1593
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8033s / 37862.2881 s
agent0:                 episode reward: -0.3019,                 loss: nan
agent1:                 episode reward: 0.3019,                 loss: 0.1595
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5267s / 37995.8148 s
agent0:                 episode reward: -0.4535,                 loss: nan
agent1:                 episode reward: 0.4535,                 loss: 0.1585
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8475s / 38130.6623 s
agent0:                 episode reward: -0.4957,                 loss: nan
agent1:                 episode reward: 0.4957,                 loss: 0.1595
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4607s / 38268.1230 s
agent0:                 episode reward: -0.4904,                 loss: nan
agent1:                 episode reward: 0.4904,                 loss: 0.1587
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3371s / 38405.4601 s
agent0:                 episode reward: -0.2214,                 loss: nan
agent1:                 episode reward: 0.2214,                 loss: 0.1558
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9393s / 38538.3994 s
agent0:                 episode reward: -0.2223,                 loss: nan
agent1:                 episode reward: 0.2223,                 loss: 0.1551
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7053s / 38673.1047 s
agent0:                 episode reward: -0.0317,                 loss: nan
agent1:                 episode reward: 0.0317,                 loss: 0.1558
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9377s / 38807.0424 s
agent0:                 episode reward: -0.1386,                 loss: nan
agent1:                 episode reward: 0.1386,                 loss: 0.1558
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0650s / 38941.1074 s
agent0:                 episode reward: -0.2422,                 loss: nan
agent1:                 episode reward: 0.2422,                 loss: 0.1538
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3065s / 39079.4138 s
agent0:                 episode reward: -0.2018,                 loss: nan
agent1:                 episode reward: 0.2018,                 loss: 0.1565
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7700s / 39217.1838 s
agent0:                 episode reward: 0.0473,                 loss: nan
agent1:                 episode reward: -0.0473,                 loss: 0.1551
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1776s / 39350.3614 s
agent0:                 episode reward: -0.4344,                 loss: nan
agent1:                 episode reward: 0.4344,                 loss: 0.1545
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9459s / 39484.3073 s
agent0:                 episode reward: -0.0627,                 loss: nan
agent1:                 episode reward: 0.0627,                 loss: 0.1556
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4600s / 39620.7673 s
agent0:                 episode reward: 0.1380,                 loss: nan
agent1:                 episode reward: -0.1380,                 loss: 0.1557
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7073s / 39757.4745 s
agent0:                 episode reward: -0.1182,                 loss: nan
agent1:                 episode reward: 0.1182,                 loss: 0.1562
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4180s / 39895.8925 s
agent0:                 episode reward: 0.0065,                 loss: nan
agent1:                 episode reward: -0.0065,                 loss: 0.1544
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7946s / 40031.6871 s
agent0:                 episode reward: 0.0373,                 loss: nan
agent1:                 episode reward: -0.0373,                 loss: 0.1557
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0538s / 40167.7409 s
agent0:                 episode reward: -0.2362,                 loss: nan
agent1:                 episode reward: 0.2362,                 loss: 0.1564
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8541s / 40302.5950 s
agent0:                 episode reward: -0.4365,                 loss: nan
agent1:                 episode reward: 0.4365,                 loss: 0.1565
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5937s / 40435.1887 s
agent0:                 episode reward: -0.1729,                 loss: nan
agent1:                 episode reward: 0.1729,                 loss: 0.1556
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9279s / 40568.1166 s
agent0:                 episode reward: -0.3339,                 loss: nan
agent1:                 episode reward: 0.3339,                 loss: 0.1569
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5949s / 40705.7116 s
agent0:                 episode reward: -0.5941,                 loss: nan
agent1:                 episode reward: 0.5941,                 loss: 0.1538
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2747s / 40846.9863 s
agent0:                 episode reward: 0.1431,                 loss: nan
agent1:                 episode reward: -0.1431,                 loss: 0.1554
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0914s / 40980.0777 s
agent0:                 episode reward: -0.1483,                 loss: nan
agent1:                 episode reward: 0.1483,                 loss: 0.1541
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7729s / 41115.8505 s
agent0:                 episode reward: -0.4232,                 loss: nan
agent1:                 episode reward: 0.4232,                 loss: 0.1559
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9757s / 41251.8262 s
agent0:                 episode reward: -0.5609,                 loss: nan
agent1:                 episode reward: 0.5609,                 loss: 0.1564
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0774s / 41387.9036 s
agent0:                 episode reward: 0.0885,                 loss: nan
agent1:                 episode reward: -0.0885,                 loss: 0.1547
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2054s / 41521.1090 s
agent0:                 episode reward: -0.2261,                 loss: nan
agent1:                 episode reward: 0.2261,                 loss: 0.1558
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4801s / 41653.5892 s
agent0:                 episode reward: -0.4747,                 loss: nan
agent1:                 episode reward: 0.4747,                 loss: 0.1553
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5003s / 41788.0895 s
agent0:                 episode reward: -0.5819,                 loss: nan
agent1:                 episode reward: 0.5819,                 loss: 0.1545
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8248s / 41923.9143 s
agent0:                 episode reward: -0.2028,                 loss: nan
agent1:                 episode reward: 0.2028,                 loss: 0.1565
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1155s / 42060.0298 s
agent0:                 episode reward: -0.1858,                 loss: nan
agent1:                 episode reward: 0.1858,                 loss: 0.1530
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7181s / 42192.7478 s
agent0:                 episode reward: -0.1941,                 loss: nan
agent1:                 episode reward: 0.1941,                 loss: 0.1541
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2766s / 42328.0244 s
agent0:                 episode reward: -0.3881,                 loss: nan
agent1:                 episode reward: 0.3881,                 loss: 0.1562
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7241s / 42465.7484 s
agent0:                 episode reward: 0.1811,                 loss: nan
agent1:                 episode reward: -0.1811,                 loss: 0.1568
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7907s / 42600.5392 s
agent0:                 episode reward: -0.5267,                 loss: nan
agent1:                 episode reward: 0.5267,                 loss: 0.1562
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0433s / 42735.5824 s
agent0:                 episode reward: -0.5614,                 loss: nan
agent1:                 episode reward: 0.5614,                 loss: 0.1538
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5480s / 42868.1305 s
agent0:                 episode reward: 0.0584,                 loss: nan
agent1:                 episode reward: -0.0584,                 loss: 0.1549
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3342s / 43001.4647 s
agent0:                 episode reward: -0.1953,                 loss: nan
agent1:                 episode reward: 0.1953,                 loss: 0.1575
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4242s / 43134.8889 s
agent0:                 episode reward: -0.3427,                 loss: nan
agent1:                 episode reward: 0.3427,                 loss: 0.1574
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4223s / 43270.3111 s
agent0:                 episode reward: -0.1887,                 loss: nan
agent1:                 episode reward: 0.1887,                 loss: 0.1558
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2666s / 43405.5777 s
agent0:                 episode reward: -0.4342,                 loss: nan
agent1:                 episode reward: 0.4342,                 loss: 0.1570
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0854s / 43540.6631 s
agent0:                 episode reward: -0.5045,                 loss: nan
agent1:                 episode reward: 0.5045,                 loss: 0.1573
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3902s / 43674.0533 s
agent0:                 episode reward: -0.3877,                 loss: nan
agent1:                 episode reward: 0.3877,                 loss: 0.1596
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7971s / 43805.8504 s
agent0:                 episode reward: -0.2918,                 loss: nan
agent1:                 episode reward: 0.2918,                 loss: 0.1557
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3305s / 43939.1808 s
agent0:                 episode reward: -0.1764,                 loss: nan
agent1:                 episode reward: 0.1764,                 loss: 0.1579
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8250s / 44076.0058 s
agent0:                 episode reward: -0.5201,                 loss: nan
agent1:                 episode reward: 0.5201,                 loss: 0.1581
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3874s / 44212.3932 s
agent0:                 episode reward: -0.0505,                 loss: nan
agent1:                 episode reward: 0.0505,                 loss: 0.1580
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3404s / 44348.7336 s
agent0:                 episode reward: 0.0203,                 loss: nan
agent1:                 episode reward: -0.0203,                 loss: 0.1577
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6540s / 44485.3876 s
agent0:                 episode reward: -0.4398,                 loss: nan
agent1:                 episode reward: 0.4398,                 loss: 0.1583
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7765s / 44621.1641 s
agent0:                 episode reward: 0.2207,                 loss: nan
agent1:                 episode reward: -0.2207,                 loss: 0.1561
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6263s / 44754.7903 s
agent0:                 episode reward: -0.1433,                 loss: nan
agent1:                 episode reward: 0.1433,                 loss: 0.1590
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0807s / 44891.8711 s
agent0:                 episode reward: -0.3012,                 loss: nan
agent1:                 episode reward: 0.3012,                 loss: 0.1582
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8403s / 45033.7113 s
agent0:                 episode reward: -0.0860,                 loss: nan
agent1:                 episode reward: 0.0860,                 loss: 0.1572
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0675s / 45173.7789 s
agent0:                 episode reward: 0.0622,                 loss: nan
agent1:                 episode reward: -0.0622,                 loss: 0.1569
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3627s / 45309.1416 s
agent0:                 episode reward: -0.0958,                 loss: nan
agent1:                 episode reward: 0.0958,                 loss: 0.1576
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4238s / 45448.5653 s
agent0:                 episode reward: -0.2898,                 loss: nan
agent1:                 episode reward: 0.2898,                 loss: 0.1545
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9224s / 45583.4878 s
agent0:                 episode reward: -0.2959,                 loss: nan
agent1:                 episode reward: 0.2959,                 loss: 0.1559
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7770s / 45717.2648 s
agent0:                 episode reward: -0.5245,                 loss: nan
agent1:                 episode reward: 0.5245,                 loss: 0.1568
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0965s / 45854.3613 s
agent0:                 episode reward: -0.2475,                 loss: nan
agent1:                 episode reward: 0.2475,                 loss: 0.1561
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3991s / 45987.7604 s
agent0:                 episode reward: -0.0082,                 loss: nan
agent1:                 episode reward: 0.0082,                 loss: 0.1559
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7641s / 46123.5245 s
agent0:                 episode reward: -0.2048,                 loss: nan
agent1:                 episode reward: 0.2048,                 loss: 0.1555
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2497s / 46257.7742 s
agent0:                 episode reward: -0.5108,                 loss: nan
agent1:                 episode reward: 0.5108,                 loss: 0.1565
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9841s / 46391.7583 s
agent0:                 episode reward: -0.2519,                 loss: nan
agent1:                 episode reward: 0.2519,                 loss: 0.1534
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1681s / 46527.9264 s
agent0:                 episode reward: -0.4134,                 loss: nan
agent1:                 episode reward: 0.4134,                 loss: 0.1564
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3244s / 46665.2508 s
agent0:                 episode reward: 0.0654,                 loss: nan
agent1:                 episode reward: -0.0654,                 loss: 0.1551
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3338s / 46804.5847 s
agent0:                 episode reward: -0.4922,                 loss: nan
agent1:                 episode reward: 0.4922,                 loss: 0.1546
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3410s / 46937.9257 s
agent0:                 episode reward: -0.2321,                 loss: nan
agent1:                 episode reward: 0.2321,                 loss: 0.1559
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6963s / 47071.6219 s
agent0:                 episode reward: -0.0987,                 loss: nan
agent1:                 episode reward: 0.0987,                 loss: 0.1576
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5686s / 47206.1906 s
agent0:                 episode reward: -0.4656,                 loss: nan
agent1:                 episode reward: 0.4656,                 loss: 0.1569
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1954s / 47342.3859 s
agent0:                 episode reward: -0.2670,                 loss: nan
agent1:                 episode reward: 0.2670,                 loss: 0.1561
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5563s / 47479.9422 s
agent0:                 episode reward: 0.2076,                 loss: nan
agent1:                 episode reward: -0.2076,                 loss: 0.1570
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0567s / 47615.9989 s
agent0:                 episode reward: -0.1769,                 loss: nan
agent1:                 episode reward: 0.1769,                 loss: 0.1566
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1738s / 47749.1726 s
agent0:                 episode reward: 0.1850,                 loss: nan
agent1:                 episode reward: -0.1850,                 loss: 0.1553
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9120s / 47884.0846 s
agent0:                 episode reward: -0.1506,                 loss: nan
agent1:                 episode reward: 0.1506,                 loss: 0.1561
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0384s / 48018.1230 s
agent0:                 episode reward: -0.1825,                 loss: nan
agent1:                 episode reward: 0.1825,                 loss: 0.1554
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6604s / 48152.7834 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.1552
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7575s / 48294.5409 s
agent0:                 episode reward: -0.3246,                 loss: nan
agent1:                 episode reward: 0.3246,                 loss: 0.1549
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1509s / 48427.6918 s
agent0:                 episode reward: -0.1992,                 loss: nan
agent1:                 episode reward: 0.1992,                 loss: 0.1555
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.3155s / 48559.0073 s
agent0:                 episode reward: -0.2757,                 loss: nan
agent1:                 episode reward: 0.2757,                 loss: 0.1553
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2950s / 48696.3023 s
agent0:                 episode reward: -0.6544,                 loss: nan
agent1:                 episode reward: 0.6544,                 loss: 0.1564
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5675s / 48830.8698 s
agent0:                 episode reward: -0.4422,                 loss: nan
agent1:                 episode reward: 0.4422,                 loss: 0.1571
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9155s / 48968.7853 s
agent0:                 episode reward: -0.1604,                 loss: nan
agent1:                 episode reward: 0.1604,                 loss: 0.1567
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4920s / 49103.2773 s
agent0:                 episode reward: -0.1800,                 loss: nan
agent1:                 episode reward: 0.1800,                 loss: 0.1574
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7744s / 49240.0518 s
agent0:                 episode reward: -0.4931,                 loss: nan
agent1:                 episode reward: 0.4931,                 loss: 0.1553
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2480s / 49374.2998 s
agent0:                 episode reward: -0.0231,                 loss: nan
agent1:                 episode reward: 0.0231,                 loss: 0.1554
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3471s / 49508.6468 s
agent0:                 episode reward: -0.3724,                 loss: nan
agent1:                 episode reward: 0.3724,                 loss: 0.1562
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8398s / 49643.4866 s
agent0:                 episode reward: 0.0001,                 loss: nan
agent1:                 episode reward: -0.0001,                 loss: 0.1547
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2380s / 49777.7246 s
agent0:                 episode reward: -0.4180,                 loss: nan
agent1:                 episode reward: 0.4180,                 loss: 0.1544
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2357s / 49914.9602 s
agent0:                 episode reward: -0.5277,                 loss: nan
agent1:                 episode reward: 0.5277,                 loss: 0.1543
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9672s / 50049.9274 s
agent0:                 episode reward: 0.0545,                 loss: nan
agent1:                 episode reward: -0.0545,                 loss: 0.1555
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3094s / 50185.2368 s
agent0:                 episode reward: -0.3067,                 loss: nan
agent1:                 episode reward: 0.3067,                 loss: 0.1542
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0978s / 50319.3346 s
agent0:                 episode reward: -0.0943,                 loss: nan
agent1:                 episode reward: 0.0943,                 loss: 0.1537
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1727s / 50454.5074 s
agent0:                 episode reward: 0.0498,                 loss: nan
agent1:                 episode reward: -0.0498,                 loss: 0.1538
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4429s / 50591.9503 s
agent0:                 episode reward: 0.2861,                 loss: nan
agent1:                 episode reward: -0.2861,                 loss: 0.1536
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5253s / 50726.4756 s
agent0:                 episode reward: -0.1024,                 loss: nan
agent1:                 episode reward: 0.1024,                 loss: 0.1547
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7350s / 50862.2106 s
agent0:                 episode reward: -0.6676,                 loss: nan
agent1:                 episode reward: 0.6676,                 loss: 0.1539
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0944s / 50996.3050 s
agent0:                 episode reward: 0.0390,                 loss: nan
agent1:                 episode reward: -0.0390,                 loss: 0.1543
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9060s / 51131.2110 s
agent0:                 episode reward: -0.0084,                 loss: nan
agent1:                 episode reward: 0.0084,                 loss: 0.1554
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7957s / 51264.0067 s
agent0:                 episode reward: -0.1720,                 loss: nan
agent1:                 episode reward: 0.1720,                 loss: 0.1538
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0328s / 51398.0395 s
agent0:                 episode reward: -0.0621,                 loss: nan
agent1:                 episode reward: 0.0621,                 loss: 0.1553
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0063s / 51533.0458 s
agent0:                 episode reward: -0.2793,                 loss: nan
agent1:                 episode reward: 0.2793,                 loss: 0.1539
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3880s / 51668.4337 s
agent0:                 episode reward: -0.3516,                 loss: nan
agent1:                 episode reward: 0.3516,                 loss: 0.1532
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7710s / 51802.2047 s
agent0:                 episode reward: -0.2166,                 loss: nan
agent1:                 episode reward: 0.2166,                 loss: 0.1546
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1640s / 51936.3687 s
agent0:                 episode reward: -0.2633,                 loss: nan
agent1:                 episode reward: 0.2633,                 loss: 0.1567
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9140s / 52076.2827 s
agent0:                 episode reward: -0.2373,                 loss: nan
agent1:                 episode reward: 0.2373,                 loss: 0.1548
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7628s / 52209.0455 s
agent0:                 episode reward: 0.2542,                 loss: nan
agent1:                 episode reward: -0.2542,                 loss: 0.1559
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9610s / 52343.0065 s
agent0:                 episode reward: -0.3185,                 loss: nan
agent1:                 episode reward: 0.3185,                 loss: 0.1548
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4036s / 52477.4101 s
agent0:                 episode reward: -0.1577,                 loss: nan
agent1:                 episode reward: 0.1577,                 loss: 0.1553
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3293s / 52612.7394 s
agent0:                 episode reward: -0.0619,                 loss: nan
agent1:                 episode reward: 0.0619,                 loss: 0.1551
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1835s / 52748.9229 s
agent0:                 episode reward: -0.3873,                 loss: nan
agent1:                 episode reward: 0.3873,                 loss: 0.1549
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4208s / 52883.3437 s
agent0:                 episode reward: 0.0034,                 loss: nan
agent1:                 episode reward: -0.0034,                 loss: 0.1561
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2029s / 53017.5466 s
agent0:                 episode reward: -0.0094,                 loss: nan
agent1:                 episode reward: 0.0094,                 loss: 0.1555
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9909s / 53153.5375 s
agent0:                 episode reward: 0.0867,                 loss: nan
agent1:                 episode reward: -0.0867,                 loss: 0.1571
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2415s / 53290.7791 s
agent0:                 episode reward: -0.4479,                 loss: nan
agent1:                 episode reward: 0.4479,                 loss: 0.1569
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7293s / 53425.5084 s
agent0:                 episode reward: -0.2777,                 loss: nan
agent1:                 episode reward: 0.2777,                 loss: 0.1554
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.2732s / 53556.7816 s
agent0:                 episode reward: 0.0103,                 loss: nan
agent1:                 episode reward: -0.0103,                 loss: 0.1554
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4333s / 53694.2149 s
agent0:                 episode reward: -0.1348,                 loss: nan
agent1:                 episode reward: 0.1348,                 loss: 0.1558
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3996s / 53829.6145 s
agent0:                 episode reward: -0.4277,                 loss: nan
agent1:                 episode reward: 0.4277,                 loss: 0.1548
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9803s / 53966.5947 s
agent0:                 episode reward: -0.4949,                 loss: nan
agent1:                 episode reward: 0.4949,                 loss: 0.1562
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0931s / 54103.6879 s
agent0:                 episode reward: -0.2064,                 loss: nan
agent1:                 episode reward: 0.2064,                 loss: 0.1553
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3496s / 54240.0375 s
agent0:                 episode reward: -0.2140,                 loss: nan
agent1:                 episode reward: 0.2140,                 loss: 0.1588
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5185s / 54374.5560 s
agent0:                 episode reward: -0.7577,                 loss: nan
agent1:                 episode reward: 0.7577,                 loss: 0.1590
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5039s / 54509.0599 s
agent0:                 episode reward: 0.0888,                 loss: nan
agent1:                 episode reward: -0.0888,                 loss: 0.1576
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7581s / 54641.8179 s
agent0:                 episode reward: -0.3122,                 loss: nan
agent1:                 episode reward: 0.3122,                 loss: 0.1595
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1839s / 54776.0019 s
agent0:                 episode reward: -0.1775,                 loss: nan
agent1:                 episode reward: 0.1775,                 loss: 0.1584
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0769s / 54910.0787 s
agent0:                 episode reward: -0.4670,                 loss: nan
agent1:                 episode reward: 0.4670,                 loss: 0.1567
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8142s / 55050.8929 s
agent0:                 episode reward: -0.3352,                 loss: nan
agent1:                 episode reward: 0.3352,                 loss: 0.1571
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4237s / 55186.3166 s
agent0:                 episode reward: -0.1993,                 loss: nan
agent1:                 episode reward: 0.1993,                 loss: 0.1571
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9355s / 55321.2521 s
agent0:                 episode reward: -0.1353,                 loss: nan
agent1:                 episode reward: 0.1353,                 loss: 0.1564
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7098s / 55457.9619 s
agent0:                 episode reward: -0.2508,                 loss: nan
agent1:                 episode reward: 0.2508,                 loss: 0.1567
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0023s / 55592.9643 s
agent0:                 episode reward: -0.4123,                 loss: nan
agent1:                 episode reward: 0.4123,                 loss: 0.1575
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4606s / 55726.4248 s
agent0:                 episode reward: -0.2782,                 loss: nan
agent1:                 episode reward: 0.2782,                 loss: 0.1566
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8527s / 55861.2775 s
agent0:                 episode reward: -0.5033,                 loss: nan
agent1:                 episode reward: 0.5033,                 loss: 0.1562
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3510s / 55993.6285 s
agent0:                 episode reward: -0.1410,                 loss: nan
agent1:                 episode reward: 0.1410,                 loss: 0.1572
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7898s / 56133.4183 s
agent0:                 episode reward: -0.4133,                 loss: nan
agent1:                 episode reward: 0.4133,                 loss: 0.1569
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6396s / 56270.0579 s
agent0:                 episode reward: -0.2744,                 loss: nan
agent1:                 episode reward: 0.2744,                 loss: 0.1587
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6511s / 56405.7090 s
agent0:                 episode reward: -0.2383,                 loss: nan
agent1:                 episode reward: 0.2383,                 loss: 0.1569
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4461s / 56542.1551 s
agent0:                 episode reward: -0.0127,                 loss: nan
agent1:                 episode reward: 0.0127,                 loss: 0.1579
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9798s / 56679.1349 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: 0.1580
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9230s / 56812.0579 s
agent0:                 episode reward: 0.1402,                 loss: nan
agent1:                 episode reward: -0.1402,                 loss: 0.1589
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9714s / 56946.0293 s
agent0:                 episode reward: -0.1136,                 loss: nan
agent1:                 episode reward: 0.1136,                 loss: 0.1598
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8774s / 57080.9067 s
agent0:                 episode reward: -0.3934,                 loss: nan
agent1:                 episode reward: 0.3934,                 loss: 0.1580
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5572s / 57216.4640 s
agent0:                 episode reward: -0.1434,                 loss: nan
agent1:                 episode reward: 0.1434,                 loss: 0.1589
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3785s / 57352.8424 s
agent0:                 episode reward: -0.5987,                 loss: nan
agent1:                 episode reward: 0.5987,                 loss: 0.1596
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5129s / 57490.3553 s
agent0:                 episode reward: -0.2551,                 loss: nan
agent1:                 episode reward: 0.2551,                 loss: 0.1584
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4042s / 57626.7595 s
agent0:                 episode reward: -0.2490,                 loss: nan
agent1:                 episode reward: 0.2490,                 loss: 0.1580
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7120s / 57760.4715 s
agent0:                 episode reward: -0.4005,                 loss: nan
agent1:                 episode reward: 0.4005,                 loss: 0.1586
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3170s / 57893.7885 s
agent0:                 episode reward: -0.2789,                 loss: nan
agent1:                 episode reward: 0.2789,                 loss: 0.1595
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4654s / 58032.2539 s
agent0:                 episode reward: -0.4117,                 loss: nan
agent1:                 episode reward: 0.4117,                 loss: 0.1560
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1477s / 58167.4016 s
agent0:                 episode reward: -0.7238,                 loss: nan
agent1:                 episode reward: 0.7238,                 loss: 0.1583
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9579s / 58304.3595 s
agent0:                 episode reward: -0.3431,                 loss: nan
agent1:                 episode reward: 0.3431,                 loss: 0.1579
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8615s / 58439.2210 s
agent0:                 episode reward: -0.3025,                 loss: nan
agent1:                 episode reward: 0.3025,                 loss: 0.1583
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9894s / 58574.2104 s
agent0:                 episode reward: -0.4573,                 loss: nan
agent1:                 episode reward: 0.4573,                 loss: 0.1597
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9900s / 58708.2005 s
agent0:                 episode reward: -0.6500,                 loss: nan
agent1:                 episode reward: 0.6500,                 loss: 0.1564
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1224s / 58843.3229 s
agent0:                 episode reward: -0.0114,                 loss: nan
agent1:                 episode reward: 0.0114,                 loss: 0.1554
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7260s / 58980.0489 s
agent0:                 episode reward: -0.5245,                 loss: nan
agent1:                 episode reward: 0.5245,                 loss: 0.1558
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9937s / 59116.0426 s
agent0:                 episode reward: -0.2450,                 loss: nan
agent1:                 episode reward: 0.2450,                 loss: 0.1567
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5037s / 59249.5462 s
agent0:                 episode reward: -0.4047,                 loss: nan
agent1:                 episode reward: 0.4047,                 loss: 0.1558
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0657s / 59385.6119 s
agent0:                 episode reward: -0.5204,                 loss: nan
agent1:                 episode reward: 0.5204,                 loss: 0.1552
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2449s / 59524.8569 s
agent0:                 episode reward: 0.2379,                 loss: nan
agent1:                 episode reward: -0.2379,                 loss: 0.1580
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3024s / 59661.1592 s
agent0:                 episode reward: -0.3334,                 loss: nan
agent1:                 episode reward: 0.3334,                 loss: 0.1556
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4824s / 59795.6417 s
agent0:                 episode reward: -0.5487,                 loss: nan
agent1:                 episode reward: 0.5487,                 loss: 0.1552
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4733s / 59929.1150 s
agent0:                 episode reward: -0.2472,                 loss: nan
agent1:                 episode reward: 0.2472,                 loss: 0.1568
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1930s / 60063.3079 s
agent0:                 episode reward: -0.3168,                 loss: nan
agent1:                 episode reward: 0.3168,                 loss: 0.1558
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3686s / 60198.6765 s
agent0:                 episode reward: -0.4298,                 loss: nan
agent1:                 episode reward: 0.4298,                 loss: 0.1566
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6514s / 60333.3279 s
agent0:                 episode reward: -0.3804,                 loss: nan
agent1:                 episode reward: 0.3804,                 loss: 0.1562
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6633s / 60469.9911 s
agent0:                 episode reward: -0.1983,                 loss: nan
agent1:                 episode reward: 0.1983,                 loss: 0.1575
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8616s / 60605.8528 s
agent0:                 episode reward: -0.5824,                 loss: nan
agent1:                 episode reward: 0.5824,                 loss: 0.1556
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6522s / 60741.5049 s
agent0:                 episode reward: 0.0979,                 loss: nan
agent1:                 episode reward: -0.0979,                 loss: 0.1580
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8725s / 60877.3774 s
agent0:                 episode reward: -0.1362,                 loss: nan
agent1:                 episode reward: 0.1362,                 loss: 0.1551
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3259s / 61009.7034 s
agent0:                 episode reward: -0.5548,                 loss: nan
agent1:                 episode reward: 0.5548,                 loss: 0.1505
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7672s / 61146.4705 s
agent0:                 episode reward: -0.5997,                 loss: nan
agent1:                 episode reward: 0.5997,                 loss: 0.1524
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5210s / 61283.9915 s
agent0:                 episode reward: -0.0597,                 loss: nan
agent1:                 episode reward: 0.0597,                 loss: 0.1527
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7133s / 61416.7048 s
agent0:                 episode reward: 0.0410,                 loss: nan
agent1:                 episode reward: -0.0410,                 loss: 0.1513
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9402s / 61553.6450 s
agent0:                 episode reward: -0.3429,                 loss: nan
agent1:                 episode reward: 0.3429,                 loss: 0.1528
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9165s / 61693.5615 s
agent0:                 episode reward: -0.4146,                 loss: nan
agent1:                 episode reward: 0.4146,                 loss: 0.1526
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5533s / 61833.1147 s
agent0:                 episode reward: -0.2568,                 loss: nan
agent1:                 episode reward: 0.2568,                 loss: 0.1530
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9315s / 61966.0463 s
agent0:                 episode reward: -0.5467,                 loss: nan
agent1:                 episode reward: 0.5467,                 loss: 0.1531
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6462s / 62102.6924 s
agent0:                 episode reward: -0.2680,                 loss: nan
agent1:                 episode reward: 0.2680,                 loss: 0.1521
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0983s / 62242.7907 s
agent0:                 episode reward: -0.1462,                 loss: nan
agent1:                 episode reward: 0.1462,                 loss: 0.1524
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4769s / 62381.2676 s
agent0:                 episode reward: -0.4457,                 loss: nan
agent1:                 episode reward: 0.4457,                 loss: 0.1529
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5249s / 62515.7926 s
agent0:                 episode reward: -0.5603,                 loss: nan
agent1:                 episode reward: 0.5603,                 loss: 0.1530
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6390s / 62651.4315 s
agent0:                 episode reward: -0.5887,                 loss: nan
agent1:                 episode reward: 0.5887,                 loss: 0.1535
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4302s / 62785.8617 s
agent0:                 episode reward: -0.2159,                 loss: nan
agent1:                 episode reward: 0.2159,                 loss: 0.1517
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7387s / 62920.6004 s
agent0:                 episode reward: -0.4085,                 loss: nan
agent1:                 episode reward: 0.4085,                 loss: 0.1510
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2469s / 63054.8473 s
agent0:                 episode reward: 0.1327,                 loss: nan
agent1:                 episode reward: -0.1327,                 loss: 0.1526
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6083s / 63193.4556 s
agent0:                 episode reward: -0.1688,                 loss: nan
agent1:                 episode reward: 0.1688,                 loss: 0.1565
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6484s / 63328.1040 s
agent0:                 episode reward: -0.2511,                 loss: nan
agent1:                 episode reward: 0.2511,                 loss: 0.1577
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7188s / 63462.8228 s
agent0:                 episode reward: -0.2433,                 loss: nan
agent1:                 episode reward: 0.2433,                 loss: 0.1576
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6012s / 63599.4240 s
agent0:                 episode reward: -0.3365,                 loss: nan
agent1:                 episode reward: 0.3365,                 loss: 0.1576
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1497s / 63736.5737 s
agent0:                 episode reward: -0.4845,                 loss: nan
agent1:                 episode reward: 0.4845,                 loss: 0.1579
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3131s / 63873.8868 s
agent0:                 episode reward: -0.1330,                 loss: nan
agent1:                 episode reward: 0.1330,                 loss: 0.1570
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2062s / 64012.0929 s
agent0:                 episode reward: -0.4505,                 loss: nan
agent1:                 episode reward: 0.4505,                 loss: 0.1579
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6515s / 64146.7444 s
agent0:                 episode reward: -0.2600,                 loss: nan
agent1:                 episode reward: 0.2600,                 loss: 0.1597
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1124s / 64283.8569 s
agent0:                 episode reward: -0.2235,                 loss: nan
agent1:                 episode reward: 0.2235,                 loss: 0.1573
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7428s / 64423.5996 s
agent0:                 episode reward: 0.1508,                 loss: nan
agent1:                 episode reward: -0.1508,                 loss: 0.1582
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3802s / 64559.9799 s
agent0:                 episode reward: -0.0302,                 loss: nan
agent1:                 episode reward: 0.0302,                 loss: 0.1575
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1367s / 64696.1166 s
agent0:                 episode reward: -0.4393,                 loss: nan
agent1:                 episode reward: 0.4393,                 loss: 0.1582
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4229s / 64830.5395 s
agent0:                 episode reward: -0.1376,                 loss: nan
agent1:                 episode reward: 0.1376,                 loss: 0.1575
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1558s / 64966.6953 s
agent0:                 episode reward: -0.3359,                 loss: nan
agent1:                 episode reward: 0.3359,                 loss: 0.1580
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1862s / 65100.8815 s
agent0:                 episode reward: 0.0143,                 loss: nan
agent1:                 episode reward: -0.0143,                 loss: 0.1579
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4397s / 65235.3212 s
agent0:                 episode reward: 0.1107,                 loss: nan
agent1:                 episode reward: -0.1107,                 loss: 0.1581
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0971s / 65373.4183 s
agent0:                 episode reward: 0.1172,                 loss: nan
agent1:                 episode reward: -0.1172,                 loss: 0.1578
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0714s / 65508.4898 s
agent0:                 episode reward: -0.1444,                 loss: nan
agent1:                 episode reward: 0.1444,                 loss: 0.1562
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2132s / 65644.7029 s
agent0:                 episode reward: -0.2546,                 loss: nan
agent1:                 episode reward: 0.2546,                 loss: 0.1569
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1118s / 65778.8148 s
agent0:                 episode reward: -0.0786,                 loss: nan
agent1:                 episode reward: 0.0786,                 loss: 0.1566
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5822s / 65913.3969 s
agent0:                 episode reward: -0.4560,                 loss: nan
agent1:                 episode reward: 0.4560,                 loss: 0.1540
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4699s / 66049.8668 s
agent0:                 episode reward: -0.1378,                 loss: nan
agent1:                 episode reward: 0.1378,                 loss: 0.1563
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0666s / 66181.9334 s
agent0:                 episode reward: -0.0777,                 loss: nan
agent1:                 episode reward: 0.0777,                 loss: 0.1556
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5402s / 66317.4736 s
agent0:                 episode reward: -0.0253,                 loss: nan
agent1:                 episode reward: 0.0253,                 loss: 0.1565
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2187s / 66452.6924 s
agent0:                 episode reward: -0.4225,                 loss: nan
agent1:                 episode reward: 0.4225,                 loss: 0.1545
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9929s / 66584.6852 s
agent0:                 episode reward: -0.0850,                 loss: nan
agent1:                 episode reward: 0.0850,                 loss: 0.1576
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1619s / 66717.8472 s
agent0:                 episode reward: -0.1541,                 loss: nan
agent1:                 episode reward: 0.1541,                 loss: 0.1553
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8477s / 66853.6948 s
agent0:                 episode reward: 0.0296,                 loss: nan
agent1:                 episode reward: -0.0296,                 loss: 0.1561
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2667s / 66990.9616 s
agent0:                 episode reward: -0.4490,                 loss: nan
agent1:                 episode reward: 0.4490,                 loss: 0.1552
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1082s / 67124.0698 s
agent0:                 episode reward: 0.3401,                 loss: nan
agent1:                 episode reward: -0.3401,                 loss: 0.1556
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6888s / 67258.7586 s
agent0:                 episode reward: -0.2043,                 loss: nan
agent1:                 episode reward: 0.2043,                 loss: 0.1569
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4851s / 67393.2436 s
agent0:                 episode reward: -0.1545,                 loss: nan
agent1:                 episode reward: 0.1545,                 loss: 0.1562
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5498s / 67529.7934 s
agent0:                 episode reward: -0.2296,                 loss: nan
agent1:                 episode reward: 0.2296,                 loss: 0.1558
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7094s / 67665.5028 s
agent0:                 episode reward: -0.1086,                 loss: nan
agent1:                 episode reward: 0.1086,                 loss: 0.1570
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2950s / 67800.7978 s
agent0:                 episode reward: -0.2037,                 loss: nan
agent1:                 episode reward: 0.2037,                 loss: 0.1547
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9392s / 67937.7369 s
agent0:                 episode reward: -0.0746,                 loss: nan
agent1:                 episode reward: 0.0746,                 loss: 0.1533
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3085s / 68071.0454 s
agent0:                 episode reward: -0.4411,                 loss: nan
agent1:                 episode reward: 0.4411,                 loss: 0.1523
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.6415s / 68201.6869 s
agent0:                 episode reward: -0.3329,                 loss: nan
agent1:                 episode reward: 0.3329,                 loss: 0.1534
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5211s / 68336.2079 s
agent0:                 episode reward: -0.3684,                 loss: nan
agent1:                 episode reward: 0.3684,                 loss: 0.1541
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6024s / 68473.8103 s
agent0:                 episode reward: -0.2975,                 loss: nan
agent1:                 episode reward: 0.2975,                 loss: 0.1536
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9752s / 68608.7855 s
agent0:                 episode reward: -0.4324,                 loss: nan
agent1:                 episode reward: 0.4324,                 loss: 0.1533
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9151s / 68743.7007 s
agent0:                 episode reward: -0.5870,                 loss: nan
agent1:                 episode reward: 0.5870,                 loss: 0.1545
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1594s / 68878.8600 s
agent0:                 episode reward: -0.3355,                 loss: nan
agent1:                 episode reward: 0.3355,                 loss: 0.1519
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1122s / 69014.9722 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.1550
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1751s / 69147.1473 s
agent0:                 episode reward: 0.0338,                 loss: nan
agent1:                 episode reward: -0.0338,                 loss: 0.1536
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5001s / 69280.6474 s
agent0:                 episode reward: -0.1424,                 loss: nan
agent1:                 episode reward: 0.1424,                 loss: 0.1541
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3233s / 69413.9707 s
agent0:                 episode reward: -0.2482,                 loss: nan
agent1:                 episode reward: 0.2482,                 loss: 0.1537
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 130.6456s / 69544.6162 s
agent0:                 episode reward: -0.2767,                 loss: nan
agent1:                 episode reward: 0.2767,                 loss: 0.1534
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4652s / 69682.0814 s
agent0:                 episode reward: -0.2769,                 loss: nan
agent1:                 episode reward: 0.2769,                 loss: 0.1546
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7308s / 69817.8122 s
agent0:                 episode reward: -0.3544,                 loss: nan
agent1:                 episode reward: 0.3544,                 loss: 0.1541
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4845s / 69953.2968 s
agent0:                 episode reward: -0.0621,                 loss: nan
agent1:                 episode reward: 0.0621,                 loss: 0.1528
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0193s / 70089.3161 s
agent0:                 episode reward: -0.5468,                 loss: nan
agent1:                 episode reward: 0.5468,                 loss: 0.1539
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7412s / 70224.0573 s
agent0:                 episode reward: -0.1610,                 loss: nan
agent1:                 episode reward: 0.1610,                 loss: 0.1549
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9607s / 70359.0179 s
agent0:                 episode reward: -0.3494,                 loss: nan
agent1:                 episode reward: 0.3494,                 loss: 0.1553
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4413s / 70494.4592 s
agent0:                 episode reward: -0.5178,                 loss: nan
agent1:                 episode reward: 0.5178,                 loss: 0.1543
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3018s / 70626.7611 s
agent0:                 episode reward: -0.6552,                 loss: nan
agent1:                 episode reward: 0.6552,                 loss: 0.1558
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7857s / 70762.5467 s
agent0:                 episode reward: -0.3441,                 loss: nan
agent1:                 episode reward: 0.3441,                 loss: 0.1555
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6149s / 70895.1617 s
agent0:                 episode reward: -0.3344,                 loss: nan
agent1:                 episode reward: 0.3344,                 loss: 0.1532
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0511s / 71031.2127 s
agent0:                 episode reward: -0.3310,                 loss: nan
agent1:                 episode reward: 0.3310,                 loss: 0.1550
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0112s / 71168.2239 s
agent0:                 episode reward: -0.0472,                 loss: nan
agent1:                 episode reward: 0.0472,                 loss: 0.1561
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6956s / 71302.9194 s
agent0:                 episode reward: -0.3185,                 loss: nan
agent1:                 episode reward: 0.3185,                 loss: 0.1547
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4197s / 71436.3391 s
agent0:                 episode reward: 0.0805,                 loss: nan
agent1:                 episode reward: -0.0805,                 loss: 0.1556
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5199s / 71570.8590 s
agent0:                 episode reward: -0.1715,                 loss: nan
agent1:                 episode reward: 0.1715,                 loss: 0.1561
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4321s / 71707.2911 s
agent0:                 episode reward: -0.2152,                 loss: nan
agent1:                 episode reward: 0.2152,                 loss: 0.1570
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1857s / 71840.4768 s
agent0:                 episode reward: -0.6219,                 loss: nan
agent1:                 episode reward: 0.6219,                 loss: 0.1545
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5278s / 71976.0047 s
agent0:                 episode reward: -0.2830,                 loss: nan
agent1:                 episode reward: 0.2830,                 loss: 0.1544
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9727s / 72109.9773 s
agent0:                 episode reward: -0.0764,                 loss: nan
agent1:                 episode reward: 0.0764,                 loss: 0.1542
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3273s / 72242.3046 s
agent0:                 episode reward: -0.3356,                 loss: nan
agent1:                 episode reward: 0.3356,                 loss: 0.1538
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8742s / 72378.1788 s
agent0:                 episode reward: -0.1338,                 loss: nan
agent1:                 episode reward: 0.1338,                 loss: 0.1551
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1865s / 72511.3652 s
agent0:                 episode reward: -0.2625,                 loss: nan
agent1:                 episode reward: 0.2625,                 loss: 0.1548
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7700s / 72645.1352 s
agent0:                 episode reward: -0.2746,                 loss: nan
agent1:                 episode reward: 0.2746,                 loss: 0.1544
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1021s / 72781.2373 s
agent0:                 episode reward: -0.4410,                 loss: nan
agent1:                 episode reward: 0.4410,                 loss: 0.1553
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6534s / 72918.8907 s
agent0:                 episode reward: 0.1558,                 loss: nan
agent1:                 episode reward: -0.1558,                 loss: 0.1537
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6688s / 73055.5596 s
agent0:                 episode reward: -0.1288,                 loss: nan
agent1:                 episode reward: 0.1288,                 loss: 0.1541
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4535s / 73194.0131 s
agent0:                 episode reward: -0.2438,                 loss: nan
agent1:                 episode reward: 0.2438,                 loss: 0.1543
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2002s / 73328.2133 s
agent0:                 episode reward: -0.2630,                 loss: nan
agent1:                 episode reward: 0.2630,                 loss: 0.1557
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0838s / 73460.2971 s
agent0:                 episode reward: 0.3138,                 loss: nan
agent1:                 episode reward: -0.3138,                 loss: 0.1553
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7899s / 73597.0870 s
agent0:                 episode reward: -0.2947,                 loss: nan
agent1:                 episode reward: 0.2947,                 loss: 0.1545
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0846s / 73733.1716 s
agent0:                 episode reward: 0.0357,                 loss: nan
agent1:                 episode reward: -0.0357,                 loss: 0.1547
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1113s / 73868.2829 s
agent0:                 episode reward: -0.2497,                 loss: nan
agent1:                 episode reward: 0.2497,                 loss: 0.1549
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5497s / 74002.8326 s
agent0:                 episode reward: -0.2123,                 loss: nan
agent1:                 episode reward: 0.2123,                 loss: 0.1553
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0615s / 74137.8940 s
agent0:                 episode reward: -0.2984,                 loss: nan
agent1:                 episode reward: 0.2984,                 loss: 0.1541
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2566s / 74273.1506 s
agent0:                 episode reward: -0.3349,                 loss: nan
agent1:                 episode reward: 0.3349,                 loss: 0.1548
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8785s / 74409.0291 s
agent0:                 episode reward: -0.6181,                 loss: nan
agent1:                 episode reward: 0.6181,                 loss: 0.1566
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9200s / 74544.9491 s
agent0:                 episode reward: -0.0780,                 loss: nan
agent1:                 episode reward: 0.0780,                 loss: 0.1557
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9024s / 74679.8515 s
agent0:                 episode reward: -0.0207,                 loss: nan
agent1:                 episode reward: 0.0207,                 loss: 0.1572
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5314s / 74815.3829 s
agent0:                 episode reward: -0.5996,                 loss: nan
agent1:                 episode reward: 0.5996,                 loss: 0.1566
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1388s / 74948.5217 s
agent0:                 episode reward: -0.3970,                 loss: nan
agent1:                 episode reward: 0.3970,                 loss: 0.1555
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2376s / 75084.7593 s
agent0:                 episode reward: -0.2754,                 loss: nan
agent1:                 episode reward: 0.2754,                 loss: 0.1576
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5170s / 75219.2763 s
agent0:                 episode reward: 0.0797,                 loss: nan
agent1:                 episode reward: -0.0797,                 loss: 0.1569
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0305s / 75354.3067 s
agent0:                 episode reward: -0.3854,                 loss: nan
agent1:                 episode reward: 0.3854,                 loss: 0.1565
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4347s / 75488.7414 s
agent0:                 episode reward: -0.8002,                 loss: nan
agent1:                 episode reward: 0.8002,                 loss: 0.1565
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0616s / 75620.8030 s
agent0:                 episode reward: -0.5452,                 loss: nan
agent1:                 episode reward: 0.5452,                 loss: 0.1562
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6201s / 75756.4231 s
agent0:                 episode reward: -0.2080,                 loss: nan
agent1:                 episode reward: 0.2080,                 loss: 0.1563
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5054s / 75891.9284 s
agent0:                 episode reward: -0.2211,                 loss: nan
agent1:                 episode reward: 0.2211,                 loss: 0.1551
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0617s / 76027.9902 s
agent0:                 episode reward: -0.2401,                 loss: nan
agent1:                 episode reward: 0.2401,                 loss: 0.1572
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9524s / 76161.9425 s
agent0:                 episode reward: 0.0190,                 loss: nan
agent1:                 episode reward: -0.0190,                 loss: 0.1569
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4604s / 76297.4029 s
agent0:                 episode reward: -0.0420,                 loss: nan
agent1:                 episode reward: 0.0420,                 loss: 0.1560
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8709s / 76434.2738 s
agent0:                 episode reward: -0.6400,                 loss: nan
agent1:                 episode reward: 0.6400,                 loss: 0.1564
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0818s / 76571.3556 s
agent0:                 episode reward: -0.2925,                 loss: nan
agent1:                 episode reward: 0.2925,                 loss: 0.1565
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2046s / 76708.5602 s
agent0:                 episode reward: -0.3737,                 loss: nan
agent1:                 episode reward: 0.3737,                 loss: 0.1533
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2375s / 76841.7977 s
agent0:                 episode reward: -0.2922,                 loss: nan
agent1:                 episode reward: 0.2922,                 loss: 0.1527
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7417s / 76978.5394 s
agent0:                 episode reward: -0.3794,                 loss: nan
agent1:                 episode reward: 0.3794,                 loss: 0.1526
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3780s / 77113.9173 s
agent0:                 episode reward: -0.3988,                 loss: nan
agent1:                 episode reward: 0.3988,                 loss: 0.1515
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9474s / 77246.8647 s
agent0:                 episode reward: -0.2814,                 loss: nan
agent1:                 episode reward: 0.2814,                 loss: 0.1514
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6865s / 77382.5512 s
agent0:                 episode reward: -0.3443,                 loss: nan
agent1:                 episode reward: 0.3443,                 loss: 0.1511
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4820s / 77517.0332 s
agent0:                 episode reward: -0.0672,                 loss: nan
agent1:                 episode reward: 0.0672,                 loss: 0.1525
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0166s / 77650.0498 s
agent0:                 episode reward: -0.5991,                 loss: nan
agent1:                 episode reward: 0.5991,                 loss: 0.1530
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5851s / 77787.6349 s
agent0:                 episode reward: -0.2816,                 loss: nan
agent1:                 episode reward: 0.2816,                 loss: 0.1537
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6716s / 77922.3065 s
agent0:                 episode reward: -0.2608,                 loss: nan
agent1:                 episode reward: 0.2608,                 loss: 0.1533
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0573s / 78058.3638 s
agent0:                 episode reward: -0.0265,                 loss: nan
agent1:                 episode reward: 0.0265,                 loss: 0.1523
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7967s / 78192.1605 s
agent0:                 episode reward: -0.5406,                 loss: nan
agent1:                 episode reward: 0.5406,                 loss: 0.1533
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1957s / 78329.3563 s
agent0:                 episode reward: -0.0395,                 loss: nan
agent1:                 episode reward: 0.0395,                 loss: 0.1537
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7568s / 78462.1131 s
agent0:                 episode reward: -0.7161,                 loss: nan
agent1:                 episode reward: 0.7161,                 loss: 0.1534
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8704s / 78597.9834 s
agent0:                 episode reward: -0.2531,                 loss: nan
agent1:                 episode reward: 0.2531,                 loss: 0.1526
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3502s / 78734.3336 s
agent0:                 episode reward: -0.7155,                 loss: nan
agent1:                 episode reward: 0.7155,                 loss: 0.1510
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9869s / 78866.3205 s
agent0:                 episode reward: -0.6122,                 loss: nan
agent1:                 episode reward: 0.6122,                 loss: 0.1533
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2073s / 79001.5277 s
agent0:                 episode reward: -0.0660,                 loss: nan
agent1:                 episode reward: 0.0660,                 loss: 0.1565
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9478s / 79135.4755 s
agent0:                 episode reward: -0.3454,                 loss: nan
agent1:                 episode reward: 0.3454,                 loss: 0.1554
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9883s / 79271.4638 s
agent0:                 episode reward: -0.1626,                 loss: nan
agent1:                 episode reward: 0.1626,                 loss: 0.1568
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9309s / 79403.3947 s
agent0:                 episode reward: -0.3435,                 loss: nan
agent1:                 episode reward: 0.3435,                 loss: 0.1563
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5952s / 79538.9899 s
agent0:                 episode reward: -0.2252,                 loss: nan
agent1:                 episode reward: 0.2252,                 loss: 0.1569
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3328s / 79671.3228 s
agent0:                 episode reward: -0.0025,                 loss: nan
agent1:                 episode reward: 0.0025,                 loss: 0.1574
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7768s / 79805.0996 s
agent0:                 episode reward: -0.0384,                 loss: nan
agent1:                 episode reward: 0.0384,                 loss: 0.1540
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0218s / 79939.1214 s
agent0:                 episode reward: -0.5238,                 loss: nan
agent1:                 episode reward: 0.5238,                 loss: 0.1561
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9921s / 80074.1135 s
agent0:                 episode reward: -0.4960,                 loss: nan
agent1:                 episode reward: 0.4960,                 loss: 0.1561
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7726s / 80208.8861 s
agent0:                 episode reward: -0.2318,                 loss: nan
agent1:                 episode reward: 0.2318,                 loss: 0.1552
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9752s / 80341.8613 s
agent0:                 episode reward: -0.2412,                 loss: nan
agent1:                 episode reward: 0.2412,                 loss: 0.1556
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0050s / 80477.8663 s
agent0:                 episode reward: -0.2293,                 loss: nan
agent1:                 episode reward: 0.2293,                 loss: 0.1551
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1951s / 80615.0614 s
agent0:                 episode reward: -0.4842,                 loss: nan
agent1:                 episode reward: 0.4842,                 loss: 0.1543
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3475s / 80751.4089 s
agent0:                 episode reward: -0.3049,                 loss: nan
agent1:                 episode reward: 0.3049,                 loss: 0.1551
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7306s / 80888.1395 s
agent0:                 episode reward: -0.3662,                 loss: nan
agent1:                 episode reward: 0.3662,                 loss: 0.1568
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4290s / 81021.5685 s
agent0:                 episode reward: -0.4159,                 loss: nan
agent1:                 episode reward: 0.4159,                 loss: 0.1582
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5300s / 81154.0986 s
agent0:                 episode reward: -0.5108,                 loss: nan
agent1:                 episode reward: 0.5108,                 loss: 0.1583
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2348s / 81291.3334 s
agent0:                 episode reward: -0.5263,                 loss: nan
agent1:                 episode reward: 0.5263,                 loss: 0.1552
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8196s / 81426.1529 s
agent0:                 episode reward: -0.3414,                 loss: nan
agent1:                 episode reward: 0.3414,                 loss: 0.1561
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6936s / 81564.8465 s
agent0:                 episode reward: -0.3453,                 loss: nan
agent1:                 episode reward: 0.3453,                 loss: 0.1549
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2464s / 81699.0929 s
agent0:                 episode reward: -0.4745,                 loss: nan
agent1:                 episode reward: 0.4745,                 loss: 0.1551
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1049s / 81835.1977 s
agent0:                 episode reward: -0.3755,                 loss: nan
agent1:                 episode reward: 0.3755,                 loss: 0.1570
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5850s / 81971.7827 s
agent0:                 episode reward: -0.2394,                 loss: nan
agent1:                 episode reward: 0.2394,                 loss: 0.1554
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3503s / 82108.1330 s
agent0:                 episode reward: -0.1663,                 loss: nan
agent1:                 episode reward: 0.1663,                 loss: 0.1551
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9835s / 82243.1165 s
agent0:                 episode reward: -0.3042,                 loss: nan
agent1:                 episode reward: 0.3042,                 loss: 0.1549
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6491s / 82378.7656 s
agent0:                 episode reward: -0.4346,                 loss: nan
agent1:                 episode reward: 0.4346,                 loss: 0.1570
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0376s / 82513.8033 s
agent0:                 episode reward: -0.2074,                 loss: nan
agent1:                 episode reward: 0.2074,                 loss: 0.1570
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1934s / 82651.9967 s
agent0:                 episode reward: 0.0036,                 loss: nan
agent1:                 episode reward: -0.0036,                 loss: 0.1550
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.3669s / 82782.3636 s
agent0:                 episode reward: -0.3152,                 loss: nan
agent1:                 episode reward: 0.3152,                 loss: 0.1553
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9389s / 82916.3025 s
agent0:                 episode reward: -0.5269,                 loss: nan
agent1:                 episode reward: 0.5269,                 loss: 0.1559
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8028s / 83048.1053 s
agent0:                 episode reward: -0.1183,                 loss: nan
agent1:                 episode reward: 0.1183,                 loss: 0.1569
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8298s / 83186.9351 s
agent0:                 episode reward: -0.2389,                 loss: nan
agent1:                 episode reward: 0.2389,                 loss: 0.1551
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6763s / 83320.6114 s
agent0:                 episode reward: -0.1700,                 loss: nan
agent1:                 episode reward: 0.1700,                 loss: 0.1569
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7170s / 83458.3283 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.1536
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8591s / 83593.1874 s
agent0:                 episode reward: -0.4409,                 loss: nan
agent1:                 episode reward: 0.4409,                 loss: 0.1538
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0864s / 83728.2738 s
agent0:                 episode reward: -0.3520,                 loss: nan
agent1:                 episode reward: 0.3520,                 loss: 0.1539
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1343s / 83864.4081 s
agent0:                 episode reward: -0.1476,                 loss: nan
agent1:                 episode reward: 0.1476,                 loss: 0.1526
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1967s / 83998.6048 s
agent0:                 episode reward: 0.0834,                 loss: nan
agent1:                 episode reward: -0.0834,                 loss: 0.1532
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9400s / 84132.5448 s
agent0:                 episode reward: -0.5092,                 loss: nan
agent1:                 episode reward: 0.5092,                 loss: 0.1544
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5340s / 84267.0788 s
agent0:                 episode reward: 0.0599,                 loss: nan
agent1:                 episode reward: -0.0599,                 loss: 0.1524
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2559s / 84403.3347 s
agent0:                 episode reward: -0.3681,                 loss: nan
agent1:                 episode reward: 0.3681,                 loss: 0.1540
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3269s / 84538.6616 s
agent0:                 episode reward: -0.1829,                 loss: nan
agent1:                 episode reward: 0.1829,                 loss: 0.1532
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7999s / 84671.4615 s
agent0:                 episode reward: -0.1212,                 loss: nan
agent1:                 episode reward: 0.1212,                 loss: 0.1539
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5749s / 84805.0363 s
agent0:                 episode reward: -0.0688,                 loss: nan
agent1:                 episode reward: 0.0688,                 loss: 0.1545
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7598s / 84940.7962 s
agent0:                 episode reward: -0.1617,                 loss: nan
agent1:                 episode reward: 0.1617,                 loss: 0.1561
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2073s / 85077.0035 s
agent0:                 episode reward: -0.5974,                 loss: nan
agent1:                 episode reward: 0.5974,                 loss: 0.1536
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4624s / 85213.4659 s
agent0:                 episode reward: -0.3405,                 loss: nan
agent1:                 episode reward: 0.3405,                 loss: 0.1535
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2230s / 85349.6889 s
agent0:                 episode reward: -0.5067,                 loss: nan
agent1:                 episode reward: 0.5067,                 loss: 0.1540
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1828s / 85483.8718 s
agent0:                 episode reward: -0.2322,                 loss: nan
agent1:                 episode reward: 0.2322,                 loss: 0.1534
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6185s / 85618.4903 s
agent0:                 episode reward: -0.0896,                 loss: nan
agent1:                 episode reward: 0.0896,                 loss: 0.1550
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4625s / 85753.9528 s
agent0:                 episode reward: -0.3535,                 loss: nan
agent1:                 episode reward: 0.3535,                 loss: 0.1576
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9244s / 85888.8772 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.1579
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4768s / 86023.3540 s
agent0:                 episode reward: -0.1621,                 loss: nan
agent1:                 episode reward: 0.1621,                 loss: 0.1594
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2003s / 86155.5543 s
agent0:                 episode reward: -0.5776,                 loss: nan
agent1:                 episode reward: 0.5776,                 loss: 0.1566
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2568s / 86290.8111 s
agent0:                 episode reward: -0.0231,                 loss: nan
agent1:                 episode reward: 0.0231,                 loss: 0.1588
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5081s / 86424.3192 s
agent0:                 episode reward: -0.8756,                 loss: nan
agent1:                 episode reward: 0.8756,                 loss: 0.1574
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2258s / 86558.5450 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: 0.1574
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3815s / 86692.9265 s
agent0:                 episode reward: -0.5095,                 loss: nan
agent1:                 episode reward: 0.5095,                 loss: 0.1577
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9384s / 86828.8649 s
agent0:                 episode reward: -0.4044,                 loss: nan
agent1:                 episode reward: 0.4044,                 loss: 0.1573
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8681s / 86963.7330 s
agent0:                 episode reward: -0.3348,                 loss: nan
agent1:                 episode reward: 0.3348,                 loss: 0.1558
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1543s / 87101.8873 s
agent0:                 episode reward: -0.4696,                 loss: nan
agent1:                 episode reward: 0.4696,                 loss: 0.1578
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0896s / 87235.9769 s
agent0:                 episode reward: -0.6121,                 loss: nan
agent1:                 episode reward: 0.6121,                 loss: 0.1573
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8517s / 87372.8287 s
agent0:                 episode reward: -0.7640,                 loss: nan
agent1:                 episode reward: 0.7640,                 loss: 0.1576
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3455s / 87508.1741 s
agent0:                 episode reward: -0.1215,                 loss: nan
agent1:                 episode reward: 0.1215,                 loss: 0.1571
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6711s / 87642.8453 s
agent0:                 episode reward: -0.3867,                 loss: nan
agent1:                 episode reward: 0.3867,                 loss: 0.1564
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0317s / 87777.8769 s
agent0:                 episode reward: -0.6272,                 loss: nan
agent1:                 episode reward: 0.6272,                 loss: 0.1573
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3225s / 87915.1995 s
agent0:                 episode reward: -0.1215,                 loss: nan
agent1:                 episode reward: 0.1215,                 loss: 0.1577
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1719s / 88055.3713 s
agent0:                 episode reward: -0.2212,                 loss: nan
agent1:                 episode reward: 0.2212,                 loss: 0.1582
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3856s / 88190.7569 s
agent0:                 episode reward: 0.1439,                 loss: nan
agent1:                 episode reward: -0.1439,                 loss: 0.1582
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6403s / 88327.3972 s
agent0:                 episode reward: -0.5183,                 loss: nan
agent1:                 episode reward: 0.5183,                 loss: 0.1572
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0669s / 88461.4641 s
agent0:                 episode reward: -0.7024,                 loss: nan
agent1:                 episode reward: 0.7024,                 loss: 0.1555
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4511s / 88598.9152 s
agent0:                 episode reward: -0.5278,                 loss: nan
agent1:                 episode reward: 0.5278,                 loss: 0.1575
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1083s / 88732.0235 s
agent0:                 episode reward: -0.0678,                 loss: nan
agent1:                 episode reward: 0.0678,                 loss: 0.1553
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3147s / 88866.3382 s
agent0:                 episode reward: -0.2608,                 loss: nan
agent1:                 episode reward: 0.2608,                 loss: 0.1571
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1836s / 89001.5218 s
agent0:                 episode reward: -0.0294,                 loss: nan
agent1:                 episode reward: 0.0294,                 loss: 0.1564
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1122s / 89134.6340 s
agent0:                 episode reward: -0.1573,                 loss: nan
agent1:                 episode reward: 0.1573,                 loss: 0.1572
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5511s / 89269.1851 s
agent0:                 episode reward: -0.6312,                 loss: nan
agent1:                 episode reward: 0.6312,                 loss: 0.1567
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7158s / 89402.9009 s
agent0:                 episode reward: -0.3245,                 loss: nan
agent1:                 episode reward: 0.3245,                 loss: 0.1570
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8977s / 89536.7986 s
agent0:                 episode reward: -0.5650,                 loss: nan
agent1:                 episode reward: 0.5650,                 loss: 0.1574
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6113s / 89673.4100 s
agent0:                 episode reward: 0.0031,                 loss: nan
agent1:                 episode reward: -0.0031,                 loss: 0.1567
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0500s / 89810.4600 s
agent0:                 episode reward: -0.4347,                 loss: nan
agent1:                 episode reward: 0.4347,                 loss: 0.1570
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7550s / 89945.2150 s
agent0:                 episode reward: -0.1175,                 loss: nan
agent1:                 episode reward: 0.1175,                 loss: 0.1575
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1296s / 90079.3446 s
agent0:                 episode reward: -0.4884,                 loss: nan
agent1:                 episode reward: 0.4884,                 loss: 0.1572
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5872s / 90216.9318 s
agent0:                 episode reward: -0.1841,                 loss: nan
agent1:                 episode reward: 0.1841,                 loss: 0.1556
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8838s / 90353.8156 s
agent0:                 episode reward: -0.4131,                 loss: nan
agent1:                 episode reward: 0.4131,                 loss: 0.1549
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6513s / 90492.4669 s
agent0:                 episode reward: -0.4658,                 loss: nan
agent1:                 episode reward: 0.4658,                 loss: 0.1557
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6619s / 90626.1289 s
agent0:                 episode reward: -0.4079,                 loss: nan
agent1:                 episode reward: 0.4079,                 loss: 0.1555
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5813s / 90764.7102 s
agent0:                 episode reward: -0.2111,                 loss: nan
agent1:                 episode reward: 0.2111,                 loss: 0.1557
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2424s / 90898.9526 s
agent0:                 episode reward: -0.9664,                 loss: nan
agent1:                 episode reward: 0.9664,                 loss: 0.1546
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5303s / 91037.4829 s
agent0:                 episode reward: -0.4495,                 loss: nan
agent1:                 episode reward: 0.4495,                 loss: 0.1557
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.6563s / 91169.1392 s
agent0:                 episode reward: 0.0602,                 loss: nan
agent1:                 episode reward: -0.0602,                 loss: 0.1563
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2503s / 91303.3895 s
agent0:                 episode reward: -0.3328,                 loss: nan
agent1:                 episode reward: 0.3328,                 loss: 0.1542
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7916s / 91437.1811 s
agent0:                 episode reward: -0.5132,                 loss: nan
agent1:                 episode reward: 0.5132,                 loss: 0.1549
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4862s / 91571.6673 s
agent0:                 episode reward: -0.1856,                 loss: nan
agent1:                 episode reward: 0.1856,                 loss: 0.1552
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1697s / 91703.8370 s
agent0:                 episode reward: -0.3666,                 loss: nan
agent1:                 episode reward: 0.3666,                 loss: 0.1559
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0815s / 91839.9186 s
agent0:                 episode reward: -0.4242,                 loss: nan
agent1:                 episode reward: 0.4242,                 loss: 0.1557
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4721s / 91972.3907 s
agent0:                 episode reward: -0.0320,                 loss: nan
agent1:                 episode reward: 0.0320,                 loss: 0.1556
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1203s / 92107.5110 s
agent0:                 episode reward: -0.5658,                 loss: nan
agent1:                 episode reward: 0.5658,                 loss: 0.1559
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2336s / 92243.7446 s
agent0:                 episode reward: -0.6855,                 loss: nan
agent1:                 episode reward: 0.6855,                 loss: 0.1552
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8891s / 92381.6337 s
agent0:                 episode reward: -0.1561,                 loss: nan
agent1:                 episode reward: 0.1561,                 loss: 0.1554
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9697s / 92513.6034 s
agent0:                 episode reward: 0.0502,                 loss: nan
agent1:                 episode reward: -0.0502,                 loss: 0.1533
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5800s / 92649.1834 s
agent0:                 episode reward: -0.4320,                 loss: nan
agent1:                 episode reward: 0.4320,                 loss: 0.1553
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4534s / 92784.6368 s
agent0:                 episode reward: -0.1978,                 loss: nan
agent1:                 episode reward: 0.1978,                 loss: 0.1561
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1156s / 92920.7524 s
agent0:                 episode reward: -0.0367,                 loss: nan
agent1:                 episode reward: 0.0367,                 loss: 0.1560
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7473s / 93054.4997 s
agent0:                 episode reward: -0.2756,                 loss: nan
agent1:                 episode reward: 0.2756,                 loss: 0.1582
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5497s / 93190.0495 s
agent0:                 episode reward: -0.5075,                 loss: nan
agent1:                 episode reward: 0.5075,                 loss: 0.1541
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7092s / 93329.7587 s
agent0:                 episode reward: -0.4243,                 loss: nan
agent1:                 episode reward: 0.4243,                 loss: 0.1560
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6840s / 93465.4427 s
agent0:                 episode reward: -0.4733,                 loss: nan