pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
random seed: [13, 60]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220112_0229/pettingzoo_boxing_v1_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220112_0229/pettingzoo_boxing_v1_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 21.0959s / 21.0959 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.2272
env0_second_0:                 episode reward: 3.0000,                 loss: 0.2158
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.2061s / 300.3020 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.0378
env0_second_0:                 episode reward: -0.4500,                 loss: -0.0406
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.6399s / 576.9419 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0937
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0963
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.4727s / 855.4146 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.0520
env0_second_0:                 episode reward: -1.1500,                 loss: -0.0524
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.8089s / 1133.2235 s
env0_first_0:                 episode reward: 1.2500,                 loss: -0.0822
env0_second_0:                 episode reward: -1.2500,                 loss: -0.0735
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.1958s / 1409.4193 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.0895
env0_second_0:                 episode reward: 1.0500,                 loss: -0.0825
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.9202s / 1688.3395 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0279
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0267
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.2918s / 1967.6313 s
env0_first_0:                 episode reward: -1.5000,                 loss: -0.0820
env0_second_0:                 episode reward: 1.5000,                 loss: -0.0809
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.4129s / 2245.0442 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.0914
env0_second_0:                 episode reward: 0.9500,                 loss: -0.0889
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.1484s / 2523.1926 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.0088
env0_second_0:                 episode reward: 0.3500,                 loss: -0.0069
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.5145s / 2801.7071 s
env0_first_0:                 episode reward: -1.3000,                 loss: -0.0361
env0_second_0:                 episode reward: 1.3000,                 loss: -0.0321
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.4216s / 3078.1287 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0543
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0529
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.2923s / 3356.4210 s
env0_first_0:                 episode reward: -4.0500,                 loss: -0.0036
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0014
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.8404s / 3634.2614 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.1493
env0_second_0:                 episode reward: 0.7000,                 loss: -0.1570
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 275.9614s / 3910.2228 s
env0_first_0:                 episode reward: -2.1000,                 loss: -0.0805
env0_second_0:                 episode reward: 2.1000,                 loss: -0.0752
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.5438s / 4187.7666 s
env0_first_0:                 episode reward: -2.2500,                 loss: -0.0606
env0_second_0:                 episode reward: 2.2500,                 loss: -0.0605
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.6200s / 4464.3865 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0360
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0331
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.4688s / 4740.8553 s
env0_first_0:                 episode reward: -2.6000,                 loss: -0.0333
env0_second_0:                 episode reward: 2.6000,                 loss: -0.0291
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.7361s / 5017.5914 s
env0_first_0:                 episode reward: -2.3500,                 loss: -0.0733
env0_second_0:                 episode reward: 2.3500,                 loss: -0.0776
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 281.4385s / 5299.0299 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.0464
env0_second_0:                 episode reward: -0.5500,                 loss: -0.0458
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 275.4417s / 5574.4716 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.0731
env0_second_0:                 episode reward: 0.0500,                 loss: -0.0803
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.0971s / 5851.5687 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0696
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0689
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.9123s / 6128.4810 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0004
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0009
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.8419s / 6406.3230 s
env0_first_0:                 episode reward: -1.8000,                 loss: -0.0249
env0_second_0:                 episode reward: 1.8000,                 loss: -0.0272
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.5355s / 6683.8584 s
env0_first_0:                 episode reward: -3.7500,                 loss: -0.0175
env0_second_0:                 episode reward: 3.7500,                 loss: -0.0214
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.3974s / 6960.2558 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0216
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0213
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 280.1140s / 7240.3698 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0432
env0_second_0:                 episode reward: -0.7000,                 loss: -0.0470
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.1462s / 7518.5160 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0431
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0366
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.6094s / 7798.1254 s
env0_first_0:                 episode reward: -1.7000,                 loss: -0.0751
env0_second_0:                 episode reward: 1.7000,                 loss: -0.0782
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.7408s / 8075.8663 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.0724
env0_second_0:                 episode reward: 1.2000,                 loss: -0.0807
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.6546s / 8354.5209 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0947
env0_second_0:                 episode reward: 0.0000,                 loss: -0.1008
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.6817s / 8632.2025 s
env0_first_0:                 episode reward: -1.4500,                 loss: -0.0067
env0_second_0:                 episode reward: 1.4500,                 loss: -0.0074
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.5495s / 8908.7521 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.0851
env0_second_0:                 episode reward: 1.0000,                 loss: -0.0837
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.2567s / 9187.0087 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.1030
env0_second_0:                 episode reward: 0.1500,                 loss: -0.1023
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.7220s / 9466.7307 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.0806
env0_second_0:                 episode reward: -1.1500,                 loss: -0.0838
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.8521s / 9746.5828 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0664
env0_second_0:                 episode reward: -0.2500,                 loss: -0.0694
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 280.4844s / 10027.0672 s
env0_first_0:                 episode reward: -2.3500,                 loss: -0.0139
env0_second_0:                 episode reward: 2.3500,                 loss: -0.0134
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.5610s / 10303.6282 s
env0_first_0:                 episode reward: -1.5000,                 loss: -0.0156
env0_second_0:                 episode reward: 1.5000,                 loss: -0.0206
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.9457s / 10581.5739 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.1178
env0_second_0:                 episode reward: -0.6000,                 loss: 0.1197
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.8039s / 10859.3778 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.0899
env0_second_0:                 episode reward: 6.7000,                 loss: 0.0706
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.6757s / 11136.0535 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0238
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.3951s / 11413.4486 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0522
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0488
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 280.4728s / 11693.9214 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0918
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0693
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.0693s / 11971.9907 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.1016
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0912
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.2793s / 12251.2700 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0382
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0316
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.9797s / 12531.2498 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0283
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0151
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.6254s / 12810.8752 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.0013
env0_second_0:                 episode reward: 0.5500,                 loss: -0.0073
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.8942s / 13088.7694 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0287
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0210
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 281.5740s / 13370.3433 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0445
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0384
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 285.0642s / 13655.4076 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0176
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0009
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 275.6009s / 13931.0084 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0905
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0801
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.2095s / 14209.2180 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0266
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0189
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.3771s / 14485.5950 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.1235
env0_second_0:                 episode reward: 2.3000,                 loss: 0.1109
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 282.2244s / 14767.8194 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0567
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0535
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.5734s / 15044.3928 s
env0_first_0:                 episode reward: -4.7000,                 loss: -0.0214
env0_second_0:                 episode reward: 4.7000,                 loss: -0.0245
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.0048s / 15320.3976 s
env0_first_0:                 episode reward: -3.2500,                 loss: -0.0048
env0_second_0:                 episode reward: 3.2500,                 loss: -0.0030
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.9591s / 15599.3567 s
env0_first_0:                 episode reward: -2.1500,                 loss: -0.0174
env0_second_0:                 episode reward: 2.1500,                 loss: -0.0188
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.2264s / 15877.5831 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0441
env0_second_0:                 episode reward: -0.2500,                 loss: -0.0517
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.4031s / 16154.9862 s
env0_first_0:                 episode reward: 3.6500,                 loss: -0.0035
env0_second_0:                 episode reward: -3.6500,                 loss: -0.0039
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 282.5047s / 16437.4909 s
env0_first_0:                 episode reward: -1.9500,                 loss: -0.0050
env0_second_0:                 episode reward: 1.9500,                 loss: -0.0057
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.9532s / 16714.4441 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0140
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0152
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.5596s / 16992.0037 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0626
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0630
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.9191s / 17270.9228 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0377
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0339
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.9721s / 17548.8949 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0000
env0_second_0:                 episode reward: 0.0500,                 loss: -0.0042
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.4230s / 17828.3178 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0219
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0101
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.0054s / 18106.3233 s
env0_first_0:                 episode reward: -6.5000,                 loss: 0.1069
env0_second_0:                 episode reward: 6.5000,                 loss: 0.1128
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 275.3738s / 18381.6971 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0491
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0440
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.3478s / 18659.0449 s
env0_first_0:                 episode reward: -2.2500,                 loss: -0.0481
env0_second_0:                 episode reward: 2.2500,                 loss: -0.0476
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.5324s / 18935.5773 s
env0_first_0:                 episode reward: -1.5000,                 loss: -0.2050
env0_second_0:                 episode reward: 1.5000,                 loss: -0.2178
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.4673s / 19213.0445 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.2087
env0_second_0:                 episode reward: 1.1000,                 loss: -0.2225
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.0628s / 19490.1074 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.2279
env0_second_0:                 episode reward: -0.6000,                 loss: -0.2407
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.8094s / 19766.9168 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.1007
env0_second_0:                 episode reward: 0.1000,                 loss: -0.1091
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.0304s / 20043.9471 s
env0_first_0:                 episode reward: -2.3500,                 loss: -0.0461
env0_second_0:                 episode reward: 2.3500,                 loss: -0.0540
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.5615s / 20323.5086 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0941
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0816
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 274.8566s / 20598.3652 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.1225
env0_second_0:                 episode reward: 2.9000,                 loss: 0.1210
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 274.9989s / 20873.3641 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.1540
env0_second_0:                 episode reward: 2.3500,                 loss: 0.1544
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.0477s / 21151.4118 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0297
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 273.2564s / 21424.6682 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.1753
env0_second_0:                 episode reward: 4.3000,                 loss: 0.1774
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.7820s / 21703.4503 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.1039
env0_second_0:                 episode reward: 3.0500,                 loss: 0.1085
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.0041s / 21980.4543 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0522
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0589
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 275.3782s / 22255.8326 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.1957
env0_second_0:                 episode reward: 2.6000,                 loss: 0.1874
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 274.7256s / 22530.5582 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.2392
env0_second_0:                 episode reward: 2.9500,                 loss: 0.2353
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.5819s / 22807.1401 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.1346
env0_second_0:                 episode reward: 6.1000,                 loss: 0.1311
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.3973s / 23083.5375 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.3835
env0_second_0:                 episode reward: 5.7000,                 loss: 0.3815
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 275.2240s / 23358.7615 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.1998
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1726
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.8573s / 23636.6188 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.1210
env0_second_0:                 episode reward: 2.5000,                 loss: 0.1155
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.2158s / 23914.8346 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.1069
env0_second_0:                 episode reward: 2.3500,                 loss: 0.1130
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.1931s / 24193.0277 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.1676
env0_second_0:                 episode reward: 2.8000,                 loss: 0.1634
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.8935s / 24469.9212 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.1537
env0_second_0:                 episode reward: 5.2500,                 loss: 0.1392
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.2103s / 24749.1314 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.2873
env0_second_0:                 episode reward: 5.4000,                 loss: 0.2809
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.4054s / 25027.5368 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.3382
env0_second_0:                 episode reward: 3.5500,                 loss: 0.3156
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 275.3882s / 25302.9250 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.3839
env0_second_0:                 episode reward: 8.4500,                 loss: 0.3787
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.3968s / 25579.3218 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.6644
env0_second_0:                 episode reward: 13.8500,                 loss: 0.6601
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1768.8,                last time consumption/overall running time: 276.2264s / 25855.5482 s
env0_first_0:                 episode reward: -21.7500,                 loss: 1.2179
env0_second_0:                 episode reward: 21.7500,                 loss: 1.2034
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1753.7,                last time consumption/overall running time: 270.7565s / 26126.3047 s
env0_first_0:                 episode reward: -21.4500,                 loss: 1.5336
env0_second_0:                 episode reward: 21.4500,                 loss: 1.4603
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1783.75,                last time consumption/overall running time: 279.1909s / 26405.4955 s
env0_first_0:                 episode reward: -11.9500,                 loss: 1.1371
env0_second_0:                 episode reward: 11.9500,                 loss: 1.0363
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1734.2,                last time consumption/overall running time: 265.9059s / 26671.4015 s
env0_first_0:                 episode reward: -26.6000,                 loss: 1.7782
env0_second_0:                 episode reward: 26.6000,                 loss: 1.7261
env1_first_0:                 episode reward: -20.6500,                 loss: nan
env1_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1717.6,                last time consumption/overall running time: 265.0856s / 26936.4871 s
env0_first_0:                 episode reward: -33.0500,                 loss: 2.1828
env0_second_0:                 episode reward: 33.0500,                 loss: 2.1191
env1_first_0:                 episode reward: -22.7500,                 loss: nan
env1_second_0:                 episode reward: 22.7500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 1491.15,                last time consumption/overall running time: 232.1006s / 27168.5876 s
env0_first_0:                 episode reward: -43.1500,                 loss: 4.0610
env0_second_0:                 episode reward: 43.1500,                 loss: 3.9910
env1_first_0:                 episode reward: -32.5500,                 loss: nan
env1_second_0:                 episode reward: 32.5500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1354.35,                last time consumption/overall running time: 212.0352s / 27380.6229 s
env0_first_0:                 episode reward: -46.7500,                 loss: 4.4555
env0_second_0:                 episode reward: 46.7500,                 loss: 4.3860
env1_first_0:                 episode reward: -36.8000,                 loss: nan
env1_second_0:                 episode reward: 36.8000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1399.5,                last time consumption/overall running time: 220.8171s / 27601.4400 s
env0_first_0:                 episode reward: -34.7500,                 loss: 4.7166
env0_second_0:                 episode reward: 34.7500,                 loss: 4.6402
env1_first_0:                 episode reward: -44.5000,                 loss: nan
env1_second_0:                 episode reward: 44.5000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1391.35,                last time consumption/overall running time: 220.3091s / 27821.7491 s
env0_first_0:                 episode reward: -41.0500,                 loss: 4.3971
env0_second_0:                 episode reward: 41.0500,                 loss: 4.3660
env1_first_0:                 episode reward: -31.2500,                 loss: nan
env1_second_0:                 episode reward: 31.2500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1226.7,                last time consumption/overall running time: 195.2511s / 28017.0002 s
env0_first_0:                 episode reward: -35.3500,                 loss: 5.2480
env0_second_0:                 episode reward: 35.3500,                 loss: 5.2575
env1_first_0:                 episode reward: -42.4500,                 loss: nan
env1_second_0:                 episode reward: 42.4500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1217.95,                last time consumption/overall running time: 192.7840s / 28209.7842 s
env0_first_0:                 episode reward: -51.1500,                 loss: 5.4360
env0_second_0:                 episode reward: 51.1500,                 loss: 5.4525
env1_first_0:                 episode reward: -34.9500,                 loss: nan
env1_second_0:                 episode reward: 34.9500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1365.7,                last time consumption/overall running time: 214.0119s / 28423.7961 s
env0_first_0:                 episode reward: -36.0000,                 loss: 4.5882
env0_second_0:                 episode reward: 36.0000,                 loss: 4.6392
env1_first_0:                 episode reward: -44.3000,                 loss: nan
env1_second_0:                 episode reward: 44.3000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1321.35,                last time consumption/overall running time: 207.9482s / 28631.7443 s
env0_first_0:                 episode reward: -38.1000,                 loss: 4.6025
env0_second_0:                 episode reward: 38.1000,                 loss: 4.5870
env1_first_0:                 episode reward: -37.6000,                 loss: nan
env1_second_0:                 episode reward: 37.6000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1192.25,                last time consumption/overall running time: 187.7397s / 28819.4840 s
env0_first_0:                 episode reward: -39.2000,                 loss: 5.1583
env0_second_0:                 episode reward: 39.2000,                 loss: 5.2174
env1_first_0:                 episode reward: -40.2500,                 loss: nan
env1_second_0:                 episode reward: 40.2500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 1264.65,                last time consumption/overall running time: 197.8627s / 29017.3467 s
env0_first_0:                 episode reward: -47.9000,                 loss: 5.3556
env0_second_0:                 episode reward: 47.9000,                 loss: 5.4233
env1_first_0:                 episode reward: -38.2500,                 loss: nan
env1_second_0:                 episode reward: 38.2500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1490.85,                last time consumption/overall running time: 233.3814s / 29250.7282 s
env0_first_0:                 episode reward: -32.9500,                 loss: 3.2084
env0_second_0:                 episode reward: 32.9500,                 loss: 3.2192
env1_first_0:                 episode reward: -30.7000,                 loss: nan
env1_second_0:                 episode reward: 30.7000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1285.3,                last time consumption/overall running time: 202.4298s / 29453.1580 s
env0_first_0:                 episode reward: -38.0500,                 loss: 4.7313
env0_second_0:                 episode reward: 38.0500,                 loss: 4.7976
env1_first_0:                 episode reward: -37.5000,                 loss: nan
env1_second_0:                 episode reward: 37.5000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1299.15,                last time consumption/overall running time: 204.9258s / 29658.0838 s
env0_first_0:                 episode reward: -32.4000,                 loss: 4.7769
env0_second_0:                 episode reward: 32.4000,                 loss: 4.8431
env1_first_0:                 episode reward: -31.7000,                 loss: nan
env1_second_0:                 episode reward: 31.7000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 1231.35,                last time consumption/overall running time: 197.4108s / 29855.4946 s
env0_first_0:                 episode reward: -39.2500,                 loss: 5.3206
env0_second_0:                 episode reward: 39.2500,                 loss: 5.3773
env1_first_0:                 episode reward: -33.0000,                 loss: nan
env1_second_0:                 episode reward: 33.0000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 1463.2,                last time consumption/overall running time: 228.4648s / 30083.9594 s
env0_first_0:                 episode reward: -31.2000,                 loss: 3.4536
env0_second_0:                 episode reward: 31.2000,                 loss: 3.5559
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 1331.1,                last time consumption/overall running time: 211.3423s / 30295.3017 s
env0_first_0:                 episode reward: -32.0500,                 loss: 4.6659
env0_second_0:                 episode reward: 32.0500,                 loss: 4.7796
env1_first_0:                 episode reward: -32.7500,                 loss: nan
env1_second_0:                 episode reward: 32.7500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 1379.4,                last time consumption/overall running time: 217.8288s / 30513.1306 s
env0_first_0:                 episode reward: -27.5500,                 loss: 4.2483
env0_second_0:                 episode reward: 27.5500,                 loss: 4.2307
env1_first_0:                 episode reward: -30.0000,                 loss: nan
env1_second_0:                 episode reward: 30.0000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 1348.95,                last time consumption/overall running time: 212.6195s / 30725.7501 s
env0_first_0:                 episode reward: -42.2500,                 loss: 5.0108
env0_second_0:                 episode reward: 42.2500,                 loss: 5.0922
env1_first_0:                 episode reward: -35.0000,                 loss: nan
env1_second_0:                 episode reward: 35.0000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1328.4,                last time consumption/overall running time: 212.0406s / 30937.7907 s
env0_first_0:                 episode reward: -32.2500,                 loss: 4.3830
env0_second_0:                 episode reward: 32.2500,                 loss: 4.4103
env1_first_0:                 episode reward: -29.3500,                 loss: nan
env1_second_0:                 episode reward: 29.3500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1343.15,                last time consumption/overall running time: 212.4829s / 31150.2736 s
env0_first_0:                 episode reward: -31.7500,                 loss: 4.7149
env0_second_0:                 episode reward: 31.7500,                 loss: 4.7246
env1_first_0:                 episode reward: -33.2500,                 loss: nan
env1_second_0:                 episode reward: 33.2500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1341.55,                last time consumption/overall running time: 212.5245s / 31362.7981 s
env0_first_0:                 episode reward: -32.8500,                 loss: 4.4049
env0_second_0:                 episode reward: 32.8500,                 loss: 4.3882
env1_first_0:                 episode reward: -33.1000,                 loss: nan
env1_second_0:                 episode reward: 33.1000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1533.35,                last time consumption/overall running time: 243.7927s / 31606.5908 s
env0_first_0:                 episode reward: -34.4000,                 loss: 3.4868
env0_second_0:                 episode reward: 34.4000,                 loss: 3.5998
env1_first_0:                 episode reward: -31.6500,                 loss: nan
env1_second_0:                 episode reward: 31.6500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 1372.05,                last time consumption/overall running time: 215.4387s / 31822.0295 s
env0_first_0:                 episode reward: -37.3500,                 loss: 4.7338
env0_second_0:                 episode reward: 37.3500,                 loss: 4.8029
env1_first_0:                 episode reward: -40.2500,                 loss: nan
env1_second_0:                 episode reward: 40.2500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1405.8,                last time consumption/overall running time: 220.7681s / 32042.7977 s
env0_first_0:                 episode reward: -32.4000,                 loss: 4.6295
env0_second_0:                 episode reward: 32.4000,                 loss: 4.6588
env1_first_0:                 episode reward: -38.6500,                 loss: nan
env1_second_0:                 episode reward: 38.6500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1407.35,                last time consumption/overall running time: 221.5727s / 32264.3704 s
env0_first_0:                 episode reward: -35.3000,                 loss: 4.2333
env0_second_0:                 episode reward: 35.3000,                 loss: 4.3573
env1_first_0:                 episode reward: -35.4000,                 loss: nan
env1_second_0:                 episode reward: 35.4000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1227.25,                last time consumption/overall running time: 193.6249s / 32457.9953 s
env0_first_0:                 episode reward: -36.2500,                 loss: 5.5224
env0_second_0:                 episode reward: 36.2500,                 loss: 5.5160
env1_first_0:                 episode reward: -41.4500,                 loss: nan
env1_second_0:                 episode reward: 41.4500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1151.8,                last time consumption/overall running time: 183.4865s / 32641.4817 s
env0_first_0:                 episode reward: -32.1500,                 loss: 5.7102
env0_second_0:                 episode reward: 32.1500,                 loss: 5.6365
env1_first_0:                 episode reward: -32.0500,                 loss: nan
env1_second_0:                 episode reward: 32.0500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1278.05,                last time consumption/overall running time: 201.7666s / 32843.2483 s
env0_first_0:                 episode reward: -31.3500,                 loss: 4.9627
env0_second_0:                 episode reward: 31.3500,                 loss: 4.9369
env1_first_0:                 episode reward: -30.2500,                 loss: nan
env1_second_0:                 episode reward: 30.2500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 1148.3,                last time consumption/overall running time: 182.7460s / 33025.9943 s
env0_first_0:                 episode reward: -41.8000,                 loss: 5.0767
env0_second_0:                 episode reward: 41.8000,                 loss: 5.0268
env1_first_0:                 episode reward: -40.9500,                 loss: nan
env1_second_0:                 episode reward: 40.9500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1038.25,                last time consumption/overall running time: 166.4996s / 33192.4939 s
env0_first_0:                 episode reward: -40.1000,                 loss: 6.2391
env0_second_0:                 episode reward: 40.1000,                 loss: 6.2934
env1_first_0:                 episode reward: -49.6500,                 loss: nan
env1_second_0:                 episode reward: 49.6500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1080.8,                last time consumption/overall running time: 172.1235s / 33364.6174 s
env0_first_0:                 episode reward: -38.0500,                 loss: 6.0500
env0_second_0:                 episode reward: 38.0500,                 loss: 6.0701
env1_first_0:                 episode reward: -45.5000,                 loss: nan
env1_second_0:                 episode reward: 45.5000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1259.05,                last time consumption/overall running time: 200.9102s / 33565.5275 s
env0_first_0:                 episode reward: -41.1000,                 loss: 5.2938
env0_second_0:                 episode reward: 41.1000,                 loss: 5.2265
env1_first_0:                 episode reward: -39.1000,                 loss: nan
env1_second_0:                 episode reward: 39.1000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1191.85,                last time consumption/overall running time: 190.1761s / 33755.7037 s
env0_first_0:                 episode reward: -38.9500,                 loss: 5.7251
env0_second_0:                 episode reward: 38.9500,                 loss: 5.5767
env1_first_0:                 episode reward: -36.7500,                 loss: nan
env1_second_0:                 episode reward: 36.7500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1206.75,                last time consumption/overall running time: 193.1148s / 33948.8185 s
env0_first_0:                 episode reward: -38.9500,                 loss: 5.4728
env0_second_0:                 episode reward: 38.9500,                 loss: 5.3963
env1_first_0:                 episode reward: -38.1500,                 loss: nan
env1_second_0:                 episode reward: 38.1500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1254.55,                last time consumption/overall running time: 198.4128s / 34147.2313 s
env0_first_0:                 episode reward: -33.5500,                 loss: 5.7776
env0_second_0:                 episode reward: 33.5500,                 loss: 5.5636
env1_first_0:                 episode reward: -31.2000,                 loss: nan
env1_second_0:                 episode reward: 31.2000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 1308.25,                last time consumption/overall running time: 209.5408s / 34356.7721 s
env0_first_0:                 episode reward: -29.5500,                 loss: 4.8987
env0_second_0:                 episode reward: 29.5500,                 loss: 4.7884
env1_first_0:                 episode reward: -33.8500,                 loss: nan
env1_second_0:                 episode reward: 33.8500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1262.3,                last time consumption/overall running time: 198.9743s / 34555.7464 s
env0_first_0:                 episode reward: -31.4500,                 loss: 4.2962
env0_second_0:                 episode reward: 31.4500,                 loss: 4.4052
env1_first_0:                 episode reward: -22.4500,                 loss: nan
env1_second_0:                 episode reward: 22.4500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 1122.7,                last time consumption/overall running time: 180.7891s / 34736.5356 s
env0_first_0:                 episode reward: -44.9500,                 loss: 4.3641
env0_second_0:                 episode reward: 44.9500,                 loss: 4.4577
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1185.2,                last time consumption/overall running time: 188.5998s / 34925.1353 s
env0_first_0:                 episode reward: -42.1500,                 loss: 5.4880
env0_second_0:                 episode reward: 42.1500,                 loss: 5.3860
env1_first_0:                 episode reward: -42.3500,                 loss: nan
env1_second_0:                 episode reward: 42.3500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1219.75,                last time consumption/overall running time: 193.5697s / 35118.7050 s
env0_first_0:                 episode reward: -27.0000,                 loss: 5.4523
env0_second_0:                 episode reward: 27.0000,                 loss: 5.3315
env1_first_0:                 episode reward: -35.1000,                 loss: nan
env1_second_0:                 episode reward: 35.1000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 1059.75,                last time consumption/overall running time: 170.4191s / 35289.1241 s
env0_first_0:                 episode reward: -37.2000,                 loss: 6.7782
env0_second_0:                 episode reward: 37.2000,                 loss: 6.6742
env1_first_0:                 episode reward: -38.7000,                 loss: nan
env1_second_0:                 episode reward: 38.7000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1064.4,                last time consumption/overall running time: 170.6217s / 35459.7457 s
env0_first_0:                 episode reward: -42.5000,                 loss: 6.6403
env0_second_0:                 episode reward: 42.5000,                 loss: 6.4759
env1_first_0:                 episode reward: -38.3000,                 loss: nan
env1_second_0:                 episode reward: 38.3000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1063.25,                last time consumption/overall running time: 169.9509s / 35629.6966 s
env0_first_0:                 episode reward: -47.6000,                 loss: 7.0427
env0_second_0:                 episode reward: 47.6000,                 loss: 6.9209
env1_first_0:                 episode reward: -39.2500,                 loss: nan
env1_second_0:                 episode reward: 39.2500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1043.45,                last time consumption/overall running time: 166.5046s / 35796.2012 s
env0_first_0:                 episode reward: -43.4500,                 loss: 7.9020
env0_second_0:                 episode reward: 43.4500,                 loss: 7.8288
env1_first_0:                 episode reward: -47.0500,                 loss: nan
env1_second_0:                 episode reward: 47.0500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1101.6,                last time consumption/overall running time: 175.3296s / 35971.5308 s
env0_first_0:                 episode reward: -35.7500,                 loss: 7.2179
env0_second_0:                 episode reward: 35.7500,                 loss: 7.0506
env1_first_0:                 episode reward: -44.3500,                 loss: nan
env1_second_0:                 episode reward: 44.3500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1092.3,                last time consumption/overall running time: 173.3730s / 36144.9038 s
env0_first_0:                 episode reward: -38.8500,                 loss: 7.6513
env0_second_0:                 episode reward: 38.8500,                 loss: 7.5546
env1_first_0:                 episode reward: -47.1000,                 loss: nan
env1_second_0:                 episode reward: 47.1000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1269.0,                last time consumption/overall running time: 199.2959s / 36344.1997 s
env0_first_0:                 episode reward: -36.0000,                 loss: 6.7385
env0_second_0:                 episode reward: 36.0000,                 loss: 6.5067
env1_first_0:                 episode reward: -39.8500,                 loss: nan
env1_second_0:                 episode reward: 39.8500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1219.1,                last time consumption/overall running time: 193.2096s / 36537.4093 s
env0_first_0:                 episode reward: -42.1000,                 loss: 6.5576
env0_second_0:                 episode reward: 42.1000,                 loss: 6.4515
env1_first_0:                 episode reward: -37.8000,                 loss: nan
env1_second_0:                 episode reward: 37.8000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 1117.85,                last time consumption/overall running time: 178.9710s / 36716.3803 s
env0_first_0:                 episode reward: -40.2000,                 loss: 8.1927
env0_second_0:                 episode reward: 40.2000,                 loss: 7.9124
env1_first_0:                 episode reward: -49.9000,                 loss: nan
env1_second_0:                 episode reward: 49.9000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1085.25,                last time consumption/overall running time: 173.6527s / 36890.0330 s
env0_first_0:                 episode reward: -41.3500,                 loss: 7.9368
env0_second_0:                 episode reward: 41.3500,                 loss: 7.7036
env1_first_0:                 episode reward: -37.0500,                 loss: nan
env1_second_0:                 episode reward: 37.0500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 1084.3,                last time consumption/overall running time: 173.9629s / 37063.9959 s
env0_first_0:                 episode reward: -43.6500,                 loss: 8.2633
env0_second_0:                 episode reward: 43.6500,                 loss: 8.0291
env1_first_0:                 episode reward: -43.2000,                 loss: nan
env1_second_0:                 episode reward: 43.2000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1097.3,                last time consumption/overall running time: 176.7698s / 37240.7657 s
env0_first_0:                 episode reward: -45.2500,                 loss: 8.3020
env0_second_0:                 episode reward: 45.2500,                 loss: 8.1464
env1_first_0:                 episode reward: -36.9000,                 loss: nan
env1_second_0:                 episode reward: 36.9000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1081.3,                last time consumption/overall running time: 174.4793s / 37415.2450 s
env0_first_0:                 episode reward: -39.4500,                 loss: 8.4037
env0_second_0:                 episode reward: 39.4500,                 loss: 8.3074
env1_first_0:                 episode reward: -46.4500,                 loss: nan
env1_second_0:                 episode reward: 46.4500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1129.65,                last time consumption/overall running time: 179.9675s / 37595.2125 s
env0_first_0:                 episode reward: -37.9500,                 loss: 8.5684
env0_second_0:                 episode reward: 37.9500,                 loss: 8.3050
env1_first_0:                 episode reward: -50.7000,                 loss: nan
env1_second_0:                 episode reward: 50.7000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1116.65,                last time consumption/overall running time: 178.6949s / 37773.9074 s
env0_first_0:                 episode reward: -42.3000,                 loss: 8.3688
env0_second_0:                 episode reward: 42.3000,                 loss: 8.1349
env1_first_0:                 episode reward: -37.7000,                 loss: nan
env1_second_0:                 episode reward: 37.7000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1096.15,                last time consumption/overall running time: 175.6797s / 37949.5871 s
env0_first_0:                 episode reward: -40.2000,                 loss: 8.8408
env0_second_0:                 episode reward: 40.2000,                 loss: 8.5385
env1_first_0:                 episode reward: -42.5500,                 loss: nan
env1_second_0:                 episode reward: 42.5500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1127.65,                last time consumption/overall running time: 180.8897s / 38130.4768 s
env0_first_0:                 episode reward: -40.8500,                 loss: 7.9655
env0_second_0:                 episode reward: 40.8500,                 loss: 7.6899
env1_first_0:                 episode reward: -33.1000,                 loss: nan
env1_second_0:                 episode reward: 33.1000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1108.55,                last time consumption/overall running time: 175.8367s / 38306.3135 s
env0_first_0:                 episode reward: -37.0500,                 loss: 8.6842
env0_second_0:                 episode reward: 37.0500,                 loss: 8.4694
env1_first_0:                 episode reward: -46.3000,                 loss: nan
env1_second_0:                 episode reward: 46.3000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1093.9,                last time consumption/overall running time: 175.3297s / 38481.6433 s
env0_first_0:                 episode reward: -41.6000,                 loss: 9.5819
env0_second_0:                 episode reward: 41.6000,                 loss: 9.3029
env1_first_0:                 episode reward: -44.5000,                 loss: nan
env1_second_0:                 episode reward: 44.5000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1086.25,                last time consumption/overall running time: 173.4324s / 38655.0756 s
env0_first_0:                 episode reward: -41.8500,                 loss: 9.8263
env0_second_0:                 episode reward: 41.8500,                 loss: 9.5459
env1_first_0:                 episode reward: -48.3500,                 loss: nan
env1_second_0:                 episode reward: 48.3500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1011.65,                last time consumption/overall running time: 162.0984s / 38817.1740 s
env0_first_0:                 episode reward: -42.6500,                 loss: 10.0625
env0_second_0:                 episode reward: 42.6500,                 loss: 9.8379
env1_first_0:                 episode reward: -44.8500,                 loss: nan
env1_second_0:                 episode reward: 44.8500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1098.35,                last time consumption/overall running time: 173.8186s / 38990.9926 s
env0_first_0:                 episode reward: -41.8000,                 loss: 10.2490
env0_second_0:                 episode reward: 41.8000,                 loss: 9.8660
env1_first_0:                 episode reward: -41.0000,                 loss: nan
env1_second_0:                 episode reward: 41.0000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1224.25,                last time consumption/overall running time: 194.0590s / 39185.0516 s
env0_first_0:                 episode reward: -42.2000,                 loss: 9.1494
env0_second_0:                 episode reward: 42.2000,                 loss: 8.9600
env1_first_0:                 episode reward: -39.9500,                 loss: nan
env1_second_0:                 episode reward: 39.9500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1044.85,                last time consumption/overall running time: 164.3352s / 39349.3867 s
env0_first_0:                 episode reward: -47.0500,                 loss: 11.5667
env0_second_0:                 episode reward: 47.0500,                 loss: 11.0825
env1_first_0:                 episode reward: -53.0000,                 loss: nan
env1_second_0:                 episode reward: 53.0000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1070.45,                last time consumption/overall running time: 170.6197s / 39520.0064 s
env0_first_0:                 episode reward: -51.8500,                 loss: 11.3867
env0_second_0:                 episode reward: 51.8500,                 loss: 10.9626
env1_first_0:                 episode reward: -39.5500,                 loss: nan
env1_second_0:                 episode reward: 39.5500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 973.75,                last time consumption/overall running time: 156.6769s / 39676.6833 s
env0_first_0:                 episode reward: -49.7000,                 loss: 12.4042
env0_second_0:                 episode reward: 49.7000,                 loss: 12.0908
env1_first_0:                 episode reward: -49.0500,                 loss: nan
env1_second_0:                 episode reward: 49.0500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 882.7,                last time consumption/overall running time: 143.0070s / 39819.6903 s
env0_first_0:                 episode reward: -47.3500,                 loss: 13.1141
env0_second_0:                 episode reward: 47.3500,                 loss: 12.9214
env1_first_0:                 episode reward: -53.0000,                 loss: nan
env1_second_0:                 episode reward: 53.0000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1087.95,                last time consumption/overall running time: 173.2832s / 39992.9736 s
env0_first_0:                 episode reward: -52.4500,                 loss: 10.9429
env0_second_0:                 episode reward: 52.4500,                 loss: 10.7403
env1_first_0:                 episode reward: -44.5500,                 loss: nan
env1_second_0:                 episode reward: 44.5500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1019.75,                last time consumption/overall running time: 163.0978s / 40156.0714 s
env0_first_0:                 episode reward: -47.6500,                 loss: 12.0692
env0_second_0:                 episode reward: 47.6500,                 loss: 11.8278
env1_first_0:                 episode reward: -45.7000,                 loss: nan
env1_second_0:                 episode reward: 45.7000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1063.7,                last time consumption/overall running time: 170.1080s / 40326.1794 s
env0_first_0:                 episode reward: -57.1500,                 loss: 12.4036
env0_second_0:                 episode reward: 57.1500,                 loss: 12.2294
env1_first_0:                 episode reward: -51.9000,                 loss: nan
env1_second_0:                 episode reward: 51.9000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1000.15,                last time consumption/overall running time: 161.4395s / 40487.6189 s
env0_first_0:                 episode reward: -52.8000,                 loss: 12.2279
env0_second_0:                 episode reward: 52.8000,                 loss: 12.1109
env1_first_0:                 episode reward: -50.1000,                 loss: nan
env1_second_0:                 episode reward: 50.1000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1162.35,                last time consumption/overall running time: 183.7162s / 40671.3351 s
env0_first_0:                 episode reward: -39.3000,                 loss: 9.7781
env0_second_0:                 episode reward: 39.3000,                 loss: 9.4676
env1_first_0:                 episode reward: -36.7000,                 loss: nan
env1_second_0:                 episode reward: 36.7000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 975.3,                last time consumption/overall running time: 155.9565s / 40827.2916 s
env0_first_0:                 episode reward: -44.4000,                 loss: 11.3962
env0_second_0:                 episode reward: 44.4000,                 loss: 11.2857
env1_first_0:                 episode reward: -42.6500,                 loss: nan
env1_second_0:                 episode reward: 42.6500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1134.15,                last time consumption/overall running time: 180.6356s / 41007.9272 s
env0_first_0:                 episode reward: -28.1000,                 loss: 8.0158
env0_second_0:                 episode reward: 28.1000,                 loss: 8.0108
env1_first_0:                 episode reward: -35.9000,                 loss: nan
env1_second_0:                 episode reward: 35.9000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1048.0,                last time consumption/overall running time: 168.6000s / 41176.5272 s
env0_first_0:                 episode reward: -42.1500,                 loss: 8.7933
env0_second_0:                 episode reward: 42.1500,                 loss: 8.5457
env1_first_0:                 episode reward: -37.0500,                 loss: nan
env1_second_0:                 episode reward: 37.0500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 818.25,                last time consumption/overall running time: 133.7303s / 41310.2574 s
env0_first_0:                 episode reward: -53.6500,                 loss: 14.7041
env0_second_0:                 episode reward: 53.6500,                 loss: 14.3144
env1_first_0:                 episode reward: -46.3500,                 loss: nan
env1_second_0:                 episode reward: 46.3500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 697.3,                last time consumption/overall running time: 115.4724s / 41425.7298 s
env0_first_0:                 episode reward: -62.3500,                 loss: 18.6527
env0_second_0:                 episode reward: 62.3500,                 loss: 18.3017
env1_first_0:                 episode reward: -51.4000,                 loss: nan
env1_second_0:                 episode reward: 51.4000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 607.55,                last time consumption/overall running time: 101.4030s / 41527.1328 s
env0_first_0:                 episode reward: -56.5000,                 loss: 19.2161
env0_second_0:                 episode reward: 56.5000,                 loss: 18.6685
env1_first_0:                 episode reward: -63.9500,                 loss: nan
env1_second_0:                 episode reward: 63.9500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 744.95,                last time consumption/overall running time: 124.0751s / 41651.2079 s
env0_first_0:                 episode reward: -55.6500,                 loss: 16.3134
env0_second_0:                 episode reward: 55.6500,                 loss: 16.4159
env1_first_0:                 episode reward: -60.0500,                 loss: nan
env1_second_0:                 episode reward: 60.0500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 600.55,                last time consumption/overall running time: 101.0936s / 41752.3014 s
env0_first_0:                 episode reward: -66.8000,                 loss: 19.6658
env0_second_0:                 episode reward: 66.8000,                 loss: 19.5577
env1_first_0:                 episode reward: -56.0000,                 loss: nan
env1_second_0:                 episode reward: 56.0000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 834.95,                last time consumption/overall running time: 135.8241s / 41888.1256 s
env0_first_0:                 episode reward: -69.1500,                 loss: 16.8289
env0_second_0:                 episode reward: 69.1500,                 loss: 17.1840
env1_first_0:                 episode reward: -54.5500,                 loss: nan
env1_second_0:                 episode reward: 54.5500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 875.2,                last time consumption/overall running time: 142.6511s / 42030.7767 s
env0_first_0:                 episode reward: -57.1000,                 loss: 14.6892
env0_second_0:                 episode reward: 57.1000,                 loss: 15.1671
env1_first_0:                 episode reward: -50.5000,                 loss: nan
env1_second_0:                 episode reward: 50.5000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 887.1,                last time consumption/overall running time: 144.3968s / 42175.1734 s
env0_first_0:                 episode reward: -65.3500,                 loss: 15.1475
env0_second_0:                 episode reward: 65.3500,                 loss: 15.1156
env1_first_0:                 episode reward: -57.8500,                 loss: nan
env1_second_0:                 episode reward: 57.8500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 885.75,                last time consumption/overall running time: 144.9387s / 42320.1122 s
env0_first_0:                 episode reward: -55.0500,                 loss: 16.0552
env0_second_0:                 episode reward: 55.0500,                 loss: 16.1559
env1_first_0:                 episode reward: -63.3000,                 loss: nan
env1_second_0:                 episode reward: 63.3000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 780.85,                last time consumption/overall running time: 125.0600s / 42445.1721 s
env0_first_0:                 episode reward: -53.4000,                 loss: 17.3579
env0_second_0:                 episode reward: 53.4000,                 loss: 17.4854
env1_first_0:                 episode reward: -61.4500,                 loss: nan
env1_second_0:                 episode reward: 61.4500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 707.7,                last time consumption/overall running time: 119.0209s / 42564.1931 s
env0_first_0:                 episode reward: -57.5500,                 loss: 18.2876
env0_second_0:                 episode reward: 57.5500,                 loss: 18.3063
env1_first_0:                 episode reward: -59.8500,                 loss: nan
env1_second_0:                 episode reward: 59.8500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 667.2,                last time consumption/overall running time: 111.5049s / 42675.6980 s
env0_first_0:                 episode reward: -68.6000,                 loss: 21.1215
env0_second_0:                 episode reward: 68.6000,                 loss: 20.5122
env1_first_0:                 episode reward: -50.0000,                 loss: nan
env1_second_0:                 episode reward: 50.0000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 684.65,                last time consumption/overall running time: 114.7074s / 42790.4054 s
env0_first_0:                 episode reward: -61.8500,                 loss: 19.6339
env0_second_0:                 episode reward: 61.8500,                 loss: 19.8589
env1_first_0:                 episode reward: -56.7000,                 loss: nan
env1_second_0:                 episode reward: 56.7000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 701.85,                last time consumption/overall running time: 116.4422s / 42906.8476 s
env0_first_0:                 episode reward: -63.5500,                 loss: 21.7369
env0_second_0:                 episode reward: 63.5500,                 loss: 21.4907
env1_first_0:                 episode reward: -65.0500,                 loss: nan
env1_second_0:                 episode reward: 65.0500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 657.05,                last time consumption/overall running time: 111.4439s / 43018.2914 s
env0_first_0:                 episode reward: -60.5000,                 loss: 24.2311
env0_second_0:                 episode reward: 60.5000,                 loss: 24.1172
env1_first_0:                 episode reward: -72.8000,                 loss: nan
env1_second_0:                 episode reward: 72.8000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 625.0,                last time consumption/overall running time: 105.9453s / 43124.2367 s
env0_first_0:                 episode reward: -63.5000,                 loss: 21.8171
env0_second_0:                 episode reward: 63.5000,                 loss: 22.3206
env1_first_0:                 episode reward: -66.0500,                 loss: nan
env1_second_0:                 episode reward: 66.0500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 611.4,                last time consumption/overall running time: 105.0240s / 43229.2607 s
env0_first_0:                 episode reward: -59.4500,                 loss: 21.1163
env0_second_0:                 episode reward: 59.4500,                 loss: 21.7202
env1_first_0:                 episode reward: -60.8000,                 loss: nan
env1_second_0:                 episode reward: 60.8000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 620.45,                last time consumption/overall running time: 105.5293s / 43334.7900 s
env0_first_0:                 episode reward: -57.1000,                 loss: 19.0428
env0_second_0:                 episode reward: 57.1000,                 loss: 19.2047
env1_first_0:                 episode reward: -58.6500,                 loss: nan
env1_second_0:                 episode reward: 58.6500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 610.0,                last time consumption/overall running time: 103.9417s / 43438.7317 s
env0_first_0:                 episode reward: -65.4000,                 loss: 23.6006
env0_second_0:                 episode reward: 65.4000,                 loss: 23.6201
env1_first_0:                 episode reward: -65.2000,                 loss: nan
env1_second_0:                 episode reward: 65.2000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 570.6,                last time consumption/overall running time: 98.7670s / 43537.4987 s
env0_first_0:                 episode reward: -70.1000,                 loss: 26.4863
env0_second_0:                 episode reward: 70.1000,                 loss: 26.5135
env1_first_0:                 episode reward: -61.7500,                 loss: nan
env1_second_0:                 episode reward: 61.7500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 553.65,                last time consumption/overall running time: 95.8836s / 43633.3823 s
env0_first_0:                 episode reward: -61.5000,                 loss: 25.5288
env0_second_0:                 episode reward: 61.5000,                 loss: 26.2064
env1_first_0:                 episode reward: -68.4000,                 loss: nan
env1_second_0:                 episode reward: 68.4000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 545.65,                last time consumption/overall running time: 94.8263s / 43728.2086 s
env0_first_0:                 episode reward: -73.7500,                 loss: 26.4145
env0_second_0:                 episode reward: 73.7500,                 loss: 26.8526
env1_first_0:                 episode reward: -60.7500,                 loss: nan
env1_second_0:                 episode reward: 60.7500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 466.8,                last time consumption/overall running time: 82.8328s / 43811.0414 s
env0_first_0:                 episode reward: -68.6000,                 loss: 32.8330
env0_second_0:                 episode reward: 68.6000,                 loss: 32.6270
env1_first_0:                 episode reward: -65.9000,                 loss: nan
env1_second_0:                 episode reward: 65.9000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 500.5,                last time consumption/overall running time: 87.1163s / 43898.1577 s
env0_first_0:                 episode reward: -67.1500,                 loss: 33.0051
env0_second_0:                 episode reward: 67.1500,                 loss: 33.8041
env1_first_0:                 episode reward: -73.7000,                 loss: nan
env1_second_0:                 episode reward: 73.7000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 514.15,                last time consumption/overall running time: 88.6854s / 43986.8431 s
env0_first_0:                 episode reward: -67.0000,                 loss: 35.3117
env0_second_0:                 episode reward: 67.0000,                 loss: 35.3882
env1_first_0:                 episode reward: -68.6500,                 loss: nan
env1_second_0:                 episode reward: 68.6500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 477.2,                last time consumption/overall running time: 84.2198s / 44071.0629 s
env0_first_0:                 episode reward: -72.2500,                 loss: 31.4968
env0_second_0:                 episode reward: 72.2500,                 loss: 32.9889
env1_first_0:                 episode reward: -70.8500,                 loss: nan
env1_second_0:                 episode reward: 70.8500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 508.0,                last time consumption/overall running time: 86.6796s / 44157.7425 s
env0_first_0:                 episode reward: -76.4000,                 loss: 32.1150
env0_second_0:                 episode reward: 76.4000,                 loss: 32.5396
env1_first_0:                 episode reward: -74.0500,                 loss: nan
env1_second_0:                 episode reward: 74.0500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 500.55,                last time consumption/overall running time: 86.2364s / 44243.9789 s
env0_first_0:                 episode reward: -78.2500,                 loss: 34.1289
env0_second_0:                 episode reward: 78.2500,                 loss: 34.2060
env1_first_0:                 episode reward: -68.9500,                 loss: nan
env1_second_0:                 episode reward: 68.9500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 475.8,                last time consumption/overall running time: 83.7285s / 44327.7074 s
env0_first_0:                 episode reward: -80.0000,                 loss: 34.0699
env0_second_0:                 episode reward: 80.0000,                 loss: 35.4014
env1_first_0:                 episode reward: -69.0000,                 loss: nan
env1_second_0:                 episode reward: 69.0000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 591.5,                last time consumption/overall running time: 99.9290s / 44427.6365 s
env0_first_0:                 episode reward: -64.5500,                 loss: 29.1381
env0_second_0:                 episode reward: 64.5500,                 loss: 28.7555
env1_first_0:                 episode reward: -66.3500,                 loss: nan
env1_second_0:                 episode reward: 66.3500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 277.6890s / 44705.3255 s
env0_first_0:                 episode reward: -18.0500,                 loss: 2.6017
env0_second_0:                 episode reward: 18.0500,                 loss: 3.4332
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 839.2,                last time consumption/overall running time: 138.1018s / 44843.4272 s
env0_first_0:                 episode reward: -47.4500,                 loss: 18.6533
env0_second_0:                 episode reward: 47.4500,                 loss: 18.5114
env1_first_0:                 episode reward: -54.3500,                 loss: nan
env1_second_0:                 episode reward: 54.3500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 678.5,                last time consumption/overall running time: 114.7670s / 44958.1943 s
env0_first_0:                 episode reward: -51.8500,                 loss: 26.0436
env0_second_0:                 episode reward: 51.8500,                 loss: 26.0058
env1_first_0:                 episode reward: -54.3500,                 loss: nan
env1_second_0:                 episode reward: 54.3500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 735.1,                last time consumption/overall running time: 122.6603s / 45080.8545 s
env0_first_0:                 episode reward: -56.4500,                 loss: 25.0560
env0_second_0:                 episode reward: 56.4500,                 loss: 25.5964
env1_first_0:                 episode reward: -50.9500,                 loss: nan
env1_second_0:                 episode reward: 50.9500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 430.9,                last time consumption/overall running time: 77.5200s / 45158.3745 s
env0_first_0:                 episode reward: -66.3000,                 loss: 31.4205
env0_second_0:                 episode reward: 66.3000,                 loss: 32.3270
env1_first_0:                 episode reward: -76.5000,                 loss: nan
env1_second_0:                 episode reward: 76.5000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 420.9,                last time consumption/overall running time: 76.5684s / 45234.9429 s
env0_first_0:                 episode reward: -68.3000,                 loss: 29.5456
env0_second_0:                 episode reward: 68.3000,                 loss: 29.6569
env1_first_0:                 episode reward: -63.4000,                 loss: nan
env1_second_0:                 episode reward: 63.4000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 417.05,                last time consumption/overall running time: 75.0059s / 45309.9489 s
env0_first_0:                 episode reward: -76.0500,                 loss: 35.8769
env0_second_0:                 episode reward: 76.0500,                 loss: 35.8483
env1_first_0:                 episode reward: -76.1500,                 loss: nan
env1_second_0:                 episode reward: 76.1500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 386.3,                last time consumption/overall running time: 70.6190s / 45380.5678 s
env0_first_0:                 episode reward: -81.8500,                 loss: 40.6232
env0_second_0:                 episode reward: 81.8500,                 loss: 41.4786
env1_first_0:                 episode reward: -76.5000,                 loss: nan
env1_second_0:                 episode reward: 76.5000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 387.4,                last time consumption/overall running time: 71.1143s / 45451.6821 s
env0_first_0:                 episode reward: -74.1500,                 loss: 40.0236
env0_second_0:                 episode reward: 74.1500,                 loss: 40.8687
env1_first_0:                 episode reward: -82.4500,                 loss: nan
env1_second_0:                 episode reward: 82.4500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 394.35,                last time consumption/overall running time: 71.6878s / 45523.3700 s
env0_first_0:                 episode reward: -70.7000,                 loss: 42.6434
env0_second_0:                 episode reward: 70.7000,                 loss: 44.0394
env1_first_0:                 episode reward: -80.3500,                 loss: nan
env1_second_0:                 episode reward: 80.3500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 537.35,                last time consumption/overall running time: 93.0630s / 45616.4330 s
env0_first_0:                 episode reward: -57.9000,                 loss: 31.8325
env0_second_0:                 episode reward: 57.9000,                 loss: 33.0010
env1_first_0:                 episode reward: -71.2500,                 loss: nan
env1_second_0:                 episode reward: 71.2500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 475.75,                last time consumption/overall running time: 83.5536s / 45699.9866 s
env0_first_0:                 episode reward: -73.4000,                 loss: 34.8919
env0_second_0:                 episode reward: 73.4000,                 loss: 35.7331
env1_first_0:                 episode reward: -66.7000,                 loss: nan
env1_second_0:                 episode reward: 66.7000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 370.7,                last time consumption/overall running time: 68.2873s / 45768.2739 s
env0_first_0:                 episode reward: -66.8000,                 loss: 42.1315
env0_second_0:                 episode reward: 66.8000,                 loss: 42.4154
env1_first_0:                 episode reward: -77.1000,                 loss: nan
env1_second_0:                 episode reward: 77.1000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 319.3,                last time consumption/overall running time: 59.5460s / 45827.8199 s
env0_first_0:                 episode reward: -75.1500,                 loss: 47.4059
env0_second_0:                 episode reward: 75.1500,                 loss: 46.7112
env1_first_0:                 episode reward: -67.4500,                 loss: nan
env1_second_0:                 episode reward: 67.4500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 330.4,                last time consumption/overall running time: 62.1520s / 45889.9719 s
env0_first_0:                 episode reward: -84.4500,                 loss: 47.6289
env0_second_0:                 episode reward: 84.4500,                 loss: 48.3462
env1_first_0:                 episode reward: -66.0500,                 loss: nan
env1_second_0:                 episode reward: 66.0500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 388.65,                last time consumption/overall running time: 72.3544s / 45962.3263 s
env0_first_0:                 episode reward: -73.6500,                 loss: 40.2551
env0_second_0:                 episode reward: 73.6500,                 loss: 42.5260
env1_first_0:                 episode reward: -74.9500,                 loss: nan
env1_second_0:                 episode reward: 74.9500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 513.5,                last time consumption/overall running time: 89.4743s / 46051.8006 s
env0_first_0:                 episode reward: -67.4000,                 loss: 31.3792
env0_second_0:                 episode reward: 67.4000,                 loss: 33.1526
env1_first_0:                 episode reward: -69.2000,                 loss: nan
env1_second_0:                 episode reward: 69.2000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 394.15,                last time consumption/overall running time: 71.7159s / 46123.5165 s
env0_first_0:                 episode reward: -71.2000,                 loss: 39.1789
env0_second_0:                 episode reward: 71.2000,                 loss: 39.5842
env1_first_0:                 episode reward: -68.7000,                 loss: nan
env1_second_0:                 episode reward: 68.7000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 496.7,                last time consumption/overall running time: 88.3436s / 46211.8601 s
env0_first_0:                 episode reward: -68.4500,                 loss: 33.0611
env0_second_0:                 episode reward: 68.4500,                 loss: 34.0501
env1_first_0:                 episode reward: -77.3500,                 loss: nan
env1_second_0:                 episode reward: 77.3500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 553.7,                last time consumption/overall running time: 95.9891s / 46307.8492 s
env0_first_0:                 episode reward: -76.8500,                 loss: 34.4563
env0_second_0:                 episode reward: 76.8500,                 loss: 35.0608
env1_first_0:                 episode reward: -67.9500,                 loss: nan
env1_second_0:                 episode reward: 67.9500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 758.55,                last time consumption/overall running time: 126.2832s / 46434.1324 s
env0_first_0:                 episode reward: -54.4000,                 loss: 18.9279
env0_second_0:                 episode reward: 54.4000,                 loss: 19.9784
env1_first_0:                 episode reward: -53.2000,                 loss: nan
env1_second_0:                 episode reward: 53.2000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 642.9,                last time consumption/overall running time: 107.3820s / 46541.5144 s
env0_first_0:                 episode reward: -56.5000,                 loss: 20.0270
env0_second_0:                 episode reward: 56.5000,                 loss: 21.3763
env1_first_0:                 episode reward: -53.3500,                 loss: nan
env1_second_0:                 episode reward: 53.3500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 400.1,                last time consumption/overall running time: 71.7803s / 46613.2947 s
env0_first_0:                 episode reward: -76.3500,                 loss: 35.0426
env0_second_0:                 episode reward: 76.3500,                 loss: 35.7152
env1_first_0:                 episode reward: -74.5000,                 loss: nan
env1_second_0:                 episode reward: 74.5000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 339.15,                last time consumption/overall running time: 63.4953s / 46676.7900 s
env0_first_0:                 episode reward: -77.1000,                 loss: 39.2015
env0_second_0:                 episode reward: 77.1000,                 loss: 41.2563
env1_first_0:                 episode reward: -72.8500,                 loss: nan
env1_second_0:                 episode reward: 72.8500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 305.95,                last time consumption/overall running time: 57.4056s / 46734.1956 s
env0_first_0:                 episode reward: -76.1500,                 loss: 43.2384
env0_second_0:                 episode reward: 76.1500,                 loss: 43.7335
env1_first_0:                 episode reward: -81.2500,                 loss: nan
env1_second_0:                 episode reward: 81.2500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 266.7,                last time consumption/overall running time: 52.8043s / 46787.0000 s
env0_first_0:                 episode reward: -83.9000,                 loss: 49.7967
env0_second_0:                 episode reward: 83.9000,                 loss: 51.5242
env1_first_0:                 episode reward: -90.0500,                 loss: nan
env1_second_0:                 episode reward: 90.0500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 263.45,                last time consumption/overall running time: 51.4730s / 46838.4730 s
env0_first_0:                 episode reward: -73.8000,                 loss: 46.5331
env0_second_0:                 episode reward: 73.8000,                 loss: 48.2666
env1_first_0:                 episode reward: -85.8500,                 loss: nan
env1_second_0:                 episode reward: 85.8500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 330.55,                last time consumption/overall running time: 61.4993s / 46899.9723 s
env0_first_0:                 episode reward: -81.1000,                 loss: 44.1302
env0_second_0:                 episode reward: 81.1000,                 loss: 43.7302
env1_first_0:                 episode reward: -76.8500,                 loss: nan
env1_second_0:                 episode reward: 76.8500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 334.6,                last time consumption/overall running time: 62.2650s / 46962.2373 s
env0_first_0:                 episode reward: -71.9500,                 loss: 46.1942
env0_second_0:                 episode reward: 71.9500,                 loss: 46.0929
env1_first_0:                 episode reward: -85.0000,                 loss: nan
env1_second_0:                 episode reward: 85.0000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 285.65,                last time consumption/overall running time: 54.5668s / 47016.8042 s
env0_first_0:                 episode reward: -85.5000,                 loss: 42.4980
env0_second_0:                 episode reward: 85.5000,                 loss: 45.1616
env1_first_0:                 episode reward: -79.4000,                 loss: nan
env1_second_0:                 episode reward: 79.4000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 245.45,                last time consumption/overall running time: 49.3096s / 47066.1138 s
env0_first_0:                 episode reward: -93.3000,                 loss: 49.3762
env0_second_0:                 episode reward: 93.3000,                 loss: 50.0106
env1_first_0:                 episode reward: -79.1000,                 loss: nan
env1_second_0:                 episode reward: 79.1000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 241.7,                last time consumption/overall running time: 48.4939s / 47114.6076 s
env0_first_0:                 episode reward: -83.8500,                 loss: 44.1382
env0_second_0:                 episode reward: 83.8500,                 loss: 44.9624
env1_first_0:                 episode reward: -85.4500,                 loss: nan
env1_second_0:                 episode reward: 85.4500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 259.9,                last time consumption/overall running time: 51.6883s / 47166.2960 s
env0_first_0:                 episode reward: -87.4000,                 loss: 41.7883
env0_second_0:                 episode reward: 87.4000,                 loss: 43.9662
env1_first_0:                 episode reward: -83.4500,                 loss: nan
env1_second_0:                 episode reward: 83.4500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 260.55,                last time consumption/overall running time: 51.4653s / 47217.7613 s
env0_first_0:                 episode reward: -81.0500,                 loss: 39.1458
env0_second_0:                 episode reward: 81.0500,                 loss: 40.0147
env1_first_0:                 episode reward: -89.8000,                 loss: nan
env1_second_0:                 episode reward: 89.8000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 240.7,                last time consumption/overall running time: 49.3644s / 47267.1257 s
env0_first_0:                 episode reward: -79.5000,                 loss: 40.0343
env0_second_0:                 episode reward: 79.5000,                 loss: 41.8321
env1_first_0:                 episode reward: -91.5500,                 loss: nan
env1_second_0:                 episode reward: 91.5500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 243.55,                last time consumption/overall running time: 49.8790s / 47317.0047 s
env0_first_0:                 episode reward: -93.0500,                 loss: 43.3762
env0_second_0:                 episode reward: 93.0500,                 loss: 44.5167
env1_first_0:                 episode reward: -86.7000,                 loss: nan
env1_second_0:                 episode reward: 86.7000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 301.6,                last time consumption/overall running time: 57.8189s / 47374.8236 s
env0_first_0:                 episode reward: -73.6500,                 loss: 45.8731
env0_second_0:                 episode reward: 73.6500,                 loss: 43.9145
env1_first_0:                 episode reward: -74.7000,                 loss: nan
env1_second_0:                 episode reward: 74.7000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 353.15,                last time consumption/overall running time: 64.2018s / 47439.0254 s
env0_first_0:                 episode reward: -75.6000,                 loss: 44.5018
env0_second_0:                 episode reward: 75.6000,                 loss: 43.8168
env1_first_0:                 episode reward: -66.6000,                 loss: nan
env1_second_0:                 episode reward: 66.6000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 329.35,                last time consumption/overall running time: 61.4705s / 47500.4958 s
env0_first_0:                 episode reward: -60.5500,                 loss: 44.9471
env0_second_0:                 episode reward: 60.5500,                 loss: 45.4262
env1_first_0:                 episode reward: -77.9000,                 loss: nan
env1_second_0:                 episode reward: 77.9000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 313.8,                last time consumption/overall running time: 59.0901s / 47559.5859 s
env0_first_0:                 episode reward: -79.5500,                 loss: 46.4913
env0_second_0:                 episode reward: 79.5500,                 loss: 46.4171
env1_first_0:                 episode reward: -71.3500,                 loss: nan
env1_second_0:                 episode reward: 71.3500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 304.9,                last time consumption/overall running time: 57.8424s / 47617.4283 s
env0_first_0:                 episode reward: -79.4000,                 loss: 47.3985
env0_second_0:                 episode reward: 79.4000,                 loss: 46.4487
env1_first_0:                 episode reward: -72.8000,                 loss: nan
env1_second_0:                 episode reward: 72.8000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 340.7,                last time consumption/overall running time: 63.2323s / 47680.6606 s
env0_first_0:                 episode reward: -57.6000,                 loss: 47.7132
env0_second_0:                 episode reward: 57.6000,                 loss: 46.9930
env1_first_0:                 episode reward: -78.7000,                 loss: nan
env1_second_0:                 episode reward: 78.7000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 376.0,                last time consumption/overall running time: 69.0264s / 47749.6871 s
env0_first_0:                 episode reward: -67.7000,                 loss: 43.1958
env0_second_0:                 episode reward: 67.7000,                 loss: 43.3282
env1_first_0:                 episode reward: -76.7000,                 loss: nan
env1_second_0:                 episode reward: 76.7000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 357.15,                last time consumption/overall running time: 66.0673s / 47815.7543 s
env0_first_0:                 episode reward: -75.0500,                 loss: 41.5862
env0_second_0:                 episode reward: 75.0500,                 loss: 41.4303
env1_first_0:                 episode reward: -68.0500,                 loss: nan
env1_second_0:                 episode reward: 68.0500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 355.2,                last time consumption/overall running time: 65.4043s / 47881.1586 s
env0_first_0:                 episode reward: -73.2000,                 loss: 40.3094
env0_second_0:                 episode reward: 73.2000,                 loss: 40.7571
env1_first_0:                 episode reward: -73.7000,                 loss: nan
env1_second_0:                 episode reward: 73.7000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 435.55,                last time consumption/overall running time: 76.5484s / 47957.7070 s
env0_first_0:                 episode reward: -63.5000,                 loss: 38.8315
env0_second_0:                 episode reward: 63.5000,                 loss: 38.4440
env1_first_0:                 episode reward: -77.9500,                 loss: nan
env1_second_0:                 episode reward: 77.9500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 393.95,                last time consumption/overall running time: 70.8894s / 48028.5964 s
env0_first_0:                 episode reward: -79.5500,                 loss: 37.8346
env0_second_0:                 episode reward: 79.5500,                 loss: 39.2899
env1_first_0:                 episode reward: -74.5500,                 loss: nan
env1_second_0:                 episode reward: 74.5500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 385.9,                last time consumption/overall running time: 70.4329s / 48099.0294 s
env0_first_0:                 episode reward: -71.3500,                 loss: 36.7705
env0_second_0:                 episode reward: 71.3500,                 loss: 37.9531
env1_first_0:                 episode reward: -72.5000,                 loss: nan
env1_second_0:                 episode reward: 72.5000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 320.0,                last time consumption/overall running time: 59.9516s / 48158.9809 s
env0_first_0:                 episode reward: -75.5500,                 loss: 44.6291
env0_second_0:                 episode reward: 75.5500,                 loss: 45.9505
env1_first_0:                 episode reward: -79.7000,                 loss: nan
env1_second_0:                 episode reward: 79.7000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 347.9,                last time consumption/overall running time: 64.6592s / 48223.6401 s
env0_first_0:                 episode reward: -80.7000,                 loss: 43.0480
env0_second_0:                 episode reward: 80.7000,                 loss: 43.9116
env1_first_0:                 episode reward: -67.9500,                 loss: nan
env1_second_0:                 episode reward: 67.9500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 335.15,                last time consumption/overall running time: 61.7649s / 48285.4051 s
env0_first_0:                 episode reward: -78.4000,                 loss: 46.6348
env0_second_0:                 episode reward: 78.4000,                 loss: 47.2676
env1_first_0:                 episode reward: -64.1500,                 loss: nan
env1_second_0:                 episode reward: 64.1500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 421.6,                last time consumption/overall running time: 74.2151s / 48359.6202 s
env0_first_0:                 episode reward: -69.8500,                 loss: 43.5110
env0_second_0:                 episode reward: 69.8500,                 loss: 44.9449
env1_first_0:                 episode reward: -74.3500,                 loss: nan
env1_second_0:                 episode reward: 74.3500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 354.9,                last time consumption/overall running time: 64.8818s / 48424.5020 s
env0_first_0:                 episode reward: -71.5000,                 loss: 45.4219
env0_second_0:                 episode reward: 71.5000,                 loss: 46.6065
env1_first_0:                 episode reward: -67.3000,                 loss: nan
env1_second_0:                 episode reward: 67.3000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 336.75,                last time consumption/overall running time: 62.8073s / 48487.3093 s
env0_first_0:                 episode reward: -75.5500,                 loss: 44.5084
env0_second_0:                 episode reward: 75.5500,                 loss: 45.0232
env1_first_0:                 episode reward: -72.6000,                 loss: nan
env1_second_0:                 episode reward: 72.6000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 320.45,                last time consumption/overall running time: 59.0684s / 48546.3777 s
env0_first_0:                 episode reward: -73.9500,                 loss: 46.4335
env0_second_0:                 episode reward: 73.9500,                 loss: 46.0893
env1_first_0:                 episode reward: -85.3500,                 loss: nan
env1_second_0:                 episode reward: 85.3500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 318.55,                last time consumption/overall running time: 59.8073s / 48606.1850 s
env0_first_0:                 episode reward: -81.7500,                 loss: 49.5964
env0_second_0:                 episode reward: 81.7500,                 loss: 53.6879
env1_first_0:                 episode reward: -76.7000,                 loss: nan
env1_second_0:                 episode reward: 76.7000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 286.65,                last time consumption/overall running time: 55.9573s / 48662.1423 s
env0_first_0:                 episode reward: -77.4500,                 loss: 40.6111
env0_second_0:                 episode reward: 77.4500,                 loss: 44.1419
env1_first_0:                 episode reward: -82.5000,                 loss: nan
env1_second_0:                 episode reward: 82.5000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 354.85,                last time consumption/overall running time: 66.3777s / 48728.5200 s
env0_first_0:                 episode reward: -73.1000,                 loss: 47.1931
env0_second_0:                 episode reward: 73.1000,                 loss: 49.3085
env1_first_0:                 episode reward: -73.5500,                 loss: nan
env1_second_0:                 episode reward: 73.5500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 321.75,                last time consumption/overall running time: 61.2573s / 48789.7773 s
env0_first_0:                 episode reward: -81.5500,                 loss: 47.0291
env0_second_0:                 episode reward: 81.5500,                 loss: 47.3245
env1_first_0:                 episode reward: -73.5500,                 loss: nan
env1_second_0:                 episode reward: 73.5500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 314.15,                last time consumption/overall running time: 59.9568s / 48849.7340 s
env0_first_0:                 episode reward: -46.5000,                 loss: 49.6434
env0_second_0:                 episode reward: 46.5000,                 loss: 50.4260
env1_first_0:                 episode reward: -85.9500,                 loss: nan
env1_second_0:                 episode reward: 85.9500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 327.85,                last time consumption/overall running time: 61.3448s / 48911.0789 s
env0_first_0:                 episode reward: -74.4500,                 loss: 50.9280
env0_second_0:                 episode reward: 74.4500,                 loss: 53.1374
env1_first_0:                 episode reward: -63.9500,                 loss: nan
env1_second_0:                 episode reward: 63.9500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 309.05,                last time consumption/overall running time: 58.7897s / 48969.8686 s
env0_first_0:                 episode reward: -89.6500,                 loss: 49.1071
env0_second_0:                 episode reward: 89.6500,                 loss: 49.1608
env1_first_0:                 episode reward: -69.6000,                 loss: nan
env1_second_0:                 episode reward: 69.6000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 326.25,                last time consumption/overall running time: 60.3164s / 49030.1851 s
env0_first_0:                 episode reward: -69.3000,                 loss: 49.0627
env0_second_0:                 episode reward: 69.3000,                 loss: 49.1557
env1_first_0:                 episode reward: -80.6000,                 loss: nan
env1_second_0:                 episode reward: 80.6000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 355.0,                last time consumption/overall running time: 64.6209s / 49094.8060 s
env0_first_0:                 episode reward: -83.7000,                 loss: 49.1666
env0_second_0:                 episode reward: 83.7000,                 loss: 49.8601
env1_first_0:                 episode reward: -66.6000,                 loss: nan
env1_second_0:                 episode reward: 66.6000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 365.95,                last time consumption/overall running time: 66.9582s / 49161.7642 s
env0_first_0:                 episode reward: -62.8000,                 loss: 49.1238
env0_second_0:                 episode reward: 62.8000,                 loss: 48.9151
env1_first_0:                 episode reward: -79.7000,                 loss: nan
env1_second_0:                 episode reward: 79.7000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 327.5,                last time consumption/overall running time: 61.8135s / 49223.5778 s
env0_first_0:                 episode reward: -68.5500,                 loss: 48.3324
env0_second_0:                 episode reward: 68.5500,                 loss: 49.7634
env1_first_0:                 episode reward: -78.4000,                 loss: nan
env1_second_0:                 episode reward: 78.4000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 305.15,                last time consumption/overall running time: 58.4398s / 49282.0175 s
env0_first_0:                 episode reward: -67.1500,                 loss: 49.5234
env0_second_0:                 episode reward: 67.1500,                 loss: 49.0807
env1_first_0:                 episode reward: -79.7500,                 loss: nan
env1_second_0:                 episode reward: 79.7500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 363.55,                last time consumption/overall running time: 65.6788s / 49347.6963 s
env0_first_0:                 episode reward: -84.1500,                 loss: 46.0769
env0_second_0:                 episode reward: 84.1500,                 loss: 46.8990
env1_first_0:                 episode reward: -63.2000,                 loss: nan
env1_second_0:                 episode reward: 63.2000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 433.85,                last time consumption/overall running time: 76.3474s / 49424.0437 s
env0_first_0:                 episode reward: -75.5000,                 loss: 39.2821
env0_second_0:                 episode reward: 75.5000,                 loss: 41.5494
env1_first_0:                 episode reward: -67.6500,                 loss: nan
env1_second_0:                 episode reward: 67.6500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 403.45,                last time consumption/overall running time: 72.9912s / 49497.0349 s
env0_first_0:                 episode reward: -57.9500,                 loss: 43.2298
env0_second_0:                 episode reward: 57.9500,                 loss: 44.3295
env1_first_0:                 episode reward: -76.8500,                 loss: nan
env1_second_0:                 episode reward: 76.8500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 401.5,                last time consumption/overall running time: 72.3553s / 49569.3902 s
env0_first_0:                 episode reward: -76.0500,                 loss: 50.3407
env0_second_0:                 episode reward: 76.0500,                 loss: 51.4887
env1_first_0:                 episode reward: -59.7500,                 loss: nan
env1_second_0:                 episode reward: 59.7500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 402.85,                last time consumption/overall running time: 71.0872s / 49640.4774 s
env0_first_0:                 episode reward: -67.5500,                 loss: 48.0654
env0_second_0:                 episode reward: 67.5500,                 loss: 49.1541
env1_first_0:                 episode reward: -81.3000,                 loss: nan
env1_second_0:                 episode reward: 81.3000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 273.2,                last time consumption/overall running time: 54.5714s / 49695.0487 s
env0_first_0:                 episode reward: -77.9000,                 loss: 44.4001
env0_second_0:                 episode reward: 77.9000,                 loss: 47.9129
env1_first_0:                 episode reward: -74.9000,                 loss: nan
env1_second_0:                 episode reward: 74.9000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 242.9,                last time consumption/overall running time: 49.9356s / 49744.9843 s
env0_first_0:                 episode reward: -85.4500,                 loss: 40.0222
env0_second_0:                 episode reward: 85.4500,                 loss: 41.5583
env1_first_0:                 episode reward: -87.4000,                 loss: nan
env1_second_0:                 episode reward: 87.4000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 320.95,                last time consumption/overall running time: 61.0143s / 49805.9986 s
env0_first_0:                 episode reward: -74.5000,                 loss: 42.2203
env0_second_0:                 episode reward: 74.5000,                 loss: 42.1588
env1_first_0:                 episode reward: -85.4000,                 loss: nan
env1_second_0:                 episode reward: 85.4000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 307.8,                last time consumption/overall running time: 58.2339s / 49864.2326 s
env0_first_0:                 episode reward: -80.2000,                 loss: 47.8590
env0_second_0:                 episode reward: 80.2000,                 loss: 48.2147
env1_first_0:                 episode reward: -72.7000,                 loss: nan
env1_second_0:                 episode reward: 72.7000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 413.1,                last time consumption/overall running time: 73.9551s / 49938.1876 s
env0_first_0:                 episode reward: -65.8000,                 loss: 43.4143
env0_second_0:                 episode reward: 65.8000,                 loss: 43.6010
env1_first_0:                 episode reward: -73.1500,                 loss: nan
env1_second_0:                 episode reward: 73.1500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 624.7,                last time consumption/overall running time: 104.2685s / 50042.4561 s
env0_first_0:                 episode reward: -58.0000,                 loss: 28.8026
env0_second_0:                 episode reward: 58.0000,                 loss: 31.3898
env1_first_0:                 episode reward: -51.8000,                 loss: nan
env1_second_0:                 episode reward: 51.8000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 748.2,                last time consumption/overall running time: 125.0596s / 50167.5158 s
env0_first_0:                 episode reward: -52.0500,                 loss: 24.9095
env0_second_0:                 episode reward: 52.0500,                 loss: 25.9045
env1_first_0:                 episode reward: -39.3500,                 loss: nan
env1_second_0:                 episode reward: 39.3500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 628.5,                last time consumption/overall running time: 105.8552s / 50273.3709 s
env0_first_0:                 episode reward: -55.2000,                 loss: 24.9990
env0_second_0:                 episode reward: 55.2000,                 loss: 26.4776
env1_first_0:                 episode reward: -47.5500,                 loss: nan
env1_second_0:                 episode reward: 47.5500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 490.35,                last time consumption/overall running time: 85.9122s / 50359.2831 s
env0_first_0:                 episode reward: -69.3000,                 loss: 28.9535
env0_second_0:                 episode reward: 69.3000,                 loss: 29.0947
env1_first_0:                 episode reward: -51.3500,                 loss: nan
env1_second_0:                 episode reward: 51.3500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 428.2,                last time consumption/overall running time: 76.8391s / 50436.1222 s
env0_first_0:                 episode reward: -65.9500,                 loss: 28.7239
env0_second_0:                 episode reward: 65.9500,                 loss: 28.4081
env1_first_0:                 episode reward: -77.7000,                 loss: nan
env1_second_0:                 episode reward: 77.7000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 371.0,                last time consumption/overall running time: 67.2219s / 50503.3442 s
env0_first_0:                 episode reward: -79.6500,                 loss: 28.8181
env0_second_0:                 episode reward: 79.6500,                 loss: 29.6559
env1_first_0:                 episode reward: -81.3500,                 loss: nan
env1_second_0:                 episode reward: 81.3500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 332.05,                last time consumption/overall running time: 63.4636s / 50566.8078 s
env0_first_0:                 episode reward: -82.2000,                 loss: 29.0263
env0_second_0:                 episode reward: 82.2000,                 loss: 29.8332
env1_first_0:                 episode reward: -84.5000,                 loss: nan
env1_second_0:                 episode reward: 84.5000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 299.05,                last time consumption/overall running time: 56.9068s / 50623.7146 s
env0_first_0:                 episode reward: -84.0500,                 loss: 30.8368
env0_second_0:                 episode reward: 84.0500,                 loss: 31.6469
env1_first_0:                 episode reward: -76.3500,                 loss: nan
env1_second_0:                 episode reward: 76.3500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 298.7,                last time consumption/overall running time: 56.4628s / 50680.1773 s
env0_first_0:                 episode reward: -87.9000,                 loss: 31.6183
env0_second_0:                 episode reward: 87.9000,                 loss: 32.7576
env1_first_0:                 episode reward: -82.6000,                 loss: nan
env1_second_0:                 episode reward: 82.6000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 263.1,                last time consumption/overall running time: 52.4111s / 50732.5885 s
env0_first_0:                 episode reward: -88.8500,                 loss: 36.3053
env0_second_0:                 episode reward: 88.8500,                 loss: 38.3171
env1_first_0:                 episode reward: -90.9000,                 loss: nan
env1_second_0:                 episode reward: 90.9000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 256.0,                last time consumption/overall running time: 50.7117s / 50783.3002 s
env0_first_0:                 episode reward: -91.3000,                 loss: 33.5310
env0_second_0:                 episode reward: 91.3000,                 loss: 36.3391
env1_first_0:                 episode reward: -86.9000,                 loss: nan
env1_second_0:                 episode reward: 86.9000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 266.65,                last time consumption/overall running time: 52.7514s / 50836.0516 s
env0_first_0:                 episode reward: -85.9000,                 loss: 37.5788
env0_second_0:                 episode reward: 85.9000,                 loss: 37.9047
env1_first_0:                 episode reward: -86.9000,                 loss: nan
env1_second_0:                 episode reward: 86.9000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 244.0,                last time consumption/overall running time: 49.2880s / 50885.3396 s
env0_first_0:                 episode reward: -89.6500,                 loss: 34.7160
env0_second_0:                 episode reward: 89.6500,                 loss: 36.8047
env1_first_0:                 episode reward: -87.8000,                 loss: nan
env1_second_0:                 episode reward: 87.8000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 231.65,                last time consumption/overall running time: 47.4138s / 50932.7534 s
env0_first_0:                 episode reward: -79.7500,                 loss: 35.2318
env0_second_0:                 episode reward: 79.7500,                 loss: 36.4921
env1_first_0:                 episode reward: -91.4000,                 loss: nan
env1_second_0:                 episode reward: 91.4000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 239.35,                last time consumption/overall running time: 48.3378s / 50981.0912 s
env0_first_0:                 episode reward: -88.1000,                 loss: 32.5922
env0_second_0:                 episode reward: 88.1000,                 loss: 33.4092
env1_first_0:                 episode reward: -86.9500,                 loss: nan
env1_second_0:                 episode reward: 86.9500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 271.25,                last time consumption/overall running time: 53.6030s / 51034.6941 s
env0_first_0:                 episode reward: -81.3000,                 loss: 32.4353
env0_second_0:                 episode reward: 81.3000,                 loss: 33.3936
env1_first_0:                 episode reward: -91.6000,                 loss: nan
env1_second_0:                 episode reward: 91.6000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 259.7,                last time consumption/overall running time: 51.4203s / 51086.1145 s
env0_first_0:                 episode reward: -86.3500,                 loss: 33.8325
env0_second_0:                 episode reward: 86.3500,                 loss: 34.4254
env1_first_0:                 episode reward: -78.9000,                 loss: nan
env1_second_0:                 episode reward: 78.9000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 427.3,                last time consumption/overall running time: 75.3950s / 51161.5095 s
env0_first_0:                 episode reward: -64.8500,                 loss: 39.7932
env0_second_0:                 episode reward: 64.8500,                 loss: 38.9457
env1_first_0:                 episode reward: -74.4000,                 loss: nan
env1_second_0:                 episode reward: 74.4000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 292.3,                last time consumption/overall running time: 56.7294s / 51218.2390 s
env0_first_0:                 episode reward: -76.6000,                 loss: 40.4309
env0_second_0:                 episode reward: 76.6000,                 loss: 39.2135
env1_first_0:                 episode reward: -84.5500,                 loss: nan
env1_second_0:                 episode reward: 84.5500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 316.6,                last time consumption/overall running time: 60.4065s / 51278.6455 s
env0_first_0:                 episode reward: -82.2000,                 loss: 36.9102
env0_second_0:                 episode reward: 82.2000,                 loss: 37.6474
env1_first_0:                 episode reward: -65.6500,                 loss: nan
env1_second_0:                 episode reward: 65.6500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 1334.75,                last time consumption/overall running time: 214.3498s / 51492.9953 s
env0_first_0:                 episode reward: -18.2500,                 loss: 18.8185
env0_second_0:                 episode reward: 18.2500,                 loss: 19.1115
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 279.6450s / 51772.6403 s
env0_first_0:                 episode reward: -4.7000,                 loss: 2.8340
env0_second_0:                 episode reward: 4.7000,                 loss: 2.6800
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 281.7312s / 52054.3715 s
env0_first_0:                 episode reward: -8.6000,                 loss: 3.0360
env0_second_0:                 episode reward: 8.6000,                 loss: 3.0561
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1436.0,                last time consumption/overall running time: 227.3529s / 52281.7244 s
env0_first_0:                 episode reward: -33.6000,                 loss: 12.2020
env0_second_0:                 episode reward: 33.6000,                 loss: 11.3760
env1_first_0:                 episode reward: -32.8500,                 loss: nan
env1_second_0:                 episode reward: 32.8500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 549.8,                last time consumption/overall running time: 94.8303s / 52376.5547 s
env0_first_0:                 episode reward: -61.5500,                 loss: 26.5480
env0_second_0:                 episode reward: 61.5500,                 loss: 27.4583
env1_first_0:                 episode reward: -57.7500,                 loss: nan
env1_second_0:                 episode reward: 57.7500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 384.35,                last time consumption/overall running time: 70.7547s / 52447.3093 s
env0_first_0:                 episode reward: -67.3000,                 loss: 31.0670
env0_second_0:                 episode reward: 67.3000,                 loss: 35.0487
env1_first_0:                 episode reward: -71.0500,                 loss: nan
env1_second_0:                 episode reward: 71.0500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 284.45,                last time consumption/overall running time: 54.3645s / 52501.6738 s
env0_first_0:                 episode reward: -82.3000,                 loss: 32.3765
env0_second_0:                 episode reward: 82.3000,                 loss: 34.5092
env1_first_0:                 episode reward: -80.1500,                 loss: nan
env1_second_0:                 episode reward: 80.1500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 268.15,                last time consumption/overall running time: 52.3344s / 52554.0082 s
env0_first_0:                 episode reward: -83.4500,                 loss: 32.1874
env0_second_0:                 episode reward: 83.4500,                 loss: 33.4318
env1_first_0:                 episode reward: -82.9000,                 loss: nan
env1_second_0:                 episode reward: 82.9000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 235.45,                last time consumption/overall running time: 47.7497s / 52601.7579 s
env0_first_0:                 episode reward: -93.4000,                 loss: 28.3176
env0_second_0:                 episode reward: 93.4000,                 loss: 30.9386
env1_first_0:                 episode reward: -87.2000,                 loss: nan
env1_second_0:                 episode reward: 87.2000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 278.35,                last time consumption/overall running time: 55.1578s / 52656.9157 s
env0_first_0:                 episode reward: -82.0000,                 loss: 36.7053
env0_second_0:                 episode reward: 82.0000,                 loss: 35.2832
env1_first_0:                 episode reward: -89.5000,                 loss: nan
env1_second_0:                 episode reward: 89.5000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 330.15,                last time consumption/overall running time: 62.0215s / 52718.9372 s
env0_first_0:                 episode reward: -73.3000,                 loss: 42.9970
env0_second_0:                 episode reward: 73.3000,                 loss: 42.4610
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 355.35,                last time consumption/overall running time: 66.0054s / 52784.9427 s
env0_first_0:                 episode reward: -77.0500,                 loss: 43.4611
env0_second_0:                 episode reward: 77.0500,                 loss: 44.1901
env1_first_0:                 episode reward: -63.0000,                 loss: nan
env1_second_0:                 episode reward: 63.0000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 390.6,                last time consumption/overall running time: 71.2472s / 52856.1899 s
env0_first_0:                 episode reward: -78.1000,                 loss: 41.7600
env0_second_0:                 episode reward: 78.1000,                 loss: 41.9647
env1_first_0:                 episode reward: -64.8500,                 loss: nan
env1_second_0:                 episode reward: 64.8500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 340.15,                last time consumption/overall running time: 63.8502s / 52920.0401 s
env0_first_0:                 episode reward: -74.9000,                 loss: 47.9718
env0_second_0:                 episode reward: 74.9000,                 loss: 48.6351
env1_first_0:                 episode reward: -68.2000,                 loss: nan
env1_second_0:                 episode reward: 68.2000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 416.0,                last time consumption/overall running time: 74.9785s / 52995.0186 s
env0_first_0:                 episode reward: -69.4000,                 loss: 41.9293
env0_second_0:                 episode reward: 69.4000,                 loss: 42.8193
env1_first_0:                 episode reward: -69.1500,                 loss: nan
env1_second_0:                 episode reward: 69.1500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 410.6,                last time consumption/overall running time: 74.1557s / 53069.1743 s
env0_first_0:                 episode reward: -76.3500,                 loss: 44.5634
env0_second_0:                 episode reward: 76.3500,                 loss: 43.9818
env1_first_0:                 episode reward: -62.5500,                 loss: nan
env1_second_0:                 episode reward: 62.5500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 487.55,                last time consumption/overall running time: 84.8235s / 53153.9978 s
env0_first_0:                 episode reward: -58.1000,                 loss: 41.8968
env0_second_0:                 episode reward: 58.1000,                 loss: 42.2535
env1_first_0:                 episode reward: -74.0000,                 loss: nan
env1_second_0:                 episode reward: 74.0000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 515.15,                last time consumption/overall running time: 88.4342s / 53242.4320 s
env0_first_0:                 episode reward: -70.3500,                 loss: 43.3173
env0_second_0:                 episode reward: 70.3500,                 loss: 43.4044
env1_first_0:                 episode reward: -71.5500,                 loss: nan
env1_second_0:                 episode reward: 71.5500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 528.95,                last time consumption/overall running time: 90.1090s / 53332.5410 s
env0_first_0:                 episode reward: -69.9000,                 loss: 39.8821
env0_second_0:                 episode reward: 69.9000,                 loss: 41.4576
env1_first_0:                 episode reward: -59.4000,                 loss: nan
env1_second_0:                 episode reward: 59.4000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 429.7,                last time consumption/overall running time: 76.4111s / 53408.9521 s
env0_first_0:                 episode reward: -68.2500,                 loss: 46.1012
env0_second_0:                 episode reward: 68.2500,                 loss: 45.8187
env1_first_0:                 episode reward: -61.0500,                 loss: nan
env1_second_0:                 episode reward: 61.0500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 503.15,                last time consumption/overall running time: 87.8664s / 53496.8185 s
env0_first_0:                 episode reward: -67.2500,                 loss: 38.4031
env0_second_0:                 episode reward: 67.2500,                 loss: 38.3354
env1_first_0:                 episode reward: -65.8000,                 loss: nan
env1_second_0:                 episode reward: 65.8000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 521.15,                last time consumption/overall running time: 91.0423s / 53587.8607 s
env0_first_0:                 episode reward: -62.0000,                 loss: 28.0346
env0_second_0:                 episode reward: 62.0000,                 loss: 28.2082
env1_first_0:                 episode reward: -72.9000,                 loss: nan
env1_second_0:                 episode reward: 72.9000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 618.7,                last time consumption/overall running time: 106.2786s / 53694.1393 s
env0_first_0:                 episode reward: -61.6500,                 loss: 24.8746
env0_second_0:                 episode reward: 61.6500,                 loss: 24.2595
env1_first_0:                 episode reward: -65.6500,                 loss: nan
env1_second_0:                 episode reward: 65.6500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 585.25,                last time consumption/overall running time: 100.0459s / 53794.1852 s
env0_first_0:                 episode reward: -64.5500,                 loss: 24.6392
env0_second_0:                 episode reward: 64.5500,                 loss: 23.6661
env1_first_0:                 episode reward: -45.8000,                 loss: nan
env1_second_0:                 episode reward: 45.8000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 533.85,                last time consumption/overall running time: 92.4719s / 53886.6571 s
env0_first_0:                 episode reward: -60.5500,                 loss: 26.3459
env0_second_0:                 episode reward: 60.5500,                 loss: 25.7164
env1_first_0:                 episode reward: -64.2000,                 loss: nan
env1_second_0:                 episode reward: 64.2000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 536.9,                last time consumption/overall running time: 92.9221s / 53979.5792 s
env0_first_0:                 episode reward: -57.9000,                 loss: 26.2410
env0_second_0:                 episode reward: 57.9000,                 loss: 25.1655
env1_first_0:                 episode reward: -63.7500,                 loss: nan
env1_second_0:                 episode reward: 63.7500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 494.3,                last time consumption/overall running time: 84.2763s / 54063.8555 s
env0_first_0:                 episode reward: -60.7000,                 loss: 27.7470
env0_second_0:                 episode reward: 60.7000,                 loss: 27.4626
env1_first_0:                 episode reward: -65.7000,                 loss: nan
env1_second_0:                 episode reward: 65.7000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 530.0,                last time consumption/overall running time: 91.3400s / 54155.1955 s
env0_first_0:                 episode reward: -58.9500,                 loss: 26.4835
env0_second_0:                 episode reward: 58.9500,                 loss: 26.3564
env1_first_0:                 episode reward: -71.5000,                 loss: nan
env1_second_0:                 episode reward: 71.5000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 462.85,                last time consumption/overall running time: 80.4920s / 54235.6875 s
env0_first_0:                 episode reward: -56.2500,                 loss: 27.4650
env0_second_0:                 episode reward: 56.2500,                 loss: 28.1263
env1_first_0:                 episode reward: -74.2000,                 loss: nan
env1_second_0:                 episode reward: 74.2000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 393.55,                last time consumption/overall running time: 71.8891s / 54307.5767 s
env0_first_0:                 episode reward: -63.1000,                 loss: 34.7350
env0_second_0:                 episode reward: 63.1000,                 loss: 35.3881
env1_first_0:                 episode reward: -73.7500,                 loss: nan
env1_second_0:                 episode reward: 73.7500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 385.45,                last time consumption/overall running time: 71.3388s / 54378.9155 s
env0_first_0:                 episode reward: -70.9000,                 loss: 31.7017
env0_second_0:                 episode reward: 70.9000,                 loss: 30.4569
env1_first_0:                 episode reward: -58.4500,                 loss: nan
env1_second_0:                 episode reward: 58.4500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 413.9,                last time consumption/overall running time: 74.5603s / 54453.4758 s
env0_first_0:                 episode reward: -75.3500,                 loss: 31.3334
env0_second_0:                 episode reward: 75.3500,                 loss: 32.2206
env1_first_0:                 episode reward: -67.0500,                 loss: nan
env1_second_0:                 episode reward: 67.0500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 320.0,                last time consumption/overall running time: 62.0004s / 54515.4762 s
env0_first_0:                 episode reward: -82.1000,                 loss: 30.8532
env0_second_0:                 episode reward: 82.1000,                 loss: 32.2196
env1_first_0:                 episode reward: -74.9000,                 loss: nan
env1_second_0:                 episode reward: 74.9000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 272.65,                last time consumption/overall running time: 53.9754s / 54569.4516 s
env0_first_0:                 episode reward: -81.2500,                 loss: 35.1458
env0_second_0:                 episode reward: 81.2500,                 loss: 38.7882
env1_first_0:                 episode reward: -82.2000,                 loss: nan
env1_second_0:                 episode reward: 82.2000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 288.9,                last time consumption/overall running time: 56.3323s / 54625.7839 s
env0_first_0:                 episode reward: -91.5000,                 loss: 35.1104
env0_second_0:                 episode reward: 91.5000,                 loss: 38.5576
env1_first_0:                 episode reward: -77.8500,                 loss: nan
env1_second_0:                 episode reward: 77.8500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 311.8,                last time consumption/overall running time: 60.0095s / 54685.7934 s
env0_first_0:                 episode reward: -75.8500,                 loss: 43.0814
env0_second_0:                 episode reward: 75.8500,                 loss: 47.2773
env1_first_0:                 episode reward: -70.2500,                 loss: nan
env1_second_0:                 episode reward: 70.2500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 263.7,                last time consumption/overall running time: 52.7559s / 54738.5493 s
env0_first_0:                 episode reward: -77.1000,                 loss: 45.1570
env0_second_0:                 episode reward: 77.1000,                 loss: 47.1057
env1_first_0:                 episode reward: -65.7500,                 loss: nan
env1_second_0:                 episode reward: 65.7500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 338.2,                last time consumption/overall running time: 63.7241s / 54802.2734 s
env0_first_0:                 episode reward: -86.5500,                 loss: 43.5790
env0_second_0:                 episode reward: 86.5500,                 loss: 46.2260
env1_first_0:                 episode reward: -67.2000,                 loss: nan
env1_second_0:                 episode reward: 67.2000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 332.35,                last time consumption/overall running time: 60.9424s / 54863.2158 s
env0_first_0:                 episode reward: -82.7500,                 loss: 46.3010
env0_second_0:                 episode reward: 82.7500,                 loss: 47.9204
env1_first_0:                 episode reward: -61.2000,                 loss: nan
env1_second_0:                 episode reward: 61.2000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 352.0,                last time consumption/overall running time: 65.0188s / 54928.2347 s
env0_first_0:                 episode reward: -69.3000,                 loss: 45.6893
env0_second_0:                 episode reward: 69.3000,                 loss: 47.4985
env1_first_0:                 episode reward: -69.2500,                 loss: nan
env1_second_0:                 episode reward: 69.2500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 392.75,                last time consumption/overall running time: 70.6488s / 54998.8834 s
env0_first_0:                 episode reward: -72.9500,                 loss: 47.1699
env0_second_0:                 episode reward: 72.9500,                 loss: 49.7975
env1_first_0:                 episode reward: -76.3000,                 loss: nan
env1_second_0:                 episode reward: 76.3000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 530.85,                last time consumption/overall running time: 92.2702s / 55091.1537 s
env0_first_0:                 episode reward: -76.6500,                 loss: 38.0451
env0_second_0:                 episode reward: 76.6500,                 loss: 39.0008
env1_first_0:                 episode reward: -61.1500,                 loss: nan
env1_second_0:                 episode reward: 61.1500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 553.65,                last time consumption/overall running time: 96.0652s / 55187.2188 s
env0_first_0:                 episode reward: -74.6000,                 loss: 36.2426
env0_second_0:                 episode reward: 74.6000,                 loss: 37.2503
env1_first_0:                 episode reward: -59.4000,                 loss: nan
env1_second_0:                 episode reward: 59.4000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 463.8,                last time consumption/overall running time: 83.0820s / 55270.3008 s
env0_first_0:                 episode reward: -69.2500,                 loss: 42.3300
env0_second_0:                 episode reward: 69.2500,                 loss: 43.2664
env1_first_0:                 episode reward: -63.7000,                 loss: nan
env1_second_0:                 episode reward: 63.7000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 494.75,                last time consumption/overall running time: 86.0970s / 55356.3978 s
env0_first_0:                 episode reward: -72.0500,                 loss: 39.9023
env0_second_0:                 episode reward: 72.0500,                 loss: 40.3232
env1_first_0:                 episode reward: -69.8500,                 loss: nan
env1_second_0:                 episode reward: 69.8500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 547.2,                last time consumption/overall running time: 94.5827s / 55450.9805 s
env0_first_0:                 episode reward: -71.1000,                 loss: 36.6590
env0_second_0:                 episode reward: 71.1000,                 loss: 37.1099
env1_first_0:                 episode reward: -71.7000,                 loss: nan
env1_second_0:                 episode reward: 71.7000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 463.0,                last time consumption/overall running time: 81.8735s / 55532.8540 s
env0_first_0:                 episode reward: -63.4500,                 loss: 40.3806
env0_second_0:                 episode reward: 63.4500,                 loss: 40.8120
env1_first_0:                 episode reward: -63.3000,                 loss: nan
env1_second_0:                 episode reward: 63.3000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 427.95,                last time consumption/overall running time: 75.3640s / 55608.2181 s
env0_first_0:                 episode reward: -73.1000,                 loss: 44.9877
env0_second_0:                 episode reward: 73.1000,                 loss: 46.8872
env1_first_0:                 episode reward: -71.1000,                 loss: nan
env1_second_0:                 episode reward: 71.1000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 393.3,                last time consumption/overall running time: 71.6536s / 55679.8717 s
env0_first_0:                 episode reward: -76.7500,                 loss: 37.3955
env0_second_0:                 episode reward: 76.7500,                 loss: 40.3236
env1_first_0:                 episode reward: -79.1500,                 loss: nan
env1_second_0:                 episode reward: 79.1500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 375.9,                last time consumption/overall running time: 68.2081s / 55748.0798 s
env0_first_0:                 episode reward: -83.0500,                 loss: 31.2679
env0_second_0:                 episode reward: 83.0500,                 loss: 32.7862
env1_first_0:                 episode reward: -80.1500,                 loss: nan
env1_second_0:                 episode reward: 80.1500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 309.1,                last time consumption/overall running time: 59.8427s / 55807.9224 s
env0_first_0:                 episode reward: -69.8000,                 loss: 38.4055
env0_second_0:                 episode reward: 69.8000,                 loss: 40.9904
env1_first_0:                 episode reward: -85.8500,                 loss: nan
env1_second_0:                 episode reward: 85.8500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 338.0,                last time consumption/overall running time: 63.0725s / 55870.9949 s
env0_first_0:                 episode reward: -77.4500,                 loss: 44.8207
env0_second_0:                 episode reward: 77.4500,                 loss: 47.4491
env1_first_0:                 episode reward: -71.2500,                 loss: nan
env1_second_0:                 episode reward: 71.2500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 369.0,                last time consumption/overall running time: 68.1063s / 55939.1012 s
env0_first_0:                 episode reward: -74.5000,                 loss: 43.2526
env0_second_0:                 episode reward: 74.5000,                 loss: 43.5029
env1_first_0:                 episode reward: -68.5500,                 loss: nan
env1_second_0:                 episode reward: 68.5500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 395.3,                last time consumption/overall running time: 71.4713s / 56010.5725 s
env0_first_0:                 episode reward: -78.2000,                 loss: 42.5211
env0_second_0:                 episode reward: 78.2000,                 loss: 44.4302
env1_first_0:                 episode reward: -66.3000,                 loss: nan
env1_second_0:                 episode reward: 66.3000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 338.15,                last time consumption/overall running time: 63.8992s / 56074.4718 s
env0_first_0:                 episode reward: -61.1500,                 loss: 50.6020
env0_second_0:                 episode reward: 61.1500,                 loss: 51.2944
env1_first_0:                 episode reward: -67.9500,                 loss: nan
env1_second_0:                 episode reward: 67.9500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 313.65,                last time consumption/overall running time: 59.7483s / 56134.2201 s
env0_first_0:                 episode reward: -79.9500,                 loss: 37.9503
env0_second_0:                 episode reward: 79.9500,                 loss: 41.4084
env1_first_0:                 episode reward: -83.0000,                 loss: nan
env1_second_0:                 episode reward: 83.0000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 388.4,                last time consumption/overall running time: 70.2933s / 56204.5134 s
env0_first_0:                 episode reward: -70.7000,                 loss: 39.2430
env0_second_0:                 episode reward: 70.7000,                 loss: 40.0200
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 340.25,                last time consumption/overall running time: 63.7309s / 56268.2443 s
env0_first_0:                 episode reward: -68.0000,                 loss: 48.3147
env0_second_0:                 episode reward: 68.0000,                 loss: 49.4700
env1_first_0:                 episode reward: -80.1500,                 loss: nan
env1_second_0:                 episode reward: 80.1500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 323.1,                last time consumption/overall running time: 61.3250s / 56329.5693 s
env0_first_0:                 episode reward: -64.1000,                 loss: 45.1134
env0_second_0:                 episode reward: 64.1000,                 loss: 46.7392
env1_first_0:                 episode reward: -78.3000,                 loss: nan
env1_second_0:                 episode reward: 78.3000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 403.2,                last time consumption/overall running time: 70.6805s / 56400.2498 s
env0_first_0:                 episode reward: -66.2500,                 loss: 44.4629
env0_second_0:                 episode reward: 66.2500,                 loss: 45.9352
env1_first_0:                 episode reward: -82.8000,                 loss: nan
env1_second_0:                 episode reward: 82.8000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 456.6,                last time consumption/overall running time: 80.2594s / 56480.5092 s
env0_first_0:                 episode reward: -78.8500,                 loss: 44.1611
env0_second_0:                 episode reward: 78.8500,                 loss: 43.8667
env1_first_0:                 episode reward: -62.3000,                 loss: nan
env1_second_0:                 episode reward: 62.3000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 425.9,                last time consumption/overall running time: 75.4475s / 56555.9567 s
env0_first_0:                 episode reward: -80.1500,                 loss: 46.8737
env0_second_0:                 episode reward: 80.1500,                 loss: 47.2399
env1_first_0:                 episode reward: -64.0000,                 loss: nan
env1_second_0:                 episode reward: 64.0000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 374.2,                last time consumption/overall running time: 65.9292s / 56621.8859 s
env0_first_0:                 episode reward: -73.2000,                 loss: 49.5180
env0_second_0:                 episode reward: 73.2000,                 loss: 52.8510
env1_first_0:                 episode reward: -84.8000,                 loss: nan
env1_second_0:                 episode reward: 84.8000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 310.8,                last time consumption/overall running time: 57.8100s / 56679.6959 s
env0_first_0:                 episode reward: -76.0500,                 loss: 35.5358
env0_second_0:                 episode reward: 76.0500,                 loss: 39.2636
env1_first_0:                 episode reward: -89.2500,                 loss: nan
env1_second_0:                 episode reward: 89.2500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 285.35,                last time consumption/overall running time: 55.2487s / 56734.9446 s
env0_first_0:                 episode reward: -84.9000,                 loss: 28.4700
env0_second_0:                 episode reward: 84.9000,                 loss: 34.0159
env1_first_0:                 episode reward: -82.0500,                 loss: nan
env1_second_0:                 episode reward: 82.0500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 262.4,                last time consumption/overall running time: 50.5254s / 56785.4700 s
env0_first_0:                 episode reward: -80.1000,                 loss: 33.1229
env0_second_0:                 episode reward: 80.1000,                 loss: 38.2145
env1_first_0:                 episode reward: -85.2000,                 loss: nan
env1_second_0:                 episode reward: 85.2000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 270.6,                last time consumption/overall running time: 52.0669s / 56837.5369 s
env0_first_0:                 episode reward: -79.4500,                 loss: 46.1154
env0_second_0:                 episode reward: 79.4500,                 loss: 47.2945
env1_first_0:                 episode reward: -64.6000,                 loss: nan
env1_second_0:                 episode reward: 64.6000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 293.6,                last time consumption/overall running time: 55.1968s / 56892.7337 s
env0_first_0:                 episode reward: -68.0500,                 loss: 51.7187
env0_second_0:                 episode reward: 68.0500,                 loss: 54.4623
env1_first_0:                 episode reward: -73.7500,                 loss: nan
env1_second_0:                 episode reward: 73.7500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 275.85,                last time consumption/overall running time: 52.8384s / 56945.5721 s
env0_first_0:                 episode reward: -75.1000,                 loss: 47.7814
env0_second_0:                 episode reward: 75.1000,                 loss: 50.9907
env1_first_0:                 episode reward: -79.1500,                 loss: nan
env1_second_0:                 episode reward: 79.1500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 286.0,                last time consumption/overall running time: 55.1426s / 57000.7147 s
env0_first_0:                 episode reward: -78.4500,                 loss: 45.8000
env0_second_0:                 episode reward: 78.4500,                 loss: 46.5112
env1_first_0:                 episode reward: -73.5000,                 loss: nan
env1_second_0:                 episode reward: 73.5000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 307.6,                last time consumption/overall running time: 58.6204s / 57059.3351 s
env0_first_0:                 episode reward: -68.8500,                 loss: 52.7847
env0_second_0:                 episode reward: 68.8500,                 loss: 51.1767
env1_first_0:                 episode reward: -87.3500,                 loss: nan
env1_second_0:                 episode reward: 87.3500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 292.75,                last time consumption/overall running time: 55.8379s / 57115.1730 s
env0_first_0:                 episode reward: -69.1500,                 loss: 43.3718
env0_second_0:                 episode reward: 69.1500,                 loss: 43.3347
env1_first_0:                 episode reward: -78.6500,                 loss: nan
env1_second_0:                 episode reward: 78.6500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 342.25,                last time consumption/overall running time: 62.3511s / 57177.5241 s
env0_first_0:                 episode reward: -74.2000,                 loss: 46.0911
env0_second_0:                 episode reward: 74.2000,                 loss: 44.3250
env1_first_0:                 episode reward: -62.7000,                 loss: nan
env1_second_0:                 episode reward: 62.7000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 356.3,                last time consumption/overall running time: 63.3338s / 57240.8579 s
env0_first_0:                 episode reward: -62.8000,                 loss: 39.2714
env0_second_0:                 episode reward: 62.8000,                 loss: 38.1259
env1_first_0:                 episode reward: -73.1500,                 loss: nan
env1_second_0:                 episode reward: 73.1500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 317.05,                last time consumption/overall running time: 59.1545s / 57300.0124 s
env0_first_0:                 episode reward: -78.7000,                 loss: 37.0675
env0_second_0:                 episode reward: 78.7000,                 loss: 38.9654
env1_first_0:                 episode reward: -76.0000,                 loss: nan
env1_second_0:                 episode reward: 76.0000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 363.35,                last time consumption/overall running time: 65.7672s / 57365.7796 s
env0_first_0:                 episode reward: -71.7500,                 loss: 41.2026
env0_second_0:                 episode reward: 71.7500,                 loss: 41.3962
env1_first_0:                 episode reward: -67.9500,                 loss: nan
env1_second_0:                 episode reward: 67.9500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 345.8,                last time consumption/overall running time: 63.0299s / 57428.8095 s
env0_first_0:                 episode reward: -81.8500,                 loss: 40.1433
env0_second_0:                 episode reward: 81.8500,                 loss: 41.4071
env1_first_0:                 episode reward: -59.2000,                 loss: nan
env1_second_0:                 episode reward: 59.2000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 290.35,                last time consumption/overall running time: 55.5395s / 57484.3489 s
env0_first_0:                 episode reward: -76.6500,                 loss: 38.7437
env0_second_0:                 episode reward: 76.6500,                 loss: 40.8290
env1_first_0:                 episode reward: -80.8500,                 loss: nan
env1_second_0:                 episode reward: 80.8500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 315.95,                last time consumption/overall running time: 59.6682s / 57544.0171 s
env0_first_0:                 episode reward: -67.2000,                 loss: 41.3222
env0_second_0:                 episode reward: 67.2000,                 loss: 44.9766
env1_first_0:                 episode reward: -78.1000,                 loss: nan
env1_second_0:                 episode reward: 78.1000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 315.65,                last time consumption/overall running time: 59.9709s / 57603.9880 s
env0_first_0:                 episode reward: -67.2500,                 loss: 42.6405
env0_second_0:                 episode reward: 67.2500,                 loss: 44.2986
env1_first_0:                 episode reward: -82.5500,                 loss: nan
env1_second_0:                 episode reward: 82.5500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 362.15,                last time consumption/overall running time: 65.9991s / 57669.9871 s
env0_first_0:                 episode reward: -66.5000,                 loss: 45.5117
env0_second_0:                 episode reward: 66.5000,                 loss: 47.8116
env1_first_0:                 episode reward: -69.5500,                 loss: nan
env1_second_0:                 episode reward: 69.5500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 404.7,                last time consumption/overall running time: 73.4263s / 57743.4134 s
env0_first_0:                 episode reward: -72.8000,                 loss: 42.6666
env0_second_0:                 episode reward: 72.8000,                 loss: 44.7550
env1_first_0:                 episode reward: -73.0000,                 loss: nan
env1_second_0:                 episode reward: 73.0000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 337.65,                last time consumption/overall running time: 62.0710s / 57805.4844 s
env0_first_0:                 episode reward: -68.0500,                 loss: 42.4882
env0_second_0:                 episode reward: 68.0500,                 loss: 44.4539
env1_first_0:                 episode reward: -77.9000,                 loss: nan
env1_second_0:                 episode reward: 77.9000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 373.8,                last time consumption/overall running time: 67.1999s / 57872.6843 s
env0_first_0:                 episode reward: -76.7500,                 loss: 43.4658
env0_second_0:                 episode reward: 76.7500,                 loss: 43.2907
env1_first_0:                 episode reward: -78.3500,                 loss: nan
env1_second_0:                 episode reward: 78.3500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 452.6,                last time consumption/overall running time: 78.4097s / 57951.0941 s
env0_first_0:                 episode reward: -63.6500,                 loss: 41.6435
env0_second_0:                 episode reward: 63.6500,                 loss: 41.9502
env1_first_0:                 episode reward: -72.2000,                 loss: nan
env1_second_0:                 episode reward: 72.2000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 359.6,                last time consumption/overall running time: 64.9656s / 58016.0596 s
env0_first_0:                 episode reward: -64.9500,                 loss: 46.7363
env0_second_0:                 episode reward: 64.9500,                 loss: 47.4683
env1_first_0:                 episode reward: -78.9500,                 loss: nan
env1_second_0:                 episode reward: 78.9500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 415.5,                last time consumption/overall running time: 73.2871s / 58089.3468 s
env0_first_0:                 episode reward: -77.3000,                 loss: 43.1021
env0_second_0:                 episode reward: 77.3000,                 loss: 43.6726
env1_first_0:                 episode reward: -57.8000,                 loss: nan
env1_second_0:                 episode reward: 57.8000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 403.4,                last time consumption/overall running time: 71.2713s / 58160.6181 s
env0_first_0:                 episode reward: -73.8500,                 loss: 44.9780
env0_second_0:                 episode reward: 73.8500,                 loss: 44.8461
env1_first_0:                 episode reward: -57.3000,                 loss: nan
env1_second_0:                 episode reward: 57.3000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 460.5,                last time consumption/overall running time: 78.3350s / 58238.9531 s
env0_first_0:                 episode reward: -75.9500,                 loss: 39.1879
env0_second_0:                 episode reward: 75.9500,                 loss: 42.1781
env1_first_0:                 episode reward: -60.4500,                 loss: nan
env1_second_0:                 episode reward: 60.4500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 347.45,                last time consumption/overall running time: 63.9516s / 58302.9046 s
env0_first_0:                 episode reward: -79.6000,                 loss: 45.5271
env0_second_0:                 episode reward: 79.6000,                 loss: 47.1941
env1_first_0:                 episode reward: -64.0500,                 loss: nan
env1_second_0:                 episode reward: 64.0500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 401.65,                last time consumption/overall running time: 71.0742s / 58373.9788 s
env0_first_0:                 episode reward: -58.5000,                 loss: 42.7269
env0_second_0:                 episode reward: 58.5000,                 loss: 43.9845
env1_first_0:                 episode reward: -70.2500,                 loss: nan
env1_second_0:                 episode reward: 70.2500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 413.2,                last time consumption/overall running time: 71.3630s / 58445.3419 s
env0_first_0:                 episode reward: -71.6500,                 loss: 45.1817
env0_second_0:                 episode reward: 71.6500,                 loss: 44.8835
env1_first_0:                 episode reward: -68.2500,                 loss: nan
env1_second_0:                 episode reward: 68.2500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 410.8,                last time consumption/overall running time: 73.4537s / 58518.7956 s
env0_first_0:                 episode reward: -69.1500,                 loss: 43.7627
env0_second_0:                 episode reward: 69.1500,                 loss: 46.1114
env1_first_0:                 episode reward: -61.4000,                 loss: nan
env1_second_0:                 episode reward: 61.4000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 487.5,                last time consumption/overall running time: 85.0351s / 58603.8306 s
env0_first_0:                 episode reward: -66.3000,                 loss: 45.2662
env0_second_0:                 episode reward: 66.3000,                 loss: 46.1749
env1_first_0:                 episode reward: -64.4000,                 loss: nan
env1_second_0:                 episode reward: 64.4000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 393.75,                last time consumption/overall running time: 69.7567s / 58673.5873 s
env0_first_0:                 episode reward: -75.6500,                 loss: 46.4923
env0_second_0:                 episode reward: 75.6500,                 loss: 48.2949
env1_first_0:                 episode reward: -58.0000,                 loss: nan
env1_second_0:                 episode reward: 58.0000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 489.65,                last time consumption/overall running time: 84.2776s / 58757.8649 s
env0_first_0:                 episode reward: -66.7500,                 loss: 41.3865
env0_second_0:                 episode reward: 66.7500,                 loss: 42.3858
env1_first_0:                 episode reward: -79.6000,                 loss: nan
env1_second_0:                 episode reward: 79.6000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 416.55,                last time consumption/overall running time: 73.8325s / 58831.6973 s
env0_first_0:                 episode reward: -59.7500,                 loss: 45.4849
env0_second_0:                 episode reward: 59.7500,                 loss: 47.5455
env1_first_0:                 episode reward: -74.3500,                 loss: nan
env1_second_0:                 episode reward: 74.3500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 381.85,                last time consumption/overall running time: 68.4305s / 58900.1278 s
env0_first_0:                 episode reward: -70.4500,                 loss: 47.5084
env0_second_0:                 episode reward: 70.4500,                 loss: 48.9162
env1_first_0:                 episode reward: -76.8500,                 loss: nan
env1_second_0:                 episode reward: 76.8500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 367.85,                last time consumption/overall running time: 65.4208s / 58965.5486 s
env0_first_0:                 episode reward: -74.1000,                 loss: 45.4901
env0_second_0:                 episode reward: 74.1000,                 loss: 45.7015
env1_first_0:                 episode reward: -73.0500,                 loss: nan
env1_second_0:                 episode reward: 73.0500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 394.95,                last time consumption/overall running time: 69.3255s / 59034.8741 s
env0_first_0:                 episode reward: -68.6000,                 loss: 42.6341
env0_second_0:                 episode reward: 68.6000,                 loss: 44.9412
env1_first_0:                 episode reward: -76.6000,                 loss: nan
env1_second_0:                 episode reward: 76.6000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 408.65,                last time consumption/overall running time: 73.2703s / 59108.1444 s
env0_first_0:                 episode reward: -87.3500,                 loss: 46.3150
env0_second_0:                 episode reward: 87.3500,                 loss: 46.5654
env1_first_0:                 episode reward: -58.8500,                 loss: nan
env1_second_0:                 episode reward: 58.8500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 332.7,                last time consumption/overall running time: 60.8527s / 59168.9970 s
env0_first_0:                 episode reward: -66.7500,                 loss: 50.2989
env0_second_0:                 episode reward: 66.7500,                 loss: 53.0850
env1_first_0:                 episode reward: -80.7500,                 loss: nan
env1_second_0:                 episode reward: 80.7500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 388.05,                last time consumption/overall running time: 70.8859s / 59239.8830 s
env0_first_0:                 episode reward: -66.6000,                 loss: 49.2267
env0_second_0:                 episode reward: 66.6000,                 loss: 51.5087
env1_first_0:                 episode reward: -68.7500,                 loss: nan
env1_second_0:                 episode reward: 68.7500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 379.6,                last time consumption/overall running time: 68.3759s / 59308.2589 s
env0_first_0:                 episode reward: -71.9500,                 loss: 47.6198
env0_second_0:                 episode reward: 71.9500,                 loss: 51.3671
env1_first_0:                 episode reward: -65.7500,                 loss: nan
env1_second_0:                 episode reward: 65.7500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 360.85,                last time consumption/overall running time: 66.3156s / 59374.5745 s
env0_first_0:                 episode reward: -71.1000,                 loss: 49.3260
env0_second_0:                 episode reward: 71.1000,                 loss: 47.6765
env1_first_0:                 episode reward: -62.7500,                 loss: nan
env1_second_0:                 episode reward: 62.7500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 415.7,                last time consumption/overall running time: 73.9166s / 59448.4911 s
env0_first_0:                 episode reward: -64.1000,                 loss: 45.4941
env0_second_0:                 episode reward: 64.1000,                 loss: 46.0247
env1_first_0:                 episode reward: -67.2500,                 loss: nan
env1_second_0:                 episode reward: 67.2500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 336.65,                last time consumption/overall running time: 60.3877s / 59508.8789 s
env0_first_0:                 episode reward: -79.9000,                 loss: 46.5834
env0_second_0:                 episode reward: 79.9000,                 loss: 48.0211
env1_first_0:                 episode reward: -65.9500,                 loss: nan
env1_second_0:                 episode reward: 65.9500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 371.1,                last time consumption/overall running time: 66.0576s / 59574.9365 s
env0_first_0:                 episode reward: -73.7000,                 loss: 48.5287
env0_second_0:                 episode reward: 73.7000,                 loss: 50.5915
env1_first_0:                 episode reward: -71.1500,                 loss: nan
env1_second_0:                 episode reward: 71.1500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 336.9,                last time consumption/overall running time: 61.3146s / 59636.2511 s
env0_first_0:                 episode reward: -82.0000,                 loss: 46.2071
env0_second_0:                 episode reward: 82.0000,                 loss: 48.3626
env1_first_0:                 episode reward: -67.3000,                 loss: nan
env1_second_0:                 episode reward: 67.3000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 377.65,                last time consumption/overall running time: 67.5468s / 59703.7979 s
env0_first_0:                 episode reward: -79.8000,                 loss: 56.3944
env0_second_0:                 episode reward: 79.8000,                 loss: 59.2340
env1_first_0:                 episode reward: -55.2000,                 loss: nan
env1_second_0:                 episode reward: 55.2000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 331.0,                last time consumption/overall running time: 61.2840s / 59765.0820 s
env0_first_0:                 episode reward: -64.3500,                 loss: 55.2806
env0_second_0:                 episode reward: 64.3500,                 loss: 56.6325
env1_first_0:                 episode reward: -70.5500,                 loss: nan
env1_second_0:                 episode reward: 70.5500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 289.45,                last time consumption/overall running time: 55.7023s / 59820.7843 s
env0_first_0:                 episode reward: -82.9000,                 loss: 49.1915
env0_second_0:                 episode reward: 82.9000,                 loss: 52.9615
env1_first_0:                 episode reward: -72.3000,                 loss: nan
env1_second_0:                 episode reward: 72.3000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 310.5,                last time consumption/overall running time: 58.0574s / 59878.8417 s
env0_first_0:                 episode reward: -70.2500,                 loss: 46.3255
env0_second_0:                 episode reward: 70.2500,                 loss: 48.5047
env1_first_0:                 episode reward: -72.2000,                 loss: nan
env1_second_0:                 episode reward: 72.2000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 335.7,                last time consumption/overall running time: 62.3030s / 59941.1447 s
env0_first_0:                 episode reward: -75.8000,                 loss: 47.3748
env0_second_0:                 episode reward: 75.8000,                 loss: 49.7189
env1_first_0:                 episode reward: -80.8500,                 loss: nan
env1_second_0:                 episode reward: 80.8500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 514.6,                last time consumption/overall running time: 88.6852s / 60029.8299 s
env0_first_0:                 episode reward: -73.8000,                 loss: 21.2049
env0_second_0:                 episode reward: 73.8000,                 loss: 22.3801
env1_first_0:                 episode reward: -74.8500,                 loss: nan
env1_second_0:                 episode reward: 74.8500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 592.5,                last time consumption/overall running time: 97.2740s / 60127.1039 s
env0_first_0:                 episode reward: -64.3000,                 loss: 20.0785
env0_second_0:                 episode reward: 64.3000,                 loss: 19.9337
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 518.35,                last time consumption/overall running time: 87.9281s / 60215.0321 s
env0_first_0:                 episode reward: -62.4000,                 loss: 23.9341
env0_second_0:                 episode reward: 62.4000,                 loss: 24.9813
env1_first_0:                 episode reward: -73.4000,                 loss: nan
env1_second_0:                 episode reward: 73.4000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 416.35,                last time consumption/overall running time: 71.6911s / 60286.7232 s
env0_first_0:                 episode reward: -70.5000,                 loss: 26.9709
env0_second_0:                 episode reward: 70.5000,                 loss: 28.4486
env1_first_0:                 episode reward: -65.1500,                 loss: nan
env1_second_0:                 episode reward: 65.1500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 301.2,                last time consumption/overall running time: 55.5294s / 60342.2525 s
env0_first_0:                 episode reward: -78.5000,                 loss: 34.5093
env0_second_0:                 episode reward: 78.5000,                 loss: 37.4319
env1_first_0:                 episode reward: -79.3000,                 loss: nan
env1_second_0:                 episode reward: 79.3000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 311.6,                last time consumption/overall running time: 57.5038s / 60399.7563 s
env0_first_0:                 episode reward: -83.7000,                 loss: 29.9541
env0_second_0:                 episode reward: 83.7000,                 loss: 34.7649
env1_first_0:                 episode reward: -74.8500,                 loss: nan
env1_second_0:                 episode reward: 74.8500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 254.25,                last time consumption/overall running time: 47.6248s / 60447.3811 s
env0_first_0:                 episode reward: -63.9000,                 loss: 32.8939
env0_second_0:                 episode reward: 63.9000,                 loss: 40.3831
env1_first_0:                 episode reward: -90.1500,                 loss: nan
env1_second_0:                 episode reward: 90.1500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 244.2,                last time consumption/overall running time: 46.3667s / 60493.7478 s
env0_first_0:                 episode reward: -87.1500,                 loss: 31.3874
env0_second_0:                 episode reward: 87.1500,                 loss: 36.2174
env1_first_0:                 episode reward: -84.1000,                 loss: nan
env1_second_0:                 episode reward: 84.1000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 348.35,                last time consumption/overall running time: 61.4650s / 60555.2128 s
env0_first_0:                 episode reward: -75.5000,                 loss: 41.1105
env0_second_0:                 episode reward: 75.5000,                 loss: 44.2515
env1_first_0:                 episode reward: -73.9500,                 loss: nan
env1_second_0:                 episode reward: 73.9500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 357.45,                last time consumption/overall running time: 62.9498s / 60618.1626 s
env0_first_0:                 episode reward: -72.5500,                 loss: 44.1154
env0_second_0:                 episode reward: 72.5500,                 loss: 47.5338
env1_first_0:                 episode reward: -78.6500,                 loss: nan
env1_second_0:                 episode reward: 78.6500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 413.65,                last time consumption/overall running time: 72.2947s / 60690.4573 s
env0_first_0:                 episode reward: -62.5500,                 loss: 42.2234
env0_second_0:                 episode reward: 62.5500,                 loss: 41.4543
env1_first_0:                 episode reward: -83.0500,                 loss: nan
env1_second_0:                 episode reward: 83.0500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 352.4,                last time consumption/overall running time: 62.4138s / 60752.8711 s
env0_first_0:                 episode reward: -69.1500,                 loss: 41.4225
env0_second_0:                 episode reward: 69.1500,                 loss: 43.3876
env1_first_0:                 episode reward: -76.2000,                 loss: nan
env1_second_0:                 episode reward: 76.2000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 355.85,                last time consumption/overall running time: 63.3495s / 60816.2206 s
env0_first_0:                 episode reward: -66.6000,                 loss: 43.3757
env0_second_0:                 episode reward: 66.6000,                 loss: 44.0251
env1_first_0:                 episode reward: -84.2000,                 loss: nan
env1_second_0:                 episode reward: 84.2000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 287.2,                last time consumption/overall running time: 53.9585s / 60870.1791 s
env0_first_0:                 episode reward: -77.4000,                 loss: 41.2118
env0_second_0:                 episode reward: 77.4000,                 loss: 43.8091
env1_first_0:                 episode reward: -83.8500,                 loss: nan
env1_second_0:                 episode reward: 83.8500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 322.2,                last time consumption/overall running time: 57.8595s / 60928.0386 s
env0_first_0:                 episode reward: -68.0500,                 loss: 32.7613
env0_second_0:                 episode reward: 68.0500,                 loss: 34.9706
env1_first_0:                 episode reward: -77.2500,                 loss: nan
env1_second_0:                 episode reward: 77.2500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 301.45,                last time consumption/overall running time: 55.0361s / 60983.0747 s
env0_first_0:                 episode reward: -76.7500,                 loss: 29.0102
env0_second_0:                 episode reward: 76.7500,                 loss: 29.6292
env1_first_0:                 episode reward: -82.9000,                 loss: nan
env1_second_0:                 episode reward: 82.9000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 294.55,                last time consumption/overall running time: 54.7576s / 61037.8323 s
env0_first_0:                 episode reward: -80.9500,                 loss: 30.3062
env0_second_0:                 episode reward: 80.9500,                 loss: 31.7277
env1_first_0:                 episode reward: -82.2000,                 loss: nan
env1_second_0:                 episode reward: 82.2000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 413.65,                last time consumption/overall running time: 70.2802s / 61108.1125 s
env0_first_0:                 episode reward: -65.1000,                 loss: 27.6223
env0_second_0:                 episode reward: 65.1000,                 loss: 28.9246
env1_first_0:                 episode reward: -72.9500,                 loss: nan
env1_second_0:                 episode reward: 72.9500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 316.95,                last time consumption/overall running time: 55.9201s / 61164.0327 s
env0_first_0:                 episode reward: -77.0000,                 loss: 26.9494
env0_second_0:                 episode reward: 77.0000,                 loss: 29.2954
env1_first_0:                 episode reward: -73.1000,                 loss: nan
env1_second_0:                 episode reward: 73.1000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 300.95,                last time consumption/overall running time: 54.7400s / 61218.7727 s
env0_first_0:                 episode reward: -88.5500,                 loss: 31.0811
env0_second_0:                 episode reward: 88.5500,                 loss: 33.9833
env1_first_0:                 episode reward: -63.5000,                 loss: nan
env1_second_0:                 episode reward: 63.5000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 347.2,                last time consumption/overall running time: 61.8746s / 61280.6473 s
env0_first_0:                 episode reward: -74.4500,                 loss: 32.4238
env0_second_0:                 episode reward: 74.4500,                 loss: 34.8444
env1_first_0:                 episode reward: -68.1000,                 loss: nan
env1_second_0:                 episode reward: 68.1000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 290.15,                last time consumption/overall running time: 52.8162s / 61333.4634 s
env0_first_0:                 episode reward: -72.4500,                 loss: 39.6588
env0_second_0:                 episode reward: 72.4500,                 loss: 39.2246
env1_first_0:                 episode reward: -75.4500,                 loss: nan
env1_second_0:                 episode reward: 75.4500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 289.15,                last time consumption/overall running time: 52.9854s / 61386.4488 s
env0_first_0:                 episode reward: -71.7500,                 loss: 33.3503
env0_second_0:                 episode reward: 71.7500,                 loss: 33.6807
env1_first_0:                 episode reward: -73.6500,                 loss: nan
env1_second_0:                 episode reward: 73.6500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 353.9,                last time consumption/overall running time: 62.6986s / 61449.1475 s
env0_first_0:                 episode reward: -77.0500,                 loss: 30.6724
env0_second_0:                 episode reward: 77.0500,                 loss: 33.0745
env1_first_0:                 episode reward: -59.2000,                 loss: nan
env1_second_0:                 episode reward: 59.2000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 550.8,                last time consumption/overall running time: 90.9282s / 61540.0756 s
env0_first_0:                 episode reward: -64.9000,                 loss: 21.6635
env0_second_0:                 episode reward: 64.9000,                 loss: 24.5446
env1_first_0:                 episode reward: -69.3000,                 loss: nan
env1_second_0:                 episode reward: 69.3000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 317.75,                last time consumption/overall running time: 57.3850s / 61597.4606 s
env0_first_0:                 episode reward: -63.3500,                 loss: 25.2457
env0_second_0:                 episode reward: 63.3500,                 loss: 26.6768
env1_first_0:                 episode reward: -67.9500,                 loss: nan
env1_second_0:                 episode reward: 67.9500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 340.6,                last time consumption/overall running time: 61.2919s / 61658.7525 s
env0_first_0:                 episode reward: -76.4000,                 loss: 26.8737
env0_second_0:                 episode reward: 76.4000,                 loss: 27.3910
env1_first_0:                 episode reward: -76.7500,                 loss: nan
env1_second_0:                 episode reward: 76.7500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 238.4,                last time consumption/overall running time: 45.0357s / 61703.7882 s
env0_first_0:                 episode reward: -80.8000,                 loss: 24.5209
env0_second_0:                 episode reward: 80.8000,                 loss: 26.3671
env1_first_0:                 episode reward: -67.6500,                 loss: nan
env1_second_0:                 episode reward: 67.6500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 244.75,                last time consumption/overall running time: 46.7609s / 61750.5490 s
env0_first_0:                 episode reward: -84.2500,                 loss: 26.0403
env0_second_0:                 episode reward: 84.2500,                 loss: 25.2332
env1_first_0:                 episode reward: -74.5000,                 loss: nan
env1_second_0:                 episode reward: 74.5000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 233.75,                last time consumption/overall running time: 45.5185s / 61796.0675 s
env0_first_0:                 episode reward: -91.6000,                 loss: 23.1028
env0_second_0:                 episode reward: 91.6000,                 loss: 24.3749
env1_first_0:                 episode reward: -80.3000,                 loss: nan
env1_second_0:                 episode reward: 80.3000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 235.8,                last time consumption/overall running time: 45.7510s / 61841.8185 s
env0_first_0:                 episode reward: -82.5000,                 loss: 23.9782
env0_second_0:                 episode reward: 82.5000,                 loss: 25.1997
env1_first_0:                 episode reward: -83.8000,                 loss: nan
env1_second_0:                 episode reward: 83.8000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 306.7,                last time consumption/overall running time: 55.6765s / 61897.4950 s
env0_first_0:                 episode reward: -81.7000,                 loss: 18.1810
env0_second_0:                 episode reward: 81.7000,                 loss: 19.5340
env1_first_0:                 episode reward: -80.5000,                 loss: nan
env1_second_0:                 episode reward: 80.5000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 232.4,                last time consumption/overall running time: 45.1663s / 61942.6613 s
env0_first_0:                 episode reward: -88.1000,                 loss: 15.6202
env0_second_0:                 episode reward: 88.1000,                 loss: 17.8180
env1_first_0:                 episode reward: -90.8000,                 loss: nan
env1_second_0:                 episode reward: 90.8000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 235.8,                last time consumption/overall running time: 44.9228s / 61987.5841 s
env0_first_0:                 episode reward: -92.5500,                 loss: 18.0125
env0_second_0:                 episode reward: 92.5500,                 loss: 18.6140
env1_first_0:                 episode reward: -88.2500,                 loss: nan
env1_second_0:                 episode reward: 88.2500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 235.2,                last time consumption/overall running time: 44.2529s / 62031.8370 s
env0_first_0:                 episode reward: -91.4000,                 loss: 17.5516
env0_second_0:                 episode reward: 91.4000,                 loss: 18.6464
env1_first_0:                 episode reward: -91.7500,                 loss: nan
env1_second_0:                 episode reward: 91.7500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 237.35,                last time consumption/overall running time: 45.9124s / 62077.7494 s
env0_first_0:                 episode reward: -93.7000,                 loss: 14.1290
env0_second_0:                 episode reward: 93.7000,                 loss: 16.9903
env1_first_0:                 episode reward: -92.4000,                 loss: nan
env1_second_0:                 episode reward: 92.4000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 225.4,                last time consumption/overall running time: 44.7395s / 62122.4889 s
env0_first_0:                 episode reward: -95.0000,                 loss: 13.5921
env0_second_0:                 episode reward: 95.0000,                 loss: 15.8678
env1_first_0:                 episode reward: -90.3000,                 loss: nan
env1_second_0:                 episode reward: 90.3000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 236.9,                last time consumption/overall running time: 45.1477s / 62167.6366 s
env0_first_0:                 episode reward: -92.1000,                 loss: 17.8785
env0_second_0:                 episode reward: 92.1000,                 loss: 17.7395
env1_first_0:                 episode reward: -90.5000,                 loss: nan
env1_second_0:                 episode reward: 90.5000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 228.4,                last time consumption/overall running time: 43.9673s / 62211.6039 s
env0_first_0:                 episode reward: -90.6500,                 loss: 13.6490
env0_second_0:                 episode reward: 90.6500,                 loss: 15.6167
env1_first_0:                 episode reward: -96.3500,                 loss: nan
env1_second_0:                 episode reward: 96.3500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 225.4,                last time consumption/overall running time: 43.5576s / 62255.1614 s
env0_first_0:                 episode reward: -89.0500,                 loss: 13.3671
env0_second_0:                 episode reward: 89.0500,                 loss: 16.2253
env1_first_0:                 episode reward: -93.8500,                 loss: nan
env1_second_0:                 episode reward: 93.8500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 262.0,                last time consumption/overall running time: 49.0920s / 62304.2534 s
env0_first_0:                 episode reward: -79.2000,                 loss: 24.7356
env0_second_0:                 episode reward: 79.2000,                 loss: 24.0295
env1_first_0:                 episode reward: -83.6500,                 loss: nan
env1_second_0:                 episode reward: 83.6500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 270.75,                last time consumption/overall running time: 51.2304s / 62355.4838 s
env0_first_0:                 episode reward: -89.1000,                 loss: 33.7632
env0_second_0:                 episode reward: 89.1000,                 loss: 34.0585
env1_first_0:                 episode reward: -77.7000,                 loss: nan
env1_second_0:                 episode reward: 77.7000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 263.3,                last time consumption/overall running time: 49.2646s / 62404.7484 s
env0_first_0:                 episode reward: -80.2500,                 loss: 31.5391
env0_second_0:                 episode reward: 80.2500,                 loss: 32.0268
env1_first_0:                 episode reward: -89.3000,                 loss: nan
env1_second_0:                 episode reward: 89.3000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 247.2,                last time consumption/overall running time: 47.3695s / 62452.1178 s
env0_first_0:                 episode reward: -85.7000,                 loss: 28.8385
env0_second_0:                 episode reward: 85.7000,                 loss: 30.0519
env1_first_0:                 episode reward: -82.7000,                 loss: nan
env1_second_0:                 episode reward: 82.7000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 244.95,                last time consumption/overall running time: 47.1807s / 62499.2985 s
env0_first_0:                 episode reward: -88.6500,                 loss: 27.9687
env0_second_0:                 episode reward: 88.6500,                 loss: 29.0735
env1_first_0:                 episode reward: -82.5000,                 loss: nan
env1_second_0:                 episode reward: 82.5000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 303.45,                last time consumption/overall running time: 53.9490s / 62553.2475 s
env0_first_0:                 episode reward: -77.1000,                 loss: 31.6142
env0_second_0:                 episode reward: 77.1000,                 loss: 32.3298
env1_first_0:                 episode reward: -80.5500,                 loss: nan
env1_second_0:                 episode reward: 80.5500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 418.45,                last time consumption/overall running time: 70.8749s / 62624.1224 s
env0_first_0:                 episode reward: -61.4000,                 loss: 42.2602
env0_second_0:                 episode reward: 61.4000,                 loss: 43.6446
env1_first_0:                 episode reward: -70.9500,                 loss: nan
env1_second_0:                 episode reward: 70.9500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 493.1,                last time consumption/overall running time: 80.1339s / 62704.2564 s
env0_first_0:                 episode reward: -64.3500,                 loss: 38.6123
env0_second_0:                 episode reward: 64.3500,                 loss: 39.4606
env1_first_0:                 episode reward: -78.7500,                 loss: nan
env1_second_0:                 episode reward: 78.7500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 502.65,                last time consumption/overall running time: 82.6352s / 62786.8916 s
env0_first_0:                 episode reward: -77.4500,                 loss: 29.6221
env0_second_0:                 episode reward: 77.4500,                 loss: 30.3700
env1_first_0:                 episode reward: -66.6500,                 loss: nan
env1_second_0:                 episode reward: 66.6500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 430.15,                last time consumption/overall running time: 72.4100s / 62859.3015 s
env0_first_0:                 episode reward: -69.4000,                 loss: 29.8646
env0_second_0:                 episode reward: 69.4000,                 loss: 29.9325
env1_first_0:                 episode reward: -77.8000,                 loss: nan
env1_second_0:                 episode reward: 77.8000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 560.75,                last time consumption/overall running time: 89.8321s / 62949.1337 s
env0_first_0:                 episode reward: -78.9000,                 loss: 24.7685
env0_second_0:                 episode reward: 78.9000,                 loss: 24.6717
env1_first_0:                 episode reward: -68.6000,                 loss: nan
env1_second_0:                 episode reward: 68.6000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 524.9,                last time consumption/overall running time: 85.9515s / 63035.0852 s
env0_first_0:                 episode reward: -70.2500,                 loss: 25.7366
env0_second_0:                 episode reward: 70.2500,                 loss: 25.9836
env1_first_0:                 episode reward: -78.1500,                 loss: nan
env1_second_0:                 episode reward: 78.1500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 455.25,                last time consumption/overall running time: 76.8434s / 63111.9285 s
env0_first_0:                 episode reward: -81.8000,                 loss: 26.8185
env0_second_0:                 episode reward: 81.8000,                 loss: 27.4184
env1_first_0:                 episode reward: -71.7000,                 loss: nan
env1_second_0:                 episode reward: 71.7000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 412.3,                last time consumption/overall running time: 70.0135s / 63181.9420 s
env0_first_0:                 episode reward: -68.3000,                 loss: 35.3879
env0_second_0:                 episode reward: 68.3000,                 loss: 36.4948
env1_first_0:                 episode reward: -81.0500,                 loss: nan
env1_second_0:                 episode reward: 81.0500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 353.55,                last time consumption/overall running time: 61.2181s / 63243.1601 s
env0_first_0:                 episode reward: -81.2000,                 loss: 38.7593
env0_second_0:                 episode reward: 81.2000,                 loss: 40.5291
env1_first_0:                 episode reward: -69.4500,                 loss: nan
env1_second_0:                 episode reward: 69.4500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 410.65,                last time consumption/overall running time: 68.4694s / 63311.6295 s
env0_first_0:                 episode reward: -82.6500,                 loss: 35.1019
env0_second_0:                 episode reward: 82.6500,                 loss: 36.1576
env1_first_0:                 episode reward: -76.2000,                 loss: nan
env1_second_0:                 episode reward: 76.2000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 397.75,                last time consumption/overall running time: 68.5682s / 63380.1977 s
env0_first_0:                 episode reward: -73.1500,                 loss: 38.5192
env0_second_0:                 episode reward: 73.1500,                 loss: 39.9484
env1_first_0:                 episode reward: -72.0500,                 loss: nan
env1_second_0:                 episode reward: 72.0500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 294.4,                last time consumption/overall running time: 51.9124s / 63432.1101 s
env0_first_0:                 episode reward: -71.3000,                 loss: 43.7241
env0_second_0:                 episode reward: 71.3000,                 loss: 44.1011
env1_first_0:                 episode reward: -77.8000,                 loss: nan
env1_second_0:                 episode reward: 77.8000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 272.6,                last time consumption/overall running time: 50.0127s / 63482.1228 s
env0_first_0:                 episode reward: -75.0000,                 loss: 35.3030
env0_second_0:                 episode reward: 75.0000,                 loss: 37.7947
env1_first_0:                 episode reward: -89.6500,                 loss: nan
env1_second_0:                 episode reward: 89.6500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 289.7,                last time consumption/overall running time: 51.3960s / 63533.5187 s
env0_first_0:                 episode reward: -84.0000,                 loss: 39.3028
env0_second_0:                 episode reward: 84.0000,                 loss: 40.0765
env1_first_0:                 episode reward: -74.5500,                 loss: nan
env1_second_0:                 episode reward: 74.5500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 283.1,                last time consumption/overall running time: 51.9456s / 63585.4643 s
env0_first_0:                 episode reward: -82.1000,                 loss: 46.8391
env0_second_0:                 episode reward: 82.1000,                 loss: 47.7418
env1_first_0:                 episode reward: -75.3500,                 loss: nan
env1_second_0:                 episode reward: 75.3500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 269.45,                last time consumption/overall running time: 49.3526s / 63634.8169 s
env0_first_0:                 episode reward: -74.1500,                 loss: 41.3761
env0_second_0:                 episode reward: 74.1500,                 loss: 43.0553
env1_first_0:                 episode reward: -78.3000,                 loss: nan
env1_second_0:                 episode reward: 78.3000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 347.05,                last time consumption/overall running time: 60.3504s / 63695.1673 s
env0_first_0:                 episode reward: -86.3000,                 loss: 40.9822
env0_second_0:                 episode reward: 86.3000,                 loss: 39.0750
env1_first_0:                 episode reward: -67.4000,                 loss: nan
env1_second_0:                 episode reward: 67.4000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 340.35,                last time consumption/overall running time: 59.5805s / 63754.7478 s
env0_first_0:                 episode reward: -80.4000,                 loss: 36.5482
env0_second_0:                 episode reward: 80.4000,                 loss: 36.6270
env1_first_0:                 episode reward: -76.7000,                 loss: nan
env1_second_0:                 episode reward: 76.7000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 318.4,                last time consumption/overall running time: 56.6395s / 63811.3873 s
env0_first_0:                 episode reward: -87.0000,                 loss: 33.1962
env0_second_0:                 episode reward: 87.0000,                 loss: 32.4679
env1_first_0:                 episode reward: -72.5500,                 loss: nan
env1_second_0:                 episode reward: 72.5500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 272.4,                last time consumption/overall running time: 50.1807s / 63861.5680 s
env0_first_0:                 episode reward: -75.5000,                 loss: 33.5199
env0_second_0:                 episode reward: 75.5000,                 loss: 34.6136
env1_first_0:                 episode reward: -76.3000,                 loss: nan
env1_second_0:                 episode reward: 76.3000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 339.4,                last time consumption/overall running time: 59.1439s / 63920.7119 s
env0_first_0:                 episode reward: -71.3500,                 loss: 30.2564
env0_second_0:                 episode reward: 71.3500,                 loss: 31.0837
env1_first_0:                 episode reward: -80.7000,                 loss: nan
env1_second_0:                 episode reward: 80.7000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 269.1,                last time consumption/overall running time: 49.4553s / 63970.1672 s
env0_first_0:                 episode reward: -80.5000,                 loss: 32.2110
env0_second_0:                 episode reward: 80.5000,                 loss: 31.9128
env1_first_0:                 episode reward: -80.5500,                 loss: nan
env1_second_0:                 episode reward: 80.5500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 255.9,                last time consumption/overall running time: 46.7112s / 64016.8784 s
env0_first_0:                 episode reward: -86.7500,                 loss: 26.9463
env0_second_0:                 episode reward: 86.7500,                 loss: 27.5618
env1_first_0:                 episode reward: -77.3500,                 loss: nan
env1_second_0:                 episode reward: 77.3500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 286.9,                last time consumption/overall running time: 51.9995s / 64068.8779 s
env0_first_0:                 episode reward: -79.5500,                 loss: 24.8019
env0_second_0:                 episode reward: 79.5500,                 loss: 23.9462
env1_first_0:                 episode reward: -80.0500,                 loss: nan
env1_second_0:                 episode reward: 80.0500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 272.5,                last time consumption/overall running time: 50.1454s / 64119.0233 s
env0_first_0:                 episode reward: -79.6000,                 loss: 24.8425
env0_second_0:                 episode reward: 79.6000,                 loss: 26.3503
env1_first_0:                 episode reward: -76.3000,                 loss: nan
env1_second_0:                 episode reward: 76.3000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 249.55,                last time consumption/overall running time: 46.8210s / 64165.8443 s
env0_first_0:                 episode reward: -88.9000,                 loss: 17.2564
env0_second_0:                 episode reward: 88.9000,                 loss: 19.6855
env1_first_0:                 episode reward: -90.3000,                 loss: nan
env1_second_0:                 episode reward: 90.3000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 249.35,                last time consumption/overall running time: 45.9943s / 64211.8386 s
env0_first_0:                 episode reward: -81.5500,                 loss: 17.0044
env0_second_0:                 episode reward: 81.5500,                 loss: 18.8326
env1_first_0:                 episode reward: -84.3500,                 loss: nan
env1_second_0:                 episode reward: 84.3500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 237.7,                last time consumption/overall running time: 44.0985s / 64255.9371 s
env0_first_0:                 episode reward: -94.6500,                 loss: 16.3470
env0_second_0:                 episode reward: 94.6500,                 loss: 17.6221
env1_first_0:                 episode reward: -85.5500,                 loss: nan
env1_second_0:                 episode reward: 85.5500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 233.05,                last time consumption/overall running time: 44.7694s / 64300.7065 s
env0_first_0:                 episode reward: -72.1500,                 loss: 20.7293
env0_second_0:                 episode reward: 72.1500,                 loss: 23.7709
env1_first_0:                 episode reward: -93.2500,                 loss: nan
env1_second_0:                 episode reward: 93.2500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 296.75,                last time consumption/overall running time: 53.6433s / 64354.3497 s
env0_first_0:                 episode reward: -70.0500,                 loss: 24.3158
env0_second_0:                 episode reward: 70.0500,                 loss: 22.3025
env1_first_0:                 episode reward: -76.0500,                 loss: nan
env1_second_0:                 episode reward: 76.0500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 464.6,                last time consumption/overall running time: 77.4005s / 64431.7503 sLoad boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -62.4000,                 loss: 15.7309
env0_second_0:                 episode reward: 62.4000,                 loss: 16.8968
env1_first_0:                 episode reward: -58.4000,                 loss: nan
env1_second_0:                 episode reward: 58.4000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 316.6,                last time consumption/overall running time: 54.7552s / 64486.5054 s
env0_first_0:                 episode reward: -71.2500,                 loss: 30.0111
env0_second_0:                 episode reward: 71.2500,                 loss: 27.9018
env1_first_0:                 episode reward: -85.8000,                 loss: nan
env1_second_0:                 episode reward: 85.8000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 344.55,                last time consumption/overall running time: 59.5864s / 64546.0919 s
env0_first_0:                 episode reward: -76.1000,                 loss: 29.3579
env0_second_0:                 episode reward: 76.1000,                 loss: 29.7152
env1_first_0:                 episode reward: -76.2000,                 loss: nan
env1_second_0:                 episode reward: 76.2000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 362.1,                last time consumption/overall running time: 63.0977s / 64609.1895 s
env0_first_0:                 episode reward: -77.4500,                 loss: 32.7177
env0_second_0:                 episode reward: 77.4500,                 loss: 32.7927
env1_first_0:                 episode reward: -72.2500,                 loss: nan
env1_second_0:                 episode reward: 72.2500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 370.8,                last time consumption/overall running time: 63.5071s / 64672.6966 s
env0_first_0:                 episode reward: -72.4500,                 loss: 43.0647
env0_second_0:                 episode reward: 72.4500,                 loss: 42.2705
env1_first_0:                 episode reward: -75.2500,                 loss: nan
env1_second_0:                 episode reward: 75.2500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 302.25,                last time consumption/overall running time: 53.8182s / 64726.5147 s
env0_first_0:                 episode reward: -75.7500,                 loss: 46.4774
env0_second_0:                 episode reward: 75.7500,                 loss: 46.9468
env1_first_0:                 episode reward: -69.4500,                 loss: nan
env1_second_0:                 episode reward: 69.4500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 293.0,                last time consumption/overall running time: 53.0210s / 64779.5358 s
env0_first_0:                 episode reward: -83.4000,                 loss: 35.6294
env0_second_0:                 episode reward: 83.4000,                 loss: 36.6894
env1_first_0:                 episode reward: -81.4000,                 loss: nan
env1_second_0:                 episode reward: 81.4000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 374.2,                last time consumption/overall running time: 63.2347s / 64842.7704 s
env0_first_0:                 episode reward: -81.8500,                 loss: 32.1114
env0_second_0:                 episode reward: 81.8500,                 loss: 33.1488
env1_first_0:                 episode reward: -76.7500,                 loss: nan
env1_second_0:                 episode reward: 76.7500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 321.65,                last time consumption/overall running time: 56.1571s / 64898.9276 s
env0_first_0:                 episode reward: -68.9500,                 loss: 47.2104
env0_second_0:                 episode reward: 68.9500,                 loss: 49.6245
env1_first_0:                 episode reward: -73.6500,                 loss: nan
env1_second_0:                 episode reward: 73.6500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 326.4,                last time consumption/overall running time: 57.0235s / 64955.9511 s
env0_first_0:                 episode reward: -76.1500,                 loss: 42.5344
env0_second_0:                 episode reward: 76.1500,                 loss: 43.1577
env1_first_0:                 episode reward: -80.5500,                 loss: nan
env1_second_0:                 episode reward: 80.5500,                 loss: nan
