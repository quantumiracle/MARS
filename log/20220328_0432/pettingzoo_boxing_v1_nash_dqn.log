Traceback (most recent call last):
  File "/home/zihan/research/MARS/general_train.py", line 1, in <module>
    from mars.utils.func import LoadYAML2Dict
  File "/home/zihan/research/MARS/mars/utils/func.py", line 7, in <module>
    from mars.rl.agents  import *
  File "/home/zihan/research/MARS/mars/rl/agents/__init__.py", line 1, in <module>
    from .dqn import DQN
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 1, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [23, 24]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 1000000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 150, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220328_0432/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220328_0432/pettingzoo_boxing_v1_nash_dqn.
Episode: 1/50000 (0.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 2.0390s / 2.0390 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0024
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0029
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/50000 (0.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 174.5989s / 176.6378 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0041
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0036
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 41/50000 (0.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 170.8194s / 347.4572 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0036
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0032
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 61/50000 (0.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 171.2308s / 518.6880 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0034
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0033
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 81/50000 (0.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 171.6863s / 690.3743 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0034
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0032
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 101/50000 (0.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 175.6245s / 865.9988 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0027
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0024
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 121/50000 (0.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 174.4333s / 1040.4321 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0027
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0024
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 141/50000 (0.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 177.8459s / 1218.2779 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0025
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0024
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 161/50000 (0.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 177.1461s / 1395.4240 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0024
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0023
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 181/50000 (0.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 179.8019s / 1575.2259 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0025
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0026
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 201/50000 (0.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 178.8360s / 1754.0620 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0023
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0024
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 221/50000 (0.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 178.5227s / 1932.5847 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0023
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0022
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 241/50000 (0.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 178.8818s / 2111.4664 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0020
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0019
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 261/50000 (0.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 181.3234s / 2292.7898 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0020
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0021
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 281/50000 (0.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 180.7791s / 2473.5690 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0020
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0020
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 301/50000 (0.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 183.6973s / 2657.2662 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0019
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0021
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 321/50000 (0.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 184.1921s / 2841.4583 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0019
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0022
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 341/50000 (0.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 183.8057s / 3025.2641 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0018
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0021
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 361/50000 (0.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 182.5387s / 3207.8028 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0019
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0023
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 381/50000 (0.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 186.3153s / 3394.1181 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0019
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0021
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 401/50000 (0.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 185.4047s / 3579.5228 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0019
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0022
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 421/50000 (0.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 186.9365s / 3766.4594 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0022
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0023
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 441/50000 (0.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 188.7390s / 3955.1983 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0021
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0021
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 461/50000 (0.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 188.9318s / 4144.1301 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0018
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0022
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 481/50000 (0.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 191.7250s / 4335.8551 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0019
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0022
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 501/50000 (1.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 190.4429s / 4526.2980 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0019
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0021
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 521/50000 (1.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 192.3578s / 4718.6558 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0021
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0022
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 541/50000 (1.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 194.0275s / 4912.6833 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0020
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0023
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 561/50000 (1.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 194.4514s / 5107.1347 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0020
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0022
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 581/50000 (1.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 196.3305s / 5303.4652 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0021
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0024
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 601/50000 (1.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 198.0385s / 5501.5037 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0021
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0024
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 621/50000 (1.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 196.5767s / 5698.0804 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0023
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0027
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 641/50000 (1.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 197.0037s / 5895.0841 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0022
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0025
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 661/50000 (1.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 201.4883s / 6096.5724 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0021
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0026
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 681/50000 (1.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 202.7415s / 6299.3138 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0021
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0024
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 701/50000 (1.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 199.9632s / 6499.2770 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0021
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0025
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 721/50000 (1.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 200.0455s / 6699.3225 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0023
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0025
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 741/50000 (1.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 203.5269s / 6902.8494 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0021
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0026
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 761/50000 (1.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 205.6574s / 7108.5068 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0022
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0025
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 781/50000 (1.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 203.7520s / 7312.2589 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0022
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0026
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 801/50000 (1.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 203.9360s / 7516.1948 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0025
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0028
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 821/50000 (1.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 207.1661s / 7723.3609 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0023
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0026
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 841/50000 (1.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 203.4568s / 7926.8177 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0023
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0028
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 861/50000 (1.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 198.2604s / 8125.0782 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0025
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0029
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 881/50000 (1.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 199.2242s / 8324.3024 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0024
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0031
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 901/50000 (1.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 198.7381s / 8523.0405 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0027
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0029
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 921/50000 (1.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 198.6934s / 8721.7338 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0026
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0033
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 941/50000 (1.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 204.3349s / 8926.0687 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0024
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0031
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 961/50000 (1.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 199.9023s / 9125.9710 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0026
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0031
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 981/50000 (1.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 199.8335s / 9325.8045 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0027
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0031
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1001/50000 (2.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 201.2459s / 9527.0504 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0026
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0029
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1021/50000 (2.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 201.8414s / 9728.8918 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0027
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0030
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1041/50000 (2.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 200.9337s / 9929.8255 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0026
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0030
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1061/50000 (2.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 200.6539s / 10130.4794 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0027
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0030
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1081/50000 (2.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 201.5823s / 10332.0617 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0027
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0028
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1101/50000 (2.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 199.6944s / 10531.7561 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0025
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0031
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1121/50000 (2.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 200.5906s / 10732.3467 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0022
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0029
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1141/50000 (2.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 201.4902s / 10933.8369 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0023
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0031
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1161/50000 (2.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 202.0946s / 11135.9315 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0024
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0029
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1181/50000 (2.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 202.3832s / 11338.3147 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0024
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1201/50000 (2.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 201.9422s / 11540.2570 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0025
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0024
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1221/50000 (2.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 201.4330s / 11741.6900 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0025
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0027
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1241/50000 (2.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 200.8923s / 11942.5823 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0026
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0028
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1261/50000 (2.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 202.1028s / 12144.6851 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0030
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0027
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1281/50000 (2.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 200.6440s / 12345.3291 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0030
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0027
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1301/50000 (2.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 201.1045s / 12546.4336 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0027
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0031
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1321/50000 (2.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 199.7754s / 12746.2090 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0026
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0031
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1341/50000 (2.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 198.9626s / 12945.1716 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0027
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0035
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1361/50000 (2.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 198.8610s / 13144.0326 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0026
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0033
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1381/50000 (2.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 199.5158s / 13343.5484 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0028
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0034
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1401/50000 (2.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 200.8950s / 13544.4434 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0029
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0029
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1421/50000 (2.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 202.5398s / 13746.9832 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0029
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0028
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1441/50000 (2.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 201.8924s / 13948.8756 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0029
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0032
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1461/50000 (2.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 201.8965s / 14150.7721 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0026
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0030
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1481/50000 (2.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 206.9909s / 14357.7630 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0027
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0030
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1501/50000 (3.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 202.4371s / 14560.2002 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0032
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0030
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1521/50000 (3.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 201.7321s / 14761.9323 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0027
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0026
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1541/50000 (3.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 201.8217s / 14963.7539 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0028
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0028
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1561/50000 (3.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 201.0886s / 15164.8425 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0030
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0029
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1581/50000 (3.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 201.4141s / 15366.2566 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0032
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0028
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1601/50000 (3.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 203.4221s / 15569.6787 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0031
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0030
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1621/50000 (3.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 202.1223s / 15771.8010 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0028
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0026
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1641/50000 (3.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 202.3186s / 15974.1197 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0028
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0026
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1661/50000 (3.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 203.9137s / 16178.0333 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0028
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0027
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1681/50000 (3.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 202.2831s / 16380.3164 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0026
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0023
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1701/50000 (3.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 201.6938s / 16582.0102 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0025
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0024
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1721/50000 (3.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 201.4980s / 16783.5082 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0025
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0024
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1741/50000 (3.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 202.7561s / 16986.2643 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0024
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0024
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1761/50000 (3.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 202.4784s / 17188.7426 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0022
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0021
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1781/50000 (3.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 202.9043s / 17391.6469 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0023
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0025
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1801/50000 (3.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 203.5426s / 17595.1895 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0021
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0022
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1821/50000 (3.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 204.0879s / 17799.2774 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0020
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0023
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1841/50000 (3.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 205.8005s / 18005.0778 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0022
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0023
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1861/50000 (3.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 205.7872s / 18210.8650 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0022
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0020
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1881/50000 (3.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 206.0465s / 18416.9116 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0024
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0021
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1901/50000 (3.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 206.8607s / 18623.7723 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0022
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0021
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1921/50000 (3.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 206.0347s / 18829.8069 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0023
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0021
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1941/50000 (3.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 204.3503s / 19034.1573 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0020
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0022
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1961/50000 (3.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 206.8640s / 19241.0212 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0022
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0022
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1981/50000 (3.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 205.2947s / 19446.3159 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0020
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0022
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2001/50000 (4.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 205.8754s / 19652.1913 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0021
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0026
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2021/50000 (4.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 204.0654s / 19856.2567 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0021
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0027
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2041/50000 (4.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 207.0858s / 20063.3425 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0021
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0030
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2061/50000 (4.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 204.1969s / 20267.5394 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0026
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0028
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2081/50000 (4.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 204.4079s / 20471.9474 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0025
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2101/50000 (4.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 206.4938s / 20678.4411 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0024
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0025
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2121/50000 (4.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 207.6617s / 20886.1029 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0022
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0023
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2141/50000 (4.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 208.0856s / 21094.1885 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0022
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0022
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2161/50000 (4.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 202.7163s / 21296.9048 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0024
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0022
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2181/50000 (4.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 206.9459s / 21503.8506 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0024
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0020
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2201/50000 (4.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 209.4251s / 21713.2757 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0028
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0021
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2221/50000 (4.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 206.7787s / 21920.0544 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0031
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0025
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2241/50000 (4.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 209.4830s / 22129.5374 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0025
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0027
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2261/50000 (4.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 206.8625s / 22336.3999 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0025
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0027
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2281/50000 (4.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 206.7791s / 22543.1789 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0025
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0026
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2301/50000 (4.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 204.0382s / 22747.2171 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0030
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0026
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2321/50000 (4.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 204.6798s / 22951.8969 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0031
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0025
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2341/50000 (4.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 205.4540s / 23157.3510 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0032
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0029
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2361/50000 (4.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 203.4722s / 23360.8232 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0032
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0030
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2381/50000 (4.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 205.2171s / 23566.0403 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0037
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0031
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2401/50000 (4.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 204.7436s / 23770.7839 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0033
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0031
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2421/50000 (4.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 205.6872s / 23976.4710 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0033
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0028
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2441/50000 (4.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 207.0536s / 24183.5246 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0033
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0029
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2461/50000 (4.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 204.9146s / 24388.4392 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0037
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0031
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2481/50000 (4.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 209.2102s / 24597.6495 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0037
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0034
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2501/50000 (5.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 202.9339s / 24800.5833 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0044
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0032
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2521/50000 (5.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 207.1028s / 25007.6861 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0047
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0031
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2541/50000 (5.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 203.6257s / 25211.3118 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0046
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0033
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2561/50000 (5.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 208.0144s / 25419.3262 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0049
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0044
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2581/50000 (5.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 203.5423s / 25622.8685 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0049
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0041
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2601/50000 (5.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 208.8332s / 25831.7017 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0053
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0038
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2621/50000 (5.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 206.1799s / 26037.8817 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0060
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0034
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2641/50000 (5.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 208.0482s / 26245.9299 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0060
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0036
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2661/50000 (5.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 205.1992s / 26451.1291 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0066
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0038
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2681/50000 (5.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 204.3972s / 26655.5263 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0079
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0040
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2701/50000 (5.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 213.3582s / 26868.8845 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0076
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0039
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2721/50000 (5.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 211.0960s / 27079.9804 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0086
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0044
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2741/50000 (5.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 209.7840s / 27289.7645 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0098
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0046
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2761/50000 (5.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 209.7789s / 27499.5433 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0048
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2781/50000 (5.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 213.4772s / 27713.0205 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0051
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2801/50000 (5.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 212.1032s / 27925.1238 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0066
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2821/50000 (5.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 218.5926s / 28143.7164 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0120
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0078
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2841/50000 (5.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 216.1023s / 28359.8187 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0143
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0093
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2861/50000 (5.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 209.2245s / 28569.0432 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0157
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0102
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2881/50000 (5.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 203.5201s / 28772.5633 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0181
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0095
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2901/50000 (5.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 208.9709s / 28981.5342 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0217
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2921/50000 (5.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 205.8978s / 29187.4320 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0228
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0111
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2941/50000 (5.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 217.7465s / 29405.1784 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0269
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0111
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2961/50000 (5.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 206.0114s / 29611.1898 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0273
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2981/50000 (5.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 210.9139s / 29822.1037 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0282
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3001/50000 (6.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 205.9291s / 30028.0329 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0307
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0135
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3021/50000 (6.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 211.7590s / 30239.7919 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0310
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0155
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3041/50000 (6.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 206.7587s / 30446.5506 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0324
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0156
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3061/50000 (6.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 209.5586s / 30656.1092 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0351
env0_second_0:                 episode reward: -1.8000,                 loss: 0.0169
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3081/50000 (6.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 205.8480s / 30861.9573 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0341
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0172
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3101/50000 (6.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 209.2408s / 31071.1981 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0345
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0200
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3121/50000 (6.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 206.2663s / 31277.4644 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0338
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0204
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3141/50000 (6.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 206.0982s / 31483.5626 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0344
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0184
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3161/50000 (6.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 206.4158s / 31689.9784 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0327
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0201
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3181/50000 (6.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 204.4987s / 31894.4772 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0333
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0206
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3201/50000 (6.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 213.0706s / 32107.5478 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0341
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0200
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3221/50000 (6.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 207.4364s / 32314.9842 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0325
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0233
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3241/50000 (6.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 211.4800s / 32526.4643 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0320
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0201
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3261/50000 (6.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 209.0996s / 32735.5638 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0335
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0216
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3281/50000 (6.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 205.8412s / 32941.4050 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0340
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0198
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3301/50000 (6.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 209.4866s / 33150.8916 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0320
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0204
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 3321/50000 (6.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 206.5638s / 33357.4554 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0318
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0218
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3341/50000 (6.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 207.8180s / 33565.2734 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0328
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0231
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3361/50000 (6.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 209.4494s / 33774.7227 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0347
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0239
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3381/50000 (6.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 207.9348s / 33982.6576 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0379
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3401/50000 (6.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 209.9633s / 34192.6209 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0369
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0234
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3421/50000 (6.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 209.2448s / 34401.8656 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0387
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0242
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3441/50000 (6.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 205.9610s / 34607.8266 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0408
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0247
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3461/50000 (6.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 208.0411s / 34815.8677 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0405
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0250
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3481/50000 (6.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 207.0644s / 35022.9321 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0403
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0253
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3501/50000 (7.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 205.0891s / 35228.0212 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0401
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0251
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3521/50000 (7.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 205.4908s / 35433.5121 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0369
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3541/50000 (7.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 205.6825s / 35639.1946 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0362
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0293
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3561/50000 (7.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 204.9697s / 35844.1643 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0323
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0289
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3581/50000 (7.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 205.6908s / 36049.8551 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0324
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0274
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3601/50000 (7.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 208.0242s / 36257.8793 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0322
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0269
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3621/50000 (7.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 218.7741s / 36476.6534 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0331
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0274
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3641/50000 (7.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 215.8180s / 36692.4714 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0332
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0276
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3661/50000 (7.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 220.6206s / 36913.0919 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0321
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0251
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3681/50000 (7.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 221.7339s / 37134.8258 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0340
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0245
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3701/50000 (7.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 216.9333s / 37351.7591 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0351
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3721/50000 (7.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 218.8402s / 37570.5993 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0335
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0286
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3741/50000 (7.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 221.4690s / 37792.0683 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0321
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0257
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3761/50000 (7.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 217.0095s / 38009.0778 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0274
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0221
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3781/50000 (7.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 221.8422s / 38230.9200 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0277
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0201
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3801/50000 (7.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 217.5463s / 38448.4663 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0261
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0205
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3821/50000 (7.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 218.2490s / 38666.7153 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0248
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0190
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3841/50000 (7.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 222.8945s / 38889.6098 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0232
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0190
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3861/50000 (7.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 217.2510s / 39106.8607 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0243
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0182
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3881/50000 (7.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 223.0496s / 39329.9103 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0254
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0179
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3901/50000 (7.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 220.2942s / 39550.2044 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0253
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0189
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 3921/50000 (7.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 219.5748s / 39769.7792 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0249
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0208
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3941/50000 (7.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 220.1904s / 39989.9696 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0261
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0223
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3961/50000 (7.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 220.4340s / 40210.4037 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0204
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3981/50000 (7.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 220.7433s / 40431.1470 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0246
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0200
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4001/50000 (8.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 217.8532s / 40649.0002 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0242
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0206
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4021/50000 (8.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 217.9741s / 40866.9743 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0254
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0189
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4041/50000 (8.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 220.7427s / 41087.7170 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0284
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0183
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4061/50000 (8.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 222.0695s / 41309.7865 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0278
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0179
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4081/50000 (8.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 216.8891s / 41526.6756 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0269
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0193
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4101/50000 (8.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 217.4427s / 41744.1183 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0263
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0230
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4121/50000 (8.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 217.8412s / 41961.9595 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0265
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0228
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4141/50000 (8.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 220.4604s / 42182.4200 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4161/50000 (8.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 221.7752s / 42404.1952 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0240
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0255
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4181/50000 (8.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 219.2131s / 42623.4083 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0248
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0253
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4201/50000 (8.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 215.9888s / 42839.3971 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0274
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0266
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4221/50000 (8.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 217.1086s / 43056.5057 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0265
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0246
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4241/50000 (8.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 215.9202s / 43272.4259 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0290
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0249
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4261/50000 (8.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 214.5037s / 43486.9297 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0317
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0249
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4281/50000 (8.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 218.0447s / 43704.9743 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0325
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0246
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4301/50000 (8.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 214.9838s / 43919.9581 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0314
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4321/50000 (8.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 216.8196s / 44136.7777 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0304
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4341/50000 (8.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 216.8410s / 44353.6187 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0310
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0248
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4361/50000 (8.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 217.7505s / 44571.3692 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0308
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0247
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4381/50000 (8.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 219.1827s / 44790.5520 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0296
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0251
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4401/50000 (8.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 216.9822s / 45007.5341 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0285
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0266
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4421/50000 (8.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 218.2912s / 45225.8253 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0304
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0279
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4441/50000 (8.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 219.9399s / 45445.7652 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0343
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0271
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4461/50000 (8.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 218.4009s / 45664.1661 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0344
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0259
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4481/50000 (8.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 216.3959s / 45880.5621 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0329
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0261
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4501/50000 (9.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 217.2733s / 46097.8354 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0336
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0265
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4521/50000 (9.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 217.7307s / 46315.5661 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0347
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0266
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4541/50000 (9.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 218.0268s / 46533.5929 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0354
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0244
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4561/50000 (9.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 216.5504s / 46750.1433 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0358
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0237
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4581/50000 (9.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 219.0112s / 46969.1546 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0355
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0238
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4601/50000 (9.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 222.3846s / 47191.5392 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0333
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0256
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4621/50000 (9.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 222.6062s / 47414.1454 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0327
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0272
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4641/50000 (9.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.4190s / 47650.5644 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0333
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0304
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4661/50000 (9.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 219.7004s / 47870.2648 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0358
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0308
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4681/50000 (9.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 217.1076s / 48087.3724 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0354
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0349
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4701/50000 (9.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 222.1556s / 48309.5280 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0371
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0349
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4721/50000 (9.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 220.0541s / 48529.5822 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0403
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0360
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4741/50000 (9.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 219.4880s / 48749.0702 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0425
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0355
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4761/50000 (9.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 218.3704s / 48967.4405 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0424
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0327
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4781/50000 (9.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 220.7505s / 49188.1911 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0389
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0316
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4801/50000 (9.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 220.4030s / 49408.5941 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0379
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0283
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4821/50000 (9.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 220.8174s / 49629.4115 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0430
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0309
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4841/50000 (9.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 216.3920s / 49845.8035 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0445
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0321
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4861/50000 (9.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 215.4628s / 50061.2662 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0443
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0370
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 4881/50000 (9.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 215.4232s / 50276.6895 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0479
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0382
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4901/50000 (9.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 218.7294s / 50495.4189 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0501
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0392
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4921/50000 (9.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 219.0897s / 50714.5086 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0459
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0410
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4941/50000 (9.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 221.6607s / 50936.1693 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0464
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0390
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4961/50000 (9.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 219.3794s / 51155.5487 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0498
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0359
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4981/50000 (9.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 216.9572s / 51372.5060 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0525
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0373
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5001/50000 (10.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 220.2917s / 51592.7976 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0550
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0401
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5021/50000 (10.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 222.0110s / 51814.8086 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0550
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0402
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5041/50000 (10.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 221.0245s / 52035.8331 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0545
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0410
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5061/50000 (10.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 217.1517s / 52252.9848 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0558
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0452
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 5081/50000 (10.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 216.0721s / 52469.0569 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0524
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0438
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5101/50000 (10.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 221.2326s / 52690.2895 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0529
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0429
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5121/50000 (10.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 223.7169s / 52914.0065 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0523
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0417
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5141/50000 (10.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 221.2338s / 53135.2403 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0566
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0436
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5161/50000 (10.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 218.1186s / 53353.3589 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0611
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0466
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5181/50000 (10.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 217.9095s / 53571.2683 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0592
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0464
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5201/50000 (10.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 221.2826s / 53792.5509 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0648
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0466
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5221/50000 (10.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 221.0853s / 54013.6362 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0708
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0454
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5241/50000 (10.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 216.9944s / 54230.6307 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0673
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0458
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 5261/50000 (10.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 216.6437s / 54447.2743 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0632
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0501
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5281/50000 (10.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 216.0548s / 54663.3291 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0649
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0491
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5301/50000 (10.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 220.2455s / 54883.5746 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0669
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0491
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5321/50000 (10.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 219.7380s / 55103.3127 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0665
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0571
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 5341/50000 (10.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 218.4653s / 55321.7779 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0707
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0598
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5361/50000 (10.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 218.5553s / 55540.3333 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0757
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0621
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 5381/50000 (10.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 216.8880s / 55757.2213 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0764
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0632
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5401/50000 (10.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 215.3474s / 55972.5686 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0806
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0615
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 5421/50000 (10.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 217.5728s / 56190.1414 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0796
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0639
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5441/50000 (10.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 218.0584s / 56408.1998 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0778
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0643
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5461/50000 (10.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 219.5392s / 56627.7390 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0794
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0603
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5481/50000 (10.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 216.7590s / 56844.4980 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0776
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0620
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5501/50000 (11.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 218.4469s / 57062.9450 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0780
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0620
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5521/50000 (11.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 221.0509s / 57283.9958 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0790
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0637
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5541/50000 (11.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 221.0637s / 57505.0596 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0766
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0614
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 5561/50000 (11.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 219.4850s / 57724.5445 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0778
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0615
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5581/50000 (11.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 218.1345s / 57942.6790 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0792
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0655
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5601/50000 (11.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 217.7657s / 58160.4447 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0790
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0684
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5621/50000 (11.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 219.0216s / 58379.4663 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0796
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0719
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5641/50000 (11.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 218.4423s / 58597.9086 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0858
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0776
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 5661/50000 (11.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 222.5633s / 58820.4720 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0838
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0736
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5681/50000 (11.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 222.3363s / 59042.8083 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0804
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0739
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5701/50000 (11.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 222.6205s / 59265.4288 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0753
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0729
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 5721/50000 (11.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 224.5943s / 59490.0231 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0740
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0670
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5741/50000 (11.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 220.1924s / 59710.2155 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0743
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0665
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 5761/50000 (11.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 217.5539s / 59927.7694 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0706
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0665
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5781/50000 (11.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 219.1163s / 60146.8856 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0714
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0701
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5801/50000 (11.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 217.7675s / 60364.6531 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0705
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0688
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5821/50000 (11.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 212.0333s / 60576.6864 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0741
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0698
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5841/50000 (11.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 211.9719s / 60788.6584 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0751
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0741
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5861/50000 (11.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 212.8465s / 61001.5049 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0802
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0887
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5881/50000 (11.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 210.9006s / 61212.4055 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0830
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0868
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5901/50000 (11.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 210.1906s / 61422.5961 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0865
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0827
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 5921/50000 (11.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 206.4384s / 61629.0345 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0954
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0806
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5941/50000 (11.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 209.2045s / 61838.2390 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0939
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0809
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5961/50000 (11.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 206.7973s / 62045.0363 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0994
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0872
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5981/50000 (11.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 208.6017s / 62253.6380 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.1044
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0923
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6001/50000 (12.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 211.5057s / 62465.1437 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.1028
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0910
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6021/50000 (12.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 210.5693s / 62675.7131 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.1033
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0893
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6041/50000 (12.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 209.4572s / 62885.1702 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.1015
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0908
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6061/50000 (12.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 211.3419s / 63096.5122 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0978
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0961
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6081/50000 (12.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 209.9698s / 63306.4820 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0969
env0_second_0:                 episode reward: -0.5500,                 loss: 0.1015
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 6101/50000 (12.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 210.6146s / 63517.0965 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0874
env0_second_0:                 episode reward: -0.7000,                 loss: 0.1003
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 6121/50000 (12.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 208.5511s / 63725.6476 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0880
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0888
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6141/50000 (12.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 208.3297s / 63933.9773 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0889
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0940
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6161/50000 (12.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 207.8698s / 64141.8472 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0893
env0_second_0:                 episode reward: -0.4000,                 loss: 0.1054
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6181/50000 (12.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 209.4759s / 64351.3231 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0938
env0_second_0:                 episode reward: -0.8500,                 loss: 0.1059
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6201/50000 (12.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 207.6243s / 64558.9474 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0907
env0_second_0:                 episode reward: -0.3500,                 loss: 0.1065
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6221/50000 (12.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 211.0419s / 64769.9893 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0945
env0_second_0:                 episode reward: -0.2000,                 loss: 0.1026
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6241/50000 (12.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 209.3298s / 64979.3192 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0965
env0_second_0:                 episode reward: 1.7000,                 loss: 0.1023
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6261/50000 (12.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 208.9308s / 65188.2500 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0971
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1057
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6281/50000 (12.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 208.8535s / 65397.1035 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.1028
env0_second_0:                 episode reward: 1.1500,                 loss: 0.1042
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6301/50000 (12.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 210.5976s / 65607.7011 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0943
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1063
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6321/50000 (12.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 207.5227s / 65815.2239 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0919
env0_second_0:                 episode reward: 1.2000,                 loss: 0.1128
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6341/50000 (12.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 210.2317s / 66025.4555 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0930
env0_second_0:                 episode reward: -1.8000,                 loss: 0.1137
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6361/50000 (12.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 213.8745s / 66239.3301 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.1013
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1134
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6381/50000 (12.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 212.1804s / 66451.5104 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.1062
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1072
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6401/50000 (12.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 210.7397s / 66662.2501 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.1088
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1040
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 6421/50000 (12.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 209.8056s / 66872.0558 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.1058
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0995
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6441/50000 (12.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 208.7069s / 67080.7627 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1136
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0980
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6461/50000 (12.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 211.3843s / 67292.1470 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.1214
env0_second_0:                 episode reward: -0.7000,                 loss: 0.1084
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 6481/50000 (12.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 208.5040s / 67500.6510 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.1252
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1201
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6501/50000 (13.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 208.9807s / 67709.6317 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.1315
env0_second_0:                 episode reward: -1.8500,                 loss: 0.1325
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6521/50000 (13.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 207.8291s / 67917.4609 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.1313
env0_second_0:                 episode reward: -1.5500,                 loss: 0.1292
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6541/50000 (13.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 207.9417s / 68125.4026 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.1304
env0_second_0:                 episode reward: -0.7500,                 loss: 0.1296
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6561/50000 (13.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 207.0349s / 68332.4375 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1188
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1238
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6581/50000 (13.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 206.0582s / 68538.4958 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.1277
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1301
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6601/50000 (13.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 212.0283s / 68750.5240 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1272
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1218
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 6621/50000 (13.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 208.3090s / 68958.8331 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.1346
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1309
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 6641/50000 (13.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 209.4085s / 69168.2416 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1357
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1305
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 6661/50000 (13.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 215.2279s / 69383.4694 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1348
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1320
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 6681/50000 (13.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 214.9134s / 69598.3829 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.1398
env0_second_0:                 episode reward: 2.1000,                 loss: 0.1483
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6701/50000 (13.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 217.4724s / 69815.8553 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.1454
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1523
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6721/50000 (13.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 211.1000s / 70026.9552 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.1428
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1416
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6741/50000 (13.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 213.4687s / 70240.4239 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.1384
env0_second_0:                 episode reward: 2.1500,                 loss: 0.1421
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6761/50000 (13.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 209.2508s / 70449.6747 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.1394
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1448
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6781/50000 (13.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 213.6054s / 70663.2801 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.1380
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1480
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6801/50000 (13.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 208.5184s / 70871.7984 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.1365
env0_second_0:                 episode reward: -1.6500,                 loss: 0.1509
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 6821/50000 (13.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 209.2318s / 71081.0303 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.1471
env0_second_0:                 episode reward: -0.5500,                 loss: 0.1388
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6841/50000 (13.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 207.9927s / 71289.0229 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.1402
env0_second_0:                 episode reward: -0.8500,                 loss: 0.1305
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6861/50000 (13.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 207.8238s / 71496.8467 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.1404
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1367
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 6881/50000 (13.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 207.6017s / 71704.4484 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.1520
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1395
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 6901/50000 (13.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 210.2641s / 71914.7125 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.1496
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1504
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6921/50000 (13.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 207.8383s / 72122.5508 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.1514
env0_second_0:                 episode reward: 1.1500,                 loss: 0.1488
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6941/50000 (13.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 208.8693s / 72331.4202 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.1441
env0_second_0:                 episode reward: -0.4000,                 loss: 0.1519
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6961/50000 (13.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 210.0119s / 72541.4321 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.1616
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1536
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 6981/50000 (13.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 209.7499s / 72751.1820 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1549
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1581
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7001/50000 (14.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 208.0475s / 72959.2295 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.1552
env0_second_0:                 episode reward: 2.7500,                 loss: 0.1643
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7021/50000 (14.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 208.9906s / 73168.2201 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1568
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1601
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 7041/50000 (14.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 210.5646s / 73378.7847 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.1563
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1601
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7061/50000 (14.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 208.3631s / 73587.1478 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.1535
env0_second_0:                 episode reward: 1.8000,                 loss: 0.1514
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 7081/50000 (14.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 209.4937s / 73796.6415 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.1595
env0_second_0:                 episode reward: -1.2000,                 loss: 0.1506
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 7101/50000 (14.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 210.0781s / 74006.7196 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.1592
env0_second_0:                 episode reward: 2.3500,                 loss: 0.1681
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7121/50000 (14.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 209.2101s / 74215.9297 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.1614
env0_second_0:                 episode reward: 2.4000,                 loss: 0.1746
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7141/50000 (14.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 209.3488s / 74425.2785 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.1639
env0_second_0:                 episode reward: -0.4500,                 loss: 0.1826
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7161/50000 (14.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 211.2793s / 74636.5578 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.1581
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1684
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7181/50000 (14.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 212.1115s / 74848.6693 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.1575
env0_second_0:                 episode reward: -0.4000,                 loss: 0.1793
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 7201/50000 (14.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 211.8538s / 75060.5232 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.1628
env0_second_0:                 episode reward: 1.2500,                 loss: 0.1826
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7221/50000 (14.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 209.7956s / 75270.3187 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.1714
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1688
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7241/50000 (14.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 211.1587s / 75481.4775 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.1766
env0_second_0:                 episode reward: 1.7000,                 loss: 0.1794
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 7261/50000 (14.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 209.9236s / 75691.4011 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.1857
env0_second_0:                 episode reward: -1.3000,                 loss: 0.1868
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 7281/50000 (14.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 224.9871s / 75916.3882 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.1802
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2063
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7301/50000 (14.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 210.5438s / 76126.9320 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.1791
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2209
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 7321/50000 (14.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 209.1720s / 76336.1040 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.1751
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2157
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 7341/50000 (14.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 210.8605s / 76546.9645 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.1817
env0_second_0:                 episode reward: 1.9000,                 loss: 0.1948
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7361/50000 (14.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 208.1496s / 76755.1140 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.1849
env0_second_0:                 episode reward: -1.5000,                 loss: 0.1906
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7381/50000 (14.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 207.0293s / 76962.1433 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.1814
env0_second_0:                 episode reward: -1.9000,                 loss: 0.1993
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 7401/50000 (14.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 207.1901s / 77169.3334 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1881
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2172
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7421/50000 (14.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 207.9155s / 77377.2489 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.2086
env0_second_0:                 episode reward: -1.8500,                 loss: 0.2355
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 7441/50000 (14.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 207.5618s / 77584.8107 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2261
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2307
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7461/50000 (14.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 207.2620s / 77792.0727 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.2425
env0_second_0:                 episode reward: 1.7000,                 loss: 0.2460
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7481/50000 (14.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 208.3537s / 78000.4264 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2474
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2471
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7501/50000 (15.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 208.0157s / 78208.4422 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2689
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2473
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7521/50000 (15.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 207.1129s / 78415.5550 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2623
env0_second_0:                 episode reward: 1.5000,                 loss: 0.2514
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7541/50000 (15.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 205.8734s / 78621.4284 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2386
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2678
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 7561/50000 (15.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 207.1766s / 78828.6050 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.2269
env0_second_0:                 episode reward: 2.2000,                 loss: 0.2684
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7581/50000 (15.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 207.0468s / 79035.6519 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2357
env0_second_0:                 episode reward: 1.4500,                 loss: 0.2707
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7601/50000 (15.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 213.7215s / 79249.3734 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.2412
env0_second_0:                 episode reward: -1.5000,                 loss: 0.2888
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7621/50000 (15.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 219.6315s / 79469.0048 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.2566
env0_second_0:                 episode reward: -1.3500,                 loss: 0.2742
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7641/50000 (15.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 218.7123s / 79687.7171 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.2497
env0_second_0:                 episode reward: 1.9500,                 loss: 0.2817
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7661/50000 (15.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 220.4277s / 79908.1449 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.2342
env0_second_0:                 episode reward: -1.7000,                 loss: 0.2674
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7681/50000 (15.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 220.5202s / 80128.6651 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2352
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2702
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7701/50000 (15.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 233.0367s / 80361.7017 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2421
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2638
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7721/50000 (15.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.4621s / 80599.1639 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2392
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2620
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7741/50000 (15.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 239.2783s / 80838.4421 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2615
env0_second_0:                 episode reward: -0.3000,                 loss: 0.3015
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 7761/50000 (15.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.3052s / 81075.7474 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2718
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3163
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7781/50000 (15.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.8497s / 81312.5971 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2959
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2902
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7801/50000 (15.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.8269s / 81551.4240 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3074
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2809
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 7821/50000 (15.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2484s / 81787.6724 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3189
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2821
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7841/50000 (15.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.3486s / 82023.0210 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.3030
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2780
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7861/50000 (15.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.9727s / 82260.9937 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3209
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2719
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7881/50000 (15.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.1126s / 82498.1062 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3109
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2699
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 7901/50000 (15.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6480s / 82734.7543 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.3352
env0_second_0:                 episode reward: 3.8500,                 loss: 0.2580
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7921/50000 (15.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.3778s / 82973.1321 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3250
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2607
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 7941/50000 (15.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7915s / 83210.9235 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.3261
env0_second_0:                 episode reward: 1.8000,                 loss: 0.2507
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7961/50000 (15.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.9843s / 83446.9079 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.3192
env0_second_0:                 episode reward: 1.5000,                 loss: 0.2635
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 7981/50000 (15.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.5556s / 83685.4634 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3097
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2497
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8001/50000 (16.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 240.2319s / 83925.6953 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3125
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2593
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8021/50000 (16.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 240.6890s / 84166.3843 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3434
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2825
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8041/50000 (16.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 240.4139s / 84406.7982 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.3454
env0_second_0:                 episode reward: 2.1500,                 loss: 0.2899
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 8061/50000 (16.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 242.1314s / 84648.9295 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.3424
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2971
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 8081/50000 (16.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 241.0055s / 84889.9351 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3482
env0_second_0:                 episode reward: 0.7500,                 loss: 0.3142
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8101/50000 (16.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.5108s / 85128.4459 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.3473
env0_second_0:                 episode reward: 4.6500,                 loss: 0.3173
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8121/50000 (16.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 240.4031s / 85368.8490 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3332
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2858
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8141/50000 (16.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 241.6829s / 85610.5318 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.3285
env0_second_0:                 episode reward: -1.4000,                 loss: 0.2927
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8161/50000 (16.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.9948s / 85849.5266 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3401
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2989
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 8181/50000 (16.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4838s / 86088.0104 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3546
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2893
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8201/50000 (16.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 239.5249s / 86327.5353 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3452
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2881
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 8221/50000 (16.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 240.4709s / 86568.0061 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3577
env0_second_0:                 episode reward: 0.4000,                 loss: 0.3032
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 8241/50000 (16.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 242.9738s / 86810.9800 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3800
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3054
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 8261/50000 (16.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 241.0933s / 87052.0733 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3555
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2883
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 8281/50000 (16.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 243.3407s / 87295.4140 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3549
env0_second_0:                 episode reward: 0.7000,                 loss: 0.3006
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8301/50000 (16.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 241.9136s / 87537.3276 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3460
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3086
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8321/50000 (16.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 241.8447s / 87779.1723 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.3729
env0_second_0:                 episode reward: -1.5500,                 loss: 0.2996
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8341/50000 (16.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 243.8805s / 88023.0528 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.3912
env0_second_0:                 episode reward: 1.4000,                 loss: 0.3092
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8361/50000 (16.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 243.0008s / 88266.0536 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.4224
env0_second_0:                 episode reward: -1.1000,                 loss: 0.3241
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 8381/50000 (16.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 240.7563s / 88506.8099 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.4072
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3150
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 8401/50000 (16.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 242.9571s / 88749.7670 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.4040
env0_second_0:                 episode reward: -2.3500,                 loss: 0.3199
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 8421/50000 (16.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 243.7732s / 88993.5402 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.4096
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3497
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 8441/50000 (16.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 242.9074s / 89236.4476 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3999
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3576
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 8461/50000 (16.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 242.6763s / 89479.1239 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.4096
env0_second_0:                 episode reward: -2.7000,                 loss: 0.3672
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8481/50000 (16.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 241.9003s / 89721.0242 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.4443
env0_second_0:                 episode reward: 1.1000,                 loss: 0.3677
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 8501/50000 (17.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 243.6956s / 89964.7198 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.4559
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4043
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8521/50000 (17.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 242.7501s / 90207.4699 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.4525
env0_second_0:                 episode reward: 0.6500,                 loss: 0.3971
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 8541/50000 (17.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 242.6327s / 90450.1026 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.4591
env0_second_0:                 episode reward: 2.2000,                 loss: 0.4087
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 8561/50000 (17.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 243.9779s / 90694.0805 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.4701
env0_second_0:                 episode reward: -1.1500,                 loss: 0.4145
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 8581/50000 (17.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 243.9944s / 90938.0748 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.4854
env0_second_0:                 episode reward: 2.9500,                 loss: 0.4424
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 8601/50000 (17.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 255.2508s / 91193.3256 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.4952
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4308
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8621/50000 (17.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 253.8161s / 91447.1417 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.4986
env0_second_0:                 episode reward: 1.2500,                 loss: 0.4194
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 8641/50000 (17.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 240.8728s / 91688.0145 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.4964
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4263
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 8661/50000 (17.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 240.4110s / 91928.4255 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.4971
env0_second_0:                 episode reward: -1.9500,                 loss: 0.4211
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 8681/50000 (17.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 240.8136s / 92169.2392 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.5294
env0_second_0:                 episode reward: 2.6500,                 loss: 0.4048
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 8701/50000 (17.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 242.1355s / 92411.3746 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.5205
env0_second_0:                 episode reward: 0.5000,                 loss: 0.4058
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 8721/50000 (17.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 241.8349s / 92653.2096 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.4979
env0_second_0:                 episode reward: 2.7500,                 loss: 0.4221
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 8741/50000 (17.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 242.2616s / 92895.4711 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.4965
env0_second_0:                 episode reward: 2.2500,                 loss: 0.4594
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 8761/50000 (17.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 241.6047s / 93137.0758 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.5114
env0_second_0:                 episode reward: 1.4500,                 loss: 0.4784
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8781/50000 (17.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 241.4824s / 93378.5582 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.5171
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4918
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8801/50000 (17.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 241.1913s / 93619.7496 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.4972
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4773
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 8821/50000 (17.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 243.1688s / 93862.9183 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.5223
env0_second_0:                 episode reward: 0.5500,                 loss: 0.4550
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 8841/50000 (17.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 245.0266s / 94107.9450 s
env0_first_0:                 episode reward: -6.7000,                 loss: 0.5487
env0_second_0:                 episode reward: 6.7000,                 loss: 0.4570
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 8861/50000 (17.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 241.4560s / 94349.4010 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.5682
env0_second_0:                 episode reward: 1.5000,                 loss: 0.4717
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8881/50000 (17.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 246.4790s / 94595.8800 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.5641
env0_second_0:                 episode reward: 2.6000,                 loss: 0.4845
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8901/50000 (17.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 247.1522s / 94843.0323 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.5561
env0_second_0:                 episode reward: 0.5500,                 loss: 0.5001
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8921/50000 (17.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 248.0202s / 95091.0525 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.5788
env0_second_0:                 episode reward: 2.7000,                 loss: 0.4896
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 8941/50000 (17.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 243.8203s / 95334.8728 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.5998
env0_second_0:                 episode reward: 1.5000,                 loss: 0.4587
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 8961/50000 (17.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 244.3373s / 95579.2101 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.5857
env0_second_0:                 episode reward: 2.3500,                 loss: 0.4908
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 8981/50000 (17.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 247.5303s / 95826.7404 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.6283
env0_second_0:                 episode reward: -1.3500,                 loss: 0.4910
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9001/50000 (18.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 246.9428s / 96073.6832 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.6526
env0_second_0:                 episode reward: 1.8500,                 loss: 0.4766
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 9021/50000 (18.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 241.5737s / 96315.2569 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.6844
env0_second_0:                 episode reward: 3.3000,                 loss: 0.4819
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9041/50000 (18.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 240.4418s / 96555.6987 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.6902
env0_second_0:                 episode reward: 3.4500,                 loss: 0.4672
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9061/50000 (18.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 240.9138s / 96796.6125 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.6672
env0_second_0:                 episode reward: 2.0000,                 loss: 0.4542
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 9081/50000 (18.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 240.3916s / 97037.0041 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.6520
env0_second_0:                 episode reward: 0.7000,                 loss: 0.4778
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 9101/50000 (18.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 241.6756s / 97278.6797 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.6392
env0_second_0:                 episode reward: 0.4500,                 loss: 0.5009
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 9121/50000 (18.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 241.1377s / 97519.8174 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.6890
env0_second_0:                 episode reward: 2.2000,                 loss: 0.4862
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 9141/50000 (18.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 242.3405s / 97762.1579 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.7399
env0_second_0:                 episode reward: -0.6000,                 loss: 0.4745
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 9161/50000 (18.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 242.0277s / 98004.1856 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.7352
env0_second_0:                 episode reward: 1.2000,                 loss: 0.4665
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 9181/50000 (18.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 240.4112s / 98244.5968 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.7723
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4666
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 9201/50000 (18.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 239.0648s / 98483.6615 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.7627
env0_second_0:                 episode reward: 0.1500,                 loss: 0.5006
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 9221/50000 (18.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.1732s / 98721.8347 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.7561
env0_second_0:                 episode reward: -1.1500,                 loss: 0.4990
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 9241/50000 (18.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 241.0722s / 98962.9069 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.7190
env0_second_0:                 episode reward: -0.6000,                 loss: 0.5185
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9261/50000 (18.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 239.8505s / 99202.7573 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.6971
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4998
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9281/50000 (18.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 240.3409s / 99443.0983 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.6625
env0_second_0:                 episode reward: -1.1000,                 loss: 0.5074
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9301/50000 (18.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 241.6758s / 99684.7740 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.6881
env0_second_0:                 episode reward: 2.6500,                 loss: 0.5135
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 9321/50000 (18.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 239.5955s / 99924.3695 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.7516
env0_second_0:                 episode reward: 0.6000,                 loss: 0.5189
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 9341/50000 (18.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 246.3271s / 100170.6967 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.7738
env0_second_0:                 episode reward: 0.4500,                 loss: 0.5409
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 9361/50000 (18.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 245.5723s / 100416.2689 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.7549
env0_second_0:                 episode reward: 1.3500,                 loss: 0.5496
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9381/50000 (18.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 246.1620s / 100662.4310 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.7995
env0_second_0:                 episode reward: 0.5500,                 loss: 0.5466
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 9401/50000 (18.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 245.6823s / 100908.1133 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.8090
env0_second_0:                 episode reward: 3.0500,                 loss: 0.5748
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 9421/50000 (18.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 244.7371s / 101152.8504 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.8252
env0_second_0:                 episode reward: 5.3500,                 loss: 0.6150
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9441/50000 (18.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 245.8476s / 101398.6980 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.8897
env0_second_0:                 episode reward: -0.8500,                 loss: 0.6131
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9461/50000 (18.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 246.5852s / 101645.2832 s
env0_first_0:                 episode reward: -5.5000,                 loss: 0.9004
env0_second_0:                 episode reward: 5.5000,                 loss: 0.6326
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 9481/50000 (18.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 244.5193s / 101889.8025 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.8686
env0_second_0:                 episode reward: 2.2000,                 loss: 0.6497
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9501/50000 (19.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 243.2361s / 102133.0387 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.8619
env0_second_0:                 episode reward: 2.0500,                 loss: 0.6496
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 9521/50000 (19.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 242.9100s / 102375.9487 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.8962
env0_second_0:                 episode reward: -0.6500,                 loss: 0.6762
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9541/50000 (19.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 241.4996s / 102617.4483 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.8872
env0_second_0:                 episode reward: 0.1500,                 loss: 0.6715
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 9561/50000 (19.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 241.8518s / 102859.3001 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.9063
env0_second_0:                 episode reward: 2.1000,                 loss: 0.7134
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 9581/50000 (19.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 243.1048s / 103102.4050 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.9486
env0_second_0:                 episode reward: 2.0500,                 loss: 0.7224
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 9601/50000 (19.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 241.5463s / 103343.9513 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.9240
env0_second_0:                 episode reward: -0.2000,                 loss: 0.7637
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 9621/50000 (19.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 239.5386s / 103583.4899 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.9697
env0_second_0:                 episode reward: 1.2500,                 loss: 0.8044
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 9641/50000 (19.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 241.1908s / 103824.6807 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.9944
env0_second_0:                 episode reward: 0.2500,                 loss: 0.8244
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 9661/50000 (19.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 242.8653s / 104067.5460 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.9521
env0_second_0:                 episode reward: -2.3000,                 loss: 0.8124
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 9681/50000 (19.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 242.7772s / 104310.3232 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.9884
env0_second_0:                 episode reward: 1.5500,                 loss: 0.8529
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 9701/50000 (19.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 242.0724s / 104552.3955 s
env0_first_0:                 episode reward: -5.6000,                 loss: 1.0052
env0_second_0:                 episode reward: 5.6000,                 loss: 0.8785
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 9721/50000 (19.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 242.7144s / 104795.1099 s
env0_first_0:                 episode reward: -2.7500,                 loss: 1.0491
env0_second_0:                 episode reward: 2.7500,                 loss: 0.8917
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 9741/50000 (19.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 246.1463s / 105041.2562 s
env0_first_0:                 episode reward: -3.8000,                 loss: 1.0973
env0_second_0:                 episode reward: 3.8000,                 loss: 0.8385
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9761/50000 (19.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 246.9471s / 105288.2034 s
env0_first_0:                 episode reward: -3.9000,                 loss: 1.1680
env0_second_0:                 episode reward: 3.9000,                 loss: 0.8407
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 9781/50000 (19.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 246.7098s / 105534.9131 s
env0_first_0:                 episode reward: 0.0500,                 loss: 1.2972
env0_second_0:                 episode reward: -0.0500,                 loss: 0.8229
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 9801/50000 (19.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 246.0158s / 105780.9289 s
env0_first_0:                 episode reward: -2.9000,                 loss: 1.3105
env0_second_0:                 episode reward: 2.9000,                 loss: 0.8416
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 9821/50000 (19.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 244.7103s / 106025.6392 s
env0_first_0:                 episode reward: -5.7000,                 loss: 1.3103
env0_second_0:                 episode reward: 5.7000,                 loss: 0.8419
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 9841/50000 (19.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 245.3496s / 106270.9888 s
env0_first_0:                 episode reward: -2.2000,                 loss: 1.3239
env0_second_0:                 episode reward: 2.2000,                 loss: 0.8594
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 9861/50000 (19.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 245.5821s / 106516.5709 s
env0_first_0:                 episode reward: -0.1500,                 loss: 1.2804
env0_second_0:                 episode reward: 0.1500,                 loss: 0.8774
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 9881/50000 (19.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 247.5690s / 106764.1399 s
env0_first_0:                 episode reward: -0.1500,                 loss: 1.2072
env0_second_0:                 episode reward: 0.1500,                 loss: 0.8595
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 9901/50000 (19.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 244.5312s / 107008.6711 s
env0_first_0:                 episode reward: 0.4500,                 loss: 1.2708
env0_second_0:                 episode reward: -0.4500,                 loss: 0.8710
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9921/50000 (19.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 247.2689s / 107255.9400 s
env0_first_0:                 episode reward: 0.3000,                 loss: 1.2307
env0_second_0:                 episode reward: -0.3000,                 loss: 0.9140
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 9941/50000 (19.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 245.0627s / 107501.0027 s
env0_first_0:                 episode reward: -3.7000,                 loss: 1.1822
env0_second_0:                 episode reward: 3.7000,                 loss: 0.9399
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 9961/50000 (19.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 244.4533s / 107745.4560 s
env0_first_0:                 episode reward: -5.4000,                 loss: 1.2398
env0_second_0:                 episode reward: 5.4000,                 loss: 0.9491
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 9981/50000 (19.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 243.5453s / 107989.0012 s
env0_first_0:                 episode reward: -3.0500,                 loss: 1.2871
env0_second_0:                 episode reward: 3.0500,                 loss: 0.9587
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 10001/50000 (20.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.9244s / 108227.9256 s
env0_first_0:                 episode reward: -4.7000,                 loss: 1.3669
env0_second_0:                 episode reward: 4.7000,                 loss: 0.9816
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 10021/50000 (20.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 247.7158s / 108475.6414 s
env0_first_0:                 episode reward: 1.7500,                 loss: 1.4030
env0_second_0:                 episode reward: -1.7500,                 loss: 1.0156
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 10041/50000 (20.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 239.6304s / 108715.2718 s
env0_first_0:                 episode reward: -8.4500,                 loss: 1.4085
env0_second_0:                 episode reward: 8.4500,                 loss: 0.9772
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 10061/50000 (20.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 239.0375s / 108954.3092 s
env0_first_0:                 episode reward: -4.7500,                 loss: 1.4487
env0_second_0:                 episode reward: 4.7500,                 loss: 0.9709
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 10081/50000 (20.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 239.1976s / 109193.5068 s
env0_first_0:                 episode reward: 1.1000,                 loss: 1.4404
env0_second_0:                 episode reward: -1.1000,                 loss: 1.0084
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 10101/50000 (20.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 234.8429s / 109428.3497 s
env0_first_0:                 episode reward: -9.9500,                 loss: 1.4537
env0_second_0:                 episode reward: 9.9500,                 loss: 1.0000
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 10121/50000 (20.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0741s / 109666.4238 s
env0_first_0:                 episode reward: -7.7500,                 loss: 1.5550
env0_second_0:                 episode reward: 7.7500,                 loss: 1.0103
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 10141/50000 (20.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 234.7013s / 109901.1251 s
env0_first_0:                 episode reward: -7.2500,                 loss: 1.6297
env0_second_0:                 episode reward: 7.2500,                 loss: 1.0393
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10161/50000 (20.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0624s / 110139.1875 s
env0_first_0:                 episode reward: -4.1500,                 loss: 1.6357
env0_second_0:                 episode reward: 4.1500,                 loss: 1.0632
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 10181/50000 (20.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2703s / 110377.4578 s
env0_first_0:                 episode reward: -4.9000,                 loss: 1.6783
env0_second_0:                 episode reward: 4.9000,                 loss: 1.0632
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 10201/50000 (20.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8543s / 110615.3121 s
env0_first_0:                 episode reward: -2.6500,                 loss: 1.6375
env0_second_0:                 episode reward: 2.6500,                 loss: 1.0569
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 10221/50000 (20.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 239.7250s / 110855.0371 s
env0_first_0:                 episode reward: -11.3500,                 loss: 1.6343
env0_second_0:                 episode reward: 11.3500,                 loss: 1.0016
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 10241/50000 (20.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.0184s / 111092.0555 s
env0_first_0:                 episode reward: -1.3500,                 loss: 1.7834
env0_second_0:                 episode reward: 1.3500,                 loss: 0.9854
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 10261/50000 (20.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9227s / 111328.9782 s
env0_first_0:                 episode reward: -3.9000,                 loss: 1.8961
env0_second_0:                 episode reward: 3.9000,                 loss: 1.1194
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 10281/50000 (20.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 240.1003s / 111569.0785 s
env0_first_0:                 episode reward: -9.6000,                 loss: 1.8348
env0_second_0:                 episode reward: 9.6000,                 loss: 1.1167
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 10301/50000 (20.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.7483s / 111807.8268 s
env0_first_0:                 episode reward: -0.4500,                 loss: 1.7627
env0_second_0:                 episode reward: 0.4500,                 loss: 1.1290
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 10321/50000 (20.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 239.6505s / 112047.4773 s
env0_first_0:                 episode reward: -2.4000,                 loss: 1.7250
env0_second_0:                 episode reward: 2.4000,                 loss: 1.1213
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 10341/50000 (20.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7928s / 112285.2701 s
env0_first_0:                 episode reward: -3.6000,                 loss: 1.8384
env0_second_0:                 episode reward: 3.6000,                 loss: 1.1251
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 10361/50000 (20.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.8356s / 112524.1058 s
env0_first_0:                 episode reward: -2.0500,                 loss: 1.8581
env0_second_0:                 episode reward: 2.0500,                 loss: 1.1851
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 10381/50000 (20.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 240.4665s / 112764.5723 s
env0_first_0:                 episode reward: -4.8000,                 loss: 1.8569
env0_second_0:                 episode reward: 4.8000,                 loss: 1.1691
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 10401/50000 (20.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.6409s / 113003.2132 s
env0_first_0:                 episode reward: -5.2000,                 loss: 1.9027
env0_second_0:                 episode reward: 5.2000,                 loss: 1.1399
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 10421/50000 (20.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 231.7514s / 113234.9646 s
env0_first_0:                 episode reward: -0.1500,                 loss: 1.9081
env0_second_0:                 episode reward: 0.1500,                 loss: 1.1497
env1_first_0:                 episode reward: -5.3000,                 loss: nan
env1_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 10441/50000 (20.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 231.6662s / 113466.6308 s
env0_first_0:                 episode reward: -4.2500,                 loss: 1.9244
env0_second_0:                 episode reward: 4.2500,                 loss: 1.1486
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10461/50000 (20.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 232.5503s / 113699.1812 s
env0_first_0:                 episode reward: -0.0500,                 loss: 1.8928
env0_second_0:                 episode reward: 0.0500,                 loss: 1.1509
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 10481/50000 (20.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 231.5116s / 113930.6928 s
env0_first_0:                 episode reward: -2.2000,                 loss: 1.9868
env0_second_0:                 episode reward: 2.2000,                 loss: 1.1313
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 10501/50000 (21.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 230.3266s / 114161.0194 s
env0_first_0:                 episode reward: -3.7500,                 loss: 1.9729
env0_second_0:                 episode reward: 3.7500,                 loss: 1.0937
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 10521/50000 (21.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 229.3968s / 114390.4162 s
env0_first_0:                 episode reward: -3.8500,                 loss: 1.9644
env0_second_0:                 episode reward: 3.8500,                 loss: 1.0928
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 10541/50000 (21.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 227.7214s / 114618.1376 s
env0_first_0:                 episode reward: -4.0500,                 loss: 2.1523
env0_second_0:                 episode reward: 4.0500,                 loss: 1.0919
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 10561/50000 (21.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 228.8907s / 114847.0284 s
env0_first_0:                 episode reward: -3.9000,                 loss: 2.2740
env0_second_0:                 episode reward: 3.9000,                 loss: 1.0917
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 10581/50000 (21.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 228.7560s / 115075.7844 s
env0_first_0:                 episode reward: -7.2500,                 loss: 2.2789
env0_second_0:                 episode reward: 7.2500,                 loss: 1.1082
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 10601/50000 (21.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 226.8990s / 115302.6834 s
env0_first_0:                 episode reward: -1.6000,                 loss: 2.3677
env0_second_0:                 episode reward: 1.6000,                 loss: 1.1111
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 10621/50000 (21.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 228.7785s / 115531.4618 s
env0_first_0:                 episode reward: -6.1500,                 loss: 2.4684
env0_second_0:                 episode reward: 6.1500,                 loss: 1.1088
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 10641/50000 (21.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 228.3289s / 115759.7908 s
env0_first_0:                 episode reward: -8.7500,                 loss: 2.5186
env0_second_0:                 episode reward: 8.7500,                 loss: 1.0907
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 10661/50000 (21.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 228.9243s / 115988.7150 s
env0_first_0:                 episode reward: -5.4000,                 loss: 2.4691
env0_second_0:                 episode reward: 5.4000,                 loss: 1.0967
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 10681/50000 (21.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 228.5191s / 116217.2342 s
env0_first_0:                 episode reward: -7.3000,                 loss: 2.5799
env0_second_0:                 episode reward: 7.3000,                 loss: 1.1304
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 10701/50000 (21.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 228.7765s / 116446.0107 s
env0_first_0:                 episode reward: -0.2000,                 loss: 2.5659
env0_second_0:                 episode reward: 0.2000,                 loss: 1.1214
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10721/50000 (21.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 229.7073s / 116675.7180 s
env0_first_0:                 episode reward: -4.8000,                 loss: 2.4734
env0_second_0:                 episode reward: 4.8000,                 loss: 1.2156
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 10741/50000 (21.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.2624s / 116908.9804 s
env0_first_0:                 episode reward: -2.7500,                 loss: 2.4512
env0_second_0:                 episode reward: 2.7500,                 loss: 1.2704
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 10761/50000 (21.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 231.5325s / 117140.5129 s
env0_first_0:                 episode reward: -2.4000,                 loss: 2.4185
env0_second_0:                 episode reward: 2.4000,                 loss: 1.2721
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 10781/50000 (21.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.5441s / 117373.0570 s
env0_first_0:                 episode reward: -3.3000,                 loss: 2.5767
env0_second_0:                 episode reward: 3.3000,                 loss: 1.2377
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 10801/50000 (21.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 229.5678s / 117602.6248 s
env0_first_0:                 episode reward: -1.5000,                 loss: 2.7118
env0_second_0:                 episode reward: 1.5000,                 loss: 1.2316
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 10821/50000 (21.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 228.7682s / 117831.3929 s
env0_first_0:                 episode reward: -4.5000,                 loss: 2.7449
env0_second_0:                 episode reward: 4.5000,                 loss: 1.2034
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 10841/50000 (21.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 229.9603s / 118061.3533 s
env0_first_0:                 episode reward: -6.5500,                 loss: 2.7489
env0_second_0:                 episode reward: 6.5500,                 loss: 1.2936
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 10861/50000 (21.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 230.1477s / 118291.5010 s
env0_first_0:                 episode reward: -2.5000,                 loss: 2.6069
env0_second_0:                 episode reward: 2.5000,                 loss: 1.3284
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 10881/50000 (21.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 227.6643s / 118519.1653 s
env0_first_0:                 episode reward: -5.5000,                 loss: 2.5502
env0_second_0:                 episode reward: 5.5000,                 loss: 1.3149
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 10901/50000 (21.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 230.7093s / 118749.8746 s
env0_first_0:                 episode reward: -0.6000,                 loss: 2.6789
env0_second_0:                 episode reward: 0.6000,                 loss: 1.3038
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 10921/50000 (21.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 228.0105s / 118977.8852 s
env0_first_0:                 episode reward: -6.2000,                 loss: 2.7118
env0_second_0:                 episode reward: 6.2000,                 loss: 1.3459
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 10941/50000 (21.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 230.9251s / 119208.8103 s
env0_first_0:                 episode reward: -4.3500,                 loss: 2.8200
env0_second_0:                 episode reward: 4.3500,                 loss: 1.3953
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 10961/50000 (21.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 231.3070s / 119440.1173 s
env0_first_0:                 episode reward: 0.3500,                 loss: 2.8863
env0_second_0:                 episode reward: -0.3500,                 loss: 1.3878
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 10981/50000 (21.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 231.3913s / 119671.5086 s
env0_first_0:                 episode reward: -4.3500,                 loss: 2.9175
env0_second_0:                 episode reward: 4.3500,                 loss: 1.3847
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 11001/50000 (22.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 228.3749s / 119899.8834 s
env0_first_0:                 episode reward: -1.2000,                 loss: 3.0351
env0_second_0:                 episode reward: 1.2000,                 loss: 1.4184
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 11021/50000 (22.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 227.1635s / 120127.0469 s
env0_first_0:                 episode reward: 0.7500,                 loss: 3.1968
env0_second_0:                 episode reward: -0.7500,                 loss: 1.4478
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 11041/50000 (22.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 230.6365s / 120357.6834 s
env0_first_0:                 episode reward: -2.8000,                 loss: 3.1573
env0_second_0:                 episode reward: 2.8000,                 loss: 1.5025
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 11061/50000 (22.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 229.8924s / 120587.5758 s
env0_first_0:                 episode reward: -2.0000,                 loss: 3.4132
env0_second_0:                 episode reward: 2.0000,                 loss: 1.4224
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 11081/50000 (22.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 228.8948s / 120816.4706 s
env0_first_0:                 episode reward: -13.6000,                 loss: 3.3797
env0_second_0:                 episode reward: 13.6000,                 loss: 1.4764
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 11101/50000 (22.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 229.7651s / 121046.2357 s
env0_first_0:                 episode reward: -13.3000,                 loss: 3.3524
env0_second_0:                 episode reward: 13.3000,                 loss: 1.5517
env1_first_0:                 episode reward: -7.6000,                 loss: nan
env1_second_0:                 episode reward: 7.6000,                 loss: nan
Episode: 11121/50000 (22.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 230.1044s / 121276.3400 s
env0_first_0:                 episode reward: -2.3500,                 loss: 3.1689
env0_second_0:                 episode reward: 2.3500,                 loss: 1.5622
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 11141/50000 (22.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 229.2729s / 121505.6130 s
env0_first_0:                 episode reward: -7.0000,                 loss: 3.1794
env0_second_0:                 episode reward: 7.0000,                 loss: 1.5048
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 11161/50000 (22.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 229.7199s / 121735.3329 s
env0_first_0:                 episode reward: -0.6500,                 loss: 3.4485
env0_second_0:                 episode reward: 0.6500,                 loss: 1.5594
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 11181/50000 (22.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 229.5947s / 121964.9276 s
env0_first_0:                 episode reward: 0.5500,                 loss: 3.5411
env0_second_0:                 episode reward: -0.5500,                 loss: 1.5033
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 11201/50000 (22.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 230.4250s / 122195.3527 s
env0_first_0:                 episode reward: -5.5500,                 loss: 3.5432
env0_second_0:                 episode reward: 5.5500,                 loss: 1.5117
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 11221/50000 (22.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 232.7091s / 122428.0618 s
env0_first_0:                 episode reward: -3.8500,                 loss: 3.5670
env0_second_0:                 episode reward: 3.8500,                 loss: 1.4736
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 11241/50000 (22.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 231.2159s / 122659.2777 s
env0_first_0:                 episode reward: -11.1000,                 loss: 3.6108
env0_second_0:                 episode reward: 11.1000,                 loss: 1.5077
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 11261/50000 (22.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 229.3424s / 122888.6201 s
env0_first_0:                 episode reward: -8.9000,                 loss: 3.6753
env0_second_0:                 episode reward: 8.9000,                 loss: 1.4518
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 11281/50000 (22.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 229.5860s / 123118.2061 s
env0_first_0:                 episode reward: 0.3500,                 loss: 3.4477
env0_second_0:                 episode reward: -0.3500,                 loss: 1.6496
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 11301/50000 (22.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 230.4795s / 123348.6855 s
env0_first_0:                 episode reward: -5.9500,                 loss: 3.3830
env0_second_0:                 episode reward: 5.9500,                 loss: 1.7073
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 11321/50000 (22.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 230.8107s / 123579.4962 s
env0_first_0:                 episode reward: -6.6000,                 loss: 3.5590
env0_second_0:                 episode reward: 6.6000,                 loss: 1.6821
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 11341/50000 (22.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 229.4673s / 123808.9636 s
env0_first_0:                 episode reward: 5.7500,                 loss: 3.6478
env0_second_0:                 episode reward: -5.7500,                 loss: 1.6769
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 11361/50000 (22.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 229.7012s / 124038.6647 s
env0_first_0:                 episode reward: -3.9500,                 loss: 3.6927
env0_second_0:                 episode reward: 3.9500,                 loss: 1.6710
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 11381/50000 (22.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 227.5684s / 124266.2331 s
env0_first_0:                 episode reward: -7.7500,                 loss: 3.7904
env0_second_0:                 episode reward: 7.7500,                 loss: 1.6460
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 11401/50000 (22.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 229.4967s / 124495.7299 s
env0_first_0:                 episode reward: -5.6000,                 loss: 3.8386
env0_second_0:                 episode reward: 5.6000,                 loss: 1.6393
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 11421/50000 (22.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 232.3249s / 124728.0547 s
env0_first_0:                 episode reward: -5.5000,                 loss: 3.9025
env0_second_0:                 episode reward: 5.5000,                 loss: 1.6793
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 11441/50000 (22.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 232.0935s / 124960.1482 s
env0_first_0:                 episode reward: -6.6000,                 loss: 4.0986
env0_second_0:                 episode reward: 6.6000,                 loss: 1.8013
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 11461/50000 (22.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 231.7249s / 125191.8731 s
env0_first_0:                 episode reward: -12.8000,                 loss: 4.3847
env0_second_0:                 episode reward: 12.8000,                 loss: 1.8650
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 11481/50000 (22.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 228.9178s / 125420.7910 s
env0_first_0:                 episode reward: -6.2500,                 loss: 4.5608
env0_second_0:                 episode reward: 6.2500,                 loss: 1.8027
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 11501/50000 (23.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 230.4360s / 125651.2270 s
env0_first_0:                 episode reward: -4.2000,                 loss: 4.3914
env0_second_0:                 episode reward: 4.2000,                 loss: 1.7811
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 11521/50000 (23.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.0695s / 125887.2965 s
env0_first_0:                 episode reward: -8.3500,                 loss: 4.4559
env0_second_0:                 episode reward: 8.3500,                 loss: 1.8128
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 11541/50000 (23.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.3446s / 126124.6411 s
env0_first_0:                 episode reward: -7.8000,                 loss: 4.6923
env0_second_0:                 episode reward: 7.8000,                 loss: 1.9471
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 11561/50000 (23.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7517s / 126362.3928 s
env0_first_0:                 episode reward: -6.2000,                 loss: 4.7095
env0_second_0:                 episode reward: 6.2000,                 loss: 1.9977
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 11581/50000 (23.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.7826s / 126599.1754 s
env0_first_0:                 episode reward: -7.1500,                 loss: 4.9069
env0_second_0:                 episode reward: 7.1500,                 loss: 2.0633
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 11601/50000 (23.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 240.1091s / 126839.2845 s
env0_first_0:                 episode reward: -5.3500,                 loss: 4.8372
env0_second_0:                 episode reward: 5.3500,                 loss: 2.1570
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 11621/50000 (23.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.4068s / 127075.6913 s
env0_first_0:                 episode reward: -3.1500,                 loss: 4.7331
env0_second_0:                 episode reward: 3.1500,                 loss: 2.2037
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 11641/50000 (23.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0881s / 127313.7794 s
env0_first_0:                 episode reward: -4.9500,                 loss: 4.6855
env0_second_0:                 episode reward: 4.9500,                 loss: 2.2177
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 11661/50000 (23.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 240.8267s / 127554.6061 s
env0_first_0:                 episode reward: -10.6000,                 loss: 4.5194
env0_second_0:                 episode reward: 10.6000,                 loss: 2.2729
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 11681/50000 (23.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1286s / 127790.7347 s
env0_first_0:                 episode reward: -10.6000,                 loss: 4.5630
env0_second_0:                 episode reward: 10.6000,                 loss: 2.4331
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 11701/50000 (23.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.6843s / 128028.4190 s
env0_first_0:                 episode reward: -6.4500,                 loss: 4.5117
env0_second_0:                 episode reward: 6.4500,                 loss: 2.3522
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 11721/50000 (23.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1157s / 128264.5347 s
env0_first_0:                 episode reward: -7.8000,                 loss: 4.5027
env0_second_0:                 episode reward: 7.8000,                 loss: 2.3876
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 11741/50000 (23.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.2306s / 128501.7653 s
env0_first_0:                 episode reward: -13.5500,                 loss: 4.4560
env0_second_0:                 episode reward: 13.5500,                 loss: 2.4432
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 11761/50000 (23.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2786s / 128740.0439 s
env0_first_0:                 episode reward: -8.1000,                 loss: 4.4089
env0_second_0:                 episode reward: 8.1000,                 loss: 2.4296
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 11781/50000 (23.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6508s / 128975.6947 s
env0_first_0:                 episode reward: -7.1500,                 loss: 4.5102
env0_second_0:                 episode reward: 7.1500,                 loss: 2.4095
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 11801/50000 (23.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.2761s / 129212.9708 s
env0_first_0:                 episode reward: -6.2500,                 loss: 4.7315
env0_second_0:                 episode reward: 6.2500,                 loss: 2.4731
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 11821/50000 (23.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.6138s / 129447.5845 s
env0_first_0:                 episode reward: -4.8500,                 loss: 4.8297
env0_second_0:                 episode reward: 4.8500,                 loss: 2.5504
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 11841/50000 (23.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6619s / 129684.2465 s
env0_first_0:                 episode reward: -4.5500,                 loss: 5.0277
env0_second_0:                 episode reward: 4.5500,                 loss: 2.5997
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 11861/50000 (23.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.7661s / 129923.0126 s
env0_first_0:                 episode reward: -7.8000,                 loss: 5.3084
env0_second_0:                 episode reward: 7.8000,                 loss: 2.5936
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 11881/50000 (23.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 239.6639s / 130162.6765 s
env0_first_0:                 episode reward: -3.7000,                 loss: 4.9957
env0_second_0:                 episode reward: 3.7000,                 loss: 2.6133
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 11901/50000 (23.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.2325s / 130399.9090 s
env0_first_0:                 episode reward: -7.3500,                 loss: 5.1019
env0_second_0:                 episode reward: 7.3500,                 loss: 2.6320
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 11921/50000 (23.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4112s / 130638.3202 s
env0_first_0:                 episode reward: -7.9000,                 loss: 5.0479
env0_second_0:                 episode reward: 7.9000,                 loss: 2.5173
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 11941/50000 (23.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 239.1947s / 130877.5149 s
env0_first_0:                 episode reward: -9.0500,                 loss: 5.3278
env0_second_0:                 episode reward: 9.0500,                 loss: 2.5410
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 11961/50000 (23.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8474s / 131115.3624 s
env0_first_0:                 episode reward: -9.8500,                 loss: 5.5017
env0_second_0:                 episode reward: 9.8500,                 loss: 2.6396
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 11981/50000 (23.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.8831s / 131352.2454 s
env0_first_0:                 episode reward: -8.8500,                 loss: 5.3705
env0_second_0:                 episode reward: 8.8500,                 loss: 2.6422
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 12001/50000 (24.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.7126s / 131590.9581 s
env0_first_0:                 episode reward: -20.4000,                 loss: 5.2300
env0_second_0:                 episode reward: 20.4000,                 loss: 2.6137
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 12021/50000 (24.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7685s / 131828.7266 s
env0_first_0:                 episode reward: -1.6000,                 loss: 4.9985
env0_second_0:                 episode reward: 1.6000,                 loss: 2.5765
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 12041/50000 (24.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 240.0067s / 132068.7333 s
env0_first_0:                 episode reward: -6.4500,                 loss: 5.3291
env0_second_0:                 episode reward: 6.4500,                 loss: 2.5474
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 12061/50000 (24.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.5347s / 132307.2681 s
env0_first_0:                 episode reward: -8.7000,                 loss: 4.9877
env0_second_0:                 episode reward: 8.7000,                 loss: 2.5680
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 12081/50000 (24.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7914s / 132545.0595 s
env0_first_0:                 episode reward: -1.1500,                 loss: 5.2174
env0_second_0:                 episode reward: 1.1500,                 loss: 2.6223
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 12101/50000 (24.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 239.4309s / 132784.4904 s
env0_first_0:                 episode reward: -10.6000,                 loss: 5.2691
env0_second_0:                 episode reward: 10.6000,                 loss: 2.7212
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 12121/50000 (24.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.1073s / 133022.5977 s
env0_first_0:                 episode reward: 0.7000,                 loss: 5.2305
env0_second_0:                 episode reward: -0.7000,                 loss: 2.7180
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 12141/50000 (24.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 239.0640s / 133261.6617 s
env0_first_0:                 episode reward: -12.0000,                 loss: 5.2045
env0_second_0:                 episode reward: 12.0000,                 loss: 2.8420
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 12161/50000 (24.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 241.6926s / 133503.3543 s
env0_first_0:                 episode reward: -8.2000,                 loss: 5.1933
env0_second_0:                 episode reward: 8.2000,                 loss: 2.7354
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 12181/50000 (24.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 240.6006s / 133743.9549 s
env0_first_0:                 episode reward: -1.8000,                 loss: 5.1623
env0_second_0:                 episode reward: 1.8000,                 loss: 2.7692
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 12201/50000 (24.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 239.9059s / 133983.8608 s
env0_first_0:                 episode reward: -9.0000,                 loss: 5.2815
env0_second_0:                 episode reward: 9.0000,                 loss: 2.8619
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12221/50000 (24.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.3244s / 134219.1852 s
env0_first_0:                 episode reward: -8.9500,                 loss: 5.2554
env0_second_0:                 episode reward: 8.9500,                 loss: 2.8201
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 12241/50000 (24.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.6631s / 134456.8483 s
env0_first_0:                 episode reward: -3.8000,                 loss: 5.3455
env0_second_0:                 episode reward: 3.8000,                 loss: 2.8262
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 12261/50000 (24.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0850s / 134694.9333 s
env0_first_0:                 episode reward: -5.1000,                 loss: 5.4916
env0_second_0:                 episode reward: 5.1000,                 loss: 2.7484
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 12281/50000 (24.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.3909s / 134933.3242 s
env0_first_0:                 episode reward: -7.0000,                 loss: 5.3990
env0_second_0:                 episode reward: 7.0000,                 loss: 2.7969
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 12301/50000 (24.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.2897s / 135170.6138 s
env0_first_0:                 episode reward: -10.0000,                 loss: 5.4112
env0_second_0:                 episode reward: 10.0000,                 loss: 2.6757
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 12321/50000 (24.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.0673s / 135406.6812 s
env0_first_0:                 episode reward: -9.1000,                 loss: 5.5648
env0_second_0:                 episode reward: 9.1000,                 loss: 2.5448
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 12341/50000 (24.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 239.6921s / 135646.3732 s
env0_first_0:                 episode reward: -10.6500,                 loss: 5.3688
env0_second_0:                 episode reward: 10.6500,                 loss: 2.4888
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 12361/50000 (24.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.9208s / 135882.2940 s
env0_first_0:                 episode reward: -7.6500,                 loss: 5.5220
env0_second_0:                 episode reward: 7.6500,                 loss: 2.5336
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 12381/50000 (24.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.8514s / 136118.1454 s
env0_first_0:                 episode reward: -7.6500,                 loss: 5.5542
env0_second_0:                 episode reward: 7.6500,                 loss: 2.5648
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 12401/50000 (24.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 240.1927s / 136358.3381 s
env0_first_0:                 episode reward: -5.1500,                 loss: 5.5689
env0_second_0:                 episode reward: 5.1500,                 loss: 2.4547
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 12421/50000 (24.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 240.7083s / 136599.0464 s
env0_first_0:                 episode reward: -10.0000,                 loss: 5.5690
env0_second_0:                 episode reward: 10.0000,                 loss: 2.5309
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 12441/50000 (24.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 240.1790s / 136839.2255 s
env0_first_0:                 episode reward: -7.4000,                 loss: 5.5289
env0_second_0:                 episode reward: 7.4000,                 loss: 2.4573
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 12461/50000 (24.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 240.3384s / 137079.5638 s
env0_first_0:                 episode reward: -0.3000,                 loss: 5.4192
env0_second_0:                 episode reward: 0.3000,                 loss: 2.4777
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 12481/50000 (24.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4592s / 137318.0230 s
env0_first_0:                 episode reward: -6.3000,                 loss: 5.5958
env0_second_0:                 episode reward: 6.3000,                 loss: 2.4814
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 12501/50000 (25.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.8008s / 137556.8238 s
env0_first_0:                 episode reward: 2.5000,                 loss: 5.8704
env0_second_0:                 episode reward: -2.5000,                 loss: 2.3668
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 12521/50000 (25.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.3337s / 137795.1576 s
env0_first_0:                 episode reward: -1.7500,                 loss: 5.5086
env0_second_0:                 episode reward: 1.7500,                 loss: 2.3207
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 12541/50000 (25.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8119s / 138032.9695 s
env0_first_0:                 episode reward: -7.7000,                 loss: 5.4383
env0_second_0:                 episode reward: 7.7000,                 loss: 2.3196
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 12561/50000 (25.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 239.9607s / 138272.9302 s
env0_first_0:                 episode reward: -4.6000,                 loss: 5.3081
env0_second_0:                 episode reward: 4.6000,                 loss: 2.4045
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12581/50000 (25.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2394s / 138511.1696 s
env0_first_0:                 episode reward: -7.2500,                 loss: 5.0968
env0_second_0:                 episode reward: 7.2500,                 loss: 2.3677
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 12601/50000 (25.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2220s / 138749.3916 s
env0_first_0:                 episode reward: -9.8500,                 loss: 5.2201
env0_second_0:                 episode reward: 9.8500,                 loss: 2.3102
env1_first_0:                 episode reward: -7.7000,                 loss: nan
env1_second_0:                 episode reward: 7.7000,                 loss: nan
Episode: 12621/50000 (25.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 240.3743s / 138989.7659 s
env0_first_0:                 episode reward: -4.7000,                 loss: 5.4432
env0_second_0:                 episode reward: 4.7000,                 loss: 2.3475
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 12641/50000 (25.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6314s / 139225.3973 s
env0_first_0:                 episode reward: -1.3500,                 loss: 5.4427
env0_second_0:                 episode reward: 1.3500,                 loss: 2.5367
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 12661/50000 (25.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 239.0801s / 139464.4774 s
env0_first_0:                 episode reward: -9.0000,                 loss: 5.8190
env0_second_0:                 episode reward: 9.0000,                 loss: 2.5122
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 12681/50000 (25.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6110s / 139701.0884 s
env0_first_0:                 episode reward: -2.2500,                 loss: 5.5946
env0_second_0:                 episode reward: 2.2500,                 loss: 2.6157
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 12701/50000 (25.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 239.3290s / 139940.4174 s
env0_first_0:                 episode reward: -8.2500,                 loss: 5.5934
env0_second_0:                 episode reward: 8.2500,                 loss: 2.7508
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 12721/50000 (25.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 239.0194s / 140179.4367 s
env0_first_0:                 episode reward: -5.8000,                 loss: 5.5566
env0_second_0:                 episode reward: 5.8000,                 loss: 2.8177
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 12741/50000 (25.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4494s / 140417.8862 s
env0_first_0:                 episode reward: -6.1000,                 loss: 5.6346
env0_second_0:                 episode reward: 6.1000,                 loss: 2.8281
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 12761/50000 (25.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.2437s / 140655.1299 s
env0_first_0:                 episode reward: 4.4000,                 loss: 5.6310
env0_second_0:                 episode reward: -4.4000,                 loss: 2.7773
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 12781/50000 (25.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.7672s / 140890.8971 s
env0_first_0:                 episode reward: -10.2500,                 loss: 5.3952
env0_second_0:                 episode reward: 10.2500,                 loss: 2.7239
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 12801/50000 (25.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.7987s / 141127.6958 s
env0_first_0:                 episode reward: -13.3500,                 loss: 5.4719
env0_second_0:                 episode reward: 13.3500,                 loss: 2.7644
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 12821/50000 (25.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.8668s / 141364.5626 s
env0_first_0:                 episode reward: -11.2500,                 loss: 5.3688
env0_second_0:                 episode reward: 11.2500,                 loss: 2.7414
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 12841/50000 (25.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.1247s / 141602.6873 s
env0_first_0:                 episode reward: -4.0500,                 loss: 5.5416
env0_second_0:                 episode reward: 4.0500,                 loss: 2.6659
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 12861/50000 (25.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2117s / 141838.8990 s
env0_first_0:                 episode reward: -15.1500,                 loss: 5.6066
env0_second_0:                 episode reward: 15.1500,                 loss: 2.7455
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 12881/50000 (25.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.5438s / 142076.4428 s
env0_first_0:                 episode reward: -2.5500,                 loss: 5.4601
env0_second_0:                 episode reward: 2.5500,                 loss: 2.6488
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 12901/50000 (25.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9864s / 142313.4293 s
env0_first_0:                 episode reward: -3.0500,                 loss: 5.4414
env0_second_0:                 episode reward: 3.0500,                 loss: 2.8149
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 12921/50000 (25.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.9450s / 142552.3743 s
env0_first_0:                 episode reward: -9.2500,                 loss: 5.7776
env0_second_0:                 episode reward: 9.2500,                 loss: 2.9865
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 12941/50000 (25.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.1511s / 142790.5254 s
env0_first_0:                 episode reward: -13.7500,                 loss: 5.6061
env0_second_0:                 episode reward: 13.7500,                 loss: 2.9730
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 12961/50000 (25.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2628s / 143026.7882 s
env0_first_0:                 episode reward: -6.4500,                 loss: 5.5566
env0_second_0:                 episode reward: 6.4500,                 loss: 3.0799
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 12981/50000 (25.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2329s / 143265.0211 s
env0_first_0:                 episode reward: -10.1500,                 loss: 5.5786
env0_second_0:                 episode reward: 10.1500,                 loss: 3.0287
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 13001/50000 (26.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.0720s / 143501.0931 s
env0_first_0:                 episode reward: -9.3500,                 loss: 5.8064
env0_second_0:                 episode reward: 9.3500,                 loss: 2.9716
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 13021/50000 (26.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.3581s / 143738.4513 s
env0_first_0:                 episode reward: -9.8000,                 loss: 5.8781
env0_second_0:                 episode reward: 9.8000,                 loss: 2.9513
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 13041/50000 (26.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.0699s / 143975.5212 s
env0_first_0:                 episode reward: -7.0000,                 loss: 5.8484
env0_second_0:                 episode reward: 7.0000,                 loss: 3.0264
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 13061/50000 (26.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.6229s / 144213.1441 s
env0_first_0:                 episode reward: -8.7500,                 loss: 6.1906
env0_second_0:                 episode reward: 8.7500,                 loss: 3.0767
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 13081/50000 (26.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.3858s / 144450.5299 s
env0_first_0:                 episode reward: -9.5500,                 loss: 6.2592
env0_second_0:                 episode reward: 9.5500,                 loss: 3.0902
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 13101/50000 (26.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8927s / 144688.4226 s
env0_first_0:                 episode reward: -9.8500,                 loss: 5.9641
env0_second_0:                 episode reward: 9.8500,                 loss: 2.9815
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 13121/50000 (26.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7800s / 144926.2026 s
env0_first_0:                 episode reward: 6.8000,                 loss: 5.8950
env0_second_0:                 episode reward: -6.8000,                 loss: 3.0600
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 13141/50000 (26.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.7044s / 145162.9069 s
env0_first_0:                 episode reward: -13.4500,                 loss: 5.9175
env0_second_0:                 episode reward: 13.4500,                 loss: 3.1890
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 13161/50000 (26.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.8758s / 145401.7828 s
env0_first_0:                 episode reward: -10.2000,                 loss: 5.9204
env0_second_0:                 episode reward: 10.2000,                 loss: 3.0914
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 13181/50000 (26.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6015s / 145638.3843 s
env0_first_0:                 episode reward: -3.8500,                 loss: 6.0128
env0_second_0:                 episode reward: 3.8500,                 loss: 3.0557
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 13201/50000 (26.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6966s / 145875.0808 s
env0_first_0:                 episode reward: -15.7000,                 loss: 5.8695
env0_second_0:                 episode reward: 15.7000,                 loss: 3.0195
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 13221/50000 (26.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.7778s / 146109.8587 s
env0_first_0:                 episode reward: -6.2000,                 loss: 5.7527
env0_second_0:                 episode reward: 6.2000,                 loss: 2.9712
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 13241/50000 (26.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.4700s / 146345.3287 s
env0_first_0:                 episode reward: -14.9500,                 loss: 5.9467
env0_second_0:                 episode reward: 14.9500,                 loss: 2.9937
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 13261/50000 (26.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.4380s / 146581.7666 s
env0_first_0:                 episode reward: -7.2500,                 loss: 5.9807
env0_second_0:                 episode reward: 7.2500,                 loss: 3.0119
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 13281/50000 (26.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.9476s / 146819.7142 s
env0_first_0:                 episode reward: -5.6500,                 loss: 5.9696
env0_second_0:                 episode reward: 5.6500,                 loss: 3.1115
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 13301/50000 (26.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.8879s / 147055.6022 s
env0_first_0:                 episode reward: -20.1000,                 loss: 6.0728
env0_second_0:                 episode reward: 20.1000,                 loss: 3.0263
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 13321/50000 (26.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6998s / 147291.3020 s
env0_first_0:                 episode reward: -10.8500,                 loss: 6.1217
env0_second_0:                 episode reward: 10.8500,                 loss: 3.1541
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 13341/50000 (26.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.5144s / 147527.8164 s
env0_first_0:                 episode reward: -1.1500,                 loss: 6.2318
env0_second_0:                 episode reward: 1.1500,                 loss: 3.1155
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 13361/50000 (26.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.3809s / 147765.1973 s
env0_first_0:                 episode reward: -14.9500,                 loss: 6.0003
env0_second_0:                 episode reward: 14.9500,                 loss: 3.0499
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Episode: 13381/50000 (26.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4231s / 148003.6204 s
env0_first_0:                 episode reward: -17.5000,                 loss: 6.1551
env0_second_0:                 episode reward: 17.5000,                 loss: 3.0242
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 13401/50000 (26.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2505s / 148239.8709 s
env0_first_0:                 episode reward: -4.6500,                 loss: 6.3192
env0_second_0:                 episode reward: 4.6500,                 loss: 2.9896
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 13421/50000 (26.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 239.0473s / 148478.9182 s
env0_first_0:                 episode reward: -18.4000,                 loss: 6.5073
env0_second_0:                 episode reward: 18.4000,                 loss: 3.1996
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 13441/50000 (26.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.9473s / 148716.8655 s
env0_first_0:                 episode reward: -15.4500,                 loss: 6.6417
env0_second_0:                 episode reward: 15.4500,                 loss: 3.1116
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 13461/50000 (26.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.3008s / 148953.1663 s
env0_first_0:                 episode reward: -10.4000,                 loss: 6.4195
env0_second_0:                 episode reward: 10.4000,                 loss: 3.1162
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 13481/50000 (26.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1526s / 149189.3189 s
env0_first_0:                 episode reward: -8.0500,                 loss: 6.4471
env0_second_0:                 episode reward: 8.0500,                 loss: 3.1498
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 13501/50000 (27.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.3700s / 149425.6890 s
env0_first_0:                 episode reward: -10.8500,                 loss: 6.7889
env0_second_0:                 episode reward: 10.8500,                 loss: 3.2499
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 13521/50000 (27.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9455s / 149662.6345 s
env0_first_0:                 episode reward: -4.4000,                 loss: 6.6984
env0_second_0:                 episode reward: 4.4000,                 loss: 3.3747
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 13541/50000 (27.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2881s / 149898.9226 s
env0_first_0:                 episode reward: -12.9000,                 loss: 6.5145
env0_second_0:                 episode reward: 12.9000,                 loss: 3.2349
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 13561/50000 (27.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.1873s / 150134.1099 s
env0_first_0:                 episode reward: -15.3000,                 loss: 6.3585
env0_second_0:                 episode reward: 15.3000,                 loss: 3.3610
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 13581/50000 (27.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.6000s / 150372.7099 s
env0_first_0:                 episode reward: -15.1000,                 loss: 6.5631
env0_second_0:                 episode reward: 15.1000,                 loss: 3.4521
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 13601/50000 (27.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.9680s / 150611.6779 s
env0_first_0:                 episode reward: -6.2500,                 loss: 6.3473
env0_second_0:                 episode reward: 6.2500,                 loss: 3.2681
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 13621/50000 (27.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2300s / 150849.9079 s
env0_first_0:                 episode reward: -8.2000,                 loss: 5.8866
env0_second_0:                 episode reward: 8.2000,                 loss: 3.1513
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 13641/50000 (27.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 239.0826s / 151088.9906 s
env0_first_0:                 episode reward: -12.2000,                 loss: 6.1898
env0_second_0:                 episode reward: 12.2000,                 loss: 3.2236
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 13661/50000 (27.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.3920s / 151327.3825 s
env0_first_0:                 episode reward: -4.9500,                 loss: 5.8793
env0_second_0:                 episode reward: 4.9500,                 loss: 3.3336
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 13681/50000 (27.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.7544s / 151566.1369 s
env0_first_0:                 episode reward: -8.1500,                 loss: 5.9054
env0_second_0:                 episode reward: 8.1500,                 loss: 3.3741
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 13701/50000 (27.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.5159s / 151804.6528 s
env0_first_0:                 episode reward: -2.0500,                 loss: 6.0335
env0_second_0:                 episode reward: 2.0500,                 loss: 3.4062
env1_first_0:                 episode reward: -8.5500,                 loss: nan
env1_second_0:                 episode reward: 8.5500,                 loss: nan
Episode: 13721/50000 (27.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.1353s / 152041.7881 s
env0_first_0:                 episode reward: -14.8000,                 loss: 6.1541
env0_second_0:                 episode reward: 14.8000,                 loss: 3.3781
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 13741/50000 (27.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.2985s / 152277.0866 s
env0_first_0:                 episode reward: -7.4000,                 loss: 6.0955
env0_second_0:                 episode reward: 7.4000,                 loss: 3.5262
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 13761/50000 (27.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0858s / 152515.1725 s
env0_first_0:                 episode reward: -2.1000,                 loss: 6.1438
env0_second_0:                 episode reward: 2.1000,                 loss: 3.7116
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 13781/50000 (27.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.5555s / 152752.7280 s
env0_first_0:                 episode reward: -10.4500,                 loss: 6.0810
env0_second_0:                 episode reward: 10.4500,                 loss: 3.6388
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 13801/50000 (27.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 234.4480s / 152987.1760 s
env0_first_0:                 episode reward: -16.3500,                 loss: 5.8671
env0_second_0:                 episode reward: 16.3500,                 loss: 3.7526
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 13821/50000 (27.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.2639s / 153222.4399 s
env0_first_0:                 episode reward: -1.4500,                 loss: 6.1349
env0_second_0:                 episode reward: 1.4500,                 loss: 3.6853
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 13841/50000 (27.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9337s / 153459.3736 s
env0_first_0:                 episode reward: -8.2000,                 loss: 6.4337
env0_second_0:                 episode reward: 8.2000,                 loss: 3.6187
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 13861/50000 (27.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.3919s / 153696.7654 s
env0_first_0:                 episode reward: -18.3000,                 loss: 6.4519
env0_second_0:                 episode reward: 18.3000,                 loss: 3.5780
env1_first_0:                 episode reward: -16.5500,                 loss: nan
env1_second_0:                 episode reward: 16.5500,                 loss: nan
Episode: 13881/50000 (27.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 234.7097s / 153931.4752 s
env0_first_0:                 episode reward: -12.1500,                 loss: 6.3782
env0_second_0:                 episode reward: 12.1500,                 loss: 3.7997
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 13901/50000 (27.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8153s / 154169.2905 s
env0_first_0:                 episode reward: -14.0500,                 loss: 6.4590
env0_second_0:                 episode reward: 14.0500,                 loss: 3.8306
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 13921/50000 (27.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.4628s / 154405.7533 s
env0_first_0:                 episode reward: -5.4500,                 loss: 6.2653
env0_second_0:                 episode reward: 5.4500,                 loss: 3.6763
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 13941/50000 (27.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.3235s / 154642.0768 s
env0_first_0:                 episode reward: -8.6500,                 loss: 6.0902
env0_second_0:                 episode reward: 8.6500,                 loss: 3.8508
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 13961/50000 (27.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9355s / 154879.0123 s
env0_first_0:                 episode reward: -7.6500,                 loss: 6.1794
env0_second_0:                 episode reward: 7.6500,                 loss: 3.9045
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 13981/50000 (27.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7101s / 155116.7224 s
env0_first_0:                 episode reward: -11.5000,                 loss: 6.3241
env0_second_0:                 episode reward: 11.5000,                 loss: 3.8029
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 14001/50000 (28.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.3207s / 155354.0431 s
env0_first_0:                 episode reward: -9.2000,                 loss: 6.2435
env0_second_0:                 episode reward: 9.2000,                 loss: 3.6569
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 14021/50000 (28.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.5017s / 155590.5448 s
env0_first_0:                 episode reward: -16.8000,                 loss: 6.0335
env0_second_0:                 episode reward: 16.8000,                 loss: 3.6718
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 14041/50000 (28.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2876s / 155826.8324 s
env0_first_0:                 episode reward: -18.7500,                 loss: 5.9098
env0_second_0:                 episode reward: 18.7500,                 loss: 3.7129
env1_first_0:                 episode reward: -23.2500,                 loss: nan
env1_second_0:                 episode reward: 23.2500,                 loss: nan
Episode: 14061/50000 (28.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.6030s / 156064.4354 s
env0_first_0:                 episode reward: -12.9000,                 loss: 6.0486
env0_second_0:                 episode reward: 12.9000,                 loss: 3.8274
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 14081/50000 (28.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 239.1247s / 156303.5601 s
env0_first_0:                 episode reward: -9.6000,                 loss: 6.1326
env0_second_0:                 episode reward: 9.6000,                 loss: 3.7260
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 14101/50000 (28.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2809s / 156539.8410 s
env0_first_0:                 episode reward: -14.2500,                 loss: 6.0233
env0_second_0:                 episode reward: 14.2500,                 loss: 3.9000
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 14121/50000 (28.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2171s / 156776.0581 s
env0_first_0:                 episode reward: -10.3000,                 loss: 6.2252
env0_second_0:                 episode reward: 10.3000,                 loss: 3.9777
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 14141/50000 (28.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9814s / 157013.0395 s
env0_first_0:                 episode reward: -22.4000,                 loss: 6.2179
env0_second_0:                 episode reward: 22.4000,                 loss: 3.9197
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 14161/50000 (28.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.2534s / 157250.2929 s
env0_first_0:                 episode reward: -12.7500,                 loss: 6.2438
env0_second_0:                 episode reward: 12.7500,                 loss: 3.9763
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 14181/50000 (28.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.5665s / 157485.8594 s
env0_first_0:                 episode reward: -10.3000,                 loss: 6.4137
env0_second_0:                 episode reward: 10.3000,                 loss: 4.1490
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 14201/50000 (28.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1153s / 157721.9747 s
env0_first_0:                 episode reward: -12.1500,                 loss: 6.1875
env0_second_0:                 episode reward: 12.1500,                 loss: 4.0332
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 14221/50000 (28.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.8854s / 157956.8601 s
env0_first_0:                 episode reward: -8.4000,                 loss: 6.2589
env0_second_0:                 episode reward: 8.4000,                 loss: 3.9764
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 14241/50000 (28.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 234.3616s / 158191.2217 s
env0_first_0:                 episode reward: -5.6500,                 loss: 6.5875
env0_second_0:                 episode reward: 5.6500,                 loss: 3.9643
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 14261/50000 (28.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7455s / 158428.9672 s
env0_first_0:                 episode reward: -10.7000,                 loss: 7.1099
env0_second_0:                 episode reward: 10.7000,                 loss: 3.8913
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 14281/50000 (28.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8899s / 158666.8571 s
env0_first_0:                 episode reward: -13.0500,                 loss: 7.1470
env0_second_0:                 episode reward: 13.0500,                 loss: 3.9281
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 14301/50000 (28.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.7849s / 158902.6421 s
env0_first_0:                 episode reward: -7.0000,                 loss: 7.2064
env0_second_0:                 episode reward: 7.0000,                 loss: 3.9057
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 14321/50000 (28.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.1425s / 159140.7846 s
env0_first_0:                 episode reward: -6.2500,                 loss: 7.0429
env0_second_0:                 episode reward: 6.2500,                 loss: 3.9885
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 14341/50000 (28.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.5348s / 159377.3194 s
env0_first_0:                 episode reward: -13.3000,                 loss: 6.9601
env0_second_0:                 episode reward: 13.3000,                 loss: 3.8942
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 14361/50000 (28.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.8020s / 159614.1213 s
env0_first_0:                 episode reward: -9.3000,                 loss: 7.2177
env0_second_0:                 episode reward: 9.3000,                 loss: 4.1642
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 14381/50000 (28.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.7772s / 159850.8986 s
env0_first_0:                 episode reward: -11.1000,                 loss: 7.2291
env0_second_0:                 episode reward: 11.1000,                 loss: 4.1033
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 14401/50000 (28.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6844s / 160086.5829 s
env0_first_0:                 episode reward: -9.4000,                 loss: 7.2376
env0_second_0:                 episode reward: 9.4000,                 loss: 3.8282
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 14421/50000 (28.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.7320s / 160321.3150 s
env0_first_0:                 episode reward: -4.3000,                 loss: 7.2845
env0_second_0:                 episode reward: 4.3000,                 loss: 3.7381
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 14441/50000 (28.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.9366s / 160560.2516 s
env0_first_0:                 episode reward: -9.7500,                 loss: 7.6529
env0_second_0:                 episode reward: 9.7500,                 loss: 3.6157
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 14461/50000 (28.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.1692s / 160798.4207 s
env0_first_0:                 episode reward: -13.9500,                 loss: 7.5478
env0_second_0:                 episode reward: 13.9500,                 loss: 3.6502
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 14481/50000 (28.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7738s / 161036.1945 s
env0_first_0:                 episode reward: -2.2500,                 loss: 7.6317
env0_second_0:                 episode reward: 2.2500,                 loss: 3.7399
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 14501/50000 (29.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 234.5156s / 161270.7101 s
env0_first_0:                 episode reward: 0.1000,                 loss: 7.7226
env0_second_0:                 episode reward: -0.1000,                 loss: 3.7826
env1_first_0:                 episode reward: -10.7000,                 loss: nan
env1_second_0:                 episode reward: 10.7000,                 loss: nan
Episode: 14521/50000 (29.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4643s / 161509.1744 s
env0_first_0:                 episode reward: -10.6000,                 loss: 7.9078
env0_second_0:                 episode reward: 10.6000,                 loss: 3.7782
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 14541/50000 (29.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 234.9130s / 161744.0875 s
env0_first_0:                 episode reward: -7.5500,                 loss: 8.0856
env0_second_0:                 episode reward: 7.5500,                 loss: 3.8000
env1_first_0:                 episode reward: -18.6500,                 loss: nan
env1_second_0:                 episode reward: 18.6500,                 loss: nan
Episode: 14561/50000 (29.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1508s / 161980.2382 s
env0_first_0:                 episode reward: -13.1500,                 loss: 8.1446
env0_second_0:                 episode reward: 13.1500,                 loss: 4.0811
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 14581/50000 (29.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2477s / 162216.4859 s
env0_first_0:                 episode reward: -16.6500,                 loss: 8.3678
env0_second_0:                 episode reward: 16.6500,                 loss: 4.0063
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 14601/50000 (29.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.3222s / 162452.8081 s
env0_first_0:                 episode reward: -8.4000,                 loss: 8.4068
env0_second_0:                 episode reward: 8.4000,                 loss: 3.9945
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 14621/50000 (29.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.8675s / 162687.6756 s
env0_first_0:                 episode reward: -20.4000,                 loss: 8.8773
env0_second_0:                 episode reward: 20.4000,                 loss: 3.8226
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 14641/50000 (29.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 234.6704s / 162922.3460 s
env0_first_0:                 episode reward: -11.2500,                 loss: 8.8927
env0_second_0:                 episode reward: 11.2500,                 loss: 3.9790
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 14661/50000 (29.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.1762s / 163157.5222 s
env0_first_0:                 episode reward: -10.8500,                 loss: 8.3050
env0_second_0:                 episode reward: 10.8500,                 loss: 4.0076
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 14681/50000 (29.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9037s / 163394.4259 s
env0_first_0:                 episode reward: -15.2500,                 loss: 8.4727
env0_second_0:                 episode reward: 15.2500,                 loss: 4.0280
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 14701/50000 (29.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1841s / 163630.6100 s
env0_first_0:                 episode reward: -9.2000,                 loss: 8.0710
env0_second_0:                 episode reward: 9.2000,                 loss: 4.0390
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 14721/50000 (29.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4408s / 163869.0508 s
env0_first_0:                 episode reward: -18.0500,                 loss: 8.2412
env0_second_0:                 episode reward: 18.0500,                 loss: 4.0797
env1_first_0:                 episode reward: -21.9500,                 loss: nan
env1_second_0:                 episode reward: 21.9500,                 loss: nan
Episode: 14741/50000 (29.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 241.1129s / 164110.1638 s
env0_first_0:                 episode reward: -2.8500,                 loss: 8.1783
env0_second_0:                 episode reward: 2.8500,                 loss: 3.9026
env1_first_0:                 episode reward: -16.7500,                 loss: nan
env1_second_0:                 episode reward: 16.7500,                 loss: nan
Episode: 14761/50000 (29.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.3719s / 164348.5357 s
env0_first_0:                 episode reward: -9.9000,                 loss: 7.8011
env0_second_0:                 episode reward: 9.9000,                 loss: 4.0436
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 14781/50000 (29.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8864s / 164586.4221 s
env0_first_0:                 episode reward: -12.5500,                 loss: 8.0860
env0_second_0:                 episode reward: 12.5500,                 loss: 3.8714
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 14801/50000 (29.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.4921s / 164822.9142 s
env0_first_0:                 episode reward: -15.9000,                 loss: 8.2476
env0_second_0:                 episode reward: 15.9000,                 loss: 3.7976
env1_first_0:                 episode reward: -19.6500,                 loss: nan
env1_second_0:                 episode reward: 19.6500,                 loss: nan
Episode: 14821/50000 (29.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6144s / 165059.5286 s
env0_first_0:                 episode reward: -16.3500,                 loss: 7.8421
env0_second_0:                 episode reward: 16.3500,                 loss: 3.7363
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 14841/50000 (29.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0893s / 165297.6179 s
env0_first_0:                 episode reward: -9.6000,                 loss: 7.4997
env0_second_0:                 episode reward: 9.6000,                 loss: 3.8040
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 14861/50000 (29.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.4134s / 165533.0314 s
env0_first_0:                 episode reward: -8.9500,                 loss: 7.6492
env0_second_0:                 episode reward: 8.9500,                 loss: 3.8274
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 14881/50000 (29.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.9986s / 165766.0300 s
env0_first_0:                 episode reward: -13.6500,                 loss: 7.9994
env0_second_0:                 episode reward: 13.6500,                 loss: 3.8705
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 14901/50000 (29.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.4586s / 166002.4886 s
env0_first_0:                 episode reward: -18.3500,                 loss: 7.7695
env0_second_0:                 episode reward: 18.3500,                 loss: 3.8571
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 14921/50000 (29.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.4115s / 166237.9001 s
env0_first_0:                 episode reward: -24.4000,                 loss: 7.7236
env0_second_0:                 episode reward: 24.4000,                 loss: 3.8873
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 14941/50000 (29.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.7343s / 166473.6344 s
env0_first_0:                 episode reward: -10.7500,                 loss: 8.0636
env0_second_0:                 episode reward: 10.7500,                 loss: 3.8369
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 14961/50000 (29.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.3493s / 166708.9837 s
env0_first_0:                 episode reward: -14.8000,                 loss: 7.8830
env0_second_0:                 episode reward: 14.8000,                 loss: 4.0430
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 14981/50000 (29.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.7263s / 166947.7100 s
env0_first_0:                 episode reward: -6.2500,                 loss: 7.5483
env0_second_0:                 episode reward: 6.2500,                 loss: 3.8409
env1_first_0:                 episode reward: -17.3000,                 loss: nan
env1_second_0:                 episode reward: 17.3000,                 loss: nan
Episode: 15001/50000 (30.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.8761s / 167184.5861 s
env0_first_0:                 episode reward: -8.1000,                 loss: 7.4408
env0_second_0:                 episode reward: 8.1000,                 loss: 4.0549
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 15021/50000 (30.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 239.5379s / 167424.1239 s
env0_first_0:                 episode reward: -17.5500,                 loss: 7.2709
env0_second_0:                 episode reward: 17.5500,                 loss: 4.1468
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 15041/50000 (30.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7219s / 167661.8459 s
env0_first_0:                 episode reward: -14.8500,                 loss: 7.3060
env0_second_0:                 episode reward: 14.8500,                 loss: 4.1855
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 15061/50000 (30.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.3798s / 167900.2257 s
env0_first_0:                 episode reward: -6.0000,                 loss: 7.2333
env0_second_0:                 episode reward: 6.0000,                 loss: 3.9332
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 15081/50000 (30.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.1318s / 168137.3575 s
env0_first_0:                 episode reward: -17.6500,                 loss: 7.4544
env0_second_0:                 episode reward: 17.6500,                 loss: 3.8354
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 15101/50000 (30.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 239.7927s / 168377.1501 s
env0_first_0:                 episode reward: -16.3000,                 loss: 7.5554
env0_second_0:                 episode reward: 16.3000,                 loss: 3.8690
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 15121/50000 (30.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 239.7727s / 168616.9228 s
env0_first_0:                 episode reward: -8.3500,                 loss: 7.4565
env0_second_0:                 episode reward: 8.3500,                 loss: 4.0608
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 15141/50000 (30.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 240.5389s / 168857.4617 s
env0_first_0:                 episode reward: -12.8500,                 loss: 7.3931
env0_second_0:                 episode reward: 12.8500,                 loss: 4.1629
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 15161/50000 (30.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 240.5775s / 169098.0392 s
env0_first_0:                 episode reward: -16.3000,                 loss: 7.5436
env0_second_0:                 episode reward: 16.3000,                 loss: 4.2104
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 15181/50000 (30.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 241.1924s / 169339.2316 s
env0_first_0:                 episode reward: -19.2500,                 loss: 7.3873
env0_second_0:                 episode reward: 19.2500,                 loss: 4.2239
env1_first_0:                 episode reward: -23.3000,                 loss: nan
env1_second_0:                 episode reward: 23.3000,                 loss: nan
Episode: 15201/50000 (30.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.9003s / 169578.1320 s
env0_first_0:                 episode reward: -9.9500,                 loss: 7.3880
env0_second_0:                 episode reward: 9.9500,                 loss: 4.0625
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 15221/50000 (30.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0871s / 169816.2191 s
env0_first_0:                 episode reward: -8.8500,                 loss: 7.5034
env0_second_0:                 episode reward: 8.8500,                 loss: 3.8792
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 15241/50000 (30.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.4353s / 170053.6544 s
env0_first_0:                 episode reward: -10.3000,                 loss: 7.3753
env0_second_0:                 episode reward: 10.3000,                 loss: 3.9267
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 15261/50000 (30.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 239.9037s / 170293.5581 s
env0_first_0:                 episode reward: -7.6500,                 loss: 7.4559
env0_second_0:                 episode reward: 7.6500,                 loss: 3.8196
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 15281/50000 (30.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 241.7987s / 170535.3567 s
env0_first_0:                 episode reward: -9.7500,                 loss: 7.8589
env0_second_0:                 episode reward: 9.7500,                 loss: 3.7859
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 15301/50000 (30.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 239.8606s / 170775.2173 s
env0_first_0:                 episode reward: -9.7000,                 loss: 7.5266
env0_second_0:                 episode reward: 9.7000,                 loss: 3.6917
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 15321/50000 (30.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2424s / 171013.4596 s
env0_first_0:                 episode reward: -2.2500,                 loss: 7.9133
env0_second_0:                 episode reward: 2.2500,                 loss: 3.8413
env1_first_0:                 episode reward: -16.5500,                 loss: nan
env1_second_0:                 episode reward: 16.5500,                 loss: nan
Episode: 15341/50000 (30.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.9840s / 171251.4436 s
env0_first_0:                 episode reward: -18.1000,                 loss: 7.8651
env0_second_0:                 episode reward: 18.1000,                 loss: 4.0329
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 15361/50000 (30.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4672s / 171489.9108 s
env0_first_0:                 episode reward: -12.0000,                 loss: 7.7989
env0_second_0:                 episode reward: 12.0000,                 loss: 4.0961
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 15381/50000 (30.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.4902s / 171727.4010 s
env0_first_0:                 episode reward: -3.7500,                 loss: 8.0031
env0_second_0:                 episode reward: 3.7500,                 loss: 4.1250
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 15401/50000 (30.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.2494s / 171964.6505 s
env0_first_0:                 episode reward: -25.3500,                 loss: 7.8692
env0_second_0:                 episode reward: 25.3500,                 loss: 4.1167
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 15421/50000 (30.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4146s / 172203.0650 s
env0_first_0:                 episode reward: 3.5500,                 loss: 7.5581
env0_second_0:                 episode reward: -3.5500,                 loss: 4.2732
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 15441/50000 (30.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 240.6012s / 172443.6662 s
env0_first_0:                 episode reward: -16.4500,                 loss: 7.3319
env0_second_0:                 episode reward: 16.4500,                 loss: 4.1636
env1_first_0:                 episode reward: -18.9000,                 loss: nan
env1_second_0:                 episode reward: 18.9000,                 loss: nan
Episode: 15461/50000 (30.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2927s / 172681.9590 s
env0_first_0:                 episode reward: -18.3000,                 loss: 7.5629
env0_second_0:                 episode reward: 18.3000,                 loss: 4.3391
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 15481/50000 (30.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.7605s / 172918.7195 s
env0_first_0:                 episode reward: -16.4500,                 loss: 7.5305
env0_second_0:                 episode reward: 16.4500,                 loss: 4.3372
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 15501/50000 (31.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2017s / 173154.9212 s
env0_first_0:                 episode reward: -22.2500,                 loss: 7.5314
env0_second_0:                 episode reward: 22.2500,                 loss: 4.3508
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 15521/50000 (31.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.0742s / 173390.9954 s
env0_first_0:                 episode reward: 0.0000,                 loss: 7.4380
env0_second_0:                 episode reward: 0.0000,                 loss: 4.3327
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 15541/50000 (31.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.4912s / 173626.4866 s
env0_first_0:                 episode reward: -18.0000,                 loss: 7.2187
env0_second_0:                 episode reward: 18.0000,                 loss: 4.2102
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 15561/50000 (31.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2528s / 173864.7394 s
env0_first_0:                 episode reward: -22.5000,                 loss: 7.0361
env0_second_0:                 episode reward: 22.5000,                 loss: 4.2021
env1_first_0:                 episode reward: -6.9500,                 loss: nan
env1_second_0:                 episode reward: 6.9500,                 loss: nan
Episode: 15581/50000 (31.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.5415s / 174102.2809 s
env0_first_0:                 episode reward: -12.9000,                 loss: 7.2432
env0_second_0:                 episode reward: 12.9000,                 loss: 4.1108
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 15601/50000 (31.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0540s / 174340.3349 s
env0_first_0:                 episode reward: -22.0500,                 loss: 7.5549
env0_second_0:                 episode reward: 22.0500,                 loss: 4.0097
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 15621/50000 (31.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6973s / 174576.0321 s
env0_first_0:                 episode reward: -3.3000,                 loss: 7.6707
env0_second_0:                 episode reward: 3.3000,                 loss: 3.8994
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 15641/50000 (31.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2753s / 174814.3074 s
env0_first_0:                 episode reward: -6.4500,                 loss: 7.6628
env0_second_0:                 episode reward: 6.4500,                 loss: 4.0179
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 15661/50000 (31.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.1012s / 175052.4086 s
env0_first_0:                 episode reward: -11.8000,                 loss: 7.9744
env0_second_0:                 episode reward: 11.8000,                 loss: 4.0747
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 15681/50000 (31.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.1177s / 175289.5263 s
env0_first_0:                 episode reward: 4.6500,                 loss: 7.4287
env0_second_0:                 episode reward: -4.6500,                 loss: 4.1708
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 15701/50000 (31.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8111s / 175527.3375 s
env0_first_0:                 episode reward: -10.0000,                 loss: 7.5210
env0_second_0:                 episode reward: 10.0000,                 loss: 4.1604
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 15721/50000 (31.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.9132s / 175763.2507 s
env0_first_0:                 episode reward: -9.0000,                 loss: 7.4386
env0_second_0:                 episode reward: 9.0000,                 loss: 4.1565
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 15741/50000 (31.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4113s / 176001.6619 s
env0_first_0:                 episode reward: -6.7000,                 loss: 7.1362
env0_second_0:                 episode reward: 6.7000,                 loss: 4.2067
env1_first_0:                 episode reward: -18.1500,                 loss: nan
env1_second_0:                 episode reward: 18.1500,                 loss: nan
Episode: 15761/50000 (31.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.9465s / 176240.6084 s
env0_first_0:                 episode reward: -20.5500,                 loss: 7.0872
env0_second_0:                 episode reward: 20.5500,                 loss: 4.3446
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 15781/50000 (31.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8488s / 176478.4573 s
env0_first_0:                 episode reward: -5.2000,                 loss: 7.2759
env0_second_0:                 episode reward: 5.2000,                 loss: 4.2076
env1_first_0:                 episode reward: -19.4500,                 loss: nan
env1_second_0:                 episode reward: 19.4500,                 loss: nan
Episode: 15801/50000 (31.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9930s / 176715.4503 s
env0_first_0:                 episode reward: -10.7500,                 loss: 7.5030
env0_second_0:                 episode reward: 10.7500,                 loss: 4.2613
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 15821/50000 (31.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2653s / 176953.7156 s
env0_first_0:                 episode reward: -12.9500,                 loss: 7.4898
env0_second_0:                 episode reward: 12.9500,                 loss: 4.1078
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 15841/50000 (31.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.5363s / 177191.2518 s
env0_first_0:                 episode reward: -20.3500,                 loss: 8.1645
env0_second_0:                 episode reward: 20.3500,                 loss: 4.0868
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 15861/50000 (31.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 239.8522s / 177431.1040 s
env0_first_0:                 episode reward: -20.9500,                 loss: 8.2585
env0_second_0:                 episode reward: 20.9500,                 loss: 4.1712
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 15881/50000 (31.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 239.6595s / 177670.7635 s
env0_first_0:                 episode reward: -19.1000,                 loss: 8.1352
env0_second_0:                 episode reward: 19.1000,                 loss: 4.1426
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 15901/50000 (31.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.0279s / 177906.7914 s
env0_first_0:                 episode reward: -6.4000,                 loss: 8.2692
env0_second_0:                 episode reward: 6.4000,                 loss: 4.3089
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 15921/50000 (31.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8213s / 178144.6127 s
env0_first_0:                 episode reward: -13.5000,                 loss: 7.9653
env0_second_0:                 episode reward: 13.5000,                 loss: 4.2315
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 15941/50000 (31.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.2383s / 178379.8510 s
env0_first_0:                 episode reward: -13.5500,                 loss: 8.1969
env0_second_0:                 episode reward: 13.5500,                 loss: 4.3649
env1_first_0:                 episode reward: -30.3000,                 loss: nan
env1_second_0:                 episode reward: 30.3000,                 loss: nan
Episode: 15961/50000 (31.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0428s / 178617.8938 s
env0_first_0:                 episode reward: -12.6000,                 loss: 8.5042
env0_second_0:                 episode reward: 12.6000,                 loss: 4.4771
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 15981/50000 (31.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.7025s / 178853.5963 s
env0_first_0:                 episode reward: -18.6500,                 loss: 8.3444
env0_second_0:                 episode reward: 18.6500,                 loss: 4.6012
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 16001/50000 (32.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.4978s / 179090.0941 s
env0_first_0:                 episode reward: -22.4000,                 loss: 8.1219
env0_second_0:                 episode reward: 22.4000,                 loss: 4.5402
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 16021/50000 (32.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.4857s / 179325.5798 s
env0_first_0:                 episode reward: -25.0000,                 loss: 8.1567
env0_second_0:                 episode reward: 25.0000,                 loss: 4.4209
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 16041/50000 (32.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.7747s / 179561.3545 s
env0_first_0:                 episode reward: -16.8000,                 loss: 8.3958
env0_second_0:                 episode reward: 16.8000,                 loss: 4.3488
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 16061/50000 (32.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 234.7968s / 179796.1514 s
env0_first_0:                 episode reward: -0.4500,                 loss: 8.4842
env0_second_0:                 episode reward: 0.4500,                 loss: 4.1904
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 16081/50000 (32.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0362s / 180034.1875 s
env0_first_0:                 episode reward: -17.3000,                 loss: 8.4281
env0_second_0:                 episode reward: 17.3000,                 loss: 4.1176
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 16101/50000 (32.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.7446s / 180272.9321 s
env0_first_0:                 episode reward: -8.4500,                 loss: 8.7203
env0_second_0:                 episode reward: 8.4500,                 loss: 4.1567
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 16121/50000 (32.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.3983s / 180511.3304 s
env0_first_0:                 episode reward: -14.4000,                 loss: 8.1885
env0_second_0:                 episode reward: 14.4000,                 loss: 4.1947
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 16141/50000 (32.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.7620s / 180750.0924 s
env0_first_0:                 episode reward: -3.7000,                 loss: 7.9289
env0_second_0:                 episode reward: 3.7000,                 loss: 4.1647
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 16161/50000 (32.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 239.2333s / 180989.3258 s
env0_first_0:                 episode reward: -12.7500,                 loss: 7.9371
env0_second_0:                 episode reward: 12.7500,                 loss: 4.2886
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 16181/50000 (32.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.5876s / 181224.9134 s
env0_first_0:                 episode reward: -16.2000,                 loss: 7.5811
env0_second_0:                 episode reward: 16.2000,                 loss: 4.3609
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 16201/50000 (32.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9457s / 181461.8591 s
env0_first_0:                 episode reward: -16.5000,                 loss: 7.8412
env0_second_0:                 episode reward: 16.5000,                 loss: 4.2397
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 16221/50000 (32.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.9528s / 181699.8119 s
env0_first_0:                 episode reward: -24.6000,                 loss: 8.4574
env0_second_0:                 episode reward: 24.6000,                 loss: 4.2543
env1_first_0:                 episode reward: -20.2000,                 loss: nan
env1_second_0:                 episode reward: 20.2000,                 loss: nan
Episode: 16241/50000 (32.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.1976s / 181938.0094 s
env0_first_0:                 episode reward: -5.7500,                 loss: 8.3027
env0_second_0:                 episode reward: 5.7500,                 loss: 4.3937
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 16261/50000 (32.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.4024s / 182174.4118 s
env0_first_0:                 episode reward: -19.4500,                 loss: 8.2960
env0_second_0:                 episode reward: 19.4500,                 loss: 4.2501
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 16281/50000 (32.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.9014s / 182410.3132 s
env0_first_0:                 episode reward: -16.5000,                 loss: 8.3408
env0_second_0:                 episode reward: 16.5000,                 loss: 4.4164
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 16301/50000 (32.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6432s / 182646.9565 s
env0_first_0:                 episode reward: -9.9000,                 loss: 8.4880
env0_second_0:                 episode reward: 9.9000,                 loss: 4.1670
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 16321/50000 (32.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6471s / 182883.6035 s
env0_first_0:                 episode reward: -21.3000,                 loss: 8.6183
env0_second_0:                 episode reward: 21.3000,                 loss: 4.1178
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 16341/50000 (32.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 240.0011s / 183123.6046 s
env0_first_0:                 episode reward: -9.7500,                 loss: 8.9029
env0_second_0:                 episode reward: 9.7500,                 loss: 4.2430
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 16361/50000 (32.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.5815s / 183361.1861 s
env0_first_0:                 episode reward: -14.4500,                 loss: 8.8339
env0_second_0:                 episode reward: 14.4500,                 loss: 4.0370
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 16381/50000 (32.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1417s / 183597.3278 s
env0_first_0:                 episode reward: -25.2000,                 loss: 8.3250
env0_second_0:                 episode reward: 25.2000,                 loss: 4.1974
env1_first_0:                 episode reward: -11.5500,                 loss: nan
env1_second_0:                 episode reward: 11.5500,                 loss: nan
Episode: 16401/50000 (32.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.9473s / 183835.2751 s
env0_first_0:                 episode reward: -14.8500,                 loss: 8.3253
env0_second_0:                 episode reward: 14.8500,                 loss: 4.6274
env1_first_0:                 episode reward: -19.8000,                 loss: nan
env1_second_0:                 episode reward: 19.8000,                 loss: nan
Episode: 16421/50000 (32.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8316s / 184073.1067 s
env0_first_0:                 episode reward: -9.5000,                 loss: 8.5985
env0_second_0:                 episode reward: 9.5000,                 loss: 4.4928
env1_first_0:                 episode reward: -17.4500,                 loss: nan
env1_second_0:                 episode reward: 17.4500,                 loss: nan
Episode: 16441/50000 (32.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9551s / 184310.0619 s
env0_first_0:                 episode reward: -20.1000,                 loss: 8.7857
env0_second_0:                 episode reward: 20.1000,                 loss: 4.4390
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 16461/50000 (32.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.3865s / 184548.4484 s
env0_first_0:                 episode reward: -26.7500,                 loss: 8.8124
env0_second_0:                 episode reward: 26.7500,                 loss: 4.2735
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 16481/50000 (32.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 239.4823s / 184787.9306 s
env0_first_0:                 episode reward: -16.4000,                 loss: 8.4304
env0_second_0:                 episode reward: 16.4000,                 loss: 4.2093
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 16501/50000 (33.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0731s / 185026.0037 s
env0_first_0:                 episode reward: -7.4500,                 loss: 8.1706
env0_second_0:                 episode reward: 7.4500,                 loss: 4.4422
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 16521/50000 (33.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.6408s / 185263.6446 s
env0_first_0:                 episode reward: -19.6500,                 loss: 7.6779
env0_second_0:                 episode reward: 19.6500,                 loss: 4.2466
env1_first_0:                 episode reward: -20.3500,                 loss: nan
env1_second_0:                 episode reward: 20.3500,                 loss: nan
Episode: 16541/50000 (33.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0996s / 185501.7442 s
env0_first_0:                 episode reward: -19.7000,                 loss: 7.6388
env0_second_0:                 episode reward: 19.7000,                 loss: 4.3267
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 16561/50000 (33.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 239.1609s / 185740.9051 s
env0_first_0:                 episode reward: -13.8500,                 loss: 7.7513
env0_second_0:                 episode reward: 13.8500,                 loss: 4.1706
env1_first_0:                 episode reward: -18.0000,                 loss: nan
env1_second_0:                 episode reward: 18.0000,                 loss: nan
Episode: 16581/50000 (33.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4806s / 185979.3856 s
env0_first_0:                 episode reward: -19.8500,                 loss: 7.6959
env0_second_0:                 episode reward: 19.8500,                 loss: 3.9014
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 16601/50000 (33.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.0323s / 186216.4179 s
env0_first_0:                 episode reward: -22.6000,                 loss: 7.5319
env0_second_0:                 episode reward: 22.6000,                 loss: 4.2324
env1_first_0:                 episode reward: -23.0000,                 loss: nan
env1_second_0:                 episode reward: 23.0000,                 loss: nan
Episode: 16621/50000 (33.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.9179s / 186455.3358 s
env0_first_0:                 episode reward: -12.3500,                 loss: 7.5010
env0_second_0:                 episode reward: 12.3500,                 loss: 4.3469
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 16641/50000 (33.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 239.5418s / 186694.8776 s
env0_first_0:                 episode reward: -7.7000,                 loss: 7.1287
env0_second_0:                 episode reward: 7.7000,                 loss: 4.4628
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 16661/50000 (33.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4004s / 186933.2781 s
env0_first_0:                 episode reward: -15.0500,                 loss: 7.2247
env0_second_0:                 episode reward: 15.0500,                 loss: 4.4341
env1_first_0:                 episode reward: -27.5500,                 loss: nan
env1_second_0:                 episode reward: 27.5500,                 loss: nan
Episode: 16681/50000 (33.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0383s / 187171.3163 s
env0_first_0:                 episode reward: -14.8000,                 loss: 7.2656
env0_second_0:                 episode reward: 14.8000,                 loss: 4.5455
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 16701/50000 (33.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2818s / 187409.5982 s
env0_first_0:                 episode reward: -14.0000,                 loss: 7.0791
env0_second_0:                 episode reward: 14.0000,                 loss: 4.4191
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 16721/50000 (33.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7130s / 187647.3111 s
env0_first_0:                 episode reward: -14.0000,                 loss: 6.9908
env0_second_0:                 episode reward: 14.0000,                 loss: 4.5579
env1_first_0:                 episode reward: -30.4500,                 loss: nan
env1_second_0:                 episode reward: 30.4500,                 loss: nan
Episode: 16741/50000 (33.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1936s / 187883.5047 s
env0_first_0:                 episode reward: -24.4000,                 loss: 7.0017
env0_second_0:                 episode reward: 24.4000,                 loss: 4.4112
env1_first_0:                 episode reward: -22.2000,                 loss: nan
env1_second_0:                 episode reward: 22.2000,                 loss: nan
Episode: 16761/50000 (33.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6520s / 188119.1567 s
env0_first_0:                 episode reward: -13.6000,                 loss: 7.0189
env0_second_0:                 episode reward: 13.6000,                 loss: 4.2601
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 16781/50000 (33.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.3725s / 188356.5293 s
env0_first_0:                 episode reward: -14.5500,                 loss: 7.3569
env0_second_0:                 episode reward: 14.5500,                 loss: 4.0750
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
Episode: 16801/50000 (33.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.0914s / 188593.6207 s
env0_first_0:                 episode reward: -15.1000,                 loss: 7.3096
env0_second_0:                 episode reward: 15.1000,                 loss: 4.2368
env1_first_0:                 episode reward: -28.0500,                 loss: nan
env1_second_0:                 episode reward: 28.0500,                 loss: nan
Episode: 16821/50000 (33.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.4328s / 188832.0535 s
env0_first_0:                 episode reward: -3.7000,                 loss: 7.2991
env0_second_0:                 episode reward: 3.7000,                 loss: 4.2380
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 16841/50000 (33.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.0290s / 189069.0825 s
env0_first_0:                 episode reward: -12.2000,                 loss: 7.2955
env0_second_0:                 episode reward: 12.2000,                 loss: 4.3121
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 16861/50000 (33.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 240.8634s / 189309.9460 s
env0_first_0:                 episode reward: -14.7000,                 loss: 7.3623
env0_second_0:                 episode reward: 14.7000,                 loss: 4.1225
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 16881/50000 (33.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8107s / 189547.7567 s
env0_first_0:                 episode reward: -6.4500,                 loss: 7.1502
env0_second_0:                 episode reward: 6.4500,                 loss: 4.3601
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 16901/50000 (33.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 239.4125s / 189787.1692 s
env0_first_0:                 episode reward: -19.6500,                 loss: 7.3375
env0_second_0:                 episode reward: 19.6500,                 loss: 4.2668
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 16921/50000 (33.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 242.2569s / 190029.4262 s
env0_first_0:                 episode reward: -17.8500,                 loss: 7.3464
env0_second_0:                 episode reward: 17.8500,                 loss: 4.1539
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 16941/50000 (33.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 240.0762s / 190269.5023 s
env0_first_0:                 episode reward: -1.5500,                 loss: 7.2357
env0_second_0:                 episode reward: 1.5500,                 loss: 4.0774
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 16961/50000 (33.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 239.2563s / 190508.7586 s
env0_first_0:                 episode reward: -27.7500,                 loss: 7.0473
env0_second_0:                 episode reward: 27.7500,                 loss: 4.1436
env1_first_0:                 episode reward: -10.2000,                 loss: nan
env1_second_0:                 episode reward: 10.2000,                 loss: nan
Episode: 16981/50000 (33.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2753s / 190745.0339 s
env0_first_0:                 episode reward: -23.4500,                 loss: 7.3581
env0_second_0:                 episode reward: 23.4500,                 loss: 4.0885
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 17001/50000 (34.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 234.8207s / 190979.8546 s
env0_first_0:                 episode reward: -24.5500,                 loss: 7.4532
env0_second_0:                 episode reward: 24.5500,                 loss: 4.0377
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 17021/50000 (34.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.9639s / 191214.8185 s
env0_first_0:                 episode reward: -8.0500,                 loss: 7.3009
env0_second_0:                 episode reward: 8.0500,                 loss: 4.1159
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 17041/50000 (34.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.5352s / 191451.3537 s
env0_first_0:                 episode reward: -20.2000,                 loss: 7.1516
env0_second_0:                 episode reward: 20.2000,                 loss: 4.1676
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 17061/50000 (34.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 234.8005s / 191686.1542 s
env0_first_0:                 episode reward: -19.9500,                 loss: 7.4569
env0_second_0:                 episode reward: 19.9500,                 loss: 4.1063
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 17081/50000 (34.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.8452s / 191922.9994 s
env0_first_0:                 episode reward: -15.5000,                 loss: 7.4787
env0_second_0:                 episode reward: 15.5000,                 loss: 3.9684
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 17101/50000 (34.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.1252s / 192160.1246 s
env0_first_0:                 episode reward: -5.6000,                 loss: 7.7687
env0_second_0:                 episode reward: 5.6000,                 loss: 4.1087
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 17121/50000 (34.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.9001s / 192396.0247 s
env0_first_0:                 episode reward: -14.8000,                 loss: 8.1338
env0_second_0:                 episode reward: 14.8000,                 loss: 4.0711
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 17141/50000 (34.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.1736s / 192631.1983 s
env0_first_0:                 episode reward: -14.2000,                 loss: 8.0911
env0_second_0:                 episode reward: 14.2000,                 loss: 3.9546
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 17161/50000 (34.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.4609s / 192867.6592 s
env0_first_0:                 episode reward: -10.6000,                 loss: 8.3668
env0_second_0:                 episode reward: 10.6000,                 loss: 4.0123
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 17181/50000 (34.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.8683s / 193106.5274 s
env0_first_0:                 episode reward: -5.4500,                 loss: 8.5585
env0_second_0:                 episode reward: 5.4500,                 loss: 3.9218
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 17201/50000 (34.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7610s / 193344.2884 s
env0_first_0:                 episode reward: -9.5500,                 loss: 8.3807
env0_second_0:                 episode reward: 9.5500,                 loss: 3.9988
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 17221/50000 (34.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 233.6170s / 193577.9054 s
env0_first_0:                 episode reward: -8.0000,                 loss: 8.4333
env0_second_0:                 episode reward: 8.0000,                 loss: 4.0657
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 17241/50000 (34.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2634s / 193814.1688 s
env0_first_0:                 episode reward: -18.3500,                 loss: 8.3070
env0_second_0:                 episode reward: 18.3500,                 loss: 3.8832
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 17261/50000 (34.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0580s / 194052.2268 s
env0_first_0:                 episode reward: -7.3500,                 loss: 8.1737
env0_second_0:                 episode reward: 7.3500,                 loss: 3.7714
env1_first_0:                 episode reward: -21.1000,                 loss: nan
env1_second_0:                 episode reward: 21.1000,                 loss: nan
Episode: 17281/50000 (34.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.3283s / 194288.5551 s
env0_first_0:                 episode reward: -9.9500,                 loss: 8.1780
env0_second_0:                 episode reward: 9.9500,                 loss: 3.8453
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 17301/50000 (34.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.1590s / 194523.7141 s
env0_first_0:                 episode reward: -17.1500,                 loss: 8.2023
env0_second_0:                 episode reward: 17.1500,                 loss: 3.8347
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 17321/50000 (34.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.9088s / 194759.6228 s
env0_first_0:                 episode reward: -14.9500,                 loss: 8.0532
env0_second_0:                 episode reward: 14.9500,                 loss: 3.9995
env1_first_0:                 episode reward: -18.0000,                 loss: nan
env1_second_0:                 episode reward: 18.0000,                 loss: nan
Episode: 17341/50000 (34.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6591s / 194996.2820 s
env0_first_0:                 episode reward: -12.9000,                 loss: 8.1206
env0_second_0:                 episode reward: 12.9000,                 loss: 4.1203
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 17361/50000 (34.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.3964s / 195232.6784 s
env0_first_0:                 episode reward: -13.2000,                 loss: 7.9832
env0_second_0:                 episode reward: 13.2000,                 loss: 4.1796
env1_first_0:                 episode reward: 6.3000,                 loss: nan
env1_second_0:                 episode reward: -6.3000,                 loss: nan
Episode: 17381/50000 (34.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7143s / 195470.3927 s
env0_first_0:                 episode reward: -12.7500,                 loss: 7.7413
env0_second_0:                 episode reward: 12.7500,                 loss: 4.1454
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 17401/50000 (34.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.9540s / 195708.3466 s
env0_first_0:                 episode reward: -8.0000,                 loss: 7.6805
env0_second_0:                 episode reward: 8.0000,                 loss: 4.1015
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 17421/50000 (34.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.9222s / 195944.2688 s
env0_first_0:                 episode reward: -19.9500,                 loss: 7.6858
env0_second_0:                 episode reward: 19.9500,                 loss: 4.1210
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 17441/50000 (34.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.0814s / 196181.3503 s
env0_first_0:                 episode reward: -5.4500,                 loss: 7.9241
env0_second_0:                 episode reward: 5.4500,                 loss: 4.3374
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 17461/50000 (34.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7237s / 196419.0739 s
env0_first_0:                 episode reward: -8.7000,                 loss: 8.1286
env0_second_0:                 episode reward: 8.7000,                 loss: 4.4519
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 17481/50000 (34.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6353s / 196654.7093 s
env0_first_0:                 episode reward: -11.8500,                 loss: 7.7396
env0_second_0:                 episode reward: 11.8500,                 loss: 4.3336
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 17501/50000 (35.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.0912s / 196890.8005 s
env0_first_0:                 episode reward: 2.9000,                 loss: 8.0680
env0_second_0:                 episode reward: -2.9000,                 loss: 4.3729
env1_first_0:                 episode reward: -23.7000,                 loss: nan
env1_second_0:                 episode reward: 23.7000,                 loss: nan
Episode: 17521/50000 (35.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.1867s / 197127.9872 s
env0_first_0:                 episode reward: -17.0500,                 loss: 7.9791
env0_second_0:                 episode reward: 17.0500,                 loss: 4.4638
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 17541/50000 (35.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.1632s / 197366.1504 s
env0_first_0:                 episode reward: -21.3000,                 loss: 7.8418
env0_second_0:                 episode reward: 21.3000,                 loss: 4.3920
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 17561/50000 (35.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.3455s / 197602.4960 s
env0_first_0:                 episode reward: -11.5500,                 loss: 7.7719
env0_second_0:                 episode reward: 11.5500,                 loss: 4.4096
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 17581/50000 (35.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 234.6349s / 197837.1309 s
env0_first_0:                 episode reward: -6.6500,                 loss: 7.8890
env0_second_0:                 episode reward: 6.6500,                 loss: 4.6328
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 17601/50000 (35.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 233.4597s / 198070.5906 s
env0_first_0:                 episode reward: -12.4500,                 loss: 7.8205
env0_second_0:                 episode reward: 12.4500,                 loss: 4.7331
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 17621/50000 (35.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2581s / 198306.8487 s
env0_first_0:                 episode reward: -2.3500,                 loss: 7.8555
env0_second_0:                 episode reward: 2.3500,                 loss: 4.8957
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 17641/50000 (35.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.0730s / 198539.9217 s
env0_first_0:                 episode reward: -19.8000,                 loss: 7.7301
env0_second_0:                 episode reward: 19.8000,                 loss: 5.0327
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 17661/50000 (35.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 233.5944s / 198773.5161 s
env0_first_0:                 episode reward: -0.2000,                 loss: 7.7330
env0_second_0:                 episode reward: 0.2000,                 loss: 4.9900
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 17681/50000 (35.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7712s / 199011.2873 s
env0_first_0:                 episode reward: -21.0500,                 loss: 7.7336
env0_second_0:                 episode reward: 21.0500,                 loss: 4.9008
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 17701/50000 (35.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 238.3544s / 199249.6417 s
env0_first_0:                 episode reward: 3.1500,                 loss: 7.5102
env0_second_0:                 episode reward: -3.1500,                 loss: 4.9317
env1_first_0:                 episode reward: -18.4500,                 loss: nan
env1_second_0:                 episode reward: 18.4500,                 loss: nan
Episode: 17721/50000 (35.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.5567s / 199486.1985 s
env0_first_0:                 episode reward: -24.7500,                 loss: 7.8254
env0_second_0:                 episode reward: 24.7500,                 loss: 5.1563
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 17741/50000 (35.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.7344s / 199721.9328 s
env0_first_0:                 episode reward: -23.0500,                 loss: 7.6421
env0_second_0:                 episode reward: 23.0500,                 loss: 5.0340
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 17761/50000 (35.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.8779s / 199957.8107 s
env0_first_0:                 episode reward: -10.3000,                 loss: 7.6798
env0_second_0:                 episode reward: 10.3000,                 loss: 5.0842
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 17781/50000 (35.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.0554s / 200192.8661 s
env0_first_0:                 episode reward: -29.2000,                 loss: 8.0854
env0_second_0:                 episode reward: 29.2000,                 loss: 5.0338
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 17801/50000 (35.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.4581s / 200428.3242 s
env0_first_0:                 episode reward: -7.5000,                 loss: 8.3367
env0_second_0:                 episode reward: 7.5000,                 loss: 5.0192
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 17821/50000 (35.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.7404s / 200663.0646 s
env0_first_0:                 episode reward: -21.9000,                 loss: 8.5269
env0_second_0:                 episode reward: 21.9000,                 loss: 5.0701
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 17841/50000 (35.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 234.8073s / 200897.8719 s
env0_first_0:                 episode reward: -12.5000,                 loss: 8.6536
env0_second_0:                 episode reward: 12.5000,                 loss: 5.0172
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 17861/50000 (35.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.6611s / 201136.5330 s
env0_first_0:                 episode reward: -17.9000,                 loss: 8.3335
env0_second_0:                 episode reward: 17.9000,                 loss: 4.8315
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 17881/50000 (35.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.5433s / 201373.0763 s
env0_first_0:                 episode reward: -5.9000,                 loss: 8.5037
env0_second_0:                 episode reward: 5.9000,                 loss: 4.7303
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 17901/50000 (35.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.1480s / 201608.2244 s
env0_first_0:                 episode reward: -15.4500,                 loss: 8.5439
env0_second_0:                 episode reward: 15.4500,                 loss: 4.6814
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 17921/50000 (35.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.9551s / 201847.1795 s
env0_first_0:                 episode reward: 0.1000,                 loss: 8.0894
env0_second_0:                 episode reward: -0.1000,                 loss: 4.6475
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 17941/50000 (35.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.5466s / 202084.7261 s
env0_first_0:                 episode reward: -15.6000,                 loss: 8.2669
env0_second_0:                 episode reward: 15.6000,                 loss: 4.8395
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 17961/50000 (35.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.9276s / 202322.6537 s
env0_first_0:                 episode reward: -24.3500,                 loss: 8.1447
env0_second_0:                 episode reward: 24.3500,                 loss: 4.9771
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Episode: 17981/50000 (35.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.7560s / 202560.4097 s
env0_first_0:                 episode reward: -4.4000,                 loss: 7.8584
env0_second_0:                 episode reward: 4.4000,                 loss: 4.9990
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 18001/50000 (36.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 234.6394s / 202795.0491 s
env0_first_0:                 episode reward: -26.7500,                 loss: 7.5226
env0_second_0:                 episode reward: 26.7500,                 loss: 5.0204
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 18021/50000 (36.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.4719s / 203029.5210 s
env0_first_0:                 episode reward: -6.3000,                 loss: 7.8156
env0_second_0:                 episode reward: 6.3000,                 loss: 5.0001
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 18041/50000 (36.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8214s / 203267.3424 s
env0_first_0:                 episode reward: -8.4500,                 loss: 7.9958
env0_second_0:                 episode reward: 8.4500,                 loss: 5.0808
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 18061/50000 (36.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 238.0247s / 203505.3671 s
env0_first_0:                 episode reward: -20.8500,                 loss: 7.8359
env0_second_0:                 episode reward: 20.8500,                 loss: 4.8844
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 18081/50000 (36.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.3685s / 203742.7356 s
env0_first_0:                 episode reward: -20.7000,                 loss: 7.8313
env0_second_0:                 episode reward: 20.7000,                 loss: 5.0888
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 18101/50000 (36.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6378s / 203979.3734 s
env0_first_0:                 episode reward: -2.8500,                 loss: 8.3606
env0_second_0:                 episode reward: 2.8500,                 loss: 4.9817
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 18121/50000 (36.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.2332s / 204214.6066 s
env0_first_0:                 episode reward: -20.8000,                 loss: 8.0267
env0_second_0:                 episode reward: 20.8000,                 loss: 5.0647
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 18141/50000 (36.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.3772s / 204450.9838 s
env0_first_0:                 episode reward: -10.8000,                 loss: 8.0781
env0_second_0:                 episode reward: 10.8000,                 loss: 4.9283
env1_first_0:                 episode reward: -29.4000,                 loss: nan
env1_second_0:                 episode reward: 29.4000,                 loss: nan
Episode: 18161/50000 (36.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9188s / 204687.9026 s
env0_first_0:                 episode reward: -20.5500,                 loss: 7.6930
env0_second_0:                 episode reward: 20.5500,                 loss: 4.7301
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 18181/50000 (36.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.2611s / 204923.1637 s
env0_first_0:                 episode reward: -13.1000,                 loss: 7.4673
env0_second_0:                 episode reward: 13.1000,                 loss: 4.5596
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 18201/50000 (36.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.3890s / 205158.5527 s
env0_first_0:                 episode reward: -14.7500,                 loss: 7.5046
env0_second_0:                 episode reward: 14.7500,                 loss: 4.6796
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 18221/50000 (36.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1438s / 205394.6966 s
env0_first_0:                 episode reward: -15.6500,                 loss: 7.7181
env0_second_0:                 episode reward: 15.6500,                 loss: 4.6323
env1_first_0:                 episode reward: -20.1500,                 loss: nan
env1_second_0:                 episode reward: 20.1500,                 loss: nan
Episode: 18241/50000 (36.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.2885s / 205632.9851 s
env0_first_0:                 episode reward: -0.3500,                 loss: 7.5815
env0_second_0:                 episode reward: 0.3500,                 loss: 4.6529
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 18261/50000 (36.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.1637s / 205870.1488 s
env0_first_0:                 episode reward: -2.5500,                 loss: 7.5329
env0_second_0:                 episode reward: 2.5500,                 loss: 4.4341
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 18281/50000 (36.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 238.6575s / 206108.8064 s
env0_first_0:                 episode reward: -14.9500,                 loss: 7.9485
env0_second_0:                 episode reward: 14.9500,                 loss: 4.6890
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 18301/50000 (36.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.8432s / 206346.6495 s
env0_first_0:                 episode reward: -14.4000,                 loss: 7.4275
env0_second_0:                 episode reward: 14.4000,                 loss: 4.9081
env1_first_0:                 episode reward: -19.6000,                 loss: nan
env1_second_0:                 episode reward: 19.6000,                 loss: nan
Episode: 18321/50000 (36.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6780s / 206582.3275 s
env0_first_0:                 episode reward: -19.7500,                 loss: 7.2048
env0_second_0:                 episode reward: 19.7500,                 loss: 4.7618
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 18341/50000 (36.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.5947s / 206817.9222 s
env0_first_0:                 episode reward: -16.2000,                 loss: 7.1051
env0_second_0:                 episode reward: 16.2000,                 loss: 4.7135
env1_first_0:                 episode reward: -23.0000,                 loss: nan
env1_second_0:                 episode reward: 23.0000,                 loss: nan
Episode: 18361/50000 (36.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1304s / 207054.0526 s
env0_first_0:                 episode reward: -3.6500,                 loss: 7.2242
env0_second_0:                 episode reward: 3.6500,                 loss: 4.7607
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 18381/50000 (36.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 237.1602s / 207291.2127 s
env0_first_0:                 episode reward: -18.3000,                 loss: 7.1812
env0_second_0:                 episode reward: 18.3000,                 loss: 4.8263
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 18401/50000 (36.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.2209s / 207526.4336 s
env0_first_0:                 episode reward: -7.9000,                 loss: 7.1569
env0_second_0:                 episode reward: 7.9000,                 loss: 4.6998
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
Episode: 18421/50000 (36.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 238.5892s / 207765.0228 s
env0_first_0:                 episode reward: -9.5500,                 loss: 7.2197
env0_second_0:                 episode reward: 9.5500,                 loss: 4.3910
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 18441/50000 (36.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.2959s / 208002.3186 s
env0_first_0:                 episode reward: -25.0000,                 loss: 7.0562
env0_second_0:                 episode reward: 25.0000,                 loss: 4.3105
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
Episode: 18461/50000 (36.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 237.0244s / 208239.3431 s
env0_first_0:                 episode reward: -9.1500,                 loss: 6.8946
env0_second_0:                 episode reward: 9.1500,                 loss: 4.5043
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 18481/50000 (36.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9349s / 208476.2780 s
env0_first_0:                 episode reward: -25.5000,                 loss: 6.8889
env0_second_0:                 episode reward: 25.5000,                 loss: 4.4751
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 18501/50000 (37.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6177s / 208712.8957 s
env0_first_0:                 episode reward: -14.1500,                 loss: 6.8047
env0_second_0:                 episode reward: 14.1500,                 loss: 4.5202
env1_first_0:                 episode reward: -27.4000,                 loss: nan
env1_second_0:                 episode reward: 27.4000,                 loss: nan
Episode: 18521/50000 (37.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 240.3465s / 208953.2422 s
env0_first_0:                 episode reward: -18.5500,                 loss: 6.6899
env0_second_0:                 episode reward: 18.5500,                 loss: 4.6409
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 18541/50000 (37.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 237.5350s / 209190.7773 s
env0_first_0:                 episode reward: -9.9000,                 loss: 7.2543
env0_second_0:                 episode reward: 9.9000,                 loss: 4.7131
env1_first_0:                 episode reward: -25.2000,                 loss: nan
env1_second_0:                 episode reward: 25.2000,                 loss: nan
Episode: 18561/50000 (37.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9470s / 209427.7243 s
env0_first_0:                 episode reward: -16.2500,                 loss: 7.3334
env0_second_0:                 episode reward: 16.2500,                 loss: 4.6339
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 18581/50000 (37.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.1661s / 209662.8904 s
env0_first_0:                 episode reward: -19.2500,                 loss: 7.3924
env0_second_0:                 episode reward: 19.2500,                 loss: 4.4565
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 18601/50000 (37.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.9534s / 209898.8438 s
env0_first_0:                 episode reward: -5.4500,                 loss: 7.2049
env0_second_0:                 episode reward: 5.4500,                 loss: 4.4140
env1_first_0:                 episode reward: -19.1500,                 loss: nan
env1_second_0:                 episode reward: 19.1500,                 loss: nan
Episode: 18621/50000 (37.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 236.5689s / 210135.4127 s
env0_first_0:                 episode reward: -19.0500,                 loss: 7.0474
env0_second_0:                 episode reward: 19.0500,                 loss: 4.3769
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 18641/50000 (37.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.7551s / 210372.1678 s
env0_first_0:                 episode reward: -25.2500,                 loss: 7.3287
env0_second_0:                 episode reward: 25.2500,                 loss: 4.3108
env1_first_0:                 episode reward: -7.3500,                 loss: nan
env1_second_0:                 episode reward: 7.3500,                 loss: nan
Episode: 18661/50000 (37.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1226s / 210608.2904 s
env0_first_0:                 episode reward: -25.3000,                 loss: 7.3147
env0_second_0:                 episode reward: 25.3000,                 loss: 4.1755
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 18681/50000 (37.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 236.9916s / 210845.2820 s
env0_first_0:                 episode reward: -18.0000,                 loss: 7.6619
env0_second_0:                 episode reward: 18.0000,                 loss: 4.2635
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 18701/50000 (37.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1967s / 211081.4787 s
env0_first_0:                 episode reward: -17.2500,                 loss: 7.1765
env0_second_0:                 episode reward: 17.2500,                 loss: 4.3857
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 18721/50000 (37.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.0045s / 211318.4832 s
env0_first_0:                 episode reward: -8.9500,                 loss: 7.1802
env0_second_0:                 episode reward: 8.9500,                 loss: 4.6530
env1_first_0:                 episode reward: 5.1000,                 loss: nan
env1_second_0:                 episode reward: -5.1000,                 loss: nan
Episode: 18741/50000 (37.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 238.5459s / 211557.0291 s
env0_first_0:                 episode reward: -19.0000,                 loss: 7.3533
env0_second_0:                 episode reward: 19.0000,                 loss: 4.4131
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 18761/50000 (37.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 236.2382s / 211793.2673 s
env0_first_0:                 episode reward: -17.5000,                 loss: 7.0016
env0_second_0:                 episode reward: 17.5000,                 loss: 4.4249
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 18781/50000 (37.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.7052s / 212025.9725 s
env0_first_0:                 episode reward: -25.9500,                 loss: 7.0050
env0_second_0:                 episode reward: 25.9500,                 loss: 4.4282
env1_first_0:                 episode reward: -19.6500,                 loss: nan
env1_second_0:                 episode reward: 19.6500,                 loss: nan
Episode: 18801/50000 (37.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 233.6252s / 212259.5977 s
env0_first_0:                 episode reward: -19.7000,                 loss: 7.1521
env0_second_0:                 episode reward: 19.7000,                 loss: 4.4420
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 18821/50000 (37.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.3977s / 212493.9953 s
env0_first_0:                 episode reward: -7.2000,                 loss: 7.5543
env0_second_0:                 episode reward: 7.2000,                 loss: 4.3341
env1_first_0:                 episode reward: -18.4500,                 loss: nan
env1_second_0:                 episode reward: 18.4500,                 loss: nan
Episode: 18841/50000 (37.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.2170s / 212727.2123 s
env0_first_0:                 episode reward: -8.4000,                 loss: 7.7062
env0_second_0:                 episode reward: 8.4000,                 loss: 4.2404
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 18861/50000 (37.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 234.5829s / 212961.7952 s
env0_first_0:                 episode reward: -21.0000,                 loss: 7.3628
env0_second_0:                 episode reward: 21.0000,                 loss: 3.9553
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 18881/50000 (37.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6758s / 213197.4710 s
env0_first_0:                 episode reward: -18.7500,                 loss: 6.9279
env0_second_0:                 episode reward: 18.7500,                 loss: 4.0889
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 18901/50000 (37.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 237.1440s / 213434.6150 s
env0_first_0:                 episode reward: -16.2000,                 loss: 6.6354
env0_second_0:                 episode reward: 16.2000,                 loss: 4.1347
env1_first_0:                 episode reward: -9.0500,                 loss: nan
env1_second_0:                 episode reward: 9.0500,                 loss: nan
Episode: 18921/50000 (37.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.8549s / 213669.4699 s
env0_first_0:                 episode reward: -9.4500,                 loss: 6.5720
env0_second_0:                 episode reward: 9.4500,                 loss: 4.2540
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 18941/50000 (37.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6610s / 213905.1310 s
env0_first_0:                 episode reward: -13.6000,                 loss: 6.5579
env0_second_0:                 episode reward: 13.6000,                 loss: 4.0352
env1_first_0:                 episode reward: -28.8000,                 loss: nan
env1_second_0:                 episode reward: 28.8000,                 loss: nan
Episode: 18961/50000 (37.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 232.9097s / 214138.0407 s
env0_first_0:                 episode reward: -8.2000,                 loss: 6.5402
env0_second_0:                 episode reward: 8.2000,                 loss: 4.0684
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 18981/50000 (37.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 234.8534s / 214372.8941 s
env0_first_0:                 episode reward: -20.2500,                 loss: 6.8337
env0_second_0:                 episode reward: 20.2500,                 loss: 4.4116
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 19001/50000 (38.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 234.2750s / 214607.1690 s
env0_first_0:                 episode reward: -32.4500,                 loss: 6.8751
env0_second_0:                 episode reward: 32.4500,                 loss: 4.2275
env1_first_0:                 episode reward: -23.9000,                 loss: nan
env1_second_0:                 episode reward: 23.9000,                 loss: nan
Episode: 19021/50000 (38.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.5377s / 214841.7067 s
env0_first_0:                 episode reward: -22.6000,                 loss: 7.0855
env0_second_0:                 episode reward: 22.6000,                 loss: 4.2614
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 19041/50000 (38.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.6090s / 215077.3157 s
env0_first_0:                 episode reward: -15.8000,                 loss: 7.1884
env0_second_0:                 episode reward: 15.8000,                 loss: 4.2638
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 19061/50000 (38.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 233.2122s / 215310.5280 s
env0_first_0:                 episode reward: -21.2000,                 loss: 7.2242
env0_second_0:                 episode reward: 21.2000,                 loss: 4.1978
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Episode: 19081/50000 (38.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 234.4103s / 215544.9383 s
env0_first_0:                 episode reward: -6.3000,                 loss: 7.3748
env0_second_0:                 episode reward: 6.3000,                 loss: 4.1965
env1_first_0:                 episode reward: -22.9500,                 loss: nan
env1_second_0:                 episode reward: 22.9500,                 loss: nan
Episode: 19101/50000 (38.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.1462s / 215780.0844 s
env0_first_0:                 episode reward: 4.0000,                 loss: 7.4790
env0_second_0:                 episode reward: -4.0000,                 loss: 4.2375
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Episode: 19121/50000 (38.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 233.4986s / 216013.5830 s
env0_first_0:                 episode reward: -14.6500,                 loss: 7.7082
env0_second_0:                 episode reward: 14.6500,                 loss: 4.3132
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 19141/50000 (38.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.6108s / 216247.1938 s
env0_first_0:                 episode reward: -16.2000,                 loss: 7.6660
env0_second_0:                 episode reward: 16.2000,                 loss: 4.3038
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 19161/50000 (38.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 233.4063s / 216480.6001 s
env0_first_0:                 episode reward: -2.9000,                 loss: 7.6171
env0_second_0:                 episode reward: 2.9000,                 loss: 4.3281
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 19181/50000 (38.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.7243s / 216713.3244 s
env0_first_0:                 episode reward: -27.0000,                 loss: 7.0639
env0_second_0:                 episode reward: 27.0000,                 loss: 4.7397
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 19201/50000 (38.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 232.0765s / 216945.4009 s
env0_first_0:                 episode reward: -12.2500,                 loss: 7.1375
env0_second_0:                 episode reward: 12.2500,                 loss: 4.6784
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 19221/50000 (38.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.2850s / 217179.6859 s
env0_first_0:                 episode reward: -12.1500,                 loss: 7.0069
env0_second_0:                 episode reward: 12.1500,                 loss: 4.2850
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 19241/50000 (38.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.1801s / 217415.8660 s
env0_first_0:                 episode reward: -4.5000,                 loss: 7.3652
env0_second_0:                 episode reward: 4.5000,                 loss: 4.2692
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 19261/50000 (38.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 232.8593s / 217648.7254 s
env0_first_0:                 episode reward: -11.5500,                 loss: 7.3728
env0_second_0:                 episode reward: 11.5500,                 loss: 4.1117
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 19281/50000 (38.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 231.7300s / 217880.4554 s
env0_first_0:                 episode reward: -20.4500,                 loss: 7.0905
env0_second_0:                 episode reward: 20.4500,                 loss: 4.1256
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 19301/50000 (38.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 233.1454s / 218113.6007 s
env0_first_0:                 episode reward: -9.2500,                 loss: 7.0777
env0_second_0:                 episode reward: 9.2500,                 loss: 4.2262
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 19321/50000 (38.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.1638s / 218348.7646 s
env0_first_0:                 episode reward: -8.5500,                 loss: 7.0796
env0_second_0:                 episode reward: 8.5500,                 loss: 4.1671
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 19341/50000 (38.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.4853s / 218584.2499 s
env0_first_0:                 episode reward: -16.3500,                 loss: 7.4442
env0_second_0:                 episode reward: 16.3500,                 loss: 4.2898
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 19361/50000 (38.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.5924s / 218819.8423 s
env0_first_0:                 episode reward: -3.4000,                 loss: 7.2300
env0_second_0:                 episode reward: 3.4000,                 loss: 4.0979
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 19381/50000 (38.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 231.7984s / 219051.6407 s
env0_first_0:                 episode reward: -14.2000,                 loss: 7.2834
env0_second_0:                 episode reward: 14.2000,                 loss: 4.4598
env1_first_0:                 episode reward: -19.4000,                 loss: nan
env1_second_0:                 episode reward: 19.4000,                 loss: nan
Episode: 19401/50000 (38.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 233.1779s / 219284.8186 s
env0_first_0:                 episode reward: -19.2500,                 loss: 7.0117
env0_second_0:                 episode reward: 19.2500,                 loss: 4.3195
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 19421/50000 (38.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 233.5237s / 219518.3423 s
env0_first_0:                 episode reward: -6.0500,                 loss: 7.4599
env0_second_0:                 episode reward: 6.0500,                 loss: 4.2518
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 19441/50000 (38.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 232.7613s / 219751.1036 s
env0_first_0:                 episode reward: -18.8500,                 loss: 7.5068
env0_second_0:                 episode reward: 18.8500,                 loss: 4.1527
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 19461/50000 (38.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 231.3764s / 219982.4800 s
env0_first_0:                 episode reward: -14.2000,                 loss: 7.5655
env0_second_0:                 episode reward: 14.2000,                 loss: 4.0688
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 19481/50000 (38.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 234.1101s / 220216.5901 s
env0_first_0:                 episode reward: -4.9000,                 loss: 7.8042
env0_second_0:                 episode reward: 4.9000,                 loss: 4.2648
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 19501/50000 (39.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 232.7769s / 220449.3669 s
env0_first_0:                 episode reward: -14.9500,                 loss: 7.8043
env0_second_0:                 episode reward: 14.9500,                 loss: 4.3583
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 19521/50000 (39.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.5862s / 220683.9532 s
env0_first_0:                 episode reward: -21.8000,                 loss: 7.8776
env0_second_0:                 episode reward: 21.8000,                 loss: 4.3437
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 19541/50000 (39.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.1593s / 220917.1124 s
env0_first_0:                 episode reward: -20.8500,                 loss: 7.9460
env0_second_0:                 episode reward: 20.8500,                 loss: 4.2012
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
Episode: 19561/50000 (39.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 232.9639s / 221150.0764 s
env0_first_0:                 episode reward: -4.0000,                 loss: 8.0061
env0_second_0:                 episode reward: 4.0000,                 loss: 4.3437
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 19581/50000 (39.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.6997s / 221382.7760 s
env0_first_0:                 episode reward: -17.3000,                 loss: 7.4074
env0_second_0:                 episode reward: 17.3000,                 loss: 4.2232
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 19601/50000 (39.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 232.8048s / 221615.5808 s
env0_first_0:                 episode reward: -11.0500,                 loss: 7.4400
env0_second_0:                 episode reward: 11.0500,                 loss: 4.1445
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 19621/50000 (39.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.1686s / 221849.7494 s
env0_first_0:                 episode reward: -6.0000,                 loss: 7.0137
env0_second_0:                 episode reward: 6.0000,                 loss: 4.1270
env1_first_0:                 episode reward: -17.2500,                 loss: nan
env1_second_0:                 episode reward: 17.2500,                 loss: nan
Episode: 19641/50000 (39.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.0560s / 222082.8054 s
env0_first_0:                 episode reward: -5.5500,                 loss: 6.7894
env0_second_0:                 episode reward: 5.5500,                 loss: 4.1747
env1_first_0:                 episode reward: -16.7500,                 loss: nan
env1_second_0:                 episode reward: 16.7500,                 loss: nan
Episode: 19661/50000 (39.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 232.2418s / 222315.0472 s
env0_first_0:                 episode reward: -17.0500,                 loss: 6.7233
env0_second_0:                 episode reward: 17.0500,                 loss: 4.2696
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 19681/50000 (39.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 233.3956s / 222548.4428 s
env0_first_0:                 episode reward: -8.1000,                 loss: 6.5375
env0_second_0:                 episode reward: 8.1000,                 loss: 4.1228
env1_first_0:                 episode reward: -30.2000,                 loss: nan
env1_second_0:                 episode reward: 30.2000,                 loss: nan
Episode: 19701/50000 (39.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 232.9333s / 222781.3761 s
env0_first_0:                 episode reward: -0.5000,                 loss: 6.8118
env0_second_0:                 episode reward: 0.5000,                 loss: 3.9859
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 19721/50000 (39.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 233.5711s / 223014.9472 s
env0_first_0:                 episode reward: -10.9000,                 loss: 7.1480
env0_second_0:                 episode reward: 10.9000,                 loss: 4.0657
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 19741/50000 (39.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 231.8175s / 223246.7647 s
env0_first_0:                 episode reward: -19.6500,                 loss: 7.1351
env0_second_0:                 episode reward: 19.6500,                 loss: 4.0925
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 19761/50000 (39.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 232.7229s / 223479.4876 s
env0_first_0:                 episode reward: -13.0500,                 loss: 7.1225
env0_second_0:                 episode reward: 13.0500,                 loss: 4.1960
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 19781/50000 (39.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.7696s / 223712.2572 s
env0_first_0:                 episode reward: -9.0000,                 loss: 7.0230
env0_second_0:                 episode reward: 9.0000,                 loss: 4.3176
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 19801/50000 (39.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 233.7824s / 223946.0395 s
env0_first_0:                 episode reward: -0.1000,                 loss: 7.0532
env0_second_0:                 episode reward: 0.1000,                 loss: 4.2897
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 19821/50000 (39.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 230.5119s / 224176.5514 s
env0_first_0:                 episode reward: -2.9500,                 loss: 6.6486
env0_second_0:                 episode reward: 2.9500,                 loss: 4.3093
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 19841/50000 (39.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 231.6620s / 224408.2135 s
env0_first_0:                 episode reward: -22.7500,                 loss: 6.4770
env0_second_0:                 episode reward: 22.7500,                 loss: 4.3147
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 19861/50000 (39.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 233.1293s / 224641.3427 s
env0_first_0:                 episode reward: -13.4500,                 loss: 6.5968
env0_second_0:                 episode reward: 13.4500,                 loss: 4.3480
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 19881/50000 (39.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 233.1231s / 224874.4658 s
env0_first_0:                 episode reward: -11.5000,                 loss: 6.9114
env0_second_0:                 episode reward: 11.5000,                 loss: 4.3767
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 19901/50000 (39.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.4525s / 225109.9183 s
env0_first_0:                 episode reward: -13.1500,                 loss: 7.0656
env0_second_0:                 episode reward: 13.1500,                 loss: 4.5082
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 19921/50000 (39.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.3936s / 225344.3119 s
env0_first_0:                 episode reward: -9.3000,                 loss: 7.2718
env0_second_0:                 episode reward: 9.3000,                 loss: 4.6303
env1_first_0:                 episode reward: -30.1500,                 loss: nan
env1_second_0:                 episode reward: 30.1500,                 loss: nan
Episode: 19941/50000 (39.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 234.6200s / 225578.9319 s
env0_first_0:                 episode reward: -20.5000,                 loss: 7.1788
env0_second_0:                 episode reward: 20.5000,                 loss: 4.4780
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 19961/50000 (39.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 232.3010s / 225811.2329 s
env0_first_0:                 episode reward: -22.7500,                 loss: 7.0213
env0_second_0:                 episode reward: 22.7500,                 loss: 4.5709
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 19981/50000 (39.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 233.8644s / 226045.0972 s
env0_first_0:                 episode reward: -27.1500,                 loss: 6.6948
env0_second_0:                 episode reward: 27.1500,                 loss: 4.4221
env1_first_0:                 episode reward: -9.1500,                 loss: nan
env1_second_0:                 episode reward: 9.1500,                 loss: nan
Episode: 20001/50000 (40.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.1216s / 226280.2188 s
env0_first_0:                 episode reward: -17.8500,                 loss: 6.4317
env0_second_0:                 episode reward: 17.8500,                 loss: 4.4520
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 20021/50000 (40.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 233.8756s / 226514.0945 s
env0_first_0:                 episode reward: -20.6000,                 loss: 6.6668
env0_second_0:                 episode reward: 20.6000,                 loss: 4.4681
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 20041/50000 (40.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.2546s / 226747.3491 s
env0_first_0:                 episode reward: -28.3500,                 loss: 6.6495
env0_second_0:                 episode reward: 28.3500,                 loss: 4.4686
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 20061/50000 (40.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 234.7325s / 226982.0815 s
env0_first_0:                 episode reward: -5.7500,                 loss: 6.7184
env0_second_0:                 episode reward: 5.7500,                 loss: 4.6714
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 20081/50000 (40.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.5947s / 227214.6762 s
env0_first_0:                 episode reward: -16.2000,                 loss: 6.3330
env0_second_0:                 episode reward: 16.2000,                 loss: 4.6095
env1_first_0:                 episode reward: -26.1000,                 loss: nan
env1_second_0:                 episode reward: 26.1000,                 loss: nan
Episode: 20101/50000 (40.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 233.6061s / 227448.2824 s
env0_first_0:                 episode reward: -13.8000,                 loss: 6.5289
env0_second_0:                 episode reward: 13.8000,                 loss: 4.3288
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 20121/50000 (40.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 230.6620s / 227678.9443 s
env0_first_0:                 episode reward: -0.3500,                 loss: 6.4914
env0_second_0:                 episode reward: 0.3500,                 loss: 4.4442
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 20141/50000 (40.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.8885s / 227912.8329 s
env0_first_0:                 episode reward: -34.6500,                 loss: 6.7927
env0_second_0:                 episode reward: 34.6500,                 loss: 4.5302
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 20161/50000 (40.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 232.2814s / 228145.1143 s
env0_first_0:                 episode reward: -11.8000,                 loss: 6.7155
env0_second_0:                 episode reward: 11.8000,                 loss: 4.2625
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 20181/50000 (40.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 231.8032s / 228376.9175 s
env0_first_0:                 episode reward: -23.3500,                 loss: 6.7131
env0_second_0:                 episode reward: 23.3500,                 loss: 4.2917
env1_first_0:                 episode reward: -28.6000,                 loss: nan
env1_second_0:                 episode reward: 28.6000,                 loss: nan
Episode: 20201/50000 (40.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 232.2667s / 228609.1842 s
env0_first_0:                 episode reward: -30.3500,                 loss: 6.5445
env0_second_0:                 episode reward: 30.3500,                 loss: 4.2080
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 20221/50000 (40.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 233.4084s / 228842.5926 s
env0_first_0:                 episode reward: -13.0000,                 loss: 6.8377
env0_second_0:                 episode reward: 13.0000,                 loss: 4.2622
env1_first_0:                 episode reward: -21.0000,                 loss: nan
env1_second_0:                 episode reward: 21.0000,                 loss: nan
Episode: 20241/50000 (40.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.3657s / 229075.9584 s
env0_first_0:                 episode reward: -20.2500,                 loss: 7.1369
env0_second_0:                 episode reward: 20.2500,                 loss: 4.2824
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 20261/50000 (40.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 232.2628s / 229308.2212 s
env0_first_0:                 episode reward: -14.0000,                 loss: 6.9530
env0_second_0:                 episode reward: 14.0000,                 loss: 4.2243
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 20281/50000 (40.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.2599s / 229540.4810 s
env0_first_0:                 episode reward: -18.2500,                 loss: 6.9232
env0_second_0:                 episode reward: 18.2500,                 loss: 4.1683
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 20301/50000 (40.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 230.4938s / 229770.9749 s
env0_first_0:                 episode reward: -27.3000,                 loss: 6.9642
env0_second_0:                 episode reward: 27.3000,                 loss: 4.3355
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 20321/50000 (40.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.2703s / 230005.2452 s
env0_first_0:                 episode reward: -19.4000,                 loss: 7.1749
env0_second_0:                 episode reward: 19.4000,                 loss: 4.1598
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 20341/50000 (40.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 232.5855s / 230237.8307 s
env0_first_0:                 episode reward: -13.5500,                 loss: 7.2103
env0_second_0:                 episode reward: 13.5500,                 loss: 4.2484
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 20361/50000 (40.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 230.5154s / 230468.3461 s
env0_first_0:                 episode reward: -22.1500,                 loss: 7.0990
env0_second_0:                 episode reward: 22.1500,                 loss: 4.3823
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 20381/50000 (40.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 230.0343s / 230698.3804 s
env0_first_0:                 episode reward: -17.5000,                 loss: 7.2486
env0_second_0:                 episode reward: 17.5000,                 loss: 4.4442
env1_first_0:                 episode reward: -29.3500,                 loss: nan
env1_second_0:                 episode reward: 29.3500,                 loss: nan
Episode: 20401/50000 (40.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 230.5786s / 230928.9590 s
env0_first_0:                 episode reward: -13.1500,                 loss: 7.2240
env0_second_0:                 episode reward: 13.1500,                 loss: 4.3730
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 20421/50000 (40.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 234.1769s / 231163.1359 s
env0_first_0:                 episode reward: -12.5500,                 loss: 7.0074
env0_second_0:                 episode reward: 12.5500,                 loss: 4.4835
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 20441/50000 (40.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 231.7288s / 231394.8647 s
env0_first_0:                 episode reward: -8.9500,                 loss: 6.9111
env0_second_0:                 episode reward: 8.9500,                 loss: 4.2230
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 20461/50000 (40.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 233.5620s / 231628.4267 s
env0_first_0:                 episode reward: -32.4000,                 loss: 6.5299
env0_second_0:                 episode reward: 32.4000,                 loss: 4.1250
env1_first_0:                 episode reward: -14.9000,                 loss: nan
env1_second_0:                 episode reward: 14.9000,                 loss: nan
Episode: 20481/50000 (40.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 233.1549s / 231861.5815 s
env0_first_0:                 episode reward: -12.2000,                 loss: 6.1733
env0_second_0:                 episode reward: 12.2000,                 loss: 4.3466
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 20501/50000 (41.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 230.6184s / 232092.1999 s
env0_first_0:                 episode reward: -4.8500,                 loss: 6.2512
env0_second_0:                 episode reward: 4.8500,                 loss: 4.3883
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 20521/50000 (41.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 233.1090s / 232325.3089 s
env0_first_0:                 episode reward: -18.8500,                 loss: 6.2855
env0_second_0:                 episode reward: 18.8500,                 loss: 4.5185
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 20541/50000 (41.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 230.3481s / 232555.6571 s
env0_first_0:                 episode reward: -15.5500,                 loss: 6.0303
env0_second_0:                 episode reward: 15.5500,                 loss: 4.5183
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 20561/50000 (41.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 233.4787s / 232789.1358 s
env0_first_0:                 episode reward: -29.9500,                 loss: 6.1779
env0_second_0:                 episode reward: 29.9500,                 loss: 4.4385
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 20581/50000 (41.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.5092s / 233021.6450 s
env0_first_0:                 episode reward: -23.8500,                 loss: 6.2403
env0_second_0:                 episode reward: 23.8500,                 loss: 4.5939
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 20601/50000 (41.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 230.9177s / 233252.5627 s
env0_first_0:                 episode reward: -34.0500,                 loss: 6.1179
env0_second_0:                 episode reward: 34.0500,                 loss: 4.2832
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 20621/50000 (41.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 232.2464s / 233484.8091 s
env0_first_0:                 episode reward: -22.1000,                 loss: 6.3593
env0_second_0:                 episode reward: 22.1000,                 loss: 4.5007
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 20641/50000 (41.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 232.0676s / 233716.8768 s
env0_first_0:                 episode reward: -5.2500,                 loss: 6.4994
env0_second_0:                 episode reward: 5.2500,                 loss: 4.5261
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 20661/50000 (41.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 233.6023s / 233950.4791 s
env0_first_0:                 episode reward: -14.0500,                 loss: 6.5137
env0_second_0:                 episode reward: 14.0500,                 loss: 4.3091
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 20681/50000 (41.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 232.3189s / 234182.7980 s
env0_first_0:                 episode reward: -13.1500,                 loss: 6.6877
env0_second_0:                 episode reward: 13.1500,                 loss: 4.5139
env1_first_0:                 episode reward: -5.4500,                 loss: nan
env1_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 20701/50000 (41.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 232.6280s / 234415.4259 s
env0_first_0:                 episode reward: -10.4500,                 loss: 6.4939
env0_second_0:                 episode reward: 10.4500,                 loss: 4.5701
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 20721/50000 (41.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 230.6042s / 234646.0301 s
env0_first_0:                 episode reward: -12.5500,                 loss: 6.7953
env0_second_0:                 episode reward: 12.5500,                 loss: 4.5282
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 20741/50000 (41.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 235.3127s / 234881.3429 s
env0_first_0:                 episode reward: -28.3500,                 loss: 6.6639
env0_second_0:                 episode reward: 28.3500,                 loss: 4.5297
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 20761/50000 (41.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.1169s / 235116.4598 s
env0_first_0:                 episode reward: -19.6500,                 loss: 6.5026
env0_second_0:                 episode reward: 19.6500,                 loss: 4.4812
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 20781/50000 (41.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 234.1301s / 235350.5899 s
env0_first_0:                 episode reward: -25.8500,                 loss: 6.3852
env0_second_0:                 episode reward: 25.8500,                 loss: 4.4762
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 20801/50000 (41.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 231.1982s / 235581.7881 s
env0_first_0:                 episode reward: -16.3000,                 loss: 6.1960
env0_second_0:                 episode reward: 16.3000,                 loss: 4.4726
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 20821/50000 (41.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 235.9042s / 235817.6923 s
env0_first_0:                 episode reward: 2.5000,                 loss: 6.0421
env0_second_0:                 episode reward: -2.5000,                 loss: 4.4061
env1_first_0:                 episode reward: -30.6000,                 loss: nan
env1_second_0:                 episode reward: 30.6000,                 loss: nan
Episode: 20841/50000 (41.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.4949s / 236051.1873 s
env0_first_0:                 episode reward: -16.0500,                 loss: 6.1086
env0_second_0:                 episode reward: 16.0500,                 loss: 4.3039
env1_first_0:                 episode reward: -28.8500,                 loss: nan
env1_second_0:                 episode reward: 28.8500,                 loss: nan
Episode: 20861/50000 (41.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 231.0806s / 236282.2679 s
env0_first_0:                 episode reward: -17.9500,                 loss: 5.9293
env0_second_0:                 episode reward: 17.9500,                 loss: 4.3295
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 20881/50000 (41.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 231.9472s / 236514.2151 s
env0_first_0:                 episode reward: -25.1500,                 loss: 6.0685
env0_second_0:                 episode reward: 25.1500,                 loss: 4.1900
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 20901/50000 (41.8020%),                 avg. length: 149.0,                last time consumption/overall running time: 233.3457s / 236747.5609 s
env0_first_0:                 episode reward: -17.1500,                 loss: 5.9875
env0_second_0:                 episode reward: 17.1500,                 loss: 4.2632
env1_first_0:                 episode reward: -22.9500,                 loss: nan
env1_second_0:                 episode reward: 22.9500,                 loss: nan
Episode: 20921/50000 (41.8420%),                 avg. length: 149.0,                last time consumption/overall running time: 233.6986s / 236981.2594 s
env0_first_0:                 episode reward: -12.7000,                 loss: 6.0095
env0_second_0:                 episode reward: 12.7000,                 loss: 4.1705
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 20941/50000 (41.8820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.4096s / 237214.6691 s
env0_first_0:                 episode reward: -11.8500,                 loss: 6.0489
env0_second_0:                 episode reward: 11.8500,                 loss: 4.0562
env1_first_0:                 episode reward: -17.7000,                 loss: nan
env1_second_0:                 episode reward: 17.7000,                 loss: nan
Episode: 20961/50000 (41.9220%),                 avg. length: 149.0,                last time consumption/overall running time: 234.1882s / 237448.8573 s
env0_first_0:                 episode reward: -18.6000,                 loss: 5.9355
env0_second_0:                 episode reward: 18.6000,                 loss: 4.3221
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 20981/50000 (41.9620%),                 avg. length: 149.0,                last time consumption/overall running time: 234.1118s / 237682.9691 s
env0_first_0:                 episode reward: -15.8500,                 loss: 5.8198
env0_second_0:                 episode reward: 15.8500,                 loss: 4.2356
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 21001/50000 (42.0020%),                 avg. length: 149.0,                last time consumption/overall running time: 234.6616s / 237917.6307 s
env0_first_0:                 episode reward: -0.5500,                 loss: 5.8058
env0_second_0:                 episode reward: 0.5500,                 loss: 4.5612
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 21021/50000 (42.0420%),                 avg. length: 149.0,                last time consumption/overall running time: 233.1730s / 238150.8037 s
env0_first_0:                 episode reward: -11.5500,                 loss: 5.7139
env0_second_0:                 episode reward: 11.5500,                 loss: 4.5798
env1_first_0:                 episode reward: -32.6500,                 loss: nan
env1_second_0:                 episode reward: 32.6500,                 loss: nan
Episode: 21041/50000 (42.0820%),                 avg. length: 149.0,                last time consumption/overall running time: 234.3999s / 238385.2035 s
env0_first_0:                 episode reward: -25.7500,                 loss: 6.0192
env0_second_0:                 episode reward: 25.7500,                 loss: 4.5695
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 21061/50000 (42.1220%),                 avg. length: 149.0,                last time consumption/overall running time: 234.8878s / 238620.0913 s
env0_first_0:                 episode reward: -11.9000,                 loss: 5.6596
env0_second_0:                 episode reward: 11.9000,                 loss: 4.6212
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 21081/50000 (42.1620%),                 avg. length: 149.0,                last time consumption/overall running time: 231.4092s / 238851.5005 s
env0_first_0:                 episode reward: -5.8000,                 loss: 5.9221
env0_second_0:                 episode reward: 5.8000,                 loss: 4.4943
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 21101/50000 (42.2020%),                 avg. length: 149.0,                last time consumption/overall running time: 233.3136s / 239084.8141 s
env0_first_0:                 episode reward: -17.5000,                 loss: 5.8417
env0_second_0:                 episode reward: 17.5000,                 loss: 4.3308
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 21121/50000 (42.2420%),                 avg. length: 149.0,                last time consumption/overall running time: 232.5869s / 239317.4010 s
env0_first_0:                 episode reward: -16.7000,                 loss: 5.6575
env0_second_0:                 episode reward: 16.7000,                 loss: 4.3313
env1_first_0:                 episode reward: -27.4500,                 loss: nan
env1_second_0:                 episode reward: 27.4500,                 loss: nan
Episode: 21141/50000 (42.2820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.0948s / 239553.4958 s
env0_first_0:                 episode reward: -6.8500,                 loss: 5.7880
env0_second_0:                 episode reward: 6.8500,                 loss: 4.2627
env1_first_0:                 episode reward: -26.2500,                 loss: nan
env1_second_0:                 episode reward: 26.2500,                 loss: nan
Episode: 21161/50000 (42.3220%),                 avg. length: 149.0,                last time consumption/overall running time: 232.9533s / 239786.4491 s
env0_first_0:                 episode reward: -22.4500,                 loss: 5.7605
env0_second_0:                 episode reward: 22.4500,                 loss: 4.3276
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 21181/50000 (42.3620%),                 avg. length: 149.0,                last time consumption/overall running time: 235.7777s / 240022.2268 s
env0_first_0:                 episode reward: -19.7000,                 loss: 5.9766
env0_second_0:                 episode reward: 19.7000,                 loss: 4.2641
env1_first_0:                 episode reward: -28.1000,                 loss: nan
env1_second_0:                 episode reward: 28.1000,                 loss: nan
Episode: 21201/50000 (42.4020%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6421s / 240258.8688 s
env0_first_0:                 episode reward: -7.6500,                 loss: 6.1146
env0_second_0:                 episode reward: 7.6500,                 loss: 4.3789
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 21221/50000 (42.4420%),                 avg. length: 149.0,                last time consumption/overall running time: 237.3327s / 240496.2016 s
env0_first_0:                 episode reward: -20.3500,                 loss: 6.1705
env0_second_0:                 episode reward: 20.3500,                 loss: 4.2387
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 21241/50000 (42.4820%),                 avg. length: 149.0,                last time consumption/overall running time: 236.6977s / 240732.8992 s
env0_first_0:                 episode reward: 6.6000,                 loss: 6.0298
env0_second_0:                 episode reward: -6.6000,                 loss: 4.2364
env1_first_0:                 episode reward: -26.1000,                 loss: nan
env1_second_0:                 episode reward: 26.1000,                 loss: nan
Episode: 21261/50000 (42.5220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.5995s / 240968.4988 s
env0_first_0:                 episode reward: -28.2500,                 loss: 6.2415
env0_second_0:                 episode reward: 28.2500,                 loss: 4.3494
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 21281/50000 (42.5620%),                 avg. length: 149.0,                last time consumption/overall running time: 234.6712s / 241203.1699 s
env0_first_0:                 episode reward: -26.1500,                 loss: 6.1501
env0_second_0:                 episode reward: 26.1500,                 loss: 4.3657
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 21301/50000 (42.6020%),                 avg. length: 149.0,                last time consumption/overall running time: 235.9202s / 241439.0901 s
env0_first_0:                 episode reward: -21.0500,                 loss: 6.3088
env0_second_0:                 episode reward: 21.0500,                 loss: 4.5572
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 21321/50000 (42.6420%),                 avg. length: 149.0,                last time consumption/overall running time: 232.5900s / 241671.6801 s
env0_first_0:                 episode reward: -11.0500,                 loss: 6.0720
env0_second_0:                 episode reward: 11.0500,                 loss: 4.3136
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 21341/50000 (42.6820%),                 avg. length: 149.0,                last time consumption/overall running time: 233.5450s / 241905.2251 s
env0_first_0:                 episode reward: -19.0500,                 loss: 5.7730
env0_second_0:                 episode reward: 19.0500,                 loss: 4.1892
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 21361/50000 (42.7220%),                 avg. length: 149.0,                last time consumption/overall running time: 235.3270s / 242140.5521 s
env0_first_0:                 episode reward: -20.1500,                 loss: 6.2196
env0_second_0:                 episode reward: 20.1500,                 loss: 4.4876
env1_first_0:                 episode reward: -17.4000,                 loss: nan
env1_second_0:                 episode reward: 17.4000,                 loss: nan
Episode: 21381/50000 (42.7620%),                 avg. length: 149.0,                last time consumption/overall running time: 233.0680s / 242373.6201 s