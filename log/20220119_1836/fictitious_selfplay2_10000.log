pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f3792950400>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2]]
Load checkpoints (policy family):  [['50' '5253' '7615' '8835' '9107']
 ['193' '5289' '7712' '9011' '9134']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_10000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220117153310_exploit_10000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220117153310_exploit_10000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0211s / 0.0211 s
agent0:                 episode reward: -1.6930,                 loss: nan
agent1:                 episode reward: 1.6930,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0421s / 0.0633 s
agent0:                 episode reward: 0.3830,                 loss: nan
agent1:                 episode reward: -0.3830,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0409s / 0.1042 s
agent0:                 episode reward: -0.0247,                 loss: nan
agent1:                 episode reward: 0.0247,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0392s / 0.1433 s
agent0:                 episode reward: -0.1160,                 loss: nan
agent1:                 episode reward: 0.1160,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0392s / 0.1825 s
agent0:                 episode reward: -0.1189,                 loss: nan
agent1:                 episode reward: 0.1189,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0398s / 0.2223 s
agent0:                 episode reward: -0.2137,                 loss: nan
agent1:                 episode reward: 0.2137,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0397s / 0.2620 s
agent0:                 episode reward: 0.1047,                 loss: nan
agent1:                 episode reward: -0.1047,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0404s / 0.3024 s
agent0:                 episode reward: 0.5073,                 loss: nan
agent1:                 episode reward: -0.5073,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0417s / 0.3441 s
agent0:                 episode reward: -0.0052,                 loss: nan
agent1:                 episode reward: 0.0052,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0400s / 0.3841 s
agent0:                 episode reward: 0.0666,                 loss: nan
agent1:                 episode reward: -0.0666,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0398s / 0.4239 s
agent0:                 episode reward: -0.1844,                 loss: nan
agent1:                 episode reward: 0.1844,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0999s / 0.5238 s
agent0:                 episode reward: -0.4971,                 loss: nan
agent1:                 episode reward: 0.4971,                 loss: 0.2386
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1477s / 0.6715 s
agent0:                 episode reward: 0.3846,                 loss: nan
agent1:                 episode reward: -0.3846,                 loss: 0.2121
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1499s / 0.8214 s
agent0:                 episode reward: 0.1118,                 loss: nan
agent1:                 episode reward: -0.1118,                 loss: 0.1884
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1520s / 0.9733 s
agent0:                 episode reward: -0.0286,                 loss: nan
agent1:                 episode reward: 0.0286,                 loss: 0.1823
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1624s / 1.1358 s
agent0:                 episode reward: -0.1210,                 loss: nan
agent1:                 episode reward: 0.1210,                 loss: 0.1763
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1691s / 1.3049 s
agent0:                 episode reward: 0.0764,                 loss: nan
agent1:                 episode reward: -0.0764,                 loss: 0.1729
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1556s / 1.4605 s
agent0:                 episode reward: 0.0267,                 loss: nan
agent1:                 episode reward: -0.0267,                 loss: 0.1725
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1554s / 1.6160 s
agent0:                 episode reward: 0.2612,                 loss: nan
agent1:                 episode reward: -0.2612,                 loss: 0.1698
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1562s / 1.7722 s
agent0:                 episode reward: -0.1401,                 loss: nan
agent1:                 episode reward: 0.1401,                 loss: 0.1682
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1834s / 1.9555 s
agent0:                 episode reward: 0.0049,                 loss: nan
agent1:                 episode reward: -0.0049,                 loss: 0.1655
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1622s / 2.1177 s
agent0:                 episode reward: -0.2243,                 loss: nan
agent1:                 episode reward: 0.2243,                 loss: 0.1650
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1548s / 2.2725 s
agent0:                 episode reward: -0.4316,                 loss: nan
agent1:                 episode reward: 0.4316,                 loss: 0.1618
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1727s / 2.4452 s
agent0:                 episode reward: 0.1192,                 loss: nan
agent1:                 episode reward: -0.1192,                 loss: 0.1593
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1581s / 2.6033 s
agent0:                 episode reward: -0.0157,                 loss: nan
agent1:                 episode reward: 0.0157,                 loss: 0.1556
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1549s / 2.7582 s
agent0:                 episode reward: -0.0432,                 loss: nan
agent1:                 episode reward: 0.0432,                 loss: 0.1523
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1541s / 2.9123 s
agent0:                 episode reward: 0.0128,                 loss: nan
agent1:                 episode reward: -0.0128,                 loss: 0.1522
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1540s / 3.0663 s
agent0:                 episode reward: -0.2256,                 loss: nan
agent1:                 episode reward: 0.2256,                 loss: 0.1493
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1534s / 3.2197 s
agent0:                 episode reward: 0.1531,                 loss: nan
agent1:                 episode reward: -0.1531,                 loss: 0.1660
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1565s / 3.3762 s
agent0:                 episode reward: -0.0902,                 loss: nan
agent1:                 episode reward: 0.0902,                 loss: 0.1548
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1552s / 3.5314 s
agent0:                 episode reward: -0.3371,                 loss: nan
agent1:                 episode reward: 0.3371,                 loss: 0.1509
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1555s / 3.6868 s
agent0:                 episode reward: -0.2351,                 loss: nan
agent1:                 episode reward: 0.2351,                 loss: 0.1490
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1545s / 3.8414 s
agent0:                 episode reward: -0.0141,                 loss: nan
agent1:                 episode reward: 0.0141,                 loss: 0.1491
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1564s / 3.9978 s
agent0:                 episode reward: -0.3256,                 loss: nan
agent1:                 episode reward: 0.3256,                 loss: 0.1459
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1820s / 4.1798 s
agent0:                 episode reward: 0.2862,                 loss: nan
agent1:                 episode reward: -0.2862,                 loss: 0.1466
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1745s / 4.3542 s
agent0:                 episode reward: -0.4221,                 loss: nan
agent1:                 episode reward: 0.4221,                 loss: 0.1459
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1521s / 4.5064 s
agent0:                 episode reward: 0.1902,                 loss: nan
agent1:                 episode reward: -0.1902,                 loss: 0.1458
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1564s / 4.6628 s
agent0:                 episode reward: -0.0220,                 loss: nan
agent1:                 episode reward: 0.0220,                 loss: 0.1450
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1550s / 4.8177 s
agent0:                 episode reward: 0.2898,                 loss: nan
agent1:                 episode reward: -0.2898,                 loss: 0.1449
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1554s / 4.9731 s
agent0:                 episode reward: -0.1748,                 loss: nan
agent1:                 episode reward: 0.1748,                 loss: 0.1449
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1547s / 5.1278 s
agent0:                 episode reward: -0.0047,                 loss: nan
agent1:                 episode reward: 0.0047,                 loss: 0.1437
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1554s / 5.2833 s
agent0:                 episode reward: -0.1636,                 loss: nan
agent1:                 episode reward: 0.1636,                 loss: 0.1432
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1546s / 5.4379 s
agent0:                 episode reward: -0.0606,                 loss: nan
agent1:                 episode reward: 0.0606,                 loss: 0.1435
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1534s / 5.5912 s
agent0:                 episode reward: -0.5215,                 loss: nan
agent1:                 episode reward: 0.5215,                 loss: 0.1432
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1552s / 5.7464 s
agent0:                 episode reward: -0.1229,                 loss: nan
agent1:                 episode reward: 0.1229,                 loss: 0.1432
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1509s / 5.8972 s
agent0:                 episode reward: -0.0629,                 loss: nan
agent1:                 episode reward: 0.0629,                 loss: 0.1471
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1537s / 6.0509 s
agent0:                 episode reward: -0.0254,                 loss: nan
agent1:                 episode reward: 0.0254,                 loss: 0.1473
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1530s / 6.2039 s
agent0:                 episode reward: 0.3392,                 loss: nan
agent1:                 episode reward: -0.3392,                 loss: 0.1482
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1564s / 6.3603 s
agent0:                 episode reward: -0.2056,                 loss: nan
agent1:                 episode reward: 0.2056,                 loss: 0.1494
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1512s / 6.5116 s
agent0:                 episode reward: -0.0661,                 loss: nan
agent1:                 episode reward: 0.0661,                 loss: 0.1477
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1528s / 6.6644 s
agent0:                 episode reward: 0.0374,                 loss: nan
agent1:                 episode reward: -0.0374,                 loss: 0.1475
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1552s / 6.8196 s
agent0:                 episode reward: 0.0175,                 loss: nan
agent1:                 episode reward: -0.0175,                 loss: 0.1501
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1552s / 6.9748 s
agent0:                 episode reward: 0.1395,                 loss: nan
agent1:                 episode reward: -0.1395,                 loss: 0.1485
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1683s / 7.1431 s
agent0:                 episode reward: 0.1861,                 loss: nan
agent1:                 episode reward: -0.1861,                 loss: 0.1485
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2314s / 7.3745 s
agent0:                 episode reward: 0.0839,                 loss: nan
agent1:                 episode reward: -0.0839,                 loss: 0.1492
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1692s / 7.5437 s
agent0:                 episode reward: 0.3782,                 loss: nan
agent1:                 episode reward: -0.3782,                 loss: 0.1495
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1822s / 7.7259 s
agent0:                 episode reward: -0.0864,                 loss: nan
agent1:                 episode reward: 0.0864,                 loss: 0.1474
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1812s / 7.9070 s
agent0:                 episode reward: 0.1806,                 loss: nan
agent1:                 episode reward: -0.1806,                 loss: 0.1478
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1695s / 8.0765 s
agent0:                 episode reward: 0.0085,                 loss: nan
agent1:                 episode reward: -0.0085,                 loss: 0.1482
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1646s / 8.2412 s
agent0:                 episode reward: -0.0928,                 loss: nan
agent1:                 episode reward: 0.0928,                 loss: 0.1477
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1627s / 8.4039 s
agent0:                 episode reward: -0.3079,                 loss: nan
agent1:                 episode reward: 0.3079,                 loss: 0.1489
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1688s / 8.5726 s
agent0:                 episode reward: -0.4019,                 loss: nan
agent1:                 episode reward: 0.4019,                 loss: 0.1469
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1590s / 8.7317 s
agent0:                 episode reward: -0.0039,                 loss: nan
agent1:                 episode reward: 0.0039,                 loss: 0.1460
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1582s / 8.8899 s
agent0:                 episode reward: -0.2260,                 loss: nan
agent1:                 episode reward: 0.2260,                 loss: 0.1449
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1606s / 9.0504 s
agent0:                 episode reward: -0.1106,                 loss: nan
agent1:                 episode reward: 0.1106,                 loss: 0.1452
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1620s / 9.2125 s
agent0:                 episode reward: 0.4748,                 loss: nan
agent1:                 episode reward: -0.4748,                 loss: 0.1448
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1616s / 9.3741 s
agent0:                 episode reward: -0.3618,                 loss: nan
agent1:                 episode reward: 0.3618,                 loss: 0.1456
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1573s / 9.5314 s
agent0:                 episode reward: -0.0771,                 loss: nan
agent1:                 episode reward: 0.0771,                 loss: 0.1434
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1565s / 9.6879 s
agent0:                 episode reward: -0.0686,                 loss: nan
agent1:                 episode reward: 0.0686,                 loss: 0.1449
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1600s / 9.8480 s
agent0:                 episode reward: -0.5229,                 loss: nan
agent1:                 episode reward: 0.5229,                 loss: 0.1462
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1616s / 10.0096 s
agent0:                 episode reward: 0.4220,                 loss: nan
agent1:                 episode reward: -0.4220,                 loss: 0.1456
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1723s / 10.1819 s
agent0:                 episode reward: -0.2965,                 loss: nan
agent1:                 episode reward: 0.2965,                 loss: 0.1465
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1875s / 10.3695 s
agent0:                 episode reward: 0.0169,                 loss: nan
agent1:                 episode reward: -0.0169,                 loss: 0.1448
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1874s / 10.5569 s
agent0:                 episode reward: -0.4336,                 loss: nan
agent1:                 episode reward: 0.4336,                 loss: 0.1441
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1743s / 10.7312 s
agent0:                 episode reward: 0.0352,                 loss: nan
agent1:                 episode reward: -0.0352,                 loss: 0.1449
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1715s / 10.9028 s
agent0:                 episode reward: 0.0879,                 loss: nan
agent1:                 episode reward: -0.0879,                 loss: 0.1438
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1653s / 11.0680 s
agent0:                 episode reward: -0.1703,                 loss: nan
agent1:                 episode reward: 0.1703,                 loss: 0.1424
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1695s / 11.2376 s
agent0:                 episode reward: -0.1903,                 loss: nan
agent1:                 episode reward: 0.1903,                 loss: 0.1439
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1617s / 11.3992 s
agent0:                 episode reward: -0.0914,                 loss: nan
agent1:                 episode reward: 0.0914,                 loss: 0.1436
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1633s / 11.5626 s
agent0:                 episode reward: -0.1899,                 loss: nan
agent1:                 episode reward: 0.1899,                 loss: 0.1439
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1650s / 11.7276 s
agent0:                 episode reward: -0.0750,                 loss: nan
agent1:                 episode reward: 0.0750,                 loss: 0.1433
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1649s / 11.8925 s
agent0:                 episode reward: -0.0620,                 loss: nan
agent1:                 episode reward: 0.0620,                 loss: 0.1430
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1676s / 12.0601 s
agent0:                 episode reward: -0.2338,                 loss: nan
agent1:                 episode reward: 0.2338,                 loss: 0.1426
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1664s / 12.2265 s
agent0:                 episode reward: -0.3100,                 loss: nan
agent1:                 episode reward: 0.3100,                 loss: 0.1429
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1636s / 12.3900 s
agent0:                 episode reward: -0.4036,                 loss: nan
agent1:                 episode reward: 0.4036,                 loss: 0.1427
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1610s / 12.5510 s
agent0:                 episode reward: -0.2105,                 loss: nan
agent1:                 episode reward: 0.2105,                 loss: 0.1416
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1622s / 12.7132 s
agent0:                 episode reward: -0.6338,                 loss: nan
agent1:                 episode reward: 0.6338,                 loss: 0.1417
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1633s / 12.8765 s
agent0:                 episode reward: -0.1965,                 loss: nan
agent1:                 episode reward: 0.1965,                 loss: 0.1443
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1653s / 13.0418 s
agent0:                 episode reward: 0.1426,                 loss: nan
agent1:                 episode reward: -0.1426,                 loss: 0.1424
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 13.2404 s
agent0:                 episode reward: -0.3477,                 loss: nan
agent1:                 episode reward: 0.3477,                 loss: 0.1427
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2370s / 13.4773 s
agent0:                 episode reward: 0.1116,                 loss: nan
agent1:                 episode reward: -0.1116,                 loss: 0.1427
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 13.6792 s
agent0:                 episode reward: -0.0327,                 loss: nan
agent1:                 episode reward: 0.0327,                 loss: 0.1432
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1688s / 13.8480 s
agent0:                 episode reward: -0.4621,                 loss: nan
agent1:                 episode reward: 0.4621,                 loss: 0.1429
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1697s / 14.0177 s
agent0:                 episode reward: -0.0197,                 loss: nan
agent1:                 episode reward: 0.0197,                 loss: 0.1414
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2107s / 14.2284 s
agent0:                 episode reward: 0.0082,                 loss: nan
agent1:                 episode reward: -0.0082,                 loss: 0.1422
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1843s / 14.4127 s
agent0:                 episode reward: 0.0628,                 loss: nan
agent1:                 episode reward: -0.0628,                 loss: 0.1428
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1724s / 14.5851 s
agent0:                 episode reward: -0.1391,                 loss: nan
agent1:                 episode reward: 0.1391,                 loss: 0.1441
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1649s / 14.7501 s
agent0:                 episode reward: 0.1244,                 loss: nan
agent1:                 episode reward: -0.1244,                 loss: 0.1446
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1617s / 14.9118 s
agent0:                 episode reward: -0.1724,                 loss: nan
agent1:                 episode reward: 0.1724,                 loss: 0.1441
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1605s / 15.0723 s
agent0:                 episode reward: -0.5701,                 loss: nan
agent1:                 episode reward: 0.5701,                 loss: 0.1435
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1644s / 15.2367 s
agent0:                 episode reward: -0.0796,                 loss: nan
agent1:                 episode reward: 0.0796,                 loss: 0.1435
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1712s / 15.4079 s
agent0:                 episode reward: 0.1034,                 loss: nan
agent1:                 episode reward: -0.1034,                 loss: 0.1447
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1655s / 15.5734 s
agent0:                 episode reward: -0.3942,                 loss: nan
agent1:                 episode reward: 0.3942,                 loss: 0.1449
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1674s / 15.7408 s
agent0:                 episode reward: 0.1296,                 loss: nan
agent1:                 episode reward: -0.1296,                 loss: 0.1439
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1731s / 15.9139 s
agent0:                 episode reward: 0.1503,                 loss: nan
agent1:                 episode reward: -0.1503,                 loss: 0.1449
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1688s / 16.0827 s
agent0:                 episode reward: -0.4010,                 loss: nan
agent1:                 episode reward: 0.4010,                 loss: 0.1450
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1721s / 16.2548 s
agent0:                 episode reward: 0.3436,                 loss: nan
agent1:                 episode reward: -0.3436,                 loss: 0.1449
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2199s / 16.4747 s
agent0:                 episode reward: 0.2576,                 loss: nan
agent1:                 episode reward: -0.2576,                 loss: 0.1436
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 16.6785 s
agent0:                 episode reward: 0.0495,                 loss: nan
agent1:                 episode reward: -0.0495,                 loss: 0.1420
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1834s / 16.8619 s
agent0:                 episode reward: -0.2325,                 loss: nan
agent1:                 episode reward: 0.2325,                 loss: 0.1431
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1714s / 17.0333 s
agent0:                 episode reward: 0.1160,                 loss: nan
agent1:                 episode reward: -0.1160,                 loss: 0.1449
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1722s / 17.2056 s
agent0:                 episode reward: 0.0043,                 loss: nan
agent1:                 episode reward: -0.0043,                 loss: 0.1460
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1734s / 17.3790 s
agent0:                 episode reward: -0.1119,                 loss: nan
agent1:                 episode reward: 0.1119,                 loss: 0.1463
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1754s / 17.5544 s
agent0:                 episode reward: -0.3350,                 loss: nan
agent1:                 episode reward: 0.3350,                 loss: 0.1470
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1816s / 17.7360 s
agent0:                 episode reward: -0.1211,                 loss: nan
agent1:                 episode reward: 0.1211,                 loss: 0.1461
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2137s / 17.9497 s
agent0:                 episode reward: -0.0066,                 loss: nan
agent1:                 episode reward: 0.0066,                 loss: 0.1463
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 18.1454 s
agent0:                 episode reward: 0.1438,                 loss: nan
agent1:                 episode reward: -0.1438,                 loss: 0.1460
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1808s / 18.3262 s
agent0:                 episode reward: -0.0212,                 loss: nan
agent1:                 episode reward: 0.0212,                 loss: 0.1468
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 18.5295 s
agent0:                 episode reward: -0.4288,                 loss: nan
agent1:                 episode reward: 0.4288,                 loss: 0.1465
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1835s / 18.7130 s
agent0:                 episode reward: -0.0257,                 loss: nan
agent1:                 episode reward: 0.0257,                 loss: 0.1457
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1728s / 18.8858 s
agent0:                 episode reward: 0.2088,                 loss: nan
agent1:                 episode reward: -0.2088,                 loss: 0.1467
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1884s / 19.0743 s
agent0:                 episode reward: 0.2145,                 loss: nan
agent1:                 episode reward: -0.2145,                 loss: 0.1469
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1637s / 19.2380 s
agent0:                 episode reward: -0.3954,                 loss: nan
agent1:                 episode reward: 0.3954,                 loss: 0.1442
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1863s / 19.4243 s
agent0:                 episode reward: -0.0518,                 loss: nan
agent1:                 episode reward: 0.0518,                 loss: 0.1443
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1908s / 19.6151 s
agent0:                 episode reward: -0.1380,                 loss: nan
agent1:                 episode reward: 0.1380,                 loss: 0.1447
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1753s / 19.7904 s
agent0:                 episode reward: -0.2393,                 loss: nan
agent1:                 episode reward: 0.2393,                 loss: 0.1448
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1720s / 19.9624 s
agent0:                 episode reward: -0.0728,                 loss: nan
agent1:                 episode reward: 0.0728,                 loss: 0.1448
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1731s / 20.1355 s
agent0:                 episode reward: -0.1129,                 loss: nan
agent1:                 episode reward: 0.1129,                 loss: 0.1461
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1707s / 20.3062 s
agent0:                 episode reward: 0.2066,                 loss: nan
agent1:                 episode reward: -0.2066,                 loss: 0.1444
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1717s / 20.4779 s
agent0:                 episode reward: 0.4213,                 loss: nan
agent1:                 episode reward: -0.4213,                 loss: 0.1446
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1674s / 20.6453 s
agent0:                 episode reward: -0.1968,                 loss: nan
agent1:                 episode reward: 0.1968,                 loss: 0.1446
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1638s / 20.8091 s
agent0:                 episode reward: -0.3104,                 loss: nan
agent1:                 episode reward: 0.3104,                 loss: 0.1447
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1670s / 20.9761 s
agent0:                 episode reward: 0.3239,                 loss: nan
agent1:                 episode reward: -0.3239,                 loss: 0.1446
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1662s / 21.1423 s
agent0:                 episode reward: -0.1342,                 loss: nan
agent1:                 episode reward: 0.1342,                 loss: 0.1454
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1779s / 21.3202 s
agent0:                 episode reward: 0.2941,                 loss: nan
agent1:                 episode reward: -0.2941,                 loss: 0.1439
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1804s / 21.5006 s
agent0:                 episode reward: 0.2607,                 loss: nan
agent1:                 episode reward: -0.2607,                 loss: 0.1451
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1813s / 21.6819 s
agent0:                 episode reward: 0.0521,                 loss: nan
agent1:                 episode reward: -0.0521,                 loss: 0.1432
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 21.8751 s
agent0:                 episode reward: -0.4172,                 loss: nan
agent1:                 episode reward: 0.4172,                 loss: 0.1437
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1845s / 22.0595 s
agent0:                 episode reward: -0.1916,                 loss: nan
agent1:                 episode reward: 0.1916,                 loss: 0.1432
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1848s / 22.2444 s
agent0:                 episode reward: -0.3877,                 loss: nan
agent1:                 episode reward: 0.3877,                 loss: 0.1416
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2307s / 22.4750 s
agent0:                 episode reward: -0.1974,                 loss: nan
agent1:                 episode reward: 0.1974,                 loss: 0.1437
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2045s / 22.6795 s
agent0:                 episode reward: -0.0287,                 loss: nan
agent1:                 episode reward: 0.0287,                 loss: 0.1430
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1878s / 22.8673 s
agent0:                 episode reward: -0.3241,                 loss: nan
agent1:                 episode reward: 0.3241,                 loss: 0.1438
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1811s / 23.0484 s
agent0:                 episode reward: -0.1963,                 loss: nan
agent1:                 episode reward: 0.1963,                 loss: 0.1428
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1876s / 23.2360 s
agent0:                 episode reward: -0.1745,                 loss: nan
agent1:                 episode reward: 0.1745,                 loss: 0.1439
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1809s / 23.4168 s
agent0:                 episode reward: -0.2276,                 loss: nan
agent1:                 episode reward: 0.2276,                 loss: 0.1462
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1767s / 23.5935 s
agent0:                 episode reward: 0.0048,                 loss: nan
agent1:                 episode reward: -0.0048,                 loss: 0.1435
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1814s / 23.7749 s
agent0:                 episode reward: -0.1514,                 loss: nan
agent1:                 episode reward: 0.1514,                 loss: 0.1435
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1768s / 23.9517 s
agent0:                 episode reward: 0.1275,                 loss: nan
agent1:                 episode reward: -0.1275,                 loss: 0.1442
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1814s / 24.1331 s
agent0:                 episode reward: -0.0502,                 loss: nan
agent1:                 episode reward: 0.0502,                 loss: 0.1450
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1820s / 24.3151 s
agent0:                 episode reward: -0.0485,                 loss: nan
agent1:                 episode reward: 0.0485,                 loss: 0.1457
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1792s / 24.4943 s
agent0:                 episode reward: -0.0612,                 loss: nan
agent1:                 episode reward: 0.0612,                 loss: 0.1450
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1801s / 24.6744 s
agent0:                 episode reward: -0.1655,                 loss: nan
agent1:                 episode reward: 0.1655,                 loss: 0.1451
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1824s / 24.8568 s
agent0:                 episode reward: -0.3945,                 loss: nan
agent1:                 episode reward: 0.3945,                 loss: 0.1446
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1834s / 25.0403 s
agent0:                 episode reward: -0.1680,                 loss: nan
agent1:                 episode reward: 0.1680,                 loss: 0.1451
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1756s / 25.2159 s
agent0:                 episode reward: -0.2732,                 loss: nan
agent1:                 episode reward: 0.2732,                 loss: 0.1445
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1785s / 25.3944 s
agent0:                 episode reward: -0.2844,                 loss: nan
agent1:                 episode reward: 0.2844,                 loss: 0.1438
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2111s / 25.6055 s
agent0:                 episode reward: -0.4121,                 loss: nan
agent1:                 episode reward: 0.4121,                 loss: 0.1459
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2149s / 25.8204 s
agent0:                 episode reward: -0.3531,                 loss: nan
agent1:                 episode reward: 0.3531,                 loss: 0.1467
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1784s / 25.9988 s
agent0:                 episode reward: 0.2134,                 loss: nan
agent1:                 episode reward: -0.2134,                 loss: 0.1440
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1755s / 26.1743 s
agent0:                 episode reward: -0.3605,                 loss: nan
agent1:                 episode reward: 0.3605,                 loss: 0.1441
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1852s / 26.3594 s
agent0:                 episode reward: -0.4208,                 loss: nan
agent1:                 episode reward: 0.4208,                 loss: 0.1441
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1836s / 26.5430 s
agent0:                 episode reward: 0.1451,                 loss: nan
agent1:                 episode reward: -0.1451,                 loss: 0.1443
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1760s / 26.7190 s
agent0:                 episode reward: -0.0837,                 loss: nan
agent1:                 episode reward: 0.0837,                 loss: 0.1449
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1832s / 26.9023 s
agent0:                 episode reward: 0.1874,                 loss: nan
agent1:                 episode reward: -0.1874,                 loss: 0.1458
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1863s / 27.0886 s
agent0:                 episode reward: -0.4370,                 loss: nan
agent1:                 episode reward: 0.4370,                 loss: 0.1454
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 27.2815 s
agent0:                 episode reward: -0.1030,                 loss: nan
agent1:                 episode reward: 0.1030,                 loss: 0.1442
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 27.4856 s
agent0:                 episode reward: 0.0054,                 loss: nan
agent1:                 episode reward: -0.0054,                 loss: 0.1444
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1882s / 27.6738 s
agent0:                 episode reward: 0.2387,                 loss: nan
agent1:                 episode reward: -0.2387,                 loss: 0.1443
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1865s / 27.8603 s
agent0:                 episode reward: -0.2849,                 loss: nan
agent1:                 episode reward: 0.2849,                 loss: 0.1455
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 28.0563 s
agent0:                 episode reward: 0.1170,                 loss: nan
agent1:                 episode reward: -0.1170,                 loss: 0.1469
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2188s / 28.2752 s
agent0:                 episode reward: -0.0387,                 loss: nan
agent1:                 episode reward: 0.0387,                 loss: 0.1451
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2099s / 28.4851 s
agent0:                 episode reward: 0.1199,                 loss: nan
agent1:                 episode reward: -0.1199,                 loss: 0.1455
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2154s / 28.7005 s
agent0:                 episode reward: 0.0609,                 loss: nan
agent1:                 episode reward: -0.0609,                 loss: 0.1429
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2081s / 28.9086 s
agent0:                 episode reward: -0.1830,                 loss: nan
agent1:                 episode reward: 0.1830,                 loss: 0.1422
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1783s / 29.0869 s
agent0:                 episode reward: -0.3189,                 loss: nan
agent1:                 episode reward: 0.3189,                 loss: 0.1433
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1732s / 29.2601 s
agent0:                 episode reward: -0.1163,                 loss: nan
agent1:                 episode reward: 0.1163,                 loss: 0.1440
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1713s / 29.4314 s
agent0:                 episode reward: -0.0678,                 loss: nan
agent1:                 episode reward: 0.0678,                 loss: 0.1450
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1726s / 29.6040 s
agent0:                 episode reward: -0.1336,                 loss: nan
agent1:                 episode reward: 0.1336,                 loss: 0.1461
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1753s / 29.7793 s
agent0:                 episode reward: -0.4490,                 loss: nan
agent1:                 episode reward: 0.4490,                 loss: 0.1441
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1738s / 29.9531 s
agent0:                 episode reward: -0.1441,                 loss: nan
agent1:                 episode reward: 0.1441,                 loss: 0.1419
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1715s / 30.1246 s
agent0:                 episode reward: -0.5428,                 loss: nan
agent1:                 episode reward: 0.5428,                 loss: 0.1428
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1729s / 30.2975 s
agent0:                 episode reward: -0.1927,                 loss: nan
agent1:                 episode reward: 0.1927,                 loss: 0.1441
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1836s / 30.4811 s
agent0:                 episode reward: 0.1258,                 loss: nan
agent1:                 episode reward: -0.1258,                 loss: 0.1436
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1808s / 30.6619 s
agent0:                 episode reward: -0.1450,                 loss: nan
agent1:                 episode reward: 0.1450,                 loss: 0.1424
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1770s / 30.8389 s
agent0:                 episode reward: -0.0635,                 loss: nan
agent1:                 episode reward: 0.0635,                 loss: 0.1424
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1807s / 31.0196 s
agent0:                 episode reward: -0.2394,                 loss: nan
agent1:                 episode reward: 0.2394,                 loss: 0.1429
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2099s / 31.2295 s
agent0:                 episode reward: -0.3477,                 loss: nan
agent1:                 episode reward: 0.3477,                 loss: 0.1423
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 31.4346 s
agent0:                 episode reward: 0.0503,                 loss: nan
agent1:                 episode reward: -0.0503,                 loss: 0.1435
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2090s / 31.6437 s
agent0:                 episode reward: -0.5281,                 loss: nan
agent1:                 episode reward: 0.5281,                 loss: 0.1435
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2075s / 31.8511 s
agent0:                 episode reward: -0.0785,                 loss: nan
agent1:                 episode reward: 0.0785,                 loss: 0.1417
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 32.0443 s
agent0:                 episode reward: -0.5767,                 loss: nan
agent1:                 episode reward: 0.5767,                 loss: 0.1439
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1887s / 32.2330 s
agent0:                 episode reward: -0.1532,                 loss: nan
agent1:                 episode reward: 0.1532,                 loss: 0.1423
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1909s / 32.4240 s
agent0:                 episode reward: -0.2415,                 loss: nan
agent1:                 episode reward: 0.2415,                 loss: 0.1409
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1858s / 32.6098 s
agent0:                 episode reward: 0.1740,                 loss: nan
agent1:                 episode reward: -0.1740,                 loss: 0.1417
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1830s / 32.7928 s
agent0:                 episode reward: 0.1195,                 loss: nan
agent1:                 episode reward: -0.1195,                 loss: 0.1429
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1833s / 32.9761 s
agent0:                 episode reward: -0.3923,                 loss: nan
agent1:                 episode reward: 0.3923,                 loss: 0.1427
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1829s / 33.1590 s
agent0:                 episode reward: -0.1279,                 loss: nan
agent1:                 episode reward: 0.1279,                 loss: 0.1434
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1835s / 33.3424 s
agent0:                 episode reward: 0.0199,                 loss: nan
agent1:                 episode reward: -0.0199,                 loss: 0.1445
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1827s / 33.5251 s
agent0:                 episode reward: -0.2276,                 loss: nan
agent1:                 episode reward: 0.2276,                 loss: 0.1426
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1822s / 33.7073 s
agent0:                 episode reward: -0.1194,                 loss: nan
agent1:                 episode reward: 0.1194,                 loss: 0.1429
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1858s / 33.8931 s
agent0:                 episode reward: 0.0152,                 loss: nan
agent1:                 episode reward: -0.0152,                 loss: 0.1432
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1921s / 34.0852 s
agent0:                 episode reward: -0.9396,                 loss: nan
agent1:                 episode reward: 0.9396,                 loss: 0.1423
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1899s / 34.2751 s
agent0:                 episode reward: -0.5978,                 loss: nan
agent1:                 episode reward: 0.5978,                 loss: 0.1407
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1866s / 34.4618 s
agent0:                 episode reward: -0.5018,                 loss: nan
agent1:                 episode reward: 0.5018,                 loss: 0.1429
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1870s / 34.6487 s
agent0:                 episode reward: -0.3733,                 loss: nan
agent1:                 episode reward: 0.3733,                 loss: 0.1425
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2159s / 34.8647 s
agent0:                 episode reward: -0.3378,                 loss: nan
agent1:                 episode reward: 0.3378,                 loss: 0.1416
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 35.0656 s
agent0:                 episode reward: -0.4382,                 loss: nan
agent1:                 episode reward: 0.4382,                 loss: 0.1407
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1859s / 35.2515 s
agent0:                 episode reward: -0.5611,                 loss: nan
agent1:                 episode reward: 0.5611,                 loss: 0.1422
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1852s / 35.4367 s
agent0:                 episode reward: -0.3426,                 loss: nan
agent1:                 episode reward: 0.3426,                 loss: 0.1443
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 35.6369 s
agent0:                 episode reward: -0.2105,                 loss: nan
agent1:                 episode reward: 0.2105,                 loss: 0.1413
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 35.8327 s
agent0:                 episode reward: -0.1066,                 loss: nan
agent1:                 episode reward: 0.1066,                 loss: 0.1410
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 36.0299 s
agent0:                 episode reward: -0.0288,                 loss: nan
agent1:                 episode reward: 0.0288,                 loss: 0.1420
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 36.2305 s
agent0:                 episode reward: -0.3366,                 loss: nan
agent1:                 episode reward: 0.3366,                 loss: 0.1429
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1785s / 36.4090 s
agent0:                 episode reward: -0.7044,                 loss: nan
agent1:                 episode reward: 0.7044,                 loss: 0.1413
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1807s / 36.5897 s
agent0:                 episode reward: -0.1720,                 loss: nan
agent1:                 episode reward: 0.1720,                 loss: 0.1441
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1820s / 36.7716 s
agent0:                 episode reward: -0.2473,                 loss: nan
agent1:                 episode reward: 0.2473,                 loss: 0.1416
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1889s / 36.9605 s
agent0:                 episode reward: 0.4245,                 loss: nan
agent1:                 episode reward: -0.4245,                 loss: 0.1421
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1904s / 37.1509 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: 0.1419
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1862s / 37.3370 s
agent0:                 episode reward: -0.3338,                 loss: nan
agent1:                 episode reward: 0.3338,                 loss: 0.1424
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1883s / 37.5254 s
agent0:                 episode reward: -0.1730,                 loss: nan
agent1:                 episode reward: 0.1730,                 loss: 0.1420
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 37.7207 s
agent0:                 episode reward: -0.1784,                 loss: nan
agent1:                 episode reward: 0.1784,                 loss: 0.1425
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2163s / 37.9369 s
agent0:                 episode reward: -0.0778,                 loss: nan
agent1:                 episode reward: 0.0778,                 loss: 0.1419
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 38.1398 s
agent0:                 episode reward: 0.0661,                 loss: nan
agent1:                 episode reward: -0.0661,                 loss: 0.1417
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 38.3349 s
agent0:                 episode reward: -0.6675,                 loss: nan
agent1:                 episode reward: 0.6675,                 loss: 0.1430
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 38.5298 s
agent0:                 episode reward: -0.0236,                 loss: nan
agent1:                 episode reward: 0.0236,                 loss: 0.1420
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 38.7218 s
agent0:                 episode reward: 0.1018,                 loss: nan
agent1:                 episode reward: -0.1018,                 loss: 0.1426
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 38.9172 s
agent0:                 episode reward: -0.4988,                 loss: nan
agent1:                 episode reward: 0.4988,                 loss: 0.1408
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 39.1146 s
agent0:                 episode reward: -0.1578,                 loss: nan
agent1:                 episode reward: 0.1578,                 loss: 0.1431
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 39.3075 s
agent0:                 episode reward: -0.3768,                 loss: nan
agent1:                 episode reward: 0.3768,                 loss: 0.1415
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1850s / 39.4926 s
agent0:                 episode reward: -0.1304,                 loss: nan
agent1:                 episode reward: 0.1304,                 loss: 0.1425
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1894s / 39.6820 s
agent0:                 episode reward: 0.0438,                 loss: nan
agent1:                 episode reward: -0.0438,                 loss: 0.1440
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1848s / 39.8668 s
agent0:                 episode reward: -0.2978,                 loss: nan
agent1:                 episode reward: 0.2978,                 loss: 0.1429
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1886s / 40.0554 s
agent0:                 episode reward: -0.3725,                 loss: nan
agent1:                 episode reward: 0.3725,                 loss: 0.1430
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1926s / 40.2480 s
agent0:                 episode reward: -0.8062,                 loss: nan
agent1:                 episode reward: 0.8062,                 loss: 0.1426
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 40.4433 s
agent0:                 episode reward: -0.1441,                 loss: nan
agent1:                 episode reward: 0.1441,                 loss: 0.1436
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1903s / 40.6335 s
agent0:                 episode reward: -0.3752,                 loss: nan
agent1:                 episode reward: 0.3752,                 loss: 0.1421
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 40.8305 s
agent0:                 episode reward: -0.4904,                 loss: nan
agent1:                 episode reward: 0.4904,                 loss: 0.1445
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2117s / 41.0422 s
agent0:                 episode reward: -0.4581,                 loss: nan
agent1:                 episode reward: 0.4581,                 loss: 0.1417
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1870s / 41.2292 s
agent0:                 episode reward: -0.5362,                 loss: nan
agent1:                 episode reward: 0.5362,                 loss: 0.1415
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1868s / 41.4160 s
agent0:                 episode reward: -0.4635,                 loss: nan
agent1:                 episode reward: 0.4635,                 loss: 0.1433
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1869s / 41.6029 s
agent0:                 episode reward: 0.1472,                 loss: nan
agent1:                 episode reward: -0.1472,                 loss: 0.1417
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1841s / 41.7870 s
agent0:                 episode reward: -0.4680,                 loss: nan
agent1:                 episode reward: 0.4680,                 loss: 0.1425
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1838s / 41.9709 s
agent0:                 episode reward: -0.2130,                 loss: nan
agent1:                 episode reward: 0.2130,                 loss: 0.1431
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 42.1640 s
agent0:                 episode reward: -0.2793,                 loss: nan
agent1:                 episode reward: 0.2793,                 loss: 0.1436
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1911s / 42.3551 s
agent0:                 episode reward: -0.5729,                 loss: nan
agent1:                 episode reward: 0.5729,                 loss: 0.1425
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1840s / 42.5391 s
agent0:                 episode reward: 0.1345,                 loss: nan
agent1:                 episode reward: -0.1345,                 loss: 0.1429
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1831s / 42.7222 s
agent0:                 episode reward: -0.2216,                 loss: nan
agent1:                 episode reward: 0.2216,                 loss: 0.1431
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1882s / 42.9104 s
agent0:                 episode reward: -0.4250,                 loss: nan
agent1:                 episode reward: 0.4250,                 loss: 0.1433
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1879s / 43.0983 s
agent0:                 episode reward: -0.1796,                 loss: nan
agent1:                 episode reward: 0.1796,                 loss: 0.1424
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1923s / 43.2906 s
agent0:                 episode reward: -0.4277,                 loss: nan
agent1:                 episode reward: 0.4277,                 loss: 0.1408
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 43.4844 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.1418
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1934s / 43.6777 s
agent0:                 episode reward: -0.1416,                 loss: nan
agent1:                 episode reward: 0.1416,                 loss: 0.1420
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 43.8794 s
agent0:                 episode reward: -0.0120,                 loss: nan
agent1:                 episode reward: 0.0120,                 loss: 0.1438
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2462s / 44.1256 s
agent0:                 episode reward: -0.0002,                 loss: nan
agent1:                 episode reward: 0.0002,                 loss: 0.1415
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 44.3218 s
agent0:                 episode reward: -0.8364,                 loss: nan
agent1:                 episode reward: 0.8364,                 loss: 0.1424
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1907s / 44.5124 s
agent0:                 episode reward: -0.4789,                 loss: nan
agent1:                 episode reward: 0.4789,                 loss: 0.1402
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1878s / 44.7003 s
agent0:                 episode reward: -0.1737,                 loss: nan
agent1:                 episode reward: 0.1737,                 loss: 0.1413
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1897s / 44.8899 s
agent0:                 episode reward: 0.1279,                 loss: nan
agent1:                 episode reward: -0.1279,                 loss: 0.1428
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 45.0845 s
agent0:                 episode reward: 0.1065,                 loss: nan
agent1:                 episode reward: -0.1065,                 loss: 0.1437
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1861s / 45.2706 s
agent0:                 episode reward: 0.0147,                 loss: nan
agent1:                 episode reward: -0.0147,                 loss: 0.1414
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1885s / 45.4591 s
agent0:                 episode reward: -0.0735,                 loss: nan
agent1:                 episode reward: 0.0735,                 loss: 0.1409
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2098s / 45.6689 s
agent0:                 episode reward: -0.0470,                 loss: nan
agent1:                 episode reward: 0.0470,                 loss: 0.1425
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 45.8682 s
agent0:                 episode reward: -0.2669,                 loss: nan
agent1:                 episode reward: 0.2669,                 loss: 0.1435
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1946s / 46.0627 s
agent0:                 episode reward: -0.0088,                 loss: nan
agent1:                 episode reward: 0.0088,                 loss: 0.1422
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 46.2560 s
agent0:                 episode reward: -0.3773,                 loss: nan
agent1:                 episode reward: 0.3773,                 loss: 0.1415
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 46.4513 s
agent0:                 episode reward: -0.2889,                 loss: nan
agent1:                 episode reward: 0.2889,                 loss: 0.1420
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1912s / 46.6426 s
agent0:                 episode reward: -0.3831,                 loss: nan
agent1:                 episode reward: 0.3831,                 loss: 0.1412
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1896s / 46.8322 s
agent0:                 episode reward: -0.1032,                 loss: nan
agent1:                 episode reward: 0.1032,                 loss: 0.1403
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2117s / 47.0438 s
agent0:                 episode reward: -0.5285,                 loss: nan
agent1:                 episode reward: 0.5285,                 loss: 0.1399
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2131s / 47.2569 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.1418
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1903s / 47.4472 s
agent0:                 episode reward: -0.5964,                 loss: nan
agent1:                 episode reward: 0.5964,                 loss: 0.1419
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 47.6435 s
agent0:                 episode reward: -0.0997,                 loss: nan
agent1:                 episode reward: 0.0997,                 loss: 0.1415
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 47.8397 s
agent0:                 episode reward: -0.4568,                 loss: nan
agent1:                 episode reward: 0.4568,                 loss: 0.1418
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 48.0387 s
agent0:                 episode reward: -0.6073,                 loss: nan
agent1:                 episode reward: 0.6073,                 loss: 0.1418
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 48.2339 s
agent0:                 episode reward: -0.3990,                 loss: nan
agent1:                 episode reward: 0.3990,                 loss: 0.1405
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2306s / 48.4645 s
agent0:                 episode reward: -0.3793,                 loss: nan
agent1:                 episode reward: 0.3793,                 loss: 0.1412
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 48.6626 s
agent0:                 episode reward: -0.2481,                 loss: nan
agent1:                 episode reward: 0.2481,                 loss: 0.1418
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 48.8628 s
agent0:                 episode reward: -0.0285,                 loss: nan
agent1:                 episode reward: 0.0285,                 loss: 0.1407
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 49.0625 s
agent0:                 episode reward: 0.1083,                 loss: nan
agent1:                 episode reward: -0.1083,                 loss: 0.1403
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2058s / 49.2683 s
agent0:                 episode reward: -0.2313,                 loss: nan
agent1:                 episode reward: 0.2313,                 loss: 0.1415
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 49.4696 s
agent0:                 episode reward: -0.0546,                 loss: nan
agent1:                 episode reward: 0.0546,                 loss: 0.1411
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 49.6668 s
agent0:                 episode reward: -0.2601,                 loss: nan
agent1:                 episode reward: 0.2601,                 loss: 0.1417
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 49.8671 s
agent0:                 episode reward: -0.4803,                 loss: nan
agent1:                 episode reward: 0.4803,                 loss: 0.1390
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2177s / 50.0848 s
agent0:                 episode reward: -0.1910,                 loss: nan
agent1:                 episode reward: 0.1910,                 loss: 0.1395
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2184s / 50.3032 s
agent0:                 episode reward: -0.1354,                 loss: nan
agent1:                 episode reward: 0.1354,                 loss: 0.1409
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 50.5024 s
agent0:                 episode reward: -0.2637,                 loss: nan
agent1:                 episode reward: 0.2637,                 loss: 0.1398
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 50.7051 s
agent0:                 episode reward: -0.3236,                 loss: nan
agent1:                 episode reward: 0.3236,                 loss: 0.1405
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 50.8990 s
agent0:                 episode reward: -0.0805,                 loss: nan
agent1:                 episode reward: 0.0805,                 loss: 0.1424
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 51.1013 s
agent0:                 episode reward: -0.1589,                 loss: nan
agent1:                 episode reward: 0.1589,                 loss: 0.1405
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 51.3023 s
agent0:                 episode reward: -0.1440,                 loss: nan
agent1:                 episode reward: 0.1440,                 loss: 0.1397
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 51.5049 s
agent0:                 episode reward: -0.1698,                 loss: nan
agent1:                 episode reward: 0.1698,                 loss: 0.1399
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2076s / 51.7125 s
agent0:                 episode reward: -0.3295,                 loss: nan
agent1:                 episode reward: 0.3295,                 loss: 0.1414
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 51.9152 s
agent0:                 episode reward: -0.4139,                 loss: nan
agent1:                 episode reward: 0.4139,                 loss: 0.1406
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 52.1176 s
agent0:                 episode reward: -0.8555,                 loss: nan
agent1:                 episode reward: 0.8555,                 loss: 0.1412
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2153s / 52.3330 s
agent0:                 episode reward: -0.4730,                 loss: nan
agent1:                 episode reward: 0.4730,                 loss: 0.1411
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 52.5280 s
agent0:                 episode reward: -0.4422,                 loss: nan
agent1:                 episode reward: 0.4422,                 loss: 0.1418
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1900s / 52.7180 s
agent0:                 episode reward: -0.5663,                 loss: nan
agent1:                 episode reward: 0.5663,                 loss: 0.1428
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1893s / 52.9073 s
agent0:                 episode reward: 0.0659,                 loss: nan
agent1:                 episode reward: -0.0659,                 loss: 0.1401
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2088s / 53.1161 s
agent0:                 episode reward: 0.0669,                 loss: nan
agent1:                 episode reward: -0.0669,                 loss: 0.1416
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2282s / 53.3443 s
agent0:                 episode reward: -0.1394,                 loss: nan
agent1:                 episode reward: 0.1394,                 loss: 0.1410
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2148s / 53.5591 s
agent0:                 episode reward: -0.2701,                 loss: nan
agent1:                 episode reward: 0.2701,                 loss: 0.1397
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 53.7552 s
agent0:                 episode reward: -0.3186,                 loss: nan
agent1:                 episode reward: 0.3186,                 loss: 0.1399
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 53.9531 s
agent0:                 episode reward: -0.4556,                 loss: nan
agent1:                 episode reward: 0.4556,                 loss: 0.1417
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 54.1538 s
agent0:                 episode reward: -0.2376,                 loss: nan
agent1:                 episode reward: 0.2376,                 loss: 0.1418
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 54.3567 s
agent0:                 episode reward: -0.2613,                 loss: nan
agent1:                 episode reward: 0.2613,                 loss: 0.1401
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 54.5573 s
agent0:                 episode reward: -0.0335,                 loss: nan
agent1:                 episode reward: 0.0335,                 loss: 0.1423
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 54.7535 s
agent0:                 episode reward: -0.4586,                 loss: nan
agent1:                 episode reward: 0.4586,                 loss: 0.1401
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 54.9514 s
agent0:                 episode reward: -0.3888,                 loss: nan
agent1:                 episode reward: 0.3888,                 loss: 0.1414
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 55.1498 s
agent0:                 episode reward: -0.0420,                 loss: nan
agent1:                 episode reward: 0.0420,                 loss: 0.1429
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 55.3488 s
agent0:                 episode reward: -0.1819,                 loss: nan
agent1:                 episode reward: 0.1819,                 loss: 0.1419
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 55.5520 s
agent0:                 episode reward: -0.3145,                 loss: nan
agent1:                 episode reward: 0.3145,                 loss: 0.1410
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2050s / 55.7570 s
agent0:                 episode reward: -0.3669,                 loss: nan
agent1:                 episode reward: 0.3669,                 loss: 0.1427
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2035s / 55.9605 s
agent0:                 episode reward: -0.5003,                 loss: nan
agent1:                 episode reward: 0.5003,                 loss: 0.1412
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2240s / 56.1845 s
agent0:                 episode reward: -0.3349,                 loss: nan
agent1:                 episode reward: 0.3349,                 loss: 0.1407
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2253s / 56.4098 s
agent0:                 episode reward: -0.5393,                 loss: nan
agent1:                 episode reward: 0.5393,                 loss: 0.1433
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 56.6080 s
agent0:                 episode reward: 0.1034,                 loss: nan
agent1:                 episode reward: -0.1034,                 loss: 0.1411
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 56.8084 s
agent0:                 episode reward: -0.2862,                 loss: nan
agent1:                 episode reward: 0.2862,                 loss: 0.1407
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 57.0092 s
agent0:                 episode reward: -0.2396,                 loss: nan
agent1:                 episode reward: 0.2396,                 loss: 0.1418
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 57.2107 s
agent0:                 episode reward: -0.3851,                 loss: nan
agent1:                 episode reward: 0.3851,                 loss: 0.1415
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2085s / 57.4192 s
agent0:                 episode reward: -0.3541,                 loss: nan
agent1:                 episode reward: 0.3541,                 loss: 0.1396
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 57.6223 s
agent0:                 episode reward: -0.3097,                 loss: nan
agent1:                 episode reward: 0.3097,                 loss: 0.1428
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 57.8196 s
agent0:                 episode reward: -0.3878,                 loss: nan
agent1:                 episode reward: 0.3878,                 loss: 0.1414
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1921s / 58.0118 s
agent0:                 episode reward: -0.3002,                 loss: nan
agent1:                 episode reward: 0.3002,                 loss: 0.1397
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 58.2098 s
agent0:                 episode reward: -0.3107,                 loss: nan
agent1:                 episode reward: 0.3107,                 loss: 0.1405
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 58.4071 s
agent0:                 episode reward: -0.4273,                 loss: nan
agent1:                 episode reward: 0.4273,                 loss: 0.1409
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 58.5991 s
agent0:                 episode reward: -0.2339,                 loss: nan
agent1:                 episode reward: 0.2339,                 loss: 0.1420
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1908s / 58.7899 s
agent0:                 episode reward: -0.3957,                 loss: nan
agent1:                 episode reward: 0.3957,                 loss: 0.1416
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1904s / 58.9803 s
agent0:                 episode reward: -0.5815,                 loss: nan
agent1:                 episode reward: 0.5815,                 loss: 0.1416
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2068s / 59.1871 s
agent0:                 episode reward: -0.0978,                 loss: nan
agent1:                 episode reward: 0.0978,                 loss: 0.1421
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2154s / 59.4024 s
agent0:                 episode reward: -0.2593,                 loss: nan
agent1:                 episode reward: 0.2593,                 loss: 0.1412
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 59.6015 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.1395
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 59.7992 s
agent0:                 episode reward: -0.7824,                 loss: nan
agent1:                 episode reward: 0.7824,                 loss: 0.1389
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 59.9950 s
agent0:                 episode reward: -0.5870,                 loss: nan
agent1:                 episode reward: 0.5870,                 loss: 0.1397
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 60.1923 s
agent0:                 episode reward: -0.4331,                 loss: nan
agent1:                 episode reward: 0.4331,                 loss: 0.1418
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 60.3945 s
agent0:                 episode reward: -0.5404,                 loss: nan
agent1:                 episode reward: 0.5404,                 loss: 0.1414
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 60.5976 s
agent0:                 episode reward: -0.6182,                 loss: nan
agent1:                 episode reward: 0.6182,                 loss: 0.1409
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2210s / 60.8186 s
agent0:                 episode reward: -0.0098,                 loss: nan
agent1:                 episode reward: 0.0098,                 loss: 0.1399
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 61.0176 s
agent0:                 episode reward: -0.5057,                 loss: nan
agent1:                 episode reward: 0.5057,                 loss: 0.1425
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 61.2180 s
agent0:                 episode reward: -0.0934,                 loss: nan
agent1:                 episode reward: 0.0934,                 loss: 0.1394
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 61.4220 s
agent0:                 episode reward: -0.3621,                 loss: nan
agent1:                 episode reward: 0.3621,                 loss: 0.1404
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 61.6189 s
agent0:                 episode reward: -0.2107,                 loss: nan
agent1:                 episode reward: 0.2107,                 loss: 0.1418
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 61.8178 s
agent0:                 episode reward: -0.3968,                 loss: nan
agent1:                 episode reward: 0.3968,                 loss: 0.1424
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 62.0123 s
agent0:                 episode reward: -0.1922,                 loss: nan
agent1:                 episode reward: 0.1922,                 loss: 0.1404
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 62.2062 s
agent0:                 episode reward: 0.2333,                 loss: nan
agent1:                 episode reward: -0.2333,                 loss: 0.1399
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2198s / 62.4261 s
agent0:                 episode reward: -0.6018,                 loss: nan
agent1:                 episode reward: 0.6018,                 loss: 0.1402
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2200s / 62.6460 s
agent0:                 episode reward: -0.4296,                 loss: nan
agent1:                 episode reward: 0.4296,                 loss: 0.1415
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2073s / 62.8533 s
agent0:                 episode reward: -0.7152,                 loss: nan
agent1:                 episode reward: 0.7152,                 loss: 0.1416
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2077s / 63.0610 s
agent0:                 episode reward: 0.1986,                 loss: nan
agent1:                 episode reward: -0.1986,                 loss: 0.1411
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2105s / 63.2715 s
agent0:                 episode reward: -0.6156,                 loss: nan
agent1:                 episode reward: 0.6156,                 loss: 0.1403
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 63.4754 s
agent0:                 episode reward: -0.3809,                 loss: nan
agent1:                 episode reward: 0.3809,                 loss: 0.1387
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 63.6784 s
agent0:                 episode reward: -0.3254,                 loss: nan
agent1:                 episode reward: 0.3254,                 loss: 0.1410
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2067s / 63.8850 s
agent0:                 episode reward: -0.6814,                 loss: nan
agent1:                 episode reward: 0.6814,                 loss: 0.1416
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2108s / 64.0958 s
agent0:                 episode reward: -0.1710,                 loss: nan
agent1:                 episode reward: 0.1710,                 loss: 0.1403
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2082s / 64.3041 s
agent0:                 episode reward: -0.2835,                 loss: nan
agent1:                 episode reward: 0.2835,                 loss: 0.1390
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 64.5061 s
agent0:                 episode reward: 0.0040,                 loss: nan
agent1:                 episode reward: -0.0040,                 loss: 0.1409
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 64.7013 s
agent0:                 episode reward: -0.3251,                 loss: nan
agent1:                 episode reward: 0.3251,                 loss: 0.1401
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1946s / 64.8959 s
agent0:                 episode reward: -0.7506,                 loss: nan
agent1:                 episode reward: 0.7506,                 loss: 0.1416
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 65.0945 s
agent0:                 episode reward: -0.7034,                 loss: nan
agent1:                 episode reward: 0.7034,                 loss: 0.1406
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 65.2949 s
agent0:                 episode reward: -0.4121,                 loss: nan
agent1:                 episode reward: 0.4121,                 loss: 0.1418
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2272s / 65.5220 s
agent0:                 episode reward: -0.6289,                 loss: nan
agent1:                 episode reward: 0.6289,                 loss: 0.1405
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2139s / 65.7359 s
agent0:                 episode reward: -0.4253,                 loss: nan
agent1:                 episode reward: 0.4253,                 loss: 0.1401
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2151s / 65.9510 s
agent0:                 episode reward: -0.4039,                 loss: nan
agent1:                 episode reward: 0.4039,                 loss: 0.1410
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2095s / 66.1605 s
agent0:                 episode reward: -0.5143,                 loss: nan
agent1:                 episode reward: 0.5143,                 loss: 0.1385
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2095s / 66.3699 s
agent0:                 episode reward: -0.1969,                 loss: nan
agent1:                 episode reward: 0.1969,                 loss: 0.1400
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2119s / 66.5819 s
agent0:                 episode reward: -0.8754,                 loss: nan
agent1:                 episode reward: 0.8754,                 loss: 0.1406
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2063s / 66.7882 s
agent0:                 episode reward: -0.1734,                 loss: nan
agent1:                 episode reward: 0.1734,                 loss: 0.1396
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2125s / 67.0007 s
agent0:                 episode reward: -0.4228,                 loss: nan
agent1:                 episode reward: 0.4228,                 loss: 0.1406
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2061s / 67.2067 s
agent0:                 episode reward: -0.1222,                 loss: nan
agent1:                 episode reward: 0.1222,                 loss: 0.1392
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2074s / 67.4141 s
agent0:                 episode reward: -0.6388,                 loss: nan
agent1:                 episode reward: 0.6388,                 loss: 0.1392
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 67.6136 s
agent0:                 episode reward: -0.4444,                 loss: nan
agent1:                 episode reward: 0.4444,                 loss: 0.1396
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2070s / 67.8206 s
agent0:                 episode reward: -0.4671,                 loss: nan
agent1:                 episode reward: 0.4671,                 loss: 0.1371
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2039s / 68.0245 s
agent0:                 episode reward: -0.3114,                 loss: nan
agent1:                 episode reward: 0.3114,                 loss: 0.1393
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 68.2252 s
agent0:                 episode reward: -0.2813,                 loss: nan
agent1:                 episode reward: 0.2813,                 loss: 0.1399
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2191s / 68.4443 s
agent0:                 episode reward: -0.4383,                 loss: nan
agent1:                 episode reward: 0.4383,                 loss: 0.1390
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2287s / 68.6730 s
agent0:                 episode reward: -0.3142,                 loss: nan
agent1:                 episode reward: 0.3142,                 loss: 0.1397
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2091s / 68.8820 s
agent0:                 episode reward: -0.1836,                 loss: nan
agent1:                 episode reward: 0.1836,                 loss: 0.1372
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2321s / 69.1141 s
agent0:                 episode reward: -0.3822,                 loss: nan
agent1:                 episode reward: 0.3822,                 loss: 0.1391
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 69.3150 s
agent0:                 episode reward: -0.5568,                 loss: nan
agent1:                 episode reward: 0.5568,                 loss: 0.1397
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 69.5130 s
agent0:                 episode reward: -0.4205,                 loss: nan
agent1:                 episode reward: 0.4205,                 loss: 0.1400
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2064s / 69.7194 s
agent0:                 episode reward: -0.6179,                 loss: nan
agent1:                 episode reward: 0.6179,                 loss: 0.1398
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 69.9167 s
agent0:                 episode reward: -0.5064,                 loss: nan
agent1:                 episode reward: 0.5064,                 loss: 0.1381
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 70.1138 s
agent0:                 episode reward: -0.4969,                 loss: nan
agent1:                 episode reward: 0.4969,                 loss: 0.1383
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2129s / 70.3268 s
agent0:                 episode reward: -0.3941,                 loss: nan
agent1:                 episode reward: 0.3941,                 loss: 0.1379
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2076s / 70.5344 s
agent0:                 episode reward: -0.0641,                 loss: nan
agent1:                 episode reward: 0.0641,                 loss: 0.1390
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2061s / 70.7405 s
agent0:                 episode reward: -0.4008,                 loss: nan
agent1:                 episode reward: 0.4008,                 loss: 0.1389
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2078s / 70.9482 s
agent0:                 episode reward: -0.6246,                 loss: nan
agent1:                 episode reward: 0.6246,                 loss: 0.1376
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2080s / 71.1562 s
agent0:                 episode reward: -0.5916,                 loss: nan
agent1:                 episode reward: 0.5916,                 loss: 0.1374
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2077s / 71.3639 s
agent0:                 episode reward: -0.0030,                 loss: nan
agent1:                 episode reward: 0.0030,                 loss: 0.1385
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2431s / 71.6070 s
agent0:                 episode reward: -0.2646,                 loss: nan
agent1:                 episode reward: 0.2646,                 loss: 0.1380
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2468s / 71.8538 s
agent0:                 episode reward: -0.3194,                 loss: nan
agent1:                 episode reward: 0.3194,                 loss: 0.1359
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2155s / 72.0693 s
agent0:                 episode reward: -0.0019,                 loss: nan
agent1:                 episode reward: 0.0019,                 loss: 0.1382
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 72.2906 s
agent0:                 episode reward: -0.6077,                 loss: nan
agent1:                 episode reward: 0.6077,                 loss: 0.1366
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2163s / 72.5068 s
agent0:                 episode reward: -0.7226,                 loss: nan
agent1:                 episode reward: 0.7226,                 loss: 0.1395
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2123s / 72.7191 s
agent0:                 episode reward: -0.4485,                 loss: nan
agent1:                 episode reward: 0.4485,                 loss: 0.1371
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2102s / 72.9293 s
agent0:                 episode reward: -0.3929,                 loss: nan
agent1:                 episode reward: 0.3929,                 loss: 0.1380
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2103s / 73.1396 s
agent0:                 episode reward: -0.3608,                 loss: nan
agent1:                 episode reward: 0.3608,                 loss: 0.1380
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2083s / 73.3479 s
agent0:                 episode reward: -0.6640,                 loss: nan
agent1:                 episode reward: 0.6640,                 loss: 0.1376
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2133s / 73.5612 s
agent0:                 episode reward: -0.3120,                 loss: nan
agent1:                 episode reward: 0.3120,                 loss: 0.1386
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2335s / 73.7947 s
agent0:                 episode reward: -0.3959,                 loss: nan
agent1:                 episode reward: 0.3959,                 loss: 0.1376
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2133s / 74.0080 s
agent0:                 episode reward: -0.6900,                 loss: nan
agent1:                 episode reward: 0.6900,                 loss: 0.1383
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2176s / 74.2256 s
agent0:                 episode reward: -0.7853,                 loss: nan
agent1:                 episode reward: 0.7853,                 loss: 0.1386
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2148s / 74.4404 s
agent0:                 episode reward: -0.0417,                 loss: nan
agent1:                 episode reward: 0.0417,                 loss: 0.1384
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2524s / 74.6928 s
agent0:                 episode reward: -0.2823,                 loss: nan
agent1:                 episode reward: 0.2823,                 loss: 0.1372
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2279s / 74.9206 s
agent0:                 episode reward: -0.2559,                 loss: nan
agent1:                 episode reward: 0.2559,                 loss: 0.1371
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2145s / 75.1351 s
agent0:                 episode reward: -0.5080,                 loss: nan
agent1:                 episode reward: 0.5080,                 loss: 0.1367
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2249s / 75.3601 s
agent0:                 episode reward: -0.6683,                 loss: nan
agent1:                 episode reward: 0.6683,                 loss: 0.1378
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2184s / 75.5785 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: 0.1379
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2118s / 75.7903 s
agent0:                 episode reward: -0.4403,                 loss: nan
agent1:                 episode reward: 0.4403,                 loss: 0.1384
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2053s / 75.9956 s
agent0:                 episode reward: -0.8476,                 loss: nan
agent1:                 episode reward: 0.8476,                 loss: 0.1369
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2097s / 76.2053 s
agent0:                 episode reward: -0.3616,                 loss: nan
agent1:                 episode reward: 0.3616,                 loss: 0.1381
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2140s / 76.4194 s
agent0:                 episode reward: -0.3219,                 loss: nan
agent1:                 episode reward: 0.3219,                 loss: 0.1386
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2144s / 76.6338 s
agent0:                 episode reward: -0.0222,                 loss: nan
agent1:                 episode reward: 0.0222,                 loss: 0.1373
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2149s / 76.8487 s
agent0:                 episode reward: -0.5903,                 loss: nan
agent1:                 episode reward: 0.5903,                 loss: 0.1383
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2123s / 77.0610 s
agent0:                 episode reward: -0.1659,                 loss: nan
agent1:                 episode reward: 0.1659,                 loss: 0.1378
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2131s / 77.2742 s
agent0:                 episode reward: -0.2270,                 loss: nan
agent1:                 episode reward: 0.2270,                 loss: 0.1383
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2331s / 77.5073 s
agent0:                 episode reward: -0.8433,                 loss: nan
agent1:                 episode reward: 0.8433,                 loss: 0.1365
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2524s / 77.7596 s
agent0:                 episode reward: -0.5532,                 loss: nan
agent1:                 episode reward: 0.5532,                 loss: 0.1383
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2351s / 77.9947 s
agent0:                 episode reward: -0.0361,                 loss: nan
agent1:                 episode reward: 0.0361,                 loss: 0.1380
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2126s / 78.2073 s
agent0:                 episode reward: -0.6313,                 loss: nan
agent1:                 episode reward: 0.6313,                 loss: 0.1391
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2163s / 78.4237 s
agent0:                 episode reward: -0.5694,                 loss: nan
agent1:                 episode reward: 0.5694,                 loss: 0.1388
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2157s / 78.6394 s
agent0:                 episode reward: -0.0562,                 loss: nan
agent1:                 episode reward: 0.0562,                 loss: 0.1382
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2154s / 78.8548 s
agent0:                 episode reward: -0.8080,                 loss: nan
agent1:                 episode reward: 0.8080,                 loss: 0.1399
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2164s / 79.0712 s
agent0:                 episode reward: -0.2719,                 loss: nan
agent1:                 episode reward: 0.2719,                 loss: 0.1387
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2485s / 79.3196 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.1391
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2089s / 79.5286 s
agent0:                 episode reward: -0.3706,                 loss: nan
agent1:                 episode reward: 0.3706,                 loss: 0.1361
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2079s / 79.7365 s
agent0:                 episode reward: -0.0925,                 loss: nan
agent1:                 episode reward: 0.0925,                 loss: 0.1383
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2070s / 79.9435 s
agent0:                 episode reward: -0.4787,                 loss: nan
agent1:                 episode reward: 0.4787,                 loss: 0.1392
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2110s / 80.1546 s
agent0:                 episode reward: -0.6439,                 loss: nan
agent1:                 episode reward: 0.6439,                 loss: 0.1383
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2171s / 80.3717 s
agent0:                 episode reward: -0.3267,                 loss: nan
agent1:                 episode reward: 0.3267,                 loss: 0.1380
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2214s / 80.5930 s
agent0:                 episode reward: -0.4421,                 loss: nan
agent1:                 episode reward: 0.4421,                 loss: 0.1371
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 80.8278 s
agent0:                 episode reward: -0.3399,                 loss: nan
agent1:                 episode reward: 0.3399,                 loss: 0.1386
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2257s / 81.0535 s
agent0:                 episode reward: -0.4383,                 loss: nan
agent1:                 episode reward: 0.4383,                 loss: 0.1374
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2156s / 81.2691 s
agent0:                 episode reward: -0.4981,                 loss: nan
agent1:                 episode reward: 0.4981,                 loss: 0.1371
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2201s / 81.4892 s
agent0:                 episode reward: 0.0067,                 loss: nan
agent1:                 episode reward: -0.0067,                 loss: 0.1373
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2189s / 81.7080 s
agent0:                 episode reward: -0.4913,                 loss: nan
agent1:                 episode reward: 0.4913,                 loss: 0.1361
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2128s / 81.9208 s
agent0:                 episode reward: -0.0267,                 loss: nan
agent1:                 episode reward: 0.0267,                 loss: 0.1384
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2122s / 82.1331 s
agent0:                 episode reward: -0.9992,                 loss: nan
agent1:                 episode reward: 0.9992,                 loss: 0.1357
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2201s / 82.3532 s
agent0:                 episode reward: -0.2426,                 loss: nan
agent1:                 episode reward: 0.2426,                 loss: 0.1379
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2109s / 82.5641 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: 0.1367
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2101s / 82.7741 s
agent0:                 episode reward: -0.1145,                 loss: nan
agent1:                 episode reward: 0.1145,                 loss: 0.1364
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2089s / 82.9830 s
agent0:                 episode reward: -0.5592,                 loss: nan
agent1:                 episode reward: 0.5592,                 loss: 0.1380
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2107s / 83.1938 s
agent0:                 episode reward: -0.3973,                 loss: nan
agent1:                 episode reward: 0.3973,                 loss: 0.1364
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2136s / 83.4074 s
agent0:                 episode reward: -0.6278,                 loss: nan
agent1:                 episode reward: 0.6278,                 loss: 0.1378
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2141s / 83.6215 s
agent0:                 episode reward: -0.3003,                 loss: nan
agent1:                 episode reward: 0.3003,                 loss: 0.1363
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2375s / 83.8590 s
agent0:                 episode reward: -0.2135,                 loss: nan
agent1:                 episode reward: 0.2135,                 loss: 0.1382
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2346s / 84.0936 s
agent0:                 episode reward: -0.6672,                 loss: nan
agent1:                 episode reward: 0.6672,                 loss: 0.1365
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2126s / 84.3062 s
agent0:                 episode reward: -0.4647,                 loss: nan
agent1:                 episode reward: 0.4647,                 loss: 0.1374
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2230s / 84.5291 s
agent0:                 episode reward: -0.4478,                 loss: nan
agent1:                 episode reward: 0.4478,                 loss: 0.1369
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2174s / 84.7466 s
agent0:                 episode reward: -0.2868,                 loss: nan
agent1:                 episode reward: 0.2868,                 loss: 0.1368
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2156s / 84.9621 s
agent0:                 episode reward: -0.0098,                 loss: nan
agent1:                 episode reward: 0.0098,                 loss: 0.1370
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2147s / 85.1769 s
agent0:                 episode reward: -0.6183,                 loss: nan
agent1:                 episode reward: 0.6183,                 loss: 0.1378
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2169s / 85.3937 s
agent0:                 episode reward: -0.4550,                 loss: nan
agent1:                 episode reward: 0.4550,                 loss: 0.1388
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2185s / 85.6122 s
agent0:                 episode reward: -0.4296,                 loss: nan
agent1:                 episode reward: 0.4296,                 loss: 0.1368
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2450s / 85.8573 s
agent0:                 episode reward: -0.4236,                 loss: nan
agent1:                 episode reward: 0.4236,                 loss: 0.1370
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2160s / 86.0733 s
agent0:                 episode reward: -0.0563,                 loss: nan
agent1:                 episode reward: 0.0563,                 loss: 0.1379
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2149s / 86.2882 s
agent0:                 episode reward: -0.3394,                 loss: nan
agent1:                 episode reward: 0.3394,                 loss: 0.1374
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2190s / 86.5072 s
agent0:                 episode reward: -0.6983,                 loss: nan
agent1:                 episode reward: 0.6983,                 loss: 0.1365
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2164s / 86.7236 s
agent0:                 episode reward: -0.4735,                 loss: nan
agent1:                 episode reward: 0.4735,                 loss: 0.1372
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2452s / 86.9688 s
agent0:                 episode reward: -0.8059,                 loss: nan
agent1:                 episode reward: 0.8059,                 loss: 0.1385
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2271s / 87.1959 s
agent0:                 episode reward: -0.6602,                 loss: nan
agent1:                 episode reward: 0.6602,                 loss: 0.1363
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2176s / 87.4135 s
agent0:                 episode reward: -0.4930,                 loss: nan
agent1:                 episode reward: 0.4930,                 loss: 0.1352
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2194s / 87.6329 s
agent0:                 episode reward: -0.4110,                 loss: nan
agent1:                 episode reward: 0.4110,                 loss: 0.1364
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2154s / 87.8483 s
agent0:                 episode reward: -0.8461,                 loss: nan
agent1:                 episode reward: 0.8461,                 loss: 0.1349
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2207s / 88.0691 s
agent0:                 episode reward: -0.3816,                 loss: nan
agent1:                 episode reward: 0.3816,                 loss: 0.1371
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2493s / 88.3184 s
agent0:                 episode reward: -0.5533,                 loss: nan
agent1:                 episode reward: 0.5533,                 loss: 0.1367
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2371s / 88.5554 s
agent0:                 episode reward: -0.7625,                 loss: nan
agent1:                 episode reward: 0.7625,                 loss: 0.1366
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2367s / 88.7922 s
agent0:                 episode reward: -0.6840,                 loss: nan
agent1:                 episode reward: 0.6840,                 loss: 0.1364
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2333s / 89.0255 s
agent0:                 episode reward: -0.3301,                 loss: nan
agent1:                 episode reward: 0.3301,                 loss: 0.1362
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2483s / 89.2738 s
agent0:                 episode reward: -0.6558,                 loss: nan
agent1:                 episode reward: 0.6558,                 loss: 0.1350
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2422s / 89.5161 s
agent0:                 episode reward: -0.5030,                 loss: nan
agent1:                 episode reward: 0.5030,                 loss: 0.1350
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2252s / 89.7413 s
agent0:                 episode reward: -0.2447,                 loss: nan
agent1:                 episode reward: 0.2447,                 loss: 0.1352
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2559s / 89.9972 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.1375
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2381s / 90.2353 s
agent0:                 episode reward: -0.3359,                 loss: nan
agent1:                 episode reward: 0.3359,                 loss: 0.1372
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2207s / 90.4560 s
agent0:                 episode reward: -0.4882,                 loss: nan
agent1:                 episode reward: 0.4882,                 loss: 0.1361
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2265s / 90.6825 s
agent0:                 episode reward: -0.5645,                 loss: nan
agent1:                 episode reward: 0.5645,                 loss: 0.1354
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2290s / 90.9115 s
agent0:                 episode reward: -0.8436,                 loss: nan
agent1:                 episode reward: 0.8436,                 loss: 0.1352
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2268s / 91.1383 s
agent0:                 episode reward: -0.4457,                 loss: nan
agent1:                 episode reward: 0.4457,                 loss: 0.1342
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2282s / 91.3665 s
agent0:                 episode reward: -0.3322,                 loss: nan
agent1:                 episode reward: 0.3322,                 loss: 0.1360
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2266s / 91.5930 s
agent0:                 episode reward: -0.2453,                 loss: nan
agent1:                 episode reward: 0.2453,                 loss: 0.1353
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2253s / 91.8183 s
agent0:                 episode reward: -0.6010,                 loss: nan
agent1:                 episode reward: 0.6010,                 loss: 0.1361
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2254s / 92.0437 s
agent0:                 episode reward: -0.5105,                 loss: nan
agent1:                 episode reward: 0.5105,                 loss: 0.1373
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2254s / 92.2691 s
agent0:                 episode reward: -0.7055,                 loss: nan
agent1:                 episode reward: 0.7055,                 loss: 0.1352
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2193s / 92.4883 s
agent0:                 episode reward: -0.5017,                 loss: nan
agent1:                 episode reward: 0.5017,                 loss: 0.1368
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2098s / 92.6982 s
agent0:                 episode reward: -0.6773,                 loss: nan
agent1:                 episode reward: 0.6773,                 loss: 0.1350
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2318s / 92.9300 s
agent0:                 episode reward: -0.3546,                 loss: nan
agent1:                 episode reward: 0.3546,                 loss: 0.1366
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2427s / 93.1727 s
agent0:                 episode reward: -0.4214,                 loss: nan
agent1:                 episode reward: 0.4214,                 loss: 0.1359
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2140s / 93.3866 s
agent0:                 episode reward: -0.1527,                 loss: nan
agent1:                 episode reward: 0.1527,                 loss: 0.1357
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2194s / 93.6060 s
agent0:                 episode reward: -0.0280,                 loss: nan
agent1:                 episode reward: 0.0280,                 loss: 0.1357
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2216s / 93.8276 s
agent0:                 episode reward: -1.1212,                 loss: nan
agent1:                 episode reward: 1.1212,                 loss: 0.1365
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2398s / 94.0674 s
agent0:                 episode reward: -0.6556,                 loss: nan
agent1:                 episode reward: 0.6556,                 loss: 0.1344
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2342s / 94.3016 s
agent0:                 episode reward: -0.5873,                 loss: nan
agent1:                 episode reward: 0.5873,                 loss: 0.1349
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2323s / 94.5340 s
agent0:                 episode reward: -0.4575,                 loss: nan
agent1:                 episode reward: 0.4575,                 loss: 0.1364
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2302s / 94.7642 s
agent0:                 episode reward: -0.8719,                 loss: nan
agent1:                 episode reward: 0.8719,                 loss: 0.1357
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2364s / 95.0006 s
agent0:                 episode reward: -0.1105,                 loss: nan
agent1:                 episode reward: 0.1105,                 loss: 0.1361
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2267s / 95.2273 s
agent0:                 episode reward: -0.9732,                 loss: nan
agent1:                 episode reward: 0.9732,                 loss: 0.1355
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2236s / 95.4509 s
agent0:                 episode reward: -0.5668,                 loss: nan
agent1:                 episode reward: 0.5668,                 loss: 0.1380
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2219s / 95.6729 s
agent0:                 episode reward: -0.3199,                 loss: nan
agent1:                 episode reward: 0.3199,                 loss: 0.1338
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2387s / 95.9116 s
agent0:                 episode reward: -0.3306,                 loss: nan
agent1:                 episode reward: 0.3306,                 loss: 0.1366
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2345s / 96.1461 s
agent0:                 episode reward: -0.7689,                 loss: nan
agent1:                 episode reward: 0.7689,                 loss: 0.1368
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2175s / 96.3636 s
agent0:                 episode reward: -0.2863,                 loss: nan
agent1:                 episode reward: 0.2863,                 loss: 0.1356
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2235s / 96.5870 s
agent0:                 episode reward: -0.3672,                 loss: nan
agent1:                 episode reward: 0.3672,                 loss: 0.1352
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2239s / 96.8109 s
agent0:                 episode reward: -0.5002,                 loss: nan
agent1:                 episode reward: 0.5002,                 loss: 0.1354
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2240s / 97.0349 s
agent0:                 episode reward: -0.2464,                 loss: nan
agent1:                 episode reward: 0.2464,                 loss: 0.1363
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2245s / 97.2595 s
agent0:                 episode reward: -0.3476,                 loss: nan
agent1:                 episode reward: 0.3476,                 loss: 0.1343
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2247s / 97.4841 s
agent0:                 episode reward: -0.5089,                 loss: nan
agent1:                 episode reward: 0.5089,                 loss: 0.1360
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2213s / 97.7055 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.1366
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2198s / 97.9253 s
agent0:                 episode reward: -0.2400,                 loss: nan
agent1:                 episode reward: 0.2400,                 loss: 0.1361
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2217s / 98.1470 s
agent0:                 episode reward: -0.6592,                 loss: nan
agent1:                 episode reward: 0.6592,                 loss: 0.1360
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2252s / 98.3723 s
agent0:                 episode reward: -0.1980,                 loss: nan
agent1:                 episode reward: 0.1980,                 loss: 0.1369
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2221s / 98.5944 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.1348
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2202s / 98.8146 s
agent0:                 episode reward: -0.4551,                 loss: nan
agent1:                 episode reward: 0.4551,                 loss: 0.1362
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2251s / 99.0396 s
agent0:                 episode reward: -0.6414,                 loss: nan
agent1:                 episode reward: 0.6414,                 loss: 0.1375
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2272s / 99.2668 s
agent0:                 episode reward: -0.3915,                 loss: nan
agent1:                 episode reward: 0.3915,                 loss: 0.1389
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2234s / 99.4902 s
agent0:                 episode reward: 0.0910,                 loss: nan
agent1:                 episode reward: -0.0910,                 loss: 0.1390
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2221s / 99.7123 s
agent0:                 episode reward: -0.2703,                 loss: nan
agent1:                 episode reward: 0.2703,                 loss: 0.1376
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2216s / 99.9339 s
agent0:                 episode reward: -0.2938,                 loss: nan
agent1:                 episode reward: 0.2938,                 loss: 0.1364
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2267s / 100.1605 s
agent0:                 episode reward: -0.2479,                 loss: nan
agent1:                 episode reward: 0.2479,                 loss: 0.1369
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2282s / 100.3887 s
agent0:                 episode reward: -0.6005,                 loss: nan
agent1:                 episode reward: 0.6005,                 loss: 0.1383
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2279s / 100.6166 s
agent0:                 episode reward: -0.2232,                 loss: nan
agent1:                 episode reward: 0.2232,                 loss: 0.1373
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2226s / 100.8392 s
agent0:                 episode reward: -0.8062,                 loss: nan
agent1:                 episode reward: 0.8062,                 loss: 0.1368
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2227s / 101.0619 s
agent0:                 episode reward: -0.0958,                 loss: nan
agent1:                 episode reward: 0.0958,                 loss: 0.1372
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2269s / 101.2888 s
agent0:                 episode reward: -0.6668,                 loss: nan
agent1:                 episode reward: 0.6668,                 loss: 0.1372
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2427s / 101.5315 s
agent0:                 episode reward: -0.6814,                 loss: nan
agent1:                 episode reward: 0.6814,                 loss: 0.1375
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2422s / 101.7737 s
agent0:                 episode reward: 0.1607,                 loss: nan
agent1:                 episode reward: -0.1607,                 loss: 0.1361
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2588s / 102.0325 s
agent0:                 episode reward: -0.4220,                 loss: nan
agent1:                 episode reward: 0.4220,                 loss: 0.1374
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2702s / 102.3026 s
agent0:                 episode reward: -0.4450,                 loss: nan
agent1:                 episode reward: 0.4450,                 loss: 0.1377
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2257s / 102.5283 s
agent0:                 episode reward: -0.3365,                 loss: nan
agent1:                 episode reward: 0.3365,                 loss: 0.1388
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2232s / 102.7515 s
agent0:                 episode reward: -0.8549,                 loss: nan
agent1:                 episode reward: 0.8549,                 loss: 0.1365
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2196s / 102.9711 s
agent0:                 episode reward: -0.3605,                 loss: nan
agent1:                 episode reward: 0.3605,                 loss: 0.1366
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2274s / 103.1984 s
agent0:                 episode reward: -0.5599,                 loss: nan
agent1:                 episode reward: 0.5599,                 loss: 0.1371
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2286s / 103.4271 s
agent0:                 episode reward: -0.2508,                 loss: nan
agent1:                 episode reward: 0.2508,                 loss: 0.1363
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2248s / 103.6519 s
agent0:                 episode reward: -0.5238,                 loss: nan
agent1:                 episode reward: 0.5238,                 loss: 0.1380
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2246s / 103.8765 s
agent0:                 episode reward: -0.4321,                 loss: nan
agent1:                 episode reward: 0.4321,                 loss: 0.1360
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2261s / 104.1025 s
agent0:                 episode reward: -0.2424,                 loss: nan
agent1:                 episode reward: 0.2424,                 loss: 0.1383
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2286s / 104.3311 s
agent0:                 episode reward: -0.2459,                 loss: nan
agent1:                 episode reward: 0.2459,                 loss: 0.1362
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2258s / 104.5569 s
agent0:                 episode reward: -0.3134,                 loss: nan
agent1:                 episode reward: 0.3134,                 loss: 0.1365
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2251s / 104.7820 s
agent0:                 episode reward: -0.5460,                 loss: nan
agent1:                 episode reward: 0.5460,                 loss: 0.1357
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2543s / 105.0363 s
agent0:                 episode reward: -0.3277,                 loss: nan
agent1:                 episode reward: 0.3277,                 loss: 0.1355
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2470s / 105.2834 s
agent0:                 episode reward: -0.6570,                 loss: nan
agent1:                 episode reward: 0.6570,                 loss: 0.1371
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2311s / 105.5145 s
agent0:                 episode reward: -0.6574,                 loss: nan
agent1:                 episode reward: 0.6574,                 loss: 0.1365
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2315s / 105.7459 s
agent0:                 episode reward: -0.4880,                 loss: nan
agent1:                 episode reward: 0.4880,                 loss: 0.1364
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2329s / 105.9789 s
agent0:                 episode reward: -0.6342,                 loss: nan
agent1:                 episode reward: 0.6342,                 loss: 0.1363
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2248s / 106.2037 s
agent0:                 episode reward: -0.3277,                 loss: nan
agent1:                 episode reward: 0.3277,                 loss: 0.1360
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2300s / 106.4337 s
agent0:                 episode reward: -0.5200,                 loss: nan
agent1:                 episode reward: 0.5200,                 loss: 0.1367
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2251s / 106.6588 s
agent0:                 episode reward: -0.8192,                 loss: nan
agent1:                 episode reward: 0.8192,                 loss: 0.1362
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2294s / 106.8882 s
agent0:                 episode reward: 0.1218,                 loss: nan
agent1:                 episode reward: -0.1218,                 loss: 0.1377
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2365s / 107.1247 s
agent0:                 episode reward: -0.8823,                 loss: nan
agent1:                 episode reward: 0.8823,                 loss: 0.1362
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2360s / 107.3608 s
agent0:                 episode reward: -0.7601,                 loss: nan
agent1:                 episode reward: 0.7601,                 loss: 0.1364
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2284s / 107.5892 s
agent0:                 episode reward: -0.1561,                 loss: nan
agent1:                 episode reward: 0.1561,                 loss: 0.1356
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2358s / 107.8250 s
agent0:                 episode reward: -0.0455,                 loss: nan
agent1:                 episode reward: 0.0455,                 loss: 0.1348
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 108.0828 s
agent0:                 episode reward: -0.3933,                 loss: nan
agent1:                 episode reward: 0.3933,                 loss: 0.1385
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2434s / 108.3263 s
agent0:                 episode reward: -0.2039,                 loss: nan
agent1:                 episode reward: 0.2039,                 loss: 0.1358
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2347s / 108.5609 s
agent0:                 episode reward: -0.5257,                 loss: nan
agent1:                 episode reward: 0.5257,                 loss: 0.1375
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2326s / 108.7935 s
agent0:                 episode reward: -0.6171,                 loss: nan
agent1:                 episode reward: 0.6171,                 loss: 0.1370
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2351s / 109.0286 s
agent0:                 episode reward: -0.5906,                 loss: nan
agent1:                 episode reward: 0.5906,                 loss: 0.1364
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2320s / 109.2606 s
agent0:                 episode reward: -0.8511,                 loss: nan
agent1:                 episode reward: 0.8511,                 loss: 0.1371
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2276s / 109.4882 s
agent0:                 episode reward: -0.7113,                 loss: nan
agent1:                 episode reward: 0.7113,                 loss: 0.1354
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2315s / 109.7198 s
agent0:                 episode reward: -0.4184,                 loss: nan
agent1:                 episode reward: 0.4184,                 loss: 0.1358
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2337s / 109.9534 s
agent0:                 episode reward: -0.5238,                 loss: nan
agent1:                 episode reward: 0.5238,                 loss: 0.1373
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2285s / 110.1819 s
agent0:                 episode reward: -0.5003,                 loss: nan
agent1:                 episode reward: 0.5003,                 loss: 0.1366
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2339s / 110.4158 s
agent0:                 episode reward: -0.5886,                 loss: nan
agent1:                 episode reward: 0.5886,                 loss: 0.1369
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2479s / 110.6637 s
agent0:                 episode reward: -0.4770,                 loss: nan
agent1:                 episode reward: 0.4770,                 loss: 0.1348
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2300s / 110.8937 s
agent0:                 episode reward: -0.3858,                 loss: nan
agent1:                 episode reward: 0.3858,                 loss: 0.1355
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2663s / 111.1600 s
agent0:                 episode reward: -0.3134,                 loss: nan
agent1:                 episode reward: 0.3134,                 loss: 0.1347
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2503s / 111.4102 s
agent0:                 episode reward: -0.7132,                 loss: nan
agent1:                 episode reward: 0.7132,                 loss: 0.1346
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2347s / 111.6450 s
agent0:                 episode reward: -0.6638,                 loss: nan
agent1:                 episode reward: 0.6638,                 loss: 0.1359
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2315s / 111.8765 s
agent0:                 episode reward: -0.3999,                 loss: nan
agent1:                 episode reward: 0.3999,                 loss: 0.1349
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2310s / 112.1075 s
agent0:                 episode reward: -0.5106,                 loss: nan
agent1:                 episode reward: 0.5106,                 loss: 0.1342
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2365s / 112.3441 s
agent0:                 episode reward: -0.3888,                 loss: nan
agent1:                 episode reward: 0.3888,                 loss: 0.1334
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2280s / 112.5720 s
agent0:                 episode reward: -0.5170,                 loss: nan
agent1:                 episode reward: 0.5170,                 loss: 0.1358
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2225s / 112.7946 s
agent0:                 episode reward: -0.9614,                 loss: nan
agent1:                 episode reward: 0.9614,                 loss: 0.1351
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2210s / 113.0156 s
agent0:                 episode reward: -0.0843,                 loss: nan
agent1:                 episode reward: 0.0843,                 loss: 0.1364
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2264s / 113.2420 s
agent0:                 episode reward: -0.3457,                 loss: nan
agent1:                 episode reward: 0.3457,                 loss: 0.1355
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2370s / 113.4791 s
agent0:                 episode reward: -0.3077,                 loss: nan
agent1:                 episode reward: 0.3077,                 loss: 0.1341
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2321s / 113.7112 s
agent0:                 episode reward: -0.8136,                 loss: nan
agent1:                 episode reward: 0.8136,                 loss: 0.1348
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2351s / 113.9463 s
agent0:                 episode reward: -0.8480,                 loss: nan
agent1:                 episode reward: 0.8480,                 loss: 0.1336
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2399s / 114.1862 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.1359
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 114.4423 s
agent0:                 episode reward: -0.5353,                 loss: nan
agent1:                 episode reward: 0.5353,                 loss: 0.1375
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 114.6896 s
agent0:                 episode reward: -0.9991,                 loss: nan
agent1:                 episode reward: 0.9991,                 loss: 0.1373
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2382s / 114.9278 s
agent0:                 episode reward: -0.6429,                 loss: nan
agent1:                 episode reward: 0.6429,                 loss: 0.1355
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2440s / 115.1718 s
agent0:                 episode reward: -0.4523,                 loss: nan
agent1:                 episode reward: 0.4523,                 loss: 0.1364
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2427s / 115.4145 s
agent0:                 episode reward: -0.9243,                 loss: nan
agent1:                 episode reward: 0.9243,                 loss: 0.1362
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2461s / 115.6606 s
agent0:                 episode reward: -0.8098,                 loss: nan
agent1:                 episode reward: 0.8098,                 loss: 0.1360
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2284s / 115.8890 s
agent0:                 episode reward: -0.9095,                 loss: nan
agent1:                 episode reward: 0.9095,                 loss: 0.1346
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2350s / 116.1240 s
agent0:                 episode reward: -0.9922,                 loss: nan
agent1:                 episode reward: 0.9922,                 loss: 0.1361
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2411s / 116.3651 s
agent0:                 episode reward: -0.1274,                 loss: nan
agent1:                 episode reward: 0.1274,                 loss: 0.1373
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2389s / 116.6040 s
agent0:                 episode reward: -0.6279,                 loss: nan
agent1:                 episode reward: 0.6279,                 loss: 0.1366
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2742s / 116.8782 s
agent0:                 episode reward: -0.7264,                 loss: nan
agent1:                 episode reward: 0.7264,                 loss: 0.1366
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2468s / 117.1250 s
agent0:                 episode reward: -0.2215,                 loss: nan
agent1:                 episode reward: 0.2215,                 loss: 0.1361
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2373s / 117.3623 s
agent0:                 episode reward: -0.7072,                 loss: nan
agent1:                 episode reward: 0.7072,                 loss: 0.1362
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2374s / 117.5997 s
agent0:                 episode reward: -0.1467,                 loss: nan
agent1:                 episode reward: 0.1467,                 loss: 0.1359
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2730s / 117.8727 s
agent0:                 episode reward: -0.0826,                 loss: nan
agent1:                 episode reward: 0.0826,                 loss: 0.1357
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2485s / 118.1212 s
agent0:                 episode reward: -0.8566,                 loss: nan
agent1:                 episode reward: 0.8566,                 loss: 0.1360
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2536s / 118.3748 s
agent0:                 episode reward: -0.3145,                 loss: nan
agent1:                 episode reward: 0.3145,                 loss: 0.1358
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2550s / 118.6298 s
agent0:                 episode reward: -0.6905,                 loss: nan
agent1:                 episode reward: 0.6905,                 loss: 0.1361
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2478s / 118.8775 s
agent0:                 episode reward: -0.4739,                 loss: nan
agent1:                 episode reward: 0.4739,                 loss: 0.1354
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2602s / 119.1377 s
agent0:                 episode reward: -0.5841,                 loss: nan
agent1:                 episode reward: 0.5841,                 loss: 0.1351
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2416s / 119.3793 s
agent0:                 episode reward: -0.7522,                 loss: nan
agent1:                 episode reward: 0.7522,                 loss: 0.1350
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2515s / 119.6308 s
agent0:                 episode reward: -0.3879,                 loss: nan
agent1:                 episode reward: 0.3879,                 loss: 0.1348
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2671s / 119.8979 s
agent0:                 episode reward: -0.4509,                 loss: nan
agent1:                 episode reward: 0.4509,                 loss: 0.1376
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2487s / 120.1467 s
agent0:                 episode reward: -0.6519,                 loss: nan
agent1:                 episode reward: 0.6519,                 loss: 0.1361
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2368s / 120.3835 s
agent0:                 episode reward: -0.4208,                 loss: nan
agent1:                 episode reward: 0.4208,                 loss: 0.1362
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2372s / 120.6207 s
agent0:                 episode reward: -0.4195,                 loss: nan
agent1:                 episode reward: 0.4195,                 loss: 0.1369
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2442s / 120.8649 s
agent0:                 episode reward: -1.1528,                 loss: nan
agent1:                 episode reward: 1.1528,                 loss: 0.1365
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2417s / 121.1066 s
agent0:                 episode reward: -0.5787,                 loss: nan
agent1:                 episode reward: 0.5787,                 loss: 0.1359
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2337s / 121.3403 s
agent0:                 episode reward: -0.7151,                 loss: nan
agent1:                 episode reward: 0.7151,                 loss: 0.1348
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2448s / 121.5851 s
agent0:                 episode reward: -0.4455,                 loss: nan
agent1:                 episode reward: 0.4455,                 loss: 0.1359
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2388s / 121.8239 s
agent0:                 episode reward: -0.2482,                 loss: nan
agent1:                 episode reward: 0.2482,                 loss: 0.1370
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2417s / 122.0656 s
agent0:                 episode reward: -0.6378,                 loss: nan
agent1:                 episode reward: 0.6378,                 loss: 0.1361
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2405s / 122.3061 s
agent0:                 episode reward: -0.7994,                 loss: nan
agent1:                 episode reward: 0.7994,                 loss: 0.1356
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2415s / 122.5476 s
agent0:                 episode reward: -0.5821,                 loss: nan
agent1:                 episode reward: 0.5821,                 loss: 0.1347
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2489s / 122.7965 s
agent0:                 episode reward: -0.4932,                 loss: nan
agent1:                 episode reward: 0.4932,                 loss: 0.1346
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2685s / 123.0650 s
agent0:                 episode reward: -0.6682,                 loss: nan
agent1:                 episode reward: 0.6682,                 loss: 0.1349
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2442s / 123.3092 s
agent0:                 episode reward: -0.4922,                 loss: nan
agent1:                 episode reward: 0.4922,                 loss: 0.1345
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2450s / 123.5542 s
agent0:                 episode reward: -0.2968,                 loss: nan
agent1:                 episode reward: 0.2968,                 loss: 0.1344
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2392s / 123.7933 s
agent0:                 episode reward: -0.6402,                 loss: nan
agent1:                 episode reward: 0.6402,                 loss: 0.1347
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2405s / 124.0338 s
agent0:                 episode reward: -0.4527,                 loss: nan
agent1:                 episode reward: 0.4527,                 loss: 0.1343
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2442s / 124.2781 s
agent0:                 episode reward: -0.2469,                 loss: nan
agent1:                 episode reward: 0.2469,                 loss: 0.1363
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2387s / 124.5168 s
agent0:                 episode reward: -0.4126,                 loss: nan
agent1:                 episode reward: 0.4126,                 loss: 0.1349
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2407s / 124.7576 s
agent0:                 episode reward: -0.4312,                 loss: nan
agent1:                 episode reward: 0.4312,                 loss: 0.1345
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2380s / 124.9955 s
agent0:                 episode reward: -0.6187,                 loss: nan
agent1:                 episode reward: 0.6187,                 loss: 0.1347
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2400s / 125.2356 s
agent0:                 episode reward: -0.8228,                 loss: nan
agent1:                 episode reward: 0.8228,                 loss: 0.1362
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2500s / 125.4856 s
agent0:                 episode reward: -0.2099,                 loss: nan
agent1:                 episode reward: 0.2099,                 loss: 0.1323
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2408s / 125.7264 s
agent0:                 episode reward: -0.3749,                 loss: nan
agent1:                 episode reward: 0.3749,                 loss: 0.1346
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2415s / 125.9678 s
agent0:                 episode reward: -0.6722,                 loss: nan
agent1:                 episode reward: 0.6722,                 loss: 0.1350
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2431s / 126.2110 s
agent0:                 episode reward: -0.5143,                 loss: nan
agent1:                 episode reward: 0.5143,                 loss: 0.1342
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2428s / 126.4538 s
agent0:                 episode reward: -0.6975,                 loss: nan
agent1:                 episode reward: 0.6975,                 loss: 0.1334
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2411s / 126.6949 s
agent0:                 episode reward: -0.4649,                 loss: nan
agent1:                 episode reward: 0.4649,                 loss: 0.1350
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2436s / 126.9385 s
agent0:                 episode reward: -0.7268,                 loss: nan
agent1:                 episode reward: 0.7268,                 loss: 0.1336
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2456s / 127.1841 s
agent0:                 episode reward: -0.5919,                 loss: nan
agent1:                 episode reward: 0.5919,                 loss: 0.1351
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2531s / 127.4372 s
agent0:                 episode reward: -0.8355,                 loss: nan
agent1:                 episode reward: 0.8355,                 loss: 0.1347
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2323s / 127.6695 s
agent0:                 episode reward: -0.4792,                 loss: nan
agent1:                 episode reward: 0.4792,                 loss: 0.1347
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2378s / 127.9073 s
agent0:                 episode reward: -0.8822,                 loss: nan
agent1:                 episode reward: 0.8822,                 loss: 0.1337
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2296s / 128.1369 s
agent0:                 episode reward: -0.7236,                 loss: nan
agent1:                 episode reward: 0.7236,                 loss: 0.1325
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2377s / 128.3747 s
agent0:                 episode reward: -0.1045,                 loss: nan
agent1:                 episode reward: 0.1045,                 loss: 0.1334
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 128.6252 s
agent0:                 episode reward: -0.5978,                 loss: nan
agent1:                 episode reward: 0.5978,                 loss: 0.1327
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2718s / 128.8970 s
agent0:                 episode reward: -0.7517,                 loss: nan
agent1:                 episode reward: 0.7517,                 loss: 0.1341
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2517s / 129.1487 s
agent0:                 episode reward: -0.7881,                 loss: nan
agent1:                 episode reward: 0.7881,                 loss: 0.1329
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2522s / 129.4008 s
agent0:                 episode reward: -0.6062,                 loss: nan
agent1:                 episode reward: 0.6062,                 loss: 0.1337
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2475s / 129.6483 s
agent0:                 episode reward: -0.3292,                 loss: nan
agent1:                 episode reward: 0.3292,                 loss: 0.1328
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2500s / 129.8983 s
agent0:                 episode reward: -0.5345,                 loss: nan
agent1:                 episode reward: 0.5345,                 loss: 0.1316
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2505s / 130.1488 s
agent0:                 episode reward: -0.9818,                 loss: nan
agent1:                 episode reward: 0.9818,                 loss: 0.1335
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2641s / 130.4129 s
agent0:                 episode reward: -0.3128,                 loss: nan
agent1:                 episode reward: 0.3128,                 loss: 0.1328
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2516s / 130.6645 s
agent0:                 episode reward: -0.5417,                 loss: nan
agent1:                 episode reward: 0.5417,                 loss: 0.1335
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2500s / 130.9146 s
agent0:                 episode reward: -0.1136,                 loss: nan
agent1:                 episode reward: 0.1136,                 loss: 0.1338
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2508s / 131.1654 s
agent0:                 episode reward: -0.3672,                 loss: nan
agent1:                 episode reward: 0.3672,                 loss: 0.1357
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2501s / 131.4155 s
agent0:                 episode reward: -0.8870,                 loss: nan
agent1:                 episode reward: 0.8870,                 loss: 0.1340
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2517s / 131.6672 s
agent0:                 episode reward: -0.4776,                 loss: nan
agent1:                 episode reward: 0.4776,                 loss: 0.1344
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2510s / 131.9182 s
agent0:                 episode reward: -0.4037,                 loss: nan
agent1:                 episode reward: 0.4037,                 loss: 0.1337
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2522s / 132.1704 s
agent0:                 episode reward: -0.7592,                 loss: nan
agent1:                 episode reward: 0.7592,                 loss: 0.1341
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 132.4290 s
agent0:                 episode reward: -0.4219,                 loss: nan
agent1:                 episode reward: 0.4219,                 loss: 0.1328
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2450s / 132.6739 s
agent0:                 episode reward: -0.5977,                 loss: nan
agent1:                 episode reward: 0.5977,                 loss: 0.1332
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2459s / 132.9198 s
agent0:                 episode reward: -0.5239,                 loss: nan
agent1:                 episode reward: 0.5239,                 loss: 0.1338
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2443s / 133.1641 s
agent0:                 episode reward: -0.4361,                 loss: nan
agent1:                 episode reward: 0.4361,                 loss: 0.1333
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2463s / 133.4104 s
agent0:                 episode reward: -0.4496,                 loss: nan
agent1:                 episode reward: 0.4496,                 loss: 0.1329
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2450s / 133.6554 s
agent0:                 episode reward: -0.6864,                 loss: nan
agent1:                 episode reward: 0.6864,                 loss: 0.1334
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2438s / 133.8992 s
agent0:                 episode reward: -0.4909,                 loss: nan
agent1:                 episode reward: 0.4909,                 loss: 0.1322
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2421s / 134.1413 s
agent0:                 episode reward: -0.4214,                 loss: nan
agent1:                 episode reward: 0.4214,                 loss: 0.1330
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2445s / 134.3858 s
agent0:                 episode reward: -0.5369,                 loss: nan
agent1:                 episode reward: 0.5369,                 loss: 0.1324
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 134.6624 s
agent0:                 episode reward: -0.3251,                 loss: nan
agent1:                 episode reward: 0.3251,                 loss: 0.1342
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2523s / 134.9147 s
agent0:                 episode reward: -0.5100,                 loss: nan
agent1:                 episode reward: 0.5100,                 loss: 0.1354
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2408s / 135.1555 s
agent0:                 episode reward: -0.5611,                 loss: nan
agent1:                 episode reward: 0.5611,                 loss: 0.1344
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2331s / 135.3886 s
agent0:                 episode reward: -0.6916,                 loss: nan
agent1:                 episode reward: 0.6916,                 loss: 0.1347
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2590s / 135.6476 s
agent0:                 episode reward: -0.7368,                 loss: nan
agent1:                 episode reward: 0.7368,                 loss: 0.1337
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2504s / 135.8980 s
agent0:                 episode reward: -0.5863,                 loss: nan
agent1:                 episode reward: 0.5863,                 loss: 0.1320
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2385s / 136.1365 s
agent0:                 episode reward: -0.3213,                 loss: nan
agent1:                 episode reward: 0.3213,                 loss: 0.1344
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2449s / 136.3814 s
agent0:                 episode reward: -0.4346,                 loss: nan
agent1:                 episode reward: 0.4346,                 loss: 0.1343
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2486s / 136.6300 s
agent0:                 episode reward: -0.7889,                 loss: nan
agent1:                 episode reward: 0.7889,                 loss: 0.1340
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2496s / 136.8797 s
agent0:                 episode reward: -0.6381,                 loss: nan
agent1:                 episode reward: 0.6381,                 loss: 0.1351
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2433s / 137.1230 s
agent0:                 episode reward: -0.4294,                 loss: nan
agent1:                 episode reward: 0.4294,                 loss: 0.1325
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2375s / 137.3605 s
agent0:                 episode reward: -0.3396,                 loss: nan
agent1:                 episode reward: 0.3396,                 loss: 0.1320
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2671s / 137.6276 s
agent0:                 episode reward: -0.3888,                 loss: nan
agent1:                 episode reward: 0.3888,                 loss: 0.1336
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2674s / 137.8949 s
agent0:                 episode reward: -0.7114,                 loss: nan
agent1:                 episode reward: 0.7114,                 loss: 0.1323
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2517s / 138.1467 s
agent0:                 episode reward: -0.7744,                 loss: nan
agent1:                 episode reward: 0.7744,                 loss: 0.1328
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2437s / 138.3903 s
agent0:                 episode reward: -0.6127,                 loss: nan
agent1:                 episode reward: 0.6127,                 loss: 0.1339
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2474s / 138.6377 s
agent0:                 episode reward: -0.4568,                 loss: nan
agent1:                 episode reward: 0.4568,                 loss: 0.1351
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2462s / 138.8840 s
agent0:                 episode reward: -0.7881,                 loss: nan
agent1:                 episode reward: 0.7881,                 loss: 0.1336
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 139.1312 s
agent0:                 episode reward: -0.2585,                 loss: nan
agent1:                 episode reward: 0.2585,                 loss: 0.1337
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2481s / 139.3793 s
agent0:                 episode reward: -0.5746,                 loss: nan
agent1:                 episode reward: 0.5746,                 loss: 0.1345
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2465s / 139.6258 s
agent0:                 episode reward: -0.8595,                 loss: nan
agent1:                 episode reward: 0.8595,                 loss: 0.1341
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2423s / 139.8681 s
agent0:                 episode reward: -0.7505,                 loss: nan
agent1:                 episode reward: 0.7505,                 loss: 0.1339
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2426s / 140.1107 s
agent0:                 episode reward: -1.0275,                 loss: nan
agent1:                 episode reward: 1.0275,                 loss: 0.1343
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2440s / 140.3547 s
agent0:                 episode reward: -0.6919,                 loss: nan
agent1:                 episode reward: 0.6919,                 loss: 0.1349
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2668s / 140.6214 s
agent0:                 episode reward: -0.4697,                 loss: nan
agent1:                 episode reward: 0.4697,                 loss: 0.1348
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2596s / 140.8811 s
agent0:                 episode reward: -0.7698,                 loss: nan
agent1:                 episode reward: 0.7698,                 loss: 0.1346
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2499s / 141.1309 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.1329
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2483s / 141.3792 s
agent0:                 episode reward: -0.5711,                 loss: nan
agent1:                 episode reward: 0.5711,                 loss: 0.1353
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2429s / 141.6221 s
agent0:                 episode reward: -1.0713,                 loss: nan
agent1:                 episode reward: 1.0713,                 loss: 0.1339
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2386s / 141.8607 s
agent0:                 episode reward: -0.4969,                 loss: nan
agent1:                 episode reward: 0.4969,                 loss: 0.1346
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2367s / 142.0974 s
agent0:                 episode reward: -0.5637,                 loss: nan
agent1:                 episode reward: 0.5637,                 loss: 0.1331
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2377s / 142.3351 s
agent0:                 episode reward: -0.1917,                 loss: nan
agent1:                 episode reward: 0.1917,                 loss: 0.1344
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2389s / 142.5740 s
agent0:                 episode reward: -0.7158,                 loss: nan
agent1:                 episode reward: 0.7158,                 loss: 0.1343
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2381s / 142.8121 s
agent0:                 episode reward: -0.4890,                 loss: nan
agent1:                 episode reward: 0.4890,                 loss: 0.1357
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2417s / 143.0539 s
agent0:                 episode reward: -0.6454,                 loss: nan
agent1:                 episode reward: 0.6454,                 loss: 0.1339
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2436s / 143.2975 s
agent0:                 episode reward: -0.5123,                 loss: nan
agent1:                 episode reward: 0.5123,                 loss: 0.1329
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2535s / 143.5510 s
agent0:                 episode reward: -1.0174,                 loss: nan
agent1:                 episode reward: 1.0174,                 loss: 0.1338
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2817s / 143.8326 s
agent0:                 episode reward: -0.7739,                 loss: nan
agent1:                 episode reward: 0.7739,                 loss: 0.1330
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2668s / 144.0994 s
agent0:                 episode reward: -0.7565,                 loss: nan
agent1:                 episode reward: 0.7565,                 loss: 0.1329
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2531s / 144.3525 s
agent0:                 episode reward: -1.0272,                 loss: nan
agent1:                 episode reward: 1.0272,                 loss: 0.1322
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2595s / 144.6119 s
agent0:                 episode reward: -0.4601,                 loss: nan
agent1:                 episode reward: 0.4601,                 loss: 0.1322
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 144.8708 s
agent0:                 episode reward: -0.5874,                 loss: nan
agent1:                 episode reward: 0.5874,                 loss: 0.1327
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2570s / 145.1278 s
agent0:                 episode reward: -0.7102,                 loss: nan
agent1:                 episode reward: 0.7102,                 loss: 0.1323
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2706s / 145.3984 s
agent0:                 episode reward: -0.4194,                 loss: nan
agent1:                 episode reward: 0.4194,                 loss: 0.1326
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2548s / 145.6532 s
agent0:                 episode reward: -0.7992,                 loss: nan
agent1:                 episode reward: 0.7992,                 loss: 0.1332
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2413s / 145.8945 s
agent0:                 episode reward: -0.5339,                 loss: nan
agent1:                 episode reward: 0.5339,                 loss: 0.1334
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2457s / 146.1402 s
agent0:                 episode reward: -0.5769,                 loss: nan
agent1:                 episode reward: 0.5769,                 loss: 0.1325
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2630s / 146.4032 s
agent0:                 episode reward: -0.8955,                 loss: nan
agent1:                 episode reward: 0.8955,                 loss: 0.1324
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2534s / 146.6566 s
agent0:                 episode reward: -0.4747,                 loss: nan
agent1:                 episode reward: 0.4747,                 loss: 0.1323
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2665s / 146.9231 s
agent0:                 episode reward: -0.4898,                 loss: nan
agent1:                 episode reward: 0.4898,                 loss: 0.1334
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 147.1792 s
agent0:                 episode reward: -0.5061,                 loss: nan
agent1:                 episode reward: 0.5061,                 loss: 0.1318
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2459s / 147.4250 s
agent0:                 episode reward: -0.7063,                 loss: nan
agent1:                 episode reward: 0.7063,                 loss: 0.1340
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2508s / 147.6758 s
agent0:                 episode reward: -0.4569,                 loss: nan
agent1:                 episode reward: 0.4569,                 loss: 0.1335
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2376s / 147.9134 s
agent0:                 episode reward: -0.8265,                 loss: nan
agent1:                 episode reward: 0.8265,                 loss: 0.1321
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2374s / 148.1508 s
agent0:                 episode reward: -0.3261,                 loss: nan
agent1:                 episode reward: 0.3261,                 loss: 0.1333
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2406s / 148.3914 s
agent0:                 episode reward: -0.3503,                 loss: nan
agent1:                 episode reward: 0.3503,                 loss: 0.1353
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2555s / 148.6469 s
agent0:                 episode reward: -0.4233,                 loss: nan
agent1:                 episode reward: 0.4233,                 loss: 0.1339
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2585s / 148.9055 s
agent0:                 episode reward: -0.4786,                 loss: nan
agent1:                 episode reward: 0.4786,                 loss: 0.1327
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2524s / 149.1578 s
agent0:                 episode reward: -0.3337,                 loss: nan
agent1:                 episode reward: 0.3337,                 loss: 0.1350
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2521s / 149.4099 s
agent0:                 episode reward: -0.4874,                 loss: nan
agent1:                 episode reward: 0.4874,                 loss: 0.1344
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2593s / 149.6693 s
agent0:                 episode reward: -0.5350,                 loss: nan
agent1:                 episode reward: 0.5350,                 loss: 0.1338
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2738s / 149.9431 s
agent0:                 episode reward: -1.0174,                 loss: nan
agent1:                 episode reward: 1.0174,                 loss: 0.1340
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 150.2092 s
agent0:                 episode reward: -0.2353,                 loss: nan
agent1:                 episode reward: 0.2353,                 loss: 0.1334
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2497s / 150.4589 s
agent0:                 episode reward: -0.6231,                 loss: nan
agent1:                 episode reward: 0.6231,                 loss: 0.1330
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2574s / 150.7163 s
agent0:                 episode reward: -0.3195,                 loss: nan
agent1:                 episode reward: 0.3195,                 loss: 0.1335
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2560s / 150.9723 s
agent0:                 episode reward: -0.4863,                 loss: nan
agent1:                 episode reward: 0.4863,                 loss: 0.1339
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2526s / 151.2249 s
agent0:                 episode reward: -0.6313,                 loss: nan
agent1:                 episode reward: 0.6313,                 loss: 0.1318
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2487s / 151.4736 s
agent0:                 episode reward: -0.6182,                 loss: nan
agent1:                 episode reward: 0.6182,                 loss: 0.1331
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2446s / 151.7181 s
agent0:                 episode reward: -0.5599,                 loss: nan
agent1:                 episode reward: 0.5599,                 loss: 0.1338
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2433s / 151.9614 s
agent0:                 episode reward: -0.6338,                 loss: nan
agent1:                 episode reward: 0.6338,                 loss: 0.1321
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2558s / 152.2172 s
agent0:                 episode reward: -0.7116,                 loss: nan
agent1:                 episode reward: 0.7116,                 loss: 0.1323
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2628s / 152.4800 s
agent0:                 episode reward: -0.5204,                 loss: nan
agent1:                 episode reward: 0.5204,                 loss: 0.1317
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2554s / 152.7354 s
agent0:                 episode reward: -1.0056,                 loss: nan
agent1:                 episode reward: 1.0056,                 loss: 0.1325
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2737s / 153.0092 s
agent0:                 episode reward: -0.2720,                 loss: nan
agent1:                 episode reward: 0.2720,                 loss: 0.1331
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2539s / 153.2631 s
agent0:                 episode reward: -0.2675,                 loss: nan
agent1:                 episode reward: 0.2675,                 loss: 0.1303
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2590s / 153.5221 s
agent0:                 episode reward: -0.5777,                 loss: nan
agent1:                 episode reward: 0.5777,                 loss: 0.1327
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2548s / 153.7769 s
agent0:                 episode reward: -0.5935,                 loss: nan
agent1:                 episode reward: 0.5935,                 loss: 0.1330
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2515s / 154.0284 s
agent0:                 episode reward: -0.6725,                 loss: nan
agent1:                 episode reward: 0.6725,                 loss: 0.1324
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 154.2864 s
agent0:                 episode reward: -0.6118,                 loss: nan
agent1:                 episode reward: 0.6118,                 loss: 0.1328
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 154.5462 s
agent0:                 episode reward: -0.5191,                 loss: nan
agent1:                 episode reward: 0.5191,                 loss: 0.1312
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2516s / 154.7978 s
agent0:                 episode reward: -0.4571,                 loss: nan
agent1:                 episode reward: 0.4571,                 loss: 0.1338
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2688s / 155.0665 s
agent0:                 episode reward: -0.7606,                 loss: nan
agent1:                 episode reward: 0.7606,                 loss: 0.1309
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3067s / 155.3732 s
agent0:                 episode reward: -0.4059,                 loss: nan
agent1:                 episode reward: 0.4059,                 loss: 0.1314
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2722s / 155.6453 s
agent0:                 episode reward: -0.3825,                 loss: nan
agent1:                 episode reward: 0.3825,                 loss: 0.1317
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2712s / 155.9165 s
agent0:                 episode reward: -0.8618,                 loss: nan
agent1:                 episode reward: 0.8618,                 loss: 0.1322
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2899s / 156.2064 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.1343
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2770s / 156.4834 s
agent0:                 episode reward: -0.9500,                 loss: nan
agent1:                 episode reward: 0.9500,                 loss: 0.1327
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2454s / 156.7288 s
agent0:                 episode reward: -0.4147,                 loss: nan
agent1:                 episode reward: 0.4147,                 loss: 0.1329
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2393s / 156.9681 s
agent0:                 episode reward: -0.8974,                 loss: nan
agent1:                 episode reward: 0.8974,                 loss: 0.1313
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2402s / 157.2083 s
agent0:                 episode reward: -0.8468,                 loss: nan
agent1:                 episode reward: 0.8468,                 loss: 0.1313
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2388s / 157.4471 s
agent0:                 episode reward: -0.4881,                 loss: nan
agent1:                 episode reward: 0.4881,                 loss: 0.1320
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2445s / 157.6917 s
agent0:                 episode reward: -0.5247,                 loss: nan
agent1:                 episode reward: 0.5247,                 loss: 0.1339
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2440s / 157.9357 s
agent0:                 episode reward: -0.5722,                 loss: nan
agent1:                 episode reward: 0.5722,                 loss: 0.1321
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2461s / 158.1818 s
agent0:                 episode reward: -0.8375,                 loss: nan
agent1:                 episode reward: 0.8375,                 loss: 0.1334
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2490s / 158.4308 s
agent0:                 episode reward: -0.4606,                 loss: nan
agent1:                 episode reward: 0.4606,                 loss: 0.1324
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2527s / 158.6835 s
agent0:                 episode reward: -0.3790,                 loss: nan
agent1:                 episode reward: 0.3790,                 loss: 0.1304
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 158.9416 s
agent0:                 episode reward: -1.0488,                 loss: nan
agent1:                 episode reward: 1.0488,                 loss: 0.1327
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2898s / 159.2313 s
agent0:                 episode reward: -0.5359,                 loss: nan
agent1:                 episode reward: 0.5359,                 loss: 0.1325
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2654s / 159.4967 s
agent0:                 episode reward: -0.1994,                 loss: nan
agent1:                 episode reward: 0.1994,                 loss: 0.1303
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2639s / 159.7607 s
agent0:                 episode reward: -0.7621,                 loss: nan
agent1:                 episode reward: 0.7621,                 loss: 0.1326
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2544s / 160.0151 s
agent0:                 episode reward: -0.6513,                 loss: nan
agent1:                 episode reward: 0.6513,                 loss: 0.1316
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2534s / 160.2685 s
agent0:                 episode reward: -0.4728,                 loss: nan
agent1:                 episode reward: 0.4728,                 loss: 0.1331
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2693s / 160.5378 s
agent0:                 episode reward: -0.5336,                 loss: nan
agent1:                 episode reward: 0.5336,                 loss: 0.1318
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2824s / 160.8201 s
agent0:                 episode reward: -0.6255,                 loss: nan
agent1:                 episode reward: 0.6255,                 loss: 0.1322
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2674s / 161.0876 s
agent0:                 episode reward: -0.7761,                 loss: nan
agent1:                 episode reward: 0.7761,                 loss: 0.1321
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2743s / 161.3619 s
agent0:                 episode reward: -0.6852,                 loss: nan
agent1:                 episode reward: 0.6852,                 loss: 0.1336
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2715s / 161.6334 s
agent0:                 episode reward: -0.6545,                 loss: nan
agent1:                 episode reward: 0.6545,                 loss: 0.1317
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2620s / 161.8954 s
agent0:                 episode reward: -0.2737,                 loss: nan
agent1:                 episode reward: 0.2737,                 loss: 0.1338
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2605s / 162.1558 s
agent0:                 episode reward: -1.2628,                 loss: nan
agent1:                 episode reward: 1.2628,                 loss: 0.1332
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2608s / 162.4166 s
agent0:                 episode reward: -1.0674,                 loss: nan
agent1:                 episode reward: 1.0674,                 loss: 0.1311
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2578s / 162.6744 s
agent0:                 episode reward: -0.5680,                 loss: nan
agent1:                 episode reward: 0.5680,                 loss: 0.1314
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2568s / 162.9312 s
agent0:                 episode reward: -0.4158,                 loss: nan
agent1:                 episode reward: 0.4158,                 loss: 0.1331
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2506s / 163.1817 s
agent0:                 episode reward: -0.7385,                 loss: nan
agent1:                 episode reward: 0.7385,                 loss: 0.1331
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2496s / 163.4313 s
agent0:                 episode reward: -0.8871,                 loss: nan
agent1:                 episode reward: 0.8871,                 loss: 0.1322
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2454s / 163.6767 s
agent0:                 episode reward: -0.4597,                 loss: nan
agent1:                 episode reward: 0.4597,                 loss: 0.1324
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2462s / 163.9228 s
agent0:                 episode reward: -0.7026,                 loss: nan
agent1:                 episode reward: 0.7026,                 loss: 0.1323
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2455s / 164.1684 s
agent0:                 episode reward: -0.4009,                 loss: nan
agent1:                 episode reward: 0.4009,                 loss: 0.1338
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2459s / 164.4143 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.1316
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2747s / 164.6890 s
agent0:                 episode reward: -0.7032,                 loss: nan
agent1:                 episode reward: 0.7032,                 loss: 0.1316
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2972s / 164.9862 s
agent0:                 episode reward: -0.1859,                 loss: nan
agent1:                 episode reward: 0.1859,                 loss: 0.1313
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3074s / 165.2936 s
agent0:                 episode reward: -0.6237,                 loss: nan
agent1:                 episode reward: 0.6237,                 loss: 0.1309
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 165.5547 s
agent0:                 episode reward: -0.6528,                 loss: nan
agent1:                 episode reward: 0.6528,                 loss: 0.1328
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2641s / 165.8188 s
agent0:                 episode reward: -0.4567,                 loss: nan
agent1:                 episode reward: 0.4567,                 loss: 0.1324
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2560s / 166.0748 s
agent0:                 episode reward: -0.5159,                 loss: nan
agent1:                 episode reward: 0.5159,                 loss: 0.1305
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2507s / 166.3255 s
agent0:                 episode reward: -0.7229,                 loss: nan
agent1:                 episode reward: 0.7229,                 loss: 0.1314
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2542s / 166.5797 s
agent0:                 episode reward: -0.8421,                 loss: nan
agent1:                 episode reward: 0.8421,                 loss: 0.1324
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2645s / 166.8442 s
agent0:                 episode reward: -0.4990,                 loss: nan
agent1:                 episode reward: 0.4990,                 loss: 0.1320
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2558s / 167.1000 s
agent0:                 episode reward: -0.5418,                 loss: nan
agent1:                 episode reward: 0.5418,                 loss: 0.1318
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 167.3618 s
agent0:                 episode reward: -0.5840,                 loss: nan
agent1:                 episode reward: 0.5840,                 loss: 0.1314
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2533s / 167.6151 s
agent0:                 episode reward: -0.8250,                 loss: nan
agent1:                 episode reward: 0.8250,                 loss: 0.1343
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 167.8729 s
agent0:                 episode reward: -0.2686,                 loss: nan
agent1:                 episode reward: 0.2686,                 loss: 0.1322
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2782s / 168.1511 s
agent0:                 episode reward: -0.7428,                 loss: nan
agent1:                 episode reward: 0.7428,                 loss: 0.1306
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2596s / 168.4108 s
agent0:                 episode reward: -0.6033,                 loss: nan
agent1:                 episode reward: 0.6033,                 loss: 0.1320
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 168.6697 s
agent0:                 episode reward: -0.7703,                 loss: nan
agent1:                 episode reward: 0.7703,                 loss: 0.1304
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 168.9454 s
agent0:                 episode reward: -0.4746,                 loss: nan
agent1:                 episode reward: 0.4746,                 loss: 0.1314
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2607s / 169.2062 s
agent0:                 episode reward: -0.4853,                 loss: nan
agent1:                 episode reward: 0.4853,                 loss: 0.1321
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2543s / 169.4605 s
agent0:                 episode reward: -0.7679,                 loss: nan
agent1:                 episode reward: 0.7679,                 loss: 0.1307
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2550s / 169.7154 s
agent0:                 episode reward: -0.5189,                 loss: nan
agent1:                 episode reward: 0.5189,                 loss: 0.1309
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2615s / 169.9770 s
agent0:                 episode reward: -0.4726,                 loss: nan
agent1:                 episode reward: 0.4726,                 loss: 0.1305
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2626s / 170.2396 s
agent0:                 episode reward: -0.8206,                 loss: nan
agent1:                 episode reward: 0.8206,                 loss: 0.1313
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2653s / 170.5049 s
agent0:                 episode reward: -0.5587,                 loss: nan
agent1:                 episode reward: 0.5587,                 loss: 0.1311
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2589s / 170.7639 s
agent0:                 episode reward: -0.3695,                 loss: nan
agent1:                 episode reward: 0.3695,                 loss: 0.1318
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2783s / 171.0422 s
agent0:                 episode reward: -0.6402,                 loss: nan
agent1:                 episode reward: 0.6402,                 loss: 0.1317
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2755s / 171.3177 s
agent0:                 episode reward: -0.5027,                 loss: nan
agent1:                 episode reward: 0.5027,                 loss: 0.1315
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 171.5776 s
agent0:                 episode reward: -0.9970,                 loss: nan
agent1:                 episode reward: 0.9970,                 loss: 0.1325
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2654s / 171.8430 s
agent0:                 episode reward: -0.3633,                 loss: nan
agent1:                 episode reward: 0.3633,                 loss: 0.1306
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2615s / 172.1044 s
agent0:                 episode reward: -0.8772,                 loss: nan
agent1:                 episode reward: 0.8772,                 loss: 0.1302
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2668s / 172.3712 s
agent0:                 episode reward: -0.6719,                 loss: nan
agent1:                 episode reward: 0.6719,                 loss: 0.1298
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2642s / 172.6354 s
agent0:                 episode reward: -0.3374,                 loss: nan
agent1:                 episode reward: 0.3374,                 loss: 0.1331
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 172.8987 s
agent0:                 episode reward: -0.9376,                 loss: nan
agent1:                 episode reward: 0.9376,                 loss: 0.1297
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 173.1597 s
agent0:                 episode reward: -0.5917,                 loss: nan
agent1:                 episode reward: 0.5917,                 loss: 0.1326
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 173.4209 s
agent0:                 episode reward: -0.8767,                 loss: nan
agent1:                 episode reward: 0.8767,                 loss: 0.1297
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2613s / 173.6822 s
agent0:                 episode reward: -0.5021,                 loss: nan
agent1:                 episode reward: 0.5021,                 loss: 0.1327
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2707s / 173.9529 s
agent0:                 episode reward: -0.7421,                 loss: nan
agent1:                 episode reward: 0.7421,                 loss: 0.1331
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2770s / 174.2300 s
agent0:                 episode reward: -0.8280,                 loss: nan
agent1:                 episode reward: 0.8280,                 loss: 0.1310
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2591s / 174.4891 s
agent0:                 episode reward: -0.4777,                 loss: nan
agent1:                 episode reward: 0.4777,                 loss: 0.1340
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 174.7471 s
agent0:                 episode reward: -0.4550,                 loss: nan
agent1:                 episode reward: 0.4550,                 loss: 0.1336
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 175.0016 s
agent0:                 episode reward: -1.2483,                 loss: nan
agent1:                 episode reward: 1.2483,                 loss: 0.1324
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2504s / 175.2520 s
agent0:                 episode reward: -0.7112,                 loss: nan
agent1:                 episode reward: 0.7112,                 loss: 0.1332
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2564s / 175.5084 s
agent0:                 episode reward: -0.5337,                 loss: nan
agent1:                 episode reward: 0.5337,                 loss: 0.1320
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2587s / 175.7670 s
agent0:                 episode reward: -0.6835,                 loss: nan
agent1:                 episode reward: 0.6835,                 loss: 0.1314
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2554s / 176.0225 s
agent0:                 episode reward: -0.3532,                 loss: nan
agent1:                 episode reward: 0.3532,                 loss: 0.1318
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2537s / 176.2762 s
agent0:                 episode reward: -0.3693,                 loss: nan
agent1:                 episode reward: 0.3693,                 loss: 0.1331
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2529s / 176.5291 s
agent0:                 episode reward: -0.7938,                 loss: nan
agent1:                 episode reward: 0.7938,                 loss: 0.1321
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2515s / 176.7806 s
agent0:                 episode reward: -0.3939,                 loss: nan
agent1:                 episode reward: 0.3939,                 loss: 0.1337
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2605s / 177.0410 s
agent0:                 episode reward: -0.3509,                 loss: nan
agent1:                 episode reward: 0.3509,                 loss: 0.1332
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3228s / 177.3638 s
agent0:                 episode reward: -0.3361,                 loss: nan
agent1:                 episode reward: 0.3361,                 loss: 0.1321
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 177.6434 s
agent0:                 episode reward: -0.8541,                 loss: nan
agent1:                 episode reward: 0.8541,                 loss: 0.1321
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2692s / 177.9125 s
agent0:                 episode reward: -0.7182,                 loss: nan
agent1:                 episode reward: 0.7182,                 loss: 0.1325
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2700s / 178.1825 s
agent0:                 episode reward: -0.5627,                 loss: nan
agent1:                 episode reward: 0.5627,                 loss: 0.1300
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2736s / 178.4562 s
agent0:                 episode reward: -0.6936,                 loss: nan
agent1:                 episode reward: 0.6936,                 loss: 0.1313
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2746s / 178.7308 s
agent0:                 episode reward: -0.7302,                 loss: nan
agent1:                 episode reward: 0.7302,                 loss: 0.1314
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2677s / 178.9985 s
agent0:                 episode reward: -0.3999,                 loss: nan
agent1:                 episode reward: 0.3999,                 loss: 0.1308
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2713s / 179.2699 s
agent0:                 episode reward: -0.8601,                 loss: nan
agent1:                 episode reward: 0.8601,                 loss: 0.1326
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2674s / 179.5373 s
agent0:                 episode reward: -0.4256,                 loss: nan
agent1:                 episode reward: 0.4256,                 loss: 0.1323
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2713s / 179.8086 s
agent0:                 episode reward: -0.5377,                 loss: nan
agent1:                 episode reward: 0.5377,                 loss: 0.1299
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2747s / 180.0833 s
agent0:                 episode reward: -0.6612,                 loss: nan
agent1:                 episode reward: 0.6612,                 loss: 0.1305
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2740s / 180.3573 s
agent0:                 episode reward: -0.8739,                 loss: nan
agent1:                 episode reward: 0.8739,                 loss: 0.1309
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2756s / 180.6329 s
agent0:                 episode reward: -0.5035,                 loss: nan
agent1:                 episode reward: 0.5035,                 loss: 0.1316
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2768s / 180.9097 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: 0.1326
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2769s / 181.1865 s
agent0:                 episode reward: -0.7142,                 loss: nan
agent1:                 episode reward: 0.7142,                 loss: 0.1299
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2722s / 181.4587 s
agent0:                 episode reward: -0.3337,                 loss: nan
agent1:                 episode reward: 0.3337,                 loss: 0.1317
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2721s / 181.7308 s
agent0:                 episode reward: -0.9617,                 loss: nan
agent1:                 episode reward: 0.9617,                 loss: 0.1318
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2711s / 182.0018 s
agent0:                 episode reward: -0.8835,                 loss: nan
agent1:                 episode reward: 0.8835,                 loss: 0.1311
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2784s / 182.2803 s
agent0:                 episode reward: -0.3410,                 loss: nan
agent1:                 episode reward: 0.3410,                 loss: 0.1316
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2650s / 182.5453 s
agent0:                 episode reward: -0.8266,                 loss: nan
agent1:                 episode reward: 0.8266,                 loss: 0.1312
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2726s / 182.8179 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.1310
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2759s / 183.0938 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.1308
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2664s / 183.3602 s
agent0:                 episode reward: -0.7535,                 loss: nan
agent1:                 episode reward: 0.7535,                 loss: 0.1309
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2578s / 183.6181 s
agent0:                 episode reward: -0.8793,                 loss: nan
agent1:                 episode reward: 0.8793,                 loss: 0.1304
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2573s / 183.8753 s
agent0:                 episode reward: -0.6991,                 loss: nan
agent1:                 episode reward: 0.6991,                 loss: 0.1320
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2581s / 184.1334 s
agent0:                 episode reward: -1.0255,                 loss: nan
agent1:                 episode reward: 1.0255,                 loss: 0.1299
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2551s / 184.3885 s
agent0:                 episode reward: -0.4507,                 loss: nan
agent1:                 episode reward: 0.4507,                 loss: 0.1289
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2530s / 184.6415 s
agent0:                 episode reward: -0.4489,                 loss: nan
agent1:                 episode reward: 0.4489,                 loss: 0.1291
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2545s / 184.8960 s
agent0:                 episode reward: -0.5364,                 loss: nan
agent1:                 episode reward: 0.5364,                 loss: 0.1322
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2527s / 185.1487 s
agent0:                 episode reward: -0.6611,                 loss: nan
agent1:                 episode reward: 0.6611,                 loss: 0.1305
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2602s / 185.4089 s
agent0:                 episode reward: -0.3425,                 loss: nan
agent1:                 episode reward: 0.3425,                 loss: 0.1313
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2857s / 185.6946 s
agent0:                 episode reward: -0.4129,                 loss: nan
agent1:                 episode reward: 0.4129,                 loss: 0.1311
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2992s / 185.9938 s
agent0:                 episode reward: -0.5344,                 loss: nan
agent1:                 episode reward: 0.5344,                 loss: 0.1308
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2668s / 186.2606 s
agent0:                 episode reward: -0.5987,                 loss: nan
agent1:                 episode reward: 0.5987,                 loss: 0.1300
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2656s / 186.5262 s
agent0:                 episode reward: -0.7522,                 loss: nan
agent1:                 episode reward: 0.7522,                 loss: 0.1304
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2648s / 186.7910 s
agent0:                 episode reward: -0.8539,                 loss: nan
agent1:                 episode reward: 0.8539,                 loss: 0.1323
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2660s / 187.0570 s
agent0:                 episode reward: -0.7503,                 loss: nan
agent1:                 episode reward: 0.7503,                 loss: 0.1335
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2634s / 187.3204 s
agent0:                 episode reward: -0.2724,                 loss: nan
agent1:                 episode reward: 0.2724,                 loss: 0.1299
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 187.5835 s
agent0:                 episode reward: -0.5914,                 loss: nan
agent1:                 episode reward: 0.5914,                 loss: 0.1318
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2680s / 187.8515 s
agent0:                 episode reward: -0.6529,                 loss: nan
agent1:                 episode reward: 0.6529,                 loss: 0.1314
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2704s / 188.1219 s
agent0:                 episode reward: -0.2860,                 loss: nan
agent1:                 episode reward: 0.2860,                 loss: 0.1321
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2534s / 188.3753 s
agent0:                 episode reward: -0.5585,                 loss: nan
agent1:                 episode reward: 0.5585,                 loss: 0.1312
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2607s / 188.6360 s
agent0:                 episode reward: -0.7659,                 loss: nan
agent1:                 episode reward: 0.7659,                 loss: 0.1315
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 188.9126 s
agent0:                 episode reward: -0.5544,                 loss: nan
agent1:                 episode reward: 0.5544,                 loss: 0.1309
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2781s / 189.1907 s
agent0:                 episode reward: -0.5801,                 loss: nan
agent1:                 episode reward: 0.5801,                 loss: 0.1308
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2641s / 189.4548 s
agent0:                 episode reward: -0.5699,                 loss: nan
agent1:                 episode reward: 0.5699,                 loss: 0.1315
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2607s / 189.7155 s
agent0:                 episode reward: -0.6919,                 loss: nan
agent1:                 episode reward: 0.6919,                 loss: 0.1305
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2596s / 189.9751 s
agent0:                 episode reward: -0.7581,                 loss: nan
agent1:                 episode reward: 0.7581,                 loss: 0.1311
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2606s / 190.2357 s
agent0:                 episode reward: -0.9611,                 loss: nan
agent1:                 episode reward: 0.9611,                 loss: 0.1301
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2620s / 190.4977 s
agent0:                 episode reward: -0.7125,                 loss: nan
agent1:                 episode reward: 0.7125,                 loss: 0.1318
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2607s / 190.7583 s
agent0:                 episode reward: -0.6591,                 loss: nan
agent1:                 episode reward: 0.6591,                 loss: 0.1321
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2588s / 191.0171 s
agent0:                 episode reward: -0.5182,                 loss: nan
agent1:                 episode reward: 0.5182,                 loss: 0.1308
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 191.2771 s
agent0:                 episode reward: -0.6549,                 loss: nan
agent1:                 episode reward: 0.6549,                 loss: 0.1298
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2602s / 191.5372 s
agent0:                 episode reward: -0.8496,                 loss: nan
agent1:                 episode reward: 0.8496,                 loss: 0.1293
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2620s / 191.7992 s
agent0:                 episode reward: -1.2274,                 loss: nan
agent1:                 episode reward: 1.2274,                 loss: 0.1291
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2780s / 192.0772 s
agent0:                 episode reward: -0.6327,                 loss: nan
agent1:                 episode reward: 0.6327,                 loss: 0.1304
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2659s / 192.3431 s
agent0:                 episode reward: -0.5174,                 loss: nan
agent1:                 episode reward: 0.5174,                 loss: 0.1317
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2660s / 192.6091 s
agent0:                 episode reward: -0.6210,                 loss: nan
agent1:                 episode reward: 0.6210,                 loss: 0.1308
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2641s / 192.8731 s
agent0:                 episode reward: -0.3742,                 loss: nan
agent1:                 episode reward: 0.3742,                 loss: 0.1304
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2594s / 193.1326 s
agent0:                 episode reward: -0.7918,                 loss: nan
agent1:                 episode reward: 0.7918,                 loss: 0.1301
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2650s / 193.3975 s
agent0:                 episode reward: -0.3828,                 loss: nan
agent1:                 episode reward: 0.3828,                 loss: 0.1313
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2625s / 193.6600 s
agent0:                 episode reward: -0.5975,                 loss: nan
agent1:                 episode reward: 0.5975,                 loss: 0.1305
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2796s / 193.9396 s
agent0:                 episode reward: -0.8298,                 loss: nan
agent1:                 episode reward: 0.8298,                 loss: 0.1297
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2769s / 194.2165 s
agent0:                 episode reward: -0.5340,                 loss: nan
agent1:                 episode reward: 0.5340,                 loss: 0.1296
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2681s / 194.4846 s
agent0:                 episode reward: -0.5260,                 loss: nan
agent1:                 episode reward: 0.5260,                 loss: 0.1313
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2802s / 194.7648 s
agent0:                 episode reward: -0.7181,                 loss: nan
agent1:                 episode reward: 0.7181,                 loss: 0.1299
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2904s / 195.0551 s
agent0:                 episode reward: -0.7260,                 loss: nan
agent1:                 episode reward: 0.7260,                 loss: 0.1296
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2848s / 195.3399 s
agent0:                 episode reward: -0.4760,                 loss: nan
agent1:                 episode reward: 0.4760,                 loss: 0.1294
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2749s / 195.6148 s
agent0:                 episode reward: -0.8632,                 loss: nan
agent1:                 episode reward: 0.8632,                 loss: 0.1297
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2714s / 195.8862 s
agent0:                 episode reward: -0.6247,                 loss: nan
agent1:                 episode reward: 0.6247,                 loss: 0.1317
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 196.1582 s
agent0:                 episode reward: -0.2092,                 loss: nan
agent1:                 episode reward: 0.2092,                 loss: 0.1303
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 196.4411 s
agent0:                 episode reward: -0.7136,                 loss: nan
agent1:                 episode reward: 0.7136,                 loss: 0.1322
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2718s / 196.7130 s
agent0:                 episode reward: -0.6998,                 loss: nan
agent1:                 episode reward: 0.6998,                 loss: 0.1304
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 196.9850 s
agent0:                 episode reward: -0.6386,                 loss: nan
agent1:                 episode reward: 0.6386,                 loss: 0.1321
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2732s / 197.2582 s
agent0:                 episode reward: -0.6504,                 loss: nan
agent1:                 episode reward: 0.6504,                 loss: 0.1315
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2774s / 197.5355 s
agent0:                 episode reward: -0.8574,                 loss: nan
agent1:                 episode reward: 0.8574,                 loss: 0.1310
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2723s / 197.8079 s
agent0:                 episode reward: -0.5115,                 loss: nan
agent1:                 episode reward: 0.5115,                 loss: 0.1312
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2871s / 198.0950 s
agent0:                 episode reward: -0.7959,                 loss: nan
agent1:                 episode reward: 0.7959,                 loss: 0.1324
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2946s / 198.3896 s
agent0:                 episode reward: -0.7942,                 loss: nan
agent1:                 episode reward: 0.7942,                 loss: 0.1313
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2751s / 198.6646 s
agent0:                 episode reward: -0.9197,                 loss: nan
agent1:                 episode reward: 0.9197,                 loss: 0.1319
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2783s / 198.9429 s
agent0:                 episode reward: -0.2796,                 loss: nan
agent1:                 episode reward: 0.2796,                 loss: 0.1301
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2761s / 199.2190 s
agent0:                 episode reward: -0.4222,                 loss: nan
agent1:                 episode reward: 0.4222,                 loss: 0.1326
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2716s / 199.4906 s
agent0:                 episode reward: -0.9123,                 loss: nan
agent1:                 episode reward: 0.9123,                 loss: 0.1324
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2760s / 199.7666 s
agent0:                 episode reward: -0.2284,                 loss: nan
agent1:                 episode reward: 0.2284,                 loss: 0.1303
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2712s / 200.0378 s
agent0:                 episode reward: -0.7602,                 loss: nan
agent1:                 episode reward: 0.7602,                 loss: 0.1322
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 200.3144 s
agent0:                 episode reward: -0.7436,                 loss: nan
agent1:                 episode reward: 0.7436,                 loss: 0.1317
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2780s / 200.5924 s
agent0:                 episode reward: -0.5816,                 loss: nan
agent1:                 episode reward: 0.5816,                 loss: 0.1310
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 200.8681 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.1308
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 201.1479 s
agent0:                 episode reward: -0.6439,                 loss: nan
agent1:                 episode reward: 0.6439,                 loss: 0.1309
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2754s / 201.4234 s
agent0:                 episode reward: -0.4261,                 loss: nan
agent1:                 episode reward: 0.4261,                 loss: 0.1315
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2758s / 201.6992 s
agent0:                 episode reward: -0.5892,                 loss: nan
agent1:                 episode reward: 0.5892,                 loss: 0.1283
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2733s / 201.9725 s
agent0:                 episode reward: -0.7273,                 loss: nan
agent1:                 episode reward: 0.7273,                 loss: 0.1311
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2909s / 202.2634 s
agent0:                 episode reward: -0.3519,                 loss: nan
agent1:                 episode reward: 0.3519,                 loss: 0.1303
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2908s / 202.5541 s
agent0:                 episode reward: -0.4698,                 loss: nan
agent1:                 episode reward: 0.4698,                 loss: 0.1310
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2783s / 202.8325 s
agent0:                 episode reward: -0.6353,                 loss: nan
agent1:                 episode reward: 0.6353,                 loss: 0.1300
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2871s / 203.1196 s
agent0:                 episode reward: -0.6282,                 loss: nan
agent1:                 episode reward: 0.6282,                 loss: 0.1291
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2848s / 203.4043 s
agent0:                 episode reward: -0.2626,                 loss: nan
agent1:                 episode reward: 0.2626,                 loss: 0.1300
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3036s / 203.7079 s
agent0:                 episode reward: -0.7462,                 loss: nan
agent1:                 episode reward: 0.7462,                 loss: 0.1313
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2787s / 203.9866 s
agent0:                 episode reward: -0.4344,                 loss: nan
agent1:                 episode reward: 0.4344,                 loss: 0.1319
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2662s / 204.2528 s
agent0:                 episode reward: -0.4706,                 loss: nan
agent1:                 episode reward: 0.4706,                 loss: 0.1289
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2633s / 204.5161 s
agent0:                 episode reward: -0.3680,                 loss: nan
agent1:                 episode reward: 0.3680,                 loss: 0.1313
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2676s / 204.7837 s
agent0:                 episode reward: -0.4134,                 loss: nan
agent1:                 episode reward: 0.4134,                 loss: 0.1312
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2680s / 205.0518 s
agent0:                 episode reward: -0.8922,                 loss: nan
agent1:                 episode reward: 0.8922,                 loss: 0.1305
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2699s / 205.3216 s
agent0:                 episode reward: -1.0464,                 loss: nan
agent1:                 episode reward: 1.0464,                 loss: 0.1305
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2613s / 205.5830 s
agent0:                 episode reward: -0.6137,                 loss: nan
agent1:                 episode reward: 0.6137,                 loss: 0.1293
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2656s / 205.8485 s
agent0:                 episode reward: -0.4087,                 loss: nan
agent1:                 episode reward: 0.4087,                 loss: 0.1300
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2626s / 206.1112 s
agent0:                 episode reward: -0.6334,                 loss: nan
agent1:                 episode reward: 0.6334,                 loss: 0.1310
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2654s / 206.3765 s
agent0:                 episode reward: -0.7860,                 loss: nan
agent1:                 episode reward: 0.7860,                 loss: 0.1303
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2646s / 206.6412 s
agent0:                 episode reward: -0.7067,                 loss: nan
agent1:                 episode reward: 0.7067,                 loss: 0.1289
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2856s / 206.9267 s
agent0:                 episode reward: -0.7344,                 loss: nan
agent1:                 episode reward: 0.7344,                 loss: 0.1285
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2666s / 207.1934 s
agent0:                 episode reward: -0.4314,                 loss: nan
agent1:                 episode reward: 0.4314,                 loss: 0.1297
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2647s / 207.4580 s
agent0:                 episode reward: -0.5152,                 loss: nan
agent1:                 episode reward: 0.5152,                 loss: 0.1287
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2691s / 207.7271 s
agent0:                 episode reward: -0.6258,                 loss: nan
agent1:                 episode reward: 0.6258,                 loss: 0.1292
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2655s / 207.9926 s
agent0:                 episode reward: -0.6496,                 loss: nan
agent1:                 episode reward: 0.6496,                 loss: 0.1302
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2679s / 208.2605 s
agent0:                 episode reward: -0.7003,                 loss: nan
agent1:                 episode reward: 0.7003,                 loss: 0.1301
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2665s / 208.5270 s
agent0:                 episode reward: -0.5943,                 loss: nan
agent1:                 episode reward: 0.5943,                 loss: 0.1301
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2981s / 208.8250 s
agent0:                 episode reward: -0.5959,                 loss: nan
agent1:                 episode reward: 0.5959,                 loss: 0.1301
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2758s / 209.1008 s
agent0:                 episode reward: -0.6622,                 loss: nan
agent1:                 episode reward: 0.6622,                 loss: 0.1302
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2874s / 209.3882 s
agent0:                 episode reward: -0.6625,                 loss: nan
agent1:                 episode reward: 0.6625,                 loss: 0.1298
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2859s / 209.6741 s
agent0:                 episode reward: -0.6904,                 loss: nan
agent1:                 episode reward: 0.6904,                 loss: 0.1303
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2956s / 209.9697 s
agent0:                 episode reward: -0.9563,                 loss: nan
agent1:                 episode reward: 0.9563,                 loss: 0.1305
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2871s / 210.2568 s
agent0:                 episode reward: -0.7421,                 loss: nan
agent1:                 episode reward: 0.7421,                 loss: 0.1309
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2818s / 210.5386 s
agent0:                 episode reward: -0.5734,                 loss: nan
agent1:                 episode reward: 0.5734,                 loss: 0.1304
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2947s / 210.8333 s
agent0:                 episode reward: -1.0087,                 loss: nan
agent1:                 episode reward: 1.0087,                 loss: 0.1310
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2752s / 211.1085 s
agent0:                 episode reward: -0.7838,                 loss: nan
agent1:                 episode reward: 0.7838,                 loss: 0.1307
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2857s / 211.3942 s
agent0:                 episode reward: -0.6091,                 loss: nan
agent1:                 episode reward: 0.6091,                 loss: 0.1321
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2753s / 211.6695 s
agent0:                 episode reward: -0.9254,                 loss: nan
agent1:                 episode reward: 0.9254,                 loss: 0.1307
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2772s / 211.9466 s
agent0:                 episode reward: -0.4814,                 loss: nan
agent1:                 episode reward: 0.4814,                 loss: 0.1303
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2716s / 212.2182 s
agent0:                 episode reward: -0.6719,                 loss: nan
agent1:                 episode reward: 0.6719,                 loss: 0.1309
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2775s / 212.4957 s
agent0:                 episode reward: -0.5262,                 loss: nan
agent1:                 episode reward: 0.5262,                 loss: 0.1300
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2740s / 212.7697 s
agent0:                 episode reward: -0.5484,                 loss: nan
agent1:                 episode reward: 0.5484,                 loss: 0.1307
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2965s / 213.0661 s
agent0:                 episode reward: -0.7118,                 loss: nan
agent1:                 episode reward: 0.7118,                 loss: 0.1305
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2823s / 213.3484 s
agent0:                 episode reward: -0.6361,                 loss: nan
agent1:                 episode reward: 0.6361,                 loss: 0.1314
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2778s / 213.6263 s
agent0:                 episode reward: -0.5307,                 loss: nan
agent1:                 episode reward: 0.5307,                 loss: 0.1309
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 213.9092 s
agent0:                 episode reward: -0.3555,                 loss: nan
agent1:                 episode reward: 0.3555,                 loss: 0.1316
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2840s / 214.1932 s
agent0:                 episode reward: -0.6780,                 loss: nan
agent1:                 episode reward: 0.6780,                 loss: 0.1320
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2835s / 214.4767 s
agent0:                 episode reward: -0.7422,                 loss: nan
agent1:                 episode reward: 0.7422,                 loss: 0.1298
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2790s / 214.7557 s
agent0:                 episode reward: -0.5459,                 loss: nan
agent1:                 episode reward: 0.5459,                 loss: 0.1319
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2719s / 215.0276 s
agent0:                 episode reward: -0.5738,                 loss: nan
agent1:                 episode reward: 0.5738,                 loss: 0.1307
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 215.3020 s
agent0:                 episode reward: -0.8259,                 loss: nan
agent1:                 episode reward: 0.8259,                 loss: 0.1294
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2799s / 215.5819 s
agent0:                 episode reward: -0.9256,                 loss: nan
agent1:                 episode reward: 0.9256,                 loss: 0.1281
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2824s / 215.8643 s
agent0:                 episode reward: -0.4912,                 loss: nan
agent1:                 episode reward: 0.4912,                 loss: 0.1309
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3222s / 216.1865 s
agent0:                 episode reward: -0.2720,                 loss: nan
agent1:                 episode reward: 0.2720,                 loss: 0.1285
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2832s / 216.4697 s
agent0:                 episode reward: -0.6226,                 loss: nan
agent1:                 episode reward: 0.6226,                 loss: 0.1310
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2802s / 216.7499 s
agent0:                 episode reward: -0.9553,                 loss: nan
agent1:                 episode reward: 0.9553,                 loss: 0.1314
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2785s / 217.0285 s
agent0:                 episode reward: -0.6229,                 loss: nan
agent1:                 episode reward: 0.6229,                 loss: 0.1286
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2839s / 217.3124 s
agent0:                 episode reward: -0.3009,                 loss: nan
agent1:                 episode reward: 0.3009,                 loss: 0.1310
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2867s / 217.5991 s
agent0:                 episode reward: -0.6724,                 loss: nan
agent1:                 episode reward: 0.6724,                 loss: 0.1284
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2796s / 217.8787 s
agent0:                 episode reward: -0.4349,                 loss: nan
agent1:                 episode reward: 0.4349,                 loss: 0.1298
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2800s / 218.1587 s
agent0:                 episode reward: -0.7085,                 loss: nan
agent1:                 episode reward: 0.7085,                 loss: 0.1300
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2821s / 218.4408 s
agent0:                 episode reward: -0.6975,                 loss: nan
agent1:                 episode reward: 0.6975,                 loss: 0.1308
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2880s / 218.7288 s
agent0:                 episode reward: -0.8489,                 loss: nan
agent1:                 episode reward: 0.8489,                 loss: 0.1305
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3207s / 219.0496 s
agent0:                 episode reward: -0.6738,                 loss: nan
agent1:                 episode reward: 0.6738,                 loss: 0.1301
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3047s / 219.3543 s
agent0:                 episode reward: -0.7691,                 loss: nan
agent1:                 episode reward: 0.7691,                 loss: 0.1302
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2708s / 219.6251 s
agent0:                 episode reward: -0.6995,                 loss: nan
agent1:                 episode reward: 0.6995,                 loss: 0.1295
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2688s / 219.8939 s
agent0:                 episode reward: -0.7406,                 loss: nan
agent1:                 episode reward: 0.7406,                 loss: 0.1308
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2696s / 220.1635 s
agent0:                 episode reward: -0.4950,                 loss: nan
agent1:                 episode reward: 0.4950,                 loss: 0.1310
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2778s / 220.4413 s
agent0:                 episode reward: -0.6433,                 loss: nan
agent1:                 episode reward: 0.6433,                 loss: 0.1317
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 220.7133 s
agent0:                 episode reward: -0.5805,                 loss: nan
agent1:                 episode reward: 0.5805,                 loss: 0.1296
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2766s / 220.9899 s
agent0:                 episode reward: -0.5746,                 loss: nan
agent1:                 episode reward: 0.5746,                 loss: 0.1300
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 221.2656 s
agent0:                 episode reward: -0.7497,                 loss: nan
agent1:                 episode reward: 0.7497,                 loss: 0.1307
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2715s / 221.5371 s
agent0:                 episode reward: -1.0451,                 loss: nan
agent1:                 episode reward: 1.0451,                 loss: 0.1285
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3297s / 221.8668 s
agent0:                 episode reward: -0.9043,                 loss: nan
agent1:                 episode reward: 0.9043,                 loss: 0.1299
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2873s / 222.1541 s
agent0:                 episode reward: -0.5121,                 loss: nan
agent1:                 episode reward: 0.5121,                 loss: 0.1310
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2785s / 222.4326 s
agent0:                 episode reward: -0.4004,                 loss: nan
agent1:                 episode reward: 0.4004,                 loss: 0.1316
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2786s / 222.7111 s
agent0:                 episode reward: -0.5913,                 loss: nan
agent1:                 episode reward: 0.5913,                 loss: 0.1306
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2779s / 222.9890 s
agent0:                 episode reward: -0.7630,                 loss: nan
agent1:                 episode reward: 0.7630,                 loss: 0.1278
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2743s / 223.2633 s
agent0:                 episode reward: -0.9671,                 loss: nan
agent1:                 episode reward: 0.9671,                 loss: 0.1308
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2776s / 223.5409 s
agent0:                 episode reward: -0.6141,                 loss: nan
agent1:                 episode reward: 0.6141,                 loss: 0.1289
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2698s / 223.8107 s
agent0:                 episode reward: -0.6355,                 loss: nan
agent1:                 episode reward: 0.6355,                 loss: 0.1284
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2692s / 224.0798 s
agent0:                 episode reward: -0.4105,                 loss: nan
agent1:                 episode reward: 0.4105,                 loss: 0.1295
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2733s / 224.3531 s
agent0:                 episode reward: -0.6623,                 loss: nan
agent1:                 episode reward: 0.6623,                 loss: 0.1286
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2831s / 224.6362 s
agent0:                 episode reward: -0.4967,                 loss: nan
agent1:                 episode reward: 0.4967,                 loss: 0.1291
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3025s / 224.9387 s
agent0:                 episode reward: -0.8540,                 loss: nan
agent1:                 episode reward: 0.8540,                 loss: 0.1273
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2800s / 225.2187 s
agent0:                 episode reward: -0.6674,                 loss: nan
agent1:                 episode reward: 0.6674,                 loss: 0.1297
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2792s / 225.4979 s
agent0:                 episode reward: -0.6866,                 loss: nan
agent1:                 episode reward: 0.6866,                 loss: 0.1295
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2765s / 225.7743 s
agent0:                 episode reward: -0.7181,                 loss: nan
agent1:                 episode reward: 0.7181,                 loss: 0.1292
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2951s / 226.0695 s
agent0:                 episode reward: -0.4848,                 loss: nan
agent1:                 episode reward: 0.4848,                 loss: 0.1283
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2881s / 226.3576 s
agent0:                 episode reward: -0.6069,                 loss: nan
agent1:                 episode reward: 0.6069,                 loss: 0.1293
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2886s / 226.6462 s
agent0:                 episode reward: -0.6477,                 loss: nan
agent1:                 episode reward: 0.6477,                 loss: 0.1293
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2821s / 226.9283 s
agent0:                 episode reward: -0.5850,                 loss: nan
agent1:                 episode reward: 0.5850,                 loss: 0.1305
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2909s / 227.2192 s
agent0:                 episode reward: -0.7753,                 loss: nan
agent1:                 episode reward: 0.7753,                 loss: 0.1294
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3115s / 227.5307 s
agent0:                 episode reward: -0.5976,                 loss: nan
agent1:                 episode reward: 0.5976,                 loss: 0.1291
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2986s / 227.8293 s
agent0:                 episode reward: -0.9784,                 loss: nan
agent1:                 episode reward: 0.9784,                 loss: 0.1301
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3573s / 228.1865 s
agent0:                 episode reward: -0.7887,                 loss: nan
agent1:                 episode reward: 0.7887,                 loss: 0.1307
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2964s / 228.4829 s
agent0:                 episode reward: -0.3492,                 loss: nan
agent1:                 episode reward: 0.3492,                 loss: 0.1316
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3025s / 228.7854 s
agent0:                 episode reward: -0.8365,                 loss: nan
agent1:                 episode reward: 0.8365,                 loss: 0.1292
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2896s / 229.0750 s
agent0:                 episode reward: -0.8404,                 loss: nan
agent1:                 episode reward: 0.8404,                 loss: 0.1290
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2957s / 229.3707 s
agent0:                 episode reward: -0.9482,                 loss: nan
agent1:                 episode reward: 0.9482,                 loss: 0.1296
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2949s / 229.6657 s
agent0:                 episode reward: -1.0494,                 loss: nan
agent1:                 episode reward: 1.0494,                 loss: 0.1299
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2872s / 229.9529 s
agent0:                 episode reward: -0.6039,                 loss: nan
agent1:                 episode reward: 0.6039,                 loss: 0.1302
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2890s / 230.2419 s
agent0:                 episode reward: -0.6056,                 loss: nan
agent1:                 episode reward: 0.6056,                 loss: 0.1298
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2938s / 230.5356 s
agent0:                 episode reward: -0.5228,                 loss: nan
agent1:                 episode reward: 0.5228,                 loss: 0.1302
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2984s / 230.8340 s
agent0:                 episode reward: -0.5145,                 loss: nan
agent1:                 episode reward: 0.5145,                 loss: 0.1315
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3111s / 231.1451 s
agent0:                 episode reward: -1.0697,                 loss: nan
agent1:                 episode reward: 1.0697,                 loss: 0.1293
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2924s / 231.4375 s
agent0:                 episode reward: -0.6285,                 loss: nan
agent1:                 episode reward: 0.6285,                 loss: 0.1309
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2918s / 231.7293 s
agent0:                 episode reward: -0.9398,                 loss: nan
agent1:                 episode reward: 0.9398,                 loss: 0.1299
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2935s / 232.0229 s
agent0:                 episode reward: -0.6246,                 loss: nan
agent1:                 episode reward: 0.6246,                 loss: 0.1295
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2902s / 232.3131 s
agent0:                 episode reward: -0.8295,                 loss: nan
agent1:                 episode reward: 0.8295,                 loss: 0.1297
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2905s / 232.6036 s
agent0:                 episode reward: -0.6120,                 loss: nan
agent1:                 episode reward: 0.6120,                 loss: 0.1297
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2881s / 232.8917 s
agent0:                 episode reward: -0.6227,                 loss: nan
agent1:                 episode reward: 0.6227,                 loss: 0.1314
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2892s / 233.1809 s
agent0:                 episode reward: -0.8309,                 loss: nan
agent1:                 episode reward: 0.8309,                 loss: 0.1292
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2936s / 233.4745 s
agent0:                 episode reward: -0.8823,                 loss: nan
agent1:                 episode reward: 0.8823,                 loss: 0.1279
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2910s / 233.7655 s
agent0:                 episode reward: -0.5242,                 loss: nan
agent1:                 episode reward: 0.5242,                 loss: 0.1300
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 234.0775 s
agent0:                 episode reward: -0.8691,                 loss: nan
agent1:                 episode reward: 0.8691,                 loss: 0.1321
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2896s / 234.3671 s
agent0:                 episode reward: -0.7878,                 loss: nan
agent1:                 episode reward: 0.7878,                 loss: 0.1295
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2883s / 234.6554 s
agent0:                 episode reward: -0.3309,                 loss: nan
agent1:                 episode reward: 0.3309,                 loss: 0.1295
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2900s / 234.9454 s
agent0:                 episode reward: -0.6182,                 loss: nan
agent1:                 episode reward: 0.6182,                 loss: 0.1297
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2876s / 235.2330 s
agent0:                 episode reward: -0.6591,                 loss: nan
agent1:                 episode reward: 0.6591,                 loss: 0.1305
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2914s / 235.5244 s
agent0:                 episode reward: -0.4513,                 loss: nan
agent1:                 episode reward: 0.4513,                 loss: 0.1291
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3135s / 235.8379 s
agent0:                 episode reward: -0.7900,                 loss: nan
agent1:                 episode reward: 0.7900,                 loss: 0.1315
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2947s / 236.1326 s
agent0:                 episode reward: -0.6088,                 loss: nan
agent1:                 episode reward: 0.6088,                 loss: 0.1282
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2971s / 236.4297 s
agent0:                 episode reward: -1.1623,                 loss: nan
agent1:                 episode reward: 1.1623,                 loss: 0.1294
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2933s / 236.7230 s
agent0:                 episode reward: -0.7837,                 loss: nan
agent1:                 episode reward: 0.7837,                 loss: 0.1298
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3066s / 237.0296 s
agent0:                 episode reward: -0.7427,                 loss: nan
agent1:                 episode reward: 0.7427,                 loss: 0.1281
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3103s / 237.3399 s
agent0:                 episode reward: -0.7203,                 loss: nan
agent1:                 episode reward: 0.7203,                 loss: 0.1304
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2892s / 237.6291 s
agent0:                 episode reward: -0.6543,                 loss: nan
agent1:                 episode reward: 0.6543,                 loss: 0.1307
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2891s / 237.9181 s
agent0:                 episode reward: -0.4111,                 loss: nan
agent1:                 episode reward: 0.4111,                 loss: 0.1289
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 238.2077 s
agent0:                 episode reward: -0.8183,                 loss: nan
agent1:                 episode reward: 0.8183,                 loss: 0.1292
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2866s / 238.4943 s
agent0:                 episode reward: -0.9512,                 loss: nan
agent1:                 episode reward: 0.9512,                 loss: 0.1302
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2932s / 238.7875 s
agent0:                 episode reward: -0.6937,                 loss: nan
agent1:                 episode reward: 0.6937,                 loss: 0.1302
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2872s / 239.0747 s
agent0:                 episode reward: -1.0624,                 loss: nan
agent1:                 episode reward: 1.0624,                 loss: 0.1288
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2807s / 239.3555 s
agent0:                 episode reward: -0.7850,                 loss: nan
agent1:                 episode reward: 0.7850,                 loss: 0.1288
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2780s / 239.6335 s
agent0:                 episode reward: -0.6218,                 loss: nan
agent1:                 episode reward: 0.6218,                 loss: 0.1299
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2828s / 239.9162 s
agent0:                 episode reward: -0.9260,                 loss: nan
agent1:                 episode reward: 0.9260,                 loss: 0.1285
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3143s / 240.2305 s
agent0:                 episode reward: -1.0592,                 loss: nan
agent1:                 episode reward: 1.0592,                 loss: 0.1289
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2878s / 240.5183 s
agent0:                 episode reward: -0.3146,                 loss: nan
agent1:                 episode reward: 0.3146,                 loss: 0.1302
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 240.7981 s
agent0:                 episode reward: -0.9131,                 loss: nan
agent1:                 episode reward: 0.9131,                 loss: 0.1287
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 241.0779 s
agent0:                 episode reward: -0.6415,                 loss: nan
agent1:                 episode reward: 0.6415,                 loss: 0.1287
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2799s / 241.3578 s
agent0:                 episode reward: -0.7750,                 loss: nan
agent1:                 episode reward: 0.7750,                 loss: 0.1300
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2823s / 241.6402 s
agent0:                 episode reward: -0.9647,                 loss: nan
agent1:                 episode reward: 0.9647,                 loss: 0.1290
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2816s / 241.9217 s
agent0:                 episode reward: -0.7327,                 loss: nan
agent1:                 episode reward: 0.7327,                 loss: 0.1315
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2779s / 242.1996 s
agent0:                 episode reward: -1.0009,                 loss: nan
agent1:                 episode reward: 1.0009,                 loss: 0.1280
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2820s / 242.4817 s
agent0:                 episode reward: -0.4079,                 loss: nan
agent1:                 episode reward: 0.4079,                 loss: 0.1291
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2807s / 242.7624 s
agent0:                 episode reward: -0.6191,                 loss: nan
agent1:                 episode reward: 0.6191,                 loss: 0.1297
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3225s / 243.0849 s
agent0:                 episode reward: -0.6936,                 loss: nan
agent1:                 episode reward: 0.6936,                 loss: 0.1289
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3161s / 243.4010 s
agent0:                 episode reward: -0.9557,                 loss: nan
agent1:                 episode reward: 0.9557,                 loss: 0.1291
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2938s / 243.6948 s
agent0:                 episode reward: -0.7392,                 loss: nan
agent1:                 episode reward: 0.7392,                 loss: 0.1311
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3113s / 244.0061 s
agent0:                 episode reward: -0.8015,                 loss: nan
agent1:                 episode reward: 0.8015,                 loss: 0.1292
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2970s / 244.3031 s
agent0:                 episode reward: -0.4059,                 loss: nan
agent1:                 episode reward: 0.4059,                 loss: 0.1294
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2963s / 244.5994 s
agent0:                 episode reward: -0.9548,                 loss: nan
agent1:                 episode reward: 0.9548,                 loss: 0.1277
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2921s / 244.8915 s
agent0:                 episode reward: -0.6821,                 loss: nan
agent1:                 episode reward: 0.6821,                 loss: 0.1294
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2945s / 245.1859 s
agent0:                 episode reward: -0.7493,                 loss: nan
agent1:                 episode reward: 0.7493,                 loss: 0.1279
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 245.4754 s
agent0:                 episode reward: -0.6338,                 loss: nan
agent1:                 episode reward: 0.6338,                 loss: 0.1292
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 245.7649 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.1286
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3053s / 246.0703 s
agent0:                 episode reward: -0.5314,                 loss: nan
agent1:                 episode reward: 0.5314,                 loss: 0.1287
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3138s / 246.3841 s
agent0:                 episode reward: -0.4213,                 loss: nan
agent1:                 episode reward: 0.4213,                 loss: 0.1294
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3009s / 246.6850 s
agent0:                 episode reward: -0.6977,                 loss: nan
agent1:                 episode reward: 0.6977,                 loss: 0.1291
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3045s / 246.9895 s
agent0:                 episode reward: -0.8309,                 loss: nan
agent1:                 episode reward: 0.8309,                 loss: 0.1288
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2981s / 247.2876 s
agent0:                 episode reward: -0.9756,                 loss: nan
agent1:                 episode reward: 0.9756,                 loss: 0.1277
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3057s / 247.5932 s
agent0:                 episode reward: -0.3869,                 loss: nan
agent1:                 episode reward: 0.3869,                 loss: 0.1285
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2989s / 247.8921 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.1276
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2974s / 248.1895 s
agent0:                 episode reward: -0.8133,                 loss: nan
agent1:                 episode reward: 0.8133,                 loss: 0.1283
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2957s / 248.4852 s
agent0:                 episode reward: -0.6242,                 loss: nan
agent1:                 episode reward: 0.6242,                 loss: 0.1288
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2988s / 248.7840 s
agent0:                 episode reward: -0.4593,                 loss: nan
agent1:                 episode reward: 0.4593,                 loss: 0.1282
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2994s / 249.0834 s
agent0:                 episode reward: -0.2432,                 loss: nan
agent1:                 episode reward: 0.2432,                 loss: 0.1280
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3171s / 249.4005 s
agent0:                 episode reward: -0.1813,                 loss: nan
agent1:                 episode reward: 0.1813,                 loss: 0.1293
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2933s / 249.6938 s
agent0:                 episode reward: -0.8507,                 loss: nan
agent1:                 episode reward: 0.8507,                 loss: 0.1287
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2920s / 249.9859 s
agent0:                 episode reward: -0.5224,                 loss: nan
agent1:                 episode reward: 0.5224,                 loss: 0.1289
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2958s / 250.2817 s
agent0:                 episode reward: -0.4915,                 loss: nan
agent1:                 episode reward: 0.4915,                 loss: 0.1281
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2935s / 250.5752 s
agent0:                 episode reward: -0.6727,                 loss: nan
agent1:                 episode reward: 0.6727,                 loss: 0.1283
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2994s / 250.8746 s
agent0:                 episode reward: -0.6231,                 loss: nan
agent1:                 episode reward: 0.6231,                 loss: 0.1304
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2880s / 251.1626 s
agent0:                 episode reward: -0.7483,                 loss: nan
agent1:                 episode reward: 0.7483,                 loss: 0.1280
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2912s / 251.4539 s
agent0:                 episode reward: -0.7036,                 loss: nan
agent1:                 episode reward: 0.7036,                 loss: 0.1284
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2946s / 251.7485 s
agent0:                 episode reward: -0.7778,                 loss: nan
agent1:                 episode reward: 0.7778,                 loss: 0.1277
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2990s / 252.0475 s
agent0:                 episode reward: -0.6747,                 loss: nan
agent1:                 episode reward: 0.6747,                 loss: 0.1278
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3322s / 252.3796 s
agent0:                 episode reward: -0.4564,                 loss: nan
agent1:                 episode reward: 0.4564,                 loss: 0.1299
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2983s / 252.6779 s
agent0:                 episode reward: -0.9663,                 loss: nan
agent1:                 episode reward: 0.9663,                 loss: 0.1271
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3001s / 252.9780 s
agent0:                 episode reward: -0.9154,                 loss: nan
agent1:                 episode reward: 0.9154,                 loss: 0.1287
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2999s / 253.2779 s
agent0:                 episode reward: -0.6828,                 loss: nan
agent1:                 episode reward: 0.6828,                 loss: 0.1300
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3014s / 253.5793 s
agent0:                 episode reward: -0.8109,                 loss: nan
agent1:                 episode reward: 0.8109,                 loss: 0.1298
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3031s / 253.8824 s
agent0:                 episode reward: -0.9375,                 loss: nan
agent1:                 episode reward: 0.9375,                 loss: 0.1303
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3050s / 254.1874 s
agent0:                 episode reward: -0.8970,                 loss: nan
agent1:                 episode reward: 0.8970,                 loss: 0.1300
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3058s / 254.4932 s
agent0:                 episode reward: -0.3821,                 loss: nan
agent1:                 episode reward: 0.3821,                 loss: 0.1293
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3035s / 254.7966 s
agent0:                 episode reward: -0.4966,                 loss: nan
agent1:                 episode reward: 0.4966,                 loss: 0.1293
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2836s / 255.0802 s
agent0:                 episode reward: -0.6201,                 loss: nan
agent1:                 episode reward: 0.6201,                 loss: 0.1289
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3085s / 255.3887 s
agent0:                 episode reward: -0.6724,                 loss: nan
agent1:                 episode reward: 0.6724,                 loss: 0.1297
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2963s / 255.6850 s
agent0:                 episode reward: -0.6878,                 loss: nan
agent1:                 episode reward: 0.6878,                 loss: 0.1279
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2887s / 255.9737 s
agent0:                 episode reward: -0.2546,                 loss: nan
agent1:                 episode reward: 0.2546,                 loss: 0.1299
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2876s / 256.2613 s
agent0:                 episode reward: -0.5843,                 loss: nan
agent1:                 episode reward: 0.5843,                 loss: 0.1287
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2888s / 256.5501 s
agent0:                 episode reward: -0.7424,                 loss: nan
agent1:                 episode reward: 0.7424,                 loss: 0.1293
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2896s / 256.8397 s
agent0:                 episode reward: -0.6991,                 loss: nan
agent1:                 episode reward: 0.6991,                 loss: 0.1284
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2877s / 257.1274 s
agent0:                 episode reward: -0.6349,                 loss: nan
agent1:                 episode reward: 0.6349,                 loss: 0.1300
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2914s / 257.4188 s
agent0:                 episode reward: -0.8017,                 loss: nan
agent1:                 episode reward: 0.8017,                 loss: 0.1296
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2974s / 257.7162 s
agent0:                 episode reward: -0.7934,                 loss: nan
agent1:                 episode reward: 0.7934,                 loss: 0.1288
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3135s / 258.0297 s
agent0:                 episode reward: -0.8375,                 loss: nan
agent1:                 episode reward: 0.8375,                 loss: 0.1286
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3237s / 258.3534 s
agent0:                 episode reward: -0.4807,                 loss: nan
agent1:                 episode reward: 0.4807,                 loss: 0.1283
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3397s / 258.6931 s
agent0:                 episode reward: -0.2666,                 loss: nan
agent1:                 episode reward: 0.2666,                 loss: 0.1283
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3127s / 259.0058 s
agent0:                 episode reward: -0.6270,                 loss: nan
agent1:                 episode reward: 0.6270,                 loss: 0.1281
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3088s / 259.3146 s
agent0:                 episode reward: -0.9437,                 loss: nan
agent1:                 episode reward: 0.9437,                 loss: 0.1288
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3057s / 259.6203 s
agent0:                 episode reward: -0.4854,                 loss: nan
agent1:                 episode reward: 0.4854,                 loss: 0.1268
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3046s / 259.9249 s
agent0:                 episode reward: -0.7567,                 loss: nan
agent1:                 episode reward: 0.7567,                 loss: 0.1283
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2977s / 260.2226 s
agent0:                 episode reward: -0.3535,                 loss: nan
agent1:                 episode reward: 0.3535,                 loss: 0.1279
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2928s / 260.5154 s
agent0:                 episode reward: -0.5056,                 loss: nan
agent1:                 episode reward: 0.5056,                 loss: 0.1278
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3091s / 260.8245 s
agent0:                 episode reward: -0.7043,                 loss: nan
agent1:                 episode reward: 0.7043,                 loss: 0.1290
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3061s / 261.1306 s
agent0:                 episode reward: -0.9861,                 loss: nan
agent1:                 episode reward: 0.9861,                 loss: 0.1281
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3109s / 261.4415 s
agent0:                 episode reward: -0.7776,                 loss: nan
agent1:                 episode reward: 0.7776,                 loss: 0.1282
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3199s / 261.7614 s
agent0:                 episode reward: -0.7645,                 loss: nan
agent1:                 episode reward: 0.7645,                 loss: 0.1286
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2997s / 262.0611 s
agent0:                 episode reward: -0.4002,                 loss: nan
agent1:                 episode reward: 0.4002,                 loss: 0.1285
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2949s / 262.3560 s
agent0:                 episode reward: -0.7974,                 loss: nan
agent1:                 episode reward: 0.7974,                 loss: 0.1287
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2863s / 262.6423 s
agent0:                 episode reward: -0.7965,                 loss: nan
agent1:                 episode reward: 0.7965,                 loss: 0.1282
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2888s / 262.9311 s
agent0:                 episode reward: -0.8148,                 loss: nan
agent1:                 episode reward: 0.8148,                 loss: 0.1281
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2896s / 263.2207 s
agent0:                 episode reward: -0.2116,                 loss: nan
agent1:                 episode reward: 0.2116,                 loss: 0.1301
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2877s / 263.5084 s
agent0:                 episode reward: -0.6127,                 loss: nan
agent1:                 episode reward: 0.6127,                 loss: 0.1283
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2886s / 263.7970 s
agent0:                 episode reward: -0.9523,                 loss: nan
agent1:                 episode reward: 0.9523,                 loss: 0.1292
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2887s / 264.0857 s
agent0:                 episode reward: -0.4115,                 loss: nan
agent1:                 episode reward: 0.4115,                 loss: 0.1293
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2873s / 264.3730 s
agent0:                 episode reward: -0.9064,                 loss: nan
agent1:                 episode reward: 0.9064,                 loss: 0.1279
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3177s / 264.6907 s
agent0:                 episode reward: -0.9475,                 loss: nan
agent1:                 episode reward: 0.9475,                 loss: 0.1285
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2871s / 264.9779 s
agent0:                 episode reward: -0.6530,                 loss: nan
agent1:                 episode reward: 0.6530,                 loss: 0.1285
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2996s / 265.2775 s
agent0:                 episode reward: -0.5293,                 loss: nan
agent1:                 episode reward: 0.5293,                 loss: 0.1269
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2920s / 265.5695 s
agent0:                 episode reward: -0.7961,                 loss: nan
agent1:                 episode reward: 0.7961,                 loss: 0.1285
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2890s / 265.8585 s
agent0:                 episode reward: -0.4626,                 loss: nan
agent1:                 episode reward: 0.4626,                 loss: 0.1295
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2935s / 266.1520 s
agent0:                 episode reward: -0.3973,                 loss: nan
agent1:                 episode reward: 0.3973,                 loss: 0.1286
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3007s / 266.4528 s
agent0:                 episode reward: -0.8955,                 loss: nan
agent1:                 episode reward: 0.8955,                 loss: 0.1273
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2989s / 266.7517 s
agent0:                 episode reward: -0.3215,                 loss: nan
agent1:                 episode reward: 0.3215,                 loss: 0.1264
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2981s / 267.0498 s
agent0:                 episode reward: -0.8226,                 loss: nan
agent1:                 episode reward: 0.8226,                 loss: 0.1272
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2955s / 267.3453 s
agent0:                 episode reward: -0.5658,                 loss: nan
agent1:                 episode reward: 0.5658,                 loss: 0.1295
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3110s / 267.6564 s
agent0:                 episode reward: -0.7782,                 loss: nan
agent1:                 episode reward: 0.7782,                 loss: 0.1284
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3088s / 267.9652 s
agent0:                 episode reward: -0.9023,                 loss: nan
agent1:                 episode reward: 0.9023,                 loss: 0.1267
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3088s / 268.2740 s
agent0:                 episode reward: -0.8466,                 loss: nan
agent1:                 episode reward: 0.8466,                 loss: 0.1301
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3037s / 268.5777 s
agent0:                 episode reward: -0.6413,                 loss: nan
agent1:                 episode reward: 0.6413,                 loss: 0.1286
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3053s / 268.8830 s
agent0:                 episode reward: -0.7498,                 loss: nan
agent1:                 episode reward: 0.7498,                 loss: 0.1298
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3262s / 269.2091 s
agent0:                 episode reward: -0.8189,                 loss: nan
agent1:                 episode reward: 0.8189,                 loss: 0.1280
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3095s / 269.5186 s
agent0:                 episode reward: -0.7811,                 loss: nan
agent1:                 episode reward: 0.7811,                 loss: 0.1288
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3134s / 269.8321 s
agent0:                 episode reward: -0.6153,                 loss: nan
agent1:                 episode reward: 0.6153,                 loss: 0.1309
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3032s / 270.1353 s
agent0:                 episode reward: -0.4642,                 loss: nan
agent1:                 episode reward: 0.4642,                 loss: 0.1299
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3100s / 270.4452 s
agent0:                 episode reward: -0.2814,                 loss: nan
agent1:                 episode reward: 0.2814,                 loss: 0.1287
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3216s / 270.7668 s
agent0:                 episode reward: -0.7202,                 loss: nan
agent1:                 episode reward: 0.7202,                 loss: 0.1297
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3149s / 271.0818 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.1293
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3169s / 271.3986 s
agent0:                 episode reward: -1.1786,                 loss: nan
agent1:                 episode reward: 1.1786,                 loss: 0.1292
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3111s / 271.7097 s
agent0:                 episode reward: -0.3253,                 loss: nan
agent1:                 episode reward: 0.3253,                 loss: 0.1308
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3047s / 272.0145 s
agent0:                 episode reward: -0.8410,                 loss: nan
agent1:                 episode reward: 0.8410,                 loss: 0.1308
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3053s / 272.3198 s
agent0:                 episode reward: -0.8646,                 loss: nan
agent1:                 episode reward: 0.8646,                 loss: 0.1297
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3097s / 272.6295 s
agent0:                 episode reward: -0.8855,                 loss: nan
agent1:                 episode reward: 0.8855,                 loss: 0.1291
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3043s / 272.9339 s
agent0:                 episode reward: -0.9752,                 loss: nan
agent1:                 episode reward: 0.9752,                 loss: 0.1283
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3102s / 273.2441 s
agent0:                 episode reward: -0.6185,                 loss: nan
agent1:                 episode reward: 0.6185,                 loss: 0.1302
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3125s / 273.5566 s
agent0:                 episode reward: -0.8627,                 loss: nan
agent1:                 episode reward: 0.8627,                 loss: 0.1290
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3341s / 273.8906 s
agent0:                 episode reward: -0.6356,                 loss: nan
agent1:                 episode reward: 0.6356,                 loss: 0.1290
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3135s / 274.2041 s
agent0:                 episode reward: -0.6168,                 loss: nan
agent1:                 episode reward: 0.6168,                 loss: 0.1289
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3151s / 274.5192 s
agent0:                 episode reward: -0.5459,                 loss: nan
agent1:                 episode reward: 0.5459,                 loss: 0.1283
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3095s / 274.8287 s
agent0:                 episode reward: -0.8215,                 loss: nan
agent1:                 episode reward: 0.8215,                 loss: 0.1285
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3131s / 275.1418 s
agent0:                 episode reward: -0.7680,                 loss: nan
agent1:                 episode reward: 0.7680,                 loss: 0.1287
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3213s / 275.4631 s
agent0:                 episode reward: -0.6571,                 loss: nan
agent1:                 episode reward: 0.6571,                 loss: 0.1280
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3109s / 275.7739 s
agent0:                 episode reward: -0.7049,                 loss: nan
agent1:                 episode reward: 0.7049,                 loss: 0.1302
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3115s / 276.0854 s
agent0:                 episode reward: -0.6559,                 loss: nan
agent1:                 episode reward: 0.6559,                 loss: 0.1291
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3062s / 276.3916 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.1282
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3102s / 276.7019 s
agent0:                 episode reward: -0.7335,                 loss: nan
agent1:                 episode reward: 0.7335,                 loss: 0.1300
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3382s / 277.0401 s
agent0:                 episode reward: -0.7658,                 loss: nan
agent1:                 episode reward: 0.7658,                 loss: 0.1291
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3466s / 277.3866 s
agent0:                 episode reward: -0.7896,                 loss: nan
agent1:                 episode reward: 0.7896,                 loss: 0.1277
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2918s / 277.6784 s
agent0:                 episode reward: -0.9021,                 loss: nan
agent1:                 episode reward: 0.9021,                 loss: 0.1286
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2950s / 277.9734 s
agent0:                 episode reward: -0.7764,                 loss: nan
agent1:                 episode reward: 0.7764,                 loss: 0.1280
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2923s / 278.2657 s
agent0:                 episode reward: -0.8982,                 loss: nan
agent1:                 episode reward: 0.8982,                 loss: 0.1287
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2950s / 278.5606 s
agent0:                 episode reward: -0.6024,                 loss: nan
agent1:                 episode reward: 0.6024,                 loss: 0.1290
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2953s / 278.8559 s
agent0:                 episode reward: -1.0348,                 loss: nan
agent1:                 episode reward: 1.0348,                 loss: 0.1304
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3089s / 279.1649 s
agent0:                 episode reward: -0.9931,                 loss: nan
agent1:                 episode reward: 0.9931,                 loss: 0.1274
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3193s / 279.4842 s
agent0:                 episode reward: -0.8074,                 loss: nan
agent1:                 episode reward: 0.8074,                 loss: 0.1290
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3308s / 279.8150 s
agent0:                 episode reward: -0.7581,                 loss: nan
agent1:                 episode reward: 0.7581,                 loss: 0.1280
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3346s / 280.1495 s
agent0:                 episode reward: -0.5792,                 loss: nan
agent1:                 episode reward: 0.5792,                 loss: 0.1299
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3149s / 280.4644 s
agent0:                 episode reward: -0.8488,                 loss: nan
agent1:                 episode reward: 0.8488,                 loss: 0.1287
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3096s / 280.7740 s
agent0:                 episode reward: -0.6332,                 loss: nan
agent1:                 episode reward: 0.6332,                 loss: 0.1278
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3075s / 281.0815 s
agent0:                 episode reward: -0.8784,                 loss: nan
agent1:                 episode reward: 0.8784,                 loss: 0.1294
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3250s / 281.4064 s
agent0:                 episode reward: -0.4458,                 loss: nan
agent1:                 episode reward: 0.4458,                 loss: 0.1297
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3077s / 281.7142 s
agent0:                 episode reward: -0.9518,                 loss: nan
agent1:                 episode reward: 0.9518,                 loss: 0.1270
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3087s / 282.0229 s
agent0:                 episode reward: -0.8057,                 loss: nan
agent1:                 episode reward: 0.8057,                 loss: 0.1290
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3144s / 282.3373 s
agent0:                 episode reward: -0.6004,                 loss: nan
agent1:                 episode reward: 0.6004,                 loss: 0.1300
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3173s / 282.6546 s
agent0:                 episode reward: -0.3732,                 loss: nan
agent1:                 episode reward: 0.3732,                 loss: 0.1277
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3350s / 282.9896 s
agent0:                 episode reward: -0.7708,                 loss: nan
agent1:                 episode reward: 0.7708,                 loss: 0.1275
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3180s / 283.3076 s
agent0:                 episode reward: -0.4586,                 loss: nan
agent1:                 episode reward: 0.4586,                 loss: 0.1288
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3172s / 283.6248 s
agent0:                 episode reward: -0.6739,                 loss: nan
agent1:                 episode reward: 0.6739,                 loss: 0.1314
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3112s / 283.9361 s
agent0:                 episode reward: -0.6446,                 loss: nan
agent1:                 episode reward: 0.6446,                 loss: 0.1269
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2959s / 284.2320 s
agent0:                 episode reward: -0.8646,                 loss: nan
agent1:                 episode reward: 0.8646,                 loss: 0.1287
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3027s / 284.5346 s
agent0:                 episode reward: -0.6815,                 loss: nan
agent1:                 episode reward: 0.6815,                 loss: 0.1285
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3001s / 284.8347 s
agent0:                 episode reward: -0.7541,                 loss: nan
agent1:                 episode reward: 0.7541,                 loss: 0.1273
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2996s / 285.1343 s
agent0:                 episode reward: -0.5789,                 loss: nan
agent1:                 episode reward: 0.5789,                 loss: 0.1284
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2988s / 285.4330 s
agent0:                 episode reward: -0.8767,                 loss: nan
agent1:                 episode reward: 0.8767,                 loss: 0.1290
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3204s / 285.7534 s
agent0:                 episode reward: -0.4396,                 loss: nan
agent1:                 episode reward: 0.4396,                 loss: 0.1282
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3360s / 286.0894 s
agent0:                 episode reward: -0.7857,                 loss: nan
agent1:                 episode reward: 0.7857,                 loss: 0.1290
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3127s / 286.4022 s
agent0:                 episode reward: -0.7693,                 loss: nan
agent1:                 episode reward: 0.7693,                 loss: 0.1290
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3163s / 286.7185 s
agent0:                 episode reward: -0.2485,                 loss: nan
agent1:                 episode reward: 0.2485,                 loss: 0.1288
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3116s / 287.0300 s
agent0:                 episode reward: -0.8522,                 loss: nan
agent1:                 episode reward: 0.8522,                 loss: 0.1290
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3122s / 287.3422 s
agent0:                 episode reward: -0.4488,                 loss: nan
agent1:                 episode reward: 0.4488,                 loss: 0.1287
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3145s / 287.6567 s
agent0:                 episode reward: -0.5632,                 loss: nan
agent1:                 episode reward: 0.5632,                 loss: 0.1293
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 287.9674 s
agent0:                 episode reward: -0.5505,                 loss: nan
agent1:                 episode reward: 0.5505,                 loss: 0.1290
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3127s / 288.2801 s
agent0:                 episode reward: -0.6256,                 loss: nan
agent1:                 episode reward: 0.6256,                 loss: 0.1295
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3131s / 288.5932 s
agent0:                 episode reward: -0.6294,                 loss: nan
agent1:                 episode reward: 0.6294,                 loss: 0.1290
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3202s / 288.9134 s
agent0:                 episode reward: -0.7108,                 loss: nan
agent1:                 episode reward: 0.7108,                 loss: 0.1293
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3443s / 289.2577 s
agent0:                 episode reward: -0.8629,                 loss: nan
agent1:                 episode reward: 0.8629,                 loss: 0.1286
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3239s / 289.5816 s
agent0:                 episode reward: -0.4778,                 loss: nan
agent1:                 episode reward: 0.4778,                 loss: 0.1313
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3261s / 289.9077 s
agent0:                 episode reward: -0.6741,                 loss: nan
agent1:                 episode reward: 0.6741,                 loss: 0.1274
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3321s / 290.2397 s
agent0:                 episode reward: -0.6400,                 loss: nan
agent1:                 episode reward: 0.6400,                 loss: 0.1291
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 290.5561 s
agent0:                 episode reward: -0.3952,                 loss: nan
agent1:                 episode reward: 0.3952,                 loss: 0.1295
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3183s / 290.8745 s
agent0:                 episode reward: -0.9467,                 loss: nan
agent1:                 episode reward: 0.9467,                 loss: 0.1307
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 291.1891 s
agent0:                 episode reward: -0.6769,                 loss: nan
agent1:                 episode reward: 0.6769,                 loss: 0.1288
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3185s / 291.5077 s
agent0:                 episode reward: -1.0762,                 loss: nan
agent1:                 episode reward: 1.0762,                 loss: 0.1291
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3640s / 291.8717 s
agent0:                 episode reward: -0.4578,                 loss: nan
agent1:                 episode reward: 0.4578,                 loss: 0.1294
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3446s / 292.2163 s
agent0:                 episode reward: -0.4862,                 loss: nan
agent1:                 episode reward: 0.4862,                 loss: 0.1301
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3240s / 292.5403 s
agent0:                 episode reward: -0.6650,                 loss: nan
agent1:                 episode reward: 0.6650,                 loss: 0.1276
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3143s / 292.8547 s
agent0:                 episode reward: -0.9023,                 loss: nan
agent1:                 episode reward: 0.9023,                 loss: 0.1298
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3157s / 293.1703 s
agent0:                 episode reward: -0.8618,                 loss: nan
agent1:                 episode reward: 0.8618,                 loss: 0.1292
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3156s / 293.4859 s
agent0:                 episode reward: -0.5198,                 loss: nan
agent1:                 episode reward: 0.5198,                 loss: 0.1305
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3165s / 293.8024 s
agent0:                 episode reward: -0.4332,                 loss: nan
agent1:                 episode reward: 0.4332,                 loss: 0.1304
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3342s / 294.1367 s
agent0:                 episode reward: -0.7271,                 loss: nan
agent1:                 episode reward: 0.7271,                 loss: 0.1291
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3289s / 294.4656 s
agent0:                 episode reward: -0.4669,                 loss: nan
agent1:                 episode reward: 0.4669,                 loss: 0.1284
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3492s / 294.8147 s
agent0:                 episode reward: -0.7853,                 loss: nan
agent1:                 episode reward: 0.7853,                 loss: 0.1282
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3713s / 295.1860 s
agent0:                 episode reward: -0.6437,                 loss: nan
agent1:                 episode reward: 0.6437,                 loss: 0.1279
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3512s / 295.5372 s
agent0:                 episode reward: -0.6962,                 loss: nan
agent1:                 episode reward: 0.6962,                 loss: 0.1271
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3296s / 295.8668 s
agent0:                 episode reward: -0.8735,                 loss: nan
agent1:                 episode reward: 0.8735,                 loss: 0.1267
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3229s / 296.1897 s
agent0:                 episode reward: -0.7055,                 loss: nan
agent1:                 episode reward: 0.7055,                 loss: 0.1280
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3266s / 296.5163 s
agent0:                 episode reward: -0.6016,                 loss: nan
agent1:                 episode reward: 0.6016,                 loss: 0.1290
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3260s / 296.8423 s
agent0:                 episode reward: -0.7322,                 loss: nan
agent1:                 episode reward: 0.7322,                 loss: 0.1304
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 297.1664 s
agent0:                 episode reward: -0.5742,                 loss: nan
agent1:                 episode reward: 0.5742,                 loss: 0.1289
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3277s / 297.4941 s
agent0:                 episode reward: -0.5441,                 loss: nan
agent1:                 episode reward: 0.5441,                 loss: 0.1287
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3250s / 297.8191 s
agent0:                 episode reward: -0.7185,                 loss: nan
agent1:                 episode reward: 0.7185,                 loss: 0.1269
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3178s / 298.1369 s
agent0:                 episode reward: -0.9549,                 loss: nan
agent1:                 episode reward: 0.9549,                 loss: 0.1273
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3391s / 298.4760 s
agent0:                 episode reward: -0.6502,                 loss: nan
agent1:                 episode reward: 0.6502,                 loss: 0.1294
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3151s / 298.7911 s
agent0:                 episode reward: -0.7750,                 loss: nan
agent1:                 episode reward: 0.7750,                 loss: 0.1294
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3139s / 299.1050 s
agent0:                 episode reward: -1.0400,                 loss: nan
agent1:                 episode reward: 1.0400,                 loss: 0.1271
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 299.4251 s
agent0:                 episode reward: -0.6590,                 loss: nan
agent1:                 episode reward: 0.6590,                 loss: 0.1292
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3192s / 299.7444 s
agent0:                 episode reward: -0.6506,                 loss: nan
agent1:                 episode reward: 0.6506,                 loss: 0.1283
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3214s / 300.0658 s
agent0:                 episode reward: -0.9202,                 loss: nan
agent1:                 episode reward: 0.9202,                 loss: 0.1275
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3298s / 300.3955 s
agent0:                 episode reward: -0.9283,                 loss: nan
agent1:                 episode reward: 0.9283,                 loss: 0.1275
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3327s / 300.7282 s
agent0:                 episode reward: -0.9350,                 loss: nan
agent1:                 episode reward: 0.9350,                 loss: 0.1280
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3276s / 301.0558 s
agent0:                 episode reward: -0.9558,                 loss: nan
agent1:                 episode reward: 0.9558,                 loss: 0.1275
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3540s / 301.4098 s
agent0:                 episode reward: -1.1132,                 loss: nan
agent1:                 episode reward: 1.1132,                 loss: 0.1293
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3253s / 301.7351 s
agent0:                 episode reward: -0.6803,                 loss: nan
agent1:                 episode reward: 0.6803,                 loss: 0.1299
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3116s / 302.0466 s
agent0:                 episode reward: -0.8741,                 loss: nan
agent1:                 episode reward: 0.8741,                 loss: 0.1273
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3189s / 302.3655 s
agent0:                 episode reward: -0.8456,                 loss: nan
agent1:                 episode reward: 0.8456,                 loss: 0.1310
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3048s / 302.6703 s
agent0:                 episode reward: -0.7867,                 loss: nan
agent1:                 episode reward: 0.7867,                 loss: 0.1295
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3027s / 302.9730 s
agent0:                 episode reward: -0.2290,                 loss: nan
agent1:                 episode reward: 0.2290,                 loss: 0.1291
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3033s / 303.2763 s
agent0:                 episode reward: -0.8480,                 loss: nan
agent1:                 episode reward: 0.8480,                 loss: 0.1285
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3057s / 303.5820 s
agent0:                 episode reward: -0.6968,                 loss: nan
agent1:                 episode reward: 0.6968,                 loss: 0.1275
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3023s / 303.8843 s
agent0:                 episode reward: -0.6917,                 loss: nan
agent1:                 episode reward: 0.6917,                 loss: 0.1297
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3010s / 304.1853 s
agent0:                 episode reward: -0.4979,                 loss: nan
agent1:                 episode reward: 0.4979,                 loss: 0.1286
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3347s / 304.5200 s
agent0:                 episode reward: -0.7603,                 loss: nan
agent1:                 episode reward: 0.7603,                 loss: 0.1291
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3043s / 304.8242 s
agent0:                 episode reward: -0.7306,                 loss: nan
agent1:                 episode reward: 0.7306,                 loss: 0.1297
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3032s / 305.1275 s
agent0:                 episode reward: -0.5755,                 loss: nan
agent1:                 episode reward: 0.5755,                 loss: 0.1290
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3167s / 305.4442 s
agent0:                 episode reward: -0.9372,                 loss: nan
agent1:                 episode reward: 0.9372,                 loss: 0.1286
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3195s / 305.7637 s
agent0:                 episode reward: -0.5669,                 loss: nan
agent1:                 episode reward: 0.5669,                 loss: 0.1306
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3250s / 306.0886 s
agent0:                 episode reward: -0.3782,                 loss: nan
agent1:                 episode reward: 0.3782,                 loss: 0.1280
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3220s / 306.4106 s
agent0:                 episode reward: -0.7738,                 loss: nan
agent1:                 episode reward: 0.7738,                 loss: 0.1269
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3207s / 306.7313 s
agent0:                 episode reward: -0.7657,                 loss: nan
agent1:                 episode reward: 0.7657,                 loss: 0.1276
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3220s / 307.0533 s
agent0:                 episode reward: -0.7590,                 loss: nan
agent1:                 episode reward: 0.7590,                 loss: 0.1287
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3369s / 307.3902 s
agent0:                 episode reward: -0.6254,                 loss: nan
agent1:                 episode reward: 0.6254,                 loss: 0.1297
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3458s / 307.7360 s
agent0:                 episode reward: -1.0320,                 loss: nan
agent1:                 episode reward: 1.0320,                 loss: 0.1301
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 308.0693 s
agent0:                 episode reward: -0.6607,                 loss: nan
agent1:                 episode reward: 0.6607,                 loss: 0.1306
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3499s / 308.4192 s
agent0:                 episode reward: -0.6404,                 loss: nan
agent1:                 episode reward: 0.6404,                 loss: 0.1269
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3313s / 308.7505 s
agent0:                 episode reward: -0.7449,                 loss: nan
agent1:                 episode reward: 0.7449,                 loss: 0.1298
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3259s / 309.0764 s
agent0:                 episode reward: -0.4427,                 loss: nan
agent1:                 episode reward: 0.4427,                 loss: 0.1298
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3305s / 309.4070 s
agent0:                 episode reward: -0.5945,                 loss: nan
agent1:                 episode reward: 0.5945,                 loss: 0.1285
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3315s / 309.7385 s
agent0:                 episode reward: -0.5517,                 loss: nan
agent1:                 episode reward: 0.5517,                 loss: 0.1290
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 310.0718 s
agent0:                 episode reward: -1.0107,                 loss: nan
agent1:                 episode reward: 1.0107,                 loss: 0.1307
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3360s / 310.4078 s
agent0:                 episode reward: -0.8692,                 loss: nan
agent1:                 episode reward: 0.8692,                 loss: 0.1305
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3762s / 310.7840 s
agent0:                 episode reward: -0.6829,                 loss: nan
agent1:                 episode reward: 0.6829,                 loss: 0.1291
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 311.0961 s
agent0:                 episode reward: -0.8989,                 loss: nan
agent1:                 episode reward: 0.8989,                 loss: 0.1261
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3122s / 311.4084 s
agent0:                 episode reward: -0.8260,                 loss: nan
agent1:                 episode reward: 0.8260,                 loss: 0.1260
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 311.7230 s
agent0:                 episode reward: -0.8089,                 loss: nan
agent1:                 episode reward: 0.8089,                 loss: 0.1282
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3192s / 312.0423 s
agent0:                 episode reward: -0.6396,                 loss: nan
agent1:                 episode reward: 0.6396,                 loss: 0.1286
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3613s / 312.4036 s
agent0:                 episode reward: -0.6687,                 loss: nan
agent1:                 episode reward: 0.6687,                 loss: 0.1296
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3381s / 312.7417 s
agent0:                 episode reward: -0.7276,                 loss: nan
agent1:                 episode reward: 0.7276,                 loss: 0.1281
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 313.0653 s
agent0:                 episode reward: -0.7356,                 loss: nan
agent1:                 episode reward: 0.7356,                 loss: 0.1284
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3267s / 313.3919 s
agent0:                 episode reward: -0.5507,                 loss: nan
agent1:                 episode reward: 0.5507,                 loss: 0.1269
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3606s / 313.7526 s
agent0:                 episode reward: -0.8431,                 loss: nan
agent1:                 episode reward: 0.8431,                 loss: 0.1278
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3215s / 314.0741 s
agent0:                 episode reward: -0.6521,                 loss: nan
agent1:                 episode reward: 0.6521,                 loss: 0.1276
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3226s / 314.3967 s
agent0:                 episode reward: -0.7328,                 loss: nan
agent1:                 episode reward: 0.7328,                 loss: 0.1279
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3195s / 314.7162 s
agent0:                 episode reward: -1.0177,                 loss: nan
agent1:                 episode reward: 1.0177,                 loss: 0.1279
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3228s / 315.0390 s
agent0:                 episode reward: -0.6146,                 loss: nan
agent1:                 episode reward: 0.6146,                 loss: 0.1291
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3230s / 315.3620 s
agent0:                 episode reward: -0.7876,                 loss: nan
agent1:                 episode reward: 0.7876,                 loss: 0.1273
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3359s / 315.6980 s
agent0:                 episode reward: -0.7133,                 loss: nan
agent1:                 episode reward: 0.7133,                 loss: 0.1277
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3338s / 316.0318 s
agent0:                 episode reward: -0.5032,                 loss: nan
agent1:                 episode reward: 0.5032,                 loss: 0.1279
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3357s / 316.3675 s
agent0:                 episode reward: -0.7150,                 loss: nan
agent1:                 episode reward: 0.7150,                 loss: 0.1306
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3577s / 316.7252 s
agent0:                 episode reward: -0.7209,                 loss: nan
agent1:                 episode reward: 0.7209,                 loss: 0.1284
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3403s / 317.0655 s
agent0:                 episode reward: -0.9927,                 loss: nan
agent1:                 episode reward: 0.9927,                 loss: 0.1298
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3353s / 317.4008 s
agent0:                 episode reward: -0.4954,                 loss: nan
agent1:                 episode reward: 0.4954,                 loss: 0.1283
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3322s / 317.7330 s
agent0:                 episode reward: -0.7544,                 loss: nan
agent1:                 episode reward: 0.7544,                 loss: 0.1288
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3392s / 318.0723 s
agent0:                 episode reward: -0.5331,                 loss: nan
agent1:                 episode reward: 0.5331,                 loss: 0.1310
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3317s / 318.4039 s
agent0:                 episode reward: -0.8427,                 loss: nan
agent1:                 episode reward: 0.8427,                 loss: 0.1299
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3373s / 318.7413 s
agent0:                 episode reward: -0.8355,                 loss: nan
agent1:                 episode reward: 0.8355,                 loss: 0.1310
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3512s / 319.0925 s
agent0:                 episode reward: -0.6136,                 loss: nan
agent1:                 episode reward: 0.6136,                 loss: 0.1280
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3283s / 319.4208 s
agent0:                 episode reward: -0.6905,                 loss: nan
agent1:                 episode reward: 0.6905,                 loss: 0.1288
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3384s / 319.7591 s
agent0:                 episode reward: -0.7406,                 loss: nan
agent1:                 episode reward: 0.7406,                 loss: 0.1308
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3276s / 320.0867 s
agent0:                 episode reward: -0.7274,                 loss: nan
agent1:                 episode reward: 0.7274,                 loss: 0.1273
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3239s / 320.4106 s
agent0:                 episode reward: -1.1260,                 loss: nan
agent1:                 episode reward: 1.1260,                 loss: 0.1300
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3211s / 320.7316 s
agent0:                 episode reward: -0.8729,                 loss: nan
agent1:                 episode reward: 0.8729,                 loss: 0.1290
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3195s / 321.0512 s
agent0:                 episode reward: -0.8949,                 loss: nan
agent1:                 episode reward: 0.8949,                 loss: 0.1296
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3305s / 321.3817 s
agent0:                 episode reward: -0.6427,                 loss: nan
agent1:                 episode reward: 0.6427,                 loss: 0.1298
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3287s / 321.7104 s
agent0:                 episode reward: -0.6452,                 loss: nan
agent1:                 episode reward: 0.6452,                 loss: 0.1286
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3200s / 322.0303 s
agent0:                 episode reward: -0.3002,                 loss: nan
agent1:                 episode reward: 0.3002,                 loss: 0.1295
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3274s / 322.3578 s
agent0:                 episode reward: -0.5332,                 loss: nan
agent1:                 episode reward: 0.5332,                 loss: 0.1279
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3285s / 322.6863 s
agent0:                 episode reward: -0.6684,                 loss: nan
agent1:                 episode reward: 0.6684,                 loss: 0.1303
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3440s / 323.0303 s
agent0:                 episode reward: -0.9071,                 loss: nan
agent1:                 episode reward: 0.9071,                 loss: 0.1301
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3205s / 323.3508 s
agent0:                 episode reward: -0.7453,                 loss: nan
agent1:                 episode reward: 0.7453,                 loss: 0.1288
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3277s / 323.6785 s
agent0:                 episode reward: -0.5016,                 loss: nan
agent1:                 episode reward: 0.5016,                 loss: 0.1280
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3282s / 324.0067 s
agent0:                 episode reward: -0.4795,                 loss: nan
agent1:                 episode reward: 0.4795,                 loss: 0.1293
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3224s / 324.3291 s
agent0:                 episode reward: -0.6847,                 loss: nan
agent1:                 episode reward: 0.6847,                 loss: 0.1297
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3299s / 324.6589 s
agent0:                 episode reward: -0.7428,                 loss: nan
agent1:                 episode reward: 0.7428,                 loss: 0.1297
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3225s / 324.9814 s
agent0:                 episode reward: -1.1177,                 loss: nan
agent1:                 episode reward: 1.1177,                 loss: 0.1286
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3310s / 325.3124 s
agent0:                 episode reward: -0.8238,                 loss: nan
agent1:                 episode reward: 0.8238,                 loss: 0.1293
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3162s / 325.6286 s
agent0:                 episode reward: -0.6458,                 loss: nan
agent1:                 episode reward: 0.6458,                 loss: 0.1289
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3408s / 325.9694 s
agent0:                 episode reward: -0.7616,                 loss: nan
agent1:                 episode reward: 0.7616,                 loss: 0.1290
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3100s / 326.2794 s
agent0:                 episode reward: -1.0157,                 loss: nan
agent1:                 episode reward: 1.0157,                 loss: 0.1289
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3177s / 326.5971 s
agent0:                 episode reward: -0.8947,                 loss: nan
agent1:                 episode reward: 0.8947,                 loss: 0.1283
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3155s / 326.9126 s
agent0:                 episode reward: -0.7140,                 loss: nan
agent1:                 episode reward: 0.7140,                 loss: 0.1295
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3131s / 327.2257 s
agent0:                 episode reward: -0.6858,                 loss: nan
agent1:                 episode reward: 0.6858,                 loss: 0.1271
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3288s / 327.5545 s
agent0:                 episode reward: -0.7123,                 loss: nan
agent1:                 episode reward: 0.7123,                 loss: 0.1276
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3182s / 327.8727 s
agent0:                 episode reward: -0.8989,                 loss: nan
agent1:                 episode reward: 0.8989,                 loss: 0.1284
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3141s / 328.1868 s
agent0:                 episode reward: -1.2025,                 loss: nan
agent1:                 episode reward: 1.2025,                 loss: 0.1293
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3317s / 328.5186 s
agent0:                 episode reward: -0.8282,                 loss: nan
agent1:                 episode reward: 0.8282,                 loss: 0.1273
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3512s / 328.8698 s
agent0:                 episode reward: -0.7889,                 loss: nan
agent1:                 episode reward: 0.7889,                 loss: 0.1282
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3544s / 329.2242 s
agent0:                 episode reward: -0.8239,                 loss: nan
agent1:                 episode reward: 0.8239,                 loss: 0.1269
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 329.5557 s
agent0:                 episode reward: -0.7412,                 loss: nan
agent1:                 episode reward: 0.7412,                 loss: 0.1258
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3289s / 329.8846 s
agent0:                 episode reward: -0.7302,                 loss: nan
agent1:                 episode reward: 0.7302,                 loss: 0.1273
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3264s / 330.2110 s
agent0:                 episode reward: -0.7783,                 loss: nan
agent1:                 episode reward: 0.7783,                 loss: 0.1257
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 330.5474 s
agent0:                 episode reward: -0.6081,                 loss: nan
agent1:                 episode reward: 0.6081,                 loss: 0.1264
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3268s / 330.8742 s
agent0:                 episode reward: -1.0842,                 loss: nan
agent1:                 episode reward: 1.0842,                 loss: 0.1277
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3161s / 331.1903 s
agent0:                 episode reward: -0.5140,                 loss: nan
agent1:                 episode reward: 0.5140,                 loss: 0.1263
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3125s / 331.5028 s
agent0:                 episode reward: -0.4036,                 loss: nan
agent1:                 episode reward: 0.4036,                 loss: 0.1273
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3308s / 331.8336 s
agent0:                 episode reward: -0.7410,                 loss: nan
agent1:                 episode reward: 0.7410,                 loss: 0.1256
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3632s / 332.1967 s
agent0:                 episode reward: -0.4616,                 loss: nan
agent1:                 episode reward: 0.4616,                 loss: 0.1278
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3345s / 332.5312 s
agent0:                 episode reward: -0.7542,                 loss: nan
agent1:                 episode reward: 0.7542,                 loss: 0.1282
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3322s / 332.8634 s
agent0:                 episode reward: -0.8046,                 loss: nan
agent1:                 episode reward: 0.8046,                 loss: 0.1271
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3367s / 333.2001 s
agent0:                 episode reward: -0.3596,                 loss: nan
agent1:                 episode reward: 0.3596,                 loss: 0.1285
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3237s / 333.5238 s
agent0:                 episode reward: -0.8281,                 loss: nan
agent1:                 episode reward: 0.8281,                 loss: 0.1278
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3261s / 333.8499 s
agent0:                 episode reward: -0.7901,                 loss: nan
agent1:                 episode reward: 0.7901,                 loss: 0.1277
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3271s / 334.1769 s
agent0:                 episode reward: -1.0192,                 loss: nan
agent1:                 episode reward: 1.0192,                 loss: 0.1293
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3374s / 334.5143 s
agent0:                 episode reward: -0.6572,                 loss: nan
agent1:                 episode reward: 0.6572,                 loss: 0.1296
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3317s / 334.8460 s
agent0:                 episode reward: -0.6161,                 loss: nan
agent1:                 episode reward: 0.6161,                 loss: 0.1297
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3588s / 335.2048 s
agent0:                 episode reward: -0.5070,                 loss: nan
agent1:                 episode reward: 0.5070,                 loss: 0.1273
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3381s / 335.5429 s
agent0:                 episode reward: -0.3813,                 loss: nan
agent1:                 episode reward: 0.3813,                 loss: 0.1287
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3666s / 335.9095 s
agent0:                 episode reward: -0.3362,                 loss: nan
agent1:                 episode reward: 0.3362,                 loss: 0.1264
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3326s / 336.2421 s
agent0:                 episode reward: -0.8448,                 loss: nan
agent1:                 episode reward: 0.8448,                 loss: 0.1268
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3361s / 336.5782 s
agent0:                 episode reward: -0.6055,                 loss: nan
agent1:                 episode reward: 0.6055,                 loss: 0.1300
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3343s / 336.9124 s
agent0:                 episode reward: -0.9183,                 loss: nan
agent1:                 episode reward: 0.9183,                 loss: 0.1270
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3398s / 337.2522 s
agent0:                 episode reward: -0.7248,                 loss: nan
agent1:                 episode reward: 0.7248,                 loss: 0.1281
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3395s / 337.5917 s
agent0:                 episode reward: -0.8037,                 loss: nan
agent1:                 episode reward: 0.8037,                 loss: 0.1280
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3385s / 337.9302 s
agent0:                 episode reward: -1.0052,                 loss: nan
agent1:                 episode reward: 1.0052,                 loss: 0.1286
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3550s / 338.2852 s
agent0:                 episode reward: -0.6192,                 loss: nan
agent1:                 episode reward: 0.6192,                 loss: 0.1269
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3395s / 338.6247 s
agent0:                 episode reward: -0.6435,                 loss: nan
agent1:                 episode reward: 0.6435,                 loss: 0.1262
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3358s / 338.9605 s
agent0:                 episode reward: -0.4846,                 loss: nan
agent1:                 episode reward: 0.4846,                 loss: 0.1273
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3371s / 339.2976 s
agent0:                 episode reward: -0.9000,                 loss: nan
agent1:                 episode reward: 0.9000,                 loss: 0.1275
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3330s / 339.6306 s
agent0:                 episode reward: -1.2098,                 loss: nan
agent1:                 episode reward: 1.2098,                 loss: 0.1260
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3351s / 339.9657 s
agent0:                 episode reward: -0.9052,                 loss: nan
agent1:                 episode reward: 0.9052,                 loss: 0.1263
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3431s / 340.3088 s
agent0:                 episode reward: -0.9626,                 loss: nan
agent1:                 episode reward: 0.9626,                 loss: 0.1280
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3401s / 340.6489 s
agent0:                 episode reward: -1.0711,                 loss: nan
agent1:                 episode reward: 1.0711,                 loss: 0.1276
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3371s / 340.9860 s
agent0:                 episode reward: -0.9120,                 loss: nan
agent1:                 episode reward: 0.9120,                 loss: 0.1269
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3576s / 341.3436 s
agent0:                 episode reward: -0.8800,                 loss: nan
agent1:                 episode reward: 0.8800,                 loss: 0.1272
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3380s / 341.6816 s
agent0:                 episode reward: -0.7315,                 loss: nan
agent1:                 episode reward: 0.7315,                 loss: 0.1275
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 342.0133 s
agent0:                 episode reward: -0.5926,                 loss: nan
agent1:                 episode reward: 0.5926,                 loss: 0.1259
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3312s / 342.3444 s
agent0:                 episode reward: -1.0498,                 loss: nan
agent1:                 episode reward: 1.0498,                 loss: 0.1281
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3341s / 342.6785 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.1259
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3375s / 343.0160 s
agent0:                 episode reward: -0.7318,                 loss: nan
agent1:                 episode reward: 0.7318,                 loss: 0.1272
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3331s / 343.3490 s
agent0:                 episode reward: -0.6952,                 loss: nan
agent1:                 episode reward: 0.6952,                 loss: 0.1272
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3352s / 343.6842 s
agent0:                 episode reward: -0.4616,                 loss: nan
agent1:                 episode reward: 0.4616,                 loss: 0.1278
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3315s / 344.0157 s
agent0:                 episode reward: -0.7373,                 loss: nan
agent1:                 episode reward: 0.7373,                 loss: 0.1263
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3796s / 344.3952 s
agent0:                 episode reward: -0.4571,                 loss: nan
agent1:                 episode reward: 0.4571,                 loss: 0.1273
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3393s / 344.7346 s
agent0:                 episode reward: -0.7032,                 loss: nan
agent1:                 episode reward: 0.7032,                 loss: 0.1271
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3375s / 345.0720 s
agent0:                 episode reward: -0.2932,                 loss: nan
agent1:                 episode reward: 0.2932,                 loss: 0.1261
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3451s / 345.4171 s
agent0:                 episode reward: -0.4047,                 loss: nan
agent1:                 episode reward: 0.4047,                 loss: 0.1278
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3363s / 345.7534 s
agent0:                 episode reward: -0.7820,                 loss: nan
agent1:                 episode reward: 0.7820,                 loss: 0.1269
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3356s / 346.0890 s
agent0:                 episode reward: -0.6273,                 loss: nan
agent1:                 episode reward: 0.6273,                 loss: 0.1269
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3329s / 346.4219 s
agent0:                 episode reward: -0.3920,                 loss: nan
agent1:                 episode reward: 0.3920,                 loss: 0.1272
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3307s / 346.7526 s
agent0:                 episode reward: -0.5897,                 loss: nan
agent1:                 episode reward: 0.5897,                 loss: 0.1280
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3341s / 347.0868 s
agent0:                 episode reward: -0.5214,                 loss: nan
agent1:                 episode reward: 0.5214,                 loss: 0.1274
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3612s / 347.4480 s
agent0:                 episode reward: -0.7725,                 loss: nan
agent1:                 episode reward: 0.7725,                 loss: 0.1276
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3397s / 347.7877 s
agent0:                 episode reward: -0.8542,                 loss: nan
agent1:                 episode reward: 0.8542,                 loss: 0.1271
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3435s / 348.1311 s
agent0:                 episode reward: -0.7897,                 loss: nan
agent1:                 episode reward: 0.7897,                 loss: 0.1276
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3388s / 348.4699 s
agent0:                 episode reward: -0.6389,                 loss: nan
agent1:                 episode reward: 0.6389,                 loss: 0.1271
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3325s / 348.8024 s
agent0:                 episode reward: -0.7894,                 loss: nan
agent1:                 episode reward: 0.7894,                 loss: 0.1276
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3393s / 349.1417 s
agent0:                 episode reward: -0.5889,                 loss: nan
agent1:                 episode reward: 0.5889,                 loss: 0.1275
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3395s / 349.4812 s
agent0:                 episode reward: -0.4966,                 loss: nan
agent1:                 episode reward: 0.4966,                 loss: 0.1271
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3402s / 349.8215 s
agent0:                 episode reward: -0.4294,                 loss: nan
agent1:                 episode reward: 0.4294,                 loss: 0.1285
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3445s / 350.1659 s
agent0:                 episode reward: -0.6406,                 loss: nan
agent1:                 episode reward: 0.6406,                 loss: 0.1278
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3784s / 350.5444 s
agent0:                 episode reward: -0.9238,                 loss: nan
agent1:                 episode reward: 0.9238,                 loss: 0.1275
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3275s / 350.8719 s
agent0:                 episode reward: -0.7636,                 loss: nan
agent1:                 episode reward: 0.7636,                 loss: 0.1263
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3217s / 351.1936 s
agent0:                 episode reward: -0.8624,                 loss: nan
agent1:                 episode reward: 0.8624,                 loss: 0.1268
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3253s / 351.5188 s
agent0:                 episode reward: -1.1754,                 loss: nan
agent1:                 episode reward: 1.1754,                 loss: 0.1280
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3372s / 351.8560 s
agent0:                 episode reward: -0.5418,                 loss: nan
agent1:                 episode reward: 0.5418,                 loss: 0.1285
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3406s / 352.1966 s
agent0:                 episode reward: -0.6522,                 loss: nan
agent1:                 episode reward: 0.6522,                 loss: 0.1279
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3538s / 352.5504 s
agent0:                 episode reward: -0.7014,                 loss: nan
agent1:                 episode reward: 0.7014,                 loss: 0.1279
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3427s / 352.8930 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.1273
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3442s / 353.2372 s
agent0:                 episode reward: -0.9058,                 loss: nan
agent1:                 episode reward: 0.9058,                 loss: 0.1265
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3628s / 353.5999 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.1253
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3397s / 353.9396 s
agent0:                 episode reward: -0.6591,                 loss: nan
agent1:                 episode reward: 0.6591,                 loss: 0.1269
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3428s / 354.2824 s
agent0:                 episode reward: -0.8981,                 loss: nan
agent1:                 episode reward: 0.8981,                 loss: 0.1268
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3455s / 354.6279 s
agent0:                 episode reward: -1.3181,                 loss: nan
agent1:                 episode reward: 1.3181,                 loss: 0.1265
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3430s / 354.9709 s
agent0:                 episode reward: -0.9549,                 loss: nan
agent1:                 episode reward: 0.9549,                 loss: 0.1273
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3363s / 355.3071 s
agent0:                 episode reward: -0.7007,                 loss: nan
agent1:                 episode reward: 0.7007,                 loss: 0.1265
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3359s / 355.6431 s
agent0:                 episode reward: -0.6775,                 loss: nan
agent1:                 episode reward: 0.6775,                 loss: 0.1271
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3405s / 355.9836 s
agent0:                 episode reward: -0.7732,                 loss: nan
agent1:                 episode reward: 0.7732,                 loss: 0.1277
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3319s / 356.3155 s
agent0:                 episode reward: -0.7919,                 loss: nan
agent1:                 episode reward: 0.7919,                 loss: 0.1267
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3576s / 356.6731 s
agent0:                 episode reward: -0.7036,                 loss: nan
agent1:                 episode reward: 0.7036,                 loss: 0.1250
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3306s / 357.0037 s
agent0:                 episode reward: -0.3094,                 loss: nan
agent1:                 episode reward: 0.3094,                 loss: 0.1267
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3288s / 357.3325 s
agent0:                 episode reward: -0.9039,                 loss: nan
agent1:                 episode reward: 0.9039,                 loss: 0.1262
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3312s / 357.6637 s
agent0:                 episode reward: -0.5310,                 loss: nan
agent1:                 episode reward: 0.5310,                 loss: 0.1269
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 357.9878 s
agent0:                 episode reward: -0.5485,                 loss: nan
agent1:                 episode reward: 0.5485,                 loss: 0.1265
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3288s / 358.3165 s
agent0:                 episode reward: -0.8721,                 loss: nan
agent1:                 episode reward: 0.8721,                 loss: 0.1264
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3311s / 358.6476 s
agent0:                 episode reward: -0.7487,                 loss: nan
agent1:                 episode reward: 0.7487,                 loss: 0.1270
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 358.9721 s
agent0:                 episode reward: -0.8181,                 loss: nan
agent1:                 episode reward: 0.8181,                 loss: 0.1250
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 359.2986 s
agent0:                 episode reward: -0.5932,                 loss: nan
agent1:                 episode reward: 0.5932,                 loss: 0.1274
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3504s / 359.6490 s
agent0:                 episode reward: -0.8559,                 loss: nan
agent1:                 episode reward: 0.8559,                 loss: 0.1260
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3262s / 359.9752 s
agent0:                 episode reward: -1.0272,                 loss: nan
agent1:                 episode reward: 1.0272,                 loss: 0.1249
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3389s / 360.3140 s
agent0:                 episode reward: -0.4432,                 loss: nan
agent1:                 episode reward: 0.4432,                 loss: 0.1260
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3230s / 360.6370 s
agent0:                 episode reward: -0.7510,                 loss: nan
agent1:                 episode reward: 0.7510,                 loss: 0.1267
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3413s / 360.9784 s
agent0:                 episode reward: -1.0077,                 loss: nan
agent1:                 episode reward: 1.0077,                 loss: 0.1277
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3294s / 361.3077 s
agent0:                 episode reward: -0.3958,                 loss: nan
agent1:                 episode reward: 0.3958,                 loss: 0.1280
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3340s / 361.6417 s
agent0:                 episode reward: -0.7644,                 loss: nan
agent1:                 episode reward: 0.7644,                 loss: 0.1277
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3514s / 361.9931 s
agent0:                 episode reward: -0.4295,                 loss: nan
agent1:                 episode reward: 0.4295,                 loss: 0.1259
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3549s / 362.3480 s
agent0:                 episode reward: -0.8953,                 loss: nan
agent1:                 episode reward: 0.8953,                 loss: 0.1269
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3686s / 362.7166 s
agent0:                 episode reward: -0.8941,                 loss: nan
agent1:                 episode reward: 0.8941,                 loss: 0.1275
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3432s / 363.0598 s
agent0:                 episode reward: -0.6467,                 loss: nan
agent1:                 episode reward: 0.6467,                 loss: 0.1282
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3451s / 363.4049 s
agent0:                 episode reward: -0.6605,                 loss: nan
agent1:                 episode reward: 0.6605,                 loss: 0.1270
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3407s / 363.7456 s
agent0:                 episode reward: -0.9312,                 loss: nan
agent1:                 episode reward: 0.9312,                 loss: 0.1274
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3466s / 364.0922 s
agent0:                 episode reward: -0.9154,                 loss: nan
agent1:                 episode reward: 0.9154,                 loss: 0.1263
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3490s / 364.4412 s
agent0:                 episode reward: -0.4773,                 loss: nan
agent1:                 episode reward: 0.4773,                 loss: 0.1274
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3487s / 364.7899 s
agent0:                 episode reward: -0.4894,                 loss: nan
agent1:                 episode reward: 0.4894,                 loss: 0.1265
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3319s / 365.1218 s
agent0:                 episode reward: -0.3521,                 loss: nan
agent1:                 episode reward: 0.3521,                 loss: 0.1282
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3308s / 365.4526 s
agent0:                 episode reward: -0.8712,                 loss: nan
agent1:                 episode reward: 0.8712,                 loss: 0.1270
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3509s / 365.8036 s
agent0:                 episode reward: -0.3572,                 loss: nan
agent1:                 episode reward: 0.3572,                 loss: 0.1264
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3243s / 366.1279 s
agent0:                 episode reward: -0.7338,                 loss: nan
agent1:                 episode reward: 0.7338,                 loss: 0.1267
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3278s / 366.4557 s
agent0:                 episode reward: -1.1452,                 loss: nan
agent1:                 episode reward: 1.1452,                 loss: 0.1266
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3251s / 366.7809 s
agent0:                 episode reward: -1.0147,                 loss: nan
agent1:                 episode reward: 1.0147,                 loss: 0.1285
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3259s / 367.1067 s
agent0:                 episode reward: -0.7545,                 loss: nan
agent1:                 episode reward: 0.7545,                 loss: 0.1292
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3264s / 367.4332 s
agent0:                 episode reward: -0.7031,                 loss: nan
agent1:                 episode reward: 0.7031,                 loss: 0.1289
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3269s / 367.7601 s
agent0:                 episode reward: -0.7067,                 loss: nan
agent1:                 episode reward: 0.7067,                 loss: 0.1274
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3280s / 368.0881 s
agent0:                 episode reward: -0.8224,                 loss: nan
agent1:                 episode reward: 0.8224,                 loss: 0.1277
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3287s / 368.4167 s
agent0:                 episode reward: -0.8826,                 loss: nan
agent1:                 episode reward: 0.8826,                 loss: 0.1281
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3617s / 368.7784 s
agent0:                 episode reward: -0.6158,                 loss: nan
agent1:                 episode reward: 0.6158,                 loss: 0.1282
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3605s / 369.1389 s
agent0:                 episode reward: -0.6288,                 loss: nan
agent1:                 episode reward: 0.6288,                 loss: 0.1277
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3781s / 369.5170 s
agent0:                 episode reward: -0.6926,                 loss: nan
agent1:                 episode reward: 0.6926,                 loss: 0.1264
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3301s / 369.8470 s
agent0:                 episode reward: -0.5626,                 loss: nan
agent1:                 episode reward: 0.5626,                 loss: 0.1272
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3304s / 370.1774 s
agent0:                 episode reward: -0.5737,                 loss: nan
agent1:                 episode reward: 0.5737,                 loss: 0.1282
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3361s / 370.5135 s
agent0:                 episode reward: -0.6096,                 loss: nan
agent1:                 episode reward: 0.6096,                 loss: 0.1276
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3390s / 370.8525 s
agent0:                 episode reward: -0.9473,                 loss: nan
agent1:                 episode reward: 0.9473,                 loss: 0.1267
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3433s / 371.1959 s
agent0:                 episode reward: -0.6794,                 loss: nan
agent1:                 episode reward: 0.6794,                 loss: 0.1288
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3404s / 371.5363 s
agent0:                 episode reward: -0.7962,                 loss: nan
agent1:                 episode reward: 0.7962,                 loss: 0.1277
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3899s / 371.9262 s
agent0:                 episode reward: -0.5703,                 loss: nan
agent1:                 episode reward: 0.5703,                 loss: 0.1292
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3428s / 372.2689 s
agent0:                 episode reward: -0.9361,                 loss: nan
agent1:                 episode reward: 0.9361,                 loss: 0.1271
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3470s / 372.6160 s
agent0:                 episode reward: -0.8003,                 loss: nan
agent1:                 episode reward: 0.8003,                 loss: 0.1284
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3338s / 372.9498 s
agent0:                 episode reward: -0.4425,                 loss: nan
agent1:                 episode reward: 0.4425,                 loss: 0.1268
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3321s / 373.2820 s
agent0:                 episode reward: -0.9209,                 loss: nan
agent1:                 episode reward: 0.9209,                 loss: 0.1267
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3332s / 373.6152 s
agent0:                 episode reward: -0.6612,                 loss: nan
agent1:                 episode reward: 0.6612,                 loss: 0.1280
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3298s / 373.9449 s
agent0:                 episode reward: -0.8424,                 loss: nan
agent1:                 episode reward: 0.8424,                 loss: 0.1277
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3331s / 374.2780 s
agent0:                 episode reward: -0.7998,                 loss: nan
agent1:                 episode reward: 0.7998,                 loss: 0.1276
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3274s / 374.6054 s
agent0:                 episode reward: -0.5662,                 loss: nan
agent1:                 episode reward: 0.5662,                 loss: 0.1285
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3797s / 374.9851 s
agent0:                 episode reward: -0.4152,                 loss: nan
agent1:                 episode reward: 0.4152,                 loss: 0.1272
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3279s / 375.3131 s
agent0:                 episode reward: -0.6570,                 loss: nan
agent1:                 episode reward: 0.6570,                 loss: 0.1268
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3283s / 375.6414 s
agent0:                 episode reward: -0.4383,                 loss: nan
agent1:                 episode reward: 0.4383,                 loss: 0.1264
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3325s / 375.9739 s
agent0:                 episode reward: -0.4422,                 loss: nan
agent1:                 episode reward: 0.4422,                 loss: 0.1281
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3286s / 376.3025 s
agent0:                 episode reward: -0.7407,                 loss: nan
agent1:                 episode reward: 0.7407,                 loss: 0.1279
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 376.6289 s
agent0:                 episode reward: -0.8739,                 loss: nan
agent1:                 episode reward: 0.8739,                 loss: 0.1272
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3266s / 376.9555 s
agent0:                 episode reward: -0.5359,                 loss: nan
agent1:                 episode reward: 0.5359,                 loss: 0.1269
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3409s / 377.2964 s
agent0:                 episode reward: -0.4497,                 loss: nan
agent1:                 episode reward: 0.4497,                 loss: 0.1277
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3526s / 377.6489 s
agent0:                 episode reward: -0.6210,                 loss: nan
agent1:                 episode reward: 0.6210,                 loss: 0.1271
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3759s / 378.0248 s
agent0:                 episode reward: -0.7023,                 loss: nan
agent1:                 episode reward: 0.7023,                 loss: 0.1265
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3430s / 378.3678 s
agent0:                 episode reward: -0.7893,                 loss: nan
agent1:                 episode reward: 0.7893,                 loss: 0.1269
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4060s / 378.7738 s
agent0:                 episode reward: -0.5436,                 loss: nan
agent1:                 episode reward: 0.5436,                 loss: 0.1279
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3524s / 379.1262 s
agent0:                 episode reward: -1.0439,                 loss: nan
agent1:                 episode reward: 1.0439,                 loss: 0.1275
Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3468s / 379.4731 s
agent0:                 episode reward: -0.4816,                 loss: nan
agent1:                 episode reward: 0.4816,                 loss: 0.1277
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3437s / 379.8168 s
agent0:                 episode reward: -0.8933,                 loss: nan
agent1:                 episode reward: 0.8933,                 loss: 0.1263
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3474s / 380.1642 s/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

agent0:                 episode reward: -0.8604,                 loss: nan
agent1:                 episode reward: 0.8604,                 loss: 0.1270
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3497s / 380.5139 s
agent0:                 episode reward: -1.2283,                 loss: nan
agent1:                 episode reward: 1.2283,                 loss: 0.1248
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3716s / 380.8856 s
agent0:                 episode reward: -0.8497,                 loss: nan
agent1:                 episode reward: 0.8497,                 loss: 0.1263
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3929s / 381.2785 s
agent0:                 episode reward: -0.4719,                 loss: nan
agent1:                 episode reward: 0.4719,                 loss: 0.1267
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3484s / 381.6269 s
agent0:                 episode reward: -0.4518,                 loss: nan
agent1:                 episode reward: 0.4518,                 loss: 0.1273
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3501s / 381.9771 s
agent0:                 episode reward: -1.0174,                 loss: nan
agent1:                 episode reward: 1.0174,                 loss: 0.1278
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3477s / 382.3248 s
agent0:                 episode reward: -0.5746,                 loss: nan
agent1:                 episode reward: 0.5746,                 loss: 0.1287
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3287s / 382.6535 s
agent0:                 episode reward: -1.0048,                 loss: nan
agent1:                 episode reward: 1.0048,                 loss: 0.1274
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3272s / 382.9807 s
agent0:                 episode reward: -0.4963,                 loss: nan
agent1:                 episode reward: 0.4963,                 loss: 0.1271
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3276s / 383.3083 s
agent0:                 episode reward: -0.9917,                 loss: nan
agent1:                 episode reward: 0.9917,                 loss: 0.1271
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3293s / 383.6376 s
agent0:                 episode reward: -0.6000,                 loss: nan
agent1:                 episode reward: 0.6000,                 loss: 0.1268
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3466s / 383.9843 s
agent0:                 episode reward: -0.9703,                 loss: nan
agent1:                 episode reward: 0.9703,                 loss: 0.1270
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3404s / 384.3246 s
agent0:                 episode reward: -0.8054,                 loss: nan
agent1:                 episode reward: 0.8054,                 loss: 0.1264
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3302s / 384.6548 s
agent0:                 episode reward: -1.0201,                 loss: nan
agent1:                 episode reward: 1.0201,                 loss: 0.1262
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3345s / 384.9893 s
agent0:                 episode reward: -0.7509,                 loss: nan
agent1:                 episode reward: 0.7509,                 loss: 0.1272
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3346s / 385.3239 s
agent0:                 episode reward: -0.9417,                 loss: nan
agent1:                 episode reward: 0.9417,                 loss: 0.1269
