pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 42.0, (1,), float32) action space: Discrete(6)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f58b236fbe0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518032943/mdp_arbitrary_mdp_nfsp/30000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518032943/mdp_arbitrary_mdp_nfsp/30000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518032943_exploit_30000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518032943_exploit_30000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 7.3952s / 7.3952 s
agent0:                 episode reward: 1.1056,                 loss: nan
agent1:                 episode reward: -1.1056,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3452s / 7.7404 s
agent0:                 episode reward: 0.2893,                 loss: nan
agent1:                 episode reward: -0.2893,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3916s / 8.1320 s
agent0:                 episode reward: 0.4717,                 loss: nan
agent1:                 episode reward: -0.4717,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3974s / 8.5294 s
agent0:                 episode reward: 0.1883,                 loss: nan
agent1:                 episode reward: -0.1883,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4000s / 8.9294 s
agent0:                 episode reward: 0.4038,                 loss: nan
agent1:                 episode reward: -0.4038,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3990s / 9.3283 s
agent0:                 episode reward: 0.3546,                 loss: nan
agent1:                 episode reward: -0.3546,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3917s / 9.7200 s
agent0:                 episode reward: 0.0224,                 loss: nan
agent1:                 episode reward: -0.0224,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4016s / 10.1217 s
agent0:                 episode reward: -0.0373,                 loss: nan
agent1:                 episode reward: 0.0373,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3992s / 10.5208 s
agent0:                 episode reward: 0.2756,                 loss: nan
agent1:                 episode reward: -0.2756,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3907s / 10.9116 s
agent0:                 episode reward: 0.1692,                 loss: nan
agent1:                 episode reward: -0.1692,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3994s / 11.3110 s
agent0:                 episode reward: -0.0991,                 loss: nan
agent1:                 episode reward: 0.0991,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3928s / 11.7037 s
agent0:                 episode reward: 0.8638,                 loss: nan
agent1:                 episode reward: -0.8638,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3974s / 12.1011 s
agent0:                 episode reward: 0.7671,                 loss: nan
agent1:                 episode reward: -0.7671,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3909s / 12.4920 s
agent0:                 episode reward: 0.5389,                 loss: nan
agent1:                 episode reward: -0.5389,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3956s / 12.8875 s
agent0:                 episode reward: 0.3333,                 loss: nan
agent1:                 episode reward: -0.3333,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3934s / 13.2809 s
agent0:                 episode reward: -0.1724,                 loss: nan
agent1:                 episode reward: 0.1724,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3853s / 13.6662 s
agent0:                 episode reward: -0.2239,                 loss: nan
agent1:                 episode reward: 0.2239,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3917s / 14.0579 s
agent0:                 episode reward: 0.9527,                 loss: nan
agent1:                 episode reward: -0.9527,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3895s / 14.4474 s
agent0:                 episode reward: 0.4592,                 loss: nan
agent1:                 episode reward: -0.4592,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3941s / 14.8415 s
agent0:                 episode reward: 0.4433,                 loss: nan
agent1:                 episode reward: -0.4433,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3922s / 15.2337 s
agent0:                 episode reward: 0.6912,                 loss: nan
agent1:                 episode reward: -0.6912,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3909s / 15.6246 s
agent0:                 episode reward: 0.2164,                 loss: nan
agent1:                 episode reward: -0.2164,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3921s / 16.0167 s
agent0:                 episode reward: 0.2517,                 loss: nan
agent1:                 episode reward: -0.2517,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3882s / 16.4049 s
agent0:                 episode reward: -0.2589,                 loss: nan
agent1:                 episode reward: 0.2589,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3884s / 16.7934 s
agent0:                 episode reward: 0.5033,                 loss: nan
agent1:                 episode reward: -0.5033,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3930s / 17.1863 s
agent0:                 episode reward: 0.7044,                 loss: nan
agent1:                 episode reward: -0.7044,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3982s / 17.5846 s
agent0:                 episode reward: 0.2952,                 loss: nan
agent1:                 episode reward: -0.2952,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3916s / 17.9761 s
agent0:                 episode reward: 0.1492,                 loss: nan
agent1:                 episode reward: -0.1492,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3947s / 18.3708 s
agent0:                 episode reward: 0.4050,                 loss: nan
agent1:                 episode reward: -0.4050,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3962s / 18.7670 s
agent0:                 episode reward: 0.4843,                 loss: nan
agent1:                 episode reward: -0.4843,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3888s / 19.1559 s
agent0:                 episode reward: 1.3126,                 loss: nan
agent1:                 episode reward: -1.3126,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3944s / 19.5503 s
agent0:                 episode reward: 0.9562,                 loss: nan
agent1:                 episode reward: -0.9562,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3883s / 19.9387 s
agent0:                 episode reward: 0.7721,                 loss: nan
agent1:                 episode reward: -0.7721,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3926s / 20.3313 s
agent0:                 episode reward: 0.5473,                 loss: nan
agent1:                 episode reward: -0.5473,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3937s / 20.7250 s
agent0:                 episode reward: 0.0238,                 loss: nan
agent1:                 episode reward: -0.0238,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3963s / 21.1213 s
agent0:                 episode reward: 0.1374,                 loss: nan
agent1:                 episode reward: -0.1374,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3977s / 21.5190 s
agent0:                 episode reward: 0.0849,                 loss: nan
agent1:                 episode reward: -0.0849,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3879s / 21.9068 s
agent0:                 episode reward: 0.2461,                 loss: nan
agent1:                 episode reward: -0.2461,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3861s / 22.2929 s
agent0:                 episode reward: 0.4179,                 loss: nan
agent1:                 episode reward: -0.4179,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3962s / 22.6891 s
agent0:                 episode reward: 0.2462,                 loss: nan
agent1:                 episode reward: -0.2462,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3941s / 23.0831 s
agent0:                 episode reward: 0.6053,                 loss: nan
agent1:                 episode reward: -0.6053,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3920s / 23.4751 s
agent0:                 episode reward: 0.6665,                 loss: nan
agent1:                 episode reward: -0.6665,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3860s / 23.8611 s
agent0:                 episode reward: 0.4156,                 loss: nan
agent1:                 episode reward: -0.4156,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3928s / 24.2539 s
agent0:                 episode reward: 0.9717,                 loss: nan
agent1:                 episode reward: -0.9717,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3892s / 24.6431 s
agent0:                 episode reward: 0.0209,                 loss: nan
agent1:                 episode reward: -0.0209,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3922s / 25.0353 s
agent0:                 episode reward: 1.1393,                 loss: nan
agent1:                 episode reward: -1.1393,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3970s / 25.4322 s
agent0:                 episode reward: 0.7868,                 loss: nan
agent1:                 episode reward: -0.7868,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3985s / 25.8307 s
agent0:                 episode reward: 0.8718,                 loss: nan
agent1:                 episode reward: -0.8718,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3936s / 26.2244 s
agent0:                 episode reward: 0.2725,                 loss: nan
agent1:                 episode reward: -0.2725,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3936s / 26.6180 s
agent0:                 episode reward: 1.0222,                 loss: nan
agent1:                 episode reward: -1.0222,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3955s / 27.0135 s
agent0:                 episode reward: 0.1036,                 loss: nan
agent1:                 episode reward: -0.1036,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3923s / 27.4058 s
agent0:                 episode reward: 0.4702,                 loss: nan
agent1:                 episode reward: -0.4702,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3887s / 27.7944 s
agent0:                 episode reward: 0.6429,                 loss: nan
agent1:                 episode reward: -0.6429,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3912s / 28.1856 s
agent0:                 episode reward: 0.3729,                 loss: nan
agent1:                 episode reward: -0.3729,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3912s / 28.5768 s
agent0:                 episode reward: 0.7068,                 loss: nan
agent1:                 episode reward: -0.7068,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3948s / 28.9716 s
agent0:                 episode reward: 0.4704,                 loss: nan
agent1:                 episode reward: -0.4704,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3947s / 29.3663 s
agent0:                 episode reward: 0.6034,                 loss: nan
agent1:                 episode reward: -0.6034,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3935s / 29.7598 s
agent0:                 episode reward: 0.5701,                 loss: nan
agent1:                 episode reward: -0.5701,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3954s / 30.1552 s
agent0:                 episode reward: 1.2742,                 loss: nan
agent1:                 episode reward: -1.2742,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3835s / 30.5387 s
agent0:                 episode reward: 0.4325,                 loss: nan
agent1:                 episode reward: -0.4325,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3888s / 30.9275 s
agent0:                 episode reward: 0.5586,                 loss: nan
agent1:                 episode reward: -0.5586,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3925s / 31.3200 s
agent0:                 episode reward: 0.4578,                 loss: nan
agent1:                 episode reward: -0.4578,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3924s / 31.7123 s
agent0:                 episode reward: -0.1297,                 loss: nan
agent1:                 episode reward: 0.1297,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3938s / 32.1062 s
agent0:                 episode reward: 0.1375,                 loss: nan
agent1:                 episode reward: -0.1375,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3948s / 32.5009 s
agent0:                 episode reward: 0.1907,                 loss: nan
agent1:                 episode reward: -0.1907,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3882s / 32.8891 s
agent0:                 episode reward: 0.5327,                 loss: nan
agent1:                 episode reward: -0.5327,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3928s / 33.2819 s
agent0:                 episode reward: 0.3829,                 loss: nan
agent1:                 episode reward: -0.3829,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3927s / 33.6746 s
agent0:                 episode reward: 0.5284,                 loss: nan
agent1:                 episode reward: -0.5284,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3961s / 34.0707 s
agent0:                 episode reward: 0.4735,                 loss: nan
agent1:                 episode reward: -0.4735,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3900s / 34.4607 s
agent0:                 episode reward: 0.2186,                 loss: nan
agent1:                 episode reward: -0.2186,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3890s / 34.8497 s
agent0:                 episode reward: -0.0495,                 loss: nan
agent1:                 episode reward: 0.0495,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3965s / 35.2461 s
agent0:                 episode reward: -0.4859,                 loss: nan
agent1:                 episode reward: 0.4859,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3965s / 35.6426 s
agent0:                 episode reward: 0.9880,                 loss: nan
agent1:                 episode reward: -0.9880,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3967s / 36.0393 s
agent0:                 episode reward: 0.2175,                 loss: nan
agent1:                 episode reward: -0.2175,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3855s / 36.4248 s
agent0:                 episode reward: 0.2492,                 loss: nan
agent1:                 episode reward: -0.2492,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3907s / 36.8155 s
agent0:                 episode reward: 0.4832,                 loss: nan
agent1:                 episode reward: -0.4832,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4318s / 37.2473 s
agent0:                 episode reward: 0.5991,                 loss: nan
agent1:                 episode reward: -0.5991,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3660s / 37.6133 s
agent0:                 episode reward: 0.6561,                 loss: nan
agent1:                 episode reward: -0.6561,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3892s / 38.0025 s
agent0:                 episode reward: 0.1907,                 loss: nan
agent1:                 episode reward: -0.1907,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3910s / 38.3934 s
agent0:                 episode reward: 0.6436,                 loss: nan
agent1:                 episode reward: -0.6436,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3977s / 38.7911 s
agent0:                 episode reward: 0.8750,                 loss: nan
agent1:                 episode reward: -0.8750,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3925s / 39.1837 s
agent0:                 episode reward: 0.4081,                 loss: nan
agent1:                 episode reward: -0.4081,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3881s / 39.5718 s
agent0:                 episode reward: 0.2774,                 loss: nan
agent1:                 episode reward: -0.2774,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3933s / 39.9651 s
agent0:                 episode reward: 0.2850,                 loss: nan
agent1:                 episode reward: -0.2850,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 2.2314s / 42.1965 s
agent0:                 episode reward: -0.4268,                 loss: nan
agent1:                 episode reward: 0.4268,                 loss: 0.4497
Episode: 1701/30000 (5.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1371s / 43.3336 s
agent0:                 episode reward: 0.5107,                 loss: nan
agent1:                 episode reward: -0.5107,                 loss: 0.4325
Episode: 1721/30000 (5.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1442s / 44.4778 s
agent0:                 episode reward: 0.2215,                 loss: nan
agent1:                 episode reward: -0.2215,                 loss: 0.4230
Episode: 1741/30000 (5.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1442s / 45.6220 s
agent0:                 episode reward: 0.3972,                 loss: nan
agent1:                 episode reward: -0.3972,                 loss: 0.4183
Episode: 1761/30000 (5.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1373s / 46.7593 s
agent0:                 episode reward: 0.1894,                 loss: nan
agent1:                 episode reward: -0.1894,                 loss: 0.4121
Episode: 1781/30000 (5.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1507s / 47.9100 s
agent0:                 episode reward: -0.0005,                 loss: nan
agent1:                 episode reward: 0.0005,                 loss: 0.4039
Episode: 1801/30000 (6.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1390s / 49.0490 s
agent0:                 episode reward: -0.2417,                 loss: nan
agent1:                 episode reward: 0.2417,                 loss: 0.3990
Episode: 1821/30000 (6.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1558s / 50.2048 s
agent0:                 episode reward: -0.1622,                 loss: nan
agent1:                 episode reward: 0.1622,                 loss: 0.3936
Episode: 1841/30000 (6.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1551s / 51.3599 s
agent0:                 episode reward: 0.2500,                 loss: nan
agent1:                 episode reward: -0.2500,                 loss: 0.4088
Episode: 1861/30000 (6.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1440s / 52.5039 s
agent0:                 episode reward: -0.2124,                 loss: nan
agent1:                 episode reward: 0.2124,                 loss: 0.4351
Episode: 1881/30000 (6.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1448s / 53.6487 s
agent0:                 episode reward: 0.3732,                 loss: nan
agent1:                 episode reward: -0.3732,                 loss: 0.4360
Episode: 1901/30000 (6.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1501s / 54.7988 s
agent0:                 episode reward: -0.0784,                 loss: nan
agent1:                 episode reward: 0.0784,                 loss: 0.4337
Episode: 1921/30000 (6.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1424s / 55.9412 s
agent0:                 episode reward: 0.3110,                 loss: nan
agent1:                 episode reward: -0.3110,                 loss: 0.4356
Episode: 1941/30000 (6.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1515s / 57.0927 s
agent0:                 episode reward: 0.6520,                 loss: nan
agent1:                 episode reward: -0.6520,                 loss: 0.4335
Episode: 1961/30000 (6.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1459s / 58.2386 s
agent0:                 episode reward: -0.3224,                 loss: nan
agent1:                 episode reward: 0.3224,                 loss: 0.4349
Episode: 1981/30000 (6.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1577s / 59.3962 s
agent0:                 episode reward: -0.3107,                 loss: nan
agent1:                 episode reward: 0.3107,                 loss: 0.4342
Episode: 2001/30000 (6.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1470s / 60.5433 s
agent0:                 episode reward: 0.2409,                 loss: nan
agent1:                 episode reward: -0.2409,                 loss: 0.4366
Episode: 2021/30000 (6.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1571s / 61.7003 s
agent0:                 episode reward: 0.2131,                 loss: nan
agent1:                 episode reward: -0.2131,                 loss: 0.4528
Episode: 2041/30000 (6.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1575s / 62.8578 s
agent0:                 episode reward: -0.3467,                 loss: nan
agent1:                 episode reward: 0.3467,                 loss: 0.4512
Episode: 2061/30000 (6.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1440s / 64.0018 s
agent0:                 episode reward: -0.0150,                 loss: nan